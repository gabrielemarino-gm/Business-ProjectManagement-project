{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a454567",
   "metadata": {},
   "source": [
    "# Text Mining Process for Face Recognition Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76dbc38e",
   "metadata": {},
   "source": [
    "## Getting the desired text from the patents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8238380",
   "metadata": {},
   "source": [
    "We start from parsing the files containing the patents and look for the ones which can give us useful information about the topic we are interested into.\n",
    "This is going to take some minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6cedf75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting files...\n",
      "START!\n",
      "END!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "path = 'C:\\\\Users\\\\Stefano\\\\Desktop\\\\Stefano\\\\Business\\\\Project\\\\Material\\\\MyPatents'\n",
    "print(\"Getting files...\")\n",
    "# getting all files from the directory given by the path\n",
    "files = os.listdir(path)\n",
    "# moving to the desired directory\n",
    "os.chdir(path)\n",
    "text = \"\"\n",
    "print(\"START!\")\n",
    "for filename in files:\n",
    "    file = open(filename, encoding=\"utf-8\")\n",
    "    text+=file.read();\n",
    "    #print(\"A file! \"+filename)\n",
    "    #    print(\"\\n\")\n",
    "    #print(text)\n",
    "print(\"END!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c2fa90",
   "metadata": {},
   "source": [
    "After obtaining the whole text of the file of our interest, we separate the sections containing the abstract and the claims, which are the two sections we are interested on for our analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b1d6ba1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['An electronic apparatus including an image capturing device, a storage device and a processor and an operation method thereof are provided. The image capturing device captures an image for a user, and the storage device records a plurality of modules. The processor is coupled to the image capturing device and the storage device and is configured to: configure the image capturing device to capture a head image of a user; perform a face recognition operation to obtain a face region; detect a plurality of facial landmarks within the face region; estimate a head posture angle of the user according to the facial landmarks; calculate a gaze position where the user gazes on the screen according to the head posture angle, a plurality of rotation reference angle, and a plurality of predetermined calibration positions; and configure the screen to display a corresponding visual effect according to the gaze position.', 'The present disclosure provides a computation method and product thereof. The computation method adopts a fusion method to perform machine learning computations. Technical effects of the present disclosure include fewer computations and less power consumption.', \"A method for detecting body information on passengers of a vehicle based on humans' status recognition is provided. The method includes steps of: a passenger body information-detecting device, (a) inputting an interior image of the vehicle into a face recognition network, to detect faces of the passengers and output passenger feature information, and inputting the interior image into a body recognition network, to detect bodies and output body-part length information; and (b) retrieving specific height mapping information by referring to a height mapping table of ratios of segment body portions of human groups to heights per the human groups, acquiring a specific height of the specific passenger, retrieving specific weight mapping information from a weight mapping table of correlations between the heights and weights per the human groups, and acquiring a weight of the specific passenger by referring to the specific height.\", 'Techniques related to improved video coding based on face detection, region extraction, and tracking are discussed. Such techniques may include performing a facial search of a video frame to determine candidate face regions in the video frame, testing the candidate face regions based on skin tone information to determine valid and invalid face regions, rejecting invalid face regions, and encoding the video frame based on valid face regions to generate a coded bitstream.', 'A method for managing a smart database which stores facial images for face recognition is provided. The method includes steps of: a managing device (a) counting specific facial images corresponding to a specific person in the smart database where new facial images are continuously stored, and determining whether a first counted value, representing a count of the specific facial images, satisfies a first set value; and (b) if the first counted value satisfies the first set value, inputting the specific facial images into a neural aggregation network, to generate quality scores of the specific facial images by aggregation of the specific facial images, and, if a second counted value, representing a count of specific quality scores among the quality scores from a highest during counting thereof, satisfies a second set value, deleting part of the specific facial images, corresponding to the uncounted quality scores, from the smart database.', 'A system capable of determining which recognition algorithms should be applied to regions of interest within digital representations is presented. A preprocessing module utilizes one or more feature identification algorithms to determine regions of interest based on feature density. The preprocessing modules leverages the feature density signature for each region to determine which of a plurality of diverse recognition modules should operate on the region of interest. A specific embodiment that focuses on structured documents is also presented. Further, the disclosed approach can be enhanced by addition of an object classifier that classifies types of objects found in the regions of interest.', 'Disclosed is a mobile terminal. The mobile terminal may include a front camera obtaining a 2D face image of a user, a glance sensor tilted by a certain angle and disposed adjacent to the front camera to obtain metadata of the 2D face image, and a controller obtaining a distance between the glance sensor and the front camera, the distance enabling an area of an overlap region, where a first region representing a range photographable by the front camera overlaps a second region representing a range photographable by the glance sensor, to be the maximum.', \"This disclosure provides systems, methods and apparatus, including computer programs encoded on computer storage media for intelligent routing of notifications related to media programming. In one aspect, a smart television (TV) can be implemented to track a user's TV watching behavior, and anticipate programming based on that behavior. In some other aspects, the smart TV can be implemented to detect a user's presence, and based on that detection, can automatically change the TV channel to media programming analyzed to be desirable to the user. In some further aspects, the smart TV can be implemented to transmit notification instructions to electronic devices within a network in an attempt to alert the user to upcoming media programming. Additionally, the smart TV can be implemented to transmit detection instructions to the electronic devices within the network, whereby the electronic devices attempt to detect a user's presence through voice or facial recognition.\", 'A camera is configured to output a test depth+multi-spectral image including a plurality of pixels. Each pixel corresponds to one of the plurality of sensors of a sensor array of the camera and includes at least a depth value and a spectral value for each spectral light sub-band of a plurality of spectral illuminators of the camera. A face recognition machine is previously trained with a set of labeled training depth+multi-spectral images having a same structure as the test depth+multi-spectral image. The face recognition machine is configured to output a confidence value indicating a likelihood that the test depth+multi-spectral image includes a face.', 'Embodiments of the present disclosure relate to an image processing method and apparatus, and an electronic device. The method includes: acquiring a photo album obtained from face clustering; collecting face information of respective images in the photo album, and acquiring a face parameter of each image according to the face information; selecting a cover image according to the face parameter of each image; and taking a face-region image from the cover image, and setting the face-region image as a cover of the photo album.', 'Techniques described herein provide location-based access control to secured resources. Generally described, configurations disclosed herein enable a system to dynamically modify access to secured resources based on one or more location-related actions. For example, techniques disclosed herein can enable a computing system to control access to resources such as computing devices, display devices, secured locations, and secured data. In some configurations, the techniques disclosed herein can enable controlled access to secured resources based, at least in part, on an invitation associated with a location and positioning data indicating a location of a user.', 'One embodiment provides a method comprising receiving a piece of content and salient moments data for the piece of content. The method further comprises, based on the salient moments data, determining a first path for a viewport for the piece of content. The method further comprises displaying the viewport on a display device. Movement of the viewport is based on the first path during playback of the piece of content. The method further comprises generating an augmentation for a salient moment occurring in the piece of content, and presenting the augmentation in the viewport during a portion of the playback. The augmentation comprises an interactive hint for guiding the viewport to the salient moment.', 'A computer-implemented method, system, and computer program product are provided for facial recognition. The method includes receiving, by a processor device, a plurality of images. The method also includes extracting, by the processor device with a feature extractor utilizing a convolutional neural network (CNN) with an enlarged intra-class variance of long-tail classes, feature vectors for each of the plurality of images. The method additionally includes generating, by the processor device with a feature generator, discriminative feature vectors for each of the feature vectors. The method further includes classifying, by the processor device utilizing a fully connected classifier, an identity from the discriminative feature vector. The method also includes control an operation of a processor-based machine to react in accordance with the identity.', 'Some embodiments of the invention provide efficient, expressive machine-trained networks for performing machine learning. The machine-trained (MT) networks of some embodiments use novel processing nodes with novel activation functions that allow the MT network to efficiently define with fewer processing node layers a complex mathematical expression that solves a particular problem (e.g., face recognition, speech recognition, etc.). In some embodiments, the same activation function (e.g., a cup function) is used for numerous processing nodes of the MT network, but through the machine learning, this activation function is configured differently for different processing nodes so that different nodes can emulate or implement two or more different functions (e.g., two or more Boolean logical operators, such as XOR and AND). The activation function in some embodiments is a periodic function that can be configured to implement different functions (e.g., different sinusoidal functions).', 'Methods and systems may provide for facial recognition of at least one input image utilizing hierarchical feature learning and pair-wise classification. Receptive field theory may be used on the input image to generate a pre-processed multi-channel image. Channels in the pre-processed image may be activated based on the amount of feature rich details within the channels. Similarly, local patches may be activated based on the discriminant features within the local patches. Features may be extracted from the local patches and the most discriminant features may be selected in order to perform feature matching on pair sets. The system may utilize patch feature pooling, pair-wise matching, and large-scale training in order to quickly and accurately perform facial recognition at a low cost for both system memory and computation.', 'A method for controlling a terminal is provided. The terminal includes a capturing apparatus and at least one processor. An image is acquired by the capturing apparatus. A motion parameter of the terminal is obtained. Image processing on the acquired image is controlled to be performed based on the motion parameter being equal to or less than a preset parameter threshold, and skipped based on the motion parameter being greater than the preset parameter threshold.', 'A drive-through order processing method and apparatus are disclosed. The drive-through order processing method includes receiving customer information detected through vision recognition, providing product information based on the customer information, and processing a product order of a customer. According to the present disclosure, it is possible to rapidly process an order using customer information based on customer recognition using an artificial intelligence (AI) model of machine learning through a 5G network.', 'An image processing method performed at a computing device includes: identifying, using face recognition, one or more faces, each face corresponding to a respective person captured in a first image; for each identified face: extracting a set of profile parameters of a corresponding person in the first image; and selecting, from a plurality of image tiles, a first image tile that matches the face of the corresponding person in the first image in accordance with a predefined correspondence between the set of profile parameters of the corresponding person and a set of pre-stored description parameters of the first image tile; generating a second image by covering the faces of respective persons in the first image with their corresponding first image tiles; and sharing the first image and the second image in a predefined order via a group chat session.', 'In one embodiment, the artificial reality system determines that a performance metric of an eye tracking system is below a first performance threshold. The eye tracking system is associated with a head-mounted display worn by a user. The artificial reality system receives first inputs associated with the body of a user and determines a region that the user is looking at within a field of view of a head-mounted display based on the received first inputs. The system determines a vergence distance of the user based at least on the first inputs associated with the body of the user, the region that the user is looking at, and locations of one or more objects in a scene displayed by the head-mounted display. The system adjusts one or more configurations of the head-mounted display based on the determined vergence distance of the user.', 'A computer-implemented method is provided for image-based, self-guided object detection. The method includes receiving, by a processor device, a set of images. Each of the images has a respective grid thereon that is labeled regarding a respective object to be detected using grid level label data. The method further includes training, by the processor device, a grid-based object detector using the grid level label data. The method also includes determining, by the processor device, a respective bounding box for the respective object in each of the images, by applying local segmentation to each of the images. The method additionally includes training, by the processor device, a Region-based Convolutional Neural Network (RCNN) for joint object localization and object classification using the respective bounding box for the respective object in each of the images as an input to the RCNN.', 'A system and method of face recognition comprising multiple phases implemented in a parallel architecture. The first phase is a normalization phase whereby a captured image is normalized to the same size, orientation, and illumination of stored images in a preexisting database. The second phase is a feature extraction/distance matrix phase where a distance matrix is generated for the captured image. In a coarse recognition phase, the generated distance matrix is compared with distance matrices in the database using Euclidean distance matches to create candidate lists, and in a detailed recognition phase, multiple face recognition algorithms are applied to the candidate lists to produce a final result. The distance matrices in the normalized database may be broken into parallel lists for parallelization in the feature extraction/distance matrix phase, and the candidate lists may also be grouped according to a dissimilarity algorithm for parallel processing in the detailed recognition phase.', 'An imaging device including a pixel matrix and a processor is provided. The pixel matrix includes a plurality of phase detection pixels and a plurality of regular pixels. The processor performs autofocusing according to pixel data of the phase detection pixels, and determines an operating resolution of the regular pixels according to autofocused pixel data of the phase detection pixels, wherein the phase detection pixels are always-on pixels and the regular pixels are selectively turned on after the autofocusing is accomplished.', 'An apparatus includes a first camera module providing a first image of an object with a first field of view, a second camera module providing a second image of the object with a second field of view different from the first field of view, a first depth map generator that generates a first depth map of the first image based on the first image and the second image, and a second depth map generator that generates a second depth map of the second image based on the first image, the second image, and the first depth map.', 'Methods, systems, and apparatus, including computer programs encoded on computer storage media, for a payment based on a face recognition are provided. One of the methods includes: acquiring first face image information of a target user; extracting first characteristic information from the first face image information, wherein the first characteristic information includes head posture information of the target user and gaze information of the target user; determining whether the target user has a willingness to pay according to the head posture information of the target user and the gaze information of the target user, including determining whether an angle of rotation in each preset direction is less than an angle threshold and whether a probability value that a user gazes at a payment screen is greater than a probability threshold; and in response to determining that the target user has a willingness to pay, completing a payment operation based on the face recognition.', 'A novel method and apparatus for face authentication is disclosed. The disclosed method comprises detecting a motion by a subject within a predetermined area of view, assigning a unique session identification number to the subject detected within a predetermined area of view, detecting a facial area of the subject detected within a predetermined area of view, generating an image of the facial area of the subject, assessing a quality of the image of the facial area of the subject, conducing an incremental training of the image of the facial area of the subject, determining an identity of the subject based on the image of the facial area of the subject, identifying an intent of the subject, and authorizing access to a point of entry based on the determined identity of the subject and based on the intent of the subject.', 'Disclosed herein is a robot and an electronic device for acquiring video, and a method for acquiring video using the robot. The robot includes a camera configured to rotate in the lateral direction and tilt in the vertical direction, and controls at least one of a direction of the rotation of the camera, an angle of the tilt of the camera, and a focal distance of the camera by recognizing and tracking users in a video acquired by the camera.', 'Systems and methods are disclosed for inferring topics from a file containing both audio and video, for example a multimodal or multimedia file, in order to facilitate video indexing. A set of entities is extracted from the file and linked to produce a graph, and reference information is also obtained for the set of entities. Entities may be drawn, for example, from Wikipedia categories, or other large ontological data sources. Analysis of the graph, using unsupervised learning, permits determining clusters in the graph. Extracting features from the clusters, possibly using supervised learning, provides for selection of topic identifiers. The topic identifiers are then used for indexing the file.', 'A face recognition method, a neural network training method, an apparatus, and an electronic device. The method comprises: obtaining a first face image by means of a first camera (101); extracting a first face feature of the first face image (102); comparing the first face feature with a pre-stored second face feature to obtain a reference similarity, the second face feature being obtained by extracting a feature of a second face image obtained by a second camera, and the second camera and the first camera being different types of cameras (103); and determining, according to the reference similarity, whether the first face feature and the second face feature correspond to a same person (104).', 'The present invention discloses a technique for alerting on vision impairment. The system comprises a processing unit configured and operable for receiving scene data being indicative of a scene of at least one consumer in an environment, identifying in the scene data a certain consumer, identifying an event being indicative of a behavioral compensation for vision impairment, and, upon identification of such an event, sending a notification relating to the vision impairment.']\n",
      "['1. An electronic device (10), configured to make a screen (110) to display a plurality of image frames, comprising: an image capturing device (120); a storage device (130), storing a plurality of modules; and a processor (14), coupled to the image capturing device (140) and the storage device (130), configured to execute the modules in the storage device (130) to: configure the screen (110) to display a plurality of marker objects at a plurality of predetermined calibration positions; configure the image capturing device (120) to capture a plurality of first head images when a user is looking at the predetermined calibration positions; (S301) perform a plurality of first face recognition operations on the first head images to obtain a plurality of first face regions corresponding to the predetermined calibration positions; (S302) detect a plurality of first facial landmarks corresponding to the first face regions; (S303) calculate a plurality of rotation reference angles of the user looking at the predetermined calibration positions according to the first facial landmarks; configure the image capturing device (120) to capture a second head image of the user; perform a second face recognition operation on the second head image to obtain a second face region; detect a plurality of second facial landmarks within the second face region; (S304) estimate a head posture angle of the user according to the second facial landmarks; calculate a gaze position of the user on the screen (110) according to the head posture angle, the rotation reference angles, and the predetermined calibration positions; and configure the screen (110) to display a corresponding visual effect according to the gaze position.\\n2. The electronic device (10) according to claim 1, wherein the gaze position comprises a first coordinate value in a first axial direction and a second coordinate value in a second axial direction.\\n3. The electronic device (10) according to claim 2, wherein the head posture angles comprise a head pitch angle and a head yaw angle, and the rotation reference angles comprise a first pitch angle, a second pitch angle, a first yaw angle, and a second yaw angle corresponding to the predetermined calibration positions.\\n4. The electronic device (10) according to claim 3, wherein the processor (140) performs interpolation operation or extrapolation operation according to the first yaw angle, the second yaw angle, a first position corresponding to the first yaw angle among the predetermined calibration positions, a second position corresponding to the second yaw angle among the predetermined calibration positions and the head yaw angle, thereby obtaining the first coordinate value of the gaze position; and\\nthe processor (140) performs interpolation operation or extrapolation operation according to the first pitch angle, the second pitch angle, a third position corresponding to the first pitch angle among the predetermined calibration positions, a fourth position corresponding to the second pitch angle among the predetermined calibration positions and the head pitch angle, thereby obtaining the second coordinate value of the gaze position.\\n5. The electronic device (10) according to claim 1, wherein the processor (140) calculates a plurality of first viewing distances between the user and the screen (110) according to the first facial landmarks;\\nThe processor (140) estimates a second viewing distance between the user and the screen (110) according to the second facial landmarks; and\\nthe processor (140) adjusts the rotation reference angles or the gaze position according to the second viewing distance and the first viewing distances.\\n6. The electronic device (10) according to claim 1, wherein the processor (140) maps a plurality of two-dimensional position coordinates of the second facial landmarks under a plane coordinate system to a plurality of three-dimensional position coordinates under a three-dimensional coordinate system; and\\nthe processor (140) estimates the head posture angle according to the three-dimensional position coordinates of the second facial landmarks.\\n7. The electronic device (10) according to claim 1, wherein the second head image comprises a wearable device, and the second facial landmarks do not comprise a plurality of third facial landmarks of the user covered by the wearable device.\\n8. The electronic device (10) according to claim 1, wherein the second head image comprises a wearable device, and the second facial landmarks comprise one or more simulated landmarks marked by the wearable device.\\n9. An operating method, adapted for an electronic device (10) comprising an image capturing device (120) and making a screen (110) to display a plurality of image frames, the method comprising: configuring the screen (110) to display a plurality of marker objects at a plurality of predetermined calibration positions; configuring the image capturing device (120) to capture a plurality of first head images when a user is looking at the predetermined calibration positions; (S301) performing a plurality of first face recognition operations on the first head images to obtain a plurality of first face regions corresponding to the predetermined calibration positions; (S302) detecting a plurality of first facial landmarks corresponding to the first face regions; (S303) calculating a plurality of rotation reference angles of the user looking at the predetermined calibration positions according to the first facial landmarks; configuring the image capturing device (120) to capture a second head image of the user; performing a second face recognition operation on the second head image to obtain a second face region; (S304) detecting a plurality of second facial landmarks within the second face region; estimating a head posture angle of the user according to the second facial landmarks; calculating a gaze position of the user on the screen (110) according to the head posture angle, the rotation reference angles, and the predetermined calibration positions; and (S305) configuring the screen (110) to display a corresponding visual effect according to the gaze position.\\n10. The operation method according to claim 9, wherein the gaze position comprises a first coordinate value in a first axial direction and a second coordinate value in a second axial direction.\\n11. The operation method according to claim 10, wherein the head posture angles comprise a head pitch angle and a head yaw angle, and the rotation reference angles comprise a first pitch angle, a second pitch angle, a first yaw angle, and a second yaw angle corresponding to the predetermined calibration positions.\\n12. The operation method according to claim 11, wherein the step of calculating the gaze position of the user on the screen (110) according to the head posture angle, the rotation reference angles and the predetermined calibration positions comprises: performing interpolation operation or extrapolation operation according to the first yaw angle, the second yaw angle, a first position corresponding to the first yaw angle among the predetermined calibration positions, a second position corresponding to the second yaw angle among the predetermined calibration positions and the head yaw angle, thereby obtaining the first coordinate value of the gaze position; and performing interpolation operation or extrapolation operation according to the first pitch angle, the second pitch angle, a third position corresponding to the first pitch angle among the predetermined calibration positions, a fourth position corresponding to the second pitch angle among the predetermined calibration positions and the head pitch angle, thereby obtaining the second coordinate value of the gaze position.\\n13. The operation method according to claim 9, wherein the method further comprises: calculating a plurality of first viewing distances between the user and the screen (110) according to the first facial landmarks; estimating a second viewing distance between the user and the screen (110) according to the second facial landmarks; and adjusting the rotation reference angles or the gaze position according to the second viewing distance and the first viewing distances.\\n14. The operation method according to claim 9, wherein the method further comprises: mapping a plurality of two-dimensional position coordinates of the second facial landmarks under a plane coordinate system to a plurality of three-dimensional position coordinates under a three-dimensional coordinate system; and estimating the head posture angle according to the three-dimensional position coordinates of the second facial landmarks.\\n15. The operation method according to claim 9, wherein the second head image comprises a wearable device, and the second facial landmarks do not comprise a plurality of third facial landmarks of the user covered by the wearable device.\\n16. The operation method according to claim 9, wherein the second head image comprises a wearable device, and the second facial landmarks comprise one or more simulated landmarks marked by the wearable device.', '1. A computation method applied to a computing system, wherein the computing system comprises: a control unit, a computation group, and a general storage unit, wherein the control unit comprises: a first memory, a decoding logic, and a controller, wherein the computation group comprises: a group controller and a plurality of computing units; the general storage unit is configured to store data; and the computation method comprises: receiving, by the controller, a first level instruction sequence, and partitioning, by the decoding logic, the first level instruction sequence into a plurality of second level instruction sequences, creating, by the controller, M threads for the plurality of second level instruction sequences, and allocating, by the controller, an independent register as well as configuring an independent addressing function for each thread of the M threads, wherein M is an integer greater than or equal to 1; and obtaining, by the group controller, a plurality of computation types of the plurality of second level instruction sequences, obtaining a corresponding fusion computation manner of the computation types according to the plurality of computation types, and adopting, by the plurality of computing units, the fusion computation manner to call the M threads for performing computations on the plurality of second level instruction sequences to obtain a final result.\\n2. The method of claim 1, wherein, the obtaining, by the group controller, a plurality of computation types of the plurality of second level instruction sequences, obtaining a corresponding fusion computation manner of the computation types according to the plurality of computation types, and adopting, by the plurality of computing units, the fusion computation manner to call the M threads for performing computations on the plurality of second instruction sequences to obtain a final result:\\nif the computation types represent computation operations of the same type, the group controller calls a combined computation manner in which single instruction multiple data of the same type is in combination with single instruction multiple threads, and uses the M threads to perform the combined computation manner to obtain a final result, which includes:\\npartitioning, by the decoding logic, the M threads into N wraps for allocating to the the plurality of computing units, converting, by the group controller, the plurality of second instruction sequences into a plurality of second control signals and sending the second control signals to the plurality of computing units, calling, by the plurality of computing units, wraps that are allocated to the computing units and the second control signals to fetch corresponding data according to the independent addressing function, performing, by the plurality of computing units, computations on the data to obtain a plurality of intermediate results, and splicing the plurality of intermediate results to obtain a final result.\\n3. The method of claim 1, wherein, the obtaining, by the group controller, a plurality of computation types of the plurality of second level instruction sequences, obtaining a corresponding fusion computation manner of the computation types according to the plurality of computation types, and adopting, by the plurality of computing units, the fusion computation manner to call the M threads for performing computations on the plurality of second instruction sequences to obtain a final result:\\nif the computation types represent computation operations of different types, the group controller calls simultaneous multi-threading and the M threads to perform computations to obtain a final result, which includes:\\npartitioning, by the decoding logic, the M threads into N wraps, converting the plurality of second instruction sequences into a plurality of second control signals, obtaining, by the group controller, computation types supported by the plurality of computing units, allocating, by the controller, the N wraps and the plurality of second control signals to corresponding computing units that support computation types of the wraps and the second control signals, calling, by the plurality of computing units, wraps that are allocated to the computing units and the second control signals, fetching, by the plurality of computing units, corresponding data, performing, by the plurality of computing units, computations on the data to obtain a plurality of intermediate results, and splicing all the intermediate results to obtain a final result.\\n4. The method of claim 2 or 3, further comprising:\\nif a wrap A in the plurality of wraps is blocked, adding the wrap A to a waiting queue, and if data of the wrap A are already fetched, adding the wrap A to a preparation queue, wherein the preparation queue is a queue where a wrap to be scheduled for executing is located when a computing resource is idle.\\n5. The method of claim 1, wherein\\nthe first level instruction sequence includes a very long instruction, and the second level instruction sequence includes an instruction sequence.\\n6. The method of claim 1, wherein the computing system further includes: a tree module, wherein the tree module includes: a root port and a plurality of branch ports, wherein the root port of the tree module is connected to the group controller, and the plurality of branch ports of the tree module are connected to a computing unit of the plurality of computing units respectively; and\\nthe tree module is configured to forward data blocks, wraps, or instruction sequences between the group controller and the plurality of computing units.\\n7. The method of claim 6, wherein the tree module is an n-ary tree, wherein n is an integer greater than or equal to 2.\\n8. The method of claim 1, wherein the computing system further includes a branch processing circuit,\\nwherein the branch processing circuit is connected between the group controller and the plurality of computing units; and\\nthe branch processing circuit is configured to forward data, wraps, or instruction sequences between the group controller and the plurality of computing units.\\n9. A computing system, comprising: a control unit, a computation group, and a general storage unit, wherein the control unit includes: a first memory, a decoding logic, and a controller, the computation group includes: a group controller and a plurality of computing units; the general storage unit is configured to store data;\\nthe controller is configured to receive a first level instruction sequence and control the first memory and the decoding logic;\\nthe decoding logic is configured to partition the first level instruction sequence into a plurality of second level instruction sequences;\\nthe the controller is further configured to create M threads for the plurality of second level instruction sequences, and allocate an independent register and configure an independent addressing function for each thread of the M threads; M is an integer greater than or equal to 1; and the controller is further configured to convert the plurality of second instruction sequences into a plurality of control signals for sending to the group controller;\\nthe group controller is configured to receive the plurality of control signals, obtain a plurality of computational types if the plurality of control signals, divide the M threads into N wraps, and allocate the N wraps and the plurality of control signals to the plurality of computing units according to the plurality of computational types;\\nthe plurality of computing units are configured to fetch data from the general storage unit through allocated wraps and control signals, and perform computations to obtain an intermediate result; and\\nthe group controller is configured to splice all intermediate results to obtain a final computation result.\\n10. The computing system of claim 9, wherein\\nthe plurality of computing units includes: an addition computing unit, a multiplication computing unit, an activation computing unit, or a dedicated computing unit.\\n11. The computing system of claim 9, wherein\\nthe dedicated computing unit includes: a face recognition computing unit, a graphics computing unit, a fingerprint computing unit, or a neural network computing unit.\\n12. The computing system of claim 11, wherein\\nthe group controller is configured to, if computation types of a plurality of control signals are graphics computations, fingerprint identification, face recognition, or neural network operations, allocate the plurality of control signals to the face recognition computing unit, the graphics computing unit, the fingerprint computing unit, or the neural network computing unit respectively.\\n13. The computing system of claim 9, wherein\\nthe first level instruction sequence includes a very long instruction, and the second level instruction sequence includes an instruction sequence.\\n14. The computing system of claim 9, further comprising a tree module, wherein the tree module includes: a root port and a plurality of branch ports, wherein the root port of the tree module is connected to the group controller, and the plurality of branch ports of the tree module are connected to a computing unit of the plurality of computing units respectively; and\\nthe tree module is configured to forward data blocks, wraps, or instruction sequences between the group controller and the plurality of computing units.\\n15. The computing system of claim 14, wherein the tree module is an n-ary tree, wherein n is an integer greater than or equal to 2.\\n16. The computing system of claim 9, wherein the computing system includes a branch processing circuit,\\nthe branch processing circuit is connected between the group controller and the plurality of computing units; and\\nthe branch processing circuit is configured to forward data, wraps, or instruction sequences between the group controller and the plurality of computing units.\\n17. A computer program product, comprising a non-instant computer readable storage medium, wherein a computer program is stored in the non-instant computer readable storage medium, and the computer program is capable of causing a computer to perform the method of any of claims 1-8 through operations.', \"1. A method for detecting body information on one or more passengers of a vehicle based on humans' status recognition, comprising steps of: (a) if at least one interior image of an interior of the vehicle is acquired, a passenger body information-detecting device performing (i) a process of inputting the interior image into a face recognition network, to thereby allow the face recognition network to detect each of faces of each of the passengers from the interior image, and thus to output multiple pieces of passenger feature information corresponding to each of the detected faces, and (ii) a process of inputting the interior image into a body recognition network, to thereby allow the body recognition network to detect each of bodies of each of the passengers from the interior image, and thus to output body-part length information of each of the detected bodies; and (b) the passenger body information-detecting device performing a process of retrieving specific height mapping information corresponding to specific passenger feature information on a specific passenger from a height mapping table which stores height mapping information representing respective one or more predetermined ratios of one or more segment body portions of each of human groups to each of heights per each of the human groups, a process of acquiring a specific height of the specific passenger from the specific height mapping information by referring to specific body-part length information of the specific passenger, a process of retrieving specific weight mapping information corresponding to the specific passenger feature information from a weight mapping table which stores multiple pieces of weight mapping information representing predetermined correlations between each of the heights and each of weights per each of the human groups, and a process of acquiring a weight of the specific passenger from the specific weight mapping information by referring to the specific height of the specific passenger.\\n2. The method of Claim 1, wherein, at the step of (a), the passenger body information-detecting device performs a process of inputting the interior image into the body recognition network, to thereby allow the body recognition network to (i) output one or more feature tensors with one or more channels corresponding to the interior image via a feature extraction network, (ii) generate at least one keypoint heatmap and at least one part affinity field with one or more channels corresponding to each of the feature tensors via a keypoint heatmap & part affinity field extractor, and (iii) extract keypoints from the keypoint heatmap via a keypoint detector, to group the extracted keypoints by referring to the part affinity field, and thus to generate body parts per the passengers, and as a result, allow the body recognition network to output multiple pieces of body-part length information on each of the passengers by referring to the body parts per the passengers.\\n3. The method of Claim 2, wherein the feature extraction network includes at least one convolutional layer and applies at least one convolution operation to the interior image, to thereby output the feature tensors.\\n4. The method of Claim 2, wherein the keypoint heatmap & part affinity field extractor includes one of a fully convolutional network and a 1×1 convolutional layer, and applies a fully-convolution operation or 1×1 convolution operation to the feature tensors, to thereby generate the keypoint heatmap and the part affinity field.\\n5. The method of Claim 2, wherein the keypoint detector connects, by referring to the part affinity field, pairs respectively having highest mutual connection probabilities of being connected among the extracted keypoints, to thereby group the extracted keypoints.\\n6. The method of Claim 2, wherein the feature extraction network and the keypoint heatmap & part affinity field extractor have been learned by a learning device performing (i) a process of inputting at least one training image including one or more objects for training into the feature extraction network, to thereby allow the feature extraction network to generate one or more feature tensors for training having one or more channels by applying at least one convolutional operation to the training image, (ii) a process of inputting the feature tensors for training into the keypoint heatmap & part affinity field extractor, to thereby allow the keypoint heatmap & part affinity field extractor to generate one or more keypoint heatmaps for training and one or more part affinity fields for training having one or more channels for each of the feature tensors for training, (iii) a process of inputting the keypoint heatmaps for training and the part affinity fields for training into the keypoint detector, to thereby allow the keypoint detector to extract keypoints for training from each of the keypoint heatmaps for training and a process of grouping the extracted keypoints for training by referring to each of the part affinity fields for training, to thereby detect keypoints per each of the objects for training, and (iv) a process of allowing a loss layer to calculate one or more losses by referring to the keypoints per each of the objects for training and their corresponding ground truths, to thereby adjust one or more parameters of the feature extraction network and the keypoint heatmap & part affinity field extractor such that the losses are minimized by backpropagation using the losses.\\n7. The method of Claim 1, wherein, at the step of (a), the passenger body information-detecting device performs a process of inputting the interior image into the face recognition network, to thereby allow the face recognition network to detect each of the faces of each of the passengers located in the interior image via a face detector, and to output multiple pieces of the passenger feature information on each of the facial images via a facial feature classifier.\\n8. The method of Claim 1, wherein, at the step of (a), the passenger body information-detecting device performs a process of inputting the interior image into the face recognition network, to thereby allow the face recognition network to (i) apply at least one convolution operation to the interior image and thus to output at least one feature map corresponding to the interior image via at least one convolutional layer, (ii) output one or more proposal boxes, where the passengers are estimated as located, on the feature map, via a region proposal network, (iii) apply pooling operation to one or more regions, corresponding to the proposal boxes, on the feature map and thus to output at least one feature vector via a pooling layer, and (iv) apply fully-connected operation to the feature vector, and thus to output the multiple pieces of the passenger feature information corresponding to each of the faces of each of the passengers corresponding to each of the proposal boxes via a fully connected layer.\\n9. The method of Claim 1, wherein the multiple pieces of the passenger feature information include each of ages, each of genders and each of races corresponding to each of the passengers.\\n10. A passenger body information-detecting device for detecting body information on one or more passengers of a vehicle based on humans' status recognition, comprising: at least one memory that stores instructions; and at least one processor configured to execute the instructions to perform or support another device to perform: (I) if at least one interior image of an interior of the vehicle is acquired, (i) a process of inputting the interior image into a face recognition network, to thereby allow the face recognition network to detect each of faces of each of the passengers from the interior image, and thus to output multiple pieces of passenger feature information corresponding to each of the detected faces, and (ii) a process of inputting the interior image into a body recognition network, to thereby allow the body recognition network to detect each of bodies of each of the passengers from the interior image, and thus to output body-part length information of each of the detected bodies, and (II) a process of retrieving specific height mapping information corresponding to specific passenger feature information on a specific passenger from a height mapping table which stores height mapping information representing respective one or more predetermined ratios of one or more segment body portions of each of human groups to each of heights per each of the human groups, a process of acquiring a specific height of the specific passenger from the specific height mapping information by referring to specific body-part length information of the specific passenger, a process of retrieving specific weight mapping information corresponding to the specific passenger feature information from a weight mapping table which stores multiple pieces of weight mapping information representing predetermined correlations between each of the heights and each of weights per each of the human groups, and a process of acquiring a weight of the specific passenger from the specific weight mapping information by referring to the specific height of the specific passenger.\\n11. The passenger body information-detecting device of Claim 10, wherein, at the process of (I), the processor performs a process of inputting the interior image into the body recognition network, to thereby allow the body recognition network to (i) output one or more feature tensors with one or more channels corresponding to the interior image via a feature extraction network, (ii) generate at least one keypoint heatmap and at least one part affinity field with one or more channels corresponding to each of the feature tensors via a keypoint heatmap & part affinity field extractor, and (iii) extract keypoints from the keypoint heatmap via a keypoint detector, to group the extracted keypoints by referring to the part affinity field, and thus to generate body parts per the passengers, and as a result, allow the body recognition network to output multiple pieces of body-part length information on each of the passengers by referring to the body parts per the passengers.\\n12. The passenger body information-detecting device of Claim 11, wherein the keypoint heatmap & part affinity field extractor includes one of a fully convolutional network and a 1×1 convolutional layer, and applies a fully-convolution operation or 1×1 convolution operation to the feature tensors, to thereby generate the keypoint heatmap and the part affinity field.\\n13. The passenger body information-detecting device of Claim 11, wherein the keypoint detector connects, by referring to the part affinity field, pairs respectively having highest mutual connection probabilities of being connected among the extracted keypoints, to thereby group the extracted keypoints.\\n14. The passenger body information-detecting device of Claim 11, wherein the feature extraction network and the keypoint heatmap & part affinity field extractor have been learned by a learning device performing (i) a process of inputting at least one training image including one or more objects for training into the feature extraction network, to thereby allow the feature extraction network to generate one or more feature tensors for training having one or more channels by applying at least one convolutional operation to the training image, (ii) a process of inputting the feature tensors for training into the keypoint heatmap & part affinity field extractor, to thereby allow the keypoint heatmap & part affinity field extractor to generate one or more keypoint heatmaps for training and one or more part affinity fields for training having one or more channels for each of the feature tensors for training, (iii) a process of inputting the keypoint heatmaps for training and the part affinity fields for training into the keypoint detector, to thereby allow the keypoint detector to extract keypoints for training from each of the keypoint heatmaps for training and a process of grouping the extracted keypoints for training by referring to each of the part affinity fields for training, to thereby detect keypoints per each of the objects for training, and (iv) a process of allowing a loss layer to calculate one or more losses by referring to the keypoints per each of the objects for training and their corresponding ground truths, to thereby adjust one or more parameters of the feature extraction network and the keypoint heatmap & part affinity field extractor such that the losses are minimized by backpropagation using the losses.\\n15. The passenger body information-detecting device of Claim 10, wherein, at the process of (I), the processor performs a process of inputting the interior image into the face recognition network, to thereby allow the face recognition network to (i) apply at least one convolution operation to the interior image and thus to output at least one feature map corresponding to the interior image via at least one convolutional layer, (ii) output one or more proposal boxes, where the passengers are estimated as located, on the feature map, via a region proposal network, (iii) apply pooling operation to one or more regions, corresponding to the proposal boxes, on the feature map and thus to output at least one feature vector via a pooling layer, and (iv) apply fully-connected operation to the feature vector, and thus to output the multiple pieces of the passenger feature information corresponding to each of the faces of each of the passengers corresponding to each of the proposal boxes via a fully connected layer.\", '1. A computer implemented method for performing video coding based on face detection comprising: receiving a video frame comprising one of a plurality of video frames of a video sequence; determining the video frame is a key frame of the video sequence; performing, in response to the video frame being a key frame of the video sequence, a multi-stage facial search of the video frame based on predetermined feature templates and a predetermined number of stages to determine a first candidate face region and a second candidate face region in the video frame; testing the first and second candidate face regions based on skin tone information to determine the first candidate face region is a valid face region and the second candidate face region is an invalid face region; rejecting the second candidate face region and outputting the first candidate face region; and encoding the video frame based at least in part on the first candidate face region being a valid face region to generate a coded bitstream.\\n2. The method of claim 1, wherein the skin tone information comprises a skin probability map.\\n3. The method of claim 1, wherein said testing the first and second candidate face regions based on skin tone information is performed in response to the video frame being a key frame of the video sequence.\\n4. The method of claim 1, wherein the first candidate face region comprises a rectangular region, the method further comprising: determining a free form shape face region corresponding to the first candidate face region, wherein the free form shape face region has at least one of a pixel accuracy or a small block of pixels accuracy.\\n5. The method of claim 4, wherein determining the free form shape face region comprises: generating an enhanced skip probability map corresponding to the first candidate face region; binarizing the enhanced skip probability map; and overlaying the binarized enhanced skip probability map over at least a portion of the video frame to provide the free form shape face region.\\n6. The method of claim 4, wherein a second video frame comprises a non-key frame of the video sequence, the method further comprising performing face detection in the second video frame of the video sequence based on the free form shape face region.\\n7. The method of claim 6, further comprising: tracking a second free form shape face region in the second video frame based on the free form shape face region in the video frame.\\n8. The method of claim 7, wherein tracking the second free form shape face region comprises determining a location of a second valid face region in the second video frame based on a displacement offset with respect to the first candidate face region.\\n9. The method of claim 8, further comprising: determining the displacement offset based on an offset between a centroid of a bounding box around a skin enhanced region corresponding to the first candidate face region and a second centroid of a second bounding box around a second skin enhanced region in the second video frame.\\n10. The method of claim 1, wherein encoding the video frame based at least in part on the first candidate face region being a valid face region comprises at least one of reducing a quantization parameter corresponding to the first candidate face region, adjusting a lambda value for the first candidate face region, or disabling skip coding for the first candidate face region.\\n11. The method of claim 1, wherein the bitstream comprises at least one of an H.264/Advanced Video Coding (AVC) compliant bitstream, an H.265/High Efficiency Video Coding (HEVC) compliant bitstream, a VP9 compliant bitstream, a VP10 compliant bitstream, or an Alliance for Open Media (AOM) AV1 compliant bitstream.\\n12. A computer implemented method for performing face detection comprising: receiving a video frame of a sequence of video frames; performing a multi-stage facial search of the video frame based on predetermined feature templates and a predetermined number of stages to determine a first candidate face region and a second candidate face region in the video frame; testing the first and second candidate face regions based on skin tone information to determine the first candidate face region is a valid face region and the second candidate face region is an invalid face region; rejecting the second candidate face region and outputting the first candidate face region as a valid face region for further processing; and providing an index indicative of a person being present in the video frame based on the valid face region.\\n13. The method of claim 12, wherein the sequence of video frames comprises a sequence of surveillance video frames, the method further comprising: performing face recognition in the surveillance video frames based on the valid face region.\\n14. The method of claim 12, wherein the sequence of video frames comprises a sequence of decoded video frames, the method further comprising: adding a marker corresponding to the received video frame to perform face recognition on the received video frame based on the valid face region.\\n15. The method of claim 12, wherein the sequence of video frames is received during a device login attempt, the method further comprising: performing face recognition based on the valid face region; and allowing access to the device if a secured face is recognized.\\n16. The method of claim 12, wherein the sequence of video frames comprises a sequence of videoconferencing frames, the method further comprising: encoding the video frame based at least in part on the valid face region to generate a coded bitstream.\\n17. The method of claim 16, wherein encoding the video frame comprises not encoding a background region of the video frame into the bitstream.\\n18. The method of claim 12, further comprising: encoding the video frame based at least in part on the valid face region to generate a coded bitstream, wherein encoding the video frame comprises including metadata corresponding to the valid face region in the bitstream.\\n19. The method of claim 18, further comprising: decoding the coded bitstream to generate a decoded video frame and to determine the metadata corresponding to the valid face region in the bitstream.\\n20. The method of claim 19, further comprising at least one of replacing the valid face region based on the decoded metadata, cropping and displaying image data corresponding only to the valid face region based on the decoded metadata, or indexing the decoded video frame based on the decoded metadata.\\n21. A system for performing video coding based on face detection comprising: a memory configured to store a video frame comprising one of a plurality of video frames of a video sequence; and a processor coupled to the memory, the processor to receive the video frame, to determine the video frame is a key frame of the video sequence; to perform, in response to the video frame being a key frame of the video sequence, a multi-stage facial search of the video frame based on predetermined feature templates and a predetermined number of stages to determine a first candidate face region and a second candidate face region in the video frame, to test the first and second candidate face regions based on skin tone information to determine the first candidate face region is a valid face region and the second candidate face region is an invalid face region, to reject the second candidate face region and outputting the first candidate face region, and to encode the video frame based at least in part on the first candidate face region being a valid face region to generate a coded bitstream.\\n22. The system of claim 21, wherein the skin tone information comprises a skin probability map.\\n23. The system of claim 21, wherein the first candidate face region comprises a rectangular region, the processor further to determine a free form shape face region corresponding to the first candidate face region, wherein the free form shape face region has at least one of a pixel accuracy or a small block of pixels accuracy.\\n24. The system of claim 23, wherein the processor to determine the free form shape face region comprises the processor to generate an enhanced skip probability map corresponding to the first candidate face region, to binarize the enhanced skip probability map, and to overlay the binarized enhanced skip probability map over at least a portion of the video frame to provide the free form shape face region.\\n25. The system of claim 23, wherein a second video frame comprises a non-key frame of the video sequence, and the processor is further to perform face detection in the second video frame of the video sequence based on the free form shape face region.\\n26. The system of claim 25, wherein the processor is further to track a second free form shape face region in the second video frame based on the free form shape face region in the video frame.\\n27. The system of claim 21, wherein to encode the video frame based at least in part on the first candidate face region being a valid face region comprises the processor to reduce a quantization parameter corresponding to the first candidate face region, adjust a lambda value for the first candidate face region, or disable skip coding for the first candidate face region.\\n28. At least one non-transitory machine readable medium comprising a plurality of instructions that, in response to being executed on a device, cause the device to perform video coding based on face detection by: receiving a video frame comprising one of a plurality of video frames of a video sequence; determining the video frame is a key frame of the video sequence; performing, in response to the video frame being a key frame of the video sequence, a multi-stage facial search of the video frame based on predetermined feature templates and a predetermined number of stages to determine a first candidate face region and a second candidate face region in the video frame; testing the first and second candidate face regions based on skin tone information to determine the first candidate face region is a valid face region and the second candidate face region is an invalid face region; rejecting the second candidate face region and outputting the first candidate face region; and encoding the video frame based at least in part on the first candidate face region being a valid face region to generate a coded bitstream.\\n29. The non-transitory machine readable medium of claim 28, wherein the skin tone information comprises a skin probability map.\\n30. The non-transitory machine readable medium of claim 28, wherein the first candidate face region comprises a rectangular region, the machine readable medium comprising further instructions that, in response to being executed on the device, cause the device to perform video coding based on face detection by: determining a free form shape face region corresponding to the first candidate face region, wherein the free form shape face region has at least one of a pixel accuracy or a small block of pixels accuracy.\\n31. The non-transitory machine readable medium of claim 30, wherein determining the free form shape face region comprises: generating an enhanced skip probability map corresponding to the first candidate face region; binarizing the enhanced skip probability map; and overlaying the binarized enhanced skip probability map over at least a portion of the video frame to provide the free form shape face region.\\n32. The non-transitory machine readable medium of claim 30, wherein a second video frame comprises a non-key frame of the video sequence, the machine readable medium comprising further instructions that, in response to being executed on the device, cause the device to perform video coding based on face detection by performing face detection in the second video frame of the video sequence based on the free form shape face region.\\n33. The non-transitory machine readable medium of claim 32, the machine readable medium comprising further instructions that, in response to being executed on the device, cause the device to perform video coding based on face detection by: tracking a second free form shape face region in the second video frame based on the free form shape face region in the video frame.\\n34. The non-transitory machine readable medium of claim 28, wherein encoding the video frame based at least in part on the first candidate face region being a valid face region comprises at least one of reducing a quantization parameter corresponding to the first candidate face region, adjusting a lambda value for the first candidate face region, or disabling skip coding for the first candidate face region.', '1. A method for managing a smart database which stores facial images for face recognition, comprising steps of: (a) a managing device performing a process of counting one or more specific facial images corresponding to at least one specific person stored in the smart database where new facial images for the face recognition are continuously stored, and a process of determining whether a first counted value representing a count of the specific facial images satisfies a preset first set value; and (b) if the first counted value is determined as satisfying the first set value, the managing device performing a process of inputting the specific facial images into a neural aggregation network, to thereby allow the neural aggregation network to generate each of quality scores of each of the specific facial images by aggregation of the specific facial images, and a process of sorting the quality scores corresponding to the specific facial images in a descending order of the quality scores, a process of counting the sorted specific facial images in the descending order until a second counted value which represents the number of a counted part of the specific facial images becomes equal to a preset second set value, and a process of deleting an uncounted part of the specific facial images from the smart database.\\n2. The method of claim 1, further comprising a step of: (c) the managing device performing a process of generating at least one optimal feature by weighted summation of one or more features of the specific facial images using the counted part of the quality scores and a process of setting the optimal feature as a representative face corresponding to the specific person.\\n3. The method of claim 1, wherein, at the step of (b), the managing device performs a process of inputting the specific facial images into a CNN of the neural aggregation network, to thereby allow the CNN to generate one or more features corresponding to each of the specific facial images, and a process of inputting at least one feature vector, where the features are embedded, into an aggregation module including at least two attention blocks, to thereby allow the aggregation module to generate each of the quality scores of each of the features.\\n4. The method of claim 1, wherein, at the step of (b), the managing device performs a process of matching (i) (i-1) one or more features corresponding to each of the specific facial images stored in the smart database and (i-2) the quality scores with (ii) the specific person, and a process of storing the matched features and the matched quality scores in the smart database.\\n5. The method of claim 1, further comprising a step of: (d) the managing device performing one of (i) a process of learning a face recognition system by using the specific facial images corresponding to the specific person stored in the smart database and (ii) a process of transmitting the specific facial images, corresponding to the specific person, to a learning device corresponding to the face recognition system, to thereby allow the learning device to learn the face recognition system using the specific facial images.\\n6. The method of claim 1, wherein the neural aggregation network has been learned by a learning device repeating more than once (i) a process of inputting multiple facial images for training corresponding to an image set of a single face or a video of the single face into a CNN of the neural aggregation network, to thereby allow the CNN to generate one or more features for training by applying at least one convolution operation to the facial images for training, (ii) a process of inputting at least one feature vector for training, where the features for training are embedded, into an aggregation module, including at least two attention blocks, of the neural aggregation network, to thereby allow the aggregation module to generate each of quality scores for training of each of the features for training by aggregation of the features for training using one or more attention parameters learned in a previous iteration, (iii) a process of outputting at least one optimal feature for training by weighted summation of the features for training using the quality scores for training, and (iv) a process of updating the attention parameters learned in the previous iteration of the at least two attention blocks such that one or more losses are minimized which are outputted from a loss layer by referring to the optimal feature for training and its corresponding ground truth.\\n7. A managing device for managing a smart database which stores facial images for face recognition, comprising: at least one memory that stores instructions; and at least one processor configured to execute the instructions to perform or support another device to perform: (I) a process of counting one or more specific facial images corresponding to at least one specific person stored in the smart database where new facial images for the face recognition are continuously stored, and a process of determining whether a first counted value representing a count of the specific facial images satisfies a preset first set value, and (II) if the first counted value is determined as satisfying the first set value, a process of inputting the specific facial images into a neural aggregation network, to thereby allow the neural aggregation network to generate each of quality scores of each of the specific facial images by aggregation of the specific facial images, and a process of sorting the quality scores corresponding to the specific facial images in a descending order of the quality scores, a process of counting the sorted specific facial images in the descending order until a second counted value which represents the number of a counted part of the specific facial images becomes equal to a preset second set value, and a process of deleting an uncounted part of the specific facial images from the smart database.\\n8. The managing device of claim 7, wherein the processor further performs: (III) a process of generating at least one optimal feature by weighted summation of one or more features of the specific facial images using the counted part of the quality scores and a process of setting the optimal feature as a representative face corresponding to the specific person.\\n9. The managing device of claim 7, wherein, at the process of (II), the processor performs a process of inputting the specific facial images into a CNN of the neural aggregation network, to thereby allow the CNN to generate one or more features corresponding to each of the specific facial images, and a process of inputting at least one feature vector, where the features are embedded, into an aggregation module including at least two attention blocks, to thereby allow the aggregation module to generate each of the quality scores of each of the features.\\n10. The managing device of claim 7, wherein, at the process of (II), the processor performs a process of matching (i) (i-1) one or more features corresponding to each of the specific facial images stored in the smart database and (i-2) the quality scores with (ii) the specific person, and a process of storing the matched features and the matched quality scores in the smart database.\\n11. The managing device of claim 7, wherein the processor further performs: (IV) one of (i) a process of learning a face recognition system by using the specific facial images corresponding to the specific person stored in the smart database and (ii) a process of transmitting the specific facial images, corresponding to the specific person, to a learning device corresponding to the face recognition system, to thereby allow the learning device to learn the face recognition system using the specific facial images.\\n12. The managing device of claim 7, wherein the neural aggregation network has been learned by a learning device repeating more than once (i) a process of inputting multiple facial images for training corresponding to an image set of a single face or a video of the single face into a CNN of the neural aggregation network, to thereby allow the CNN to generate one or more features for training by applying at least one convolution operation to the facial images for training, (ii) a process of inputting at least one feature vector for training, where the features for training are embedded, into an aggregation module, including at least two attention blocks, of the neural aggregation network, to thereby allow the aggregation module to generate each of quality scores for training of each of the features for training by aggregation of the features for training using one or more attention parameters learned in a previous iteration, (iii) a process of outputting at least one optimal feature for training by weighted summation of the features for training using the quality scores for training, and (iv) a process of updating the attention parameters learned in the previous iteration of the at least two attention blocks such that one or more losses are minimized which are outputted from a loss layer by referring to the optimal feature for training and its corresponding ground truth.', '1. An object data processing system comprising: at least one processor configured to execute: at least one implementation of a plurality of recognition algorithms stored on at least one non-transitory computer-readable storage medium, each recognition algorithm having feature density selection criteria; and data preprocessing code executed by at least one processor, the data preprocessing code comprising an invariant feature identification algorithm and configured to: obtain a digital representation of a scene, the scene comprising one or more textual media; generate a set of invariant features by applying the invariant feature identification algorithm to the digital representation; cluster the set of invariant features into regions of interest in the digital representation of the scene, each region of interest having a region feature density; classify, by region classifier code, at least one of the regions of interest according to object type as a function of attributes derived from the region feature density and the digital representation, wherein the at least one of the classified regions of interest corresponds to text; and use a classification result corresponding to the at least one of the regions of interest to classify another of the regions of interest according to object type, wherein the another of the regions of interest corresponds to a region of interest for images.\\n2. The system of claim 1, wherein preprocessing code, based on the feature density selection criteria, determines that an OCR algorithm is applicable to the text, and that other recognition algorithms are applicable to aspects of the photographs and to logos.\\n3. The system of claim 1, wherein a user creates a user profile for a camera-equipped smartphone that includes the information that the user is visually impaired, which causes prioritized execution of the OCR algorithm such that a text reader program begins reading the text to the user as quickly as possible.\\n4. The system of claim 3, further comprising an audio or tactile feedback mechanism that helps the user to position the smart phone relative to the text.\\n5. The system of claim 4, further comprising a \"hold still\" audio feedback signal that is sent to the user when the text is at the center of the captured scene.\\n6. The system of claim 1, wherein the digital representation comprises at least one of the following types of digital data: image data, video data, and audio data.\\n7. The system of claim 1, wherein invariant feature identification algorithm comprises at least one of the following feature identification algorithms: FAST, SIFT, FREAK, BRISK, Harris, DAISY, and MSER.\\n8. The system of claim 1, wherein the invariant feature identification algorithm includes at least one of the following: edge detection algorithm, corner detection algorithm, saliency map algorithm, curve detection algorithm, a texton identification algorithm, and wavelets algorithm.\\n9. The system of claim 1, wherein at least one region of interest represents at least one physical object in the scene.\\n10. The system of claim 1, wherein at least one region of interest represents at least one textual media in the scene.\\n11. The system of claim 10, wherein the region of interest represents a document as the textual media.\\n12. The system of claim 11, wherein the region of interest represents a financial document.\\n13. The system of claim 11, wherein the region of interest represents a structured document.\\n14. The system of claim 1, wherein at least one implementation of a plurality of recognition algorithms includes at least one of the following: a template driven algorithm, a face recognition algorithm, an optical character recognition algorithm, a speech recognition algorithm, and an object recognition algorithm.\\n15. The system of claim 1, wherein data preprocessing code is further configured to assign each region of interest at least one recognition algorithm as a function of a scene context derived from the digital representation.\\n16. The system of claim 15, wherein the scene context includes at least one of the following types of data: a location, a position, a time, a user identity, a news event, a medical event, and a promotion.\\n17. The system of claim 1, further comprising a mobile device comprising at least one implementation of a plurality of recognition algorithms and data preprocessing code.\\n18. The system of claim 17, wherein the mobile device comprises at least one of the following: a smart phone, a tablet, wearable glass, a toy, a vehicle, a computer, and a phablet.\\n19. The system of claim 1, further comprising a network-accessible server device comprising at least one implementation of a plurality of recognition algorithms and data preprocessing code.\\n20. The system of claim 1, wherein the object type includes at least one of the following: a face, an animal, a vehicle, a document, a plant, a building, an appliance, clothing, a body part, and a toy.\\n21. An object data processing system comprising: at least one processor configured to execute: at least one implementation of a plurality of recognition algorithms stored on at least one non-transitory computer-readable storage medium, each recognition algorithm having feature density selection criteria; and data preprocessing code executed by at least one processor, the data preprocessing code comprising an invariant feature identification algorithm and configured to: obtain a digital representation of a scene, the scene comprising one or more textual media; generate a set of invariant features by applying the invariant feature identification algorithm to the digital representation; cluster the set of invariant features into regions of interest in the digital representation of the scene, each region of interest having a region feature density; classify, by region classifier code, at least one of the regions of interest according to object type as a function of attributes derived from the region feature density and the digital representation; wherein the at least one of the classified regions of interest corresponds to text; and use a classification result corresponding to the at least one of the regions of interest to classify another of the regions of interest according to object type, wherein the another of the regions of interest corresponds to a region of interest for images; assign each region of interest at least one recognition algorithm from at least one implementation of a plurality of diverse recognition algorithms as a function of the region feature density of each region of interest and the feature density selection criteria of the at least one implementation of a plurality of diverse recognition algorithms; and configure the assigned recognition algorithms to process their respective regions of interest, wherein preprocessing code, based on the feature density selection criteria, determines that an OCR algorithm is applicable to the text, and that other recognition algorithms are applicable to aspects of the photographs and to logos.\\n22. A device comprising: at least one processor configured to execute: at least one implementation of a plurality of recognition algorithms stored on at least one non-transitory computer-readable storage medium, each recognition algorithm having feature density selection criteria; and data preprocessing code executed by at least one processor, the data preprocessing code comprising an invariant feature identification algorithm and configured to: obtain a digital representation of a scene, the scene comprising one or more textual media; generate a set of invariant features by applying the invariant feature identification algorithm to the digital representation; cluster the set of invariant features into regions of interest in the digital representation of the scene, each region of interest having a region feature density; and classify, by region classifier code, at least one of the regions of interest according to object type as a function of attributes derived from the region feature density and the digital representation, wherein the at least one of the classified regions of interest corresponds to text; and use a classification result corresponding to the at least one of the regions of interest to classify another of the regions of interest according to object type, wherein the another of the regions of interest corresponds to a region of interest for images.', '1. A mobile terminal comprising: a front camera configured to obtain a two-dimensional (2D) face image of a user; a glance sensor tilted by a certain angle and disposed adjacent to the front camera to obtain metadata of the 2D face image; and a controller obtaining a distance between the glance sensor and the front camera, the distance enabling an area of an overlap region, where a first region representing a range photographable by the front camera overlaps a second region representing a range photographable by the glance sensor, to be the maximum.\\n2. The mobile terminal of claim 1, wherein the controller is configured to obtain the distance, enabling the area of the overlap region to be the maximum, between the glance sensor and the front camera by varying a tilting angle of the glance sensor.\\n3. The mobile terminal of claim 2, wherein the controller is configured to set the distance, enabling the area of the overlap region to be the maximum, between the glance sensor and the front camera and the tilting angle of the glance sensor as an optimal disposition location of the glance sensor.\\n4. The mobile terminal of claim 3, wherein the controller is configured to set a disposition location of the front camera as an original point and calculates coordinates of a first triangle representing the first region, based on a field of view of the front camera and a maximum photographing distance of the front camera.\\n5. The mobile terminal of claim 4, wherein the controller is configured to calculate coordinates of a second triangle representing the second region, based on a field of view of the glance sensor, a maximum photographing distance of the glance sensor, a distance between the front camera and the glance sensor, and a tilting angle of the glance sensor.\\n6. The mobile terminal of claim 5, wherein before the glance sensor is tilted, the controller is configured to calculate coordinates of a third triangle representing a third region photographable by the glance sensor, and the controller is configured to rotation-convert the coordinates of the third triangle, based on the tilting angle of the glance sensor and calculate the coordinates of the second triangle.\\n7. The mobile terminal of claim 6, wherein the controller is configured to calculate coordinates of the overlap region, based on the coordinates of the first triangle and the coordinates of the second triangle and calculates the area of the overlap region, based on the coordinates of the overlap region.\\n8. The mobile terminal of claim 1, wherein the controller is configured to generate three-dimensional (3D) face information, based on the 2D face image obtained by the front camera and metadata obtained by the glance sensor.\\n9. The mobile terminal of claim 8, wherein the metadata comprises one or more of an angle of a face of the user, a size of the face, and a location of the face.\\n10. The mobile terminal of claim 9, wherein the angle of the face comprises an angle by which the face is rotated about one or more of a pitch axis, a roll axis, and a yaw axis.\\n11. The mobile terminal of claim 8, further comprising a memory storing the generated 3D face information, wherein the controller is configured to performs a user authentication process by comparing the stored 3D face information with 3D face information obtained for user authentication.\\n12. The mobile terminal of claim 1, wherein the glance sensor is controlled to be permanently activated with a low power to obtain a front image and metadata of the front image.\\n13. The mobile terminal of claim 1, wherein the front camera and the glance sensor are disposed on the same line in an upper end of the mobile terminal.\\n14. The mobile terminal of claim 1, wherein the glance sensor is tilted in one direction of an up direction, a down direction, a left direction, and a right direction.\\n15. The mobile terminal of claim 1, wherein the metadata is data which is changed when the mobile terminal is tilted by an external physical force.', '1. A method, comprising: receiving, by a smart television (TV), an indication of upcoming media programming, wherein the upcoming media programming is based on a user profile; identifying one or more devices in communication with the smart TV, each of the one or more devices including at least one of a microphone or a camera; instructing at least one identified device to detect audio signals using its respective microphone, or to detect visual signals using its respective camera; selecting at least one device of the one or more devices based on the detected audio signal or detected visual signal; and providing instructions to the selected device to output a notification related to the upcoming media programming.\\n2. The method of claim 1, wherein the upcoming media programming is one of a live television program, a recorded television program, a broadcast television program, or an application-provided program.\\n3. The method of claim 1, wherein selecting the first device based on the detected audio signal includes recognizing a voice.\\n4. The method of claim 3, further comprising determining a distance to the recognized voice, and wherein selecting the first device is further based on the determined distance.\\n5. The method of claim 1, wherein selecting the first device based on the detected visual signals includes recognizing a face.\\n6. The method of claim 5, wherein recognizing the face includes a face recognition technique.\\n7. The method of claim 1, further comprising presenting, on the smart TV, the upcoming media programming in a favorite channel list.\\n8. The method of claim 7, further comprising: obtaining media programming viewing data, wherein the media programming viewing data includes at least one of a historical time and a historical date that one or more media programs were viewed; obtaining at least one of a current time and a current date; processing the media programming viewing data to determine a probability of the one or more media programs being viewed based on at least one of the current time and the current date; and presenting the favorite channel list based on the determined probability of the one or more media programs being viewed.\\n9. The method of claim 8, wherein processing the media programming viewing data includes employing a neural network model.\\n10. The method of claim 9, wherein employing the neural network model comprises: determining a duration that the one or more media programs were viewed for each of the at least one of the historical time and the historical date; setting a threshold time duration; comparing the determined duration to the threshold time duration; and filtering out the one or more media programs viewed below the threshold time duration.\\n11. A smart television (TV), comprising: a network interface; a non-transitory computer-readable medium; and a processor in communication with the network interface, and the non-transitory computer-readable medium, and capable of executing processor-executable program code stored in the non-transitory computer-readable medium, to cause the smart TV to: receive an indication of upcoming media programming, wherein the upcoming media programming is based on a user profile; identify one or more devices in communication with the smart TV, each of the one or more devices including at least one of a microphone or a camera; instruct at least one identified device to detect audio signals using its respective microphone, or to detect visual signals using its respective camera; select at least one device of the one or more devices based on the detected audio signal or detected visual signal; and provide instructions to the selected device to output a notification related to the upcoming media programming.\\n12. The smart TV of claim 11, wherein selecting the first device based on the detected audio signal includes recognizing a voice.\\n13. The smart TV of claim 12, wherein the processor is further capable of executing processor-executable program code to: determine a distance to the recognized voice, and wherein selecting the first device is further based on the determined distance.\\n14. The smart TV of claim 11, wherein selecting the first device based on the detected visual signals includes detecting the presence of a user.\\n15. The smart TV of claim 14, wherein detecting the presence of the user includes employing one or more of a camera, a microphone, or a fingerprint sensor associated with at least one of the smart TV a mobile device, a smartphone, a laptop computer, a tablet device, a wearable device, an Internet of Things (IoT) device, an Internet of Everything (IoE) device, an IoT hub, or an IoE hub.\\n16. A smart television (TV), comprising: means for receiving an indication of upcoming media programming, wherein the upcoming media programming is based on a user profile; means for identifying one or more devices in communication with the smart TV, each of the one or more devices including at least one of a microphone or a camera; means for instructing at least one identified device to detect audio signals using its respective microphone, or to detect visual signals using its respective camera; means for selecting at least one device of the one or more devices based on the detected audio signal or detected visual signal; and means for providing instructions to the selected device to output a notification related to the upcoming media programming.\\n17. The smart TV of claim 16, wherein the one or more devices includes at least one of a mobile device, a smartphone, a laptop computer, a tablet device, a wearable device, an Internet of Things (IoT) device, an Internet of Everything (IoE) device, an IoT hub, an IoE hub, or another smart TV.\\n18. The smart TV of claim 16, wherein the upcoming media programming is one of a live television program, a recorded television program, a broadcast television program, or an application-provided program.\\n19. The smart TV of claim 16, wherein the notification includes at least one of a push message, a SMS message, a Way2SMS message, an audio alert, an audio message, or an email message.\\n20. The smart TV of claim 16, further comprising presenting the upcoming media programming in a favorite channel list.\\n21. The smart TV of claim 20, further comprising: means for obtaining media programming viewing data, wherein the media programming viewing data includes at least one of a historical time and a historical date that one or more media programs were viewed on the smart TV; means for obtaining at least one of a current time and a current date; means for processing the media programming viewing data to determine a probability of the one or more media programs being viewed on the smart TV based on at least one of the current time and the current date; and means for presenting the favorite channel list based on the determined probability of the one or more media programs being viewed.\\n22. The smart TV of claim 21, wherein the means for processing the media programming viewing data includes employing a neural network model.\\n23. The smart TV of claim 22, wherein employing the neural network model comprises: determining a duration that the one or more media programs were viewed on the smart TV for each of the at least one of the historical time and the historical date; setting a threshold time duration; comparing the determined duration to the threshold time duration; and filtering out the one or more media programs viewed below the threshold time duration.\\n24. The smart TV of claim 21, further comprising: means for adjusting at least one of a volume or a brightness of the smart TV, wherein the adjusting is based on at least one of the historical time and the historical date.\\n25. The smart TV of claim 21, further comprising means for restricting access to one or more media programs.\\n26. A non-transitory computer-readable medium comprising processor-executable program code configured to cause a processor of a smart television (TV) to: receive an indication of upcoming media programming, wherein the upcoming media programming is based on a user profile; identify one or more devices in communication with the smart TV, each of the one or more devices including at least one of a microphone or a camera; instruct at least one identified device to detect audio signals using its respective microphone, or to detect visual signals using its respective camera; select at least one device of the one or more devices based on the detected audio signal or detected visual signal; and provide instructions to the selected device to output a notification related to the upcoming media programming.\\n27. The non-transitory computer-readable medium of claim 26, wherein selecting the first device based on the detected audio signal includes recognizing a voice.\\n28. The non-transitory computer-readable medium of claim 27, wherein the processor is further capable of executing processor-executable program code to: determine a distance to the recognized voice, and wherein selecting the first device is further based on the determined distance.\\n29. The non-transitory computer-readable medium of claim 26, wherein selecting the first device based on the detected visual signals includes recognizing a face.\\n30. The non-transitory computer-readable medium of claim 29, wherein recognizing the face includes a face recognition technique.', '1. A camera comprising: a sensor array including a plurality of sensors; an infrared (IR) illuminator configured to emit active IR light in an IR light sub-band; a plurality of spectral illuminators, each spectral illuminator configured to emit active spectral light in a different spectral light sub-band; a depth controller machine configured to determine a depth value for each of the plurality of sensors based on the active IR light, a spectral controller machine configured to, for each of the plurality of sensors, determine a spectral value for each spectral light sub-band of the plurality of spectral illuminators; and an output machine configured to output a test depth+multi-spectral image including a plurality of pixels, each pixel corresponding to one of the plurality of sensors of the sensor array and including at least: a depth value, and a spectral value for each spectral light sub-band of the plurality of spectral illuminators; a face recognition machine previously trained with a set of labeled training depth+multi-spectral images having a same structure as the test depth+multi-spectral image, the face recognition machine configured to output a confidence value indicating a likelihood that the test depth+multi-spectral image includes a face.\\n2. The camera of claim 1, wherein each spectral value is calculated based on the depth value determined for the sensor that corresponds to the pixel.\\n3. The camera of claim 1, wherein the face recognition machine is configured to use a convolutional neural network to determine the confidence value.\\n4. The camera of claim 3, wherein the face recognition machine includes a plurality of input nodes, wherein each input node is configured to receive a pixel value array corresponding to a different pixel of the plurality of pixels of the test depth+multi-spectral image, and wherein the pixel value array includes the depth value and the plurality of multi-spectral values for the pixel.\\n5. The camera of claim 4, wherein the plurality of multi-spectral values for the pixel include more than three spectral values.\\n6. The camera of claim 4, wherein the output machine is configured to output a surface normal for each pixel of the test depth+multi-spectral image, and wherein the pixel value array includes the surface normal.\\n7. The camera of claim 4, wherein the output machine is configured to output a curvature for each pixel of the test depth+multi-spectral image, and wherein the pixel value array includes the curvature.\\n8. The camera of claim 3, wherein the face recognition machine is configured to use a plurality of models to determine the confidence value, wherein the plurality of models includes a plurality of channel-specific models, wherein each channel-specific model is configured to process a different pixel parameter for the plurality of pixels of the test depth+multi-spectral image, wherein each channel-specific model includes a plurality of input nodes, and wherein, for each channel-specific model, each input node is configured to receive a pixel parameter value for a different pixel of the plurality of pixels of the test depth+multi-spectral image.\\n9. The camera of claim 1, wherein the face recognition machine is configured to use a statistical model to determine the confidence value.\\n10. The camera of claim 9, wherein the statistical model includes a nearest neighbor algorithm.\\n11. The camera of claim 9, wherein the statistical model includes a support vector machine.\\n12. The camera of claim 1, wherein the face recognition machine is further configured to output a location on the test depth+multi-spectral image of a bounding box around a recognized face.\\n13. The camera of claim 1, wherein the face recognition machine is further configured to output a location on the test depth+multi-spectral image of an identified two-dimensional (2D) facial feature of a recognized face.\\n14. The camera of claim 1, wherein the face recognition machine is further configured to output a location on the test depth+multi-spectral image of an identified three-dimensional (3D) facial feature of a recognized face.\\n15. The camera of claim 1, wherein the face recognition machine is further configured to output a location on the test depth+multi-spectral image of an identified spectral feature on a recognized face.\\n16. The camera of claim 1, wherein the face recognition machine is further configured to output, for each pixel of the test depth+multi-spectral image, a confidence value indicating a likelihood that the pixel is included in a face.\\n17. The camera of claim 1, wherein the face recognition machine is further configured to output an identity of a face recognized in the test depth+multi-spectral image.\\n18. The camera of claim 1, wherein the plurality of sensors of the sensor array are differential sensors, and wherein each spectral value is determined based on a depth value and a differential measurement for that differential sensor.\\n19. A camera comprising: a sensor array including a plurality of sensors; an infrared (IR) illuminator configured to emit active IR light in an IR light sub-band; a plurality of spectral illuminators, each spectral illuminator configured to emit active spectral light in a different spectral light sub-band; a depth controller machine configured to determine a depth value for each of the plurality of sensors based on the active IR light, a spectral controller machine configured to, for each of the plurality of sensors, determine a spectral value for each spectral light sub-band of the plurality of spectral illuminators, wherein each spectral value is calculated based on the depth value determined for the sensor that corresponds to the pixel; and an output machine configured to output a test depth+multi-spectral image including a plurality of pixels, each pixel corresponding to one of the plurality of sensors of the sensor array and including at least: a depth value, and a spectral value for each spectral light sub-band of the plurality of spectral illuminators; and a face recognition machine including a convolutional neural network previously trained with a set of labeled training depth+multi-spectral images having a same structure as the test depth+multi-spectral image, the face recognition machine configured to output a confidence value indicating a likelihood that the test depth+multi-spectral image includes a face.', '1. An image processing method, comprising: acquiring a photo album obtained from face clustering; collecting face information of respective images in the photo album, and acquiring a face parameter of each image according to the face information; selecting a cover image according to the face parameter of each image; and taking a face-region image from the cover image, and setting the face-region image as a cover of the photo album; wherein selecting the cover image according to the face parameter of each image comprises: performing calculation on the face parameter of each image in a preset way, to obtain a cover score of each image; selecting the image with a highest cover score as the cover image; wherein selecting the image with the highest cover score as the cover image comprises: acquiring a source of each image; and selecting the image with the highest cover score in images coming from a preset source as the cover image.\\n2. The method according to claim 1, wherein selecting the image with the highest cover score as the cover image comprises: acquiring the number of faces contained in each image; determining single-person images according to the number of faces; and selecting the single-person image with the highest cover score as the cover image.\\n3. The method according to claim 2, wherein selecting the image with the highest cover score as the cover image further comprises: when there is no single-person image in the photo album, determining images including two faces from the photo album; and selecting the image with the highest cover score from the images including two faces as the cover image.\\n4. The method according to claim 1, wherein the face information comprises face feature points, and the face parameter comprises a face turning angle; acquiring the face parameter of each image according to the face information comprises: acquiring coordinate values of the face feature points; determining distances and angles between the face feature points; and determining the face turning angle according to the distances and the angles.\\n5. The method according to claim 1, wherein the face parameter comprises a face ratio; acquiring the face parameter of each image according to the face information comprises: determining a face region of the image according to the face information; and calculating a ratio of an area of the face region to an area of the image to obtain the face ratio.\\n6. The method according to claim 5, wherein calculating the face ratio comprises: when there is more than one face in the image, subtracting an area occupied faces other than a face corresponding to the photo album from the face region to obtain a remaining area; and calculating a ratio of the remaining area to the area of the image to obtain the face ratio.\\n7. The method according to claim 1, wherein collecting face information of respective images in the photo album comprises: acquiring image identifications of images in the photo album; extracting face information corresponding to the image identifications from a face database, the face database being stored with face recognition results of images, the face recognition results including the face information.\\n8. An image processing apparatus, comprising: a processor; and a memory, configured to store instructions executable by the processor, wherein the processor is configured to run a program corresponding to the instructions by reading the instructions stored in the memory, so as to perform: acquiring a photo album obtained from face clustering; collecting face information of each image in the photo album; acquiring a face parameter of each image according to the face information; selecting a cover image according to the face parameter of each image; taking a face-region image from the cover image, and setting the face-region image as a cover of the photo album; wherein the processor is configured to: perform calculation on the face parameter of each image in a preset way, to obtain a cover score of each image; and select the image with a highest cover score as the cover image; and wherein the processor is configured to: acquire a source of each image; and select the image with the highest cover score in images coming from a preset source as the cover image.\\n9. The apparatus according to claim 8, wherein the processor is configured to: acquire the number of faces contained in each image; determine single-person images according to the number of faces; and select the single-person image with the highest cover score as the cover image.\\n10. The apparatus according to claim 9, wherein the processor is further configured to: when there is no single-person image in the photo album, determine images including two faces from the photo album; and select the image with the highest cover score from the images including two faces as the cover image.\\n11. The apparatus according to claim 8, wherein the face information comprises face feature points, and the face parameter comprises a face turning angle; the processor is configured to: acquire coordinate values of the face feature points; determine distances and angles between the face feature points; and determine the face turning angle according to the distances and the angles.\\n12. The apparatus according to claim 8, wherein the face parameter comprises a face ratio; the processor is configured to: determine a face region of the image according to the face information; and calculate a ratio of an area of the face region to an area of the image to obtain the face ratio.\\n13. The apparatus according to claim 12, wherein the processor is configured to: when there is more than one face in the image, subtract an area occupied faces other than a face corresponding to the photo album from the face region to obtain a remaining area; and calculate a ratio of the remaining area to the area of the image to obtain the face ratio.\\n14. The apparatus according to claim 8, wherein the processor is configured to: acquire image identifications of images in the photo album; extract face information corresponding to the image identifications from a face database, the face database being stored with face recognition results of images, the face recognition results including the face information.\\n15. An electronic device, comprising a processor, a memory, a display screen and an input device connected via a system bus, wherein the memory is stored with computer programs that, when executed by the processor, cause the processor to implement an image processing method, the image processing method comprising: acquiring a photo album obtained from face clustering; collecting face information of respective images in the photo album, and acquiring a face parameter of each image according to the face information; selecting a cover image according to the face parameter of each image; and taking a face-region image from the cover image, and setting the face-region image as a cover of the photo album; wherein selecting the cover image according to the face parameter of each image comprises: performing calculation on the face parameter of each image in a preset way, to obtain a cover score of each image; and selecting the image with a highest cover score as the cover image; and wherein selecting the image with the highest cover score as the cover image comprises: acquiring a source of each image; and selecting the image with the highest cover score in images coming from a preset source as the cover image.\\n16. The electronic device according to claim 15, wherein the electronic device comprises at least one of a mobile phone, a tablet computer, a personal digital assistant and a wearable device.', '1. A computer-implemented method, comprising: receiving, at a computing device, a meeting invitation identifying a location and at least one invitee, the meeting invitation configured to provide the at least one invitee with physical access to the location, wherein the meeting invitation causes a system to control a pathway allowing physical access to the location; providing, based on the meeting invitation, the at least one invitee with physical access to the location by controlling the pathway allowing the at least one invitee to physically access the location through the pathway in response to positioning data indicating that the at least one invitee is at a predetermined location near the location wherein the positioning data is based in part on a face recognition camera system identifying the at least one invitee; receiving the positioning data from the face recognition camera system identifying the at least one invitee, wherein the positioning data indicates a pattern of movement of the at least one invitee; determining that the pattern of movement indicates that the at least one invitee has exited the location; and revoking physical access to the location identified in the meeting invitation by controlling the pathway to restrict the at least one invitee identified in the meeting invitation from physical access to the location through the pathway, in response to determining that the pattern of movement indicates that the at least one invitee has exited the location.\\n2. The computer-implemented method of claim 1, wherein determining that the at least one invitee has exited the location comprises determining that the at least one invitee has passed through an egress associated with the location in a predetermined direction.\\n3. The computer-implemented method of claim 1, wherein determining that the at least one invitee has exited the location comprises determining that the at least one invitee has moved through an area in a predetermined direction.\\n4. The computer-implemented method of claim 1, wherein the positioning data indicates a second pattern of movement of the at least one invitee and, wherein access to secured data associated with the location is provided in response to detecting the second pattern of movement.\\n5. The computer-implemented method of claim 1, further comprising: collating secured data and public data to generate resource data; and communicating the resource data to a client computing device associated with the at least one invitee when access of the location is provided.\\n6. The computer-implemented method of claim 1, wherein the positioning data indicates that the at least one invitee is at the predetermined location when the at least one invitee passes through the predetermined location.\\n7. The computer-implemented method of claim 1, wherein the positioning data indicates that the at least one invitee is at the predetermined location when the at least one invitee passes through the predetermined location near the location in a predetermined direction.\\n8. A system, comprising: a processor; and a memory in communication with the processor, the memory having computer-readable instructions stored thereupon that, when executed by the processor, cause the processor to: receive a meeting invitation indicating a location and an identity, the meeting invitation configured to provide at least one invitee with physical access to the location, wherein the meeting invitation causes the system to control a pathway allowing physical access to the location; provide the at least one invitee associated with the identity access to the location by controlling the pathway allowing the at least one invitee to physically access the location through the pathway in response to positioning data indicating that the at least one invitee is at a predetermined location near the location, wherein the positioning data is based in part on a face recognition camera system identifying the at least one invitee; receive the positioning data from the face recognition camera system identifying the at least one invitee, wherein the positioning data indicates a pattern of movement of the at least one invitee; determine that the pattern of movement indicates that the at least one invitee has exited the location; and revoke physical access to the location identified in the meeting invitation by controlling the pathway to restrict the at least one invitee identified in the meeting invitation from physical access to the location through the pathway, in response to determining that the pattern of movement indicates that the at least one invitee has exited the location.\\n9. The system of claim 8, wherein determining that the at least one invitee has exited the location comprises determining that the at least one invitee has passed through an egress associated with the location.\\n10. The system of claim 8, wherein determining that the at least one invitee has exited the location comprises determining that the at least one invitee has moved through an area in a predetermined direction.\\n11. The system of claim 8, wherein the positioning data indicates a second pattern of movement of the at least one invitee and wherein access to secured data associated with the location is provided in response to detecting the second pattern of movement.\\n12. The system of claim 8, wherein the instructions further cause the processor to: collate secured data and public data to generate resource data; and communicate the resource data to a client computing device associated with the at least one invitee when access of the location is provided.\\n13. A non-transitory computer-readable storage medium having computer-executable instructions stored thereupon which, when executed by one or more processors of a computing device, cause the one or more processors of the computing device to: receive a meeting invitation indicating a location and an identity, the meeting invitation configured to provide at least one invitee with physical access to the location, wherein the meeting invitation causes a system to control a pathway allowing physical access to the location; provide the at least one invitee associated with the identity access to the location by controlling the pathway allowing the at least one invitee to physically access the location through the pathway in response to positioning data indicating that the at least one invitee is at a predetermined location near the location, wherein the positioning data is based in part on a face recognition camera system identifying the at least one invitee; receive the positioning data from the face recognition camera system identifying the at least one invitee, wherein the positioning data indicates a pattern of movement of the at least one invitee; determine that the pattern of movement indicates that the at least one invitee has exited the location; and revoke physical access to the location identified in the meeting invitation by controlling the pathway to restrict the at least one invitee identified in the meeting invitation from physical access to the location through the pathway, in response to determining that the pattern of movement indicates that the at least one invitee has exited the location.\\n14. The non-transitory computer-readable storage medium of claim 13, wherein determining that the at least one invitee has exited the location comprises determining that the at least one invitee has passed through an egress associated with the location.\\n15. The non-transitory computer-readable storage medium of claim 13, wherein the positioning data indicates a second pattern of movement of the at least one invitee and wherein access to secured data associated with the location is provided in response to detecting the second pattern of movement.\\n16. The non-transitory computer-readable storage medium of claim 13, wherein the instructions further cause the one or more processors to: collate secured data and public data to generate resource data; and communicate the resource data to a client computing device associated with the at least one invitee when access of the location is provided.', '1. A method, comprising: receiving a piece of content and salient data for the piece of content; based on the salient data, determining a first path for a viewport for the piece of content, wherein the first path for the viewport includes different salient events occurring in the piece of content at different times during playback of the piece of content; providing the viewport on a display device, wherein movement of the viewport is based on the first path for the viewport and the salient data during the playback; detecting an additional salient event in the piece of content that is not included in the first path for the viewport; and providing an indication for the additional salient event in the viewport during the playback.\\n2. The method of claim 1, wherein the salient data identifies each salient event in the piece of content, and the salient data indicates, for each salient event in the piece of content, a corresponding point location of the salient event in the piece of content and a corresponding time at which the salient event occurs during the playback.\\n3. The method of claim 2, wherein the salient data further indicates, for each salient event in the piece of content, a corresponding type of the salient event and a corresponding strength value of the salient event.\\n4. The method of claim 1, wherein the first path for the viewport controls the movement of the viewport to put the different salient events in a view of the viewport at the different times during the playback.\\n5. The method of claim 1, further comprising: detecting one or more salient events in the piece of content based on at least one of the following: visual data of the piece of content, audio data of the piece of content, or content consumption experience data for the piece of content; wherein the salient data is indicative of each salient event detected.\\n6. The method of claim 1, further comprising: detecting one or more salient events in the piece of content based on at least one of the following: face recognition, facial emotion recognition, object recognition, motion recognition, or metadata of the piece of content; wherein the salient data is indicative of each salient event detected.\\n7. The method of claim 1, further comprising: detecting user interaction with the indication, wherein the indication comprises an interactive hint; and in response to detecting the user interaction: adapting the first path for the viewport to a second path for the viewport based on the user interaction, wherein the second path for the viewport includes the additional salient event; and providing an updated viewport for the piece of content on the display device, wherein movement of the updated viewport is based on the second path for the viewport and the salient data during the playback, and the second path for the viewport controls the movement of the updated viewport to put the additional salient event in a view of the updated viewport.\\n8. The method of claim 7, further comprising: changing a weight assigned to the additional salient event and one or more other salient events in the piece of content having the same type as the additional salient event.\\n9. The method of claim 7, wherein the second path for the viewport includes one or more other salient events in the piece of content having the same type as the additional salient event.\\n10. A system, comprising: at least one processor; and a non-transitory processor-readable memory device storing instructions that when executed by the at least one processor causes the at least one processor to perform operations including: receiving a piece of content and salient data for the piece of content; based on the salient data, determining a first path for a viewport for the piece of content, wherein the first path for the viewport includes different salient events occurring in the piece of content at different times during playback of the piece of content; providing the viewport on a display device, wherein movement of the viewport is based on the first path for the viewport and the salient data during the playback; detecting an additional salient event in the piece of content that is not included in the first path for the viewport; and providing an indication for the additional salient event in the viewport during the playback.\\n11. The system of claim 10, wherein the salient data identifies each salient event in the piece of content, and the salient data indicates, for each salient event in the piece of content, a corresponding point location of the salient event in the piece of content and a corresponding time at which the salient event occurs during the playback.\\n12. The system of claim 11, wherein the salient data further indicates, for each salient event in the piece of content, a corresponding type of the salient event and a corresponding strength value of the salient event.\\n13. The system of claim 10, wherein the salient data is generated offline on a server.\\n14. The system of claim 10, the operations further comprising: detecting one or more salient events in the piece of content based on at least one of the following: visual data of the piece of content, audio data of the piece of content, or content consumption experience data for the piece of content; wherein the salient data is indicative of each salient event detected.\\n15. The system of claim 10, the operations further comprising: detecting one or more salient events in the piece of content based on at least one of the following: face recognition, facial emotion recognition, object recognition, motion recognition, or metadata of the piece of content; wherein the salient data is indicative of each salient event detected.\\n16. The system of claim 10, the operations further comprising: detecting user interaction with the indication, wherein the indication comprises an interactive hint; and in response to detecting the user interaction: adapting the first path for the viewport to a second path for the viewport based on the user interaction, wherein the second path for the viewport includes the additional salient event; and providing an updated viewport for the piece of content on the display device, wherein movement of the updated viewport is based on the second path for the viewport and the salient data during the playback, and the second path for the viewport controls the movement of the updated viewport to put the additional salient event in a view of the updated viewport.\\n17. The system of claim 16, the operations further comprising: changing a weight assigned to the additional salient event and one or more other salient events in the piece of content having the same type as the additional salient event.\\n18. The system of claim 16, wherein the second path for the viewport includes one or more other salient events in the piece of content having the same type as the additional salient event.\\n19. A non-transitory computer readable storage medium including instructions to perform a method comprising: receiving a piece of content and salient data for the piece of content; based on the salient data, determining a first path for a viewport for the piece of content, wherein the first path for the viewport includes different salient events occurring in the piece of content at different times during playback of the piece of content; providing the viewport on a display device, wherein movement of the viewport is based on the first path for the viewport and the salient data during the playback; detecting an additional salient event in the piece of content that is not included in the first path for the viewport; and providing an indication for the additional salient event in the viewport during the playback.\\n20. The computer readable storage medium of claim 19, the method further comprising: detecting user interaction with the indication, wherein the indication comprises an interactive hint; and in response to detecting the user interaction: adapting the first path for the viewport to a second path for the viewport based on the user interaction, wherein the second path for the viewport includes the additional salient event; and providing an updated viewport for the piece of content on the display device, wherein movement of the updated viewport is based on the second path for the viewport and the salient data during the playback, and the second path for the viewport controls the movement of the updated viewport to put the additional salient event in a view of the updated viewport.', '1. A mobile device with facial recognition, the mobile device comprising: one or more cameras; a processor device and memory coupled to the processor device, the processing system programmed to: receive a plurality of images from the one or more cameras; extract, with a feature extractor utilizing a convolutional neural network (CNN) with an enlarged intra-class variance of long-tail classes, feature vectors from each of the plurality of images; generate, with a feature generator, discriminative feature vectors for each of the feature vectors; classify, with a fully connected classifier, an identity from the discriminative feature vectors; and control an operation of the mobile device to react in accordance with the identity.\\n2. The mobile device as recited in claim 1, further includes a communication system.\\n3. The mobile device as recited in claim 1, wherein the operation tags the video with the identity and uploads the video to social media.\\n4. The mobile device as recited in claim 1, wherein the operation tags the video with the identity and sends the video to a user.\\n5. The mobile device as recited in claim 1, wherein the mobile device is a smart phone.\\n6. The mobile device as recited in claim 1, wherein the mobile device is a body cam.\\n7. The mobile device as recited in claim 1, further programmed to train the feature extractor, the feature generator, and the fully connected classifier with an alternative bi-stage strategy.\\n8. The mobile device as recited in claim 1, wherein the feature extractor shares covariance matrices across all classes to transfer intra-class variance from regular classes to the long-tail classes.\\n9. The mobile device as recited in claim 1, wherein the feature generator optimizes a softmax loss by joint regularization of weights and features through a magnitude of an inner product of the weights and features.\\n10. The mobile device as recited in claim 1, wherein the feature extractor averages the feature vector with a flipped feature vector, the flipped feature vector being generated from a horizontally flipped frame from one of the plurality of images.\\n11. The mobile device as recited in claim 1, wherein each of the plurality of images is selected from the group consisting of an image, a video, and a frame from the video.\\n12. The mobile device as recited in claim 2, wherein the communication system connects to a remote server that includes a facial recognition network.\\n13. The mobile device as recited in claim 7, wherein one stage of the alternative bi-stage strategy fixes the feature extractor and applies the feature generator to generate new transferred features that are more diverse and violate a decision boundary.\\n14. The mobile device as recited in claim 7, wherein one stage of the alternative bi-stage strategy fixes the fully connected classifier and updates the feature extractor and the feature generator.\\n15. A computer program product for a mobile device with facial recognition, the computer program product comprising a non-transitory computer readable storage medium having program instructions embodied therewith, the program instructions executable by a computer to cause the computer to perform a method comprising: receiving, by a processor device, a plurality of images; extracting, by the processor device with a feature extractor utilizing a convolutional neural network (CNN) with an enlarged intra-class variance of long-tail classes, feature vectors for each of the plurality of images; generating, by the processor device with a feature generator, discriminative feature vectors for each of the feature vectors; classifying, by the processor device utilizing a fully connected classifier, an identity from the discriminative feature vector; and controlling an operation of the mobile device to react in accordance with the identity.\\n16. A computer-implemented method for facial recognition in a mobile device, the method comprising: receiving, by a processor device, a plurality of images; extracting, by the processor device with a feature extractor utilizing a convolutional neural network (CNN) with an enlarged intra-class variance of long-tail classes, feature vectors for each of the plurality of images; generating, by the processor device with a feature generator, discriminative feature vectors for each of the feature vectors; classifying, by the processor device utilizing a fully connected classifier, an identity from the discriminative feature vector; and controlling an operation of the mobile device to react in accordance with the identity.\\n17. The computer-implemented method as recited in claim 16, wherein controlling includes tagging the video with the identity and uploading the video to social media.\\n18. The computer-implemented method as recited in claim 16, wherein controlling includes tagging the video with the identity and sending the video to a user.\\n19. The computer-implemented method as recited in claim 16, wherein extracting includes sharing covariance matrices across all classes to transfer intra-class variance from regular classes to the long-tail classes.', '1. A computing device comprising: a non-transitory machine readable medium storing a machine trained (MT) network comprising a plurality of layers of processing nodes, each processing node configured to: compute a first output value by combining a set of output values from a set of processing nodes, and use a piecewise linear cup function to compute a second output value from the first output value of the processing node, wherein the piecewise linear cup function prior to training of the MT network comprises at least (i) a first linear section with a first slope, followed by (ii) a second linear section with a negative second slope, followed by (iii) a third linear section with a negative third slope that is different from the second slope, followed by (iv) a fourth linear section with a positive fourth slope, followed by (v) a fifth linear section with a positive fifth slope that is different from the fourth slope, followed by (vi) a sixth linear section with a sixth slope, wherein the piecewise linear cup function is symmetric about a vertical axis between the third and fourth linear sections prior to training of the MT network; a content capturing circuit for capturing content for processing by the MT network; and a set of processing units for executing the processing nodes to process content captured by the content capturing circuit, wherein by training a set of parameters that define the piecewise linear cup function of each node in first and second pluralities of processing nodes, (i) each processing node in the first plurality of processing nodes is configured to emulate a Boolean AND operator such that an output value of the processing node is in a range associated with a \"1\" value only when a set of inputs to the processing node have a set of values in a range associated with \"1\" and (ii) each processing node in the second plurality of processing nodes is configured to emulate a Boolean XNOR operator such that an output value of the processing node is in the range associated with \"1\" only when (a) a set of inputs to the node have a set of values in a range associated with \"1\" or (b) the set of inputs to the node have a set of values in a range associated with a \"0\" value.\\n2. The computing device of claim 1, wherein the third linear section of the piecewise linear cup function of a first processing node in the MT network has a different slope from the third linear section of a second processing node in the MT network.\\n3. The computing device of claim 1, wherein the length of the third section of a piecewise linear cup function of a first processing node in the MT network is different from the length of the third section of a piecewise linear cup function of a second processing node in the MT network.\\n4. The computing device of claim 1, wherein the sets of parameters are trained in part by a back propagating module for back propagating errors in output values of later layers of processing nodes to earlier layers of processing nodes by adjusting the set of parameters that define the piecewise linear cup functions of the earlier layers of processing nodes.\\n5. The computing device of claim 4, wherein each processing node uses a linear function that is defined by a set of parameters to compute the first output value of the processing node, wherein the back propagating module back propagates errors in output values of later layers of processing nodes to earlier layers of processing nodes by adjusting the set of parameters that define the linear functions of the earlier layers of processing nodes.\\n6. The computing device of claim 1, wherein the first plurality of processing nodes that emulate the Boolean AND operator and the second plurality of processing nodes that emulate the Boolean XNOR operator enable the MT network to implement mathematical problems.\\n7. The computing device of claim 1, wherein each of a plurality of processing node layers has a plurality of processing nodes that receive as input values the output values from a plurality of processing nodes in a set of prior layers.\\n8. The computing device of claim 7, wherein each processing node uses a linear function to compute the first output value of the processing node, wherein each processing node\\'s piecewise linear cup function is defined along first and second axes, the first axis defining a range of output values from the processing node\\'s linear function, and the second axis defining a range of output values produced by the piecewise linear cup function for the range of output values from the processing node\\'s linear function.\\n9. The computing device of claim 1, further comprising: a content output circuit for presenting an output based on the processing of the content by the MT network.\\n10. The computing device of claim 9, wherein the captured content is one of an image and an audio segment, and wherein the presented output is an output display on a display screen of the computing device or an audio presentation output on a speaker of the computing device.\\n11. The computing device of claim 10, wherein the computing device is a mobile device.\\n12. The computing device of claim 1, wherein the MT network is a MT neural network and the processing nodes are MT neurons.\\n13. The computing device of claim 1, wherein the set of parameters configured through training for a plurality of the processing nodes comprise at least one of the negative second and third slopes for the second and third linear sections, the positive fourth and fifth slopes for the fourth and fifth linear sections, a first intercept for the second linear section, a second intercept for the fifth linear section, and a set of lengths for at least the second, third, fourth, and fifth sections.\\n14. The computing device of claim 1, wherein the trained set of parameters that define the piecewise linear cup function of each node comprise a plurality of output values.\\n15. The computing device of claim 1, wherein the first and sixth slopes are zero.', 'We claim:\\n1. A system comprising: a memory device to store an input image; a processor including, an image input interface to receive the input image, a pre-processor to model the input image to yield a multi-channel image, a feature extractor to extract a set of features based on the multi-channel image, a feature selector to select one or more features from the set of features of the multi-channel image, wherein the one or more features are selected based on an ability to differentiate features, a feature matcher to match the one or more features to a learned feature set, and a similarity detector to determine whether the one or more features meet a pre-defined similarity threshold.\\n2. The system of claim 1, wherein the pre-processor further is to activate one or more channels of the multi-channel image to yield one or more activated channels.\\n3. The system of claim 2, wherein the one or more activated channels are to be determined based on their ability to differentiate features.\\n4. The system of claim 2, wherein the pre-processor further is to activate one or more local patches of the one or more activated channels.\\n5. The system of claim 4, wherein the one or more local patches are to be determined based on their ability to differentiate features.\\n6. The system of claim 1, wherein the feature matcher further is to utilize a large-scale data learning process to perform the feature matching.\\n7. An apparatus comprising: an image input interface to receive an input image; a pre-processor to model the input image to yield a multi-channel image; a feature extractor to extract a set of features based on the multi-channel image; a feature selector to select one or more features from the set of features of the multi-channel image, wherein the one or more features are selected based on an ability to differentiate features; a feature matcher to match the one or more features to a learned feature set; and a similarity detector to determine whether the one or more features meet a pre-defined similarity threshold.\\n8. The apparatus of claim 7, wherein the pre-processor further is to activate one or more channels of the multi-channel image to yield one or more activated channels.\\n9. The apparatus of claim 8, wherein the one or more activated channels are to be determined based on their ability to differentiate features.\\n10. The apparatus of claim 8, wherein the pre-processor further is to activate one or more local patches of the one or more activated channels.\\n11. The apparatus of claim 10, wherein the one or more local patches are to be determined based on their ability to differentiate features.\\n12. The apparatus of claim 7, wherein the feature matcher further is to utilize a large-scale data learning process to perform the feature matching.\\n13. A method comprising: modeling an input image to yield a multi-channel image; extracting a set of features based on the multi-channel image; selecting one or more features from the set of features of the multi-channel image, wherein the one or more features are selected based on an ability to differentiate features; matching the one or more features to a learned feature set; and determining whether the one or more features meet a pre-defined similarity threshold.\\n14. The method of claim 13, wherein modeling the input image further is to include activating one or more channels of the multi-channel image to yield one or more activated channels.\\n15. The method of claim 14, wherein the one or more activated channels are to be determined based on their ability to differentiate features.\\n16. The method of claim 13, wherein extracting features of the input image further is to include activating one or more local patches of the one or more activated channels.\\n17. The method of claim 16, wherein the one or more local patches are to be determined based on their ability to differentiate features.\\n18. The method of claim 13, wherein the feature matcher utilizes a large-scale data learning process to perform the feature matching.\\n19. At least one non-transitory computer readable storage medium comprising a set of instructions which, when executed by a computing device, cause the computing device to: model an input image to yield a multi-channel image, extract a set of features based on the multi-channel image, select one or more features from the set of features of the multi-channel image, wherein the features are selected based on an ability to differentiate features, match the one or more features to a learned feature set, and determine whether the one or more features meet a pre-defined similarity threshold.\\n20. The at least one non-transitory computer readable storage medium of claim 19, wherein the instructions, when executed, cause a computing device to activate one or more channels of the multi-channel image to yield one or more activated channels.\\n21. The at least one non-transitory computer readable storage medium of claim 20, wherein the instructions, when executed, cause a computing device to determine the one or more activated channels based on their ability to differentiate features.\\n22. The at least one non-transitory computer readable storage medium of claim 20, wherein extracting features of the input image is to further include activating one or more local patches of the one or more activated channels.\\n23. The at least one non-transitory computer readable storage medium of claim 22, wherein the one or more local patches are to be determined based on their ability to differentiate features.\\n24. The at least one non-transitory computer readable storage medium of claim 19, wherein the feature matcher further is to utilize a large-scale data learning process to perform the feature matching.\\n25. An apparatus comprising: means for modeling an input image to yield a multi-channel image, means for extracting a set of features based on the multi-channel image, means for selecting one or more features from the set of features of the multi-channel image, wherein the one or more features are selected based on an ability to differentiate features, means for matching the one or more features to a learned feature set, and means for determining whether the one or more features meet a pre-defined similarity threshold.', '1. A method for controlling a terminal, the terminal comprising a capturing apparatus and at least one processor, the method comprising: acquiring, by the capturing apparatus, an image; obtaining, by the at least one processor, a motion parameter of the terminal, the motion parameter comprising at least one of a motion frequency or a motion time, and two or more parameters from among an acceleration, an angular velocity, a motion amplitude, the motion frequency, and the motion time; transmitting, by the at least one processor, a parameter threshold obtaining request to a data management server, the parameter threshold obtaining request comprising configuration information of the terminal; receiving corresponding preset thresholds that correspond to the configuration information in response to the parameter threshold obtaining request; comparing the two or more parameters with the corresponding preset thresholds; and controlling, by the at least one processor, not to perform image processing on the acquired image based on at least one of the two or more parameters of the motion parameter being greater than a corresponding preset threshold or based on the two or more parameters of the motion parameter being respectively greater than the corresponding preset thresholds, wherein the acquiring comprises acquiring the image in real time, and the obtaining comprises obtaining the motion parameter of the terminal in real time, the method further comprising: in response to the at least one of the two or more parameters of the motion parameter being greater than the corresponding preset threshold, obtaining the motion parameter of the terminal again; and in response to the two or more parameters of the motion parameter obtained at a latest time being less than or equal to the corresponding preset thresholds, performing the image processing on the image acquired at the latest time.\\n2. The method according to claim 1, wherein the acquiring comprises: controlling, by the at least one processor, to turn on the capturing apparatus based on a face recognition instruction; and acquiring, by the capturing apparatus, a face image when the capturing apparatus is turned on.\\n3. The method according to claim 2, wherein the controlling not to perform the image processing comprises: skipping performing face recognition on the acquired face image based on the at least one of the two or more parameters of the motion parameter being greater than the corresponding preset threshold or based on the two or more parameters of the motion parameter being respectively greater than the corresponding preset thresholds.\\n4. The method according to claim 1, wherein the obtaining comprises at least one of: obtaining the acceleration of the terminal by using an acceleration sensor; or obtaining the angular velocity of the terminal by using a gyro sensor.\\n5. The method according to claim 1, wherein the transmitting comprises: transmitting the parameter threshold obtaining request to the data management server according to a preset time period.\\n6. The method according to claim 1, further comprising: generating prompt information based on the at least one of the two or more parameters of the motion parameter being greater than the corresponding preset threshold, the prompt information being used for prompting the terminal to stop moving.\\n7. The method according to claim 1, wherein the motion parameter comprises the motion frequency and the motion time.\\n8. A terminal comprising: a capturing apparatus; at least one memory configured to store program code; and at least one processor configured to access the at least one memory and operate according to the program code, the program code comprising: motion parameter obtaining code configured to cause the at least one processor to acquire an image by using the capturing apparatus and obtain a motion parameter of the terminal, the motion parameter comprising at least one of a motion frequency or a motion time, and two or more parameters from among an acceleration, an angular velocity, a motion amplitude, the motion frequency, and the motion time; request transmitting code configured to cause the at least one processor to transmit a parameter threshold obtaining request to a data management server, the parameter threshold obtaining request comprising configuration information of the terminal; parameter threshold receiving code configured to cause the at least one processor to receive corresponding preset thresholds that correspond to the configuration information in response to the parameter threshold obtaining request; comparing code configured to cause the at least one processor to compare the two or more parameters with the corresponding preset thresholds; and control code configured to cause the at least one processor not to perform image processing on the acquired image based on at least one of the two or more parameters of the motion parameter being greater than a corresponding preset threshold or based on the two or more parameters of the motion parameter being respectively greater than the corresponding preset thresholds, wherein the motion parameter obtaining code causes the at least one processor to: acquire the image in real time and obtain the motion parameter of the terminal in real time, and in response to the at least one of the two or more parameters of the motion parameter being greater than the corresponding preset threshold, obtain the motion parameter of the terminal again, and wherein the control code causes the at least one processor to, in response to the two or more parameters of the motion parameter obtained at a latest time being less than or equal to the corresponding preset thresholds, perform the image processing on the image acquired at the latest time.\\n9. The terminal according to claim 8, wherein the program code further comprises face instruction receiving code configured to cause the at least one processor to receive a face recognition instruction, wherein the motion parameter obtaining code causes the at least one processor to control, according to the face recognition instruction, the capturing apparatus to turn on, and acquire a face image by using the capturing apparatus when the capturing apparatus is turned on; and wherein the control code causes the at least one processor to skip performing face recognition on the acquired face image based on the at least one of the two or more parameters of the motion parameter being greater than the corresponding preset threshold or based on the two or more parameters of the motion parameter being respectively greater than the corresponding preset thresholds.\\n10. The terminal according to claim 8, wherein the request transmitting code causes the at least one processor to transmit the parameter threshold obtaining request to the data management server according to a preset time period.\\n11. The terminal according to claim 8, wherein the program code further comprises: prompt information generation code configured to cause the at least one processor to generate prompt information based on at least one of the two or more parameters of the motion parameter being greater than the corresponding preset threshold, the prompt information being used for prompting the terminal to stop moving.\\n12. The terminal according to claim 8, wherein the motion parameter comprises the motion frequency and the motion time.\\n13. A non-transitory computer-readable storage medium, storing a machine instruction, which, when executed by one or more processors, causes the one or more processors to perform: obtaining an image acquired by a capturing apparatus; obtaining a motion parameter of a terminal, the terminal comprising the capturing apparatus, the motion parameter comprising at least one of a motion frequency or a motion time, and two or more parameters from among an acceleration, an angular velocity, a motion amplitude, the motion frequency, and the motion time; transmitting a parameter threshold obtaining request to a data management server, the parameter threshold obtaining request comprising configuration information of the terminal; receiving corresponding preset thresholds that correspond to the configuration information in response to the parameter threshold obtaining request; comparing the two or more parameters with the corresponding preset thresholds; and controlling not to perform image processing on an acquired image based on at least one of the two or more parameters of the motion parameter being greater than a corresponding preset threshold or based on the two or more parameters of the motion parameter being respectively greater than the corresponding preset thresholds, wherein the acquiring comprises acquiring the image in real time, and the obtaining comprises obtaining the motion parameter of the terminal in real time, the method further comprising: in response to the at least one of the two or more parameters of the motion parameter being greater than the corresponding preset threshold, obtaining the motion parameter of the terminal again; and in response to the two or more parameters of the motion parameter obtained at a latest time being less than or equal to the corresponding preset thresholds, performing the image processing on the image acquired at the latest time.\\n14. The non-transitory computer-readable storage medium according to claim 13, wherein the acquired image is a face image and the image processing comprises performing face recognition.\\n15. The non-transitory computer-readable storage medium according to claim 13, wherein the obtaining the motion parameter comprises at least one of: obtaining the acceleration of the terminal by using an acceleration sensor; or obtaining the angular velocity of the terminal by using a gyro sensor.\\n16. The non-transitory computer-readable storage medium according to claim 13, wherein the motion parameter comprises the motion frequency and the motion time.', '1. A method of processing a drive-through order, the method comprising: receiving customer information detected through vision recognition; providing product information to a customer based on the customer information; and processing a product order of the customer.\\n2. The method according to claim 1, wherein the receiving of customer information comprises at least one of receiving customer information associated with vehicle information detected through vehicle recognition, or receiving customer information associated with identification information detected through face recognition.\\n3. The method according to claim 1, further comprising determining whether the customer is a pre-order customer based on the customer information, wherein when the customer is determined to be a pre-order customer: the providing of product information based on the customer information comprises providing pre-order information using at least one of audio or video, and the processing of the product order of the customer comprises: providing information for promptly guiding a vehicle to a pickup stand using at least one of audio or video, and providing information that an additional order is available.\\n4. The method according to claim 1, wherein the product information based on the customer information comprises a most recently ordered product component and a most frequently ordered product component in an order history of the customer information.\\n5. The method according to claim 1, wherein the receiving of customer information comprises receiving information about an age and gender of a passenger detected through face recognition, and the providing of product information to a customer based on the customer information comprises providing recommended menu information differentiated according to the age and gender.\\n6. The method according to claim 1, wherein the processing of a product order of the customer comprises determining a product component in a past order history or a component modified from the product component as a product order.\\n7. The method according to claim 1, wherein the processing of a product order of the customer comprises paying a product price according to biometrics-based authentication through a communication system of a vehicle or a mobile terminal.\\n8. The method according to claim 1, wherein the processing of a product order of the customer comprises: issuing a payment number for a divided payment, and performing the divided payments according to payment requests of a plurality of mobile terminals to which the payment numbers are inputted.\\n9. The method according to claim 8, wherein the processing of a product order of the customer further comprises accumulating mileage in an account corresponding to the mobile terminal undergoing a payment.\\n10. The method according to claim 1, wherein the processing of a product order of the customer further comprises suggesting a takeout packaging method according to a temperature of a product, an atmospheric temperature, weather, and a vehicle type.\\n11. An apparatus configured to process a drive-through order, the apparatus comprising: a transceiver configured to receive customer information detected through vision recognition; a digital signage configured to provide product information to a customer based on the customer information; and a processor configured to process a product order of the customer.\\n12. The apparatus according to claim 11, wherein the transceiver receives at least one of customer information associated with vehicle information detected through vehicle recognition, or customer information associated with identification information detected through face recognition.\\n13. The apparatus according to claim 11, wherein the processor is configured to: determine whether the customer is a pre-order customer based on the customer information; and when the customer is determined to be a pre-order customer, perform a control operation to provide pre-order information, and control the digital signage to output information for promptly guiding a vehicle to a pickup stand and provide information that an additional order is available.\\n14. The apparatus according to claim 11, wherein the product information based on the customer information comprises a most recently ordered product component and a most frequently ordered product component in an order history of the customer information.\\n15. The apparatus according to claim 11, wherein the transceiver is configured to receive information about an age and gender of a passenger detected through face recognition, and the processor is configured to control the digital signage to provide recommended menu information differentiated according to the age and gender.\\n16. The apparatus according to claim 11, wherein the processor is configured to determine a product component in a past order history or a component modified from the product component as the product order.\\n17. The apparatus according to claim 11, wherein the processor is configured to pay a product price according to biometrics-based authentication through a communication system of a vehicle or a mobile terminal.\\n18. The apparatus according to claim 11, wherein the processor is configured to: issue a payment number for a divided payment; and perform the divided payments according to requests of a plurality of mobile terminals to which the payment numbers are inputted.\\n19. The apparatus according to claim 18, wherein the processor is configured to accumulate mileage in an account corresponding to the mobile terminal undergoing a payment.\\n20. The apparatus according to claim 11, wherein the processor is configured to control the digital signage to suggest a takeout packaging method according to a temperature of a product, an atmospheric temperature, weather, and a vehicle type.', '1. An image information processing method performed at a computing device having one or more processors and memory storing a plurality of programs to be executed by the one or more processors, the method comprising: identifying, using face recognition, one or more faces, each face corresponding to a respective person captured in a first image; for each identified face: extracting a set of profile parameters of a corresponding person in the first image; and selecting, from a plurality of image tiles, a first image tile that matches the face of the corresponding person in the first image in accordance with a predefined correspondence between the set of profile parameters of the corresponding person and a set of pre-stored description parameters of the first image tile; generating a second image by covering the faces of respective persons in the first image with their corresponding first image tiles; and sharing the first image and the second image in a predefined order via a group chat session.\\n2. The method of claim 1, wherein the first image and the second image are displayed in the group chat session one image at a time such that one of the two images is replaced by the other of the two images periodically.\\n3. The method of claim 1, wherein extracting a set of profile parameters of a corresponding person in the first image includes: determining one or more descriptive labels corresponding to the identified face of the corresponding person using a first machine learning model, wherein the first machine learning model is trained with the facial images and corresponding descriptive labels.\\n4. The method of claim 1, wherein extracting a set of profile parameters of a corresponding person in the first image includes: determining an identity of the corresponding person based on the identified face of the corresponding person; locating respective profile information of the first person based on the determined identity of the corresponding person; and using one or more characteristics in the respective profile information of the first person as the set of profile parameters corresponding to the identified face of the corresponding person.\\n5. The method of claim 1, wherein at least a first one of the first image tiles is a dynamic image tile and at least a second one of the first image tiles is a static image tile.\\n6. The method of claim 1, including: receiving a plurality of user comments from different users of the group chat session, each user comment including a descriptive term for a respective person identified in the first image; choosing a descriptive label for the respective person according to the plurality of user comments; and updating the second image by adding the descriptive label adjacent to the first image tile of the respective person.\\n7. A computing device for image information processing, comprising: one or more processors; and memory storing instructions which, when executed by the one or more processors, cause the processors to perform a plurality of operations comprising: identifying, using face recognition, one or more faces, each face corresponding to a respective person captured in a first image; for each identified face: extracting a set of profile parameters of a corresponding person in the first image; and selecting, from a plurality of image tiles, a first image tile that matches the face of the corresponding person in the first image in accordance with a predefined correspondence between the set of profile parameters of the corresponding person and a set of pre-stored description parameters of the first image tile; generating a second image by covering the faces of respective persons in the first image with their corresponding first image tiles; and sharing the first image and the second image in a predefined order via a group chat session.\\n8. The computing device of claim 7, wherein the first image and the second image are displayed in the group chat session one image at a time such that one of the two images is replaced by the other of the two images periodically.\\n9. The computing device of claim 7, wherein extracting a set of profile parameters of a corresponding person in the first image includes: determining one or more descriptive labels corresponding to the identified face of the corresponding person using a first machine learning model, wherein the first machine learning model is trained with the facial images and corresponding descriptive labels.\\n10. The computing device of claim 7, wherein extracting a set of profile parameters of a corresponding person in the first image includes: determining an identity of the corresponding person based on the identified face of the corresponding person; locating respective profile information of the first person based on the determined identity of the corresponding person; and using one or more characteristics in the respective profile information of the first person as the set of profile parameters corresponding to the identified face of the corresponding person.\\n11. The computing device of claim 7, wherein at least a first one of the first image tiles is a dynamic image tile and at least a second one of the first image tiles is a static image tile.\\n12. The computing device of claim 7, wherein the plurality of operations further include: receiving a plurality of user comments from different users of the group chat session, each user comment including a descriptive term for a respective person identified in the first image; choosing a descriptive label for the respective person according to the plurality of user comments; and updating the second image by adding the descriptive label adjacent to the first image tile of the respective person.\\n13. A non-transitory computer-readable storage medium storing instructions which, when executed by a computing device having one or more processors, cause the computing device to perform a plurality of operations comprising: identifying, using face recognition, one or more faces, each face corresponding to a respective person captured in a first image; for each identified face: extracting a set of profile parameters of a corresponding person in the first image; and selecting, from a plurality of image tiles, a first image tile that matches the face of the corresponding person in the first image in accordance with a predefined correspondence between the set of profile parameters of the corresponding person and a set of pre-stored description parameters of the first image tile; generating a second image by covering the faces of respective persons in the first image with their corresponding first image tiles; and sharing the first image and the second image in a predefined order via a group chat session.\\n14. The non-transitory computer-readable storage medium of claim 13, wherein the first image and the second image are displayed in the group chat session one image at a time such that one of the two images is replaced by the other of the two images periodically.\\n15. The non-transitory computer-readable storage medium of claim 13, wherein extracting a set of profile parameters of a corresponding person in the first image includes: determining one or more descriptive labels corresponding to the identified face of the corresponding person using a first machine learning model, wherein the first machine learning model is trained with the facial images and corresponding descriptive labels.\\n16. The non-transitory computer-readable storage medium of claim 13, wherein extracting a set of profile parameters of a corresponding person in the first image includes: determining an identity of the corresponding person based on the identified face of the corresponding person; locating respective profile information of the first person based on the determined identity of the corresponding person; and using one or more characteristics in the respective profile information of the first person as the set of profile parameters corresponding to the identified face of the corresponding person.\\n17. The non-transitory computer-readable storage medium of claim 13, wherein at least a first one of the first image tiles is a dynamic image tile and at least a second one of the first image tiles is a static image tile.\\n18. The non-transitory computer-readable storage medium of claim 13, wherein the plurality of operations further include: receiving a plurality of user comments from different users of the group chat session, each user comment including a descriptive term for a respective person identified in the first image; choosing a descriptive label for the respective person according to the plurality of user comments; and updating the second image by adding the descriptive label adjacent to the first image tile of the respective person.', '1. A method comprising, by a computing system: determining that a performance metric of an eye tracking system is below a first performance threshold, wherein the eye tracking system is associated with a head-mounted display worn by a user; based on the determination of the performance metric of the eye tracking system being below the first performance threshold, the computer system performing: receiving one or more first inputs associated with a body of the user; estimating a region that the user is looking at within a field of view of the head-mounted display based on the received one or more first inputs associated with the body of the user; determining a vergence distance of the user based at least on the one or more first inputs associated with the body of the user, the estimated region that the user is looking at, and locations of one or more objects in a scene displayed by the head-mounted display; and adjusting one or more configurations of the head-mounted display based on the determined vergence distance of the user.\\n2. The method of claim 1, wherein the one or more configurations of the head-mounted display comprise one or more of: a rendering image; a position of a display screen; or a position of an optics block.\\n3. The method of claim 1, further comprising: determining that the performance metric of the eye tracking system is above a second performance threshold; receiving eye tracking data from the eye tracking system; and determining the vergence distance of the user based on the eye tracking data and the one or more first inputs associated with the body of the user.\\n4. The method of claim 3, further comprising: receiving one or more second inputs associated with one or more displaying elements in the scene displayed by the head-mounted display; and determining the vergence distance of the user based at least on the eye tracking data, the one or more first inputs associated with the body of the user, and the one or more second inputs associated with the one or more displaying elements of the scene.\\n5. The method of claim 4, further comprising: feeding the one or more first inputs associated with the body of the user to a fusion algorithm, wherein the fusion algorithm assigns a weight score to each input of the one or more first inputs; determining the vergence distance of the user using the fusion algorithm based on the one or more first inputs associated with the body of the user; and determining a Z-depth of a display screen and a confidence score based on the one or more first inputs associated with the body of the user\\n6. The method of claim 5, further comprising: comparing the confidence score to a confidence level threshold; in response to a determination that the confidence score is below the confidence level threshold, feeding the one or more second inputs associated with the one or more displaying elements of the scene to the fusion algorithm; and determining the Z-depth of the display screen using the fusion algorithm based on the one or more first inputs associated with the body of the user and the one or more second inputs associated with the one or more displaying elements of the scene.\\n7. The method of claim 6, further comparing: comparing, by the fusion algorithm, confidence scores associated with a plurality of combinations of inputs; and determining, by the fusion algorithm, the Z-depth of the display screen based on a combination of inputs associated with a highest confidence score.\\n8. The method of claim 6, wherein the Z-depth and the confidence score are determined by the fusion algorithm using a piecewise comparison of the one or more first inputs and the one or more second inputs.\\n9. The method of claim 6, wherein the Z-depth and the confidence score are determined based on a correlation between two or more inputs of the one or more first inputs and the one or more second inputs.\\n10. The method of claim 5, wherein the fusion algorithm comprises a machine learning (ML) algorithm, and wherein the machine learning (ML) algorithm determines a combination of first inputs fed to the fusion algorithm.\\n11. The method of claim 4, wherein the one or more first inputs associated with the body of the user comprise one or more of: a hand position; a hand direction; a hand movement; a hand gesture; a head position; a head direction; a head movement; a head gesture; a gaze angle; rea body gesture; a body posture; a body movement; a behavior of the user; or a weighted combination of one or more related parameters.\\n12. The method of claim 11, wherein the one or more first inputs associated with the body of the user are received from one or more of: a controller; a sensor; a camera; a microphone; an accelerometer; a headset worn by the user; or a mobile device.\\n13. The method of claim 4, wherein the one or more second inputs associated with the one or more displaying elements comprise one or more of: a Z-buffer value associated with a displaying element; a displaying element marked by a developer; an image analysis result; a shape of a displaying element; a face recognition result; an object recognition result; a person identified in a displaying content; an object identified in a displaying content; a correlation of two or more displaying elements; or a weighted combination of the one or more second inputs.\\n14. The method of claim 1, further comprising: determining that the performance metric of the eye tracking system is below a second performance threshold; receiving one or more second inputs associated with one or more displaying elements in the scene displayed by the head-mounted display; and determining the vergence distance of the user based at least on the one or more first inputs associated with the body of the user and the one or more second inputs associated with the one or more displaying elements.\\n15. The method of claim 14, wherein determining that the performance metric of the eye tracking system is below the second performance threshold comprises determining that the eye tracking system does not exist or fails to provide eye tracking data.\\n16. The method of claim 1, wherein the performance metric of the eye tracking system comprises one or more of: an accuracy of a parameter from the eye tracking system; a precision of a parameter from the eye tracking system; a value of a parameter from the eye tracking system; a detectability of a pupil; a metric based on one or more parameters associated with the user; a parameter change; a parameter changing trend; a data availability; or a weighted combination of one or more performance related parameters.\\n17. The method of claim 16, wherein the one or more parameters associated with the user comprise one or more of: an eye distance of the user; a pupil position; a pupil status; a correlation of two pupils of the user; a head size of the user; a position of a headset worn by the user; an angle of the headset worn by the user; a direction of the headset worn by the user; an alignment of the eyes of the user; or a weighted combination of one or more related parameters associated with the user.\\n18. The method of claim 1, wherein the first performance threshold comprises one or more of: a pre-determined value; a pre-determined range; a state of a data; a changing speed of a data; or a trend of a data change.\\n19. One or more non-transitory computer-readable storage media embodying software that is operable when executed by a computing system to: determine that a performance metric of an eye tracking system is below a first performance threshold, wherein the eye tracking system is associated with a head-mounted display worn by a user; based on the determination of the performance metric of the eye tracking system being below the first performance threshold, the media embodying software operable when executed by the computing system to: receive one or more first inputs associated with a body of the user; estimate a region that the user is looking at within a field of view of the head-mounted display based on the received one or more first inputs associated with the body of the user; determine a vergence distance of the user based at least on the one or more first inputs associated with the body of the user, the estimated region that the user is looking at, and locations of one or more objects in a scene displayed by the head-mounted display; and adjust one or more configurations of the head-mounted display based on the determined vergence distance of the user.\\n20. A system comprising: one or more non-transitory computer-readable storage media embodying instructions; one or more processors coupled to the storage media and operable to execute the instructions to: determine that a performance metric of an eye tracking system is below a first performance threshold, wherein the eye tracking system is associated with a head-mounted display worn by a user; based on the determination of the performance metric of the eye tracking system being below the first performance threshold, the system is configured to: receive one or more first inputs associated with a body of the user; estimate a region that the user is looking at within a field of view of the head-mounted display based on the received one or more first inputs associated with the body of the user; determine a vergence distance of the user based at least on the one or more first inputs associated with the body of the user, the estimated region that the user is looking at, and locations of one or more objects in a scene displayed by the head-mounted display; and adjust one or more configurations of the head-mounted display based on the determined vergence distance of the user.', '1. A computer-implemented method for image-based, self-guided object detection, comprising: receiving, by a processor device, a set of images, each of the images having a respective grid thereon that is labeled regarding a respective object to be detected using grid level label data; training, by the processor device, a grid-based object detector using the grid level label data; determining, by the processor device, a respective bounding box for the respective object in each of the images, by applying local segmentation to each of the images; and training, by the processor device, a Region-based Convolutional Neural Network (RCNN) for joint object localization and object classification using the respective bounding box for the respective object in each of the images as an input to the RCNN.\\n2. The computer-implemented method of claim 1, further comprising performing an action responsive to the object localization and object classification for a respective new object in a new image to which the RCNN is applied.\\n3. The computer-implemented method of claim 2, wherein the action comprises autonomously controlling a motor vehicle to avoid a collision with the new object responsive to the object localization and object classification for the respective new object.\\n4. The computer-implemented method of claim 1, wherein the local segmentation is performed using a self-similarity search and template matching to provide the respective bounding box around the respective object in the set of images.\\n5. The computer-implemented method of claim 1, wherein the local segmentation is applied to each of the images to segment a respective target region therein.\\n6. The computer-implemented method of claim 1, wherein the Region-based Convolutional Neural Network (RCNN) forms a model during an object training stage that is to detect objects in new images during an inference stage.\\n7. The computer-implemented method of claim 1, wherein the method is performed by a system selected from the group consisting of a surveillance system, a face detection system, a face recognition system, a cancer detection system, an object tracking system, and an Advanced Driver-Assistance System.\\n8. A computer program product for image-based, self-guided object detection, the computer program product comprising a non-transitory computer readable storage medium having program instructions embodied therewith, the program instructions executable by a computer to cause the computer to perform a method comprising: receiving, by a processor device, a set of images, each of the images having a respective grid thereon that is labeled regarding a respective object to be detected using grid level label data; training, by the processor device, a grid-based object detector using the grid level label data; determining, by the processor device, a respective bounding box for the respective object in each of the images, by applying local segmentation to each of the images; and training, by the processor device, a Region-based Convolutional Neural Network (RCNN) for joint object localization and object classification using the respective bounding box for the respective object in each of the images as an input to the RCNN.\\n9. The computer program product of claim 8, wherein the method further comprises performing an action responsive to the object localization and object classification for a respective new object in a new image to which the RCNN is applied.\\n10. The computer program product of claim 9, wherein the action comprises autonomously controlling a motor vehicle to avoid a collision with the new object responsive to the object localization and object classification for the respective new object.\\n11. The computer program product of claim 8, wherein the local segmentation is performed using a self-similarity search and template matching to provide the respective bounding box around the respective object in the set of images.\\n12. The computer program product of claim 8, wherein the local segmentation is applied to each of the images to segment a respective target region therein.\\n13. The computer program product of claim 8, wherein the Region-based Convolutional Neural Network (RCNN) forms a model during an object training stage that is to detect objects in new images during an inference stage.\\n14. The computer program product of claim 8, wherein the method is performed by a system selected from the group consisting of a surveillance system, a face detection system, a face recognition system, a cancer detection system, an object tracking system, and an Advanced Driver-Assistance System.\\n15. A computer processing system for image-based, self-guided object detection, comprising: a memory device for storing program code; and a processor device for running the program code to receive a set of images, each of the images having a respective grid thereon that is labeled regarding a respective object to be detected using grid level label data; train a grid-based object detector using the grid level label data; determine a respective bounding box for the respective object in each of the images, by applying local segmentation to each of the images; and train a Region-based Convolutional Neural Network (RCNN) for joint object localization and object classification using the respective bounding box for the respective object in each of the images as an input to the RCNN.\\n16. The computer processing system of claim 15, wherein the processor device further runs the program code to perform an action responsive to the object localization and object classification for a respective new object in a new image to which the RCNN is applied.\\n17. The computer processing system of claim 16, wherein the action comprises autonomously controlling a motor vehicle to avoid a collision with the new object responsive to the object localization and object classification for the respective new object.\\n18. The computer processing system of claim 15, wherein the local segmentation is performed using a self-similarity search and template matching to provide the respective bounding box around the respective object in the set of images.\\n19. The computer processing system of claim 15, wherein the Region-based Convolutional Neural Network (RCNN) forms a model during an object training stage that is to detect objects in new images during an inference stage.\\n20. The computer processing system of claim 15, wherein the computer processing system is comprised in a system selected from the group consisting of a surveillance system, a face detection system, a face recognition system, a cancer detection system, an object tracking system, and an Advanced Driver-Assistance System.', '1. A method of scalable, parallel, cloud-based face recognition utilizing a database of normalized stored images, comprising: capturing an image using a camera; detecting a face in the captured image; normalizing the detected facial image to match the normalized stored images; identifying facial features in the normalized detected facial image; generating a plurality of facial metrics from the facial features; calculating Euclidean distances between the facial metrics of the normalized detected facial image with corresponding facial metrics of each of the stored images; comparing each Euclidean distance against a predetermined threshold; responsive to the Euclidean distance comparison, producing a reduced candidate list of best possible image matches from the normalized stored images; comparing, in parallel, the normalized detected facial image with each of the normalized stored images of the reduced candidate list utilizing a plurality of face recognition algorithms, where each processor of a parallel processing system uses a different face recognition algorithm; responsive to the comparison, producing best match results from each parallel subset of the reduced candidate list; and selecting a final match from the best match results using a deep learning neural network face recognition algorithm trained on outputs of individual face recognition algorithms.\\n2. The method of scalable, parallel, cloud-based face recognition of claim 1, wherein detecting a face in the captured image comprises: utilizing OpenCV to detect a face in the captured image; extracting the location of the eyes and a tip of the nose in the face; determining a distance between the eyes; cropping the face from the captured image, where the width and the height of a cropped face image is a function of the distance between the eyes; and rotating the face by an angle of rotation that is a function of the distance between the eyes.\\n3. The method of scalable, parallel, cloud-based face recognition of claim 2, wherein: the width of the cropped face image is 2.5 times the distance between the eyes; the height of the cropped face image is 3.5 times the distance between the eyes; and the angle of rotation is an angle formed by a straight line joining the eyes and an x-axis of the face.\\n4. The method of scalable, parallel, cloud-based face recognition of claim 3, wherein rotating the face comprises rotating the face to provide a frontal face pattern.\\n5. The method of scalable, parallel, cloud-based face recognition of claim 4, further comprising the step of proportionally rescaling the cropped and rotated image.\\n6. The method of scalable, parallel, cloud-based face recognition of claim 5, where the proportional rescaling yields a cropped and rotated image with a size of 100=100 pixels.\\n7. The method of scalable, parallel, cloud-based face recognition of claim 1, wherein the facial features identified in the normalized detected facial image comprise a pair of eyes, a tip of a nose, a mouth, a center of the mouth, and a chin area comprising a bottom, a top left landmark, and a top right landmark.\\n8. The method of scalable, parallel, cloud-based face recognition of claim 7, wherein generating a plurality of facial metrics comprises: calculating a distance between the pair of eyes, a distance between the eyes and the tip of the nose, a distance equal to the width of the mouth, a distance between the tip of the nose and the center of mouth, a distance between the bottom of chin and the center of mouth, a distance between the top left landmark on the chin and the tip of the nose, and a distance between the top right landmark on the chin and the tip of the nose.\\n9. The method of scalable, parallel, cloud-based face recognition of claim 8, wherein performing a Euclidean distance match further comprises: partitioning the normalized stored images into a plurality of substantially equal subsets; performing a Euclidean distance match between the facial metrics of the normalized detected facial image and corresponding facial metrics of each of the stored images of the subsets of the normalized stored images with a separate processor of a parallel processing system to generate a Euclidean distance for each stored image of the subset; comparing each Euclidean distance against a predetermined threshold with the separate processors; responsive to the Euclidean distance comparison, producing a reduced candidate list of best possible image matches from the normalized stored images of each subset; and combining the reduced candidate lists from each subset to produce a single reduced candidate list.\\n10. The method of scalable, parallel, cloud-based face recognition of claim 9, wherein the plurality of face recognition algorithms utilized in comparing, in parallel, the normalized detected facial image with each of the normalized stored images of the reduced candidate list, consists of face recognition algorithms selected from a group consisting of Principle Component Analysis (PCA)-based algorithms, Linear Discriminant Analysis (LDA) algorithms, Independent Component Analysis (ICA) algorithms, kernel-based algorithms, feature-based techniques, algorithms based on neural networks, algorithms based on transforms, and model-based face recognition algorithms.\\n11. The method of scalable, parallel, cloud-based face recognition of claim 10, wherein the PCA-based algorithms include Eigenfaces for face detection/recognition, and the LDA algorithms include the Fisherfaces method of face recognition.\\n12. The method of scalable, parallel, cloud-based face recognition of claim 1, wherein comparing, in parallel, the captured image with each of the normalized stored images of the reduced candidate list further comprises: partitioning the reduced candidate list into a plurality of substantially equal subsets; processing each subset in a different processor of the parallel processing system uses a unique face recognition algorithm to produce the best match results; and using a reduce function of a MapReduce program to combine the best match results from each of the subsets to produce a single set of the best match results.\\n13. The method of scalable, parallel, cloud-based face recognition of claim 12, wherein partitioning the reduced candidate list comprises: selecting the images comprising each subset by optimizing the variance between of each of the images according to the following equation: where m and n are the number of rows and columns of the face vector image, N is the number of groups, and σij is the standard deviation of image dimension i in the group j of the face image vector.\\n14. The method of scalable, parallel, cloud-based face recognition of claim 13, wherein selecting the images comprising each subset by optimizing the variance between each of the images according to the following equation: d(μi, μj) is the Euclidean distance between the mean of the group i and the mean of group j, I is the face image vector, and L is the number of group levels.\\n15. The method of scalable, parallel, cloud-based face recognition of claim 1, where selecting a final match from the best match results utilizing a deep learning neural network face recognition algorithm comprises utilizing either an AdaBoost machine-learning algorithm or a neural networks machine-learning model.\\n16. The method of scalable, parallel, cloud-based face recognition of claim 1, where normalizing the detected facial image to match the normalized stored images includes normalizing the detected facial image to the same size, orientation, and illumination of the normalized stored images.\\n17. A non-transitory computer-readable medium containing executable program instructions for causing a computer to perform a method of face recognition, the method comprising: detecting a face in an image captured by a camera; normalizing the detected facial image to match the normalized stored images; identifying facial features in the normalized detected facial image; generating a plurality of facial metrics from the facial features; calculating Euclidean distances between the facial metrics of the normalized detected facial image with corresponding facial metrics of each of the stored images; comparing each Euclidean distance against a predetermined threshold; responsive to the Euclidean distance comparison, producing a reduced candidate list of best possible image matches from the normalized stored images; comparing, in parallel, the captured image with each of the normalized stored images of the reduced candidate list utilizing a plurality of face recognition algorithms, where each processor of a parallel processing system uses a different face recognition algorithm; responsive to the comparison, producing best match results from each parallel subset of the reduced candidate list; and selecting a final match from the best match results using a deep learning neural network face recognition algorithm trained on outputs of individual face recognition algorithms.\\n18. The non-transitory computer-readable medium containing executable program instructions of claim 17, wherein the plurality of face recognition algorithms utilized in comparing, in parallel, the normalized detected facial image with each of the normalized stored images of the reduced candidate list, consists of face recognition algorithms selected from a group consisting of Principle Component Analysis (PCA)-based algorithms, Linear Discriminant Analysis (LDA) algorithms, Independent Component Analysis (ICA) algorithms, kernel-based algorithms, feature-based techniques, algorithms based on neural networks, algorithms based on transforms, and model-based face recognition algorithms.\\n19. The non-transitory computer-readable medium containing executable program instructions of claim 18, wherein the PCA-based algorithms include Eigenfaces for face detection/recognition, and the LDA algorithms include the Fisherfaces method of face recognition.\\n20. The non-transitory computer-readable medium containing executable program instructions of claim 17, where selecting a final match from the best match results utilizing a deep learning neural network face recognition algorithm comprises utilizing either an AdaBoost machine-learning algorithm or a neural networks machine-learning model.', '1. An imaging device, comprising: a condensing lens; an image sensor configured to detect light passing through the condensing lens and comprising a pixel matrix, wherein the pixel matrix comprises a plurality of phase detection pixel pairs and a plurality of regular pixels; and a processor configured to turn on the phase detection pixel pairs for autofocusing and output autofocused pixel data after completing the autofocusing, divide the autofocused pixel data into a first subframe and a second subframe, calculate image features of at least one of the first subframe and the second subframe, wherein the image features comprise module widths of a finder pattern, and the finder pattern has a predetermined ratio, a Harr-like feature, or a Gabor feature, and determine an operating resolution of the regular pixels according to the image features calculated from at least one of the first subframe and the second subframe divided from the autofocused pixel data.\\n2. The imaging device as claimed in claim 1, wherein each of the phase detection pixel pairs comprises: a first pixel and a second pixel; a cover layer covering upon a first region of the first pixel and upon a second region of the second pixel, wherein the first region and the second region are mirror symmetrical to each other; and a microlens aligned with at least one of the first pixel and the second pixel.\\n3. The imaging device as claimed in claim 2, wherein the first region and the second region are 5% to 95% of an area of a single pixel.\\n4. The imaging device as claimed in claim 1, wherein the processor is configured to perform the autofocusing using a dual pixel autofocus technique according to pixel data of the phase detection pixel pairs before completing the autofocusing.\\n5. The imaging device as claimed in claim 1, wherein the processor is configured to divide pixel data of the phase detection pixel pairs into a third subframe and a fourth subframe before completing the autofocusing, and perform the autofocusing according to the third subframe and the fourth subframe.\\n6. The imaging device as claimed in claim 5, wherein the processor is further configured to calibrate brightness of the third subframe and the fourth subframe to be identical using a shading algorithm.\\n7. The imaging device as claimed in claim 1, wherein the operating resolution is selected as a first resolution smaller than a number of the regular pixels or as a second resolution larger than the first resolution.\\n8. The imaging device as claimed in claim 1, wherein the regular pixels are turned off in the autofocusing.\\n9. The imaging device as claimed in claim 1, wherein a number of the phase detection pixel pairs is smaller than that of the regular pixels.\\n10. An imaging device, comprising: a condensing lens; an image sensor configured to detect light passing through the condensing lens and comprising a pixel matrix, wherein the pixel matrix comprises a plurality of phase detection pixel pairs and a plurality of regular pixels; and a processor configured to turn on the phase detection pixel pairs for autofocusing and output autofocused pixel data after completing the autofocusing, divide the autofocused pixel data into a first subframe and a second subframe, calculate image features of at least one of the first subframe and the second subframe, wherein the image features comprise module widths of a finder pattern, and the finder pattern has a predetermined ratio, a Harr-like feature, or a Gabor feature, and select an image decoding or an image recognition using pixel data of the regular pixels according to the image features calculated from at least one of the first subframe and the second subframe divided from the autofocused pixel data.\\n11. The imaging device as claimed in claim 10, wherein each of the phase detection pixel pairs comprises: a first pixel and a second pixel; a cover layer covering upon a first region of the first pixel and upon a second region of the second pixel, wherein the first region and the second region are mirror symmetrical to each other; and a microlens aligned with at least one of the first pixel and the second pixel.\\n12. The imaging device as claimed in claim 10, wherein the processor is configured to perform the autofocusing using a dual pixel autofocus technique according to pixel data of the phase detection pixel pairs before completing the autofocusing.\\n13. The imaging device as claimed in claim 10, wherein the processor is configured to divide the pixel data of the phase detection pixel pairs into a third subframe and a fourth subframe before completing the autofocusing, calibrate brightness of the third subframe and the fourth subframe to be identical using a shading algorithm, and perform the autofocusing according to the third subframe and the fourth subframe.\\n14. The imaging device as claimed in claim 10, wherein the processor is configured to calculate the image features using at least one of a rule based algorithm and a machine learning algorithm.\\n15. The imaging device as claimed in claim 10, wherein the image decoding is decoding QR codes, and the image recognition is face recognition.\\n16. An operating method of an imaging device, the imaging device comprising a plurality of phase detection pixel pairs and a plurality of regular pixels, the operating method comprising: turning on the phase detection pixel pairs for autofocusing and outputting autofocused image frame after completing the autofocusing; dividing the autofocused image frame, acquired by the phase detection pixel pairs, into a first subframe and a second subframe; calculating image features of at least one of the first subframe and the second subframe, wherein the image feature comprise module widths of a finder pattern, and the finder pattern has a predetermined ratio, a Harr-like feature, or a Gabor feature; and selectively activating at least a part of the regular pixels according to the image features calculated from at least one of the first subframe and the second subframe divided from the autofocused image frame.\\n17. The operating method as claimed in claim 16, wherein the selectively activating comprises: activating a first part of the regular pixels to perform an image decoding according to pixel data of the first part of the regular pixels; or activating all the regular pixels to perform an image recognition according to pixel data of the all regular pixels.\\n18. The operating method as claimed in claim 17, wherein pixel data of the phase detection pixel pairs captured in a same frame with the pixel data of the regular pixels is also used in performing the image decoding and the image recognition.\\n19. The operating method as claimed in claim 17, wherein the image decoding is decoding QR codes, and the image recognition is face recognition.\\n20. The operating method as claimed in claim 16, wherein the phase detection pixel pairs are partially covered pixels or have a structure of dual pixel.', '1. An apparatus comprising: a first camera module configured to obtain a first image of an object with a first field of view; a second camera module configured to obtain a second image of the object with a second field of view different from the first field of view; a first depth map generator configured to generate a first depth map of the first image based on the first image and the second image; and a second depth map generator configured to generate a second depth map of the second image based on the first image, the second image, and the first depth map.\\n2. The apparatus of claim 1, wherein the first field of view is a narrow angle and the second field of view is a wider angle.\\n3. The apparatus of claim 2, wherein the second image is divided into a primary region and a residual region, and the second depth map generator comprises: a relationship estimating module configured to estimate a relationship between the primary region and the residual region based on the first image and the second image; and a depth map estimating module configured to estimate a depth map of the residual region based on the estimated relationship and the first depth map.\\n4. The apparatus of claim 3, wherein at least one of the relationship estimating module and the depth map estimating module performs an estimating operation based on a neural network module.\\n5. The apparatus of claim 1, further comprising: a depth map fusion unit configured to generate a third depth map of the second image by performing a fusion operation based on the first depth map and the second depth map.\\n6. The apparatus of claim 5, wherein the depth map fusion unit comprises: a tone mapping module configured to generate a tone-mapped second depth map to correspond to the first depth map by performing a bias removing operation on the second depth map; and a fusion module configured to generate the third depth map by fusing the tone-mapped second depth map and the first depth map.\\n7. The apparatus of claim 6, wherein the depth map fusion unit further comprises a propagating module configured to generate a propagated first depth map in the second image by iterated propagating of the first depth map based on the first depth map and the second image, and the fusion module generates the third depth map by fusing the tone-mapped second depth map and the propagated first depth map.\\n8. The apparatus of claim 6, wherein the depth map fusion unit further comprises a post-processing module configured to perform a post-processing operation on the third depth map generated by the fusion module to provide the post-processed third depth map.\\n9. The apparatus of claim 8, wherein the post-processing module performs the post-processing operation by filtering an interface generated in the third depth map in accordance with fusion of the fusion module.\\n10. The apparatus of claim 8, wherein the post-processing module removes artifacts generated in the third depth map in accordance with fusion of the fusion module.\\n11. The apparatus of claim 1, wherein the first depth map generator analyses a distance relationship between the first image and the second image, and generates a first depth map of the first image based on the distance relationship.\\n12. A method of processing an image of an electronic apparatus, the method comprising: obtaining a first image of an object using a first camera module; obtaining a second image of the object using a second camera module; generating a first depth map of the first image based on the first image and the second image; estimating a relationship between a primary region of the second image and a residual region of the second image based on the first image and the second image; and generating a second depth map of the second image based on the estimated relationship between the primary region and the residual region, and the first depth map.\\n13. The method of claim 12, wherein the electronic apparatus comprises a first camera module including a first lens having a first field of view and a second camera module including a second lens having a second field of view wider than the first field of view.\\n14. The method of claim 13, wherein the generating of the second depth map comprises: estimating a depth map of the residual region based on the estimated relationship between the primary region and the residual region, and the first depth map; and generating the second depth map based on a depth map of the residual region and the first depth map.\\n15. The method of claim 12, wherein the estimating of the relationship between a primary region of the second image is performed using a neural network model.\\n16. The method of claim 12, further comprising: performing a pre-processing operation on the second depth map; and generating a third depth map of the residual image by fusing the second depth map on which the pre-processing operation is performed and the first depth map.\\n17. The method of claim 16, wherein the performing of the pre-processing operation comprises performing a tone mapping operation between a depth map of the primary region and a depth map of the residual region based on the second depth map.\\n18. An operating method for an electronic apparatus, the electronic apparatus including; a first camera module providing a first image of an object using a first field of view and a second camera module providing a second image of the object using second field of view wider than the first field of view, and a processor generating a depth map of the second image based on a primary region of the second image and a residual region of the second image, the operating method comprising: generating a first depth map of the primary region by estimating a relationship between the first image and the second image; estimating a relationship between the primary region and the residual region based on the first image and the second image; generating a second depth map of the second image by estimating a depth map of the second region based on the estimated relationship between the primary region and the residual region; and generating a depth map of the second image by fusing the first depth map and the second depth map.\\n19. The operation method of claim 18, further comprising: executing an application that applies an image effect to the second image based on a depth map of the residual image.\\n20. The operation method of claim 19, wherein the application applies at least one image effect of auto-focusing, out-focusing, fore/background separation, face recognition, object detection within a frame, and augmented reality to the second image based on a depth map of the second image.', '1. A payment method based on a face recognition, comprising: acquiring first face image information of a target user; extracting first characteristic information from the first face image information, wherein the first characteristic information includes head posture information of the target user and gaze information of the target user; determining whether the target user has a willingness to pay according to the head posture information of the target user and the gaze information of the target user, including: determining whether an angle of rotation in each preset direction is less than an angle threshold, wherein the head posture information includes the angle of rotation in each preset direction; determining whether a probability value that a user gazes at a payment screen is greater than a probability threshold, wherein the gaze information includes the probability value that a user gazes at a payment screen; and in response to determining that the angle of rotation in each preset direction is less than the angle threshold and that the probability value that a user gazes at a payment screen is greater than the probability threshold, determining that the target user has a willingness to pay; and in response to determining that the target user has a willingness to pay, completing a payment operation based on the face recognition.\\n2. The method as claimed in claim 1, wherein the completing a payment operation based on the face recognition comprises: triggering and performing a payment initiating operation to acquire second face image information based on the face recognition; determining whether second characteristic information extracted from the second face image information indicates that the user has a willingness to pay; and in response to determining that the second characteristic information indicates that the user has a willingness to pay, triggering and performing a payment confirmation operation to complete the payment operation based on payment account information corresponding to the target user.\\n3. The method as claimed in claim 2, wherein the determining whether second characteristic information extracted from the second face image information indicates that the user has a willingness to pay comprises: determining whether a current user corresponding to the second face image information is consistent with the target user; and in response to determining that the current user is consistent with the target user, determining whether the target user has a willingness to pay according to the second characteristic information extracted from the second face image information.\\n4. The method as claimed in claim 1, wherein the extracting first characteristic information from the first face image information comprises: determining the head posture information of the target user using a head posture recognition model based on the first face image information; and determining the gaze information of the target user using a gaze information recognition model based on characteristics of an eye region in the first face image information.\\n5. The method as claimed in claim 4, wherein the head posture recognition model is obtained through training by: acquiring a first sample data set, wherein the first sample data set includes a plurality of pieces of first sample data, and each of the plurality of pieces of first sample data includes a correspondence between a sample face image and head posture information; determining mean image data and variance image data of a plurality of sample face images; for each of the plurality of pieces of first sample data, preprocessing the sample face image contained in each of the plurality of pieces of first sample data based on the mean image data and the variance image data to obtain a preprocessed sample face image; setting the preprocessed sample face image and the corresponding head posture information as a first model training sample; and performing training using a machine learning method and based on a plurality of first model training samples to obtain the head posture recognition model.\\n6. The method as claimed in claim 4, wherein the gaze information recognition model is obtained through training by: acquiring a second sample data set, wherein the second sample data set includes a plurality of pieces of second sample data, and each of the plurality of pieces of second sample data includes a correspondence between a sample eye image and gaze information; determining mean image data and variance image data of a plurality of sample eye images; for each of the plurality of pieces of second sample data, preprocessing the sample eye image contained in each of the plurality of pieces of second sample data based on the mean image data and the variance image data to obtain a preprocessed sample eye image; setting the preprocessed sample eye image and the corresponding gaze information as a second model training sample; and performing training using a machine learning method and based on a plurality of second model training samples to obtain the gaze information recognition model.\\n7. The method as claimed in claim 1, wherein the angle of rotation in each preset direction comprises a pitch angle, a yaw angle, and a roll angle, wherein the pitch angle refers to an angle of rotation around a X-axis, the yaw angle refers to an angle of rotation around a Y-axis, and the roll angle refers to an angle of rotation around a Z-axis.\\n8. A payment device based on a face recognition, comprising: a processor, and a non-transitory computer-readable storage medium storing instructions executable by the processor to cause the device to perform operations comprising: acquiring first face image information of a target user; extracting first characteristic information from the first face image information, wherein the first characteristic information includes head posture information of the target user and gaze information of the target user; determining whether the target user has a willingness to pay according to the head posture information of the target user and the gaze information of the target user, including: determining whether an angle of rotation in each preset direction is less than an angle threshold, wherein the head posture information includes the angle of rotation in each preset direction; determining whether a probability value that a user gazes at a payment screen is greater than a probability threshold, wherein the gaze information includes the probability value that a user gazes at a payment screen; and in response to determining that the angle of rotation in each preset direction is less than the angle threshold and that the probability value that a user gazes at a payment screen is greater than the probability threshold, determining that the target user has a willingness to pay; and in response to determining that the target user has a willingness to pay, completing a payment operation based on the face recognition.\\n9. The device as claimed in claim 8, wherein the completing a payment operation based on the face recognition comprises: triggering and performing a payment initiating operation to acquire second face image information based on the face recognition; determining whether second characteristic information extracted from the second face image information indicates that the user has a willingness to pay; and in response to determining that the second characteristic information indicates that the user has a willingness to pay, triggering and performing a payment confirmation operation to complete the payment operation based on payment account information corresponding to the target user.\\n10. The device as claimed in claim 9, wherein the determining whether second characteristic information extracted from the second face image information indicates that the user has a willingness to pay comprises: determining whether a current user corresponding to the second face image information is consistent with the target user; and in response to determining that the current user is consistent with the target user, determining whether the target user has a willingness to pay according to the second characteristic information extracted from the second face image information.\\n11. The device as claimed in claim 8, wherein the extracting first characteristic information from the first face image information comprises: determining the head posture information of the target user using a head posture recognition model based on the first face image information; and determining the gaze information of the target user using a gaze information recognition model based on characteristics of an eye region in the first face image information.\\n12. The device as claimed in claim 11, wherein the head posture recognition model is obtained through training by: acquiring a first sample data set, wherein the first sample data set includes a plurality of pieces of first sample data, and each of the plurality of pieces of first sample data includes a correspondence between a sample face image and head posture information; determining mean image data and variance image data of a plurality of sample face images; for each of the plurality of pieces of first sample data, preprocessing the sample face image contained in each of the plurality of pieces of first sample data based on the mean image data and the variance image data to obtain a preprocessed sample face image; setting the preprocessed sample face image and the corresponding head posture information as a first model training sample; and performing training using a machine learning method and based on a plurality of first model training samples to obtain the head posture recognition model.\\n13. The device as claimed in claim 11, wherein the gaze information recognition model is obtained through training by: acquiring a second sample data set, wherein the second sample data set includes a plurality of pieces of second sample data, and each of the plurality of pieces of second sample data includes a correspondence between a sample eye image and gaze information; determining mean image data and variance image data of a plurality of sample eye images; for each of the plurality of pieces of second sample data, preprocessing the sample eye image contained in each of the plurality of pieces of second sample data based on the mean image data and the variance image data to obtain a preprocessed sample eye image; setting the preprocessed sample eye image and the corresponding gaze information as a second model training sample; and performing training using a machine learning method and on a plurality of second model training samples to obtain the gaze information recognition model.\\n14. The device as claimed in claim 11, wherein the angle of rotation in each preset direction comprises a pitch angle, a yaw angle, and a roll angle, wherein the pitch angle refers to an angle of rotation around a X-axis, the yaw angle refers to an angle of rotation around a Y-axis, and the roll angle refers to an angle of rotation around a Z-axis.\\n15. A non-transitory computer-readable storage medium for a payment based on a face recognition, configured with instructions executable by one or more processors to cause the one or more processors to perform operations comprising: acquiring first face image information of a target user; extracting first characteristic information from the first face image information, wherein the first characteristic information includes head posture information of the target user, and gaze information of the target user; determining whether the target user has a willingness to pay according to the head posture information of the target user and the gaze information of the target user, including: determining whether an angle of rotation in each preset direction is less than an angle threshold, wherein the head posture information includes the angle of rotation in each preset direction; determining whether a probability value that a user gazes at a payment screen is greater than a probability threshold, wherein the gaze information includes the probability value that a user gazes at a payment screen; and in response to determining that the angle of rotation in each preset direction is less than the angle threshold and that the probability value that a user gazes at a payment screen is greater than the probability threshold, determining that the target user has a willingness to pay; and in response to determining that the target user has a willingness to pay, completing a payment operation based on the face recognition.\\n16. The storage medium as claimed in claim 15, wherein the completing a payment operation based on the face recognition comprises: triggering and performing a payment initiating operation to acquire second face image information based on the face recognition; determining whether second characteristic information extracted from the second face image information indicates that the user has a willingness to pay; and in response to determining that the second characteristic information indicates that the user has a willingness to pay, triggering and performing a payment confirmation operation to complete the payment operation based on payment account information corresponding to the target user.\\n17. The storage medium as claimed in claim 16, wherein the determining whether second characteristic information extracted from the second face image information indicates that the user has a willingness to pay comprises: determining whether a current user corresponding to the second face image information is consistent with the target user; and in response to determining that the current user is consistent with the target user, determining whether the target user has a willingness to pay according to the second characteristic information extracted from the second face image information.\\n18. The storage medium as claimed in claim 15, wherein the extracting first characteristic information from the first face image information comprises: determining the head posture information of the target user using a head posture recognition model based on the first face image information; and determining the gaze information of the target user using a gaze information recognition model based on characteristics of an eye region in the first face image information.\\n19. The storage medium as claimed in claim 18, wherein the head posture recognition model is obtained through training by: acquiring a first sample data set, wherein the first sample data set includes a plurality of pieces of first sample data, and each of the plurality of pieces of first sample data includes a correspondence between a sample face image and head posture information; determining mean image data and variance image data of a plurality of sample face images; for each of the plurality of pieces of first sample data, preprocessing the sample face image contained in each of the plurality of pieces of first sample data based on the mean image data and the variance image data to obtain a preprocessed sample face image; setting the preprocessed sample face image and the corresponding head posture information as a first model training sample; and performing training using a machine learning method and based on a plurality of first model training samples to obtain the head posture recognition model; and wherein the gaze information recognition model is obtained through training by: acquiring a second sample data set, wherein the second sample data set includes a plurality of pieces of second sample data, and each of the plurality of pieces of second sample data includes a correspondence between a sample eye image and gaze information; determining mean image data and variance image data of a plurality of sample eye images; for each of the plurality of pieces of second sample data, preprocessing the sample eye image contained in each of the plurality of pieces of second sample data based on the mean image data and the variance image data to obtain a preprocessed sample eye image; setting the preprocessed sample eye image and the corresponding gaze information as a second model training sample; and performing training using a machine learning method and based on a plurality of second model training samples to obtain the gaze information recognition model.\\n20. The storage medium as claimed in claim 18, wherein the angle of rotation in each preset direction comprises a pitch angle, a yaw angle, and a roll angle, wherein the pitch angle refers to an angle of rotation around a X-axis, the yaw angle refers to an angle of rotation around a Y-axis, and the roll angle refers to an angle of rotation around a Z-axis.', '1. A method comprising: detecting, by a motion detection module, a motion by a subject within a predetermined area of view; assigning a unique session identification number to the subject detected within a predetermined area of view; detecting a facial area of the subject detected within a predetermined area of view; generating an image of the facial area of the subject; assessing a quality of the image of the facial area of the subject; determining an identity of the subject based on the image of the facial area of the subject; identifying an intent of the subject; and authorizing access to a point of entry based on the determined identity of the subject and based on the intent of the subject.\\n2. The method of claim 1, further comprising: determining one or more additional subjects within the predetermined area of view; and assigning a unique session identification number to each of the one or more additional subjects detected within a predetermined area of view.\\n3. The method of claim 1, wherein the assessing a quality of the image of the facial area of the subject comprises: assessing whether the quality of the image of the facial area of the object equates predetermined metric of quality; and upon determining that the quality of the image of the facial area of the object is inferior to the predetermined metric of quality, discarding the image of the facial area of the subject and generating a second image of the facial area of the subject.\\n4. The method of claim 1, further comprising: detecting whether the facial area of the subject is photographic image; and upon detecting that the facial area of the subject is a photographic image, generating a warning and restrict access to the point of entry.\\n5. The method of claim 1, further comprising: conducing an incremental training of the image of the facial area of the subject.\\n6. The method of claim 5, wherein conducing an incremental training of the image of the facial area of the subject comprises: capturing a first image of the facial area having facial landmarks; converting the first image of the facial area into a first numeric vector; capturing a second image of the facial area having facial landmarks; converting the second image of the facial area into a second numeric vector; calculating a weighted mean of the first numeric vector and the second numeric vector, wherein the weighted mean represents a change in a facial area; and storing the weighted mean in the database.\\n7. The method of claim 1, wherein determining an identity of the subject based on the image of the facial area of the subject comprises: comparing the image of the facial area of the subject with a plurality of images stored in a database; and authenticating the subject.\\n8. The method of claim 1, wherein identifying an intent of the subject comprises: upon detecting the facial area in a bounding box, commencing authentication of the subject; calculating a directional vector of a face of the subject; determine an intent of the subject to gain access to the point of entry based on the directional vector of the face of the subject; granting the access to the point of entry based on authentication of the subject and based on determining the intent of the subject.\\n9. A non-transitory computer readable medium having program instructions stored thereon, that in response to execution by a computing device cause the computing device to perform operations comprising: detecting a motion by a subject within a predetermined area of view; assigning a unique session identification number to the subject detected within a predetermined area of view; detecting a facial area of the subject detected within a predetermined area of view; generating an image of the facial area of the subject; assessing a quality of the image of the facial area of the subject; determining an identity of the subject based on the image of the facial area of the subject; identifying an intent of the subject; and authorizing access to a point of entry based on the determined identity of the subject and based on the intent of the subject.\\n10. The non-transitory computer readable medium of claim 9, further comprising: determining one or more additional subjects within the predetermined area of view; and assigning a unique session identification number to each of the one or more additional subjects detected within a predetermined area of view.\\n11. The non-transitory computer readable medium of claim 9, wherein the assessing a quality of the image of the facial area of the subject comprises: assessing whether the quality of the image of the facial area of the object equates predetermined metric of quality; and upon determining that the quality of the image of the facial area of the object is inferior to the predetermined metric of quality, discarding the image of the facial area of the subject and generating a second image of the facial area of the subject.\\n12. The non-transitory computer readable medium of claim 9, further comprising: detecting whether the facial area of the subject is photographic image; and upon detecting that the facial area of the subject is a photographic image, generating a warning and restrict access to the access point.\\n13. The non-transitory computer readable medium of claim 9, further comprising: conducing an incremental training of the image of the facial area of the subject.\\n14. The non-transitory computer readable medium of claim 13, wherein conducing an incremental training of the image of the facial area of the subject comprises: capturing a first image of the facial area having facial landmarks; converting the first image of the facial area into a first numeric vector; capturing a second image of the facial area having facial landmarks; converting the second image of the facial area into a second numeric vector; calculating a weighted mean of the first numeric vector and the second numeric vector, wherein the weighted mean represents a change in a facial area; and storing the weighted mean in the database.\\n15. An apparatus for face recognition comprising: a processor; and a memory to store computer program instructions, the computer program instructions when executed on the processor cause the processor to perform operations comprising: detecting a motion by a subject within a predetermined area of view; assigning a unique session identification number to the subject detected within a predetermined area of view; detecting a facial area of the subject detected within a predetermined area of view; generating an image of the facial area of the subject; assessing a quality of the image of the facial area of the subject; determining an identity of the subject based on the image of the facial area of the subject; identifying an intent of the subject; and authorizing access to a point of entry based on the determined identity of the subject and based on the intent of the subject.\\n16. The apparatus of claim 15, further comprising: determining one or more additional subjects within the predetermined area of view; and assigning a unique session identification number to each of the one or more additional subjects detected within a predetermined area of view.\\n17. The apparatus of claim 15, wherein the assessing a quality of the image of the facial area of the subject comprises: assessing whether the quality of the image of the facial area of the object equates predetermined metric of quality; and upon determining that the quality of the image of the facial area of the object is inferior to the predetermined metric of quality, discarding the image of the facial area of the subject and generating a second image of the facial area of the subject.\\n18. The apparatus of claim 15, further comprising: detecting whether the facial area of the subject is photographic image; and upon detecting that the facial area of the subject is a photographic image, generating a warning and restrict access to the access point.\\n19. The apparatus of claim 15, further comprising: conducing an incremental training of the image of the facial area of the subject.\\n20. The apparatus of claim 15, wherein conducing an incremental training of the image of the facial area of the subject comprises: capturing a first image of the facial area having facial landmarks; converting the first image of the facial area into a first numeric vector; capturing a second image of the facial area having facial landmarks; converting the second image of the facial area into a second numeric vector; calculating a weighted mean of the first numeric vector and the second numeric vector, wherein the weighted mean represents a change in a facial area; and storing the weighted mean in the database.', '1. A robot, comprising: a body configured to rotate and to tilt; a camera coupled to the body and configured to rotate and tilt according to the rotate and the tilt of the body, wherein the camera is configured to acquire a video of a space; a face recognition unit configured to recognize respective faces of one or more persons in the video; a tracking unit configured to track motion of each of the recognized faces of the one or more persons; and a controller configured to: calculate a respective size of each of the faces of the one or more persons; select a first person, from among the one or more persons, based on the calculated sizes of the faces; and control at least one of a direction of the rotation of the camera, an angle of the tilt of the camera and a focal distance of the camera, based on the tracked motion of the recognized face of the first person.\\n2. The robot of claim 1, wherein the controller is configured to: control the direction of the rotation of the camera and the angle of the tilt of the camera to achieve an particular orientation of the camera relative to the face of the first person; and control a focal distance of the camera by comparing respective sizes of the face of the first person before and after motion of the first person.\\n3. The robot of claim 2, wherein the particular orientation occurs when the camera faces a general direction of the face of the first person.\\n4. The robot of claim 1, wherein the controller is configured to: normalize sizes of the faces of the one or more persons based on an interocular distance; and select the first person based on the normalized sizes of the faces of the one or more persons.\\n5. The robot of claim 1, wherein the controller is configured to: select a person having a largest face size, from among the one or more persons, as the first person.\\n6. The robot of claim 1, further comprising: a microphone configured to receive a spoken audio that is present in the space; wherein the controller is further configured to select the first person further based on the received spoken audio.\\n7. The robot of claim 6, wherein the controller is further configured to: control gain of the microphone by comparing respective sizes of the face of the first person before and after motion of the first person.\\n8. The robot of claim 6, wherein the controller is configured to: calculate a position from which the spoken audio is provided; and select the first person further based on whether the one or more persons are in the position from which the voice signal is provided.\\n9. The robot of claim 8, wherein the controller is configured to: select a second person as the first person, from among the one or more persons, when the second person is located in the position from which the spoken audio is provided.\\n10. The robot of claim 8, wherein the controller is configured to: select a second person having a largest face size as the first person, from among the one or more persons, when none of the one or more persons is located in the position from which the spoken audio is provided.\\n11. The robot of claim 8, wherein the controller is configured to: select a second person having a largest face size as the first person, from among the one or more persons, when a plurality of persons from among the one or more persons are located in the position from which the spoken audio is provided.\\n12. The robot of claim 1, further comprising: a speaker, wherein the controller is configured to: control volume of the speaker by comparing respective sizes of the face of the first person before and after motion of the first person.\\n13. The robot of claim 1, wherein the body is further configured to rotate in a lateral direction, and to tilt in an vertical direction.\\n14. An electronic device, comprising: a camera coupled to the body and configured to rotate and to tilt, wherein the camera is configured to acquire a video of a space within which one or more persons are positioned; and a processor configured to: recognize respective faces of the one or more persons in the video; track motion of each of the recognized faces of the one or more persons; calculate a respective size of each of the faces of the one or more persons; select a first person, from among the one or more persons, based on the calculated sizes of the faces; and control at least one of a direction of the rotation of the camera, an angle of the tilt of the camera and a focal distance of the camera, based on the tracked motion of the recognized face of the first person.\\n15. A method, comprising: acquiring, by a camera, a video of a space within which one or more persons are positioned; recognizing respective faces of the one or more persons in the video; tracking motion of each of the recognized faces of the one or more persons; calculating a respective size of each of the faces of the one or more persons; selecting a first person, from among the one or more persons, based on the calculated sizes of the faces; and controlling at least one of a direction of rotation of the camera, an angle of tilt of the camera and a focal distance of the camera, based on the tracked motion of the recognized face of the first person.', '1. A method of inferring topics from a multimodal file, the method comprising: receiving a multimodal file;\\nextracting a set of entities from the multimodal file;\\nlinking the set of entities to produce a set of linked entities;\\nobtaining reference information for the set of entities;\\nbased at least on the reference information, generating a graph of the set of linked entities, the graph comprising nodes and edges;\\nbased at least on the nodes and edges of the graph, determining clusters in the graph;\\nbased at least on the clusters in the graph, identifying topic candidates;\\nextracting features from the clusters in the graph;\\nbased at least on the extracted features, selecting at least one TopicID from among the topic candidates to represent at least one cluster; and\\nindexing the multimodal file with the at least one TopicID.\\n2. The method of claim 1 wherein the multimodal file comprises a video portion and an audio portion and wherein extracting a set of entities from the multimodal file comprises:\\ndetecting objects in the video portion of the multimodal file; and\\ndetecting text in the audio portion of the multimodal file.\\n3. The method of claim 2 wherein detecting objects comprises performing face recognition.\\n4. The method of claim 2 wherein detecting text comprises performing a speech to text process.\\n5. The method of claim 4 further comprising:\\nidentifying a language used in the audio portion of the multimodal file, and wherein performing a speech to text process comprises performing a speech to text process in the identified language.\\n6. The method of claim 4 further comprising:\\ntranslating the detected text.\\n7. The method of claim 1 further comprising:\\ndetermining significant clusters and insignificant clusters in the determined clusters, and\\nwherein extracting features from the clusters in the graph comprises extracting features from the significant clusters in the graph.\\n8. The method of claim 1 wherein extracting features from the clusters in the graph comprises at least one process selected from the list consisting of:\\ndetermining a graph diameter and determining a Jaccard coefficient.\\n9. The method of claim 1 wherein selecting at least one TopicID to represent at least one cluster comprises:\\nbased at least on the extracted features, mapping topic candidates into a probability interval; and\\nbased at least on the mapping, ranking topic candidates within the at least one cluster, and\\nselecting the at least one TopicID based at least on the ranking.\\n10. The method of claim 1 further comprising:\\ntranslating the at least one TopicID, and\\nwherein indexing the multimodal file with the at least one TopicID comprises indexing the multimodal file with the at least one translated TopicID.\\n11. A system for inferring topics from a multimodal file, the system comprising: an entity extraction component comprising an object detection component and a speech to text component, operative to extract a set of entities from a multimodal file comprising a video portion and an audio portion;\\nan entity linking component operative to link the extracted set of entities to produce a set of linked entities;\\nan information retrieval component operative to obtain reference information for the extracted set of entities;\\na graphing and analysis component operative to:\\ngenerate a graph of the set of linked entities, the graph comprising nodes and edges;\\nbased at least on the nodes and edges of the graph, determine clusters in the graph;\\nbased at least on the clusters in the graph, identify topic candidates; and extract features from the clusters in the graph;\\na TopicID selection component operative to:\\nrank the topic candidates within at least one cluster; and\\nbased at least on the ranking, select at least one TopicID from among the topic candidates to represent at least one cluster; and a video indexer operative to index the multimodal file with the at least one TopicID.\\n12. The system of claim 11 wherein the object detection component is operative to perform face recognition.\\n13. The system of claim 11 wherein the speech to text component is operative to extract entity information in at least two different languages.\\n14. One or more computer storage devices having computer-executable instructions stored thereon for inferring topics from a multimodal file, which, on execution by a computer, cause the computer to perform operations comprising:\\nreceiving a multimodal file comprising a video portion and an audio portion; extracting a set of entities from the multimodal file, wherein extracting a set of entities from the multimodal file comprises:\\ndetecting objects in the video portion of the multimodal file with face recognition;\\ndetecting text in the audio portion of the multimodal file with a speech to text process; and\\ndisambiguating among a set of detected entity names;\\nlinking the set of entities to produce a set of linked entities;\\nobtaining reference information for the set of entities;\\nbased at least on the reference information, generating a graph of the set of linked entities, the graph comprising nodes and edges;\\nbased at least on the nodes and edges of the graph, determining clusters in the graph;\\ndetermining significant clusters and insignificant clusters in the determined clusters;\\nbased at least on the significant clusters in the graph, identifying topic candidates; extracting features from the significant clusters in the graph;\\nbased at least on the extracted features, mapping the topic candidates into a probability interval;\\nbased at least on the mapping, ranking the topic candidates within at least one significant cluster,\\nbased on the ranking, selecting at least one TopicID from among the topic candidates to represent the at least one significant cluster; and\\nindexing the multimodal file with the at least one TopicID.\\n15. The one or more computer storage devices of claim 14 wherein the operations further comprise:\\nidentifying a language used in the audio portion of the multimodal file, and detecting text in the audio portion of the multimodal file with a speech to text process comprises performing a speech to text process in the identified language.', '权利要求\\n1、 一种人脸识别方法,其特征在于,包括:\\n通过第一摄像头获取第一人脸图像;\\n提取所述第一人脸图像的第一人脸特征;\\n将所述第一人脸特征与预先存储的第二人脸特征进行对比,获得参考相似度,所述第 二人脸特征经第二摄像头获取的第二人脸图像的特征提取而得,所述第二摄像头与所述第 一摄像头属于不同类型的摄像头;\\n根据所述参考相似度确定所述第一人脸特征与所述第二人脸特征是否对应相同人。\\n2、 根据权利要求 1所述的方法,其特征在于,\\n所述第一摄像头为热成像摄像头,所述第二摄像头为可见光摄像头;\\n或者,所述第一摄像头为可见光摄像头,所述第一摄像头为热成像摄像头。\\n3、 根据权利要求 1或 2所述的方法,其特征在于,所述根据所述参考相似度确定所 述第一人脸特征与所述第二人脸特征是否对应相同人,包括:\\n根据所述参考相似度、 参考误报率以及相似度阈值确定所述第一人脸特征与所述第二 人脸特征是否对应相同人;其中,不同的误报率对应不同的相似度阈值。\\n4、 根据权利要求 1或 2所述的方法,其特征在于,所述根据所述参考相似度确定所 述第一人脸特征与所述第二人脸特征是否对应相同人,包括:\\n根据所述参考相似度以及阈值信息确定归一化后的参考相似度;\\n根据所述归一化后的参考相似度确定所述第一人脸特征与所述第二人脸特征是否对 应相同人。\\n5、 根据权利要求 1-4任一项所述的方法,其特征在于,所述提取所述第一人脸图像的 第_人脸特征,包括:\\n将所述第一人脸图像输入预先训练完成的神经网络,通过所述神经网络输出所述第一 人脸图像的第一人脸特征;其中,所述神经网络基于第一类型图像样本和第二类型图像样 本训练得到,所述第一类型图像样本和所述第二类型图像样本由不同类型的摄像头拍摄得 到,且所述第一类型图像样本和所述第二类型图像样本中包括人脸。\\n6、 根据权利要求 5 所述的方法,其特征在于,所述神经网络基于所述第一类型图像 样本、 所述第二类型图像样本和混合类型图像样本训练得到,所述混合类型图像样本由所 述第一类型图像样本和所述第二类型图像样本配对而得。\\n1、 根据权利要求 1-6任一项所述的方法,其特征在于,所述第一摄像头包括车载摄像 头,所述通过第一摄像头获取第一人脸图像,包括:\\n通过所述车载摄像头获取所述第一人脸图像,所述第一人脸图像包括车辆的用车人的 人脸图像。\\n8、 根据权利要求 7 所述的方法,其特征在于,所述用车人包括驾驶所述车辆的人、 乘坐所述车辆的人、 对所述车辆进行修理的人、 给所述车辆加油的人以及控制所述车辆的 人中的一项或多项。\\n9、 根据权利要求 7 所述的方法,其特征在于,所述用车人包括驾驶所述车辆的人, 所述通过所述车载摄像头获取所述第一人脸图像,包括: 在接收到触发指令的情况下,通过所述车载摄像头获取所述第一人脸图像; 或者,在所述车辆运行时,通过所述车载摄像头获取所述第一人脸图像;\\n或者,在所述车辆的运行速度达到参考速度的情况下,通过所述车载摄像头获取所述 第一人脸图像。\\n10、 根据权利要求 7-9任一项所述的方法,其特征在于,所述第二人脸图像为对所述 用车人进行人脸注册的图像,所述将所述第一人脸特征与预先存储的第二人脸特征进行对 比之前,所述方法还包括:\\n通过所述第二摄像头获取所述第二人脸图像;\\n提取所述第二人脸图像的第二人脸特征;\\n保存所述第二人脸图像的第二人脸特征。\\n11、 一种神经网络训练方法,其特征在于,包括:\\n获取第一类型图像样本和第二类型图像样本,所述第一类型图像样本和所述第二类型 图像样本由不同类型的摄像头拍摄得到,且所述第一类型图像样本和所述第二类型图像样 本中包括人脸;\\n根据所述第一类型图像样本和所述第二类型图像样本训练神经网络。\\n12、 根据权利要求 11所述的方法,其特征在于,所述根据所述第一类型图像样本和所 述第二类型图像样本训练神经网络,包括:\\n将所述第一类型图像样本和所述第二类型图像样本配对,得到所述第一类型图像样本 和所述第二类型图像样本的混合类型图像样本;\\n根据所述第一类型图像样本、 所述第二类型图像样本和所述混合类型图像样本,训练 所述神经网络。\\n13、 根据权利要求 12 所述的方法,其特征在于,所述根据所述第一类型图像样本、 所述第二类型图像样本和所述混合类型图像样本,训练所述神经网络,包括:\\n通过所述神经网络获取所述第一类型图像样本的人脸预测结果、 所述第二类型图像样 本的人脸预测结果和所述混合类型图像样本的人脸预测结果;\\n根据所述第一类型图像样本的人脸预测结果和人脸标注结果的差异、 所述第二类型图 像样本的人脸预测结果和人脸标注结果之间的差异、 以及所述混合类型图像样本的人脸预 测结果和人脸标注结果的差异,训练所述神经网络。\\n14、 根据权利要求 13 所述的方法,其特征在于,所述神经网络中包括第一分类器、 第二分类器和混合分类器,所述通过所述神经网络获取所述第一类型图像样本的人脸预测 结果、 所述第二类型图像样本的人脸预测结果和所述混合类型图像样本的人脸预测结果, 包括:\\n将所述第一类型图像样本的人脸特征输入至所述第一分类器中,得到所述第一类型图 像样本的人脸预测结果;\\n将所述第二类型图像样本的人脸特征输入至所述第二分类器中,得到所述第二类型图 像样本的人脸预测结果;\\n将所述混合类型图像样本的人脸特征输入至所述混合分类器中,得到所述混合类型图 像样本的人脸预测结果。 15、 根据权利要求 14所述的方法,其特征在于,所述方法还包括:\\n在训练完成的所述神经网络中去除所述第一分类器、 所述第二分类器和所述混合分类 器,得到用于进行人脸识别的神经网络。\\n16、 一种人脸识别装置,其特征在于,包括:\\n第一获取单元,用于通过第一摄像头获取第一人脸图像;\\n第一提取单元,用于提取所述第一人脸图像的第一人脸特征;\\n对比单元,用于将所述第一人脸特征与预先存储的第二人脸特征进行对比,获得参考 相似度,所述第二人脸特征经第二摄像头获取的第二人脸图像的特征提取而得,所述第二 摄像头与所述第一摄像头属于不同类型的摄像头;\\n确定单元,用于根据所述参考相似度确定所述第一人脸特征与所述第二人脸特征是否 对应相同人。\\n17、 根据权利要求 16所述的装置,其特征在于,\\n所述第一摄像头为热成像摄像头,所述第二摄像头为可见光摄像头;\\n或者,所述第一摄像头为可见光摄像头,所述第一摄像头为热成像摄像头。\\n18、 根据权利要求 16或 17所述的装置,其特征在于,\\n所述确定单元,具体用于根据所述参考相似度、 参考误报率以及相似度阈值确定所述 第一人脸特征与所述第二人脸特征是否对应相同人;其中,不同的误报率对应不同的相似 度阈值。\\n19、 根据权利要求 16或 17所述的装置,其特征在于,\\n所述确定单元,具体用于根据所述参考相似度以及阈值信息确定归一化后的参考相似 度;以及根据所述归一化后的参考相似度确定所述第一人脸特征与所述第二人脸特征是否 对应相同人。\\n20、 根据权利要求 16-19任_项所述的装置,其特征在于,\\n所述第一提取单元,具体用于将所述第一人脸图像输入预先训练完成的神经网络,通 过所述神经网络输出所述第一人脸图像的第一人脸特征;其中,所述神经网络基于第一类 型图像样本和第二类型图像样本训练得到,所述第一类型图像样本和所述第二类型图像样 本由不同类型的摄像头拍摄得到,且所述第一类型图像样本和所述第二类型图像样本中包 括人脸。\\n21、 根据权利要求 20 所述的装置,其特征在于,所述神经网络基于所述第一类型图 像样本、 所述第二类型图像样本和混合类型图像样本训练得到,所述混合类型图像样本由 所述第一类型图像样本和所述第二类型图像样本配对而得。\\n22、 根据权利要求 16-21任一项所述的装置,其特征在于,所述第一摄像头包括车载 摄像头,\\n所述第一获取单元,具体用于通过所述车载摄像头获取所述第一人脸图像,所述第一 人脸图像包括车辆的用车人的人脸图像。\\n23、 根据权利要求 22所述的装置,其特征在于,所述用车人包括驾驶所述车辆的人、 乘坐所述车辆的人、 对所述车辆进行修理的人、 给所述车辆加油的人以及控制所述车辆的 人中的一项或多项。 24、 根据权利要求 22所述的装置,其特征在于,所述用车人包括驾驶所述车辆的人, 所述第一获取单元,具体用于在接收到触发指令的情况下,通过所述车载摄像头获取所述 第一人脸图像;\\n或者,所述第一获取单元,具体用于在所述车辆运行时,通过所述车载摄像头获取所 述第 _人脸图像;\\n或者,所述第一获取单元,具体用于在所述车辆的运行速度达到参考速度的情况下, 通过所述车载摄像头获取所述第一人脸图像。\\n25、 根据权利要求 22-24任一项所述的装置,其特征在于,所述第二人脸图像为对所 述用车人进行人脸注册的图像,所述装置还包括:\\n第二获取单元,用于通过所述第二摄像头获取所述第二人脸图像;\\n第二提取单元,用于提取所述第二人脸图像的第二人脸特征;\\n保存单元,用于保存所述第二人脸图像的第二人脸特征。\\n26、 一种神经网络训练装置,其特征在于,包括:\\n获取单元,用于获取第一类型图像样本和第二类型图像样本,所述第一类型图像样本 和所述第二类型图像样本由不同类型的摄像头拍摄得到,且所述第一类型图像样本和所述 第二类型图像样本中包括人脸;\\n训练单元,用于根据所述第一类型图像样本和所述第二类型图像样本训练神经网络。\\n27、 根据权利要求 26所述的装置,其特征在于,所述训练单元包括:\\n配对子单元,用于将所述第一类型图像样本和所述第二类型图像样本配对,得到所述 第一类型图像样本和所述第二类型图像样本的混合类型图像样本;\\n训练子单元,用于根据所述第一类型图像样本、 所述第二类型图像样本和所述混合类 型图像样本,训练所述神经网络。\\n28、 根据权利要求 27所述的装置,其特征在于,\\n所述训练子单元,具体用于通过所述神经网络获取所述第一类型图像样本的人脸预测 结果、 所述第二类型图像样本的人脸预测结果和所述混合类型图像样本的人脸预测结果; 以及根据所述第一类型图像样本的人脸预测结果和人脸标注结果的差异、 所述第二类型图 像样本的人脸预测结果和人脸标注结果之间的差异、 以及所述混合类型图像样本的人脸预 测结果和人脸标注结果的差异,训练所述神经网络。\\n29、 根据权利要求 28 所述的装置,其特征在于,所述神经网络中包括第一分类器、 第二分类器和混合分类器,\\n所述训练子单元,具体用于将所述第一类型图像样本的人脸特征输入至所述第一分类 器中,得到所述第一类型图像样本的人脸预测结果;以及将所述第二类型图像样本的人脸 特征输入至所述第二分类器中,得到所述第二类型图像样本的人脸预测结果;以及将所述 混合类型图像样本的人脸特征输入至所述混合分类器中,得到所述混合类型图像样本的人 脸预测结果。\\n30、 根据权利要求 29所述的装置,其特征在于,所述装置还包括:\\n神经网络应用单元,用于在训练完成的所述神经网络中去除所述第一分类器、 所述第 二分类器和所述混合分类器,得到用于进行人脸识别的神经网络。 31、 一种电子设备,其特征在于,包括处理器和存储器,所述处理器和所述存储器耦 合;其中,所述存储器用于存储程序指令,所述程序指令被所述处理器执行时,使所述处 理器执行权利要求 1-10任一项所述的方法;和/或,使所述处理器执行权利要求 11-15任一 项所述的方法。\\n32、 一种计算机可读存储介质,其特征在于,所述计算机可读存储介质中存储有计算 机程序,所述计算机程序包括程序指令,所述程序指令当被处理器执行时,使所述处理器 执行权利要求 1-10任一项所述的方法;和/或,使所述处理器执行权利要求 11-15任一项所 述的方法。', \"1. A system for alerting on vision impairment, said system comprising a processing unit configured and operable for receiving scene data being indicative of a scene of at least one consumer in an environment, identifying in the scene data a certain consumer, identifying an event being indicative of a behavioral compensation for vision impairment, and, upon identification of such an event, sending a notification relating to the vision impairment.\\n2. The system of claim 1, further comprising at least one sensing unit configured and operable for detecting the scene data.\\n3. The system of claim 2, wherein said at least one sensing unit comprises at least one of: at least one imaging unit configured and operable for capturing at least one image of at least a portion of a consumer's body, at least one motion detector configured and operable for detecting consumer data being indicative of a motion of a consumer, or at least one eye tracker configured and operable for tracking eye motion of a consumer. 4. The system of claim 3, wherein the at least one imaging unit comprises a plurality of cameras placed at different heights.\\n5. The system of any one of claims 2 to 4, wherein said sensing unit is accommodated in an optical or digital eyewear frame display.\\n6. The system of any one of claims 1 to 5, wherein said processing unit is configured and operable for identifying a consumer's condition, said consumer's condition comprising consumer data being indicative of the consumer's position and location relative to at least one object in the consumer's environment; said consumer data comprises at least one of a consumer's face, eyewear, posture, position, sound or motion.\\n7. The system of any one of claims 1 to 6, wherein said event comprises at least one position and orientation of head increase or decrease of viewing distance between the consumer and viewed object and changing the position of eyeglasses worn by the consumer.\\n8. The system of any one of claims 1 to 7, wherein said event is identified by identifying images having an image feature being indicative of behavioral compensation, performing a Bruckner test, performing a Hirschberg test, and measuring blink count/ frequency.\\n9. The system of claim 8, wherein the image feature being indicative of behavioral compensation comprises squinting, head orientation, certain distances between an object and consumer's eyes, certain position of eyeglasses on the consumer's face, strabismus, cataracts, and reflections from the eye.\\n10. The system of any one of claims 1 to 9, wherein the notification includes at least one of the data indicative of the identified event, data indicative of the identified consumer, ophthalmologic recommendations based on the identified event, or lack of events, or an appointment for a vision test.\\n11. The system of any one of claims 1 to 10, wherein said processing unit comprises a memory for storing at least one of a reference data indicative of behavioral compensation for vision impairment, data indicative of the notification, or data indicative of a follow-up of the notification.\\n12. The system of claim 11 , wherein said processing unit is configured for at least one of identifying the event upon comparison between the detected data and the reference data or determining a probability for a vision impairment of the consumer based on the comparison.\\n13. The system of any one of claims 1 to 12, wherein said processing unit comprises a communication interface being configured for sending the notification to at least one of the identified consumer or a third party.\\n14. The system of any one of claims 1 to 13, wherein said processing unit is configured for providing a frame recommendation.\\n15. The system of any one of claims 11 to 14, wherein said memory is configured for storing a database including a multiplicity of data sets related to a plurality of spectacle frame models and sizes.\\n16. The system according to claim 14 or 15, wherein said processing unit is configured and operable to correlate between frames parameters and ophthalmic prescriptions.\\n17. The system according to any of claims 14 to 16, wherein said processing unit is configured and operable to correlate between frames parameters and facial features.\\n18. The system according to any of claims 14 to 17, wherein said processing unit is configured and operable to correlate between frames parameters and eyewear preferences.\\n19. The system according to any of claims 14 to 18, comprising a server and at least one computer entity linked to the server via a network, wherein said network is configured to receive and respond to requests sent across the network; transmitting one or more modules of computer executable program instructions and displayable data to the network connected user computer platform in response to a request, wherein said modules include modules configured to: receive and transmit image information, transmitting a frame recommendation and an optical lens option recommendation based on received image information, for display by the network connected user computer platform.\\n20. A computer program instructions stored in the local storage that, when executed by a processing unit, cause the processing unit to: receive data being indicative of a scene of at least one consumer in an environment, identify in the data a certain consumer, identify an event being indicative of a behavioral compensation for vision impairment, and, upon identification of such an event, send a notification relating to the vision impairment.\\n21. A computer program product stored on a tangible computer readable medium, comprising: a library of software modules which cause a computer executing them to prompt for information pertinent to at least one of an eyeglasses recommendation and an optical lens option recommendation, to store said information or to display eyewear recommendations .\\n22. The computer program product of claim 21 , wherein said library further comprises a module for frame selection, point of sales and advertising.\\n23. A computer platform for facilitating eye glasses marketing or selection, comprising: a camera; a processor configured to execute computer program instructions to cause the processor to take an image of a consumer, identify in the image a certain consumer, identify an event being indicative of a behavioral compensation for vision impairment, and, upon identification of such an event, sending a notification relating to the vision impairment; local storage for processor executable instructions for carrying out storage of information.\\n24. A method for alerting on vision impairment; said method comprising:\\nidentifying a certain individual in scene data being indicative of a scene of at least one consumer in an environment;\\nidentifying an event being indicative of a behavioral compensation for vision impairment; and\\nupon identification of such an event, sending a notification on the vision impairment. 25. The method of claim 24, further comprising detecting data being indicative of a scene of at least one consumer in a retail environment.\\n26. The method of claim 24, wherein detecting the data being indicative of at least one consumer comprises at least one of capturing at least one image of at least one consumer, detecting data being indicative of a motion of a consumer, or tracking an eye motion of a consumer.\\n27. The method of claim 26, wherein capturing at least one image of at least one consumer comprises continuously recording a scene.\\n28. The method of any one of claims 24 to 27, further comprising identifying, in the data, the consumer' s condition including data being indicative of the consumer's position and location relative to the consumer's environment; said data comprising at least one of the consumer's face, posture, position, sound or motion.\\n29. The method of any one of claims 26 to 28, wherein said event comprises at least one of position and orientation of head, increase or decrease of viewing distance between the consumer and viewed object, or changing the position of eyeglasses worn by the consumer.\\n30. The method of any one of claims 26 to 29, wherein identifying of the event comprises identifying images having an image feature being indicative of behavioral compensation, performing a Bruckner test, performing a Hirschberg test, and measuring blink count/frequency.\\n31. The method of claim 30, wherein the image feature being indicative of behavioral compensation comprises squinting, head orientation, certain distances between an object and a consumer's eyes, certain position of eyeglasses on the consumer's face, strabismus, cataracts, and reflections from the eye.\\n32. The method of any one of claims 27 to 31, wherein identifying in the at least one image a consumer in a retail environment, comprising at least one of receiving data characterizing the retail environment, or performing face recognition.\\n33. The method of any one of claims 24 to 32, wherein sending a notification comprising sending the notification to at least one of the identified consumer or a third party.\\n34. The method of any one of claims 24 to 33, wherein the notification includes at least one of the data indicative of the identified event, data indicative of the identified consumer, ophthalmologic recommendations based on the identified event, or lack of events, and an appointment for a vision test.\\n35. The method of any one of claims 24 to 34, further comprising storing at least one of a reference data indicative of behavioral compensation for vision impairment, data indicative of the notification, or data indicative of a follow-up of the notification.\\n36. The method of claim 35, further comprising identifying the event upon comparison between the detected data and the reference data and determining a probability for a vision impairment of the consumer, based on the comparison.\\n37. A computer program intended to be stored in a memory of a processor unit of a computer system, or in a removable memory medium adapted to cooperate with a reader of the processor unit, comprising instructions for implementing the method according to any of claims 24 to 36.\"]\n",
      "TEXT OBTAINED!\n"
     ]
    }
   ],
   "source": [
    "p1 = \"\"\n",
    "p2 = \"\"\n",
    "p1=re.findall(r'(?<=<abstract>\\n)(?s:.*?)(?=\\n</abstract>)',text)\n",
    "p2=re.findall(r'(?<=<claims>\\n)(?s:.+?)(?=\\n</claims>)',text)\n",
    "print(p1)\n",
    "print(p2)\n",
    "print(\"TEXT OBTAINED!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b90597",
   "metadata": {},
   "source": [
    "### Text cleaining\n",
    "First we lower the text for both sections, then we do the whitespace and punctuation removal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c9d89701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. an electronic device (10), configured to make a screen (110) to display a plurality of image frames, comprising: an image capturing device (120); a storage device (130), storing a plurality of modules; and a processor (14), coupled to the image capturing device (140) and the storage device (130), configured to execute the modules in the storage device (130) to: configure the screen (110) to display a plurality of marker objects at a plurality of predetermined calibration positions; configure the image capturing device (120) to capture a plurality of first head images when a user is looking at the predetermined calibration positions; (s301) perform a plurality of first face recognition operations on the first head images to obtain a plurality of first face regions corresponding to the predetermined calibration positions; (s302) detect a plurality of first facial landmarks corresponding to the first face regions; (s303) calculate a plurality of rotation reference angles of the user looking at the predetermined calibration positions according to the first facial landmarks; configure the image capturing device (120) to capture a second head image of the user; perform a second face recognition operation on the second head image to obtain a second face region; detect a plurality of second facial landmarks within the second face region; (s304) estimate a head posture angle of the user according to the second facial landmarks; calculate a gaze position of the user on the screen (110) according to the head posture angle, the rotation reference angles, and the predetermined calibration positions; and configure the screen (110) to display a corresponding visual effect according to the gaze position.\\n2. the electronic device (10) according to claim 1, wherein the gaze position comprises a first coordinate value in a first axial direction and a second coordinate value in a second axial direction.\\n3. the electronic device (10) according to claim 2, wherein the head posture angles comprise a head pitch angle and a head yaw angle, and the rotation reference angles comprise a first pitch angle, a second pitch angle, a first yaw angle, and a second yaw angle corresponding to the predetermined calibration positions.\\n4. the electronic device (10) according to claim 3, wherein the processor (140) performs interpolation operation or extrapolation operation according to the first yaw angle, the second yaw angle, a first position corresponding to the first yaw angle among the predetermined calibration positions, a second position corresponding to the second yaw angle among the predetermined calibration positions and the head yaw angle, thereby obtaining the first coordinate value of the gaze position; and\\nthe processor (140) performs interpolation operation or extrapolation operation according to the first pitch angle, the second pitch angle, a third position corresponding to the first pitch angle among the predetermined calibration positions, a fourth position corresponding to the second pitch angle among the predetermined calibration positions and the head pitch angle, thereby obtaining the second coordinate value of the gaze position.\\n5. the electronic device (10) according to claim 1, wherein the processor (140) calculates a plurality of first viewing distances between the user and the screen (110) according to the first facial landmarks;\\nthe processor (140) estimates a second viewing distance between the user and the screen (110) according to the second facial landmarks; and\\nthe processor (140) adjusts the rotation reference angles or the gaze position according to the second viewing distance and the first viewing distances.\\n6. the electronic device (10) according to claim 1, wherein the processor (140) maps a plurality of two-dimensional position coordinates of the second facial landmarks under a plane coordinate system to a plurality of three-dimensional position coordinates under a three-dimensional coordinate system; and\\nthe processor (140) estimates the head posture angle according to the three-dimensional position coordinates of the second facial landmarks.\\n7. the electronic device (10) according to claim 1, wherein the second head image comprises a wearable device, and the second facial landmarks do not comprise a plurality of third facial landmarks of the user covered by the wearable device.\\n8. the electronic device (10) according to claim 1, wherein the second head image comprises a wearable device, and the second facial landmarks comprise one or more simulated landmarks marked by the wearable device.\\n9. an operating method, adapted for an electronic device (10) comprising an image capturing device (120) and making a screen (110) to display a plurality of image frames, the method comprising: configuring the screen (110) to display a plurality of marker objects at a plurality of predetermined calibration positions; configuring the image capturing device (120) to capture a plurality of first head images when a user is looking at the predetermined calibration positions; (s301) performing a plurality of first face recognition operations on the first head images to obtain a plurality of first face regions corresponding to the predetermined calibration positions; (s302) detecting a plurality of first facial landmarks corresponding to the first face regions; (s303) calculating a plurality of rotation reference angles of the user looking at the predetermined calibration positions according to the first facial landmarks; configuring the image capturing device (120) to capture a second head image of the user; performing a second face recognition operation on the second head image to obtain a second face region; (s304) detecting a plurality of second facial landmarks within the second face region; estimating a head posture angle of the user according to the second facial landmarks; calculating a gaze position of the user on the screen (110) according to the head posture angle, the rotation reference angles, and the predetermined calibration positions; and (s305) configuring the screen (110) to display a corresponding visual effect according to the gaze position.\\n10. the operation method according to claim 9, wherein the gaze position comprises a first coordinate value in a first axial direction and a second coordinate value in a second axial direction.\\n11. the operation method according to claim 10, wherein the head posture angles comprise a head pitch angle and a head yaw angle, and the rotation reference angles comprise a first pitch angle, a second pitch angle, a first yaw angle, and a second yaw angle corresponding to the predetermined calibration positions.\\n12. the operation method according to claim 11, wherein the step of calculating the gaze position of the user on the screen (110) according to the head posture angle, the rotation reference angles and the predetermined calibration positions comprises: performing interpolation operation or extrapolation operation according to the first yaw angle, the second yaw angle, a first position corresponding to the first yaw angle among the predetermined calibration positions, a second position corresponding to the second yaw angle among the predetermined calibration positions and the head yaw angle, thereby obtaining the first coordinate value of the gaze position; and performing interpolation operation or extrapolation operation according to the first pitch angle, the second pitch angle, a third position corresponding to the first pitch angle among the predetermined calibration positions, a fourth position corresponding to the second pitch angle among the predetermined calibration positions and the head pitch angle, thereby obtaining the second coordinate value of the gaze position.\\n13. the operation method according to claim 9, wherein the method further comprises: calculating a plurality of first viewing distances between the user and the screen (110) according to the first facial landmarks; estimating a second viewing distance between the user and the screen (110) according to the second facial landmarks; and adjusting the rotation reference angles or the gaze position according to the second viewing distance and the first viewing distances.\\n14. the operation method according to claim 9, wherein the method further comprises: mapping a plurality of two-dimensional position coordinates of the second facial landmarks under a plane coordinate system to a plurality of three-dimensional position coordinates under a three-dimensional coordinate system; and estimating the head posture angle according to the three-dimensional position coordinates of the second facial landmarks.\\n15. the operation method according to claim 9, wherein the second head image comprises a wearable device, and the second facial landmarks do not comprise a plurality of third facial landmarks of the user covered by the wearable device.\\n16. the operation method according to claim 9, wherein the second head image comprises a wearable device, and the second facial landmarks comprise one or more simulated landmarks marked by the wearable device.1. a computation method applied to a computing system, wherein the computing system comprises: a control unit, a computation group, and a general storage unit, wherein the control unit comprises: a first memory, a decoding logic, and a controller, wherein the computation group comprises: a group controller and a plurality of computing units; the general storage unit is configured to store data; and the computation method comprises: receiving, by the controller, a first level instruction sequence, and partitioning, by the decoding logic, the first level instruction sequence into a plurality of second level instruction sequences, creating, by the controller, m threads for the plurality of second level instruction sequences, and allocating, by the controller, an independent register as well as configuring an independent addressing function for each thread of the m threads, wherein m is an integer greater than or equal to 1; and obtaining, by the group controller, a plurality of computation types of the plurality of second level instruction sequences, obtaining a corresponding fusion computation manner of the computation types according to the plurality of computation types, and adopting, by the plurality of computing units, the fusion computation manner to call the m threads for performing computations on the plurality of second level instruction sequences to obtain a final result.\\n2. the method of claim 1, wherein, the obtaining, by the group controller, a plurality of computation types of the plurality of second level instruction sequences, obtaining a corresponding fusion computation manner of the computation types according to the plurality of computation types, and adopting, by the plurality of computing units, the fusion computation manner to call the m threads for performing computations on the plurality of second instruction sequences to obtain a final result:\\nif the computation types represent computation operations of the same type, the group controller calls a combined computation manner in which single instruction multiple data of the same type is in combination with single instruction multiple threads, and uses the m threads to perform the combined computation manner to obtain a final result, which includes:\\npartitioning, by the decoding logic, the m threads into n wraps for allocating to the the plurality of computing units, converting, by the group controller, the plurality of second instruction sequences into a plurality of second control signals and sending the second control signals to the plurality of computing units, calling, by the plurality of computing units, wraps that are allocated to the computing units and the second control signals to fetch corresponding data according to the independent addressing function, performing, by the plurality of computing units, computations on the data to obtain a plurality of intermediate results, and splicing the plurality of intermediate results to obtain a final result.\\n3. the method of claim 1, wherein, the obtaining, by the group controller, a plurality of computation types of the plurality of second level instruction sequences, obtaining a corresponding fusion computation manner of the computation types according to the plurality of computation types, and adopting, by the plurality of computing units, the fusion computation manner to call the m threads for performing computations on the plurality of second instruction sequences to obtain a final result:\\nif the computation types represent computation operations of different types, the group controller calls simultaneous multi-threading and the m threads to perform computations to obtain a final result, which includes:\\npartitioning, by the decoding logic, the m threads into n wraps, converting the plurality of second instruction sequences into a plurality of second control signals, obtaining, by the group controller, computation types supported by the plurality of computing units, allocating, by the controller, the n wraps and the plurality of second control signals to corresponding computing units that support computation types of the wraps and the second control signals, calling, by the plurality of computing units, wraps that are allocated to the computing units and the second control signals, fetching, by the plurality of computing units, corresponding data, performing, by the plurality of computing units, computations on the data to obtain a plurality of intermediate results, and splicing all the intermediate results to obtain a final result.\\n4. the method of claim 2 or 3, further comprising:\\nif a wrap a in the plurality of wraps is blocked, adding the wrap a to a waiting queue, and if data of the wrap a are already fetched, adding the wrap a to a preparation queue, wherein the preparation queue is a queue where a wrap to be scheduled for executing is located when a computing resource is idle.\\n5. the method of claim 1, wherein\\nthe first level instruction sequence includes a very long instruction, and the second level instruction sequence includes an instruction sequence.\\n6. the method of claim 1, wherein the computing system further includes: a tree module, wherein the tree module includes: a root port and a plurality of branch ports, wherein the root port of the tree module is connected to the group controller, and the plurality of branch ports of the tree module are connected to a computing unit of the plurality of computing units respectively; and\\nthe tree module is configured to forward data blocks, wraps, or instruction sequences between the group controller and the plurality of computing units.\\n7. the method of claim 6, wherein the tree module is an n-ary tree, wherein n is an integer greater than or equal to 2.\\n8. the method of claim 1, wherein the computing system further includes a branch processing circuit,\\nwherein the branch processing circuit is connected between the group controller and the plurality of computing units; and\\nthe branch processing circuit is configured to forward data, wraps, or instruction sequences between the group controller and the plurality of computing units.\\n9. a computing system, comprising: a control unit, a computation group, and a general storage unit, wherein the control unit includes: a first memory, a decoding logic, and a controller, the computation group includes: a group controller and a plurality of computing units; the general storage unit is configured to store data;\\nthe controller is configured to receive a first level instruction sequence and control the first memory and the decoding logic;\\nthe decoding logic is configured to partition the first level instruction sequence into a plurality of second level instruction sequences;\\nthe the controller is further configured to create m threads for the plurality of second level instruction sequences, and allocate an independent register and configure an independent addressing function for each thread of the m threads; m is an integer greater than or equal to 1; and the controller is further configured to convert the plurality of second instruction sequences into a plurality of control signals for sending to the group controller;\\nthe group controller is configured to receive the plurality of control signals, obtain a plurality of computational types if the plurality of control signals, divide the m threads into n wraps, and allocate the n wraps and the plurality of control signals to the plurality of computing units according to the plurality of computational types;\\nthe plurality of computing units are configured to fetch data from the general storage unit through allocated wraps and control signals, and perform computations to obtain an intermediate result; and\\nthe group controller is configured to splice all intermediate results to obtain a final computation result.\\n10. the computing system of claim 9, wherein\\nthe plurality of computing units includes: an addition computing unit, a multiplication computing unit, an activation computing unit, or a dedicated computing unit.\\n11. the computing system of claim 9, wherein\\nthe dedicated computing unit includes: a face recognition computing unit, a graphics computing unit, a fingerprint computing unit, or a neural network computing unit.\\n12. the computing system of claim 11, wherein\\nthe group controller is configured to, if computation types of a plurality of control signals are graphics computations, fingerprint identification, face recognition, or neural network operations, allocate the plurality of control signals to the face recognition computing unit, the graphics computing unit, the fingerprint computing unit, or the neural network computing unit respectively.\\n13. the computing system of claim 9, wherein\\nthe first level instruction sequence includes a very long instruction, and the second level instruction sequence includes an instruction sequence.\\n14. the computing system of claim 9, further comprising a tree module, wherein the tree module includes: a root port and a plurality of branch ports, wherein the root port of the tree module is connected to the group controller, and the plurality of branch ports of the tree module are connected to a computing unit of the plurality of computing units respectively; and\\nthe tree module is configured to forward data blocks, wraps, or instruction sequences between the group controller and the plurality of computing units.\\n15. the computing system of claim 14, wherein the tree module is an n-ary tree, wherein n is an integer greater than or equal to 2.\\n16. the computing system of claim 9, wherein the computing system includes a branch processing circuit,\\nthe branch processing circuit is connected between the group controller and the plurality of computing units; and\\nthe branch processing circuit is configured to forward data, wraps, or instruction sequences between the group controller and the plurality of computing units.\\n17. a computer program product, comprising a non-instant computer readable storage medium, wherein a computer program is stored in the non-instant computer readable storage medium, and the computer program is capable of causing a computer to perform the method of any of claims 1-8 through operations.1. a method for detecting body information on one or more passengers of a vehicle based on humans\\' status recognition, comprising steps of: (a) if at least one interior image of an interior of the vehicle is acquired, a passenger body information-detecting device performing (i) a process of inputting the interior image into a face recognition network, to thereby allow the face recognition network to detect each of faces of each of the passengers from the interior image, and thus to output multiple pieces of passenger feature information corresponding to each of the detected faces, and (ii) a process of inputting the interior image into a body recognition network, to thereby allow the body recognition network to detect each of bodies of each of the passengers from the interior image, and thus to output body-part length information of each of the detected bodies; and (b) the passenger body information-detecting device performing a process of retrieving specific height mapping information corresponding to specific passenger feature information on a specific passenger from a height mapping table which stores height mapping information representing respective one or more predetermined ratios of one or more segment body portions of each of human groups to each of heights per each of the human groups, a process of acquiring a specific height of the specific passenger from the specific height mapping information by referring to specific body-part length information of the specific passenger, a process of retrieving specific weight mapping information corresponding to the specific passenger feature information from a weight mapping table which stores multiple pieces of weight mapping information representing predetermined correlations between each of the heights and each of weights per each of the human groups, and a process of acquiring a weight of the specific passenger from the specific weight mapping information by referring to the specific height of the specific passenger.\\n2. the method of claim 1, wherein, at the step of (a), the passenger body information-detecting device performs a process of inputting the interior image into the body recognition network, to thereby allow the body recognition network to (i) output one or more feature tensors with one or more channels corresponding to the interior image via a feature extraction network, (ii) generate at least one keypoint heatmap and at least one part affinity field with one or more channels corresponding to each of the feature tensors via a keypoint heatmap & part affinity field extractor, and (iii) extract keypoints from the keypoint heatmap via a keypoint detector, to group the extracted keypoints by referring to the part affinity field, and thus to generate body parts per the passengers, and as a result, allow the body recognition network to output multiple pieces of body-part length information on each of the passengers by referring to the body parts per the passengers.\\n3. the method of claim 2, wherein the feature extraction network includes at least one convolutional layer and applies at least one convolution operation to the interior image, to thereby output the feature tensors.\\n4. the method of claim 2, wherein the keypoint heatmap & part affinity field extractor includes one of a fully convolutional network and a 1×1 convolutional layer, and applies a fully-convolution operation or 1×1 convolution operation to the feature tensors, to thereby generate the keypoint heatmap and the part affinity field.\\n5. the method of claim 2, wherein the keypoint detector connects, by referring to the part affinity field, pairs respectively having highest mutual connection probabilities of being connected among the extracted keypoints, to thereby group the extracted keypoints.\\n6. the method of claim 2, wherein the feature extraction network and the keypoint heatmap & part affinity field extractor have been learned by a learning device performing (i) a process of inputting at least one training image including one or more objects for training into the feature extraction network, to thereby allow the feature extraction network to generate one or more feature tensors for training having one or more channels by applying at least one convolutional operation to the training image, (ii) a process of inputting the feature tensors for training into the keypoint heatmap & part affinity field extractor, to thereby allow the keypoint heatmap & part affinity field extractor to generate one or more keypoint heatmaps for training and one or more part affinity fields for training having one or more channels for each of the feature tensors for training, (iii) a process of inputting the keypoint heatmaps for training and the part affinity fields for training into the keypoint detector, to thereby allow the keypoint detector to extract keypoints for training from each of the keypoint heatmaps for training and a process of grouping the extracted keypoints for training by referring to each of the part affinity fields for training, to thereby detect keypoints per each of the objects for training, and (iv) a process of allowing a loss layer to calculate one or more losses by referring to the keypoints per each of the objects for training and their corresponding ground truths, to thereby adjust one or more parameters of the feature extraction network and the keypoint heatmap & part affinity field extractor such that the losses are minimized by backpropagation using the losses.\\n7. the method of claim 1, wherein, at the step of (a), the passenger body information-detecting device performs a process of inputting the interior image into the face recognition network, to thereby allow the face recognition network to detect each of the faces of each of the passengers located in the interior image via a face detector, and to output multiple pieces of the passenger feature information on each of the facial images via a facial feature classifier.\\n8. the method of claim 1, wherein, at the step of (a), the passenger body information-detecting device performs a process of inputting the interior image into the face recognition network, to thereby allow the face recognition network to (i) apply at least one convolution operation to the interior image and thus to output at least one feature map corresponding to the interior image via at least one convolutional layer, (ii) output one or more proposal boxes, where the passengers are estimated as located, on the feature map, via a region proposal network, (iii) apply pooling operation to one or more regions, corresponding to the proposal boxes, on the feature map and thus to output at least one feature vector via a pooling layer, and (iv) apply fully-connected operation to the feature vector, and thus to output the multiple pieces of the passenger feature information corresponding to each of the faces of each of the passengers corresponding to each of the proposal boxes via a fully connected layer.\\n9. the method of claim 1, wherein the multiple pieces of the passenger feature information include each of ages, each of genders and each of races corresponding to each of the passengers.\\n10. a passenger body information-detecting device for detecting body information on one or more passengers of a vehicle based on humans\\' status recognition, comprising: at least one memory that stores instructions; and at least one processor configured to execute the instructions to perform or support another device to perform: (i) if at least one interior image of an interior of the vehicle is acquired, (i) a process of inputting the interior image into a face recognition network, to thereby allow the face recognition network to detect each of faces of each of the passengers from the interior image, and thus to output multiple pieces of passenger feature information corresponding to each of the detected faces, and (ii) a process of inputting the interior image into a body recognition network, to thereby allow the body recognition network to detect each of bodies of each of the passengers from the interior image, and thus to output body-part length information of each of the detected bodies, and (ii) a process of retrieving specific height mapping information corresponding to specific passenger feature information on a specific passenger from a height mapping table which stores height mapping information representing respective one or more predetermined ratios of one or more segment body portions of each of human groups to each of heights per each of the human groups, a process of acquiring a specific height of the specific passenger from the specific height mapping information by referring to specific body-part length information of the specific passenger, a process of retrieving specific weight mapping information corresponding to the specific passenger feature information from a weight mapping table which stores multiple pieces of weight mapping information representing predetermined correlations between each of the heights and each of weights per each of the human groups, and a process of acquiring a weight of the specific passenger from the specific weight mapping information by referring to the specific height of the specific passenger.\\n11. the passenger body information-detecting device of claim 10, wherein, at the process of (i), the processor performs a process of inputting the interior image into the body recognition network, to thereby allow the body recognition network to (i) output one or more feature tensors with one or more channels corresponding to the interior image via a feature extraction network, (ii) generate at least one keypoint heatmap and at least one part affinity field with one or more channels corresponding to each of the feature tensors via a keypoint heatmap & part affinity field extractor, and (iii) extract keypoints from the keypoint heatmap via a keypoint detector, to group the extracted keypoints by referring to the part affinity field, and thus to generate body parts per the passengers, and as a result, allow the body recognition network to output multiple pieces of body-part length information on each of the passengers by referring to the body parts per the passengers.\\n12. the passenger body information-detecting device of claim 11, wherein the keypoint heatmap & part affinity field extractor includes one of a fully convolutional network and a 1×1 convolutional layer, and applies a fully-convolution operation or 1×1 convolution operation to the feature tensors, to thereby generate the keypoint heatmap and the part affinity field.\\n13. the passenger body information-detecting device of claim 11, wherein the keypoint detector connects, by referring to the part affinity field, pairs respectively having highest mutual connection probabilities of being connected among the extracted keypoints, to thereby group the extracted keypoints.\\n14. the passenger body information-detecting device of claim 11, wherein the feature extraction network and the keypoint heatmap & part affinity field extractor have been learned by a learning device performing (i) a process of inputting at least one training image including one or more objects for training into the feature extraction network, to thereby allow the feature extraction network to generate one or more feature tensors for training having one or more channels by applying at least one convolutional operation to the training image, (ii) a process of inputting the feature tensors for training into the keypoint heatmap & part affinity field extractor, to thereby allow the keypoint heatmap & part affinity field extractor to generate one or more keypoint heatmaps for training and one or more part affinity fields for training having one or more channels for each of the feature tensors for training, (iii) a process of inputting the keypoint heatmaps for training and the part affinity fields for training into the keypoint detector, to thereby allow the keypoint detector to extract keypoints for training from each of the keypoint heatmaps for training and a process of grouping the extracted keypoints for training by referring to each of the part affinity fields for training, to thereby detect keypoints per each of the objects for training, and (iv) a process of allowing a loss layer to calculate one or more losses by referring to the keypoints per each of the objects for training and their corresponding ground truths, to thereby adjust one or more parameters of the feature extraction network and the keypoint heatmap & part affinity field extractor such that the losses are minimized by backpropagation using the losses.\\n15. the passenger body information-detecting device of claim 10, wherein, at the process of (i), the processor performs a process of inputting the interior image into the face recognition network, to thereby allow the face recognition network to (i) apply at least one convolution operation to the interior image and thus to output at least one feature map corresponding to the interior image via at least one convolutional layer, (ii) output one or more proposal boxes, where the passengers are estimated as located, on the feature map, via a region proposal network, (iii) apply pooling operation to one or more regions, corresponding to the proposal boxes, on the feature map and thus to output at least one feature vector via a pooling layer, and (iv) apply fully-connected operation to the feature vector, and thus to output the multiple pieces of the passenger feature information corresponding to each of the faces of each of the passengers corresponding to each of the proposal boxes via a fully connected layer.1. a computer implemented method for performing video coding based on face detection comprising: receiving a video frame comprising one of a plurality of video frames of a video sequence; determining the video frame is a key frame of the video sequence; performing, in response to the video frame being a key frame of the video sequence, a multi-stage facial search of the video frame based on predetermined feature templates and a predetermined number of stages to determine a first candidate face region and a second candidate face region in the video frame; testing the first and second candidate face regions based on skin tone information to determine the first candidate face region is a valid face region and the second candidate face region is an invalid face region; rejecting the second candidate face region and outputting the first candidate face region; and encoding the video frame based at least in part on the first candidate face region being a valid face region to generate a coded bitstream.\\n2. the method of claim 1, wherein the skin tone information comprises a skin probability map.\\n3. the method of claim 1, wherein said testing the first and second candidate face regions based on skin tone information is performed in response to the video frame being a key frame of the video sequence.\\n4. the method of claim 1, wherein the first candidate face region comprises a rectangular region, the method further comprising: determining a free form shape face region corresponding to the first candidate face region, wherein the free form shape face region has at least one of a pixel accuracy or a small block of pixels accuracy.\\n5. the method of claim 4, wherein determining the free form shape face region comprises: generating an enhanced skip probability map corresponding to the first candidate face region; binarizing the enhanced skip probability map; and overlaying the binarized enhanced skip probability map over at least a portion of the video frame to provide the free form shape face region.\\n6. the method of claim 4, wherein a second video frame comprises a non-key frame of the video sequence, the method further comprising performing face detection in the second video frame of the video sequence based on the free form shape face region.\\n7. the method of claim 6, further comprising: tracking a second free form shape face region in the second video frame based on the free form shape face region in the video frame.\\n8. the method of claim 7, wherein tracking the second free form shape face region comprises determining a location of a second valid face region in the second video frame based on a displacement offset with respect to the first candidate face region.\\n9. the method of claim 8, further comprising: determining the displacement offset based on an offset between a centroid of a bounding box around a skin enhanced region corresponding to the first candidate face region and a second centroid of a second bounding box around a second skin enhanced region in the second video frame.\\n10. the method of claim 1, wherein encoding the video frame based at least in part on the first candidate face region being a valid face region comprises at least one of reducing a quantization parameter corresponding to the first candidate face region, adjusting a lambda value for the first candidate face region, or disabling skip coding for the first candidate face region.\\n11. the method of claim 1, wherein the bitstream comprises at least one of an h.264/advanced video coding (avc) compliant bitstream, an h.265/high efficiency video coding (hevc) compliant bitstream, a vp9 compliant bitstream, a vp10 compliant bitstream, or an alliance for open media (aom) av1 compliant bitstream.\\n12. a computer implemented method for performing face detection comprising: receiving a video frame of a sequence of video frames; performing a multi-stage facial search of the video frame based on predetermined feature templates and a predetermined number of stages to determine a first candidate face region and a second candidate face region in the video frame; testing the first and second candidate face regions based on skin tone information to determine the first candidate face region is a valid face region and the second candidate face region is an invalid face region; rejecting the second candidate face region and outputting the first candidate face region as a valid face region for further processing; and providing an index indicative of a person being present in the video frame based on the valid face region.\\n13. the method of claim 12, wherein the sequence of video frames comprises a sequence of surveillance video frames, the method further comprising: performing face recognition in the surveillance video frames based on the valid face region.\\n14. the method of claim 12, wherein the sequence of video frames comprises a sequence of decoded video frames, the method further comprising: adding a marker corresponding to the received video frame to perform face recognition on the received video frame based on the valid face region.\\n15. the method of claim 12, wherein the sequence of video frames is received during a device login attempt, the method further comprising: performing face recognition based on the valid face region; and allowing access to the device if a secured face is recognized.\\n16. the method of claim 12, wherein the sequence of video frames comprises a sequence of videoconferencing frames, the method further comprising: encoding the video frame based at least in part on the valid face region to generate a coded bitstream.\\n17. the method of claim 16, wherein encoding the video frame comprises not encoding a background region of the video frame into the bitstream.\\n18. the method of claim 12, further comprising: encoding the video frame based at least in part on the valid face region to generate a coded bitstream, wherein encoding the video frame comprises including metadata corresponding to the valid face region in the bitstream.\\n19. the method of claim 18, further comprising: decoding the coded bitstream to generate a decoded video frame and to determine the metadata corresponding to the valid face region in the bitstream.\\n20. the method of claim 19, further comprising at least one of replacing the valid face region based on the decoded metadata, cropping and displaying image data corresponding only to the valid face region based on the decoded metadata, or indexing the decoded video frame based on the decoded metadata.\\n21. a system for performing video coding based on face detection comprising: a memory configured to store a video frame comprising one of a plurality of video frames of a video sequence; and a processor coupled to the memory, the processor to receive the video frame, to determine the video frame is a key frame of the video sequence; to perform, in response to the video frame being a key frame of the video sequence, a multi-stage facial search of the video frame based on predetermined feature templates and a predetermined number of stages to determine a first candidate face region and a second candidate face region in the video frame, to test the first and second candidate face regions based on skin tone information to determine the first candidate face region is a valid face region and the second candidate face region is an invalid face region, to reject the second candidate face region and outputting the first candidate face region, and to encode the video frame based at least in part on the first candidate face region being a valid face region to generate a coded bitstream.\\n22. the system of claim 21, wherein the skin tone information comprises a skin probability map.\\n23. the system of claim 21, wherein the first candidate face region comprises a rectangular region, the processor further to determine a free form shape face region corresponding to the first candidate face region, wherein the free form shape face region has at least one of a pixel accuracy or a small block of pixels accuracy.\\n24. the system of claim 23, wherein the processor to determine the free form shape face region comprises the processor to generate an enhanced skip probability map corresponding to the first candidate face region, to binarize the enhanced skip probability map, and to overlay the binarized enhanced skip probability map over at least a portion of the video frame to provide the free form shape face region.\\n25. the system of claim 23, wherein a second video frame comprises a non-key frame of the video sequence, and the processor is further to perform face detection in the second video frame of the video sequence based on the free form shape face region.\\n26. the system of claim 25, wherein the processor is further to track a second free form shape face region in the second video frame based on the free form shape face region in the video frame.\\n27. the system of claim 21, wherein to encode the video frame based at least in part on the first candidate face region being a valid face region comprises the processor to reduce a quantization parameter corresponding to the first candidate face region, adjust a lambda value for the first candidate face region, or disable skip coding for the first candidate face region.\\n28. at least one non-transitory machine readable medium comprising a plurality of instructions that, in response to being executed on a device, cause the device to perform video coding based on face detection by: receiving a video frame comprising one of a plurality of video frames of a video sequence; determining the video frame is a key frame of the video sequence; performing, in response to the video frame being a key frame of the video sequence, a multi-stage facial search of the video frame based on predetermined feature templates and a predetermined number of stages to determine a first candidate face region and a second candidate face region in the video frame; testing the first and second candidate face regions based on skin tone information to determine the first candidate face region is a valid face region and the second candidate face region is an invalid face region; rejecting the second candidate face region and outputting the first candidate face region; and encoding the video frame based at least in part on the first candidate face region being a valid face region to generate a coded bitstream.\\n29. the non-transitory machine readable medium of claim 28, wherein the skin tone information comprises a skin probability map.\\n30. the non-transitory machine readable medium of claim 28, wherein the first candidate face region comprises a rectangular region, the machine readable medium comprising further instructions that, in response to being executed on the device, cause the device to perform video coding based on face detection by: determining a free form shape face region corresponding to the first candidate face region, wherein the free form shape face region has at least one of a pixel accuracy or a small block of pixels accuracy.\\n31. the non-transitory machine readable medium of claim 30, wherein determining the free form shape face region comprises: generating an enhanced skip probability map corresponding to the first candidate face region; binarizing the enhanced skip probability map; and overlaying the binarized enhanced skip probability map over at least a portion of the video frame to provide the free form shape face region.\\n32. the non-transitory machine readable medium of claim 30, wherein a second video frame comprises a non-key frame of the video sequence, the machine readable medium comprising further instructions that, in response to being executed on the device, cause the device to perform video coding based on face detection by performing face detection in the second video frame of the video sequence based on the free form shape face region.\\n33. the non-transitory machine readable medium of claim 32, the machine readable medium comprising further instructions that, in response to being executed on the device, cause the device to perform video coding based on face detection by: tracking a second free form shape face region in the second video frame based on the free form shape face region in the video frame.\\n34. the non-transitory machine readable medium of claim 28, wherein encoding the video frame based at least in part on the first candidate face region being a valid face region comprises at least one of reducing a quantization parameter corresponding to the first candidate face region, adjusting a lambda value for the first candidate face region, or disabling skip coding for the first candidate face region.1. a method for managing a smart database which stores facial images for face recognition, comprising steps of: (a) a managing device performing a process of counting one or more specific facial images corresponding to at least one specific person stored in the smart database where new facial images for the face recognition are continuously stored, and a process of determining whether a first counted value representing a count of the specific facial images satisfies a preset first set value; and (b) if the first counted value is determined as satisfying the first set value, the managing device performing a process of inputting the specific facial images into a neural aggregation network, to thereby allow the neural aggregation network to generate each of quality scores of each of the specific facial images by aggregation of the specific facial images, and a process of sorting the quality scores corresponding to the specific facial images in a descending order of the quality scores, a process of counting the sorted specific facial images in the descending order until a second counted value which represents the number of a counted part of the specific facial images becomes equal to a preset second set value, and a process of deleting an uncounted part of the specific facial images from the smart database.\\n2. the method of claim 1, further comprising a step of: (c) the managing device performing a process of generating at least one optimal feature by weighted summation of one or more features of the specific facial images using the counted part of the quality scores and a process of setting the optimal feature as a representative face corresponding to the specific person.\\n3. the method of claim 1, wherein, at the step of (b), the managing device performs a process of inputting the specific facial images into a cnn of the neural aggregation network, to thereby allow the cnn to generate one or more features corresponding to each of the specific facial images, and a process of inputting at least one feature vector, where the features are embedded, into an aggregation module including at least two attention blocks, to thereby allow the aggregation module to generate each of the quality scores of each of the features.\\n4. the method of claim 1, wherein, at the step of (b), the managing device performs a process of matching (i) (i-1) one or more features corresponding to each of the specific facial images stored in the smart database and (i-2) the quality scores with (ii) the specific person, and a process of storing the matched features and the matched quality scores in the smart database.\\n5. the method of claim 1, further comprising a step of: (d) the managing device performing one of (i) a process of learning a face recognition system by using the specific facial images corresponding to the specific person stored in the smart database and (ii) a process of transmitting the specific facial images, corresponding to the specific person, to a learning device corresponding to the face recognition system, to thereby allow the learning device to learn the face recognition system using the specific facial images.\\n6. the method of claim 1, wherein the neural aggregation network has been learned by a learning device repeating more than once (i) a process of inputting multiple facial images for training corresponding to an image set of a single face or a video of the single face into a cnn of the neural aggregation network, to thereby allow the cnn to generate one or more features for training by applying at least one convolution operation to the facial images for training, (ii) a process of inputting at least one feature vector for training, where the features for training are embedded, into an aggregation module, including at least two attention blocks, of the neural aggregation network, to thereby allow the aggregation module to generate each of quality scores for training of each of the features for training by aggregation of the features for training using one or more attention parameters learned in a previous iteration, (iii) a process of outputting at least one optimal feature for training by weighted summation of the features for training using the quality scores for training, and (iv) a process of updating the attention parameters learned in the previous iteration of the at least two attention blocks such that one or more losses are minimized which are outputted from a loss layer by referring to the optimal feature for training and its corresponding ground truth.\\n7. a managing device for managing a smart database which stores facial images for face recognition, comprising: at least one memory that stores instructions; and at least one processor configured to execute the instructions to perform or support another device to perform: (i) a process of counting one or more specific facial images corresponding to at least one specific person stored in the smart database where new facial images for the face recognition are continuously stored, and a process of determining whether a first counted value representing a count of the specific facial images satisfies a preset first set value, and (ii) if the first counted value is determined as satisfying the first set value, a process of inputting the specific facial images into a neural aggregation network, to thereby allow the neural aggregation network to generate each of quality scores of each of the specific facial images by aggregation of the specific facial images, and a process of sorting the quality scores corresponding to the specific facial images in a descending order of the quality scores, a process of counting the sorted specific facial images in the descending order until a second counted value which represents the number of a counted part of the specific facial images becomes equal to a preset second set value, and a process of deleting an uncounted part of the specific facial images from the smart database.\\n8. the managing device of claim 7, wherein the processor further performs: (iii) a process of generating at least one optimal feature by weighted summation of one or more features of the specific facial images using the counted part of the quality scores and a process of setting the optimal feature as a representative face corresponding to the specific person.\\n9. the managing device of claim 7, wherein, at the process of (ii), the processor performs a process of inputting the specific facial images into a cnn of the neural aggregation network, to thereby allow the cnn to generate one or more features corresponding to each of the specific facial images, and a process of inputting at least one feature vector, where the features are embedded, into an aggregation module including at least two attention blocks, to thereby allow the aggregation module to generate each of the quality scores of each of the features.\\n10. the managing device of claim 7, wherein, at the process of (ii), the processor performs a process of matching (i) (i-1) one or more features corresponding to each of the specific facial images stored in the smart database and (i-2) the quality scores with (ii) the specific person, and a process of storing the matched features and the matched quality scores in the smart database.\\n11. the managing device of claim 7, wherein the processor further performs: (iv) one of (i) a process of learning a face recognition system by using the specific facial images corresponding to the specific person stored in the smart database and (ii) a process of transmitting the specific facial images, corresponding to the specific person, to a learning device corresponding to the face recognition system, to thereby allow the learning device to learn the face recognition system using the specific facial images.\\n12. the managing device of claim 7, wherein the neural aggregation network has been learned by a learning device repeating more than once (i) a process of inputting multiple facial images for training corresponding to an image set of a single face or a video of the single face into a cnn of the neural aggregation network, to thereby allow the cnn to generate one or more features for training by applying at least one convolution operation to the facial images for training, (ii) a process of inputting at least one feature vector for training, where the features for training are embedded, into an aggregation module, including at least two attention blocks, of the neural aggregation network, to thereby allow the aggregation module to generate each of quality scores for training of each of the features for training by aggregation of the features for training using one or more attention parameters learned in a previous iteration, (iii) a process of outputting at least one optimal feature for training by weighted summation of the features for training using the quality scores for training, and (iv) a process of updating the attention parameters learned in the previous iteration of the at least two attention blocks such that one or more losses are minimized which are outputted from a loss layer by referring to the optimal feature for training and its corresponding ground truth.1. an object data processing system comprising: at least one processor configured to execute: at least one implementation of a plurality of recognition algorithms stored on at least one non-transitory computer-readable storage medium, each recognition algorithm having feature density selection criteria; and data preprocessing code executed by at least one processor, the data preprocessing code comprising an invariant feature identification algorithm and configured to: obtain a digital representation of a scene, the scene comprising one or more textual media; generate a set of invariant features by applying the invariant feature identification algorithm to the digital representation; cluster the set of invariant features into regions of interest in the digital representation of the scene, each region of interest having a region feature density; classify, by region classifier code, at least one of the regions of interest according to object type as a function of attributes derived from the region feature density and the digital representation, wherein the at least one of the classified regions of interest corresponds to text; and use a classification result corresponding to the at least one of the regions of interest to classify another of the regions of interest according to object type, wherein the another of the regions of interest corresponds to a region of interest for images.\\n2. the system of claim 1, wherein preprocessing code, based on the feature density selection criteria, determines that an ocr algorithm is applicable to the text, and that other recognition algorithms are applicable to aspects of the photographs and to logos.\\n3. the system of claim 1, wherein a user creates a user profile for a camera-equipped smartphone that includes the information that the user is visually impaired, which causes prioritized execution of the ocr algorithm such that a text reader program begins reading the text to the user as quickly as possible.\\n4. the system of claim 3, further comprising an audio or tactile feedback mechanism that helps the user to position the smart phone relative to the text.\\n5. the system of claim 4, further comprising a \"hold still\" audio feedback signal that is sent to the user when the text is at the center of the captured scene.\\n6. the system of claim 1, wherein the digital representation comprises at least one of the following types of digital data: image data, video data, and audio data.\\n7. the system of claim 1, wherein invariant feature identification algorithm comprises at least one of the following feature identification algorithms: fast, sift, freak, brisk, harris, daisy, and mser.\\n8. the system of claim 1, wherein the invariant feature identification algorithm includes at least one of the following: edge detection algorithm, corner detection algorithm, saliency map algorithm, curve detection algorithm, a texton identification algorithm, and wavelets algorithm.\\n9. the system of claim 1, wherein at least one region of interest represents at least one physical object in the scene.\\n10. the system of claim 1, wherein at least one region of interest represents at least one textual media in the scene.\\n11. the system of claim 10, wherein the region of interest represents a document as the textual media.\\n12. the system of claim 11, wherein the region of interest represents a financial document.\\n13. the system of claim 11, wherein the region of interest represents a structured document.\\n14. the system of claim 1, wherein at least one implementation of a plurality of recognition algorithms includes at least one of the following: a template driven algorithm, a face recognition algorithm, an optical character recognition algorithm, a speech recognition algorithm, and an object recognition algorithm.\\n15. the system of claim 1, wherein data preprocessing code is further configured to assign each region of interest at least one recognition algorithm as a function of a scene context derived from the digital representation.\\n16. the system of claim 15, wherein the scene context includes at least one of the following types of data: a location, a position, a time, a user identity, a news event, a medical event, and a promotion.\\n17. the system of claim 1, further comprising a mobile device comprising at least one implementation of a plurality of recognition algorithms and data preprocessing code.\\n18. the system of claim 17, wherein the mobile device comprises at least one of the following: a smart phone, a tablet, wearable glass, a toy, a vehicle, a computer, and a phablet.\\n19. the system of claim 1, further comprising a network-accessible server device comprising at least one implementation of a plurality of recognition algorithms and data preprocessing code.\\n20. the system of claim 1, wherein the object type includes at least one of the following: a face, an animal, a vehicle, a document, a plant, a building, an appliance, clothing, a body part, and a toy.\\n21. an object data processing system comprising: at least one processor configured to execute: at least one implementation of a plurality of recognition algorithms stored on at least one non-transitory computer-readable storage medium, each recognition algorithm having feature density selection criteria; and data preprocessing code executed by at least one processor, the data preprocessing code comprising an invariant feature identification algorithm and configured to: obtain a digital representation of a scene, the scene comprising one or more textual media; generate a set of invariant features by applying the invariant feature identification algorithm to the digital representation; cluster the set of invariant features into regions of interest in the digital representation of the scene, each region of interest having a region feature density; classify, by region classifier code, at least one of the regions of interest according to object type as a function of attributes derived from the region feature density and the digital representation; wherein the at least one of the classified regions of interest corresponds to text; and use a classification result corresponding to the at least one of the regions of interest to classify another of the regions of interest according to object type, wherein the another of the regions of interest corresponds to a region of interest for images; assign each region of interest at least one recognition algorithm from at least one implementation of a plurality of diverse recognition algorithms as a function of the region feature density of each region of interest and the feature density selection criteria of the at least one implementation of a plurality of diverse recognition algorithms; and configure the assigned recognition algorithms to process their respective regions of interest, wherein preprocessing code, based on the feature density selection criteria, determines that an ocr algorithm is applicable to the text, and that other recognition algorithms are applicable to aspects of the photographs and to logos.\\n22. a device comprising: at least one processor configured to execute: at least one implementation of a plurality of recognition algorithms stored on at least one non-transitory computer-readable storage medium, each recognition algorithm having feature density selection criteria; and data preprocessing code executed by at least one processor, the data preprocessing code comprising an invariant feature identification algorithm and configured to: obtain a digital representation of a scene, the scene comprising one or more textual media; generate a set of invariant features by applying the invariant feature identification algorithm to the digital representation; cluster the set of invariant features into regions of interest in the digital representation of the scene, each region of interest having a region feature density; and classify, by region classifier code, at least one of the regions of interest according to object type as a function of attributes derived from the region feature density and the digital representation, wherein the at least one of the classified regions of interest corresponds to text; and use a classification result corresponding to the at least one of the regions of interest to classify another of the regions of interest according to object type, wherein the another of the regions of interest corresponds to a region of interest for images.1. a mobile terminal comprising: a front camera configured to obtain a two-dimensional (2d) face image of a user; a glance sensor tilted by a certain angle and disposed adjacent to the front camera to obtain metadata of the 2d face image; and a controller obtaining a distance between the glance sensor and the front camera, the distance enabling an area of an overlap region, where a first region representing a range photographable by the front camera overlaps a second region representing a range photographable by the glance sensor, to be the maximum.\\n2. the mobile terminal of claim 1, wherein the controller is configured to obtain the distance, enabling the area of the overlap region to be the maximum, between the glance sensor and the front camera by varying a tilting angle of the glance sensor.\\n3. the mobile terminal of claim 2, wherein the controller is configured to set the distance, enabling the area of the overlap region to be the maximum, between the glance sensor and the front camera and the tilting angle of the glance sensor as an optimal disposition location of the glance sensor.\\n4. the mobile terminal of claim 3, wherein the controller is configured to set a disposition location of the front camera as an original point and calculates coordinates of a first triangle representing the first region, based on a field of view of the front camera and a maximum photographing distance of the front camera.\\n5. the mobile terminal of claim 4, wherein the controller is configured to calculate coordinates of a second triangle representing the second region, based on a field of view of the glance sensor, a maximum photographing distance of the glance sensor, a distance between the front camera and the glance sensor, and a tilting angle of the glance sensor.\\n6. the mobile terminal of claim 5, wherein before the glance sensor is tilted, the controller is configured to calculate coordinates of a third triangle representing a third region photographable by the glance sensor, and the controller is configured to rotation-convert the coordinates of the third triangle, based on the tilting angle of the glance sensor and calculate the coordinates of the second triangle.\\n7. the mobile terminal of claim 6, wherein the controller is configured to calculate coordinates of the overlap region, based on the coordinates of the first triangle and the coordinates of the second triangle and calculates the area of the overlap region, based on the coordinates of the overlap region.\\n8. the mobile terminal of claim 1, wherein the controller is configured to generate three-dimensional (3d) face information, based on the 2d face image obtained by the front camera and metadata obtained by the glance sensor.\\n9. the mobile terminal of claim 8, wherein the metadata comprises one or more of an angle of a face of the user, a size of the face, and a location of the face.\\n10. the mobile terminal of claim 9, wherein the angle of the face comprises an angle by which the face is rotated about one or more of a pitch axis, a roll axis, and a yaw axis.\\n11. the mobile terminal of claim 8, further comprising a memory storing the generated 3d face information, wherein the controller is configured to performs a user authentication process by comparing the stored 3d face information with 3d face information obtained for user authentication.\\n12. the mobile terminal of claim 1, wherein the glance sensor is controlled to be permanently activated with a low power to obtain a front image and metadata of the front image.\\n13. the mobile terminal of claim 1, wherein the front camera and the glance sensor are disposed on the same line in an upper end of the mobile terminal.\\n14. the mobile terminal of claim 1, wherein the glance sensor is tilted in one direction of an up direction, a down direction, a left direction, and a right direction.\\n15. the mobile terminal of claim 1, wherein the metadata is data which is changed when the mobile terminal is tilted by an external physical force.1. a method, comprising: receiving, by a smart television (tv), an indication of upcoming media programming, wherein the upcoming media programming is based on a user profile; identifying one or more devices in communication with the smart tv, each of the one or more devices including at least one of a microphone or a camera; instructing at least one identified device to detect audio signals using its respective microphone, or to detect visual signals using its respective camera; selecting at least one device of the one or more devices based on the detected audio signal or detected visual signal; and providing instructions to the selected device to output a notification related to the upcoming media programming.\\n2. the method of claim 1, wherein the upcoming media programming is one of a live television program, a recorded television program, a broadcast television program, or an application-provided program.\\n3. the method of claim 1, wherein selecting the first device based on the detected audio signal includes recognizing a voice.\\n4. the method of claim 3, further comprising determining a distance to the recognized voice, and wherein selecting the first device is further based on the determined distance.\\n5. the method of claim 1, wherein selecting the first device based on the detected visual signals includes recognizing a face.\\n6. the method of claim 5, wherein recognizing the face includes a face recognition technique.\\n7. the method of claim 1, further comprising presenting, on the smart tv, the upcoming media programming in a favorite channel list.\\n8. the method of claim 7, further comprising: obtaining media programming viewing data, wherein the media programming viewing data includes at least one of a historical time and a historical date that one or more media programs were viewed; obtaining at least one of a current time and a current date; processing the media programming viewing data to determine a probability of the one or more media programs being viewed based on at least one of the current time and the current date; and presenting the favorite channel list based on the determined probability of the one or more media programs being viewed.\\n9. the method of claim 8, wherein processing the media programming viewing data includes employing a neural network model.\\n10. the method of claim 9, wherein employing the neural network model comprises: determining a duration that the one or more media programs were viewed for each of the at least one of the historical time and the historical date; setting a threshold time duration; comparing the determined duration to the threshold time duration; and filtering out the one or more media programs viewed below the threshold time duration.\\n11. a smart television (tv), comprising: a network interface; a non-transitory computer-readable medium; and a processor in communication with the network interface, and the non-transitory computer-readable medium, and capable of executing processor-executable program code stored in the non-transitory computer-readable medium, to cause the smart tv to: receive an indication of upcoming media programming, wherein the upcoming media programming is based on a user profile; identify one or more devices in communication with the smart tv, each of the one or more devices including at least one of a microphone or a camera; instruct at least one identified device to detect audio signals using its respective microphone, or to detect visual signals using its respective camera; select at least one device of the one or more devices based on the detected audio signal or detected visual signal; and provide instructions to the selected device to output a notification related to the upcoming media programming.\\n12. the smart tv of claim 11, wherein selecting the first device based on the detected audio signal includes recognizing a voice.\\n13. the smart tv of claim 12, wherein the processor is further capable of executing processor-executable program code to: determine a distance to the recognized voice, and wherein selecting the first device is further based on the determined distance.\\n14. the smart tv of claim 11, wherein selecting the first device based on the detected visual signals includes detecting the presence of a user.\\n15. the smart tv of claim 14, wherein detecting the presence of the user includes employing one or more of a camera, a microphone, or a fingerprint sensor associated with at least one of the smart tv a mobile device, a smartphone, a laptop computer, a tablet device, a wearable device, an internet of things (iot) device, an internet of everything (ioe) device, an iot hub, or an ioe hub.\\n16. a smart television (tv), comprising: means for receiving an indication of upcoming media programming, wherein the upcoming media programming is based on a user profile; means for identifying one or more devices in communication with the smart tv, each of the one or more devices including at least one of a microphone or a camera; means for instructing at least one identified device to detect audio signals using its respective microphone, or to detect visual signals using its respective camera; means for selecting at least one device of the one or more devices based on the detected audio signal or detected visual signal; and means for providing instructions to the selected device to output a notification related to the upcoming media programming.\\n17. the smart tv of claim 16, wherein the one or more devices includes at least one of a mobile device, a smartphone, a laptop computer, a tablet device, a wearable device, an internet of things (iot) device, an internet of everything (ioe) device, an iot hub, an ioe hub, or another smart tv.\\n18. the smart tv of claim 16, wherein the upcoming media programming is one of a live television program, a recorded television program, a broadcast television program, or an application-provided program.\\n19. the smart tv of claim 16, wherein the notification includes at least one of a push message, a sms message, a way2sms message, an audio alert, an audio message, or an email message.\\n20. the smart tv of claim 16, further comprising presenting the upcoming media programming in a favorite channel list.\\n21. the smart tv of claim 20, further comprising: means for obtaining media programming viewing data, wherein the media programming viewing data includes at least one of a historical time and a historical date that one or more media programs were viewed on the smart tv; means for obtaining at least one of a current time and a current date; means for processing the media programming viewing data to determine a probability of the one or more media programs being viewed on the smart tv based on at least one of the current time and the current date; and means for presenting the favorite channel list based on the determined probability of the one or more media programs being viewed.\\n22. the smart tv of claim 21, wherein the means for processing the media programming viewing data includes employing a neural network model.\\n23. the smart tv of claim 22, wherein employing the neural network model comprises: determining a duration that the one or more media programs were viewed on the smart tv for each of the at least one of the historical time and the historical date; setting a threshold time duration; comparing the determined duration to the threshold time duration; and filtering out the one or more media programs viewed below the threshold time duration.\\n24. the smart tv of claim 21, further comprising: means for adjusting at least one of a volume or a brightness of the smart tv, wherein the adjusting is based on at least one of the historical time and the historical date.\\n25. the smart tv of claim 21, further comprising means for restricting access to one or more media programs.\\n26. a non-transitory computer-readable medium comprising processor-executable program code configured to cause a processor of a smart television (tv) to: receive an indication of upcoming media programming, wherein the upcoming media programming is based on a user profile; identify one or more devices in communication with the smart tv, each of the one or more devices including at least one of a microphone or a camera; instruct at least one identified device to detect audio signals using its respective microphone, or to detect visual signals using its respective camera; select at least one device of the one or more devices based on the detected audio signal or detected visual signal; and provide instructions to the selected device to output a notification related to the upcoming media programming.\\n27. the non-transitory computer-readable medium of claim 26, wherein selecting the first device based on the detected audio signal includes recognizing a voice.\\n28. the non-transitory computer-readable medium of claim 27, wherein the processor is further capable of executing processor-executable program code to: determine a distance to the recognized voice, and wherein selecting the first device is further based on the determined distance.\\n29. the non-transitory computer-readable medium of claim 26, wherein selecting the first device based on the detected visual signals includes recognizing a face.\\n30. the non-transitory computer-readable medium of claim 29, wherein recognizing the face includes a face recognition technique.1. a camera comprising: a sensor array including a plurality of sensors; an infrared (ir) illuminator configured to emit active ir light in an ir light sub-band; a plurality of spectral illuminators, each spectral illuminator configured to emit active spectral light in a different spectral light sub-band; a depth controller machine configured to determine a depth value for each of the plurality of sensors based on the active ir light, a spectral controller machine configured to, for each of the plurality of sensors, determine a spectral value for each spectral light sub-band of the plurality of spectral illuminators; and an output machine configured to output a test depth+multi-spectral image including a plurality of pixels, each pixel corresponding to one of the plurality of sensors of the sensor array and including at least: a depth value, and a spectral value for each spectral light sub-band of the plurality of spectral illuminators; a face recognition machine previously trained with a set of labeled training depth+multi-spectral images having a same structure as the test depth+multi-spectral image, the face recognition machine configured to output a confidence value indicating a likelihood that the test depth+multi-spectral image includes a face.\\n2. the camera of claim 1, wherein each spectral value is calculated based on the depth value determined for the sensor that corresponds to the pixel.\\n3. the camera of claim 1, wherein the face recognition machine is configured to use a convolutional neural network to determine the confidence value.\\n4. the camera of claim 3, wherein the face recognition machine includes a plurality of input nodes, wherein each input node is configured to receive a pixel value array corresponding to a different pixel of the plurality of pixels of the test depth+multi-spectral image, and wherein the pixel value array includes the depth value and the plurality of multi-spectral values for the pixel.\\n5. the camera of claim 4, wherein the plurality of multi-spectral values for the pixel include more than three spectral values.\\n6. the camera of claim 4, wherein the output machine is configured to output a surface normal for each pixel of the test depth+multi-spectral image, and wherein the pixel value array includes the surface normal.\\n7. the camera of claim 4, wherein the output machine is configured to output a curvature for each pixel of the test depth+multi-spectral image, and wherein the pixel value array includes the curvature.\\n8. the camera of claim 3, wherein the face recognition machine is configured to use a plurality of models to determine the confidence value, wherein the plurality of models includes a plurality of channel-specific models, wherein each channel-specific model is configured to process a different pixel parameter for the plurality of pixels of the test depth+multi-spectral image, wherein each channel-specific model includes a plurality of input nodes, and wherein, for each channel-specific model, each input node is configured to receive a pixel parameter value for a different pixel of the plurality of pixels of the test depth+multi-spectral image.\\n9. the camera of claim 1, wherein the face recognition machine is configured to use a statistical model to determine the confidence value.\\n10. the camera of claim 9, wherein the statistical model includes a nearest neighbor algorithm.\\n11. the camera of claim 9, wherein the statistical model includes a support vector machine.\\n12. the camera of claim 1, wherein the face recognition machine is further configured to output a location on the test depth+multi-spectral image of a bounding box around a recognized face.\\n13. the camera of claim 1, wherein the face recognition machine is further configured to output a location on the test depth+multi-spectral image of an identified two-dimensional (2d) facial feature of a recognized face.\\n14. the camera of claim 1, wherein the face recognition machine is further configured to output a location on the test depth+multi-spectral image of an identified three-dimensional (3d) facial feature of a recognized face.\\n15. the camera of claim 1, wherein the face recognition machine is further configured to output a location on the test depth+multi-spectral image of an identified spectral feature on a recognized face.\\n16. the camera of claim 1, wherein the face recognition machine is further configured to output, for each pixel of the test depth+multi-spectral image, a confidence value indicating a likelihood that the pixel is included in a face.\\n17. the camera of claim 1, wherein the face recognition machine is further configured to output an identity of a face recognized in the test depth+multi-spectral image.\\n18. the camera of claim 1, wherein the plurality of sensors of the sensor array are differential sensors, and wherein each spectral value is determined based on a depth value and a differential measurement for that differential sensor.\\n19. a camera comprising: a sensor array including a plurality of sensors; an infrared (ir) illuminator configured to emit active ir light in an ir light sub-band; a plurality of spectral illuminators, each spectral illuminator configured to emit active spectral light in a different spectral light sub-band; a depth controller machine configured to determine a depth value for each of the plurality of sensors based on the active ir light, a spectral controller machine configured to, for each of the plurality of sensors, determine a spectral value for each spectral light sub-band of the plurality of spectral illuminators, wherein each spectral value is calculated based on the depth value determined for the sensor that corresponds to the pixel; and an output machine configured to output a test depth+multi-spectral image including a plurality of pixels, each pixel corresponding to one of the plurality of sensors of the sensor array and including at least: a depth value, and a spectral value for each spectral light sub-band of the plurality of spectral illuminators; and a face recognition machine including a convolutional neural network previously trained with a set of labeled training depth+multi-spectral images having a same structure as the test depth+multi-spectral image, the face recognition machine configured to output a confidence value indicating a likelihood that the test depth+multi-spectral image includes a face.1. an image processing method, comprising: acquiring a photo album obtained from face clustering; collecting face information of respective images in the photo album, and acquiring a face parameter of each image according to the face information; selecting a cover image according to the face parameter of each image; and taking a face-region image from the cover image, and setting the face-region image as a cover of the photo album; wherein selecting the cover image according to the face parameter of each image comprises: performing calculation on the face parameter of each image in a preset way, to obtain a cover score of each image; selecting the image with a highest cover score as the cover image; wherein selecting the image with the highest cover score as the cover image comprises: acquiring a source of each image; and selecting the image with the highest cover score in images coming from a preset source as the cover image.\\n2. the method according to claim 1, wherein selecting the image with the highest cover score as the cover image comprises: acquiring the number of faces contained in each image; determining single-person images according to the number of faces; and selecting the single-person image with the highest cover score as the cover image.\\n3. the method according to claim 2, wherein selecting the image with the highest cover score as the cover image further comprises: when there is no single-person image in the photo album, determining images including two faces from the photo album; and selecting the image with the highest cover score from the images including two faces as the cover image.\\n4. the method according to claim 1, wherein the face information comprises face feature points, and the face parameter comprises a face turning angle; acquiring the face parameter of each image according to the face information comprises: acquiring coordinate values of the face feature points; determining distances and angles between the face feature points; and determining the face turning angle according to the distances and the angles.\\n5. the method according to claim 1, wherein the face parameter comprises a face ratio; acquiring the face parameter of each image according to the face information comprises: determining a face region of the image according to the face information; and calculating a ratio of an area of the face region to an area of the image to obtain the face ratio.\\n6. the method according to claim 5, wherein calculating the face ratio comprises: when there is more than one face in the image, subtracting an area occupied faces other than a face corresponding to the photo album from the face region to obtain a remaining area; and calculating a ratio of the remaining area to the area of the image to obtain the face ratio.\\n7. the method according to claim 1, wherein collecting face information of respective images in the photo album comprises: acquiring image identifications of images in the photo album; extracting face information corresponding to the image identifications from a face database, the face database being stored with face recognition results of images, the face recognition results including the face information.\\n8. an image processing apparatus, comprising: a processor; and a memory, configured to store instructions executable by the processor, wherein the processor is configured to run a program corresponding to the instructions by reading the instructions stored in the memory, so as to perform: acquiring a photo album obtained from face clustering; collecting face information of each image in the photo album; acquiring a face parameter of each image according to the face information; selecting a cover image according to the face parameter of each image; taking a face-region image from the cover image, and setting the face-region image as a cover of the photo album; wherein the processor is configured to: perform calculation on the face parameter of each image in a preset way, to obtain a cover score of each image; and select the image with a highest cover score as the cover image; and wherein the processor is configured to: acquire a source of each image; and select the image with the highest cover score in images coming from a preset source as the cover image.\\n9. the apparatus according to claim 8, wherein the processor is configured to: acquire the number of faces contained in each image; determine single-person images according to the number of faces; and select the single-person image with the highest cover score as the cover image.\\n10. the apparatus according to claim 9, wherein the processor is further configured to: when there is no single-person image in the photo album, determine images including two faces from the photo album; and select the image with the highest cover score from the images including two faces as the cover image.\\n11. the apparatus according to claim 8, wherein the face information comprises face feature points, and the face parameter comprises a face turning angle; the processor is configured to: acquire coordinate values of the face feature points; determine distances and angles between the face feature points; and determine the face turning angle according to the distances and the angles.\\n12. the apparatus according to claim 8, wherein the face parameter comprises a face ratio; the processor is configured to: determine a face region of the image according to the face information; and calculate a ratio of an area of the face region to an area of the image to obtain the face ratio.\\n13. the apparatus according to claim 12, wherein the processor is configured to: when there is more than one face in the image, subtract an area occupied faces other than a face corresponding to the photo album from the face region to obtain a remaining area; and calculate a ratio of the remaining area to the area of the image to obtain the face ratio.\\n14. the apparatus according to claim 8, wherein the processor is configured to: acquire image identifications of images in the photo album; extract face information corresponding to the image identifications from a face database, the face database being stored with face recognition results of images, the face recognition results including the face information.\\n15. an electronic device, comprising a processor, a memory, a display screen and an input device connected via a system bus, wherein the memory is stored with computer programs that, when executed by the processor, cause the processor to implement an image processing method, the image processing method comprising: acquiring a photo album obtained from face clustering; collecting face information of respective images in the photo album, and acquiring a face parameter of each image according to the face information; selecting a cover image according to the face parameter of each image; and taking a face-region image from the cover image, and setting the face-region image as a cover of the photo album; wherein selecting the cover image according to the face parameter of each image comprises: performing calculation on the face parameter of each image in a preset way, to obtain a cover score of each image; and selecting the image with a highest cover score as the cover image; and wherein selecting the image with the highest cover score as the cover image comprises: acquiring a source of each image; and selecting the image with the highest cover score in images coming from a preset source as the cover image.\\n16. the electronic device according to claim 15, wherein the electronic device comprises at least one of a mobile phone, a tablet computer, a personal digital assistant and a wearable device.1. a computer-implemented method, comprising: receiving, at a computing device, a meeting invitation identifying a location and at least one invitee, the meeting invitation configured to provide the at least one invitee with physical access to the location, wherein the meeting invitation causes a system to control a pathway allowing physical access to the location; providing, based on the meeting invitation, the at least one invitee with physical access to the location by controlling the pathway allowing the at least one invitee to physically access the location through the pathway in response to positioning data indicating that the at least one invitee is at a predetermined location near the location wherein the positioning data is based in part on a face recognition camera system identifying the at least one invitee; receiving the positioning data from the face recognition camera system identifying the at least one invitee, wherein the positioning data indicates a pattern of movement of the at least one invitee; determining that the pattern of movement indicates that the at least one invitee has exited the location; and revoking physical access to the location identified in the meeting invitation by controlling the pathway to restrict the at least one invitee identified in the meeting invitation from physical access to the location through the pathway, in response to determining that the pattern of movement indicates that the at least one invitee has exited the location.\\n2. the computer-implemented method of claim 1, wherein determining that the at least one invitee has exited the location comprises determining that the at least one invitee has passed through an egress associated with the location in a predetermined direction.\\n3. the computer-implemented method of claim 1, wherein determining that the at least one invitee has exited the location comprises determining that the at least one invitee has moved through an area in a predetermined direction.\\n4. the computer-implemented method of claim 1, wherein the positioning data indicates a second pattern of movement of the at least one invitee and, wherein access to secured data associated with the location is provided in response to detecting the second pattern of movement.\\n5. the computer-implemented method of claim 1, further comprising: collating secured data and public data to generate resource data; and communicating the resource data to a client computing device associated with the at least one invitee when access of the location is provided.\\n6. the computer-implemented method of claim 1, wherein the positioning data indicates that the at least one invitee is at the predetermined location when the at least one invitee passes through the predetermined location.\\n7. the computer-implemented method of claim 1, wherein the positioning data indicates that the at least one invitee is at the predetermined location when the at least one invitee passes through the predetermined location near the location in a predetermined direction.\\n8. a system, comprising: a processor; and a memory in communication with the processor, the memory having computer-readable instructions stored thereupon that, when executed by the processor, cause the processor to: receive a meeting invitation indicating a location and an identity, the meeting invitation configured to provide at least one invitee with physical access to the location, wherein the meeting invitation causes the system to control a pathway allowing physical access to the location; provide the at least one invitee associated with the identity access to the location by controlling the pathway allowing the at least one invitee to physically access the location through the pathway in response to positioning data indicating that the at least one invitee is at a predetermined location near the location, wherein the positioning data is based in part on a face recognition camera system identifying the at least one invitee; receive the positioning data from the face recognition camera system identifying the at least one invitee, wherein the positioning data indicates a pattern of movement of the at least one invitee; determine that the pattern of movement indicates that the at least one invitee has exited the location; and revoke physical access to the location identified in the meeting invitation by controlling the pathway to restrict the at least one invitee identified in the meeting invitation from physical access to the location through the pathway, in response to determining that the pattern of movement indicates that the at least one invitee has exited the location.\\n9. the system of claim 8, wherein determining that the at least one invitee has exited the location comprises determining that the at least one invitee has passed through an egress associated with the location.\\n10. the system of claim 8, wherein determining that the at least one invitee has exited the location comprises determining that the at least one invitee has moved through an area in a predetermined direction.\\n11. the system of claim 8, wherein the positioning data indicates a second pattern of movement of the at least one invitee and wherein access to secured data associated with the location is provided in response to detecting the second pattern of movement.\\n12. the system of claim 8, wherein the instructions further cause the processor to: collate secured data and public data to generate resource data; and communicate the resource data to a client computing device associated with the at least one invitee when access of the location is provided.\\n13. a non-transitory computer-readable storage medium having computer-executable instructions stored thereupon which, when executed by one or more processors of a computing device, cause the one or more processors of the computing device to: receive a meeting invitation indicating a location and an identity, the meeting invitation configured to provide at least one invitee with physical access to the location, wherein the meeting invitation causes a system to control a pathway allowing physical access to the location; provide the at least one invitee associated with the identity access to the location by controlling the pathway allowing the at least one invitee to physically access the location through the pathway in response to positioning data indicating that the at least one invitee is at a predetermined location near the location, wherein the positioning data is based in part on a face recognition camera system identifying the at least one invitee; receive the positioning data from the face recognition camera system identifying the at least one invitee, wherein the positioning data indicates a pattern of movement of the at least one invitee; determine that the pattern of movement indicates that the at least one invitee has exited the location; and revoke physical access to the location identified in the meeting invitation by controlling the pathway to restrict the at least one invitee identified in the meeting invitation from physical access to the location through the pathway, in response to determining that the pattern of movement indicates that the at least one invitee has exited the location.\\n14. the non-transitory computer-readable storage medium of claim 13, wherein determining that the at least one invitee has exited the location comprises determining that the at least one invitee has passed through an egress associated with the location.\\n15. the non-transitory computer-readable storage medium of claim 13, wherein the positioning data indicates a second pattern of movement of the at least one invitee and wherein access to secured data associated with the location is provided in response to detecting the second pattern of movement.\\n16. the non-transitory computer-readable storage medium of claim 13, wherein the instructions further cause the one or more processors to: collate secured data and public data to generate resource data; and communicate the resource data to a client computing device associated with the at least one invitee when access of the location is provided.1. a method, comprising: receiving a piece of content and salient data for the piece of content; based on the salient data, determining a first path for a viewport for the piece of content, wherein the first path for the viewport includes different salient events occurring in the piece of content at different times during playback of the piece of content; providing the viewport on a display device, wherein movement of the viewport is based on the first path for the viewport and the salient data during the playback; detecting an additional salient event in the piece of content that is not included in the first path for the viewport; and providing an indication for the additional salient event in the viewport during the playback.\\n2. the method of claim 1, wherein the salient data identifies each salient event in the piece of content, and the salient data indicates, for each salient event in the piece of content, a corresponding point location of the salient event in the piece of content and a corresponding time at which the salient event occurs during the playback.\\n3. the method of claim 2, wherein the salient data further indicates, for each salient event in the piece of content, a corresponding type of the salient event and a corresponding strength value of the salient event.\\n4. the method of claim 1, wherein the first path for the viewport controls the movement of the viewport to put the different salient events in a view of the viewport at the different times during the playback.\\n5. the method of claim 1, further comprising: detecting one or more salient events in the piece of content based on at least one of the following: visual data of the piece of content, audio data of the piece of content, or content consumption experience data for the piece of content; wherein the salient data is indicative of each salient event detected.\\n6. the method of claim 1, further comprising: detecting one or more salient events in the piece of content based on at least one of the following: face recognition, facial emotion recognition, object recognition, motion recognition, or metadata of the piece of content; wherein the salient data is indicative of each salient event detected.\\n7. the method of claim 1, further comprising: detecting user interaction with the indication, wherein the indication comprises an interactive hint; and in response to detecting the user interaction: adapting the first path for the viewport to a second path for the viewport based on the user interaction, wherein the second path for the viewport includes the additional salient event; and providing an updated viewport for the piece of content on the display device, wherein movement of the updated viewport is based on the second path for the viewport and the salient data during the playback, and the second path for the viewport controls the movement of the updated viewport to put the additional salient event in a view of the updated viewport.\\n8. the method of claim 7, further comprising: changing a weight assigned to the additional salient event and one or more other salient events in the piece of content having the same type as the additional salient event.\\n9. the method of claim 7, wherein the second path for the viewport includes one or more other salient events in the piece of content having the same type as the additional salient event.\\n10. a system, comprising: at least one processor; and a non-transitory processor-readable memory device storing instructions that when executed by the at least one processor causes the at least one processor to perform operations including: receiving a piece of content and salient data for the piece of content; based on the salient data, determining a first path for a viewport for the piece of content, wherein the first path for the viewport includes different salient events occurring in the piece of content at different times during playback of the piece of content; providing the viewport on a display device, wherein movement of the viewport is based on the first path for the viewport and the salient data during the playback; detecting an additional salient event in the piece of content that is not included in the first path for the viewport; and providing an indication for the additional salient event in the viewport during the playback.\\n11. the system of claim 10, wherein the salient data identifies each salient event in the piece of content, and the salient data indicates, for each salient event in the piece of content, a corresponding point location of the salient event in the piece of content and a corresponding time at which the salient event occurs during the playback.\\n12. the system of claim 11, wherein the salient data further indicates, for each salient event in the piece of content, a corresponding type of the salient event and a corresponding strength value of the salient event.\\n13. the system of claim 10, wherein the salient data is generated offline on a server.\\n14. the system of claim 10, the operations further comprising: detecting one or more salient events in the piece of content based on at least one of the following: visual data of the piece of content, audio data of the piece of content, or content consumption experience data for the piece of content; wherein the salient data is indicative of each salient event detected.\\n15. the system of claim 10, the operations further comprising: detecting one or more salient events in the piece of content based on at least one of the following: face recognition, facial emotion recognition, object recognition, motion recognition, or metadata of the piece of content; wherein the salient data is indicative of each salient event detected.\\n16. the system of claim 10, the operations further comprising: detecting user interaction with the indication, wherein the indication comprises an interactive hint; and in response to detecting the user interaction: adapting the first path for the viewport to a second path for the viewport based on the user interaction, wherein the second path for the viewport includes the additional salient event; and providing an updated viewport for the piece of content on the display device, wherein movement of the updated viewport is based on the second path for the viewport and the salient data during the playback, and the second path for the viewport controls the movement of the updated viewport to put the additional salient event in a view of the updated viewport.\\n17. the system of claim 16, the operations further comprising: changing a weight assigned to the additional salient event and one or more other salient events in the piece of content having the same type as the additional salient event.\\n18. the system of claim 16, wherein the second path for the viewport includes one or more other salient events in the piece of content having the same type as the additional salient event.\\n19. a non-transitory computer readable storage medium including instructions to perform a method comprising: receiving a piece of content and salient data for the piece of content; based on the salient data, determining a first path for a viewport for the piece of content, wherein the first path for the viewport includes different salient events occurring in the piece of content at different times during playback of the piece of content; providing the viewport on a display device, wherein movement of the viewport is based on the first path for the viewport and the salient data during the playback; detecting an additional salient event in the piece of content that is not included in the first path for the viewport; and providing an indication for the additional salient event in the viewport during the playback.\\n20. the computer readable storage medium of claim 19, the method further comprising: detecting user interaction with the indication, wherein the indication comprises an interactive hint; and in response to detecting the user interaction: adapting the first path for the viewport to a second path for the viewport based on the user interaction, wherein the second path for the viewport includes the additional salient event; and providing an updated viewport for the piece of content on the display device, wherein movement of the updated viewport is based on the second path for the viewport and the salient data during the playback, and the second path for the viewport controls the movement of the updated viewport to put the additional salient event in a view of the updated viewport.1. a mobile device with facial recognition, the mobile device comprising: one or more cameras; a processor device and memory coupled to the processor device, the processing system programmed to: receive a plurality of images from the one or more cameras; extract, with a feature extractor utilizing a convolutional neural network (cnn) with an enlarged intra-class variance of long-tail classes, feature vectors from each of the plurality of images; generate, with a feature generator, discriminative feature vectors for each of the feature vectors; classify, with a fully connected classifier, an identity from the discriminative feature vectors; and control an operation of the mobile device to react in accordance with the identity.\\n2. the mobile device as recited in claim 1, further includes a communication system.\\n3. the mobile device as recited in claim 1, wherein the operation tags the video with the identity and uploads the video to social media.\\n4. the mobile device as recited in claim 1, wherein the operation tags the video with the identity and sends the video to a user.\\n5. the mobile device as recited in claim 1, wherein the mobile device is a smart phone.\\n6. the mobile device as recited in claim 1, wherein the mobile device is a body cam.\\n7. the mobile device as recited in claim 1, further programmed to train the feature extractor, the feature generator, and the fully connected classifier with an alternative bi-stage strategy.\\n8. the mobile device as recited in claim 1, wherein the feature extractor shares covariance matrices across all classes to transfer intra-class variance from regular classes to the long-tail classes.\\n9. the mobile device as recited in claim 1, wherein the feature generator optimizes a softmax loss by joint regularization of weights and features through a magnitude of an inner product of the weights and features.\\n10. the mobile device as recited in claim 1, wherein the feature extractor averages the feature vector with a flipped feature vector, the flipped feature vector being generated from a horizontally flipped frame from one of the plurality of images.\\n11. the mobile device as recited in claim 1, wherein each of the plurality of images is selected from the group consisting of an image, a video, and a frame from the video.\\n12. the mobile device as recited in claim 2, wherein the communication system connects to a remote server that includes a facial recognition network.\\n13. the mobile device as recited in claim 7, wherein one stage of the alternative bi-stage strategy fixes the feature extractor and applies the feature generator to generate new transferred features that are more diverse and violate a decision boundary.\\n14. the mobile device as recited in claim 7, wherein one stage of the alternative bi-stage strategy fixes the fully connected classifier and updates the feature extractor and the feature generator.\\n15. a computer program product for a mobile device with facial recognition, the computer program product comprising a non-transitory computer readable storage medium having program instructions embodied therewith, the program instructions executable by a computer to cause the computer to perform a method comprising: receiving, by a processor device, a plurality of images; extracting, by the processor device with a feature extractor utilizing a convolutional neural network (cnn) with an enlarged intra-class variance of long-tail classes, feature vectors for each of the plurality of images; generating, by the processor device with a feature generator, discriminative feature vectors for each of the feature vectors; classifying, by the processor device utilizing a fully connected classifier, an identity from the discriminative feature vector; and controlling an operation of the mobile device to react in accordance with the identity.\\n16. a computer-implemented method for facial recognition in a mobile device, the method comprising: receiving, by a processor device, a plurality of images; extracting, by the processor device with a feature extractor utilizing a convolutional neural network (cnn) with an enlarged intra-class variance of long-tail classes, feature vectors for each of the plurality of images; generating, by the processor device with a feature generator, discriminative feature vectors for each of the feature vectors; classifying, by the processor device utilizing a fully connected classifier, an identity from the discriminative feature vector; and controlling an operation of the mobile device to react in accordance with the identity.\\n17. the computer-implemented method as recited in claim 16, wherein controlling includes tagging the video with the identity and uploading the video to social media.\\n18. the computer-implemented method as recited in claim 16, wherein controlling includes tagging the video with the identity and sending the video to a user.\\n19. the computer-implemented method as recited in claim 16, wherein extracting includes sharing covariance matrices across all classes to transfer intra-class variance from regular classes to the long-tail classes.1. a computing device comprising: a non-transitory machine readable medium storing a machine trained (mt) network comprising a plurality of layers of processing nodes, each processing node configured to: compute a first output value by combining a set of output values from a set of processing nodes, and use a piecewise linear cup function to compute a second output value from the first output value of the processing node, wherein the piecewise linear cup function prior to training of the mt network comprises at least (i) a first linear section with a first slope, followed by (ii) a second linear section with a negative second slope, followed by (iii) a third linear section with a negative third slope that is different from the second slope, followed by (iv) a fourth linear section with a positive fourth slope, followed by (v) a fifth linear section with a positive fifth slope that is different from the fourth slope, followed by (vi) a sixth linear section with a sixth slope, wherein the piecewise linear cup function is symmetric about a vertical axis between the third and fourth linear sections prior to training of the mt network; a content capturing circuit for capturing content for processing by the mt network; and a set of processing units for executing the processing nodes to process content captured by the content capturing circuit, wherein by training a set of parameters that define the piecewise linear cup function of each node in first and second pluralities of processing nodes, (i) each processing node in the first plurality of processing nodes is configured to emulate a boolean and operator such that an output value of the processing node is in a range associated with a \"1\" value only when a set of inputs to the processing node have a set of values in a range associated with \"1\" and (ii) each processing node in the second plurality of processing nodes is configured to emulate a boolean xnor operator such that an output value of the processing node is in the range associated with \"1\" only when (a) a set of inputs to the node have a set of values in a range associated with \"1\" or (b) the set of inputs to the node have a set of values in a range associated with a \"0\" value.\\n2. the computing device of claim 1, wherein the third linear section of the piecewise linear cup function of a first processing node in the mt network has a different slope from the third linear section of a second processing node in the mt network.\\n3. the computing device of claim 1, wherein the length of the third section of a piecewise linear cup function of a first processing node in the mt network is different from the length of the third section of a piecewise linear cup function of a second processing node in the mt network.\\n4. the computing device of claim 1, wherein the sets of parameters are trained in part by a back propagating module for back propagating errors in output values of later layers of processing nodes to earlier layers of processing nodes by adjusting the set of parameters that define the piecewise linear cup functions of the earlier layers of processing nodes.\\n5. the computing device of claim 4, wherein each processing node uses a linear function that is defined by a set of parameters to compute the first output value of the processing node, wherein the back propagating module back propagates errors in output values of later layers of processing nodes to earlier layers of processing nodes by adjusting the set of parameters that define the linear functions of the earlier layers of processing nodes.\\n6. the computing device of claim 1, wherein the first plurality of processing nodes that emulate the boolean and operator and the second plurality of processing nodes that emulate the boolean xnor operator enable the mt network to implement mathematical problems.\\n7. the computing device of claim 1, wherein each of a plurality of processing node layers has a plurality of processing nodes that receive as input values the output values from a plurality of processing nodes in a set of prior layers.\\n8. the computing device of claim 7, wherein each processing node uses a linear function to compute the first output value of the processing node, wherein each processing node\\'s piecewise linear cup function is defined along first and second axes, the first axis defining a range of output values from the processing node\\'s linear function, and the second axis defining a range of output values produced by the piecewise linear cup function for the range of output values from the processing node\\'s linear function.\\n9. the computing device of claim 1, further comprising: a content output circuit for presenting an output based on the processing of the content by the mt network.\\n10. the computing device of claim 9, wherein the captured content is one of an image and an audio segment, and wherein the presented output is an output display on a display screen of the computing device or an audio presentation output on a speaker of the computing device.\\n11. the computing device of claim 10, wherein the computing device is a mobile device.\\n12. the computing device of claim 1, wherein the mt network is a mt neural network and the processing nodes are mt neurons.\\n13. the computing device of claim 1, wherein the set of parameters configured through training for a plurality of the processing nodes comprise at least one of the negative second and third slopes for the second and third linear sections, the positive fourth and fifth slopes for the fourth and fifth linear sections, a first intercept for the second linear section, a second intercept for the fifth linear section, and a set of lengths for at least the second, third, fourth, and fifth sections.\\n14. the computing device of claim 1, wherein the trained set of parameters that define the piecewise linear cup function of each node comprise a plurality of output values.\\n15. the computing device of claim 1, wherein the first and sixth slopes are zero.we claim:\\n1. a system comprising: a memory device to store an input image; a processor including, an image input interface to receive the input image, a pre-processor to model the input image to yield a multi-channel image, a feature extractor to extract a set of features based on the multi-channel image, a feature selector to select one or more features from the set of features of the multi-channel image, wherein the one or more features are selected based on an ability to differentiate features, a feature matcher to match the one or more features to a learned feature set, and a similarity detector to determine whether the one or more features meet a pre-defined similarity threshold.\\n2. the system of claim 1, wherein the pre-processor further is to activate one or more channels of the multi-channel image to yield one or more activated channels.\\n3. the system of claim 2, wherein the one or more activated channels are to be determined based on their ability to differentiate features.\\n4. the system of claim 2, wherein the pre-processor further is to activate one or more local patches of the one or more activated channels.\\n5. the system of claim 4, wherein the one or more local patches are to be determined based on their ability to differentiate features.\\n6. the system of claim 1, wherein the feature matcher further is to utilize a large-scale data learning process to perform the feature matching.\\n7. an apparatus comprising: an image input interface to receive an input image; a pre-processor to model the input image to yield a multi-channel image; a feature extractor to extract a set of features based on the multi-channel image; a feature selector to select one or more features from the set of features of the multi-channel image, wherein the one or more features are selected based on an ability to differentiate features; a feature matcher to match the one or more features to a learned feature set; and a similarity detector to determine whether the one or more features meet a pre-defined similarity threshold.\\n8. the apparatus of claim 7, wherein the pre-processor further is to activate one or more channels of the multi-channel image to yield one or more activated channels.\\n9. the apparatus of claim 8, wherein the one or more activated channels are to be determined based on their ability to differentiate features.\\n10. the apparatus of claim 8, wherein the pre-processor further is to activate one or more local patches of the one or more activated channels.\\n11. the apparatus of claim 10, wherein the one or more local patches are to be determined based on their ability to differentiate features.\\n12. the apparatus of claim 7, wherein the feature matcher further is to utilize a large-scale data learning process to perform the feature matching.\\n13. a method comprising: modeling an input image to yield a multi-channel image; extracting a set of features based on the multi-channel image; selecting one or more features from the set of features of the multi-channel image, wherein the one or more features are selected based on an ability to differentiate features; matching the one or more features to a learned feature set; and determining whether the one or more features meet a pre-defined similarity threshold.\\n14. the method of claim 13, wherein modeling the input image further is to include activating one or more channels of the multi-channel image to yield one or more activated channels.\\n15. the method of claim 14, wherein the one or more activated channels are to be determined based on their ability to differentiate features.\\n16. the method of claim 13, wherein extracting features of the input image further is to include activating one or more local patches of the one or more activated channels.\\n17. the method of claim 16, wherein the one or more local patches are to be determined based on their ability to differentiate features.\\n18. the method of claim 13, wherein the feature matcher utilizes a large-scale data learning process to perform the feature matching.\\n19. at least one non-transitory computer readable storage medium comprising a set of instructions which, when executed by a computing device, cause the computing device to: model an input image to yield a multi-channel image, extract a set of features based on the multi-channel image, select one or more features from the set of features of the multi-channel image, wherein the features are selected based on an ability to differentiate features, match the one or more features to a learned feature set, and determine whether the one or more features meet a pre-defined similarity threshold.\\n20. the at least one non-transitory computer readable storage medium of claim 19, wherein the instructions, when executed, cause a computing device to activate one or more channels of the multi-channel image to yield one or more activated channels.\\n21. the at least one non-transitory computer readable storage medium of claim 20, wherein the instructions, when executed, cause a computing device to determine the one or more activated channels based on their ability to differentiate features.\\n22. the at least one non-transitory computer readable storage medium of claim 20, wherein extracting features of the input image is to further include activating one or more local patches of the one or more activated channels.\\n23. the at least one non-transitory computer readable storage medium of claim 22, wherein the one or more local patches are to be determined based on their ability to differentiate features.\\n24. the at least one non-transitory computer readable storage medium of claim 19, wherein the feature matcher further is to utilize a large-scale data learning process to perform the feature matching.\\n25. an apparatus comprising: means for modeling an input image to yield a multi-channel image, means for extracting a set of features based on the multi-channel image, means for selecting one or more features from the set of features of the multi-channel image, wherein the one or more features are selected based on an ability to differentiate features, means for matching the one or more features to a learned feature set, and means for determining whether the one or more features meet a pre-defined similarity threshold.1. a method for controlling a terminal, the terminal comprising a capturing apparatus and at least one processor, the method comprising: acquiring, by the capturing apparatus, an image; obtaining, by the at least one processor, a motion parameter of the terminal, the motion parameter comprising at least one of a motion frequency or a motion time, and two or more parameters from among an acceleration, an angular velocity, a motion amplitude, the motion frequency, and the motion time; transmitting, by the at least one processor, a parameter threshold obtaining request to a data management server, the parameter threshold obtaining request comprising configuration information of the terminal; receiving corresponding preset thresholds that correspond to the configuration information in response to the parameter threshold obtaining request; comparing the two or more parameters with the corresponding preset thresholds; and controlling, by the at least one processor, not to perform image processing on the acquired image based on at least one of the two or more parameters of the motion parameter being greater than a corresponding preset threshold or based on the two or more parameters of the motion parameter being respectively greater than the corresponding preset thresholds, wherein the acquiring comprises acquiring the image in real time, and the obtaining comprises obtaining the motion parameter of the terminal in real time, the method further comprising: in response to the at least one of the two or more parameters of the motion parameter being greater than the corresponding preset threshold, obtaining the motion parameter of the terminal again; and in response to the two or more parameters of the motion parameter obtained at a latest time being less than or equal to the corresponding preset thresholds, performing the image processing on the image acquired at the latest time.\\n2. the method according to claim 1, wherein the acquiring comprises: controlling, by the at least one processor, to turn on the capturing apparatus based on a face recognition instruction; and acquiring, by the capturing apparatus, a face image when the capturing apparatus is turned on.\\n3. the method according to claim 2, wherein the controlling not to perform the image processing comprises: skipping performing face recognition on the acquired face image based on the at least one of the two or more parameters of the motion parameter being greater than the corresponding preset threshold or based on the two or more parameters of the motion parameter being respectively greater than the corresponding preset thresholds.\\n4. the method according to claim 1, wherein the obtaining comprises at least one of: obtaining the acceleration of the terminal by using an acceleration sensor; or obtaining the angular velocity of the terminal by using a gyro sensor.\\n5. the method according to claim 1, wherein the transmitting comprises: transmitting the parameter threshold obtaining request to the data management server according to a preset time period.\\n6. the method according to claim 1, further comprising: generating prompt information based on the at least one of the two or more parameters of the motion parameter being greater than the corresponding preset threshold, the prompt information being used for prompting the terminal to stop moving.\\n7. the method according to claim 1, wherein the motion parameter comprises the motion frequency and the motion time.\\n8. a terminal comprising: a capturing apparatus; at least one memory configured to store program code; and at least one processor configured to access the at least one memory and operate according to the program code, the program code comprising: motion parameter obtaining code configured to cause the at least one processor to acquire an image by using the capturing apparatus and obtain a motion parameter of the terminal, the motion parameter comprising at least one of a motion frequency or a motion time, and two or more parameters from among an acceleration, an angular velocity, a motion amplitude, the motion frequency, and the motion time; request transmitting code configured to cause the at least one processor to transmit a parameter threshold obtaining request to a data management server, the parameter threshold obtaining request comprising configuration information of the terminal; parameter threshold receiving code configured to cause the at least one processor to receive corresponding preset thresholds that correspond to the configuration information in response to the parameter threshold obtaining request; comparing code configured to cause the at least one processor to compare the two or more parameters with the corresponding preset thresholds; and control code configured to cause the at least one processor not to perform image processing on the acquired image based on at least one of the two or more parameters of the motion parameter being greater than a corresponding preset threshold or based on the two or more parameters of the motion parameter being respectively greater than the corresponding preset thresholds, wherein the motion parameter obtaining code causes the at least one processor to: acquire the image in real time and obtain the motion parameter of the terminal in real time, and in response to the at least one of the two or more parameters of the motion parameter being greater than the corresponding preset threshold, obtain the motion parameter of the terminal again, and wherein the control code causes the at least one processor to, in response to the two or more parameters of the motion parameter obtained at a latest time being less than or equal to the corresponding preset thresholds, perform the image processing on the image acquired at the latest time.\\n9. the terminal according to claim 8, wherein the program code further comprises face instruction receiving code configured to cause the at least one processor to receive a face recognition instruction, wherein the motion parameter obtaining code causes the at least one processor to control, according to the face recognition instruction, the capturing apparatus to turn on, and acquire a face image by using the capturing apparatus when the capturing apparatus is turned on; and wherein the control code causes the at least one processor to skip performing face recognition on the acquired face image based on the at least one of the two or more parameters of the motion parameter being greater than the corresponding preset threshold or based on the two or more parameters of the motion parameter being respectively greater than the corresponding preset thresholds.\\n10. the terminal according to claim 8, wherein the request transmitting code causes the at least one processor to transmit the parameter threshold obtaining request to the data management server according to a preset time period.\\n11. the terminal according to claim 8, wherein the program code further comprises: prompt information generation code configured to cause the at least one processor to generate prompt information based on at least one of the two or more parameters of the motion parameter being greater than the corresponding preset threshold, the prompt information being used for prompting the terminal to stop moving.\\n12. the terminal according to claim 8, wherein the motion parameter comprises the motion frequency and the motion time.\\n13. a non-transitory computer-readable storage medium, storing a machine instruction, which, when executed by one or more processors, causes the one or more processors to perform: obtaining an image acquired by a capturing apparatus; obtaining a motion parameter of a terminal, the terminal comprising the capturing apparatus, the motion parameter comprising at least one of a motion frequency or a motion time, and two or more parameters from among an acceleration, an angular velocity, a motion amplitude, the motion frequency, and the motion time; transmitting a parameter threshold obtaining request to a data management server, the parameter threshold obtaining request comprising configuration information of the terminal; receiving corresponding preset thresholds that correspond to the configuration information in response to the parameter threshold obtaining request; comparing the two or more parameters with the corresponding preset thresholds; and controlling not to perform image processing on an acquired image based on at least one of the two or more parameters of the motion parameter being greater than a corresponding preset threshold or based on the two or more parameters of the motion parameter being respectively greater than the corresponding preset thresholds, wherein the acquiring comprises acquiring the image in real time, and the obtaining comprises obtaining the motion parameter of the terminal in real time, the method further comprising: in response to the at least one of the two or more parameters of the motion parameter being greater than the corresponding preset threshold, obtaining the motion parameter of the terminal again; and in response to the two or more parameters of the motion parameter obtained at a latest time being less than or equal to the corresponding preset thresholds, performing the image processing on the image acquired at the latest time.\\n14. the non-transitory computer-readable storage medium according to claim 13, wherein the acquired image is a face image and the image processing comprises performing face recognition.\\n15. the non-transitory computer-readable storage medium according to claim 13, wherein the obtaining the motion parameter comprises at least one of: obtaining the acceleration of the terminal by using an acceleration sensor; or obtaining the angular velocity of the terminal by using a gyro sensor.\\n16. the non-transitory computer-readable storage medium according to claim 13, wherein the motion parameter comprises the motion frequency and the motion time.1. a method of processing a drive-through order, the method comprising: receiving customer information detected through vision recognition; providing product information to a customer based on the customer information; and processing a product order of the customer.\\n2. the method according to claim 1, wherein the receiving of customer information comprises at least one of receiving customer information associated with vehicle information detected through vehicle recognition, or receiving customer information associated with identification information detected through face recognition.\\n3. the method according to claim 1, further comprising determining whether the customer is a pre-order customer based on the customer information, wherein when the customer is determined to be a pre-order customer: the providing of product information based on the customer information comprises providing pre-order information using at least one of audio or video, and the processing of the product order of the customer comprises: providing information for promptly guiding a vehicle to a pickup stand using at least one of audio or video, and providing information that an additional order is available.\\n4. the method according to claim 1, wherein the product information based on the customer information comprises a most recently ordered product component and a most frequently ordered product component in an order history of the customer information.\\n5. the method according to claim 1, wherein the receiving of customer information comprises receiving information about an age and gender of a passenger detected through face recognition, and the providing of product information to a customer based on the customer information comprises providing recommended menu information differentiated according to the age and gender.\\n6. the method according to claim 1, wherein the processing of a product order of the customer comprises determining a product component in a past order history or a component modified from the product component as a product order.\\n7. the method according to claim 1, wherein the processing of a product order of the customer comprises paying a product price according to biometrics-based authentication through a communication system of a vehicle or a mobile terminal.\\n8. the method according to claim 1, wherein the processing of a product order of the customer comprises: issuing a payment number for a divided payment, and performing the divided payments according to payment requests of a plurality of mobile terminals to which the payment numbers are inputted.\\n9. the method according to claim 8, wherein the processing of a product order of the customer further comprises accumulating mileage in an account corresponding to the mobile terminal undergoing a payment.\\n10. the method according to claim 1, wherein the processing of a product order of the customer further comprises suggesting a takeout packaging method according to a temperature of a product, an atmospheric temperature, weather, and a vehicle type.\\n11. an apparatus configured to process a drive-through order, the apparatus comprising: a transceiver configured to receive customer information detected through vision recognition; a digital signage configured to provide product information to a customer based on the customer information; and a processor configured to process a product order of the customer.\\n12. the apparatus according to claim 11, wherein the transceiver receives at least one of customer information associated with vehicle information detected through vehicle recognition, or customer information associated with identification information detected through face recognition.\\n13. the apparatus according to claim 11, wherein the processor is configured to: determine whether the customer is a pre-order customer based on the customer information; and when the customer is determined to be a pre-order customer, perform a control operation to provide pre-order information, and control the digital signage to output information for promptly guiding a vehicle to a pickup stand and provide information that an additional order is available.\\n14. the apparatus according to claim 11, wherein the product information based on the customer information comprises a most recently ordered product component and a most frequently ordered product component in an order history of the customer information.\\n15. the apparatus according to claim 11, wherein the transceiver is configured to receive information about an age and gender of a passenger detected through face recognition, and the processor is configured to control the digital signage to provide recommended menu information differentiated according to the age and gender.\\n16. the apparatus according to claim 11, wherein the processor is configured to determine a product component in a past order history or a component modified from the product component as the product order.\\n17. the apparatus according to claim 11, wherein the processor is configured to pay a product price according to biometrics-based authentication through a communication system of a vehicle or a mobile terminal.\\n18. the apparatus according to claim 11, wherein the processor is configured to: issue a payment number for a divided payment; and perform the divided payments according to requests of a plurality of mobile terminals to which the payment numbers are inputted.\\n19. the apparatus according to claim 18, wherein the processor is configured to accumulate mileage in an account corresponding to the mobile terminal undergoing a payment.\\n20. the apparatus according to claim 11, wherein the processor is configured to control the digital signage to suggest a takeout packaging method according to a temperature of a product, an atmospheric temperature, weather, and a vehicle type.1. an image information processing method performed at a computing device having one or more processors and memory storing a plurality of programs to be executed by the one or more processors, the method comprising: identifying, using face recognition, one or more faces, each face corresponding to a respective person captured in a first image; for each identified face: extracting a set of profile parameters of a corresponding person in the first image; and selecting, from a plurality of image tiles, a first image tile that matches the face of the corresponding person in the first image in accordance with a predefined correspondence between the set of profile parameters of the corresponding person and a set of pre-stored description parameters of the first image tile; generating a second image by covering the faces of respective persons in the first image with their corresponding first image tiles; and sharing the first image and the second image in a predefined order via a group chat session.\\n2. the method of claim 1, wherein the first image and the second image are displayed in the group chat session one image at a time such that one of the two images is replaced by the other of the two images periodically.\\n3. the method of claim 1, wherein extracting a set of profile parameters of a corresponding person in the first image includes: determining one or more descriptive labels corresponding to the identified face of the corresponding person using a first machine learning model, wherein the first machine learning model is trained with the facial images and corresponding descriptive labels.\\n4. the method of claim 1, wherein extracting a set of profile parameters of a corresponding person in the first image includes: determining an identity of the corresponding person based on the identified face of the corresponding person; locating respective profile information of the first person based on the determined identity of the corresponding person; and using one or more characteristics in the respective profile information of the first person as the set of profile parameters corresponding to the identified face of the corresponding person.\\n5. the method of claim 1, wherein at least a first one of the first image tiles is a dynamic image tile and at least a second one of the first image tiles is a static image tile.\\n6. the method of claim 1, including: receiving a plurality of user comments from different users of the group chat session, each user comment including a descriptive term for a respective person identified in the first image; choosing a descriptive label for the respective person according to the plurality of user comments; and updating the second image by adding the descriptive label adjacent to the first image tile of the respective person.\\n7. a computing device for image information processing, comprising: one or more processors; and memory storing instructions which, when executed by the one or more processors, cause the processors to perform a plurality of operations comprising: identifying, using face recognition, one or more faces, each face corresponding to a respective person captured in a first image; for each identified face: extracting a set of profile parameters of a corresponding person in the first image; and selecting, from a plurality of image tiles, a first image tile that matches the face of the corresponding person in the first image in accordance with a predefined correspondence between the set of profile parameters of the corresponding person and a set of pre-stored description parameters of the first image tile; generating a second image by covering the faces of respective persons in the first image with their corresponding first image tiles; and sharing the first image and the second image in a predefined order via a group chat session.\\n8. the computing device of claim 7, wherein the first image and the second image are displayed in the group chat session one image at a time such that one of the two images is replaced by the other of the two images periodically.\\n9. the computing device of claim 7, wherein extracting a set of profile parameters of a corresponding person in the first image includes: determining one or more descriptive labels corresponding to the identified face of the corresponding person using a first machine learning model, wherein the first machine learning model is trained with the facial images and corresponding descriptive labels.\\n10. the computing device of claim 7, wherein extracting a set of profile parameters of a corresponding person in the first image includes: determining an identity of the corresponding person based on the identified face of the corresponding person; locating respective profile information of the first person based on the determined identity of the corresponding person; and using one or more characteristics in the respective profile information of the first person as the set of profile parameters corresponding to the identified face of the corresponding person.\\n11. the computing device of claim 7, wherein at least a first one of the first image tiles is a dynamic image tile and at least a second one of the first image tiles is a static image tile.\\n12. the computing device of claim 7, wherein the plurality of operations further include: receiving a plurality of user comments from different users of the group chat session, each user comment including a descriptive term for a respective person identified in the first image; choosing a descriptive label for the respective person according to the plurality of user comments; and updating the second image by adding the descriptive label adjacent to the first image tile of the respective person.\\n13. a non-transitory computer-readable storage medium storing instructions which, when executed by a computing device having one or more processors, cause the computing device to perform a plurality of operations comprising: identifying, using face recognition, one or more faces, each face corresponding to a respective person captured in a first image; for each identified face: extracting a set of profile parameters of a corresponding person in the first image; and selecting, from a plurality of image tiles, a first image tile that matches the face of the corresponding person in the first image in accordance with a predefined correspondence between the set of profile parameters of the corresponding person and a set of pre-stored description parameters of the first image tile; generating a second image by covering the faces of respective persons in the first image with their corresponding first image tiles; and sharing the first image and the second image in a predefined order via a group chat session.\\n14. the non-transitory computer-readable storage medium of claim 13, wherein the first image and the second image are displayed in the group chat session one image at a time such that one of the two images is replaced by the other of the two images periodically.\\n15. the non-transitory computer-readable storage medium of claim 13, wherein extracting a set of profile parameters of a corresponding person in the first image includes: determining one or more descriptive labels corresponding to the identified face of the corresponding person using a first machine learning model, wherein the first machine learning model is trained with the facial images and corresponding descriptive labels.\\n16. the non-transitory computer-readable storage medium of claim 13, wherein extracting a set of profile parameters of a corresponding person in the first image includes: determining an identity of the corresponding person based on the identified face of the corresponding person; locating respective profile information of the first person based on the determined identity of the corresponding person; and using one or more characteristics in the respective profile information of the first person as the set of profile parameters corresponding to the identified face of the corresponding person.\\n17. the non-transitory computer-readable storage medium of claim 13, wherein at least a first one of the first image tiles is a dynamic image tile and at least a second one of the first image tiles is a static image tile.\\n18. the non-transitory computer-readable storage medium of claim 13, wherein the plurality of operations further include: receiving a plurality of user comments from different users of the group chat session, each user comment including a descriptive term for a respective person identified in the first image; choosing a descriptive label for the respective person according to the plurality of user comments; and updating the second image by adding the descriptive label adjacent to the first image tile of the respective person.1. a method comprising, by a computing system: determining that a performance metric of an eye tracking system is below a first performance threshold, wherein the eye tracking system is associated with a head-mounted display worn by a user; based on the determination of the performance metric of the eye tracking system being below the first performance threshold, the computer system performing: receiving one or more first inputs associated with a body of the user; estimating a region that the user is looking at within a field of view of the head-mounted display based on the received one or more first inputs associated with the body of the user; determining a vergence distance of the user based at least on the one or more first inputs associated with the body of the user, the estimated region that the user is looking at, and locations of one or more objects in a scene displayed by the head-mounted display; and adjusting one or more configurations of the head-mounted display based on the determined vergence distance of the user.\\n2. the method of claim 1, wherein the one or more configurations of the head-mounted display comprise one or more of: a rendering image; a position of a display screen; or a position of an optics block.\\n3. the method of claim 1, further comprising: determining that the performance metric of the eye tracking system is above a second performance threshold; receiving eye tracking data from the eye tracking system; and determining the vergence distance of the user based on the eye tracking data and the one or more first inputs associated with the body of the user.\\n4. the method of claim 3, further comprising: receiving one or more second inputs associated with one or more displaying elements in the scene displayed by the head-mounted display; and determining the vergence distance of the user based at least on the eye tracking data, the one or more first inputs associated with the body of the user, and the one or more second inputs associated with the one or more displaying elements of the scene.\\n5. the method of claim 4, further comprising: feeding the one or more first inputs associated with the body of the user to a fusion algorithm, wherein the fusion algorithm assigns a weight score to each input of the one or more first inputs; determining the vergence distance of the user using the fusion algorithm based on the one or more first inputs associated with the body of the user; and determining a z-depth of a display screen and a confidence score based on the one or more first inputs associated with the body of the user\\n6. the method of claim 5, further comprising: comparing the confidence score to a confidence level threshold; in response to a determination that the confidence score is below the confidence level threshold, feeding the one or more second inputs associated with the one or more displaying elements of the scene to the fusion algorithm; and determining the z-depth of the display screen using the fusion algorithm based on the one or more first inputs associated with the body of the user and the one or more second inputs associated with the one or more displaying elements of the scene.\\n7. the method of claim 6, further comparing: comparing, by the fusion algorithm, confidence scores associated with a plurality of combinations of inputs; and determining, by the fusion algorithm, the z-depth of the display screen based on a combination of inputs associated with a highest confidence score.\\n8. the method of claim 6, wherein the z-depth and the confidence score are determined by the fusion algorithm using a piecewise comparison of the one or more first inputs and the one or more second inputs.\\n9. the method of claim 6, wherein the z-depth and the confidence score are determined based on a correlation between two or more inputs of the one or more first inputs and the one or more second inputs.\\n10. the method of claim 5, wherein the fusion algorithm comprises a machine learning (ml) algorithm, and wherein the machine learning (ml) algorithm determines a combination of first inputs fed to the fusion algorithm.\\n11. the method of claim 4, wherein the one or more first inputs associated with the body of the user comprise one or more of: a hand position; a hand direction; a hand movement; a hand gesture; a head position; a head direction; a head movement; a head gesture; a gaze angle; rea body gesture; a body posture; a body movement; a behavior of the user; or a weighted combination of one or more related parameters.\\n12. the method of claim 11, wherein the one or more first inputs associated with the body of the user are received from one or more of: a controller; a sensor; a camera; a microphone; an accelerometer; a headset worn by the user; or a mobile device.\\n13. the method of claim 4, wherein the one or more second inputs associated with the one or more displaying elements comprise one or more of: a z-buffer value associated with a displaying element; a displaying element marked by a developer; an image analysis result; a shape of a displaying element; a face recognition result; an object recognition result; a person identified in a displaying content; an object identified in a displaying content; a correlation of two or more displaying elements; or a weighted combination of the one or more second inputs.\\n14. the method of claim 1, further comprising: determining that the performance metric of the eye tracking system is below a second performance threshold; receiving one or more second inputs associated with one or more displaying elements in the scene displayed by the head-mounted display; and determining the vergence distance of the user based at least on the one or more first inputs associated with the body of the user and the one or more second inputs associated with the one or more displaying elements.\\n15. the method of claim 14, wherein determining that the performance metric of the eye tracking system is below the second performance threshold comprises determining that the eye tracking system does not exist or fails to provide eye tracking data.\\n16. the method of claim 1, wherein the performance metric of the eye tracking system comprises one or more of: an accuracy of a parameter from the eye tracking system; a precision of a parameter from the eye tracking system; a value of a parameter from the eye tracking system; a detectability of a pupil; a metric based on one or more parameters associated with the user; a parameter change; a parameter changing trend; a data availability; or a weighted combination of one or more performance related parameters.\\n17. the method of claim 16, wherein the one or more parameters associated with the user comprise one or more of: an eye distance of the user; a pupil position; a pupil status; a correlation of two pupils of the user; a head size of the user; a position of a headset worn by the user; an angle of the headset worn by the user; a direction of the headset worn by the user; an alignment of the eyes of the user; or a weighted combination of one or more related parameters associated with the user.\\n18. the method of claim 1, wherein the first performance threshold comprises one or more of: a pre-determined value; a pre-determined range; a state of a data; a changing speed of a data; or a trend of a data change.\\n19. one or more non-transitory computer-readable storage media embodying software that is operable when executed by a computing system to: determine that a performance metric of an eye tracking system is below a first performance threshold, wherein the eye tracking system is associated with a head-mounted display worn by a user; based on the determination of the performance metric of the eye tracking system being below the first performance threshold, the media embodying software operable when executed by the computing system to: receive one or more first inputs associated with a body of the user; estimate a region that the user is looking at within a field of view of the head-mounted display based on the received one or more first inputs associated with the body of the user; determine a vergence distance of the user based at least on the one or more first inputs associated with the body of the user, the estimated region that the user is looking at, and locations of one or more objects in a scene displayed by the head-mounted display; and adjust one or more configurations of the head-mounted display based on the determined vergence distance of the user.\\n20. a system comprising: one or more non-transitory computer-readable storage media embodying instructions; one or more processors coupled to the storage media and operable to execute the instructions to: determine that a performance metric of an eye tracking system is below a first performance threshold, wherein the eye tracking system is associated with a head-mounted display worn by a user; based on the determination of the performance metric of the eye tracking system being below the first performance threshold, the system is configured to: receive one or more first inputs associated with a body of the user; estimate a region that the user is looking at within a field of view of the head-mounted display based on the received one or more first inputs associated with the body of the user; determine a vergence distance of the user based at least on the one or more first inputs associated with the body of the user, the estimated region that the user is looking at, and locations of one or more objects in a scene displayed by the head-mounted display; and adjust one or more configurations of the head-mounted display based on the determined vergence distance of the user.1. a computer-implemented method for image-based, self-guided object detection, comprising: receiving, by a processor device, a set of images, each of the images having a respective grid thereon that is labeled regarding a respective object to be detected using grid level label data; training, by the processor device, a grid-based object detector using the grid level label data; determining, by the processor device, a respective bounding box for the respective object in each of the images, by applying local segmentation to each of the images; and training, by the processor device, a region-based convolutional neural network (rcnn) for joint object localization and object classification using the respective bounding box for the respective object in each of the images as an input to the rcnn.\\n2. the computer-implemented method of claim 1, further comprising performing an action responsive to the object localization and object classification for a respective new object in a new image to which the rcnn is applied.\\n3. the computer-implemented method of claim 2, wherein the action comprises autonomously controlling a motor vehicle to avoid a collision with the new object responsive to the object localization and object classification for the respective new object.\\n4. the computer-implemented method of claim 1, wherein the local segmentation is performed using a self-similarity search and template matching to provide the respective bounding box around the respective object in the set of images.\\n5. the computer-implemented method of claim 1, wherein the local segmentation is applied to each of the images to segment a respective target region therein.\\n6. the computer-implemented method of claim 1, wherein the region-based convolutional neural network (rcnn) forms a model during an object training stage that is to detect objects in new images during an inference stage.\\n7. the computer-implemented method of claim 1, wherein the method is performed by a system selected from the group consisting of a surveillance system, a face detection system, a face recognition system, a cancer detection system, an object tracking system, and an advanced driver-assistance system.\\n8. a computer program product for image-based, self-guided object detection, the computer program product comprising a non-transitory computer readable storage medium having program instructions embodied therewith, the program instructions executable by a computer to cause the computer to perform a method comprising: receiving, by a processor device, a set of images, each of the images having a respective grid thereon that is labeled regarding a respective object to be detected using grid level label data; training, by the processor device, a grid-based object detector using the grid level label data; determining, by the processor device, a respective bounding box for the respective object in each of the images, by applying local segmentation to each of the images; and training, by the processor device, a region-based convolutional neural network (rcnn) for joint object localization and object classification using the respective bounding box for the respective object in each of the images as an input to the rcnn.\\n9. the computer program product of claim 8, wherein the method further comprises performing an action responsive to the object localization and object classification for a respective new object in a new image to which the rcnn is applied.\\n10. the computer program product of claim 9, wherein the action comprises autonomously controlling a motor vehicle to avoid a collision with the new object responsive to the object localization and object classification for the respective new object.\\n11. the computer program product of claim 8, wherein the local segmentation is performed using a self-similarity search and template matching to provide the respective bounding box around the respective object in the set of images.\\n12. the computer program product of claim 8, wherein the local segmentation is applied to each of the images to segment a respective target region therein.\\n13. the computer program product of claim 8, wherein the region-based convolutional neural network (rcnn) forms a model during an object training stage that is to detect objects in new images during an inference stage.\\n14. the computer program product of claim 8, wherein the method is performed by a system selected from the group consisting of a surveillance system, a face detection system, a face recognition system, a cancer detection system, an object tracking system, and an advanced driver-assistance system.\\n15. a computer processing system for image-based, self-guided object detection, comprising: a memory device for storing program code; and a processor device for running the program code to receive a set of images, each of the images having a respective grid thereon that is labeled regarding a respective object to be detected using grid level label data; train a grid-based object detector using the grid level label data; determine a respective bounding box for the respective object in each of the images, by applying local segmentation to each of the images; and train a region-based convolutional neural network (rcnn) for joint object localization and object classification using the respective bounding box for the respective object in each of the images as an input to the rcnn.\\n16. the computer processing system of claim 15, wherein the processor device further runs the program code to perform an action responsive to the object localization and object classification for a respective new object in a new image to which the rcnn is applied.\\n17. the computer processing system of claim 16, wherein the action comprises autonomously controlling a motor vehicle to avoid a collision with the new object responsive to the object localization and object classification for the respective new object.\\n18. the computer processing system of claim 15, wherein the local segmentation is performed using a self-similarity search and template matching to provide the respective bounding box around the respective object in the set of images.\\n19. the computer processing system of claim 15, wherein the region-based convolutional neural network (rcnn) forms a model during an object training stage that is to detect objects in new images during an inference stage.\\n20. the computer processing system of claim 15, wherein the computer processing system is comprised in a system selected from the group consisting of a surveillance system, a face detection system, a face recognition system, a cancer detection system, an object tracking system, and an advanced driver-assistance system.1. a method of scalable, parallel, cloud-based face recognition utilizing a database of normalized stored images, comprising: capturing an image using a camera; detecting a face in the captured image; normalizing the detected facial image to match the normalized stored images; identifying facial features in the normalized detected facial image; generating a plurality of facial metrics from the facial features; calculating euclidean distances between the facial metrics of the normalized detected facial image with corresponding facial metrics of each of the stored images; comparing each euclidean distance against a predetermined threshold; responsive to the euclidean distance comparison, producing a reduced candidate list of best possible image matches from the normalized stored images; comparing, in parallel, the normalized detected facial image with each of the normalized stored images of the reduced candidate list utilizing a plurality of face recognition algorithms, where each processor of a parallel processing system uses a different face recognition algorithm; responsive to the comparison, producing best match results from each parallel subset of the reduced candidate list; and selecting a final match from the best match results using a deep learning neural network face recognition algorithm trained on outputs of individual face recognition algorithms.\\n2. the method of scalable, parallel, cloud-based face recognition of claim 1, wherein detecting a face in the captured image comprises: utilizing opencv to detect a face in the captured image; extracting the location of the eyes and a tip of the nose in the face; determining a distance between the eyes; cropping the face from the captured image, where the width and the height of a cropped face image is a function of the distance between the eyes; and rotating the face by an angle of rotation that is a function of the distance between the eyes.\\n3. the method of scalable, parallel, cloud-based face recognition of claim 2, wherein: the width of the cropped face image is 2.5 times the distance between the eyes; the height of the cropped face image is 3.5 times the distance between the eyes; and the angle of rotation is an angle formed by a straight line joining the eyes and an x-axis of the face.\\n4. the method of scalable, parallel, cloud-based face recognition of claim 3, wherein rotating the face comprises rotating the face to provide a frontal face pattern.\\n5. the method of scalable, parallel, cloud-based face recognition of claim 4, further comprising the step of proportionally rescaling the cropped and rotated image.\\n6. the method of scalable, parallel, cloud-based face recognition of claim 5, where the proportional rescaling yields a cropped and rotated image with a size of 100=100 pixels.\\n7. the method of scalable, parallel, cloud-based face recognition of claim 1, wherein the facial features identified in the normalized detected facial image comprise a pair of eyes, a tip of a nose, a mouth, a center of the mouth, and a chin area comprising a bottom, a top left landmark, and a top right landmark.\\n8. the method of scalable, parallel, cloud-based face recognition of claim 7, wherein generating a plurality of facial metrics comprises: calculating a distance between the pair of eyes, a distance between the eyes and the tip of the nose, a distance equal to the width of the mouth, a distance between the tip of the nose and the center of mouth, a distance between the bottom of chin and the center of mouth, a distance between the top left landmark on the chin and the tip of the nose, and a distance between the top right landmark on the chin and the tip of the nose.\\n9. the method of scalable, parallel, cloud-based face recognition of claim 8, wherein performing a euclidean distance match further comprises: partitioning the normalized stored images into a plurality of substantially equal subsets; performing a euclidean distance match between the facial metrics of the normalized detected facial image and corresponding facial metrics of each of the stored images of the subsets of the normalized stored images with a separate processor of a parallel processing system to generate a euclidean distance for each stored image of the subset; comparing each euclidean distance against a predetermined threshold with the separate processors; responsive to the euclidean distance comparison, producing a reduced candidate list of best possible image matches from the normalized stored images of each subset; and combining the reduced candidate lists from each subset to produce a single reduced candidate list.\\n10. the method of scalable, parallel, cloud-based face recognition of claim 9, wherein the plurality of face recognition algorithms utilized in comparing, in parallel, the normalized detected facial image with each of the normalized stored images of the reduced candidate list, consists of face recognition algorithms selected from a group consisting of principle component analysis (pca)-based algorithms, linear discriminant analysis (lda) algorithms, independent component analysis (ica) algorithms, kernel-based algorithms, feature-based techniques, algorithms based on neural networks, algorithms based on transforms, and model-based face recognition algorithms.\\n11. the method of scalable, parallel, cloud-based face recognition of claim 10, wherein the pca-based algorithms include eigenfaces for face detection/recognition, and the lda algorithms include the fisherfaces method of face recognition.\\n12. the method of scalable, parallel, cloud-based face recognition of claim 1, wherein comparing, in parallel, the captured image with each of the normalized stored images of the reduced candidate list further comprises: partitioning the reduced candidate list into a plurality of substantially equal subsets; processing each subset in a different processor of the parallel processing system uses a unique face recognition algorithm to produce the best match results; and using a reduce function of a mapreduce program to combine the best match results from each of the subsets to produce a single set of the best match results.\\n13. the method of scalable, parallel, cloud-based face recognition of claim 12, wherein partitioning the reduced candidate list comprises: selecting the images comprising each subset by optimizing the variance between of each of the images according to the following equation: where m and n are the number of rows and columns of the face vector image, n is the number of groups, and σij is the standard deviation of image dimension i in the group j of the face image vector.\\n14. the method of scalable, parallel, cloud-based face recognition of claim 13, wherein selecting the images comprising each subset by optimizing the variance between each of the images according to the following equation: d(μi, μj) is the euclidean distance between the mean of the group i and the mean of group j, i is the face image vector, and l is the number of group levels.\\n15. the method of scalable, parallel, cloud-based face recognition of claim 1, where selecting a final match from the best match results utilizing a deep learning neural network face recognition algorithm comprises utilizing either an adaboost machine-learning algorithm or a neural networks machine-learning model.\\n16. the method of scalable, parallel, cloud-based face recognition of claim 1, where normalizing the detected facial image to match the normalized stored images includes normalizing the detected facial image to the same size, orientation, and illumination of the normalized stored images.\\n17. a non-transitory computer-readable medium containing executable program instructions for causing a computer to perform a method of face recognition, the method comprising: detecting a face in an image captured by a camera; normalizing the detected facial image to match the normalized stored images; identifying facial features in the normalized detected facial image; generating a plurality of facial metrics from the facial features; calculating euclidean distances between the facial metrics of the normalized detected facial image with corresponding facial metrics of each of the stored images; comparing each euclidean distance against a predetermined threshold; responsive to the euclidean distance comparison, producing a reduced candidate list of best possible image matches from the normalized stored images; comparing, in parallel, the captured image with each of the normalized stored images of the reduced candidate list utilizing a plurality of face recognition algorithms, where each processor of a parallel processing system uses a different face recognition algorithm; responsive to the comparison, producing best match results from each parallel subset of the reduced candidate list; and selecting a final match from the best match results using a deep learning neural network face recognition algorithm trained on outputs of individual face recognition algorithms.\\n18. the non-transitory computer-readable medium containing executable program instructions of claim 17, wherein the plurality of face recognition algorithms utilized in comparing, in parallel, the normalized detected facial image with each of the normalized stored images of the reduced candidate list, consists of face recognition algorithms selected from a group consisting of principle component analysis (pca)-based algorithms, linear discriminant analysis (lda) algorithms, independent component analysis (ica) algorithms, kernel-based algorithms, feature-based techniques, algorithms based on neural networks, algorithms based on transforms, and model-based face recognition algorithms.\\n19. the non-transitory computer-readable medium containing executable program instructions of claim 18, wherein the pca-based algorithms include eigenfaces for face detection/recognition, and the lda algorithms include the fisherfaces method of face recognition.\\n20. the non-transitory computer-readable medium containing executable program instructions of claim 17, where selecting a final match from the best match results utilizing a deep learning neural network face recognition algorithm comprises utilizing either an adaboost machine-learning algorithm or a neural networks machine-learning model.1. an imaging device, comprising: a condensing lens; an image sensor configured to detect light passing through the condensing lens and comprising a pixel matrix, wherein the pixel matrix comprises a plurality of phase detection pixel pairs and a plurality of regular pixels; and a processor configured to turn on the phase detection pixel pairs for autofocusing and output autofocused pixel data after completing the autofocusing, divide the autofocused pixel data into a first subframe and a second subframe, calculate image features of at least one of the first subframe and the second subframe, wherein the image features comprise module widths of a finder pattern, and the finder pattern has a predetermined ratio, a harr-like feature, or a gabor feature, and determine an operating resolution of the regular pixels according to the image features calculated from at least one of the first subframe and the second subframe divided from the autofocused pixel data.\\n2. the imaging device as claimed in claim 1, wherein each of the phase detection pixel pairs comprises: a first pixel and a second pixel; a cover layer covering upon a first region of the first pixel and upon a second region of the second pixel, wherein the first region and the second region are mirror symmetrical to each other; and a microlens aligned with at least one of the first pixel and the second pixel.\\n3. the imaging device as claimed in claim 2, wherein the first region and the second region are 5% to 95% of an area of a single pixel.\\n4. the imaging device as claimed in claim 1, wherein the processor is configured to perform the autofocusing using a dual pixel autofocus technique according to pixel data of the phase detection pixel pairs before completing the autofocusing.\\n5. the imaging device as claimed in claim 1, wherein the processor is configured to divide pixel data of the phase detection pixel pairs into a third subframe and a fourth subframe before completing the autofocusing, and perform the autofocusing according to the third subframe and the fourth subframe.\\n6. the imaging device as claimed in claim 5, wherein the processor is further configured to calibrate brightness of the third subframe and the fourth subframe to be identical using a shading algorithm.\\n7. the imaging device as claimed in claim 1, wherein the operating resolution is selected as a first resolution smaller than a number of the regular pixels or as a second resolution larger than the first resolution.\\n8. the imaging device as claimed in claim 1, wherein the regular pixels are turned off in the autofocusing.\\n9. the imaging device as claimed in claim 1, wherein a number of the phase detection pixel pairs is smaller than that of the regular pixels.\\n10. an imaging device, comprising: a condensing lens; an image sensor configured to detect light passing through the condensing lens and comprising a pixel matrix, wherein the pixel matrix comprises a plurality of phase detection pixel pairs and a plurality of regular pixels; and a processor configured to turn on the phase detection pixel pairs for autofocusing and output autofocused pixel data after completing the autofocusing, divide the autofocused pixel data into a first subframe and a second subframe, calculate image features of at least one of the first subframe and the second subframe, wherein the image features comprise module widths of a finder pattern, and the finder pattern has a predetermined ratio, a harr-like feature, or a gabor feature, and select an image decoding or an image recognition using pixel data of the regular pixels according to the image features calculated from at least one of the first subframe and the second subframe divided from the autofocused pixel data.\\n11. the imaging device as claimed in claim 10, wherein each of the phase detection pixel pairs comprises: a first pixel and a second pixel; a cover layer covering upon a first region of the first pixel and upon a second region of the second pixel, wherein the first region and the second region are mirror symmetrical to each other; and a microlens aligned with at least one of the first pixel and the second pixel.\\n12. the imaging device as claimed in claim 10, wherein the processor is configured to perform the autofocusing using a dual pixel autofocus technique according to pixel data of the phase detection pixel pairs before completing the autofocusing.\\n13. the imaging device as claimed in claim 10, wherein the processor is configured to divide the pixel data of the phase detection pixel pairs into a third subframe and a fourth subframe before completing the autofocusing, calibrate brightness of the third subframe and the fourth subframe to be identical using a shading algorithm, and perform the autofocusing according to the third subframe and the fourth subframe.\\n14. the imaging device as claimed in claim 10, wherein the processor is configured to calculate the image features using at least one of a rule based algorithm and a machine learning algorithm.\\n15. the imaging device as claimed in claim 10, wherein the image decoding is decoding qr codes, and the image recognition is face recognition.\\n16. an operating method of an imaging device, the imaging device comprising a plurality of phase detection pixel pairs and a plurality of regular pixels, the operating method comprising: turning on the phase detection pixel pairs for autofocusing and outputting autofocused image frame after completing the autofocusing; dividing the autofocused image frame, acquired by the phase detection pixel pairs, into a first subframe and a second subframe; calculating image features of at least one of the first subframe and the second subframe, wherein the image feature comprise module widths of a finder pattern, and the finder pattern has a predetermined ratio, a harr-like feature, or a gabor feature; and selectively activating at least a part of the regular pixels according to the image features calculated from at least one of the first subframe and the second subframe divided from the autofocused image frame.\\n17. the operating method as claimed in claim 16, wherein the selectively activating comprises: activating a first part of the regular pixels to perform an image decoding according to pixel data of the first part of the regular pixels; or activating all the regular pixels to perform an image recognition according to pixel data of the all regular pixels.\\n18. the operating method as claimed in claim 17, wherein pixel data of the phase detection pixel pairs captured in a same frame with the pixel data of the regular pixels is also used in performing the image decoding and the image recognition.\\n19. the operating method as claimed in claim 17, wherein the image decoding is decoding qr codes, and the image recognition is face recognition.\\n20. the operating method as claimed in claim 16, wherein the phase detection pixel pairs are partially covered pixels or have a structure of dual pixel.1. an apparatus comprising: a first camera module configured to obtain a first image of an object with a first field of view; a second camera module configured to obtain a second image of the object with a second field of view different from the first field of view; a first depth map generator configured to generate a first depth map of the first image based on the first image and the second image; and a second depth map generator configured to generate a second depth map of the second image based on the first image, the second image, and the first depth map.\\n2. the apparatus of claim 1, wherein the first field of view is a narrow angle and the second field of view is a wider angle.\\n3. the apparatus of claim 2, wherein the second image is divided into a primary region and a residual region, and the second depth map generator comprises: a relationship estimating module configured to estimate a relationship between the primary region and the residual region based on the first image and the second image; and a depth map estimating module configured to estimate a depth map of the residual region based on the estimated relationship and the first depth map.\\n4. the apparatus of claim 3, wherein at least one of the relationship estimating module and the depth map estimating module performs an estimating operation based on a neural network module.\\n5. the apparatus of claim 1, further comprising: a depth map fusion unit configured to generate a third depth map of the second image by performing a fusion operation based on the first depth map and the second depth map.\\n6. the apparatus of claim 5, wherein the depth map fusion unit comprises: a tone mapping module configured to generate a tone-mapped second depth map to correspond to the first depth map by performing a bias removing operation on the second depth map; and a fusion module configured to generate the third depth map by fusing the tone-mapped second depth map and the first depth map.\\n7. the apparatus of claim 6, wherein the depth map fusion unit further comprises a propagating module configured to generate a propagated first depth map in the second image by iterated propagating of the first depth map based on the first depth map and the second image, and the fusion module generates the third depth map by fusing the tone-mapped second depth map and the propagated first depth map.\\n8. the apparatus of claim 6, wherein the depth map fusion unit further comprises a post-processing module configured to perform a post-processing operation on the third depth map generated by the fusion module to provide the post-processed third depth map.\\n9. the apparatus of claim 8, wherein the post-processing module performs the post-processing operation by filtering an interface generated in the third depth map in accordance with fusion of the fusion module.\\n10. the apparatus of claim 8, wherein the post-processing module removes artifacts generated in the third depth map in accordance with fusion of the fusion module.\\n11. the apparatus of claim 1, wherein the first depth map generator analyses a distance relationship between the first image and the second image, and generates a first depth map of the first image based on the distance relationship.\\n12. a method of processing an image of an electronic apparatus, the method comprising: obtaining a first image of an object using a first camera module; obtaining a second image of the object using a second camera module; generating a first depth map of the first image based on the first image and the second image; estimating a relationship between a primary region of the second image and a residual region of the second image based on the first image and the second image; and generating a second depth map of the second image based on the estimated relationship between the primary region and the residual region, and the first depth map.\\n13. the method of claim 12, wherein the electronic apparatus comprises a first camera module including a first lens having a first field of view and a second camera module including a second lens having a second field of view wider than the first field of view.\\n14. the method of claim 13, wherein the generating of the second depth map comprises: estimating a depth map of the residual region based on the estimated relationship between the primary region and the residual region, and the first depth map; and generating the second depth map based on a depth map of the residual region and the first depth map.\\n15. the method of claim 12, wherein the estimating of the relationship between a primary region of the second image is performed using a neural network model.\\n16. the method of claim 12, further comprising: performing a pre-processing operation on the second depth map; and generating a third depth map of the residual image by fusing the second depth map on which the pre-processing operation is performed and the first depth map.\\n17. the method of claim 16, wherein the performing of the pre-processing operation comprises performing a tone mapping operation between a depth map of the primary region and a depth map of the residual region based on the second depth map.\\n18. an operating method for an electronic apparatus, the electronic apparatus including; a first camera module providing a first image of an object using a first field of view and a second camera module providing a second image of the object using second field of view wider than the first field of view, and a processor generating a depth map of the second image based on a primary region of the second image and a residual region of the second image, the operating method comprising: generating a first depth map of the primary region by estimating a relationship between the first image and the second image; estimating a relationship between the primary region and the residual region based on the first image and the second image; generating a second depth map of the second image by estimating a depth map of the second region based on the estimated relationship between the primary region and the residual region; and generating a depth map of the second image by fusing the first depth map and the second depth map.\\n19. the operation method of claim 18, further comprising: executing an application that applies an image effect to the second image based on a depth map of the residual image.\\n20. the operation method of claim 19, wherein the application applies at least one image effect of auto-focusing, out-focusing, fore/background separation, face recognition, object detection within a frame, and augmented reality to the second image based on a depth map of the second image.1. a payment method based on a face recognition, comprising: acquiring first face image information of a target user; extracting first characteristic information from the first face image information, wherein the first characteristic information includes head posture information of the target user and gaze information of the target user; determining whether the target user has a willingness to pay according to the head posture information of the target user and the gaze information of the target user, including: determining whether an angle of rotation in each preset direction is less than an angle threshold, wherein the head posture information includes the angle of rotation in each preset direction; determining whether a probability value that a user gazes at a payment screen is greater than a probability threshold, wherein the gaze information includes the probability value that a user gazes at a payment screen; and in response to determining that the angle of rotation in each preset direction is less than the angle threshold and that the probability value that a user gazes at a payment screen is greater than the probability threshold, determining that the target user has a willingness to pay; and in response to determining that the target user has a willingness to pay, completing a payment operation based on the face recognition.\\n2. the method as claimed in claim 1, wherein the completing a payment operation based on the face recognition comprises: triggering and performing a payment initiating operation to acquire second face image information based on the face recognition; determining whether second characteristic information extracted from the second face image information indicates that the user has a willingness to pay; and in response to determining that the second characteristic information indicates that the user has a willingness to pay, triggering and performing a payment confirmation operation to complete the payment operation based on payment account information corresponding to the target user.\\n3. the method as claimed in claim 2, wherein the determining whether second characteristic information extracted from the second face image information indicates that the user has a willingness to pay comprises: determining whether a current user corresponding to the second face image information is consistent with the target user; and in response to determining that the current user is consistent with the target user, determining whether the target user has a willingness to pay according to the second characteristic information extracted from the second face image information.\\n4. the method as claimed in claim 1, wherein the extracting first characteristic information from the first face image information comprises: determining the head posture information of the target user using a head posture recognition model based on the first face image information; and determining the gaze information of the target user using a gaze information recognition model based on characteristics of an eye region in the first face image information.\\n5. the method as claimed in claim 4, wherein the head posture recognition model is obtained through training by: acquiring a first sample data set, wherein the first sample data set includes a plurality of pieces of first sample data, and each of the plurality of pieces of first sample data includes a correspondence between a sample face image and head posture information; determining mean image data and variance image data of a plurality of sample face images; for each of the plurality of pieces of first sample data, preprocessing the sample face image contained in each of the plurality of pieces of first sample data based on the mean image data and the variance image data to obtain a preprocessed sample face image; setting the preprocessed sample face image and the corresponding head posture information as a first model training sample; and performing training using a machine learning method and based on a plurality of first model training samples to obtain the head posture recognition model.\\n6. the method as claimed in claim 4, wherein the gaze information recognition model is obtained through training by: acquiring a second sample data set, wherein the second sample data set includes a plurality of pieces of second sample data, and each of the plurality of pieces of second sample data includes a correspondence between a sample eye image and gaze information; determining mean image data and variance image data of a plurality of sample eye images; for each of the plurality of pieces of second sample data, preprocessing the sample eye image contained in each of the plurality of pieces of second sample data based on the mean image data and the variance image data to obtain a preprocessed sample eye image; setting the preprocessed sample eye image and the corresponding gaze information as a second model training sample; and performing training using a machine learning method and based on a plurality of second model training samples to obtain the gaze information recognition model.\\n7. the method as claimed in claim 1, wherein the angle of rotation in each preset direction comprises a pitch angle, a yaw angle, and a roll angle, wherein the pitch angle refers to an angle of rotation around a x-axis, the yaw angle refers to an angle of rotation around a y-axis, and the roll angle refers to an angle of rotation around a z-axis.\\n8. a payment device based on a face recognition, comprising: a processor, and a non-transitory computer-readable storage medium storing instructions executable by the processor to cause the device to perform operations comprising: acquiring first face image information of a target user; extracting first characteristic information from the first face image information, wherein the first characteristic information includes head posture information of the target user and gaze information of the target user; determining whether the target user has a willingness to pay according to the head posture information of the target user and the gaze information of the target user, including: determining whether an angle of rotation in each preset direction is less than an angle threshold, wherein the head posture information includes the angle of rotation in each preset direction; determining whether a probability value that a user gazes at a payment screen is greater than a probability threshold, wherein the gaze information includes the probability value that a user gazes at a payment screen; and in response to determining that the angle of rotation in each preset direction is less than the angle threshold and that the probability value that a user gazes at a payment screen is greater than the probability threshold, determining that the target user has a willingness to pay; and in response to determining that the target user has a willingness to pay, completing a payment operation based on the face recognition.\\n9. the device as claimed in claim 8, wherein the completing a payment operation based on the face recognition comprises: triggering and performing a payment initiating operation to acquire second face image information based on the face recognition; determining whether second characteristic information extracted from the second face image information indicates that the user has a willingness to pay; and in response to determining that the second characteristic information indicates that the user has a willingness to pay, triggering and performing a payment confirmation operation to complete the payment operation based on payment account information corresponding to the target user.\\n10. the device as claimed in claim 9, wherein the determining whether second characteristic information extracted from the second face image information indicates that the user has a willingness to pay comprises: determining whether a current user corresponding to the second face image information is consistent with the target user; and in response to determining that the current user is consistent with the target user, determining whether the target user has a willingness to pay according to the second characteristic information extracted from the second face image information.\\n11. the device as claimed in claim 8, wherein the extracting first characteristic information from the first face image information comprises: determining the head posture information of the target user using a head posture recognition model based on the first face image information; and determining the gaze information of the target user using a gaze information recognition model based on characteristics of an eye region in the first face image information.\\n12. the device as claimed in claim 11, wherein the head posture recognition model is obtained through training by: acquiring a first sample data set, wherein the first sample data set includes a plurality of pieces of first sample data, and each of the plurality of pieces of first sample data includes a correspondence between a sample face image and head posture information; determining mean image data and variance image data of a plurality of sample face images; for each of the plurality of pieces of first sample data, preprocessing the sample face image contained in each of the plurality of pieces of first sample data based on the mean image data and the variance image data to obtain a preprocessed sample face image; setting the preprocessed sample face image and the corresponding head posture information as a first model training sample; and performing training using a machine learning method and based on a plurality of first model training samples to obtain the head posture recognition model.\\n13. the device as claimed in claim 11, wherein the gaze information recognition model is obtained through training by: acquiring a second sample data set, wherein the second sample data set includes a plurality of pieces of second sample data, and each of the plurality of pieces of second sample data includes a correspondence between a sample eye image and gaze information; determining mean image data and variance image data of a plurality of sample eye images; for each of the plurality of pieces of second sample data, preprocessing the sample eye image contained in each of the plurality of pieces of second sample data based on the mean image data and the variance image data to obtain a preprocessed sample eye image; setting the preprocessed sample eye image and the corresponding gaze information as a second model training sample; and performing training using a machine learning method and on a plurality of second model training samples to obtain the gaze information recognition model.\\n14. the device as claimed in claim 11, wherein the angle of rotation in each preset direction comprises a pitch angle, a yaw angle, and a roll angle, wherein the pitch angle refers to an angle of rotation around a x-axis, the yaw angle refers to an angle of rotation around a y-axis, and the roll angle refers to an angle of rotation around a z-axis.\\n15. a non-transitory computer-readable storage medium for a payment based on a face recognition, configured with instructions executable by one or more processors to cause the one or more processors to perform operations comprising: acquiring first face image information of a target user; extracting first characteristic information from the first face image information, wherein the first characteristic information includes head posture information of the target user, and gaze information of the target user; determining whether the target user has a willingness to pay according to the head posture information of the target user and the gaze information of the target user, including: determining whether an angle of rotation in each preset direction is less than an angle threshold, wherein the head posture information includes the angle of rotation in each preset direction; determining whether a probability value that a user gazes at a payment screen is greater than a probability threshold, wherein the gaze information includes the probability value that a user gazes at a payment screen; and in response to determining that the angle of rotation in each preset direction is less than the angle threshold and that the probability value that a user gazes at a payment screen is greater than the probability threshold, determining that the target user has a willingness to pay; and in response to determining that the target user has a willingness to pay, completing a payment operation based on the face recognition.\\n16. the storage medium as claimed in claim 15, wherein the completing a payment operation based on the face recognition comprises: triggering and performing a payment initiating operation to acquire second face image information based on the face recognition; determining whether second characteristic information extracted from the second face image information indicates that the user has a willingness to pay; and in response to determining that the second characteristic information indicates that the user has a willingness to pay, triggering and performing a payment confirmation operation to complete the payment operation based on payment account information corresponding to the target user.\\n17. the storage medium as claimed in claim 16, wherein the determining whether second characteristic information extracted from the second face image information indicates that the user has a willingness to pay comprises: determining whether a current user corresponding to the second face image information is consistent with the target user; and in response to determining that the current user is consistent with the target user, determining whether the target user has a willingness to pay according to the second characteristic information extracted from the second face image information.\\n18. the storage medium as claimed in claim 15, wherein the extracting first characteristic information from the first face image information comprises: determining the head posture information of the target user using a head posture recognition model based on the first face image information; and determining the gaze information of the target user using a gaze information recognition model based on characteristics of an eye region in the first face image information.\\n19. the storage medium as claimed in claim 18, wherein the head posture recognition model is obtained through training by: acquiring a first sample data set, wherein the first sample data set includes a plurality of pieces of first sample data, and each of the plurality of pieces of first sample data includes a correspondence between a sample face image and head posture information; determining mean image data and variance image data of a plurality of sample face images; for each of the plurality of pieces of first sample data, preprocessing the sample face image contained in each of the plurality of pieces of first sample data based on the mean image data and the variance image data to obtain a preprocessed sample face image; setting the preprocessed sample face image and the corresponding head posture information as a first model training sample; and performing training using a machine learning method and based on a plurality of first model training samples to obtain the head posture recognition model; and wherein the gaze information recognition model is obtained through training by: acquiring a second sample data set, wherein the second sample data set includes a plurality of pieces of second sample data, and each of the plurality of pieces of second sample data includes a correspondence between a sample eye image and gaze information; determining mean image data and variance image data of a plurality of sample eye images; for each of the plurality of pieces of second sample data, preprocessing the sample eye image contained in each of the plurality of pieces of second sample data based on the mean image data and the variance image data to obtain a preprocessed sample eye image; setting the preprocessed sample eye image and the corresponding gaze information as a second model training sample; and performing training using a machine learning method and based on a plurality of second model training samples to obtain the gaze information recognition model.\\n20. the storage medium as claimed in claim 18, wherein the angle of rotation in each preset direction comprises a pitch angle, a yaw angle, and a roll angle, wherein the pitch angle refers to an angle of rotation around a x-axis, the yaw angle refers to an angle of rotation around a y-axis, and the roll angle refers to an angle of rotation around a z-axis.1. a method comprising: detecting, by a motion detection module, a motion by a subject within a predetermined area of view; assigning a unique session identification number to the subject detected within a predetermined area of view; detecting a facial area of the subject detected within a predetermined area of view; generating an image of the facial area of the subject; assessing a quality of the image of the facial area of the subject; determining an identity of the subject based on the image of the facial area of the subject; identifying an intent of the subject; and authorizing access to a point of entry based on the determined identity of the subject and based on the intent of the subject.\\n2. the method of claim 1, further comprising: determining one or more additional subjects within the predetermined area of view; and assigning a unique session identification number to each of the one or more additional subjects detected within a predetermined area of view.\\n3. the method of claim 1, wherein the assessing a quality of the image of the facial area of the subject comprises: assessing whether the quality of the image of the facial area of the object equates predetermined metric of quality; and upon determining that the quality of the image of the facial area of the object is inferior to the predetermined metric of quality, discarding the image of the facial area of the subject and generating a second image of the facial area of the subject.\\n4. the method of claim 1, further comprising: detecting whether the facial area of the subject is photographic image; and upon detecting that the facial area of the subject is a photographic image, generating a warning and restrict access to the point of entry.\\n5. the method of claim 1, further comprising: conducing an incremental training of the image of the facial area of the subject.\\n6. the method of claim 5, wherein conducing an incremental training of the image of the facial area of the subject comprises: capturing a first image of the facial area having facial landmarks; converting the first image of the facial area into a first numeric vector; capturing a second image of the facial area having facial landmarks; converting the second image of the facial area into a second numeric vector; calculating a weighted mean of the first numeric vector and the second numeric vector, wherein the weighted mean represents a change in a facial area; and storing the weighted mean in the database.\\n7. the method of claim 1, wherein determining an identity of the subject based on the image of the facial area of the subject comprises: comparing the image of the facial area of the subject with a plurality of images stored in a database; and authenticating the subject.\\n8. the method of claim 1, wherein identifying an intent of the subject comprises: upon detecting the facial area in a bounding box, commencing authentication of the subject; calculating a directional vector of a face of the subject; determine an intent of the subject to gain access to the point of entry based on the directional vector of the face of the subject; granting the access to the point of entry based on authentication of the subject and based on determining the intent of the subject.\\n9. a non-transitory computer readable medium having program instructions stored thereon, that in response to execution by a computing device cause the computing device to perform operations comprising: detecting a motion by a subject within a predetermined area of view; assigning a unique session identification number to the subject detected within a predetermined area of view; detecting a facial area of the subject detected within a predetermined area of view; generating an image of the facial area of the subject; assessing a quality of the image of the facial area of the subject; determining an identity of the subject based on the image of the facial area of the subject; identifying an intent of the subject; and authorizing access to a point of entry based on the determined identity of the subject and based on the intent of the subject.\\n10. the non-transitory computer readable medium of claim 9, further comprising: determining one or more additional subjects within the predetermined area of view; and assigning a unique session identification number to each of the one or more additional subjects detected within a predetermined area of view.\\n11. the non-transitory computer readable medium of claim 9, wherein the assessing a quality of the image of the facial area of the subject comprises: assessing whether the quality of the image of the facial area of the object equates predetermined metric of quality; and upon determining that the quality of the image of the facial area of the object is inferior to the predetermined metric of quality, discarding the image of the facial area of the subject and generating a second image of the facial area of the subject.\\n12. the non-transitory computer readable medium of claim 9, further comprising: detecting whether the facial area of the subject is photographic image; and upon detecting that the facial area of the subject is a photographic image, generating a warning and restrict access to the access point.\\n13. the non-transitory computer readable medium of claim 9, further comprising: conducing an incremental training of the image of the facial area of the subject.\\n14. the non-transitory computer readable medium of claim 13, wherein conducing an incremental training of the image of the facial area of the subject comprises: capturing a first image of the facial area having facial landmarks; converting the first image of the facial area into a first numeric vector; capturing a second image of the facial area having facial landmarks; converting the second image of the facial area into a second numeric vector; calculating a weighted mean of the first numeric vector and the second numeric vector, wherein the weighted mean represents a change in a facial area; and storing the weighted mean in the database.\\n15. an apparatus for face recognition comprising: a processor; and a memory to store computer program instructions, the computer program instructions when executed on the processor cause the processor to perform operations comprising: detecting a motion by a subject within a predetermined area of view; assigning a unique session identification number to the subject detected within a predetermined area of view; detecting a facial area of the subject detected within a predetermined area of view; generating an image of the facial area of the subject; assessing a quality of the image of the facial area of the subject; determining an identity of the subject based on the image of the facial area of the subject; identifying an intent of the subject; and authorizing access to a point of entry based on the determined identity of the subject and based on the intent of the subject.\\n16. the apparatus of claim 15, further comprising: determining one or more additional subjects within the predetermined area of view; and assigning a unique session identification number to each of the one or more additional subjects detected within a predetermined area of view.\\n17. the apparatus of claim 15, wherein the assessing a quality of the image of the facial area of the subject comprises: assessing whether the quality of the image of the facial area of the object equates predetermined metric of quality; and upon determining that the quality of the image of the facial area of the object is inferior to the predetermined metric of quality, discarding the image of the facial area of the subject and generating a second image of the facial area of the subject.\\n18. the apparatus of claim 15, further comprising: detecting whether the facial area of the subject is photographic image; and upon detecting that the facial area of the subject is a photographic image, generating a warning and restrict access to the access point.\\n19. the apparatus of claim 15, further comprising: conducing an incremental training of the image of the facial area of the subject.\\n20. the apparatus of claim 15, wherein conducing an incremental training of the image of the facial area of the subject comprises: capturing a first image of the facial area having facial landmarks; converting the first image of the facial area into a first numeric vector; capturing a second image of the facial area having facial landmarks; converting the second image of the facial area into a second numeric vector; calculating a weighted mean of the first numeric vector and the second numeric vector, wherein the weighted mean represents a change in a facial area; and storing the weighted mean in the database.1. a robot, comprising: a body configured to rotate and to tilt; a camera coupled to the body and configured to rotate and tilt according to the rotate and the tilt of the body, wherein the camera is configured to acquire a video of a space; a face recognition unit configured to recognize respective faces of one or more persons in the video; a tracking unit configured to track motion of each of the recognized faces of the one or more persons; and a controller configured to: calculate a respective size of each of the faces of the one or more persons; select a first person, from among the one or more persons, based on the calculated sizes of the faces; and control at least one of a direction of the rotation of the camera, an angle of the tilt of the camera and a focal distance of the camera, based on the tracked motion of the recognized face of the first person.\\n2. the robot of claim 1, wherein the controller is configured to: control the direction of the rotation of the camera and the angle of the tilt of the camera to achieve an particular orientation of the camera relative to the face of the first person; and control a focal distance of the camera by comparing respective sizes of the face of the first person before and after motion of the first person.\\n3. the robot of claim 2, wherein the particular orientation occurs when the camera faces a general direction of the face of the first person.\\n4. the robot of claim 1, wherein the controller is configured to: normalize sizes of the faces of the one or more persons based on an interocular distance; and select the first person based on the normalized sizes of the faces of the one or more persons.\\n5. the robot of claim 1, wherein the controller is configured to: select a person having a largest face size, from among the one or more persons, as the first person.\\n6. the robot of claim 1, further comprising: a microphone configured to receive a spoken audio that is present in the space; wherein the controller is further configured to select the first person further based on the received spoken audio.\\n7. the robot of claim 6, wherein the controller is further configured to: control gain of the microphone by comparing respective sizes of the face of the first person before and after motion of the first person.\\n8. the robot of claim 6, wherein the controller is configured to: calculate a position from which the spoken audio is provided; and select the first person further based on whether the one or more persons are in the position from which the voice signal is provided.\\n9. the robot of claim 8, wherein the controller is configured to: select a second person as the first person, from among the one or more persons, when the second person is located in the position from which the spoken audio is provided.\\n10. the robot of claim 8, wherein the controller is configured to: select a second person having a largest face size as the first person, from among the one or more persons, when none of the one or more persons is located in the position from which the spoken audio is provided.\\n11. the robot of claim 8, wherein the controller is configured to: select a second person having a largest face size as the first person, from among the one or more persons, when a plurality of persons from among the one or more persons are located in the position from which the spoken audio is provided.\\n12. the robot of claim 1, further comprising: a speaker, wherein the controller is configured to: control volume of the speaker by comparing respective sizes of the face of the first person before and after motion of the first person.\\n13. the robot of claim 1, wherein the body is further configured to rotate in a lateral direction, and to tilt in an vertical direction.\\n14. an electronic device, comprising: a camera coupled to the body and configured to rotate and to tilt, wherein the camera is configured to acquire a video of a space within which one or more persons are positioned; and a processor configured to: recognize respective faces of the one or more persons in the video; track motion of each of the recognized faces of the one or more persons; calculate a respective size of each of the faces of the one or more persons; select a first person, from among the one or more persons, based on the calculated sizes of the faces; and control at least one of a direction of the rotation of the camera, an angle of the tilt of the camera and a focal distance of the camera, based on the tracked motion of the recognized face of the first person.\\n15. a method, comprising: acquiring, by a camera, a video of a space within which one or more persons are positioned; recognizing respective faces of the one or more persons in the video; tracking motion of each of the recognized faces of the one or more persons; calculating a respective size of each of the faces of the one or more persons; selecting a first person, from among the one or more persons, based on the calculated sizes of the faces; and controlling at least one of a direction of rotation of the camera, an angle of tilt of the camera and a focal distance of the camera, based on the tracked motion of the recognized face of the first person.1. a method of inferring topics from a multimodal file, the method comprising: receiving a multimodal file;\\nextracting a set of entities from the multimodal file;\\nlinking the set of entities to produce a set of linked entities;\\nobtaining reference information for the set of entities;\\nbased at least on the reference information, generating a graph of the set of linked entities, the graph comprising nodes and edges;\\nbased at least on the nodes and edges of the graph, determining clusters in the graph;\\nbased at least on the clusters in the graph, identifying topic candidates;\\nextracting features from the clusters in the graph;\\nbased at least on the extracted features, selecting at least one topicid from among the topic candidates to represent at least one cluster; and\\nindexing the multimodal file with the at least one topicid.\\n2. the method of claim 1 wherein the multimodal file comprises a video portion and an audio portion and wherein extracting a set of entities from the multimodal file comprises:\\ndetecting objects in the video portion of the multimodal file; and\\ndetecting text in the audio portion of the multimodal file.\\n3. the method of claim 2 wherein detecting objects comprises performing face recognition.\\n4. the method of claim 2 wherein detecting text comprises performing a speech to text process.\\n5. the method of claim 4 further comprising:\\nidentifying a language used in the audio portion of the multimodal file, and wherein performing a speech to text process comprises performing a speech to text process in the identified language.\\n6. the method of claim 4 further comprising:\\ntranslating the detected text.\\n7. the method of claim 1 further comprising:\\ndetermining significant clusters and insignificant clusters in the determined clusters, and\\nwherein extracting features from the clusters in the graph comprises extracting features from the significant clusters in the graph.\\n8. the method of claim 1 wherein extracting features from the clusters in the graph comprises at least one process selected from the list consisting of:\\ndetermining a graph diameter and determining a jaccard coefficient.\\n9. the method of claim 1 wherein selecting at least one topicid to represent at least one cluster comprises:\\nbased at least on the extracted features, mapping topic candidates into a probability interval; and\\nbased at least on the mapping, ranking topic candidates within the at least one cluster, and\\nselecting the at least one topicid based at least on the ranking.\\n10. the method of claim 1 further comprising:\\ntranslating the at least one topicid, and\\nwherein indexing the multimodal file with the at least one topicid comprises indexing the multimodal file with the at least one translated topicid.\\n11. a system for inferring topics from a multimodal file, the system comprising: an entity extraction component comprising an object detection component and a speech to text component, operative to extract a set of entities from a multimodal file comprising a video portion and an audio portion;\\nan entity linking component operative to link the extracted set of entities to produce a set of linked entities;\\nan information retrieval component operative to obtain reference information for the extracted set of entities;\\na graphing and analysis component operative to:\\ngenerate a graph of the set of linked entities, the graph comprising nodes and edges;\\nbased at least on the nodes and edges of the graph, determine clusters in the graph;\\nbased at least on the clusters in the graph, identify topic candidates; and extract features from the clusters in the graph;\\na topicid selection component operative to:\\nrank the topic candidates within at least one cluster; and\\nbased at least on the ranking, select at least one topicid from among the topic candidates to represent at least one cluster; and a video indexer operative to index the multimodal file with the at least one topicid.\\n12. the system of claim 11 wherein the object detection component is operative to perform face recognition.\\n13. the system of claim 11 wherein the speech to text component is operative to extract entity information in at least two different languages.\\n14. one or more computer storage devices having computer-executable instructions stored thereon for inferring topics from a multimodal file, which, on execution by a computer, cause the computer to perform operations comprising:\\nreceiving a multimodal file comprising a video portion and an audio portion; extracting a set of entities from the multimodal file, wherein extracting a set of entities from the multimodal file comprises:\\ndetecting objects in the video portion of the multimodal file with face recognition;\\ndetecting text in the audio portion of the multimodal file with a speech to text process; and\\ndisambiguating among a set of detected entity names;\\nlinking the set of entities to produce a set of linked entities;\\nobtaining reference information for the set of entities;\\nbased at least on the reference information, generating a graph of the set of linked entities, the graph comprising nodes and edges;\\nbased at least on the nodes and edges of the graph, determining clusters in the graph;\\ndetermining significant clusters and insignificant clusters in the determined clusters;\\nbased at least on the significant clusters in the graph, identifying topic candidates; extracting features from the significant clusters in the graph;\\nbased at least on the extracted features, mapping the topic candidates into a probability interval;\\nbased at least on the mapping, ranking the topic candidates within at least one significant cluster,\\nbased on the ranking, selecting at least one topicid from among the topic candidates to represent the at least one significant cluster; and\\nindexing the multimodal file with the at least one topicid.\\n15. the one or more computer storage devices of claim 14 wherein the operations further comprise:\\nidentifying a language used in the audio portion of the multimodal file, and detecting text in the audio portion of the multimodal file with a speech to text process comprises performing a speech to text process in the identified language.权利要求\\n1、 一种人脸识别方法,其特征在于,包括:\\n通过第一摄像头获取第一人脸图像;\\n提取所述第一人脸图像的第一人脸特征;\\n将所述第一人脸特征与预先存储的第二人脸特征进行对比,获得参考相似度,所述第 二人脸特征经第二摄像头获取的第二人脸图像的特征提取而得,所述第二摄像头与所述第 一摄像头属于不同类型的摄像头;\\n根据所述参考相似度确定所述第一人脸特征与所述第二人脸特征是否对应相同人。\\n2、 根据权利要求 1所述的方法,其特征在于,\\n所述第一摄像头为热成像摄像头,所述第二摄像头为可见光摄像头;\\n或者,所述第一摄像头为可见光摄像头,所述第一摄像头为热成像摄像头。\\n3、 根据权利要求 1或 2所述的方法,其特征在于,所述根据所述参考相似度确定所 述第一人脸特征与所述第二人脸特征是否对应相同人,包括:\\n根据所述参考相似度、 参考误报率以及相似度阈值确定所述第一人脸特征与所述第二 人脸特征是否对应相同人;其中,不同的误报率对应不同的相似度阈值。\\n4、 根据权利要求 1或 2所述的方法,其特征在于,所述根据所述参考相似度确定所 述第一人脸特征与所述第二人脸特征是否对应相同人,包括:\\n根据所述参考相似度以及阈值信息确定归一化后的参考相似度;\\n根据所述归一化后的参考相似度确定所述第一人脸特征与所述第二人脸特征是否对 应相同人。\\n5、 根据权利要求 1-4任一项所述的方法,其特征在于,所述提取所述第一人脸图像的 第_人脸特征,包括:\\n将所述第一人脸图像输入预先训练完成的神经网络,通过所述神经网络输出所述第一 人脸图像的第一人脸特征;其中,所述神经网络基于第一类型图像样本和第二类型图像样 本训练得到,所述第一类型图像样本和所述第二类型图像样本由不同类型的摄像头拍摄得 到,且所述第一类型图像样本和所述第二类型图像样本中包括人脸。\\n6、 根据权利要求 5 所述的方法,其特征在于,所述神经网络基于所述第一类型图像 样本、 所述第二类型图像样本和混合类型图像样本训练得到,所述混合类型图像样本由所 述第一类型图像样本和所述第二类型图像样本配对而得。\\n1、 根据权利要求 1-6任一项所述的方法,其特征在于,所述第一摄像头包括车载摄像 头,所述通过第一摄像头获取第一人脸图像,包括:\\n通过所述车载摄像头获取所述第一人脸图像,所述第一人脸图像包括车辆的用车人的 人脸图像。\\n8、 根据权利要求 7 所述的方法,其特征在于,所述用车人包括驾驶所述车辆的人、 乘坐所述车辆的人、 对所述车辆进行修理的人、 给所述车辆加油的人以及控制所述车辆的 人中的一项或多项。\\n9、 根据权利要求 7 所述的方法,其特征在于,所述用车人包括驾驶所述车辆的人, 所述通过所述车载摄像头获取所述第一人脸图像,包括: 在接收到触发指令的情况下,通过所述车载摄像头获取所述第一人脸图像; 或者,在所述车辆运行时,通过所述车载摄像头获取所述第一人脸图像;\\n或者,在所述车辆的运行速度达到参考速度的情况下,通过所述车载摄像头获取所述 第一人脸图像。\\n10、 根据权利要求 7-9任一项所述的方法,其特征在于,所述第二人脸图像为对所述 用车人进行人脸注册的图像,所述将所述第一人脸特征与预先存储的第二人脸特征进行对 比之前,所述方法还包括:\\n通过所述第二摄像头获取所述第二人脸图像;\\n提取所述第二人脸图像的第二人脸特征;\\n保存所述第二人脸图像的第二人脸特征。\\n11、 一种神经网络训练方法,其特征在于,包括:\\n获取第一类型图像样本和第二类型图像样本,所述第一类型图像样本和所述第二类型 图像样本由不同类型的摄像头拍摄得到,且所述第一类型图像样本和所述第二类型图像样 本中包括人脸;\\n根据所述第一类型图像样本和所述第二类型图像样本训练神经网络。\\n12、 根据权利要求 11所述的方法,其特征在于,所述根据所述第一类型图像样本和所 述第二类型图像样本训练神经网络,包括:\\n将所述第一类型图像样本和所述第二类型图像样本配对,得到所述第一类型图像样本 和所述第二类型图像样本的混合类型图像样本;\\n根据所述第一类型图像样本、 所述第二类型图像样本和所述混合类型图像样本,训练 所述神经网络。\\n13、 根据权利要求 12 所述的方法,其特征在于,所述根据所述第一类型图像样本、 所述第二类型图像样本和所述混合类型图像样本,训练所述神经网络,包括:\\n通过所述神经网络获取所述第一类型图像样本的人脸预测结果、 所述第二类型图像样 本的人脸预测结果和所述混合类型图像样本的人脸预测结果;\\n根据所述第一类型图像样本的人脸预测结果和人脸标注结果的差异、 所述第二类型图 像样本的人脸预测结果和人脸标注结果之间的差异、 以及所述混合类型图像样本的人脸预 测结果和人脸标注结果的差异,训练所述神经网络。\\n14、 根据权利要求 13 所述的方法,其特征在于,所述神经网络中包括第一分类器、 第二分类器和混合分类器,所述通过所述神经网络获取所述第一类型图像样本的人脸预测 结果、 所述第二类型图像样本的人脸预测结果和所述混合类型图像样本的人脸预测结果, 包括:\\n将所述第一类型图像样本的人脸特征输入至所述第一分类器中,得到所述第一类型图 像样本的人脸预测结果;\\n将所述第二类型图像样本的人脸特征输入至所述第二分类器中,得到所述第二类型图 像样本的人脸预测结果;\\n将所述混合类型图像样本的人脸特征输入至所述混合分类器中,得到所述混合类型图 像样本的人脸预测结果。 15、 根据权利要求 14所述的方法,其特征在于,所述方法还包括:\\n在训练完成的所述神经网络中去除所述第一分类器、 所述第二分类器和所述混合分类 器,得到用于进行人脸识别的神经网络。\\n16、 一种人脸识别装置,其特征在于,包括:\\n第一获取单元,用于通过第一摄像头获取第一人脸图像;\\n第一提取单元,用于提取所述第一人脸图像的第一人脸特征;\\n对比单元,用于将所述第一人脸特征与预先存储的第二人脸特征进行对比,获得参考 相似度,所述第二人脸特征经第二摄像头获取的第二人脸图像的特征提取而得,所述第二 摄像头与所述第一摄像头属于不同类型的摄像头;\\n确定单元,用于根据所述参考相似度确定所述第一人脸特征与所述第二人脸特征是否 对应相同人。\\n17、 根据权利要求 16所述的装置,其特征在于,\\n所述第一摄像头为热成像摄像头,所述第二摄像头为可见光摄像头;\\n或者,所述第一摄像头为可见光摄像头,所述第一摄像头为热成像摄像头。\\n18、 根据权利要求 16或 17所述的装置,其特征在于,\\n所述确定单元,具体用于根据所述参考相似度、 参考误报率以及相似度阈值确定所述 第一人脸特征与所述第二人脸特征是否对应相同人;其中,不同的误报率对应不同的相似 度阈值。\\n19、 根据权利要求 16或 17所述的装置,其特征在于,\\n所述确定单元,具体用于根据所述参考相似度以及阈值信息确定归一化后的参考相似 度;以及根据所述归一化后的参考相似度确定所述第一人脸特征与所述第二人脸特征是否 对应相同人。\\n20、 根据权利要求 16-19任_项所述的装置,其特征在于,\\n所述第一提取单元,具体用于将所述第一人脸图像输入预先训练完成的神经网络,通 过所述神经网络输出所述第一人脸图像的第一人脸特征;其中,所述神经网络基于第一类 型图像样本和第二类型图像样本训练得到,所述第一类型图像样本和所述第二类型图像样 本由不同类型的摄像头拍摄得到,且所述第一类型图像样本和所述第二类型图像样本中包 括人脸。\\n21、 根据权利要求 20 所述的装置,其特征在于,所述神经网络基于所述第一类型图 像样本、 所述第二类型图像样本和混合类型图像样本训练得到,所述混合类型图像样本由 所述第一类型图像样本和所述第二类型图像样本配对而得。\\n22、 根据权利要求 16-21任一项所述的装置,其特征在于,所述第一摄像头包括车载 摄像头,\\n所述第一获取单元,具体用于通过所述车载摄像头获取所述第一人脸图像,所述第一 人脸图像包括车辆的用车人的人脸图像。\\n23、 根据权利要求 22所述的装置,其特征在于,所述用车人包括驾驶所述车辆的人、 乘坐所述车辆的人、 对所述车辆进行修理的人、 给所述车辆加油的人以及控制所述车辆的 人中的一项或多项。 24、 根据权利要求 22所述的装置,其特征在于,所述用车人包括驾驶所述车辆的人, 所述第一获取单元,具体用于在接收到触发指令的情况下,通过所述车载摄像头获取所述 第一人脸图像;\\n或者,所述第一获取单元,具体用于在所述车辆运行时,通过所述车载摄像头获取所 述第 _人脸图像;\\n或者,所述第一获取单元,具体用于在所述车辆的运行速度达到参考速度的情况下, 通过所述车载摄像头获取所述第一人脸图像。\\n25、 根据权利要求 22-24任一项所述的装置,其特征在于,所述第二人脸图像为对所 述用车人进行人脸注册的图像,所述装置还包括:\\n第二获取单元,用于通过所述第二摄像头获取所述第二人脸图像;\\n第二提取单元,用于提取所述第二人脸图像的第二人脸特征;\\n保存单元,用于保存所述第二人脸图像的第二人脸特征。\\n26、 一种神经网络训练装置,其特征在于,包括:\\n获取单元,用于获取第一类型图像样本和第二类型图像样本,所述第一类型图像样本 和所述第二类型图像样本由不同类型的摄像头拍摄得到,且所述第一类型图像样本和所述 第二类型图像样本中包括人脸;\\n训练单元,用于根据所述第一类型图像样本和所述第二类型图像样本训练神经网络。\\n27、 根据权利要求 26所述的装置,其特征在于,所述训练单元包括:\\n配对子单元,用于将所述第一类型图像样本和所述第二类型图像样本配对,得到所述 第一类型图像样本和所述第二类型图像样本的混合类型图像样本;\\n训练子单元,用于根据所述第一类型图像样本、 所述第二类型图像样本和所述混合类 型图像样本,训练所述神经网络。\\n28、 根据权利要求 27所述的装置,其特征在于,\\n所述训练子单元,具体用于通过所述神经网络获取所述第一类型图像样本的人脸预测 结果、 所述第二类型图像样本的人脸预测结果和所述混合类型图像样本的人脸预测结果; 以及根据所述第一类型图像样本的人脸预测结果和人脸标注结果的差异、 所述第二类型图 像样本的人脸预测结果和人脸标注结果之间的差异、 以及所述混合类型图像样本的人脸预 测结果和人脸标注结果的差异,训练所述神经网络。\\n29、 根据权利要求 28 所述的装置,其特征在于,所述神经网络中包括第一分类器、 第二分类器和混合分类器,\\n所述训练子单元,具体用于将所述第一类型图像样本的人脸特征输入至所述第一分类 器中,得到所述第一类型图像样本的人脸预测结果;以及将所述第二类型图像样本的人脸 特征输入至所述第二分类器中,得到所述第二类型图像样本的人脸预测结果;以及将所述 混合类型图像样本的人脸特征输入至所述混合分类器中,得到所述混合类型图像样本的人 脸预测结果。\\n30、 根据权利要求 29所述的装置,其特征在于,所述装置还包括:\\n神经网络应用单元,用于在训练完成的所述神经网络中去除所述第一分类器、 所述第 二分类器和所述混合分类器,得到用于进行人脸识别的神经网络。 31、 一种电子设备,其特征在于,包括处理器和存储器,所述处理器和所述存储器耦 合;其中,所述存储器用于存储程序指令,所述程序指令被所述处理器执行时,使所述处 理器执行权利要求 1-10任一项所述的方法;和/或,使所述处理器执行权利要求 11-15任一 项所述的方法。\\n32、 一种计算机可读存储介质,其特征在于,所述计算机可读存储介质中存储有计算 机程序,所述计算机程序包括程序指令,所述程序指令当被处理器执行时,使所述处理器 执行权利要求 1-10任一项所述的方法;和/或,使所述处理器执行权利要求 11-15任一项所 述的方法。1. a system for alerting on vision impairment, said system comprising a processing unit configured and operable for receiving scene data being indicative of a scene of at least one consumer in an environment, identifying in the scene data a certain consumer, identifying an event being indicative of a behavioral compensation for vision impairment, and, upon identification of such an event, sending a notification relating to the vision impairment.\\n2. the system of claim 1, further comprising at least one sensing unit configured and operable for detecting the scene data.\\n3. the system of claim 2, wherein said at least one sensing unit comprises at least one of: at least one imaging unit configured and operable for capturing at least one image of at least a portion of a consumer\\'s body, at least one motion detector configured and operable for detecting consumer data being indicative of a motion of a consumer, or at least one eye tracker configured and operable for tracking eye motion of a consumer. 4. the system of claim 3, wherein the at least one imaging unit comprises a plurality of cameras placed at different heights.\\n5. the system of any one of claims 2 to 4, wherein said sensing unit is accommodated in an optical or digital eyewear frame display.\\n6. the system of any one of claims 1 to 5, wherein said processing unit is configured and operable for identifying a consumer\\'s condition, said consumer\\'s condition comprising consumer data being indicative of the consumer\\'s position and location relative to at least one object in the consumer\\'s environment; said consumer data comprises at least one of a consumer\\'s face, eyewear, posture, position, sound or motion.\\n7. the system of any one of claims 1 to 6, wherein said event comprises at least one position and orientation of head increase or decrease of viewing distance between the consumer and viewed object and changing the position of eyeglasses worn by the consumer.\\n8. the system of any one of claims 1 to 7, wherein said event is identified by identifying images having an image feature being indicative of behavioral compensation, performing a bruckner test, performing a hirschberg test, and measuring blink count/ frequency.\\n9. the system of claim 8, wherein the image feature being indicative of behavioral compensation comprises squinting, head orientation, certain distances between an object and consumer\\'s eyes, certain position of eyeglasses on the consumer\\'s face, strabismus, cataracts, and reflections from the eye.\\n10. the system of any one of claims 1 to 9, wherein the notification includes at least one of the data indicative of the identified event, data indicative of the identified consumer, ophthalmologic recommendations based on the identified event, or lack of events, or an appointment for a vision test.\\n11. the system of any one of claims 1 to 10, wherein said processing unit comprises a memory for storing at least one of a reference data indicative of behavioral compensation for vision impairment, data indicative of the notification, or data indicative of a follow-up of the notification.\\n12. the system of claim 11 , wherein said processing unit is configured for at least one of identifying the event upon comparison between the detected data and the reference data or determining a probability for a vision impairment of the consumer based on the comparison.\\n13. the system of any one of claims 1 to 12, wherein said processing unit comprises a communication interface being configured for sending the notification to at least one of the identified consumer or a third party.\\n14. the system of any one of claims 1 to 13, wherein said processing unit is configured for providing a frame recommendation.\\n15. the system of any one of claims 11 to 14, wherein said memory is configured for storing a database including a multiplicity of data sets related to a plurality of spectacle frame models and sizes.\\n16. the system according to claim 14 or 15, wherein said processing unit is configured and operable to correlate between frames parameters and ophthalmic prescriptions.\\n17. the system according to any of claims 14 to 16, wherein said processing unit is configured and operable to correlate between frames parameters and facial features.\\n18. the system according to any of claims 14 to 17, wherein said processing unit is configured and operable to correlate between frames parameters and eyewear preferences.\\n19. the system according to any of claims 14 to 18, comprising a server and at least one computer entity linked to the server via a network, wherein said network is configured to receive and respond to requests sent across the network; transmitting one or more modules of computer executable program instructions and displayable data to the network connected user computer platform in response to a request, wherein said modules include modules configured to: receive and transmit image information, transmitting a frame recommendation and an optical lens option recommendation based on received image information, for display by the network connected user computer platform.\\n20. a computer program instructions stored in the local storage that, when executed by a processing unit, cause the processing unit to: receive data being indicative of a scene of at least one consumer in an environment, identify in the data a certain consumer, identify an event being indicative of a behavioral compensation for vision impairment, and, upon identification of such an event, send a notification relating to the vision impairment.\\n21. a computer program product stored on a tangible computer readable medium, comprising: a library of software modules which cause a computer executing them to prompt for information pertinent to at least one of an eyeglasses recommendation and an optical lens option recommendation, to store said information or to display eyewear recommendations .\\n22. the computer program product of claim 21 , wherein said library further comprises a module for frame selection, point of sales and advertising.\\n23. a computer platform for facilitating eye glasses marketing or selection, comprising: a camera; a processor configured to execute computer program instructions to cause the processor to take an image of a consumer, identify in the image a certain consumer, identify an event being indicative of a behavioral compensation for vision impairment, and, upon identification of such an event, sending a notification relating to the vision impairment; local storage for processor executable instructions for carrying out storage of information.\\n24. a method for alerting on vision impairment; said method comprising:\\nidentifying a certain individual in scene data being indicative of a scene of at least one consumer in an environment;\\nidentifying an event being indicative of a behavioral compensation for vision impairment; and\\nupon identification of such an event, sending a notification on the vision impairment. 25. the method of claim 24, further comprising detecting data being indicative of a scene of at least one consumer in a retail environment.\\n26. the method of claim 24, wherein detecting the data being indicative of at least one consumer comprises at least one of capturing at least one image of at least one consumer, detecting data being indicative of a motion of a consumer, or tracking an eye motion of a consumer.\\n27. the method of claim 26, wherein capturing at least one image of at least one consumer comprises continuously recording a scene.\\n28. the method of any one of claims 24 to 27, further comprising identifying, in the data, the consumer\\' s condition including data being indicative of the consumer\\'s position and location relative to the consumer\\'s environment; said data comprising at least one of the consumer\\'s face, posture, position, sound or motion.\\n29. the method of any one of claims 26 to 28, wherein said event comprises at least one of position and orientation of head, increase or decrease of viewing distance between the consumer and viewed object, or changing the position of eyeglasses worn by the consumer.\\n30. the method of any one of claims 26 to 29, wherein identifying of the event comprises identifying images having an image feature being indicative of behavioral compensation, performing a bruckner test, performing a hirschberg test, and measuring blink count/frequency.\\n31. the method of claim 30, wherein the image feature being indicative of behavioral compensation comprises squinting, head orientation, certain distances between an object and a consumer\\'s eyes, certain position of eyeglasses on the consumer\\'s face, strabismus, cataracts, and reflections from the eye.\\n32. the method of any one of claims 27 to 31, wherein identifying in the at least one image a consumer in a retail environment, comprising at least one of receiving data characterizing the retail environment, or performing face recognition.\\n33. the method of any one of claims 24 to 32, wherein sending a notification comprising sending the notification to at least one of the identified consumer or a third party.\\n34. the method of any one of claims 24 to 33, wherein the notification includes at least one of the data indicative of the identified event, data indicative of the identified consumer, ophthalmologic recommendations based on the identified event, or lack of events, and an appointment for a vision test.\\n35. the method of any one of claims 24 to 34, further comprising storing at least one of a reference data indicative of behavioral compensation for vision impairment, data indicative of the notification, or data indicative of a follow-up of the notification.\\n36. the method of claim 35, further comprising identifying the event upon comparison between the detected data and the reference data and determining a probability for a vision impairment of the consumer, based on the comparison.\\n37. a computer program intended to be stored in a memory of a processor unit of a computer system, or in a removable memory medium adapted to cooperate with a reader of the processor unit, comprising instructions for implementing the method according to any of claims 24 to 36.'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lower() is a Python function for strings\n",
    "lower_atext = \"\"\n",
    "lower_ctext = \"\"\n",
    "for abstract_text in p1:\n",
    "    lower_atext += abstract_text.lower() #we pick each word and add to a variable, which will contain all the text\n",
    "lower_atext\n",
    "\n",
    "for claim_text in p2:\n",
    "    lower_ctext += claim_text.lower() #we pick each word and add to a variable, which will contain all the text\n",
    "lower_ctext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "be41e13f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. an electronic device (10), configured to make a screen (110) to display a plurality of image frames, comprising: an image capturing device (120); a storage device (130), storing a plurality of modules; and a processor (14), coupled to the image capturing device (140) and the storage device (130), configured to execute the modules in the storage device (130) to: configure the screen (110) to display a plurality of marker objects at a plurality of predetermined calibration positions; configure the image capturing device (120) to capture a plurality of first head images when a user is looking at the predetermined calibration positions; (s301) perform a plurality of first face recognition operations on the first head images to obtain a plurality of first face regions corresponding to the predetermined calibration positions; (s302) detect a plurality of first facial landmarks corresponding to the first face regions; (s303) calculate a plurality of rotation reference angles of the user looking at the predetermined calibration positions according to the first facial landmarks; configure the image capturing device (120) to capture a second head image of the user; perform a second face recognition operation on the second head image to obtain a second face region; detect a plurality of second facial landmarks within the second face region; (s304) estimate a head posture angle of the user according to the second facial landmarks; calculate a gaze position of the user on the screen (110) according to the head posture angle, the rotation reference angles, and the predetermined calibration positions; and configure the screen (110) to display a corresponding visual effect according to the gaze position. 2. the electronic device (10) according to claim 1, wherein the gaze position comprises a first coordinate value in a first axial direction and a second coordinate value in a second axial direction. 3. the electronic device (10) according to claim 2, wherein the head posture angles comprise a head pitch angle and a head yaw angle, and the rotation reference angles comprise a first pitch angle, a second pitch angle, a first yaw angle, and a second yaw angle corresponding to the predetermined calibration positions. 4. the electronic device (10) according to claim 3, wherein the processor (140) performs interpolation operation or extrapolation operation according to the first yaw angle, the second yaw angle, a first position corresponding to the first yaw angle among the predetermined calibration positions, a second position corresponding to the second yaw angle among the predetermined calibration positions and the head yaw angle, thereby obtaining the first coordinate value of the gaze position; and the processor (140) performs interpolation operation or extrapolation operation according to the first pitch angle, the second pitch angle, a third position corresponding to the first pitch angle among the predetermined calibration positions, a fourth position corresponding to the second pitch angle among the predetermined calibration positions and the head pitch angle, thereby obtaining the second coordinate value of the gaze position. 5. the electronic device (10) according to claim 1, wherein the processor (140) calculates a plurality of first viewing distances between the user and the screen (110) according to the first facial landmarks; the processor (140) estimates a second viewing distance between the user and the screen (110) according to the second facial landmarks; and the processor (140) adjusts the rotation reference angles or the gaze position according to the second viewing distance and the first viewing distances. 6. the electronic device (10) according to claim 1, wherein the processor (140) maps a plurality of two-dimensional position coordinates of the second facial landmarks under a plane coordinate system to a plurality of three-dimensional position coordinates under a three-dimensional coordinate system; and the processor (140) estimates the head posture angle according to the three-dimensional position coordinates of the second facial landmarks. 7. the electronic device (10) according to claim 1, wherein the second head image comprises a wearable device, and the second facial landmarks do not comprise a plurality of third facial landmarks of the user covered by the wearable device. 8. the electronic device (10) according to claim 1, wherein the second head image comprises a wearable device, and the second facial landmarks comprise one or more simulated landmarks marked by the wearable device. 9. an operating method, adapted for an electronic device (10) comprising an image capturing device (120) and making a screen (110) to display a plurality of image frames, the method comprising: configuring the screen (110) to display a plurality of marker objects at a plurality of predetermined calibration positions; configuring the image capturing device (120) to capture a plurality of first head images when a user is looking at the predetermined calibration positions; (s301) performing a plurality of first face recognition operations on the first head images to obtain a plurality of first face regions corresponding to the predetermined calibration positions; (s302) detecting a plurality of first facial landmarks corresponding to the first face regions; (s303) calculating a plurality of rotation reference angles of the user looking at the predetermined calibration positions according to the first facial landmarks; configuring the image capturing device (120) to capture a second head image of the user; performing a second face recognition operation on the second head image to obtain a second face region; (s304) detecting a plurality of second facial landmarks within the second face region; estimating a head posture angle of the user according to the second facial landmarks; calculating a gaze position of the user on the screen (110) according to the head posture angle, the rotation reference angles, and the predetermined calibration positions; and (s305) configuring the screen (110) to display a corresponding visual effect according to the gaze position. 10. the operation method according to claim 9, wherein the gaze position comprises a first coordinate value in a first axial direction and a second coordinate value in a second axial direction. 11. the operation method according to claim 10, wherein the head posture angles comprise a head pitch angle and a head yaw angle, and the rotation reference angles comprise a first pitch angle, a second pitch angle, a first yaw angle, and a second yaw angle corresponding to the predetermined calibration positions. 12. the operation method according to claim 11, wherein the step of calculating the gaze position of the user on the screen (110) according to the head posture angle, the rotation reference angles and the predetermined calibration positions comprises: performing interpolation operation or extrapolation operation according to the first yaw angle, the second yaw angle, a first position corresponding to the first yaw angle among the predetermined calibration positions, a second position corresponding to the second yaw angle among the predetermined calibration positions and the head yaw angle, thereby obtaining the first coordinate value of the gaze position; and performing interpolation operation or extrapolation operation according to the first pitch angle, the second pitch angle, a third position corresponding to the first pitch angle among the predetermined calibration positions, a fourth position corresponding to the second pitch angle among the predetermined calibration positions and the head pitch angle, thereby obtaining the second coordinate value of the gaze position. 13. the operation method according to claim 9, wherein the method further comprises: calculating a plurality of first viewing distances between the user and the screen (110) according to the first facial landmarks; estimating a second viewing distance between the user and the screen (110) according to the second facial landmarks; and adjusting the rotation reference angles or the gaze position according to the second viewing distance and the first viewing distances. 14. the operation method according to claim 9, wherein the method further comprises: mapping a plurality of two-dimensional position coordinates of the second facial landmarks under a plane coordinate system to a plurality of three-dimensional position coordinates under a three-dimensional coordinate system; and estimating the head posture angle according to the three-dimensional position coordinates of the second facial landmarks. 15. the operation method according to claim 9, wherein the second head image comprises a wearable device, and the second facial landmarks do not comprise a plurality of third facial landmarks of the user covered by the wearable device. 16. the operation method according to claim 9, wherein the second head image comprises a wearable device, and the second facial landmarks comprise one or more simulated landmarks marked by the wearable device.1. a computation method applied to a computing system, wherein the computing system comprises: a control unit, a computation group, and a general storage unit, wherein the control unit comprises: a first memory, a decoding logic, and a controller, wherein the computation group comprises: a group controller and a plurality of computing units; the general storage unit is configured to store data; and the computation method comprises: receiving, by the controller, a first level instruction sequence, and partitioning, by the decoding logic, the first level instruction sequence into a plurality of second level instruction sequences, creating, by the controller, m threads for the plurality of second level instruction sequences, and allocating, by the controller, an independent register as well as configuring an independent addressing function for each thread of the m threads, wherein m is an integer greater than or equal to 1; and obtaining, by the group controller, a plurality of computation types of the plurality of second level instruction sequences, obtaining a corresponding fusion computation manner of the computation types according to the plurality of computation types, and adopting, by the plurality of computing units, the fusion computation manner to call the m threads for performing computations on the plurality of second level instruction sequences to obtain a final result. 2. the method of claim 1, wherein, the obtaining, by the group controller, a plurality of computation types of the plurality of second level instruction sequences, obtaining a corresponding fusion computation manner of the computation types according to the plurality of computation types, and adopting, by the plurality of computing units, the fusion computation manner to call the m threads for performing computations on the plurality of second instruction sequences to obtain a final result: if the computation types represent computation operations of the same type, the group controller calls a combined computation manner in which single instruction multiple data of the same type is in combination with single instruction multiple threads, and uses the m threads to perform the combined computation manner to obtain a final result, which includes: partitioning, by the decoding logic, the m threads into n wraps for allocating to the the plurality of computing units, converting, by the group controller, the plurality of second instruction sequences into a plurality of second control signals and sending the second control signals to the plurality of computing units, calling, by the plurality of computing units, wraps that are allocated to the computing units and the second control signals to fetch corresponding data according to the independent addressing function, performing, by the plurality of computing units, computations on the data to obtain a plurality of intermediate results, and splicing the plurality of intermediate results to obtain a final result. 3. the method of claim 1, wherein, the obtaining, by the group controller, a plurality of computation types of the plurality of second level instruction sequences, obtaining a corresponding fusion computation manner of the computation types according to the plurality of computation types, and adopting, by the plurality of computing units, the fusion computation manner to call the m threads for performing computations on the plurality of second instruction sequences to obtain a final result: if the computation types represent computation operations of different types, the group controller calls simultaneous multi-threading and the m threads to perform computations to obtain a final result, which includes: partitioning, by the decoding logic, the m threads into n wraps, converting the plurality of second instruction sequences into a plurality of second control signals, obtaining, by the group controller, computation types supported by the plurality of computing units, allocating, by the controller, the n wraps and the plurality of second control signals to corresponding computing units that support computation types of the wraps and the second control signals, calling, by the plurality of computing units, wraps that are allocated to the computing units and the second control signals, fetching, by the plurality of computing units, corresponding data, performing, by the plurality of computing units, computations on the data to obtain a plurality of intermediate results, and splicing all the intermediate results to obtain a final result. 4. the method of claim 2 or 3, further comprising: if a wrap a in the plurality of wraps is blocked, adding the wrap a to a waiting queue, and if data of the wrap a are already fetched, adding the wrap a to a preparation queue, wherein the preparation queue is a queue where a wrap to be scheduled for executing is located when a computing resource is idle. 5. the method of claim 1, wherein the first level instruction sequence includes a very long instruction, and the second level instruction sequence includes an instruction sequence. 6. the method of claim 1, wherein the computing system further includes: a tree module, wherein the tree module includes: a root port and a plurality of branch ports, wherein the root port of the tree module is connected to the group controller, and the plurality of branch ports of the tree module are connected to a computing unit of the plurality of computing units respectively; and the tree module is configured to forward data blocks, wraps, or instruction sequences between the group controller and the plurality of computing units. 7. the method of claim 6, wherein the tree module is an n-ary tree, wherein n is an integer greater than or equal to 2. 8. the method of claim 1, wherein the computing system further includes a branch processing circuit, wherein the branch processing circuit is connected between the group controller and the plurality of computing units; and the branch processing circuit is configured to forward data, wraps, or instruction sequences between the group controller and the plurality of computing units. 9. a computing system, comprising: a control unit, a computation group, and a general storage unit, wherein the control unit includes: a first memory, a decoding logic, and a controller, the computation group includes: a group controller and a plurality of computing units; the general storage unit is configured to store data; the controller is configured to receive a first level instruction sequence and control the first memory and the decoding logic; the decoding logic is configured to partition the first level instruction sequence into a plurality of second level instruction sequences; the the controller is further configured to create m threads for the plurality of second level instruction sequences, and allocate an independent register and configure an independent addressing function for each thread of the m threads; m is an integer greater than or equal to 1; and the controller is further configured to convert the plurality of second instruction sequences into a plurality of control signals for sending to the group controller; the group controller is configured to receive the plurality of control signals, obtain a plurality of computational types if the plurality of control signals, divide the m threads into n wraps, and allocate the n wraps and the plurality of control signals to the plurality of computing units according to the plurality of computational types; the plurality of computing units are configured to fetch data from the general storage unit through allocated wraps and control signals, and perform computations to obtain an intermediate result; and the group controller is configured to splice all intermediate results to obtain a final computation result. 10. the computing system of claim 9, wherein the plurality of computing units includes: an addition computing unit, a multiplication computing unit, an activation computing unit, or a dedicated computing unit. 11. the computing system of claim 9, wherein the dedicated computing unit includes: a face recognition computing unit, a graphics computing unit, a fingerprint computing unit, or a neural network computing unit. 12. the computing system of claim 11, wherein the group controller is configured to, if computation types of a plurality of control signals are graphics computations, fingerprint identification, face recognition, or neural network operations, allocate the plurality of control signals to the face recognition computing unit, the graphics computing unit, the fingerprint computing unit, or the neural network computing unit respectively. 13. the computing system of claim 9, wherein the first level instruction sequence includes a very long instruction, and the second level instruction sequence includes an instruction sequence. 14. the computing system of claim 9, further comprising a tree module, wherein the tree module includes: a root port and a plurality of branch ports, wherein the root port of the tree module is connected to the group controller, and the plurality of branch ports of the tree module are connected to a computing unit of the plurality of computing units respectively; and the tree module is configured to forward data blocks, wraps, or instruction sequences between the group controller and the plurality of computing units. 15. the computing system of claim 14, wherein the tree module is an n-ary tree, wherein n is an integer greater than or equal to 2. 16. the computing system of claim 9, wherein the computing system includes a branch processing circuit, the branch processing circuit is connected between the group controller and the plurality of computing units; and the branch processing circuit is configured to forward data, wraps, or instruction sequences between the group controller and the plurality of computing units. 17. a computer program product, comprising a non-instant computer readable storage medium, wherein a computer program is stored in the non-instant computer readable storage medium, and the computer program is capable of causing a computer to perform the method of any of claims 1-8 through operations.1. a method for detecting body information on one or more passengers of a vehicle based on humans\\' status recognition, comprising steps of: (a) if at least one interior image of an interior of the vehicle is acquired, a passenger body information-detecting device performing (i) a process of inputting the interior image into a face recognition network, to thereby allow the face recognition network to detect each of faces of each of the passengers from the interior image, and thus to output multiple pieces of passenger feature information corresponding to each of the detected faces, and (ii) a process of inputting the interior image into a body recognition network, to thereby allow the body recognition network to detect each of bodies of each of the passengers from the interior image, and thus to output body-part length information of each of the detected bodies; and (b) the passenger body information-detecting device performing a process of retrieving specific height mapping information corresponding to specific passenger feature information on a specific passenger from a height mapping table which stores height mapping information representing respective one or more predetermined ratios of one or more segment body portions of each of human groups to each of heights per each of the human groups, a process of acquiring a specific height of the specific passenger from the specific height mapping information by referring to specific body-part length information of the specific passenger, a process of retrieving specific weight mapping information corresponding to the specific passenger feature information from a weight mapping table which stores multiple pieces of weight mapping information representing predetermined correlations between each of the heights and each of weights per each of the human groups, and a process of acquiring a weight of the specific passenger from the specific weight mapping information by referring to the specific height of the specific passenger. 2. the method of claim 1, wherein, at the step of (a), the passenger body information-detecting device performs a process of inputting the interior image into the body recognition network, to thereby allow the body recognition network to (i) output one or more feature tensors with one or more channels corresponding to the interior image via a feature extraction network, (ii) generate at least one keypoint heatmap and at least one part affinity field with one or more channels corresponding to each of the feature tensors via a keypoint heatmap & part affinity field extractor, and (iii) extract keypoints from the keypoint heatmap via a keypoint detector, to group the extracted keypoints by referring to the part affinity field, and thus to generate body parts per the passengers, and as a result, allow the body recognition network to output multiple pieces of body-part length information on each of the passengers by referring to the body parts per the passengers. 3. the method of claim 2, wherein the feature extraction network includes at least one convolutional layer and applies at least one convolution operation to the interior image, to thereby output the feature tensors. 4. the method of claim 2, wherein the keypoint heatmap & part affinity field extractor includes one of a fully convolutional network and a 1×1 convolutional layer, and applies a fully-convolution operation or 1×1 convolution operation to the feature tensors, to thereby generate the keypoint heatmap and the part affinity field. 5. the method of claim 2, wherein the keypoint detector connects, by referring to the part affinity field, pairs respectively having highest mutual connection probabilities of being connected among the extracted keypoints, to thereby group the extracted keypoints. 6. the method of claim 2, wherein the feature extraction network and the keypoint heatmap & part affinity field extractor have been learned by a learning device performing (i) a process of inputting at least one training image including one or more objects for training into the feature extraction network, to thereby allow the feature extraction network to generate one or more feature tensors for training having one or more channels by applying at least one convolutional operation to the training image, (ii) a process of inputting the feature tensors for training into the keypoint heatmap & part affinity field extractor, to thereby allow the keypoint heatmap & part affinity field extractor to generate one or more keypoint heatmaps for training and one or more part affinity fields for training having one or more channels for each of the feature tensors for training, (iii) a process of inputting the keypoint heatmaps for training and the part affinity fields for training into the keypoint detector, to thereby allow the keypoint detector to extract keypoints for training from each of the keypoint heatmaps for training and a process of grouping the extracted keypoints for training by referring to each of the part affinity fields for training, to thereby detect keypoints per each of the objects for training, and (iv) a process of allowing a loss layer to calculate one or more losses by referring to the keypoints per each of the objects for training and their corresponding ground truths, to thereby adjust one or more parameters of the feature extraction network and the keypoint heatmap & part affinity field extractor such that the losses are minimized by backpropagation using the losses. 7. the method of claim 1, wherein, at the step of (a), the passenger body information-detecting device performs a process of inputting the interior image into the face recognition network, to thereby allow the face recognition network to detect each of the faces of each of the passengers located in the interior image via a face detector, and to output multiple pieces of the passenger feature information on each of the facial images via a facial feature classifier. 8. the method of claim 1, wherein, at the step of (a), the passenger body information-detecting device performs a process of inputting the interior image into the face recognition network, to thereby allow the face recognition network to (i) apply at least one convolution operation to the interior image and thus to output at least one feature map corresponding to the interior image via at least one convolutional layer, (ii) output one or more proposal boxes, where the passengers are estimated as located, on the feature map, via a region proposal network, (iii) apply pooling operation to one or more regions, corresponding to the proposal boxes, on the feature map and thus to output at least one feature vector via a pooling layer, and (iv) apply fully-connected operation to the feature vector, and thus to output the multiple pieces of the passenger feature information corresponding to each of the faces of each of the passengers corresponding to each of the proposal boxes via a fully connected layer. 9. the method of claim 1, wherein the multiple pieces of the passenger feature information include each of ages, each of genders and each of races corresponding to each of the passengers. 10. a passenger body information-detecting device for detecting body information on one or more passengers of a vehicle based on humans\\' status recognition, comprising: at least one memory that stores instructions; and at least one processor configured to execute the instructions to perform or support another device to perform: (i) if at least one interior image of an interior of the vehicle is acquired, (i) a process of inputting the interior image into a face recognition network, to thereby allow the face recognition network to detect each of faces of each of the passengers from the interior image, and thus to output multiple pieces of passenger feature information corresponding to each of the detected faces, and (ii) a process of inputting the interior image into a body recognition network, to thereby allow the body recognition network to detect each of bodies of each of the passengers from the interior image, and thus to output body-part length information of each of the detected bodies, and (ii) a process of retrieving specific height mapping information corresponding to specific passenger feature information on a specific passenger from a height mapping table which stores height mapping information representing respective one or more predetermined ratios of one or more segment body portions of each of human groups to each of heights per each of the human groups, a process of acquiring a specific height of the specific passenger from the specific height mapping information by referring to specific body-part length information of the specific passenger, a process of retrieving specific weight mapping information corresponding to the specific passenger feature information from a weight mapping table which stores multiple pieces of weight mapping information representing predetermined correlations between each of the heights and each of weights per each of the human groups, and a process of acquiring a weight of the specific passenger from the specific weight mapping information by referring to the specific height of the specific passenger. 11. the passenger body information-detecting device of claim 10, wherein, at the process of (i), the processor performs a process of inputting the interior image into the body recognition network, to thereby allow the body recognition network to (i) output one or more feature tensors with one or more channels corresponding to the interior image via a feature extraction network, (ii) generate at least one keypoint heatmap and at least one part affinity field with one or more channels corresponding to each of the feature tensors via a keypoint heatmap & part affinity field extractor, and (iii) extract keypoints from the keypoint heatmap via a keypoint detector, to group the extracted keypoints by referring to the part affinity field, and thus to generate body parts per the passengers, and as a result, allow the body recognition network to output multiple pieces of body-part length information on each of the passengers by referring to the body parts per the passengers. 12. the passenger body information-detecting device of claim 11, wherein the keypoint heatmap & part affinity field extractor includes one of a fully convolutional network and a 1×1 convolutional layer, and applies a fully-convolution operation or 1×1 convolution operation to the feature tensors, to thereby generate the keypoint heatmap and the part affinity field. 13. the passenger body information-detecting device of claim 11, wherein the keypoint detector connects, by referring to the part affinity field, pairs respectively having highest mutual connection probabilities of being connected among the extracted keypoints, to thereby group the extracted keypoints. 14. the passenger body information-detecting device of claim 11, wherein the feature extraction network and the keypoint heatmap & part affinity field extractor have been learned by a learning device performing (i) a process of inputting at least one training image including one or more objects for training into the feature extraction network, to thereby allow the feature extraction network to generate one or more feature tensors for training having one or more channels by applying at least one convolutional operation to the training image, (ii) a process of inputting the feature tensors for training into the keypoint heatmap & part affinity field extractor, to thereby allow the keypoint heatmap & part affinity field extractor to generate one or more keypoint heatmaps for training and one or more part affinity fields for training having one or more channels for each of the feature tensors for training, (iii) a process of inputting the keypoint heatmaps for training and the part affinity fields for training into the keypoint detector, to thereby allow the keypoint detector to extract keypoints for training from each of the keypoint heatmaps for training and a process of grouping the extracted keypoints for training by referring to each of the part affinity fields for training, to thereby detect keypoints per each of the objects for training, and (iv) a process of allowing a loss layer to calculate one or more losses by referring to the keypoints per each of the objects for training and their corresponding ground truths, to thereby adjust one or more parameters of the feature extraction network and the keypoint heatmap & part affinity field extractor such that the losses are minimized by backpropagation using the losses. 15. the passenger body information-detecting device of claim 10, wherein, at the process of (i), the processor performs a process of inputting the interior image into the face recognition network, to thereby allow the face recognition network to (i) apply at least one convolution operation to the interior image and thus to output at least one feature map corresponding to the interior image via at least one convolutional layer, (ii) output one or more proposal boxes, where the passengers are estimated as located, on the feature map, via a region proposal network, (iii) apply pooling operation to one or more regions, corresponding to the proposal boxes, on the feature map and thus to output at least one feature vector via a pooling layer, and (iv) apply fully-connected operation to the feature vector, and thus to output the multiple pieces of the passenger feature information corresponding to each of the faces of each of the passengers corresponding to each of the proposal boxes via a fully connected layer.1. a computer implemented method for performing video coding based on face detection comprising: receiving a video frame comprising one of a plurality of video frames of a video sequence; determining the video frame is a key frame of the video sequence; performing, in response to the video frame being a key frame of the video sequence, a multi-stage facial search of the video frame based on predetermined feature templates and a predetermined number of stages to determine a first candidate face region and a second candidate face region in the video frame; testing the first and second candidate face regions based on skin tone information to determine the first candidate face region is a valid face region and the second candidate face region is an invalid face region; rejecting the second candidate face region and outputting the first candidate face region; and encoding the video frame based at least in part on the first candidate face region being a valid face region to generate a coded bitstream. 2. the method of claim 1, wherein the skin tone information comprises a skin probability map. 3. the method of claim 1, wherein said testing the first and second candidate face regions based on skin tone information is performed in response to the video frame being a key frame of the video sequence. 4. the method of claim 1, wherein the first candidate face region comprises a rectangular region, the method further comprising: determining a free form shape face region corresponding to the first candidate face region, wherein the free form shape face region has at least one of a pixel accuracy or a small block of pixels accuracy. 5. the method of claim 4, wherein determining the free form shape face region comprises: generating an enhanced skip probability map corresponding to the first candidate face region; binarizing the enhanced skip probability map; and overlaying the binarized enhanced skip probability map over at least a portion of the video frame to provide the free form shape face region. 6. the method of claim 4, wherein a second video frame comprises a non-key frame of the video sequence, the method further comprising performing face detection in the second video frame of the video sequence based on the free form shape face region. 7. the method of claim 6, further comprising: tracking a second free form shape face region in the second video frame based on the free form shape face region in the video frame. 8. the method of claim 7, wherein tracking the second free form shape face region comprises determining a location of a second valid face region in the second video frame based on a displacement offset with respect to the first candidate face region. 9. the method of claim 8, further comprising: determining the displacement offset based on an offset between a centroid of a bounding box around a skin enhanced region corresponding to the first candidate face region and a second centroid of a second bounding box around a second skin enhanced region in the second video frame. 10. the method of claim 1, wherein encoding the video frame based at least in part on the first candidate face region being a valid face region comprises at least one of reducing a quantization parameter corresponding to the first candidate face region, adjusting a lambda value for the first candidate face region, or disabling skip coding for the first candidate face region. 11. the method of claim 1, wherein the bitstream comprises at least one of an h.264/advanced video coding (avc) compliant bitstream, an h.265/high efficiency video coding (hevc) compliant bitstream, a vp9 compliant bitstream, a vp10 compliant bitstream, or an alliance for open media (aom) av1 compliant bitstream. 12. a computer implemented method for performing face detection comprising: receiving a video frame of a sequence of video frames; performing a multi-stage facial search of the video frame based on predetermined feature templates and a predetermined number of stages to determine a first candidate face region and a second candidate face region in the video frame; testing the first and second candidate face regions based on skin tone information to determine the first candidate face region is a valid face region and the second candidate face region is an invalid face region; rejecting the second candidate face region and outputting the first candidate face region as a valid face region for further processing; and providing an index indicative of a person being present in the video frame based on the valid face region. 13. the method of claim 12, wherein the sequence of video frames comprises a sequence of surveillance video frames, the method further comprising: performing face recognition in the surveillance video frames based on the valid face region. 14. the method of claim 12, wherein the sequence of video frames comprises a sequence of decoded video frames, the method further comprising: adding a marker corresponding to the received video frame to perform face recognition on the received video frame based on the valid face region. 15. the method of claim 12, wherein the sequence of video frames is received during a device login attempt, the method further comprising: performing face recognition based on the valid face region; and allowing access to the device if a secured face is recognized. 16. the method of claim 12, wherein the sequence of video frames comprises a sequence of videoconferencing frames, the method further comprising: encoding the video frame based at least in part on the valid face region to generate a coded bitstream. 17. the method of claim 16, wherein encoding the video frame comprises not encoding a background region of the video frame into the bitstream. 18. the method of claim 12, further comprising: encoding the video frame based at least in part on the valid face region to generate a coded bitstream, wherein encoding the video frame comprises including metadata corresponding to the valid face region in the bitstream. 19. the method of claim 18, further comprising: decoding the coded bitstream to generate a decoded video frame and to determine the metadata corresponding to the valid face region in the bitstream. 20. the method of claim 19, further comprising at least one of replacing the valid face region based on the decoded metadata, cropping and displaying image data corresponding only to the valid face region based on the decoded metadata, or indexing the decoded video frame based on the decoded metadata. 21. a system for performing video coding based on face detection comprising: a memory configured to store a video frame comprising one of a plurality of video frames of a video sequence; and a processor coupled to the memory, the processor to receive the video frame, to determine the video frame is a key frame of the video sequence; to perform, in response to the video frame being a key frame of the video sequence, a multi-stage facial search of the video frame based on predetermined feature templates and a predetermined number of stages to determine a first candidate face region and a second candidate face region in the video frame, to test the first and second candidate face regions based on skin tone information to determine the first candidate face region is a valid face region and the second candidate face region is an invalid face region, to reject the second candidate face region and outputting the first candidate face region, and to encode the video frame based at least in part on the first candidate face region being a valid face region to generate a coded bitstream. 22. the system of claim 21, wherein the skin tone information comprises a skin probability map. 23. the system of claim 21, wherein the first candidate face region comprises a rectangular region, the processor further to determine a free form shape face region corresponding to the first candidate face region, wherein the free form shape face region has at least one of a pixel accuracy or a small block of pixels accuracy. 24. the system of claim 23, wherein the processor to determine the free form shape face region comprises the processor to generate an enhanced skip probability map corresponding to the first candidate face region, to binarize the enhanced skip probability map, and to overlay the binarized enhanced skip probability map over at least a portion of the video frame to provide the free form shape face region. 25. the system of claim 23, wherein a second video frame comprises a non-key frame of the video sequence, and the processor is further to perform face detection in the second video frame of the video sequence based on the free form shape face region. 26. the system of claim 25, wherein the processor is further to track a second free form shape face region in the second video frame based on the free form shape face region in the video frame. 27. the system of claim 21, wherein to encode the video frame based at least in part on the first candidate face region being a valid face region comprises the processor to reduce a quantization parameter corresponding to the first candidate face region, adjust a lambda value for the first candidate face region, or disable skip coding for the first candidate face region. 28. at least one non-transitory machine readable medium comprising a plurality of instructions that, in response to being executed on a device, cause the device to perform video coding based on face detection by: receiving a video frame comprising one of a plurality of video frames of a video sequence; determining the video frame is a key frame of the video sequence; performing, in response to the video frame being a key frame of the video sequence, a multi-stage facial search of the video frame based on predetermined feature templates and a predetermined number of stages to determine a first candidate face region and a second candidate face region in the video frame; testing the first and second candidate face regions based on skin tone information to determine the first candidate face region is a valid face region and the second candidate face region is an invalid face region; rejecting the second candidate face region and outputting the first candidate face region; and encoding the video frame based at least in part on the first candidate face region being a valid face region to generate a coded bitstream. 29. the non-transitory machine readable medium of claim 28, wherein the skin tone information comprises a skin probability map. 30. the non-transitory machine readable medium of claim 28, wherein the first candidate face region comprises a rectangular region, the machine readable medium comprising further instructions that, in response to being executed on the device, cause the device to perform video coding based on face detection by: determining a free form shape face region corresponding to the first candidate face region, wherein the free form shape face region has at least one of a pixel accuracy or a small block of pixels accuracy. 31. the non-transitory machine readable medium of claim 30, wherein determining the free form shape face region comprises: generating an enhanced skip probability map corresponding to the first candidate face region; binarizing the enhanced skip probability map; and overlaying the binarized enhanced skip probability map over at least a portion of the video frame to provide the free form shape face region. 32. the non-transitory machine readable medium of claim 30, wherein a second video frame comprises a non-key frame of the video sequence, the machine readable medium comprising further instructions that, in response to being executed on the device, cause the device to perform video coding based on face detection by performing face detection in the second video frame of the video sequence based on the free form shape face region. 33. the non-transitory machine readable medium of claim 32, the machine readable medium comprising further instructions that, in response to being executed on the device, cause the device to perform video coding based on face detection by: tracking a second free form shape face region in the second video frame based on the free form shape face region in the video frame. 34. the non-transitory machine readable medium of claim 28, wherein encoding the video frame based at least in part on the first candidate face region being a valid face region comprises at least one of reducing a quantization parameter corresponding to the first candidate face region, adjusting a lambda value for the first candidate face region, or disabling skip coding for the first candidate face region.1. a method for managing a smart database which stores facial images for face recognition, comprising steps of: (a) a managing device performing a process of counting one or more specific facial images corresponding to at least one specific person stored in the smart database where new facial images for the face recognition are continuously stored, and a process of determining whether a first counted value representing a count of the specific facial images satisfies a preset first set value; and (b) if the first counted value is determined as satisfying the first set value, the managing device performing a process of inputting the specific facial images into a neural aggregation network, to thereby allow the neural aggregation network to generate each of quality scores of each of the specific facial images by aggregation of the specific facial images, and a process of sorting the quality scores corresponding to the specific facial images in a descending order of the quality scores, a process of counting the sorted specific facial images in the descending order until a second counted value which represents the number of a counted part of the specific facial images becomes equal to a preset second set value, and a process of deleting an uncounted part of the specific facial images from the smart database. 2. the method of claim 1, further comprising a step of: (c) the managing device performing a process of generating at least one optimal feature by weighted summation of one or more features of the specific facial images using the counted part of the quality scores and a process of setting the optimal feature as a representative face corresponding to the specific person. 3. the method of claim 1, wherein, at the step of (b), the managing device performs a process of inputting the specific facial images into a cnn of the neural aggregation network, to thereby allow the cnn to generate one or more features corresponding to each of the specific facial images, and a process of inputting at least one feature vector, where the features are embedded, into an aggregation module including at least two attention blocks, to thereby allow the aggregation module to generate each of the quality scores of each of the features. 4. the method of claim 1, wherein, at the step of (b), the managing device performs a process of matching (i) (i-1) one or more features corresponding to each of the specific facial images stored in the smart database and (i-2) the quality scores with (ii) the specific person, and a process of storing the matched features and the matched quality scores in the smart database. 5. the method of claim 1, further comprising a step of: (d) the managing device performing one of (i) a process of learning a face recognition system by using the specific facial images corresponding to the specific person stored in the smart database and (ii) a process of transmitting the specific facial images, corresponding to the specific person, to a learning device corresponding to the face recognition system, to thereby allow the learning device to learn the face recognition system using the specific facial images. 6. the method of claim 1, wherein the neural aggregation network has been learned by a learning device repeating more than once (i) a process of inputting multiple facial images for training corresponding to an image set of a single face or a video of the single face into a cnn of the neural aggregation network, to thereby allow the cnn to generate one or more features for training by applying at least one convolution operation to the facial images for training, (ii) a process of inputting at least one feature vector for training, where the features for training are embedded, into an aggregation module, including at least two attention blocks, of the neural aggregation network, to thereby allow the aggregation module to generate each of quality scores for training of each of the features for training by aggregation of the features for training using one or more attention parameters learned in a previous iteration, (iii) a process of outputting at least one optimal feature for training by weighted summation of the features for training using the quality scores for training, and (iv) a process of updating the attention parameters learned in the previous iteration of the at least two attention blocks such that one or more losses are minimized which are outputted from a loss layer by referring to the optimal feature for training and its corresponding ground truth. 7. a managing device for managing a smart database which stores facial images for face recognition, comprising: at least one memory that stores instructions; and at least one processor configured to execute the instructions to perform or support another device to perform: (i) a process of counting one or more specific facial images corresponding to at least one specific person stored in the smart database where new facial images for the face recognition are continuously stored, and a process of determining whether a first counted value representing a count of the specific facial images satisfies a preset first set value, and (ii) if the first counted value is determined as satisfying the first set value, a process of inputting the specific facial images into a neural aggregation network, to thereby allow the neural aggregation network to generate each of quality scores of each of the specific facial images by aggregation of the specific facial images, and a process of sorting the quality scores corresponding to the specific facial images in a descending order of the quality scores, a process of counting the sorted specific facial images in the descending order until a second counted value which represents the number of a counted part of the specific facial images becomes equal to a preset second set value, and a process of deleting an uncounted part of the specific facial images from the smart database. 8. the managing device of claim 7, wherein the processor further performs: (iii) a process of generating at least one optimal feature by weighted summation of one or more features of the specific facial images using the counted part of the quality scores and a process of setting the optimal feature as a representative face corresponding to the specific person. 9. the managing device of claim 7, wherein, at the process of (ii), the processor performs a process of inputting the specific facial images into a cnn of the neural aggregation network, to thereby allow the cnn to generate one or more features corresponding to each of the specific facial images, and a process of inputting at least one feature vector, where the features are embedded, into an aggregation module including at least two attention blocks, to thereby allow the aggregation module to generate each of the quality scores of each of the features. 10. the managing device of claim 7, wherein, at the process of (ii), the processor performs a process of matching (i) (i-1) one or more features corresponding to each of the specific facial images stored in the smart database and (i-2) the quality scores with (ii) the specific person, and a process of storing the matched features and the matched quality scores in the smart database. 11. the managing device of claim 7, wherein the processor further performs: (iv) one of (i) a process of learning a face recognition system by using the specific facial images corresponding to the specific person stored in the smart database and (ii) a process of transmitting the specific facial images, corresponding to the specific person, to a learning device corresponding to the face recognition system, to thereby allow the learning device to learn the face recognition system using the specific facial images. 12. the managing device of claim 7, wherein the neural aggregation network has been learned by a learning device repeating more than once (i) a process of inputting multiple facial images for training corresponding to an image set of a single face or a video of the single face into a cnn of the neural aggregation network, to thereby allow the cnn to generate one or more features for training by applying at least one convolution operation to the facial images for training, (ii) a process of inputting at least one feature vector for training, where the features for training are embedded, into an aggregation module, including at least two attention blocks, of the neural aggregation network, to thereby allow the aggregation module to generate each of quality scores for training of each of the features for training by aggregation of the features for training using one or more attention parameters learned in a previous iteration, (iii) a process of outputting at least one optimal feature for training by weighted summation of the features for training using the quality scores for training, and (iv) a process of updating the attention parameters learned in the previous iteration of the at least two attention blocks such that one or more losses are minimized which are outputted from a loss layer by referring to the optimal feature for training and its corresponding ground truth.1. an object data processing system comprising: at least one processor configured to execute: at least one implementation of a plurality of recognition algorithms stored on at least one non-transitory computer-readable storage medium, each recognition algorithm having feature density selection criteria; and data preprocessing code executed by at least one processor, the data preprocessing code comprising an invariant feature identification algorithm and configured to: obtain a digital representation of a scene, the scene comprising one or more textual media; generate a set of invariant features by applying the invariant feature identification algorithm to the digital representation; cluster the set of invariant features into regions of interest in the digital representation of the scene, each region of interest having a region feature density; classify, by region classifier code, at least one of the regions of interest according to object type as a function of attributes derived from the region feature density and the digital representation, wherein the at least one of the classified regions of interest corresponds to text; and use a classification result corresponding to the at least one of the regions of interest to classify another of the regions of interest according to object type, wherein the another of the regions of interest corresponds to a region of interest for images. 2. the system of claim 1, wherein preprocessing code, based on the feature density selection criteria, determines that an ocr algorithm is applicable to the text, and that other recognition algorithms are applicable to aspects of the photographs and to logos. 3. the system of claim 1, wherein a user creates a user profile for a camera-equipped smartphone that includes the information that the user is visually impaired, which causes prioritized execution of the ocr algorithm such that a text reader program begins reading the text to the user as quickly as possible. 4. the system of claim 3, further comprising an audio or tactile feedback mechanism that helps the user to position the smart phone relative to the text. 5. the system of claim 4, further comprising a \"hold still\" audio feedback signal that is sent to the user when the text is at the center of the captured scene. 6. the system of claim 1, wherein the digital representation comprises at least one of the following types of digital data: image data, video data, and audio data. 7. the system of claim 1, wherein invariant feature identification algorithm comprises at least one of the following feature identification algorithms: fast, sift, freak, brisk, harris, daisy, and mser. 8. the system of claim 1, wherein the invariant feature identification algorithm includes at least one of the following: edge detection algorithm, corner detection algorithm, saliency map algorithm, curve detection algorithm, a texton identification algorithm, and wavelets algorithm. 9. the system of claim 1, wherein at least one region of interest represents at least one physical object in the scene. 10. the system of claim 1, wherein at least one region of interest represents at least one textual media in the scene. 11. the system of claim 10, wherein the region of interest represents a document as the textual media. 12. the system of claim 11, wherein the region of interest represents a financial document. 13. the system of claim 11, wherein the region of interest represents a structured document. 14. the system of claim 1, wherein at least one implementation of a plurality of recognition algorithms includes at least one of the following: a template driven algorithm, a face recognition algorithm, an optical character recognition algorithm, a speech recognition algorithm, and an object recognition algorithm. 15. the system of claim 1, wherein data preprocessing code is further configured to assign each region of interest at least one recognition algorithm as a function of a scene context derived from the digital representation. 16. the system of claim 15, wherein the scene context includes at least one of the following types of data: a location, a position, a time, a user identity, a news event, a medical event, and a promotion. 17. the system of claim 1, further comprising a mobile device comprising at least one implementation of a plurality of recognition algorithms and data preprocessing code. 18. the system of claim 17, wherein the mobile device comprises at least one of the following: a smart phone, a tablet, wearable glass, a toy, a vehicle, a computer, and a phablet. 19. the system of claim 1, further comprising a network-accessible server device comprising at least one implementation of a plurality of recognition algorithms and data preprocessing code. 20. the system of claim 1, wherein the object type includes at least one of the following: a face, an animal, a vehicle, a document, a plant, a building, an appliance, clothing, a body part, and a toy. 21. an object data processing system comprising: at least one processor configured to execute: at least one implementation of a plurality of recognition algorithms stored on at least one non-transitory computer-readable storage medium, each recognition algorithm having feature density selection criteria; and data preprocessing code executed by at least one processor, the data preprocessing code comprising an invariant feature identification algorithm and configured to: obtain a digital representation of a scene, the scene comprising one or more textual media; generate a set of invariant features by applying the invariant feature identification algorithm to the digital representation; cluster the set of invariant features into regions of interest in the digital representation of the scene, each region of interest having a region feature density; classify, by region classifier code, at least one of the regions of interest according to object type as a function of attributes derived from the region feature density and the digital representation; wherein the at least one of the classified regions of interest corresponds to text; and use a classification result corresponding to the at least one of the regions of interest to classify another of the regions of interest according to object type, wherein the another of the regions of interest corresponds to a region of interest for images; assign each region of interest at least one recognition algorithm from at least one implementation of a plurality of diverse recognition algorithms as a function of the region feature density of each region of interest and the feature density selection criteria of the at least one implementation of a plurality of diverse recognition algorithms; and configure the assigned recognition algorithms to process their respective regions of interest, wherein preprocessing code, based on the feature density selection criteria, determines that an ocr algorithm is applicable to the text, and that other recognition algorithms are applicable to aspects of the photographs and to logos. 22. a device comprising: at least one processor configured to execute: at least one implementation of a plurality of recognition algorithms stored on at least one non-transitory computer-readable storage medium, each recognition algorithm having feature density selection criteria; and data preprocessing code executed by at least one processor, the data preprocessing code comprising an invariant feature identification algorithm and configured to: obtain a digital representation of a scene, the scene comprising one or more textual media; generate a set of invariant features by applying the invariant feature identification algorithm to the digital representation; cluster the set of invariant features into regions of interest in the digital representation of the scene, each region of interest having a region feature density; and classify, by region classifier code, at least one of the regions of interest according to object type as a function of attributes derived from the region feature density and the digital representation, wherein the at least one of the classified regions of interest corresponds to text; and use a classification result corresponding to the at least one of the regions of interest to classify another of the regions of interest according to object type, wherein the another of the regions of interest corresponds to a region of interest for images.1. a mobile terminal comprising: a front camera configured to obtain a two-dimensional (2d) face image of a user; a glance sensor tilted by a certain angle and disposed adjacent to the front camera to obtain metadata of the 2d face image; and a controller obtaining a distance between the glance sensor and the front camera, the distance enabling an area of an overlap region, where a first region representing a range photographable by the front camera overlaps a second region representing a range photographable by the glance sensor, to be the maximum. 2. the mobile terminal of claim 1, wherein the controller is configured to obtain the distance, enabling the area of the overlap region to be the maximum, between the glance sensor and the front camera by varying a tilting angle of the glance sensor. 3. the mobile terminal of claim 2, wherein the controller is configured to set the distance, enabling the area of the overlap region to be the maximum, between the glance sensor and the front camera and the tilting angle of the glance sensor as an optimal disposition location of the glance sensor. 4. the mobile terminal of claim 3, wherein the controller is configured to set a disposition location of the front camera as an original point and calculates coordinates of a first triangle representing the first region, based on a field of view of the front camera and a maximum photographing distance of the front camera. 5. the mobile terminal of claim 4, wherein the controller is configured to calculate coordinates of a second triangle representing the second region, based on a field of view of the glance sensor, a maximum photographing distance of the glance sensor, a distance between the front camera and the glance sensor, and a tilting angle of the glance sensor. 6. the mobile terminal of claim 5, wherein before the glance sensor is tilted, the controller is configured to calculate coordinates of a third triangle representing a third region photographable by the glance sensor, and the controller is configured to rotation-convert the coordinates of the third triangle, based on the tilting angle of the glance sensor and calculate the coordinates of the second triangle. 7. the mobile terminal of claim 6, wherein the controller is configured to calculate coordinates of the overlap region, based on the coordinates of the first triangle and the coordinates of the second triangle and calculates the area of the overlap region, based on the coordinates of the overlap region. 8. the mobile terminal of claim 1, wherein the controller is configured to generate three-dimensional (3d) face information, based on the 2d face image obtained by the front camera and metadata obtained by the glance sensor. 9. the mobile terminal of claim 8, wherein the metadata comprises one or more of an angle of a face of the user, a size of the face, and a location of the face. 10. the mobile terminal of claim 9, wherein the angle of the face comprises an angle by which the face is rotated about one or more of a pitch axis, a roll axis, and a yaw axis. 11. the mobile terminal of claim 8, further comprising a memory storing the generated 3d face information, wherein the controller is configured to performs a user authentication process by comparing the stored 3d face information with 3d face information obtained for user authentication. 12. the mobile terminal of claim 1, wherein the glance sensor is controlled to be permanently activated with a low power to obtain a front image and metadata of the front image. 13. the mobile terminal of claim 1, wherein the front camera and the glance sensor are disposed on the same line in an upper end of the mobile terminal. 14. the mobile terminal of claim 1, wherein the glance sensor is tilted in one direction of an up direction, a down direction, a left direction, and a right direction. 15. the mobile terminal of claim 1, wherein the metadata is data which is changed when the mobile terminal is tilted by an external physical force.1. a method, comprising: receiving, by a smart television (tv), an indication of upcoming media programming, wherein the upcoming media programming is based on a user profile; identifying one or more devices in communication with the smart tv, each of the one or more devices including at least one of a microphone or a camera; instructing at least one identified device to detect audio signals using its respective microphone, or to detect visual signals using its respective camera; selecting at least one device of the one or more devices based on the detected audio signal or detected visual signal; and providing instructions to the selected device to output a notification related to the upcoming media programming. 2. the method of claim 1, wherein the upcoming media programming is one of a live television program, a recorded television program, a broadcast television program, or an application-provided program. 3. the method of claim 1, wherein selecting the first device based on the detected audio signal includes recognizing a voice. 4. the method of claim 3, further comprising determining a distance to the recognized voice, and wherein selecting the first device is further based on the determined distance. 5. the method of claim 1, wherein selecting the first device based on the detected visual signals includes recognizing a face. 6. the method of claim 5, wherein recognizing the face includes a face recognition technique. 7. the method of claim 1, further comprising presenting, on the smart tv, the upcoming media programming in a favorite channel list. 8. the method of claim 7, further comprising: obtaining media programming viewing data, wherein the media programming viewing data includes at least one of a historical time and a historical date that one or more media programs were viewed; obtaining at least one of a current time and a current date; processing the media programming viewing data to determine a probability of the one or more media programs being viewed based on at least one of the current time and the current date; and presenting the favorite channel list based on the determined probability of the one or more media programs being viewed. 9. the method of claim 8, wherein processing the media programming viewing data includes employing a neural network model. 10. the method of claim 9, wherein employing the neural network model comprises: determining a duration that the one or more media programs were viewed for each of the at least one of the historical time and the historical date; setting a threshold time duration; comparing the determined duration to the threshold time duration; and filtering out the one or more media programs viewed below the threshold time duration. 11. a smart television (tv), comprising: a network interface; a non-transitory computer-readable medium; and a processor in communication with the network interface, and the non-transitory computer-readable medium, and capable of executing processor-executable program code stored in the non-transitory computer-readable medium, to cause the smart tv to: receive an indication of upcoming media programming, wherein the upcoming media programming is based on a user profile; identify one or more devices in communication with the smart tv, each of the one or more devices including at least one of a microphone or a camera; instruct at least one identified device to detect audio signals using its respective microphone, or to detect visual signals using its respective camera; select at least one device of the one or more devices based on the detected audio signal or detected visual signal; and provide instructions to the selected device to output a notification related to the upcoming media programming. 12. the smart tv of claim 11, wherein selecting the first device based on the detected audio signal includes recognizing a voice. 13. the smart tv of claim 12, wherein the processor is further capable of executing processor-executable program code to: determine a distance to the recognized voice, and wherein selecting the first device is further based on the determined distance. 14. the smart tv of claim 11, wherein selecting the first device based on the detected visual signals includes detecting the presence of a user. 15. the smart tv of claim 14, wherein detecting the presence of the user includes employing one or more of a camera, a microphone, or a fingerprint sensor associated with at least one of the smart tv a mobile device, a smartphone, a laptop computer, a tablet device, a wearable device, an internet of things (iot) device, an internet of everything (ioe) device, an iot hub, or an ioe hub. 16. a smart television (tv), comprising: means for receiving an indication of upcoming media programming, wherein the upcoming media programming is based on a user profile; means for identifying one or more devices in communication with the smart tv, each of the one or more devices including at least one of a microphone or a camera; means for instructing at least one identified device to detect audio signals using its respective microphone, or to detect visual signals using its respective camera; means for selecting at least one device of the one or more devices based on the detected audio signal or detected visual signal; and means for providing instructions to the selected device to output a notification related to the upcoming media programming. 17. the smart tv of claim 16, wherein the one or more devices includes at least one of a mobile device, a smartphone, a laptop computer, a tablet device, a wearable device, an internet of things (iot) device, an internet of everything (ioe) device, an iot hub, an ioe hub, or another smart tv. 18. the smart tv of claim 16, wherein the upcoming media programming is one of a live television program, a recorded television program, a broadcast television program, or an application-provided program. 19. the smart tv of claim 16, wherein the notification includes at least one of a push message, a sms message, a way2sms message, an audio alert, an audio message, or an email message. 20. the smart tv of claim 16, further comprising presenting the upcoming media programming in a favorite channel list. 21. the smart tv of claim 20, further comprising: means for obtaining media programming viewing data, wherein the media programming viewing data includes at least one of a historical time and a historical date that one or more media programs were viewed on the smart tv; means for obtaining at least one of a current time and a current date; means for processing the media programming viewing data to determine a probability of the one or more media programs being viewed on the smart tv based on at least one of the current time and the current date; and means for presenting the favorite channel list based on the determined probability of the one or more media programs being viewed. 22. the smart tv of claim 21, wherein the means for processing the media programming viewing data includes employing a neural network model. 23. the smart tv of claim 22, wherein employing the neural network model comprises: determining a duration that the one or more media programs were viewed on the smart tv for each of the at least one of the historical time and the historical date; setting a threshold time duration; comparing the determined duration to the threshold time duration; and filtering out the one or more media programs viewed below the threshold time duration. 24. the smart tv of claim 21, further comprising: means for adjusting at least one of a volume or a brightness of the smart tv, wherein the adjusting is based on at least one of the historical time and the historical date. 25. the smart tv of claim 21, further comprising means for restricting access to one or more media programs. 26. a non-transitory computer-readable medium comprising processor-executable program code configured to cause a processor of a smart television (tv) to: receive an indication of upcoming media programming, wherein the upcoming media programming is based on a user profile; identify one or more devices in communication with the smart tv, each of the one or more devices including at least one of a microphone or a camera; instruct at least one identified device to detect audio signals using its respective microphone, or to detect visual signals using its respective camera; select at least one device of the one or more devices based on the detected audio signal or detected visual signal; and provide instructions to the selected device to output a notification related to the upcoming media programming. 27. the non-transitory computer-readable medium of claim 26, wherein selecting the first device based on the detected audio signal includes recognizing a voice. 28. the non-transitory computer-readable medium of claim 27, wherein the processor is further capable of executing processor-executable program code to: determine a distance to the recognized voice, and wherein selecting the first device is further based on the determined distance. 29. the non-transitory computer-readable medium of claim 26, wherein selecting the first device based on the detected visual signals includes recognizing a face. 30. the non-transitory computer-readable medium of claim 29, wherein recognizing the face includes a face recognition technique.1. a camera comprising: a sensor array including a plurality of sensors; an infrared (ir) illuminator configured to emit active ir light in an ir light sub-band; a plurality of spectral illuminators, each spectral illuminator configured to emit active spectral light in a different spectral light sub-band; a depth controller machine configured to determine a depth value for each of the plurality of sensors based on the active ir light, a spectral controller machine configured to, for each of the plurality of sensors, determine a spectral value for each spectral light sub-band of the plurality of spectral illuminators; and an output machine configured to output a test depth+multi-spectral image including a plurality of pixels, each pixel corresponding to one of the plurality of sensors of the sensor array and including at least: a depth value, and a spectral value for each spectral light sub-band of the plurality of spectral illuminators; a face recognition machine previously trained with a set of labeled training depth+multi-spectral images having a same structure as the test depth+multi-spectral image, the face recognition machine configured to output a confidence value indicating a likelihood that the test depth+multi-spectral image includes a face. 2. the camera of claim 1, wherein each spectral value is calculated based on the depth value determined for the sensor that corresponds to the pixel. 3. the camera of claim 1, wherein the face recognition machine is configured to use a convolutional neural network to determine the confidence value. 4. the camera of claim 3, wherein the face recognition machine includes a plurality of input nodes, wherein each input node is configured to receive a pixel value array corresponding to a different pixel of the plurality of pixels of the test depth+multi-spectral image, and wherein the pixel value array includes the depth value and the plurality of multi-spectral values for the pixel. 5. the camera of claim 4, wherein the plurality of multi-spectral values for the pixel include more than three spectral values. 6. the camera of claim 4, wherein the output machine is configured to output a surface normal for each pixel of the test depth+multi-spectral image, and wherein the pixel value array includes the surface normal. 7. the camera of claim 4, wherein the output machine is configured to output a curvature for each pixel of the test depth+multi-spectral image, and wherein the pixel value array includes the curvature. 8. the camera of claim 3, wherein the face recognition machine is configured to use a plurality of models to determine the confidence value, wherein the plurality of models includes a plurality of channel-specific models, wherein each channel-specific model is configured to process a different pixel parameter for the plurality of pixels of the test depth+multi-spectral image, wherein each channel-specific model includes a plurality of input nodes, and wherein, for each channel-specific model, each input node is configured to receive a pixel parameter value for a different pixel of the plurality of pixels of the test depth+multi-spectral image. 9. the camera of claim 1, wherein the face recognition machine is configured to use a statistical model to determine the confidence value. 10. the camera of claim 9, wherein the statistical model includes a nearest neighbor algorithm. 11. the camera of claim 9, wherein the statistical model includes a support vector machine. 12. the camera of claim 1, wherein the face recognition machine is further configured to output a location on the test depth+multi-spectral image of a bounding box around a recognized face. 13. the camera of claim 1, wherein the face recognition machine is further configured to output a location on the test depth+multi-spectral image of an identified two-dimensional (2d) facial feature of a recognized face. 14. the camera of claim 1, wherein the face recognition machine is further configured to output a location on the test depth+multi-spectral image of an identified three-dimensional (3d) facial feature of a recognized face. 15. the camera of claim 1, wherein the face recognition machine is further configured to output a location on the test depth+multi-spectral image of an identified spectral feature on a recognized face. 16. the camera of claim 1, wherein the face recognition machine is further configured to output, for each pixel of the test depth+multi-spectral image, a confidence value indicating a likelihood that the pixel is included in a face. 17. the camera of claim 1, wherein the face recognition machine is further configured to output an identity of a face recognized in the test depth+multi-spectral image. 18. the camera of claim 1, wherein the plurality of sensors of the sensor array are differential sensors, and wherein each spectral value is determined based on a depth value and a differential measurement for that differential sensor. 19. a camera comprising: a sensor array including a plurality of sensors; an infrared (ir) illuminator configured to emit active ir light in an ir light sub-band; a plurality of spectral illuminators, each spectral illuminator configured to emit active spectral light in a different spectral light sub-band; a depth controller machine configured to determine a depth value for each of the plurality of sensors based on the active ir light, a spectral controller machine configured to, for each of the plurality of sensors, determine a spectral value for each spectral light sub-band of the plurality of spectral illuminators, wherein each spectral value is calculated based on the depth value determined for the sensor that corresponds to the pixel; and an output machine configured to output a test depth+multi-spectral image including a plurality of pixels, each pixel corresponding to one of the plurality of sensors of the sensor array and including at least: a depth value, and a spectral value for each spectral light sub-band of the plurality of spectral illuminators; and a face recognition machine including a convolutional neural network previously trained with a set of labeled training depth+multi-spectral images having a same structure as the test depth+multi-spectral image, the face recognition machine configured to output a confidence value indicating a likelihood that the test depth+multi-spectral image includes a face.1. an image processing method, comprising: acquiring a photo album obtained from face clustering; collecting face information of respective images in the photo album, and acquiring a face parameter of each image according to the face information; selecting a cover image according to the face parameter of each image; and taking a face-region image from the cover image, and setting the face-region image as a cover of the photo album; wherein selecting the cover image according to the face parameter of each image comprises: performing calculation on the face parameter of each image in a preset way, to obtain a cover score of each image; selecting the image with a highest cover score as the cover image; wherein selecting the image with the highest cover score as the cover image comprises: acquiring a source of each image; and selecting the image with the highest cover score in images coming from a preset source as the cover image. 2. the method according to claim 1, wherein selecting the image with the highest cover score as the cover image comprises: acquiring the number of faces contained in each image; determining single-person images according to the number of faces; and selecting the single-person image with the highest cover score as the cover image. 3. the method according to claim 2, wherein selecting the image with the highest cover score as the cover image further comprises: when there is no single-person image in the photo album, determining images including two faces from the photo album; and selecting the image with the highest cover score from the images including two faces as the cover image. 4. the method according to claim 1, wherein the face information comprises face feature points, and the face parameter comprises a face turning angle; acquiring the face parameter of each image according to the face information comprises: acquiring coordinate values of the face feature points; determining distances and angles between the face feature points; and determining the face turning angle according to the distances and the angles. 5. the method according to claim 1, wherein the face parameter comprises a face ratio; acquiring the face parameter of each image according to the face information comprises: determining a face region of the image according to the face information; and calculating a ratio of an area of the face region to an area of the image to obtain the face ratio. 6. the method according to claim 5, wherein calculating the face ratio comprises: when there is more than one face in the image, subtracting an area occupied faces other than a face corresponding to the photo album from the face region to obtain a remaining area; and calculating a ratio of the remaining area to the area of the image to obtain the face ratio. 7. the method according to claim 1, wherein collecting face information of respective images in the photo album comprises: acquiring image identifications of images in the photo album; extracting face information corresponding to the image identifications from a face database, the face database being stored with face recognition results of images, the face recognition results including the face information. 8. an image processing apparatus, comprising: a processor; and a memory, configured to store instructions executable by the processor, wherein the processor is configured to run a program corresponding to the instructions by reading the instructions stored in the memory, so as to perform: acquiring a photo album obtained from face clustering; collecting face information of each image in the photo album; acquiring a face parameter of each image according to the face information; selecting a cover image according to the face parameter of each image; taking a face-region image from the cover image, and setting the face-region image as a cover of the photo album; wherein the processor is configured to: perform calculation on the face parameter of each image in a preset way, to obtain a cover score of each image; and select the image with a highest cover score as the cover image; and wherein the processor is configured to: acquire a source of each image; and select the image with the highest cover score in images coming from a preset source as the cover image. 9. the apparatus according to claim 8, wherein the processor is configured to: acquire the number of faces contained in each image; determine single-person images according to the number of faces; and select the single-person image with the highest cover score as the cover image. 10. the apparatus according to claim 9, wherein the processor is further configured to: when there is no single-person image in the photo album, determine images including two faces from the photo album; and select the image with the highest cover score from the images including two faces as the cover image. 11. the apparatus according to claim 8, wherein the face information comprises face feature points, and the face parameter comprises a face turning angle; the processor is configured to: acquire coordinate values of the face feature points; determine distances and angles between the face feature points; and determine the face turning angle according to the distances and the angles. 12. the apparatus according to claim 8, wherein the face parameter comprises a face ratio; the processor is configured to: determine a face region of the image according to the face information; and calculate a ratio of an area of the face region to an area of the image to obtain the face ratio. 13. the apparatus according to claim 12, wherein the processor is configured to: when there is more than one face in the image, subtract an area occupied faces other than a face corresponding to the photo album from the face region to obtain a remaining area; and calculate a ratio of the remaining area to the area of the image to obtain the face ratio. 14. the apparatus according to claim 8, wherein the processor is configured to: acquire image identifications of images in the photo album; extract face information corresponding to the image identifications from a face database, the face database being stored with face recognition results of images, the face recognition results including the face information. 15. an electronic device, comprising a processor, a memory, a display screen and an input device connected via a system bus, wherein the memory is stored with computer programs that, when executed by the processor, cause the processor to implement an image processing method, the image processing method comprising: acquiring a photo album obtained from face clustering; collecting face information of respective images in the photo album, and acquiring a face parameter of each image according to the face information; selecting a cover image according to the face parameter of each image; and taking a face-region image from the cover image, and setting the face-region image as a cover of the photo album; wherein selecting the cover image according to the face parameter of each image comprises: performing calculation on the face parameter of each image in a preset way, to obtain a cover score of each image; and selecting the image with a highest cover score as the cover image; and wherein selecting the image with the highest cover score as the cover image comprises: acquiring a source of each image; and selecting the image with the highest cover score in images coming from a preset source as the cover image. 16. the electronic device according to claim 15, wherein the electronic device comprises at least one of a mobile phone, a tablet computer, a personal digital assistant and a wearable device.1. a computer-implemented method, comprising: receiving, at a computing device, a meeting invitation identifying a location and at least one invitee, the meeting invitation configured to provide the at least one invitee with physical access to the location, wherein the meeting invitation causes a system to control a pathway allowing physical access to the location; providing, based on the meeting invitation, the at least one invitee with physical access to the location by controlling the pathway allowing the at least one invitee to physically access the location through the pathway in response to positioning data indicating that the at least one invitee is at a predetermined location near the location wherein the positioning data is based in part on a face recognition camera system identifying the at least one invitee; receiving the positioning data from the face recognition camera system identifying the at least one invitee, wherein the positioning data indicates a pattern of movement of the at least one invitee; determining that the pattern of movement indicates that the at least one invitee has exited the location; and revoking physical access to the location identified in the meeting invitation by controlling the pathway to restrict the at least one invitee identified in the meeting invitation from physical access to the location through the pathway, in response to determining that the pattern of movement indicates that the at least one invitee has exited the location. 2. the computer-implemented method of claim 1, wherein determining that the at least one invitee has exited the location comprises determining that the at least one invitee has passed through an egress associated with the location in a predetermined direction. 3. the computer-implemented method of claim 1, wherein determining that the at least one invitee has exited the location comprises determining that the at least one invitee has moved through an area in a predetermined direction. 4. the computer-implemented method of claim 1, wherein the positioning data indicates a second pattern of movement of the at least one invitee and, wherein access to secured data associated with the location is provided in response to detecting the second pattern of movement. 5. the computer-implemented method of claim 1, further comprising: collating secured data and public data to generate resource data; and communicating the resource data to a client computing device associated with the at least one invitee when access of the location is provided. 6. the computer-implemented method of claim 1, wherein the positioning data indicates that the at least one invitee is at the predetermined location when the at least one invitee passes through the predetermined location. 7. the computer-implemented method of claim 1, wherein the positioning data indicates that the at least one invitee is at the predetermined location when the at least one invitee passes through the predetermined location near the location in a predetermined direction. 8. a system, comprising: a processor; and a memory in communication with the processor, the memory having computer-readable instructions stored thereupon that, when executed by the processor, cause the processor to: receive a meeting invitation indicating a location and an identity, the meeting invitation configured to provide at least one invitee with physical access to the location, wherein the meeting invitation causes the system to control a pathway allowing physical access to the location; provide the at least one invitee associated with the identity access to the location by controlling the pathway allowing the at least one invitee to physically access the location through the pathway in response to positioning data indicating that the at least one invitee is at a predetermined location near the location, wherein the positioning data is based in part on a face recognition camera system identifying the at least one invitee; receive the positioning data from the face recognition camera system identifying the at least one invitee, wherein the positioning data indicates a pattern of movement of the at least one invitee; determine that the pattern of movement indicates that the at least one invitee has exited the location; and revoke physical access to the location identified in the meeting invitation by controlling the pathway to restrict the at least one invitee identified in the meeting invitation from physical access to the location through the pathway, in response to determining that the pattern of movement indicates that the at least one invitee has exited the location. 9. the system of claim 8, wherein determining that the at least one invitee has exited the location comprises determining that the at least one invitee has passed through an egress associated with the location. 10. the system of claim 8, wherein determining that the at least one invitee has exited the location comprises determining that the at least one invitee has moved through an area in a predetermined direction. 11. the system of claim 8, wherein the positioning data indicates a second pattern of movement of the at least one invitee and wherein access to secured data associated with the location is provided in response to detecting the second pattern of movement. 12. the system of claim 8, wherein the instructions further cause the processor to: collate secured data and public data to generate resource data; and communicate the resource data to a client computing device associated with the at least one invitee when access of the location is provided. 13. a non-transitory computer-readable storage medium having computer-executable instructions stored thereupon which, when executed by one or more processors of a computing device, cause the one or more processors of the computing device to: receive a meeting invitation indicating a location and an identity, the meeting invitation configured to provide at least one invitee with physical access to the location, wherein the meeting invitation causes a system to control a pathway allowing physical access to the location; provide the at least one invitee associated with the identity access to the location by controlling the pathway allowing the at least one invitee to physically access the location through the pathway in response to positioning data indicating that the at least one invitee is at a predetermined location near the location, wherein the positioning data is based in part on a face recognition camera system identifying the at least one invitee; receive the positioning data from the face recognition camera system identifying the at least one invitee, wherein the positioning data indicates a pattern of movement of the at least one invitee; determine that the pattern of movement indicates that the at least one invitee has exited the location; and revoke physical access to the location identified in the meeting invitation by controlling the pathway to restrict the at least one invitee identified in the meeting invitation from physical access to the location through the pathway, in response to determining that the pattern of movement indicates that the at least one invitee has exited the location. 14. the non-transitory computer-readable storage medium of claim 13, wherein determining that the at least one invitee has exited the location comprises determining that the at least one invitee has passed through an egress associated with the location. 15. the non-transitory computer-readable storage medium of claim 13, wherein the positioning data indicates a second pattern of movement of the at least one invitee and wherein access to secured data associated with the location is provided in response to detecting the second pattern of movement. 16. the non-transitory computer-readable storage medium of claim 13, wherein the instructions further cause the one or more processors to: collate secured data and public data to generate resource data; and communicate the resource data to a client computing device associated with the at least one invitee when access of the location is provided.1. a method, comprising: receiving a piece of content and salient data for the piece of content; based on the salient data, determining a first path for a viewport for the piece of content, wherein the first path for the viewport includes different salient events occurring in the piece of content at different times during playback of the piece of content; providing the viewport on a display device, wherein movement of the viewport is based on the first path for the viewport and the salient data during the playback; detecting an additional salient event in the piece of content that is not included in the first path for the viewport; and providing an indication for the additional salient event in the viewport during the playback. 2. the method of claim 1, wherein the salient data identifies each salient event in the piece of content, and the salient data indicates, for each salient event in the piece of content, a corresponding point location of the salient event in the piece of content and a corresponding time at which the salient event occurs during the playback. 3. the method of claim 2, wherein the salient data further indicates, for each salient event in the piece of content, a corresponding type of the salient event and a corresponding strength value of the salient event. 4. the method of claim 1, wherein the first path for the viewport controls the movement of the viewport to put the different salient events in a view of the viewport at the different times during the playback. 5. the method of claim 1, further comprising: detecting one or more salient events in the piece of content based on at least one of the following: visual data of the piece of content, audio data of the piece of content, or content consumption experience data for the piece of content; wherein the salient data is indicative of each salient event detected. 6. the method of claim 1, further comprising: detecting one or more salient events in the piece of content based on at least one of the following: face recognition, facial emotion recognition, object recognition, motion recognition, or metadata of the piece of content; wherein the salient data is indicative of each salient event detected. 7. the method of claim 1, further comprising: detecting user interaction with the indication, wherein the indication comprises an interactive hint; and in response to detecting the user interaction: adapting the first path for the viewport to a second path for the viewport based on the user interaction, wherein the second path for the viewport includes the additional salient event; and providing an updated viewport for the piece of content on the display device, wherein movement of the updated viewport is based on the second path for the viewport and the salient data during the playback, and the second path for the viewport controls the movement of the updated viewport to put the additional salient event in a view of the updated viewport. 8. the method of claim 7, further comprising: changing a weight assigned to the additional salient event and one or more other salient events in the piece of content having the same type as the additional salient event. 9. the method of claim 7, wherein the second path for the viewport includes one or more other salient events in the piece of content having the same type as the additional salient event. 10. a system, comprising: at least one processor; and a non-transitory processor-readable memory device storing instructions that when executed by the at least one processor causes the at least one processor to perform operations including: receiving a piece of content and salient data for the piece of content; based on the salient data, determining a first path for a viewport for the piece of content, wherein the first path for the viewport includes different salient events occurring in the piece of content at different times during playback of the piece of content; providing the viewport on a display device, wherein movement of the viewport is based on the first path for the viewport and the salient data during the playback; detecting an additional salient event in the piece of content that is not included in the first path for the viewport; and providing an indication for the additional salient event in the viewport during the playback. 11. the system of claim 10, wherein the salient data identifies each salient event in the piece of content, and the salient data indicates, for each salient event in the piece of content, a corresponding point location of the salient event in the piece of content and a corresponding time at which the salient event occurs during the playback. 12. the system of claim 11, wherein the salient data further indicates, for each salient event in the piece of content, a corresponding type of the salient event and a corresponding strength value of the salient event. 13. the system of claim 10, wherein the salient data is generated offline on a server. 14. the system of claim 10, the operations further comprising: detecting one or more salient events in the piece of content based on at least one of the following: visual data of the piece of content, audio data of the piece of content, or content consumption experience data for the piece of content; wherein the salient data is indicative of each salient event detected. 15. the system of claim 10, the operations further comprising: detecting one or more salient events in the piece of content based on at least one of the following: face recognition, facial emotion recognition, object recognition, motion recognition, or metadata of the piece of content; wherein the salient data is indicative of each salient event detected. 16. the system of claim 10, the operations further comprising: detecting user interaction with the indication, wherein the indication comprises an interactive hint; and in response to detecting the user interaction: adapting the first path for the viewport to a second path for the viewport based on the user interaction, wherein the second path for the viewport includes the additional salient event; and providing an updated viewport for the piece of content on the display device, wherein movement of the updated viewport is based on the second path for the viewport and the salient data during the playback, and the second path for the viewport controls the movement of the updated viewport to put the additional salient event in a view of the updated viewport. 17. the system of claim 16, the operations further comprising: changing a weight assigned to the additional salient event and one or more other salient events in the piece of content having the same type as the additional salient event. 18. the system of claim 16, wherein the second path for the viewport includes one or more other salient events in the piece of content having the same type as the additional salient event. 19. a non-transitory computer readable storage medium including instructions to perform a method comprising: receiving a piece of content and salient data for the piece of content; based on the salient data, determining a first path for a viewport for the piece of content, wherein the first path for the viewport includes different salient events occurring in the piece of content at different times during playback of the piece of content; providing the viewport on a display device, wherein movement of the viewport is based on the first path for the viewport and the salient data during the playback; detecting an additional salient event in the piece of content that is not included in the first path for the viewport; and providing an indication for the additional salient event in the viewport during the playback. 20. the computer readable storage medium of claim 19, the method further comprising: detecting user interaction with the indication, wherein the indication comprises an interactive hint; and in response to detecting the user interaction: adapting the first path for the viewport to a second path for the viewport based on the user interaction, wherein the second path for the viewport includes the additional salient event; and providing an updated viewport for the piece of content on the display device, wherein movement of the updated viewport is based on the second path for the viewport and the salient data during the playback, and the second path for the viewport controls the movement of the updated viewport to put the additional salient event in a view of the updated viewport.1. a mobile device with facial recognition, the mobile device comprising: one or more cameras; a processor device and memory coupled to the processor device, the processing system programmed to: receive a plurality of images from the one or more cameras; extract, with a feature extractor utilizing a convolutional neural network (cnn) with an enlarged intra-class variance of long-tail classes, feature vectors from each of the plurality of images; generate, with a feature generator, discriminative feature vectors for each of the feature vectors; classify, with a fully connected classifier, an identity from the discriminative feature vectors; and control an operation of the mobile device to react in accordance with the identity. 2. the mobile device as recited in claim 1, further includes a communication system. 3. the mobile device as recited in claim 1, wherein the operation tags the video with the identity and uploads the video to social media. 4. the mobile device as recited in claim 1, wherein the operation tags the video with the identity and sends the video to a user. 5. the mobile device as recited in claim 1, wherein the mobile device is a smart phone. 6. the mobile device as recited in claim 1, wherein the mobile device is a body cam. 7. the mobile device as recited in claim 1, further programmed to train the feature extractor, the feature generator, and the fully connected classifier with an alternative bi-stage strategy. 8. the mobile device as recited in claim 1, wherein the feature extractor shares covariance matrices across all classes to transfer intra-class variance from regular classes to the long-tail classes. 9. the mobile device as recited in claim 1, wherein the feature generator optimizes a softmax loss by joint regularization of weights and features through a magnitude of an inner product of the weights and features. 10. the mobile device as recited in claim 1, wherein the feature extractor averages the feature vector with a flipped feature vector, the flipped feature vector being generated from a horizontally flipped frame from one of the plurality of images. 11. the mobile device as recited in claim 1, wherein each of the plurality of images is selected from the group consisting of an image, a video, and a frame from the video. 12. the mobile device as recited in claim 2, wherein the communication system connects to a remote server that includes a facial recognition network. 13. the mobile device as recited in claim 7, wherein one stage of the alternative bi-stage strategy fixes the feature extractor and applies the feature generator to generate new transferred features that are more diverse and violate a decision boundary. 14. the mobile device as recited in claim 7, wherein one stage of the alternative bi-stage strategy fixes the fully connected classifier and updates the feature extractor and the feature generator. 15. a computer program product for a mobile device with facial recognition, the computer program product comprising a non-transitory computer readable storage medium having program instructions embodied therewith, the program instructions executable by a computer to cause the computer to perform a method comprising: receiving, by a processor device, a plurality of images; extracting, by the processor device with a feature extractor utilizing a convolutional neural network (cnn) with an enlarged intra-class variance of long-tail classes, feature vectors for each of the plurality of images; generating, by the processor device with a feature generator, discriminative feature vectors for each of the feature vectors; classifying, by the processor device utilizing a fully connected classifier, an identity from the discriminative feature vector; and controlling an operation of the mobile device to react in accordance with the identity. 16. a computer-implemented method for facial recognition in a mobile device, the method comprising: receiving, by a processor device, a plurality of images; extracting, by the processor device with a feature extractor utilizing a convolutional neural network (cnn) with an enlarged intra-class variance of long-tail classes, feature vectors for each of the plurality of images; generating, by the processor device with a feature generator, discriminative feature vectors for each of the feature vectors; classifying, by the processor device utilizing a fully connected classifier, an identity from the discriminative feature vector; and controlling an operation of the mobile device to react in accordance with the identity. 17. the computer-implemented method as recited in claim 16, wherein controlling includes tagging the video with the identity and uploading the video to social media. 18. the computer-implemented method as recited in claim 16, wherein controlling includes tagging the video with the identity and sending the video to a user. 19. the computer-implemented method as recited in claim 16, wherein extracting includes sharing covariance matrices across all classes to transfer intra-class variance from regular classes to the long-tail classes.1. a computing device comprising: a non-transitory machine readable medium storing a machine trained (mt) network comprising a plurality of layers of processing nodes, each processing node configured to: compute a first output value by combining a set of output values from a set of processing nodes, and use a piecewise linear cup function to compute a second output value from the first output value of the processing node, wherein the piecewise linear cup function prior to training of the mt network comprises at least (i) a first linear section with a first slope, followed by (ii) a second linear section with a negative second slope, followed by (iii) a third linear section with a negative third slope that is different from the second slope, followed by (iv) a fourth linear section with a positive fourth slope, followed by (v) a fifth linear section with a positive fifth slope that is different from the fourth slope, followed by (vi) a sixth linear section with a sixth slope, wherein the piecewise linear cup function is symmetric about a vertical axis between the third and fourth linear sections prior to training of the mt network; a content capturing circuit for capturing content for processing by the mt network; and a set of processing units for executing the processing nodes to process content captured by the content capturing circuit, wherein by training a set of parameters that define the piecewise linear cup function of each node in first and second pluralities of processing nodes, (i) each processing node in the first plurality of processing nodes is configured to emulate a boolean and operator such that an output value of the processing node is in a range associated with a \"1\" value only when a set of inputs to the processing node have a set of values in a range associated with \"1\" and (ii) each processing node in the second plurality of processing nodes is configured to emulate a boolean xnor operator such that an output value of the processing node is in the range associated with \"1\" only when (a) a set of inputs to the node have a set of values in a range associated with \"1\" or (b) the set of inputs to the node have a set of values in a range associated with a \"0\" value. 2. the computing device of claim 1, wherein the third linear section of the piecewise linear cup function of a first processing node in the mt network has a different slope from the third linear section of a second processing node in the mt network. 3. the computing device of claim 1, wherein the length of the third section of a piecewise linear cup function of a first processing node in the mt network is different from the length of the third section of a piecewise linear cup function of a second processing node in the mt network. 4. the computing device of claim 1, wherein the sets of parameters are trained in part by a back propagating module for back propagating errors in output values of later layers of processing nodes to earlier layers of processing nodes by adjusting the set of parameters that define the piecewise linear cup functions of the earlier layers of processing nodes. 5. the computing device of claim 4, wherein each processing node uses a linear function that is defined by a set of parameters to compute the first output value of the processing node, wherein the back propagating module back propagates errors in output values of later layers of processing nodes to earlier layers of processing nodes by adjusting the set of parameters that define the linear functions of the earlier layers of processing nodes. 6. the computing device of claim 1, wherein the first plurality of processing nodes that emulate the boolean and operator and the second plurality of processing nodes that emulate the boolean xnor operator enable the mt network to implement mathematical problems. 7. the computing device of claim 1, wherein each of a plurality of processing node layers has a plurality of processing nodes that receive as input values the output values from a plurality of processing nodes in a set of prior layers. 8. the computing device of claim 7, wherein each processing node uses a linear function to compute the first output value of the processing node, wherein each processing node\\'s piecewise linear cup function is defined along first and second axes, the first axis defining a range of output values from the processing node\\'s linear function, and the second axis defining a range of output values produced by the piecewise linear cup function for the range of output values from the processing node\\'s linear function. 9. the computing device of claim 1, further comprising: a content output circuit for presenting an output based on the processing of the content by the mt network. 10. the computing device of claim 9, wherein the captured content is one of an image and an audio segment, and wherein the presented output is an output display on a display screen of the computing device or an audio presentation output on a speaker of the computing device. 11. the computing device of claim 10, wherein the computing device is a mobile device. 12. the computing device of claim 1, wherein the mt network is a mt neural network and the processing nodes are mt neurons. 13. the computing device of claim 1, wherein the set of parameters configured through training for a plurality of the processing nodes comprise at least one of the negative second and third slopes for the second and third linear sections, the positive fourth and fifth slopes for the fourth and fifth linear sections, a first intercept for the second linear section, a second intercept for the fifth linear section, and a set of lengths for at least the second, third, fourth, and fifth sections. 14. the computing device of claim 1, wherein the trained set of parameters that define the piecewise linear cup function of each node comprise a plurality of output values. 15. the computing device of claim 1, wherein the first and sixth slopes are zero.we claim: 1. a system comprising: a memory device to store an input image; a processor including, an image input interface to receive the input image, a pre-processor to model the input image to yield a multi-channel image, a feature extractor to extract a set of features based on the multi-channel image, a feature selector to select one or more features from the set of features of the multi-channel image, wherein the one or more features are selected based on an ability to differentiate features, a feature matcher to match the one or more features to a learned feature set, and a similarity detector to determine whether the one or more features meet a pre-defined similarity threshold. 2. the system of claim 1, wherein the pre-processor further is to activate one or more channels of the multi-channel image to yield one or more activated channels. 3. the system of claim 2, wherein the one or more activated channels are to be determined based on their ability to differentiate features. 4. the system of claim 2, wherein the pre-processor further is to activate one or more local patches of the one or more activated channels. 5. the system of claim 4, wherein the one or more local patches are to be determined based on their ability to differentiate features. 6. the system of claim 1, wherein the feature matcher further is to utilize a large-scale data learning process to perform the feature matching. 7. an apparatus comprising: an image input interface to receive an input image; a pre-processor to model the input image to yield a multi-channel image; a feature extractor to extract a set of features based on the multi-channel image; a feature selector to select one or more features from the set of features of the multi-channel image, wherein the one or more features are selected based on an ability to differentiate features; a feature matcher to match the one or more features to a learned feature set; and a similarity detector to determine whether the one or more features meet a pre-defined similarity threshold. 8. the apparatus of claim 7, wherein the pre-processor further is to activate one or more channels of the multi-channel image to yield one or more activated channels. 9. the apparatus of claim 8, wherein the one or more activated channels are to be determined based on their ability to differentiate features. 10. the apparatus of claim 8, wherein the pre-processor further is to activate one or more local patches of the one or more activated channels. 11. the apparatus of claim 10, wherein the one or more local patches are to be determined based on their ability to differentiate features. 12. the apparatus of claim 7, wherein the feature matcher further is to utilize a large-scale data learning process to perform the feature matching. 13. a method comprising: modeling an input image to yield a multi-channel image; extracting a set of features based on the multi-channel image; selecting one or more features from the set of features of the multi-channel image, wherein the one or more features are selected based on an ability to differentiate features; matching the one or more features to a learned feature set; and determining whether the one or more features meet a pre-defined similarity threshold. 14. the method of claim 13, wherein modeling the input image further is to include activating one or more channels of the multi-channel image to yield one or more activated channels. 15. the method of claim 14, wherein the one or more activated channels are to be determined based on their ability to differentiate features. 16. the method of claim 13, wherein extracting features of the input image further is to include activating one or more local patches of the one or more activated channels. 17. the method of claim 16, wherein the one or more local patches are to be determined based on their ability to differentiate features. 18. the method of claim 13, wherein the feature matcher utilizes a large-scale data learning process to perform the feature matching. 19. at least one non-transitory computer readable storage medium comprising a set of instructions which, when executed by a computing device, cause the computing device to: model an input image to yield a multi-channel image, extract a set of features based on the multi-channel image, select one or more features from the set of features of the multi-channel image, wherein the features are selected based on an ability to differentiate features, match the one or more features to a learned feature set, and determine whether the one or more features meet a pre-defined similarity threshold. 20. the at least one non-transitory computer readable storage medium of claim 19, wherein the instructions, when executed, cause a computing device to activate one or more channels of the multi-channel image to yield one or more activated channels. 21. the at least one non-transitory computer readable storage medium of claim 20, wherein the instructions, when executed, cause a computing device to determine the one or more activated channels based on their ability to differentiate features. 22. the at least one non-transitory computer readable storage medium of claim 20, wherein extracting features of the input image is to further include activating one or more local patches of the one or more activated channels. 23. the at least one non-transitory computer readable storage medium of claim 22, wherein the one or more local patches are to be determined based on their ability to differentiate features. 24. the at least one non-transitory computer readable storage medium of claim 19, wherein the feature matcher further is to utilize a large-scale data learning process to perform the feature matching. 25. an apparatus comprising: means for modeling an input image to yield a multi-channel image, means for extracting a set of features based on the multi-channel image, means for selecting one or more features from the set of features of the multi-channel image, wherein the one or more features are selected based on an ability to differentiate features, means for matching the one or more features to a learned feature set, and means for determining whether the one or more features meet a pre-defined similarity threshold.1. a method for controlling a terminal, the terminal comprising a capturing apparatus and at least one processor, the method comprising: acquiring, by the capturing apparatus, an image; obtaining, by the at least one processor, a motion parameter of the terminal, the motion parameter comprising at least one of a motion frequency or a motion time, and two or more parameters from among an acceleration, an angular velocity, a motion amplitude, the motion frequency, and the motion time; transmitting, by the at least one processor, a parameter threshold obtaining request to a data management server, the parameter threshold obtaining request comprising configuration information of the terminal; receiving corresponding preset thresholds that correspond to the configuration information in response to the parameter threshold obtaining request; comparing the two or more parameters with the corresponding preset thresholds; and controlling, by the at least one processor, not to perform image processing on the acquired image based on at least one of the two or more parameters of the motion parameter being greater than a corresponding preset threshold or based on the two or more parameters of the motion parameter being respectively greater than the corresponding preset thresholds, wherein the acquiring comprises acquiring the image in real time, and the obtaining comprises obtaining the motion parameter of the terminal in real time, the method further comprising: in response to the at least one of the two or more parameters of the motion parameter being greater than the corresponding preset threshold, obtaining the motion parameter of the terminal again; and in response to the two or more parameters of the motion parameter obtained at a latest time being less than or equal to the corresponding preset thresholds, performing the image processing on the image acquired at the latest time. 2. the method according to claim 1, wherein the acquiring comprises: controlling, by the at least one processor, to turn on the capturing apparatus based on a face recognition instruction; and acquiring, by the capturing apparatus, a face image when the capturing apparatus is turned on. 3. the method according to claim 2, wherein the controlling not to perform the image processing comprises: skipping performing face recognition on the acquired face image based on the at least one of the two or more parameters of the motion parameter being greater than the corresponding preset threshold or based on the two or more parameters of the motion parameter being respectively greater than the corresponding preset thresholds. 4. the method according to claim 1, wherein the obtaining comprises at least one of: obtaining the acceleration of the terminal by using an acceleration sensor; or obtaining the angular velocity of the terminal by using a gyro sensor. 5. the method according to claim 1, wherein the transmitting comprises: transmitting the parameter threshold obtaining request to the data management server according to a preset time period. 6. the method according to claim 1, further comprising: generating prompt information based on the at least one of the two or more parameters of the motion parameter being greater than the corresponding preset threshold, the prompt information being used for prompting the terminal to stop moving. 7. the method according to claim 1, wherein the motion parameter comprises the motion frequency and the motion time. 8. a terminal comprising: a capturing apparatus; at least one memory configured to store program code; and at least one processor configured to access the at least one memory and operate according to the program code, the program code comprising: motion parameter obtaining code configured to cause the at least one processor to acquire an image by using the capturing apparatus and obtain a motion parameter of the terminal, the motion parameter comprising at least one of a motion frequency or a motion time, and two or more parameters from among an acceleration, an angular velocity, a motion amplitude, the motion frequency, and the motion time; request transmitting code configured to cause the at least one processor to transmit a parameter threshold obtaining request to a data management server, the parameter threshold obtaining request comprising configuration information of the terminal; parameter threshold receiving code configured to cause the at least one processor to receive corresponding preset thresholds that correspond to the configuration information in response to the parameter threshold obtaining request; comparing code configured to cause the at least one processor to compare the two or more parameters with the corresponding preset thresholds; and control code configured to cause the at least one processor not to perform image processing on the acquired image based on at least one of the two or more parameters of the motion parameter being greater than a corresponding preset threshold or based on the two or more parameters of the motion parameter being respectively greater than the corresponding preset thresholds, wherein the motion parameter obtaining code causes the at least one processor to: acquire the image in real time and obtain the motion parameter of the terminal in real time, and in response to the at least one of the two or more parameters of the motion parameter being greater than the corresponding preset threshold, obtain the motion parameter of the terminal again, and wherein the control code causes the at least one processor to, in response to the two or more parameters of the motion parameter obtained at a latest time being less than or equal to the corresponding preset thresholds, perform the image processing on the image acquired at the latest time. 9. the terminal according to claim 8, wherein the program code further comprises face instruction receiving code configured to cause the at least one processor to receive a face recognition instruction, wherein the motion parameter obtaining code causes the at least one processor to control, according to the face recognition instruction, the capturing apparatus to turn on, and acquire a face image by using the capturing apparatus when the capturing apparatus is turned on; and wherein the control code causes the at least one processor to skip performing face recognition on the acquired face image based on the at least one of the two or more parameters of the motion parameter being greater than the corresponding preset threshold or based on the two or more parameters of the motion parameter being respectively greater than the corresponding preset thresholds. 10. the terminal according to claim 8, wherein the request transmitting code causes the at least one processor to transmit the parameter threshold obtaining request to the data management server according to a preset time period. 11. the terminal according to claim 8, wherein the program code further comprises: prompt information generation code configured to cause the at least one processor to generate prompt information based on at least one of the two or more parameters of the motion parameter being greater than the corresponding preset threshold, the prompt information being used for prompting the terminal to stop moving. 12. the terminal according to claim 8, wherein the motion parameter comprises the motion frequency and the motion time. 13. a non-transitory computer-readable storage medium, storing a machine instruction, which, when executed by one or more processors, causes the one or more processors to perform: obtaining an image acquired by a capturing apparatus; obtaining a motion parameter of a terminal, the terminal comprising the capturing apparatus, the motion parameter comprising at least one of a motion frequency or a motion time, and two or more parameters from among an acceleration, an angular velocity, a motion amplitude, the motion frequency, and the motion time; transmitting a parameter threshold obtaining request to a data management server, the parameter threshold obtaining request comprising configuration information of the terminal; receiving corresponding preset thresholds that correspond to the configuration information in response to the parameter threshold obtaining request; comparing the two or more parameters with the corresponding preset thresholds; and controlling not to perform image processing on an acquired image based on at least one of the two or more parameters of the motion parameter being greater than a corresponding preset threshold or based on the two or more parameters of the motion parameter being respectively greater than the corresponding preset thresholds, wherein the acquiring comprises acquiring the image in real time, and the obtaining comprises obtaining the motion parameter of the terminal in real time, the method further comprising: in response to the at least one of the two or more parameters of the motion parameter being greater than the corresponding preset threshold, obtaining the motion parameter of the terminal again; and in response to the two or more parameters of the motion parameter obtained at a latest time being less than or equal to the corresponding preset thresholds, performing the image processing on the image acquired at the latest time. 14. the non-transitory computer-readable storage medium according to claim 13, wherein the acquired image is a face image and the image processing comprises performing face recognition. 15. the non-transitory computer-readable storage medium according to claim 13, wherein the obtaining the motion parameter comprises at least one of: obtaining the acceleration of the terminal by using an acceleration sensor; or obtaining the angular velocity of the terminal by using a gyro sensor. 16. the non-transitory computer-readable storage medium according to claim 13, wherein the motion parameter comprises the motion frequency and the motion time.1. a method of processing a drive-through order, the method comprising: receiving customer information detected through vision recognition; providing product information to a customer based on the customer information; and processing a product order of the customer. 2. the method according to claim 1, wherein the receiving of customer information comprises at least one of receiving customer information associated with vehicle information detected through vehicle recognition, or receiving customer information associated with identification information detected through face recognition. 3. the method according to claim 1, further comprising determining whether the customer is a pre-order customer based on the customer information, wherein when the customer is determined to be a pre-order customer: the providing of product information based on the customer information comprises providing pre-order information using at least one of audio or video, and the processing of the product order of the customer comprises: providing information for promptly guiding a vehicle to a pickup stand using at least one of audio or video, and providing information that an additional order is available. 4. the method according to claim 1, wherein the product information based on the customer information comprises a most recently ordered product component and a most frequently ordered product component in an order history of the customer information. 5. the method according to claim 1, wherein the receiving of customer information comprises receiving information about an age and gender of a passenger detected through face recognition, and the providing of product information to a customer based on the customer information comprises providing recommended menu information differentiated according to the age and gender. 6. the method according to claim 1, wherein the processing of a product order of the customer comprises determining a product component in a past order history or a component modified from the product component as a product order. 7. the method according to claim 1, wherein the processing of a product order of the customer comprises paying a product price according to biometrics-based authentication through a communication system of a vehicle or a mobile terminal. 8. the method according to claim 1, wherein the processing of a product order of the customer comprises: issuing a payment number for a divided payment, and performing the divided payments according to payment requests of a plurality of mobile terminals to which the payment numbers are inputted. 9. the method according to claim 8, wherein the processing of a product order of the customer further comprises accumulating mileage in an account corresponding to the mobile terminal undergoing a payment. 10. the method according to claim 1, wherein the processing of a product order of the customer further comprises suggesting a takeout packaging method according to a temperature of a product, an atmospheric temperature, weather, and a vehicle type. 11. an apparatus configured to process a drive-through order, the apparatus comprising: a transceiver configured to receive customer information detected through vision recognition; a digital signage configured to provide product information to a customer based on the customer information; and a processor configured to process a product order of the customer. 12. the apparatus according to claim 11, wherein the transceiver receives at least one of customer information associated with vehicle information detected through vehicle recognition, or customer information associated with identification information detected through face recognition. 13. the apparatus according to claim 11, wherein the processor is configured to: determine whether the customer is a pre-order customer based on the customer information; and when the customer is determined to be a pre-order customer, perform a control operation to provide pre-order information, and control the digital signage to output information for promptly guiding a vehicle to a pickup stand and provide information that an additional order is available. 14. the apparatus according to claim 11, wherein the product information based on the customer information comprises a most recently ordered product component and a most frequently ordered product component in an order history of the customer information. 15. the apparatus according to claim 11, wherein the transceiver is configured to receive information about an age and gender of a passenger detected through face recognition, and the processor is configured to control the digital signage to provide recommended menu information differentiated according to the age and gender. 16. the apparatus according to claim 11, wherein the processor is configured to determine a product component in a past order history or a component modified from the product component as the product order. 17. the apparatus according to claim 11, wherein the processor is configured to pay a product price according to biometrics-based authentication through a communication system of a vehicle or a mobile terminal. 18. the apparatus according to claim 11, wherein the processor is configured to: issue a payment number for a divided payment; and perform the divided payments according to requests of a plurality of mobile terminals to which the payment numbers are inputted. 19. the apparatus according to claim 18, wherein the processor is configured to accumulate mileage in an account corresponding to the mobile terminal undergoing a payment. 20. the apparatus according to claim 11, wherein the processor is configured to control the digital signage to suggest a takeout packaging method according to a temperature of a product, an atmospheric temperature, weather, and a vehicle type.1. an image information processing method performed at a computing device having one or more processors and memory storing a plurality of programs to be executed by the one or more processors, the method comprising: identifying, using face recognition, one or more faces, each face corresponding to a respective person captured in a first image; for each identified face: extracting a set of profile parameters of a corresponding person in the first image; and selecting, from a plurality of image tiles, a first image tile that matches the face of the corresponding person in the first image in accordance with a predefined correspondence between the set of profile parameters of the corresponding person and a set of pre-stored description parameters of the first image tile; generating a second image by covering the faces of respective persons in the first image with their corresponding first image tiles; and sharing the first image and the second image in a predefined order via a group chat session. 2. the method of claim 1, wherein the first image and the second image are displayed in the group chat session one image at a time such that one of the two images is replaced by the other of the two images periodically. 3. the method of claim 1, wherein extracting a set of profile parameters of a corresponding person in the first image includes: determining one or more descriptive labels corresponding to the identified face of the corresponding person using a first machine learning model, wherein the first machine learning model is trained with the facial images and corresponding descriptive labels. 4. the method of claim 1, wherein extracting a set of profile parameters of a corresponding person in the first image includes: determining an identity of the corresponding person based on the identified face of the corresponding person; locating respective profile information of the first person based on the determined identity of the corresponding person; and using one or more characteristics in the respective profile information of the first person as the set of profile parameters corresponding to the identified face of the corresponding person. 5. the method of claim 1, wherein at least a first one of the first image tiles is a dynamic image tile and at least a second one of the first image tiles is a static image tile. 6. the method of claim 1, including: receiving a plurality of user comments from different users of the group chat session, each user comment including a descriptive term for a respective person identified in the first image; choosing a descriptive label for the respective person according to the plurality of user comments; and updating the second image by adding the descriptive label adjacent to the first image tile of the respective person. 7. a computing device for image information processing, comprising: one or more processors; and memory storing instructions which, when executed by the one or more processors, cause the processors to perform a plurality of operations comprising: identifying, using face recognition, one or more faces, each face corresponding to a respective person captured in a first image; for each identified face: extracting a set of profile parameters of a corresponding person in the first image; and selecting, from a plurality of image tiles, a first image tile that matches the face of the corresponding person in the first image in accordance with a predefined correspondence between the set of profile parameters of the corresponding person and a set of pre-stored description parameters of the first image tile; generating a second image by covering the faces of respective persons in the first image with their corresponding first image tiles; and sharing the first image and the second image in a predefined order via a group chat session. 8. the computing device of claim 7, wherein the first image and the second image are displayed in the group chat session one image at a time such that one of the two images is replaced by the other of the two images periodically. 9. the computing device of claim 7, wherein extracting a set of profile parameters of a corresponding person in the first image includes: determining one or more descriptive labels corresponding to the identified face of the corresponding person using a first machine learning model, wherein the first machine learning model is trained with the facial images and corresponding descriptive labels. 10. the computing device of claim 7, wherein extracting a set of profile parameters of a corresponding person in the first image includes: determining an identity of the corresponding person based on the identified face of the corresponding person; locating respective profile information of the first person based on the determined identity of the corresponding person; and using one or more characteristics in the respective profile information of the first person as the set of profile parameters corresponding to the identified face of the corresponding person. 11. the computing device of claim 7, wherein at least a first one of the first image tiles is a dynamic image tile and at least a second one of the first image tiles is a static image tile. 12. the computing device of claim 7, wherein the plurality of operations further include: receiving a plurality of user comments from different users of the group chat session, each user comment including a descriptive term for a respective person identified in the first image; choosing a descriptive label for the respective person according to the plurality of user comments; and updating the second image by adding the descriptive label adjacent to the first image tile of the respective person. 13. a non-transitory computer-readable storage medium storing instructions which, when executed by a computing device having one or more processors, cause the computing device to perform a plurality of operations comprising: identifying, using face recognition, one or more faces, each face corresponding to a respective person captured in a first image; for each identified face: extracting a set of profile parameters of a corresponding person in the first image; and selecting, from a plurality of image tiles, a first image tile that matches the face of the corresponding person in the first image in accordance with a predefined correspondence between the set of profile parameters of the corresponding person and a set of pre-stored description parameters of the first image tile; generating a second image by covering the faces of respective persons in the first image with their corresponding first image tiles; and sharing the first image and the second image in a predefined order via a group chat session. 14. the non-transitory computer-readable storage medium of claim 13, wherein the first image and the second image are displayed in the group chat session one image at a time such that one of the two images is replaced by the other of the two images periodically. 15. the non-transitory computer-readable storage medium of claim 13, wherein extracting a set of profile parameters of a corresponding person in the first image includes: determining one or more descriptive labels corresponding to the identified face of the corresponding person using a first machine learning model, wherein the first machine learning model is trained with the facial images and corresponding descriptive labels. 16. the non-transitory computer-readable storage medium of claim 13, wherein extracting a set of profile parameters of a corresponding person in the first image includes: determining an identity of the corresponding person based on the identified face of the corresponding person; locating respective profile information of the first person based on the determined identity of the corresponding person; and using one or more characteristics in the respective profile information of the first person as the set of profile parameters corresponding to the identified face of the corresponding person. 17. the non-transitory computer-readable storage medium of claim 13, wherein at least a first one of the first image tiles is a dynamic image tile and at least a second one of the first image tiles is a static image tile. 18. the non-transitory computer-readable storage medium of claim 13, wherein the plurality of operations further include: receiving a plurality of user comments from different users of the group chat session, each user comment including a descriptive term for a respective person identified in the first image; choosing a descriptive label for the respective person according to the plurality of user comments; and updating the second image by adding the descriptive label adjacent to the first image tile of the respective person.1. a method comprising, by a computing system: determining that a performance metric of an eye tracking system is below a first performance threshold, wherein the eye tracking system is associated with a head-mounted display worn by a user; based on the determination of the performance metric of the eye tracking system being below the first performance threshold, the computer system performing: receiving one or more first inputs associated with a body of the user; estimating a region that the user is looking at within a field of view of the head-mounted display based on the received one or more first inputs associated with the body of the user; determining a vergence distance of the user based at least on the one or more first inputs associated with the body of the user, the estimated region that the user is looking at, and locations of one or more objects in a scene displayed by the head-mounted display; and adjusting one or more configurations of the head-mounted display based on the determined vergence distance of the user. 2. the method of claim 1, wherein the one or more configurations of the head-mounted display comprise one or more of: a rendering image; a position of a display screen; or a position of an optics block. 3. the method of claim 1, further comprising: determining that the performance metric of the eye tracking system is above a second performance threshold; receiving eye tracking data from the eye tracking system; and determining the vergence distance of the user based on the eye tracking data and the one or more first inputs associated with the body of the user. 4. the method of claim 3, further comprising: receiving one or more second inputs associated with one or more displaying elements in the scene displayed by the head-mounted display; and determining the vergence distance of the user based at least on the eye tracking data, the one or more first inputs associated with the body of the user, and the one or more second inputs associated with the one or more displaying elements of the scene. 5. the method of claim 4, further comprising: feeding the one or more first inputs associated with the body of the user to a fusion algorithm, wherein the fusion algorithm assigns a weight score to each input of the one or more first inputs; determining the vergence distance of the user using the fusion algorithm based on the one or more first inputs associated with the body of the user; and determining a z-depth of a display screen and a confidence score based on the one or more first inputs associated with the body of the user 6. the method of claim 5, further comprising: comparing the confidence score to a confidence level threshold; in response to a determination that the confidence score is below the confidence level threshold, feeding the one or more second inputs associated with the one or more displaying elements of the scene to the fusion algorithm; and determining the z-depth of the display screen using the fusion algorithm based on the one or more first inputs associated with the body of the user and the one or more second inputs associated with the one or more displaying elements of the scene. 7. the method of claim 6, further comparing: comparing, by the fusion algorithm, confidence scores associated with a plurality of combinations of inputs; and determining, by the fusion algorithm, the z-depth of the display screen based on a combination of inputs associated with a highest confidence score. 8. the method of claim 6, wherein the z-depth and the confidence score are determined by the fusion algorithm using a piecewise comparison of the one or more first inputs and the one or more second inputs. 9. the method of claim 6, wherein the z-depth and the confidence score are determined based on a correlation between two or more inputs of the one or more first inputs and the one or more second inputs. 10. the method of claim 5, wherein the fusion algorithm comprises a machine learning (ml) algorithm, and wherein the machine learning (ml) algorithm determines a combination of first inputs fed to the fusion algorithm. 11. the method of claim 4, wherein the one or more first inputs associated with the body of the user comprise one or more of: a hand position; a hand direction; a hand movement; a hand gesture; a head position; a head direction; a head movement; a head gesture; a gaze angle; rea body gesture; a body posture; a body movement; a behavior of the user; or a weighted combination of one or more related parameters. 12. the method of claim 11, wherein the one or more first inputs associated with the body of the user are received from one or more of: a controller; a sensor; a camera; a microphone; an accelerometer; a headset worn by the user; or a mobile device. 13. the method of claim 4, wherein the one or more second inputs associated with the one or more displaying elements comprise one or more of: a z-buffer value associated with a displaying element; a displaying element marked by a developer; an image analysis result; a shape of a displaying element; a face recognition result; an object recognition result; a person identified in a displaying content; an object identified in a displaying content; a correlation of two or more displaying elements; or a weighted combination of the one or more second inputs. 14. the method of claim 1, further comprising: determining that the performance metric of the eye tracking system is below a second performance threshold; receiving one or more second inputs associated with one or more displaying elements in the scene displayed by the head-mounted display; and determining the vergence distance of the user based at least on the one or more first inputs associated with the body of the user and the one or more second inputs associated with the one or more displaying elements. 15. the method of claim 14, wherein determining that the performance metric of the eye tracking system is below the second performance threshold comprises determining that the eye tracking system does not exist or fails to provide eye tracking data. 16. the method of claim 1, wherein the performance metric of the eye tracking system comprises one or more of: an accuracy of a parameter from the eye tracking system; a precision of a parameter from the eye tracking system; a value of a parameter from the eye tracking system; a detectability of a pupil; a metric based on one or more parameters associated with the user; a parameter change; a parameter changing trend; a data availability; or a weighted combination of one or more performance related parameters. 17. the method of claim 16, wherein the one or more parameters associated with the user comprise one or more of: an eye distance of the user; a pupil position; a pupil status; a correlation of two pupils of the user; a head size of the user; a position of a headset worn by the user; an angle of the headset worn by the user; a direction of the headset worn by the user; an alignment of the eyes of the user; or a weighted combination of one or more related parameters associated with the user. 18. the method of claim 1, wherein the first performance threshold comprises one or more of: a pre-determined value; a pre-determined range; a state of a data; a changing speed of a data; or a trend of a data change. 19. one or more non-transitory computer-readable storage media embodying software that is operable when executed by a computing system to: determine that a performance metric of an eye tracking system is below a first performance threshold, wherein the eye tracking system is associated with a head-mounted display worn by a user; based on the determination of the performance metric of the eye tracking system being below the first performance threshold, the media embodying software operable when executed by the computing system to: receive one or more first inputs associated with a body of the user; estimate a region that the user is looking at within a field of view of the head-mounted display based on the received one or more first inputs associated with the body of the user; determine a vergence distance of the user based at least on the one or more first inputs associated with the body of the user, the estimated region that the user is looking at, and locations of one or more objects in a scene displayed by the head-mounted display; and adjust one or more configurations of the head-mounted display based on the determined vergence distance of the user. 20. a system comprising: one or more non-transitory computer-readable storage media embodying instructions; one or more processors coupled to the storage media and operable to execute the instructions to: determine that a performance metric of an eye tracking system is below a first performance threshold, wherein the eye tracking system is associated with a head-mounted display worn by a user; based on the determination of the performance metric of the eye tracking system being below the first performance threshold, the system is configured to: receive one or more first inputs associated with a body of the user; estimate a region that the user is looking at within a field of view of the head-mounted display based on the received one or more first inputs associated with the body of the user; determine a vergence distance of the user based at least on the one or more first inputs associated with the body of the user, the estimated region that the user is looking at, and locations of one or more objects in a scene displayed by the head-mounted display; and adjust one or more configurations of the head-mounted display based on the determined vergence distance of the user.1. a computer-implemented method for image-based, self-guided object detection, comprising: receiving, by a processor device, a set of images, each of the images having a respective grid thereon that is labeled regarding a respective object to be detected using grid level label data; training, by the processor device, a grid-based object detector using the grid level label data; determining, by the processor device, a respective bounding box for the respective object in each of the images, by applying local segmentation to each of the images; and training, by the processor device, a region-based convolutional neural network (rcnn) for joint object localization and object classification using the respective bounding box for the respective object in each of the images as an input to the rcnn. 2. the computer-implemented method of claim 1, further comprising performing an action responsive to the object localization and object classification for a respective new object in a new image to which the rcnn is applied. 3. the computer-implemented method of claim 2, wherein the action comprises autonomously controlling a motor vehicle to avoid a collision with the new object responsive to the object localization and object classification for the respective new object. 4. the computer-implemented method of claim 1, wherein the local segmentation is performed using a self-similarity search and template matching to provide the respective bounding box around the respective object in the set of images. 5. the computer-implemented method of claim 1, wherein the local segmentation is applied to each of the images to segment a respective target region therein. 6. the computer-implemented method of claim 1, wherein the region-based convolutional neural network (rcnn) forms a model during an object training stage that is to detect objects in new images during an inference stage. 7. the computer-implemented method of claim 1, wherein the method is performed by a system selected from the group consisting of a surveillance system, a face detection system, a face recognition system, a cancer detection system, an object tracking system, and an advanced driver-assistance system. 8. a computer program product for image-based, self-guided object detection, the computer program product comprising a non-transitory computer readable storage medium having program instructions embodied therewith, the program instructions executable by a computer to cause the computer to perform a method comprising: receiving, by a processor device, a set of images, each of the images having a respective grid thereon that is labeled regarding a respective object to be detected using grid level label data; training, by the processor device, a grid-based object detector using the grid level label data; determining, by the processor device, a respective bounding box for the respective object in each of the images, by applying local segmentation to each of the images; and training, by the processor device, a region-based convolutional neural network (rcnn) for joint object localization and object classification using the respective bounding box for the respective object in each of the images as an input to the rcnn. 9. the computer program product of claim 8, wherein the method further comprises performing an action responsive to the object localization and object classification for a respective new object in a new image to which the rcnn is applied. 10. the computer program product of claim 9, wherein the action comprises autonomously controlling a motor vehicle to avoid a collision with the new object responsive to the object localization and object classification for the respective new object. 11. the computer program product of claim 8, wherein the local segmentation is performed using a self-similarity search and template matching to provide the respective bounding box around the respective object in the set of images. 12. the computer program product of claim 8, wherein the local segmentation is applied to each of the images to segment a respective target region therein. 13. the computer program product of claim 8, wherein the region-based convolutional neural network (rcnn) forms a model during an object training stage that is to detect objects in new images during an inference stage. 14. the computer program product of claim 8, wherein the method is performed by a system selected from the group consisting of a surveillance system, a face detection system, a face recognition system, a cancer detection system, an object tracking system, and an advanced driver-assistance system. 15. a computer processing system for image-based, self-guided object detection, comprising: a memory device for storing program code; and a processor device for running the program code to receive a set of images, each of the images having a respective grid thereon that is labeled regarding a respective object to be detected using grid level label data; train a grid-based object detector using the grid level label data; determine a respective bounding box for the respective object in each of the images, by applying local segmentation to each of the images; and train a region-based convolutional neural network (rcnn) for joint object localization and object classification using the respective bounding box for the respective object in each of the images as an input to the rcnn. 16. the computer processing system of claim 15, wherein the processor device further runs the program code to perform an action responsive to the object localization and object classification for a respective new object in a new image to which the rcnn is applied. 17. the computer processing system of claim 16, wherein the action comprises autonomously controlling a motor vehicle to avoid a collision with the new object responsive to the object localization and object classification for the respective new object. 18. the computer processing system of claim 15, wherein the local segmentation is performed using a self-similarity search and template matching to provide the respective bounding box around the respective object in the set of images. 19. the computer processing system of claim 15, wherein the region-based convolutional neural network (rcnn) forms a model during an object training stage that is to detect objects in new images during an inference stage. 20. the computer processing system of claim 15, wherein the computer processing system is comprised in a system selected from the group consisting of a surveillance system, a face detection system, a face recognition system, a cancer detection system, an object tracking system, and an advanced driver-assistance system.1. a method of scalable, parallel, cloud-based face recognition utilizing a database of normalized stored images, comprising: capturing an image using a camera; detecting a face in the captured image; normalizing the detected facial image to match the normalized stored images; identifying facial features in the normalized detected facial image; generating a plurality of facial metrics from the facial features; calculating euclidean distances between the facial metrics of the normalized detected facial image with corresponding facial metrics of each of the stored images; comparing each euclidean distance against a predetermined threshold; responsive to the euclidean distance comparison, producing a reduced candidate list of best possible image matches from the normalized stored images; comparing, in parallel, the normalized detected facial image with each of the normalized stored images of the reduced candidate list utilizing a plurality of face recognition algorithms, where each processor of a parallel processing system uses a different face recognition algorithm; responsive to the comparison, producing best match results from each parallel subset of the reduced candidate list; and selecting a final match from the best match results using a deep learning neural network face recognition algorithm trained on outputs of individual face recognition algorithms. 2. the method of scalable, parallel, cloud-based face recognition of claim 1, wherein detecting a face in the captured image comprises: utilizing opencv to detect a face in the captured image; extracting the location of the eyes and a tip of the nose in the face; determining a distance between the eyes; cropping the face from the captured image, where the width and the height of a cropped face image is a function of the distance between the eyes; and rotating the face by an angle of rotation that is a function of the distance between the eyes. 3. the method of scalable, parallel, cloud-based face recognition of claim 2, wherein: the width of the cropped face image is 2.5 times the distance between the eyes; the height of the cropped face image is 3.5 times the distance between the eyes; and the angle of rotation is an angle formed by a straight line joining the eyes and an x-axis of the face. 4. the method of scalable, parallel, cloud-based face recognition of claim 3, wherein rotating the face comprises rotating the face to provide a frontal face pattern. 5. the method of scalable, parallel, cloud-based face recognition of claim 4, further comprising the step of proportionally rescaling the cropped and rotated image. 6. the method of scalable, parallel, cloud-based face recognition of claim 5, where the proportional rescaling yields a cropped and rotated image with a size of 100=100 pixels. 7. the method of scalable, parallel, cloud-based face recognition of claim 1, wherein the facial features identified in the normalized detected facial image comprise a pair of eyes, a tip of a nose, a mouth, a center of the mouth, and a chin area comprising a bottom, a top left landmark, and a top right landmark. 8. the method of scalable, parallel, cloud-based face recognition of claim 7, wherein generating a plurality of facial metrics comprises: calculating a distance between the pair of eyes, a distance between the eyes and the tip of the nose, a distance equal to the width of the mouth, a distance between the tip of the nose and the center of mouth, a distance between the bottom of chin and the center of mouth, a distance between the top left landmark on the chin and the tip of the nose, and a distance between the top right landmark on the chin and the tip of the nose. 9. the method of scalable, parallel, cloud-based face recognition of claim 8, wherein performing a euclidean distance match further comprises: partitioning the normalized stored images into a plurality of substantially equal subsets; performing a euclidean distance match between the facial metrics of the normalized detected facial image and corresponding facial metrics of each of the stored images of the subsets of the normalized stored images with a separate processor of a parallel processing system to generate a euclidean distance for each stored image of the subset; comparing each euclidean distance against a predetermined threshold with the separate processors; responsive to the euclidean distance comparison, producing a reduced candidate list of best possible image matches from the normalized stored images of each subset; and combining the reduced candidate lists from each subset to produce a single reduced candidate list. 10. the method of scalable, parallel, cloud-based face recognition of claim 9, wherein the plurality of face recognition algorithms utilized in comparing, in parallel, the normalized detected facial image with each of the normalized stored images of the reduced candidate list, consists of face recognition algorithms selected from a group consisting of principle component analysis (pca)-based algorithms, linear discriminant analysis (lda) algorithms, independent component analysis (ica) algorithms, kernel-based algorithms, feature-based techniques, algorithms based on neural networks, algorithms based on transforms, and model-based face recognition algorithms. 11. the method of scalable, parallel, cloud-based face recognition of claim 10, wherein the pca-based algorithms include eigenfaces for face detection/recognition, and the lda algorithms include the fisherfaces method of face recognition. 12. the method of scalable, parallel, cloud-based face recognition of claim 1, wherein comparing, in parallel, the captured image with each of the normalized stored images of the reduced candidate list further comprises: partitioning the reduced candidate list into a plurality of substantially equal subsets; processing each subset in a different processor of the parallel processing system uses a unique face recognition algorithm to produce the best match results; and using a reduce function of a mapreduce program to combine the best match results from each of the subsets to produce a single set of the best match results. 13. the method of scalable, parallel, cloud-based face recognition of claim 12, wherein partitioning the reduced candidate list comprises: selecting the images comprising each subset by optimizing the variance between of each of the images according to the following equation: where m and n are the number of rows and columns of the face vector image, n is the number of groups, and σij is the standard deviation of image dimension i in the group j of the face image vector. 14. the method of scalable, parallel, cloud-based face recognition of claim 13, wherein selecting the images comprising each subset by optimizing the variance between each of the images according to the following equation: d(μi, μj) is the euclidean distance between the mean of the group i and the mean of group j, i is the face image vector, and l is the number of group levels. 15. the method of scalable, parallel, cloud-based face recognition of claim 1, where selecting a final match from the best match results utilizing a deep learning neural network face recognition algorithm comprises utilizing either an adaboost machine-learning algorithm or a neural networks machine-learning model. 16. the method of scalable, parallel, cloud-based face recognition of claim 1, where normalizing the detected facial image to match the normalized stored images includes normalizing the detected facial image to the same size, orientation, and illumination of the normalized stored images. 17. a non-transitory computer-readable medium containing executable program instructions for causing a computer to perform a method of face recognition, the method comprising: detecting a face in an image captured by a camera; normalizing the detected facial image to match the normalized stored images; identifying facial features in the normalized detected facial image; generating a plurality of facial metrics from the facial features; calculating euclidean distances between the facial metrics of the normalized detected facial image with corresponding facial metrics of each of the stored images; comparing each euclidean distance against a predetermined threshold; responsive to the euclidean distance comparison, producing a reduced candidate list of best possible image matches from the normalized stored images; comparing, in parallel, the captured image with each of the normalized stored images of the reduced candidate list utilizing a plurality of face recognition algorithms, where each processor of a parallel processing system uses a different face recognition algorithm; responsive to the comparison, producing best match results from each parallel subset of the reduced candidate list; and selecting a final match from the best match results using a deep learning neural network face recognition algorithm trained on outputs of individual face recognition algorithms. 18. the non-transitory computer-readable medium containing executable program instructions of claim 17, wherein the plurality of face recognition algorithms utilized in comparing, in parallel, the normalized detected facial image with each of the normalized stored images of the reduced candidate list, consists of face recognition algorithms selected from a group consisting of principle component analysis (pca)-based algorithms, linear discriminant analysis (lda) algorithms, independent component analysis (ica) algorithms, kernel-based algorithms, feature-based techniques, algorithms based on neural networks, algorithms based on transforms, and model-based face recognition algorithms. 19. the non-transitory computer-readable medium containing executable program instructions of claim 18, wherein the pca-based algorithms include eigenfaces for face detection/recognition, and the lda algorithms include the fisherfaces method of face recognition. 20. the non-transitory computer-readable medium containing executable program instructions of claim 17, where selecting a final match from the best match results utilizing a deep learning neural network face recognition algorithm comprises utilizing either an adaboost machine-learning algorithm or a neural networks machine-learning model.1. an imaging device, comprising: a condensing lens; an image sensor configured to detect light passing through the condensing lens and comprising a pixel matrix, wherein the pixel matrix comprises a plurality of phase detection pixel pairs and a plurality of regular pixels; and a processor configured to turn on the phase detection pixel pairs for autofocusing and output autofocused pixel data after completing the autofocusing, divide the autofocused pixel data into a first subframe and a second subframe, calculate image features of at least one of the first subframe and the second subframe, wherein the image features comprise module widths of a finder pattern, and the finder pattern has a predetermined ratio, a harr-like feature, or a gabor feature, and determine an operating resolution of the regular pixels according to the image features calculated from at least one of the first subframe and the second subframe divided from the autofocused pixel data. 2. the imaging device as claimed in claim 1, wherein each of the phase detection pixel pairs comprises: a first pixel and a second pixel; a cover layer covering upon a first region of the first pixel and upon a second region of the second pixel, wherein the first region and the second region are mirror symmetrical to each other; and a microlens aligned with at least one of the first pixel and the second pixel. 3. the imaging device as claimed in claim 2, wherein the first region and the second region are 5% to 95% of an area of a single pixel. 4. the imaging device as claimed in claim 1, wherein the processor is configured to perform the autofocusing using a dual pixel autofocus technique according to pixel data of the phase detection pixel pairs before completing the autofocusing. 5. the imaging device as claimed in claim 1, wherein the processor is configured to divide pixel data of the phase detection pixel pairs into a third subframe and a fourth subframe before completing the autofocusing, and perform the autofocusing according to the third subframe and the fourth subframe. 6. the imaging device as claimed in claim 5, wherein the processor is further configured to calibrate brightness of the third subframe and the fourth subframe to be identical using a shading algorithm. 7. the imaging device as claimed in claim 1, wherein the operating resolution is selected as a first resolution smaller than a number of the regular pixels or as a second resolution larger than the first resolution. 8. the imaging device as claimed in claim 1, wherein the regular pixels are turned off in the autofocusing. 9. the imaging device as claimed in claim 1, wherein a number of the phase detection pixel pairs is smaller than that of the regular pixels. 10. an imaging device, comprising: a condensing lens; an image sensor configured to detect light passing through the condensing lens and comprising a pixel matrix, wherein the pixel matrix comprises a plurality of phase detection pixel pairs and a plurality of regular pixels; and a processor configured to turn on the phase detection pixel pairs for autofocusing and output autofocused pixel data after completing the autofocusing, divide the autofocused pixel data into a first subframe and a second subframe, calculate image features of at least one of the first subframe and the second subframe, wherein the image features comprise module widths of a finder pattern, and the finder pattern has a predetermined ratio, a harr-like feature, or a gabor feature, and select an image decoding or an image recognition using pixel data of the regular pixels according to the image features calculated from at least one of the first subframe and the second subframe divided from the autofocused pixel data. 11. the imaging device as claimed in claim 10, wherein each of the phase detection pixel pairs comprises: a first pixel and a second pixel; a cover layer covering upon a first region of the first pixel and upon a second region of the second pixel, wherein the first region and the second region are mirror symmetrical to each other; and a microlens aligned with at least one of the first pixel and the second pixel. 12. the imaging device as claimed in claim 10, wherein the processor is configured to perform the autofocusing using a dual pixel autofocus technique according to pixel data of the phase detection pixel pairs before completing the autofocusing. 13. the imaging device as claimed in claim 10, wherein the processor is configured to divide the pixel data of the phase detection pixel pairs into a third subframe and a fourth subframe before completing the autofocusing, calibrate brightness of the third subframe and the fourth subframe to be identical using a shading algorithm, and perform the autofocusing according to the third subframe and the fourth subframe. 14. the imaging device as claimed in claim 10, wherein the processor is configured to calculate the image features using at least one of a rule based algorithm and a machine learning algorithm. 15. the imaging device as claimed in claim 10, wherein the image decoding is decoding qr codes, and the image recognition is face recognition. 16. an operating method of an imaging device, the imaging device comprising a plurality of phase detection pixel pairs and a plurality of regular pixels, the operating method comprising: turning on the phase detection pixel pairs for autofocusing and outputting autofocused image frame after completing the autofocusing; dividing the autofocused image frame, acquired by the phase detection pixel pairs, into a first subframe and a second subframe; calculating image features of at least one of the first subframe and the second subframe, wherein the image feature comprise module widths of a finder pattern, and the finder pattern has a predetermined ratio, a harr-like feature, or a gabor feature; and selectively activating at least a part of the regular pixels according to the image features calculated from at least one of the first subframe and the second subframe divided from the autofocused image frame. 17. the operating method as claimed in claim 16, wherein the selectively activating comprises: activating a first part of the regular pixels to perform an image decoding according to pixel data of the first part of the regular pixels; or activating all the regular pixels to perform an image recognition according to pixel data of the all regular pixels. 18. the operating method as claimed in claim 17, wherein pixel data of the phase detection pixel pairs captured in a same frame with the pixel data of the regular pixels is also used in performing the image decoding and the image recognition. 19. the operating method as claimed in claim 17, wherein the image decoding is decoding qr codes, and the image recognition is face recognition. 20. the operating method as claimed in claim 16, wherein the phase detection pixel pairs are partially covered pixels or have a structure of dual pixel.1. an apparatus comprising: a first camera module configured to obtain a first image of an object with a first field of view; a second camera module configured to obtain a second image of the object with a second field of view different from the first field of view; a first depth map generator configured to generate a first depth map of the first image based on the first image and the second image; and a second depth map generator configured to generate a second depth map of the second image based on the first image, the second image, and the first depth map. 2. the apparatus of claim 1, wherein the first field of view is a narrow angle and the second field of view is a wider angle. 3. the apparatus of claim 2, wherein the second image is divided into a primary region and a residual region, and the second depth map generator comprises: a relationship estimating module configured to estimate a relationship between the primary region and the residual region based on the first image and the second image; and a depth map estimating module configured to estimate a depth map of the residual region based on the estimated relationship and the first depth map. 4. the apparatus of claim 3, wherein at least one of the relationship estimating module and the depth map estimating module performs an estimating operation based on a neural network module. 5. the apparatus of claim 1, further comprising: a depth map fusion unit configured to generate a third depth map of the second image by performing a fusion operation based on the first depth map and the second depth map. 6. the apparatus of claim 5, wherein the depth map fusion unit comprises: a tone mapping module configured to generate a tone-mapped second depth map to correspond to the first depth map by performing a bias removing operation on the second depth map; and a fusion module configured to generate the third depth map by fusing the tone-mapped second depth map and the first depth map. 7. the apparatus of claim 6, wherein the depth map fusion unit further comprises a propagating module configured to generate a propagated first depth map in the second image by iterated propagating of the first depth map based on the first depth map and the second image, and the fusion module generates the third depth map by fusing the tone-mapped second depth map and the propagated first depth map. 8. the apparatus of claim 6, wherein the depth map fusion unit further comprises a post-processing module configured to perform a post-processing operation on the third depth map generated by the fusion module to provide the post-processed third depth map. 9. the apparatus of claim 8, wherein the post-processing module performs the post-processing operation by filtering an interface generated in the third depth map in accordance with fusion of the fusion module. 10. the apparatus of claim 8, wherein the post-processing module removes artifacts generated in the third depth map in accordance with fusion of the fusion module. 11. the apparatus of claim 1, wherein the first depth map generator analyses a distance relationship between the first image and the second image, and generates a first depth map of the first image based on the distance relationship. 12. a method of processing an image of an electronic apparatus, the method comprising: obtaining a first image of an object using a first camera module; obtaining a second image of the object using a second camera module; generating a first depth map of the first image based on the first image and the second image; estimating a relationship between a primary region of the second image and a residual region of the second image based on the first image and the second image; and generating a second depth map of the second image based on the estimated relationship between the primary region and the residual region, and the first depth map. 13. the method of claim 12, wherein the electronic apparatus comprises a first camera module including a first lens having a first field of view and a second camera module including a second lens having a second field of view wider than the first field of view. 14. the method of claim 13, wherein the generating of the second depth map comprises: estimating a depth map of the residual region based on the estimated relationship between the primary region and the residual region, and the first depth map; and generating the second depth map based on a depth map of the residual region and the first depth map. 15. the method of claim 12, wherein the estimating of the relationship between a primary region of the second image is performed using a neural network model. 16. the method of claim 12, further comprising: performing a pre-processing operation on the second depth map; and generating a third depth map of the residual image by fusing the second depth map on which the pre-processing operation is performed and the first depth map. 17. the method of claim 16, wherein the performing of the pre-processing operation comprises performing a tone mapping operation between a depth map of the primary region and a depth map of the residual region based on the second depth map. 18. an operating method for an electronic apparatus, the electronic apparatus including; a first camera module providing a first image of an object using a first field of view and a second camera module providing a second image of the object using second field of view wider than the first field of view, and a processor generating a depth map of the second image based on a primary region of the second image and a residual region of the second image, the operating method comprising: generating a first depth map of the primary region by estimating a relationship between the first image and the second image; estimating a relationship between the primary region and the residual region based on the first image and the second image; generating a second depth map of the second image by estimating a depth map of the second region based on the estimated relationship between the primary region and the residual region; and generating a depth map of the second image by fusing the first depth map and the second depth map. 19. the operation method of claim 18, further comprising: executing an application that applies an image effect to the second image based on a depth map of the residual image. 20. the operation method of claim 19, wherein the application applies at least one image effect of auto-focusing, out-focusing, fore/background separation, face recognition, object detection within a frame, and augmented reality to the second image based on a depth map of the second image.1. a payment method based on a face recognition, comprising: acquiring first face image information of a target user; extracting first characteristic information from the first face image information, wherein the first characteristic information includes head posture information of the target user and gaze information of the target user; determining whether the target user has a willingness to pay according to the head posture information of the target user and the gaze information of the target user, including: determining whether an angle of rotation in each preset direction is less than an angle threshold, wherein the head posture information includes the angle of rotation in each preset direction; determining whether a probability value that a user gazes at a payment screen is greater than a probability threshold, wherein the gaze information includes the probability value that a user gazes at a payment screen; and in response to determining that the angle of rotation in each preset direction is less than the angle threshold and that the probability value that a user gazes at a payment screen is greater than the probability threshold, determining that the target user has a willingness to pay; and in response to determining that the target user has a willingness to pay, completing a payment operation based on the face recognition. 2. the method as claimed in claim 1, wherein the completing a payment operation based on the face recognition comprises: triggering and performing a payment initiating operation to acquire second face image information based on the face recognition; determining whether second characteristic information extracted from the second face image information indicates that the user has a willingness to pay; and in response to determining that the second characteristic information indicates that the user has a willingness to pay, triggering and performing a payment confirmation operation to complete the payment operation based on payment account information corresponding to the target user. 3. the method as claimed in claim 2, wherein the determining whether second characteristic information extracted from the second face image information indicates that the user has a willingness to pay comprises: determining whether a current user corresponding to the second face image information is consistent with the target user; and in response to determining that the current user is consistent with the target user, determining whether the target user has a willingness to pay according to the second characteristic information extracted from the second face image information. 4. the method as claimed in claim 1, wherein the extracting first characteristic information from the first face image information comprises: determining the head posture information of the target user using a head posture recognition model based on the first face image information; and determining the gaze information of the target user using a gaze information recognition model based on characteristics of an eye region in the first face image information. 5. the method as claimed in claim 4, wherein the head posture recognition model is obtained through training by: acquiring a first sample data set, wherein the first sample data set includes a plurality of pieces of first sample data, and each of the plurality of pieces of first sample data includes a correspondence between a sample face image and head posture information; determining mean image data and variance image data of a plurality of sample face images; for each of the plurality of pieces of first sample data, preprocessing the sample face image contained in each of the plurality of pieces of first sample data based on the mean image data and the variance image data to obtain a preprocessed sample face image; setting the preprocessed sample face image and the corresponding head posture information as a first model training sample; and performing training using a machine learning method and based on a plurality of first model training samples to obtain the head posture recognition model. 6. the method as claimed in claim 4, wherein the gaze information recognition model is obtained through training by: acquiring a second sample data set, wherein the second sample data set includes a plurality of pieces of second sample data, and each of the plurality of pieces of second sample data includes a correspondence between a sample eye image and gaze information; determining mean image data and variance image data of a plurality of sample eye images; for each of the plurality of pieces of second sample data, preprocessing the sample eye image contained in each of the plurality of pieces of second sample data based on the mean image data and the variance image data to obtain a preprocessed sample eye image; setting the preprocessed sample eye image and the corresponding gaze information as a second model training sample; and performing training using a machine learning method and based on a plurality of second model training samples to obtain the gaze information recognition model. 7. the method as claimed in claim 1, wherein the angle of rotation in each preset direction comprises a pitch angle, a yaw angle, and a roll angle, wherein the pitch angle refers to an angle of rotation around a x-axis, the yaw angle refers to an angle of rotation around a y-axis, and the roll angle refers to an angle of rotation around a z-axis. 8. a payment device based on a face recognition, comprising: a processor, and a non-transitory computer-readable storage medium storing instructions executable by the processor to cause the device to perform operations comprising: acquiring first face image information of a target user; extracting first characteristic information from the first face image information, wherein the first characteristic information includes head posture information of the target user and gaze information of the target user; determining whether the target user has a willingness to pay according to the head posture information of the target user and the gaze information of the target user, including: determining whether an angle of rotation in each preset direction is less than an angle threshold, wherein the head posture information includes the angle of rotation in each preset direction; determining whether a probability value that a user gazes at a payment screen is greater than a probability threshold, wherein the gaze information includes the probability value that a user gazes at a payment screen; and in response to determining that the angle of rotation in each preset direction is less than the angle threshold and that the probability value that a user gazes at a payment screen is greater than the probability threshold, determining that the target user has a willingness to pay; and in response to determining that the target user has a willingness to pay, completing a payment operation based on the face recognition. 9. the device as claimed in claim 8, wherein the completing a payment operation based on the face recognition comprises: triggering and performing a payment initiating operation to acquire second face image information based on the face recognition; determining whether second characteristic information extracted from the second face image information indicates that the user has a willingness to pay; and in response to determining that the second characteristic information indicates that the user has a willingness to pay, triggering and performing a payment confirmation operation to complete the payment operation based on payment account information corresponding to the target user. 10. the device as claimed in claim 9, wherein the determining whether second characteristic information extracted from the second face image information indicates that the user has a willingness to pay comprises: determining whether a current user corresponding to the second face image information is consistent with the target user; and in response to determining that the current user is consistent with the target user, determining whether the target user has a willingness to pay according to the second characteristic information extracted from the second face image information. 11. the device as claimed in claim 8, wherein the extracting first characteristic information from the first face image information comprises: determining the head posture information of the target user using a head posture recognition model based on the first face image information; and determining the gaze information of the target user using a gaze information recognition model based on characteristics of an eye region in the first face image information. 12. the device as claimed in claim 11, wherein the head posture recognition model is obtained through training by: acquiring a first sample data set, wherein the first sample data set includes a plurality of pieces of first sample data, and each of the plurality of pieces of first sample data includes a correspondence between a sample face image and head posture information; determining mean image data and variance image data of a plurality of sample face images; for each of the plurality of pieces of first sample data, preprocessing the sample face image contained in each of the plurality of pieces of first sample data based on the mean image data and the variance image data to obtain a preprocessed sample face image; setting the preprocessed sample face image and the corresponding head posture information as a first model training sample; and performing training using a machine learning method and based on a plurality of first model training samples to obtain the head posture recognition model. 13. the device as claimed in claim 11, wherein the gaze information recognition model is obtained through training by: acquiring a second sample data set, wherein the second sample data set includes a plurality of pieces of second sample data, and each of the plurality of pieces of second sample data includes a correspondence between a sample eye image and gaze information; determining mean image data and variance image data of a plurality of sample eye images; for each of the plurality of pieces of second sample data, preprocessing the sample eye image contained in each of the plurality of pieces of second sample data based on the mean image data and the variance image data to obtain a preprocessed sample eye image; setting the preprocessed sample eye image and the corresponding gaze information as a second model training sample; and performing training using a machine learning method and on a plurality of second model training samples to obtain the gaze information recognition model. 14. the device as claimed in claim 11, wherein the angle of rotation in each preset direction comprises a pitch angle, a yaw angle, and a roll angle, wherein the pitch angle refers to an angle of rotation around a x-axis, the yaw angle refers to an angle of rotation around a y-axis, and the roll angle refers to an angle of rotation around a z-axis. 15. a non-transitory computer-readable storage medium for a payment based on a face recognition, configured with instructions executable by one or more processors to cause the one or more processors to perform operations comprising: acquiring first face image information of a target user; extracting first characteristic information from the first face image information, wherein the first characteristic information includes head posture information of the target user, and gaze information of the target user; determining whether the target user has a willingness to pay according to the head posture information of the target user and the gaze information of the target user, including: determining whether an angle of rotation in each preset direction is less than an angle threshold, wherein the head posture information includes the angle of rotation in each preset direction; determining whether a probability value that a user gazes at a payment screen is greater than a probability threshold, wherein the gaze information includes the probability value that a user gazes at a payment screen; and in response to determining that the angle of rotation in each preset direction is less than the angle threshold and that the probability value that a user gazes at a payment screen is greater than the probability threshold, determining that the target user has a willingness to pay; and in response to determining that the target user has a willingness to pay, completing a payment operation based on the face recognition. 16. the storage medium as claimed in claim 15, wherein the completing a payment operation based on the face recognition comprises: triggering and performing a payment initiating operation to acquire second face image information based on the face recognition; determining whether second characteristic information extracted from the second face image information indicates that the user has a willingness to pay; and in response to determining that the second characteristic information indicates that the user has a willingness to pay, triggering and performing a payment confirmation operation to complete the payment operation based on payment account information corresponding to the target user. 17. the storage medium as claimed in claim 16, wherein the determining whether second characteristic information extracted from the second face image information indicates that the user has a willingness to pay comprises: determining whether a current user corresponding to the second face image information is consistent with the target user; and in response to determining that the current user is consistent with the target user, determining whether the target user has a willingness to pay according to the second characteristic information extracted from the second face image information. 18. the storage medium as claimed in claim 15, wherein the extracting first characteristic information from the first face image information comprises: determining the head posture information of the target user using a head posture recognition model based on the first face image information; and determining the gaze information of the target user using a gaze information recognition model based on characteristics of an eye region in the first face image information. 19. the storage medium as claimed in claim 18, wherein the head posture recognition model is obtained through training by: acquiring a first sample data set, wherein the first sample data set includes a plurality of pieces of first sample data, and each of the plurality of pieces of first sample data includes a correspondence between a sample face image and head posture information; determining mean image data and variance image data of a plurality of sample face images; for each of the plurality of pieces of first sample data, preprocessing the sample face image contained in each of the plurality of pieces of first sample data based on the mean image data and the variance image data to obtain a preprocessed sample face image; setting the preprocessed sample face image and the corresponding head posture information as a first model training sample; and performing training using a machine learning method and based on a plurality of first model training samples to obtain the head posture recognition model; and wherein the gaze information recognition model is obtained through training by: acquiring a second sample data set, wherein the second sample data set includes a plurality of pieces of second sample data, and each of the plurality of pieces of second sample data includes a correspondence between a sample eye image and gaze information; determining mean image data and variance image data of a plurality of sample eye images; for each of the plurality of pieces of second sample data, preprocessing the sample eye image contained in each of the plurality of pieces of second sample data based on the mean image data and the variance image data to obtain a preprocessed sample eye image; setting the preprocessed sample eye image and the corresponding gaze information as a second model training sample; and performing training using a machine learning method and based on a plurality of second model training samples to obtain the gaze information recognition model. 20. the storage medium as claimed in claim 18, wherein the angle of rotation in each preset direction comprises a pitch angle, a yaw angle, and a roll angle, wherein the pitch angle refers to an angle of rotation around a x-axis, the yaw angle refers to an angle of rotation around a y-axis, and the roll angle refers to an angle of rotation around a z-axis.1. a method comprising: detecting, by a motion detection module, a motion by a subject within a predetermined area of view; assigning a unique session identification number to the subject detected within a predetermined area of view; detecting a facial area of the subject detected within a predetermined area of view; generating an image of the facial area of the subject; assessing a quality of the image of the facial area of the subject; determining an identity of the subject based on the image of the facial area of the subject; identifying an intent of the subject; and authorizing access to a point of entry based on the determined identity of the subject and based on the intent of the subject. 2. the method of claim 1, further comprising: determining one or more additional subjects within the predetermined area of view; and assigning a unique session identification number to each of the one or more additional subjects detected within a predetermined area of view. 3. the method of claim 1, wherein the assessing a quality of the image of the facial area of the subject comprises: assessing whether the quality of the image of the facial area of the object equates predetermined metric of quality; and upon determining that the quality of the image of the facial area of the object is inferior to the predetermined metric of quality, discarding the image of the facial area of the subject and generating a second image of the facial area of the subject. 4. the method of claim 1, further comprising: detecting whether the facial area of the subject is photographic image; and upon detecting that the facial area of the subject is a photographic image, generating a warning and restrict access to the point of entry. 5. the method of claim 1, further comprising: conducing an incremental training of the image of the facial area of the subject. 6. the method of claim 5, wherein conducing an incremental training of the image of the facial area of the subject comprises: capturing a first image of the facial area having facial landmarks; converting the first image of the facial area into a first numeric vector; capturing a second image of the facial area having facial landmarks; converting the second image of the facial area into a second numeric vector; calculating a weighted mean of the first numeric vector and the second numeric vector, wherein the weighted mean represents a change in a facial area; and storing the weighted mean in the database. 7. the method of claim 1, wherein determining an identity of the subject based on the image of the facial area of the subject comprises: comparing the image of the facial area of the subject with a plurality of images stored in a database; and authenticating the subject. 8. the method of claim 1, wherein identifying an intent of the subject comprises: upon detecting the facial area in a bounding box, commencing authentication of the subject; calculating a directional vector of a face of the subject; determine an intent of the subject to gain access to the point of entry based on the directional vector of the face of the subject; granting the access to the point of entry based on authentication of the subject and based on determining the intent of the subject. 9. a non-transitory computer readable medium having program instructions stored thereon, that in response to execution by a computing device cause the computing device to perform operations comprising: detecting a motion by a subject within a predetermined area of view; assigning a unique session identification number to the subject detected within a predetermined area of view; detecting a facial area of the subject detected within a predetermined area of view; generating an image of the facial area of the subject; assessing a quality of the image of the facial area of the subject; determining an identity of the subject based on the image of the facial area of the subject; identifying an intent of the subject; and authorizing access to a point of entry based on the determined identity of the subject and based on the intent of the subject. 10. the non-transitory computer readable medium of claim 9, further comprising: determining one or more additional subjects within the predetermined area of view; and assigning a unique session identification number to each of the one or more additional subjects detected within a predetermined area of view. 11. the non-transitory computer readable medium of claim 9, wherein the assessing a quality of the image of the facial area of the subject comprises: assessing whether the quality of the image of the facial area of the object equates predetermined metric of quality; and upon determining that the quality of the image of the facial area of the object is inferior to the predetermined metric of quality, discarding the image of the facial area of the subject and generating a second image of the facial area of the subject. 12. the non-transitory computer readable medium of claim 9, further comprising: detecting whether the facial area of the subject is photographic image; and upon detecting that the facial area of the subject is a photographic image, generating a warning and restrict access to the access point. 13. the non-transitory computer readable medium of claim 9, further comprising: conducing an incremental training of the image of the facial area of the subject. 14. the non-transitory computer readable medium of claim 13, wherein conducing an incremental training of the image of the facial area of the subject comprises: capturing a first image of the facial area having facial landmarks; converting the first image of the facial area into a first numeric vector; capturing a second image of the facial area having facial landmarks; converting the second image of the facial area into a second numeric vector; calculating a weighted mean of the first numeric vector and the second numeric vector, wherein the weighted mean represents a change in a facial area; and storing the weighted mean in the database. 15. an apparatus for face recognition comprising: a processor; and a memory to store computer program instructions, the computer program instructions when executed on the processor cause the processor to perform operations comprising: detecting a motion by a subject within a predetermined area of view; assigning a unique session identification number to the subject detected within a predetermined area of view; detecting a facial area of the subject detected within a predetermined area of view; generating an image of the facial area of the subject; assessing a quality of the image of the facial area of the subject; determining an identity of the subject based on the image of the facial area of the subject; identifying an intent of the subject; and authorizing access to a point of entry based on the determined identity of the subject and based on the intent of the subject. 16. the apparatus of claim 15, further comprising: determining one or more additional subjects within the predetermined area of view; and assigning a unique session identification number to each of the one or more additional subjects detected within a predetermined area of view. 17. the apparatus of claim 15, wherein the assessing a quality of the image of the facial area of the subject comprises: assessing whether the quality of the image of the facial area of the object equates predetermined metric of quality; and upon determining that the quality of the image of the facial area of the object is inferior to the predetermined metric of quality, discarding the image of the facial area of the subject and generating a second image of the facial area of the subject. 18. the apparatus of claim 15, further comprising: detecting whether the facial area of the subject is photographic image; and upon detecting that the facial area of the subject is a photographic image, generating a warning and restrict access to the access point. 19. the apparatus of claim 15, further comprising: conducing an incremental training of the image of the facial area of the subject. 20. the apparatus of claim 15, wherein conducing an incremental training of the image of the facial area of the subject comprises: capturing a first image of the facial area having facial landmarks; converting the first image of the facial area into a first numeric vector; capturing a second image of the facial area having facial landmarks; converting the second image of the facial area into a second numeric vector; calculating a weighted mean of the first numeric vector and the second numeric vector, wherein the weighted mean represents a change in a facial area; and storing the weighted mean in the database.1. a robot, comprising: a body configured to rotate and to tilt; a camera coupled to the body and configured to rotate and tilt according to the rotate and the tilt of the body, wherein the camera is configured to acquire a video of a space; a face recognition unit configured to recognize respective faces of one or more persons in the video; a tracking unit configured to track motion of each of the recognized faces of the one or more persons; and a controller configured to: calculate a respective size of each of the faces of the one or more persons; select a first person, from among the one or more persons, based on the calculated sizes of the faces; and control at least one of a direction of the rotation of the camera, an angle of the tilt of the camera and a focal distance of the camera, based on the tracked motion of the recognized face of the first person. 2. the robot of claim 1, wherein the controller is configured to: control the direction of the rotation of the camera and the angle of the tilt of the camera to achieve an particular orientation of the camera relative to the face of the first person; and control a focal distance of the camera by comparing respective sizes of the face of the first person before and after motion of the first person. 3. the robot of claim 2, wherein the particular orientation occurs when the camera faces a general direction of the face of the first person. 4. the robot of claim 1, wherein the controller is configured to: normalize sizes of the faces of the one or more persons based on an interocular distance; and select the first person based on the normalized sizes of the faces of the one or more persons. 5. the robot of claim 1, wherein the controller is configured to: select a person having a largest face size, from among the one or more persons, as the first person. 6. the robot of claim 1, further comprising: a microphone configured to receive a spoken audio that is present in the space; wherein the controller is further configured to select the first person further based on the received spoken audio. 7. the robot of claim 6, wherein the controller is further configured to: control gain of the microphone by comparing respective sizes of the face of the first person before and after motion of the first person. 8. the robot of claim 6, wherein the controller is configured to: calculate a position from which the spoken audio is provided; and select the first person further based on whether the one or more persons are in the position from which the voice signal is provided. 9. the robot of claim 8, wherein the controller is configured to: select a second person as the first person, from among the one or more persons, when the second person is located in the position from which the spoken audio is provided. 10. the robot of claim 8, wherein the controller is configured to: select a second person having a largest face size as the first person, from among the one or more persons, when none of the one or more persons is located in the position from which the spoken audio is provided. 11. the robot of claim 8, wherein the controller is configured to: select a second person having a largest face size as the first person, from among the one or more persons, when a plurality of persons from among the one or more persons are located in the position from which the spoken audio is provided. 12. the robot of claim 1, further comprising: a speaker, wherein the controller is configured to: control volume of the speaker by comparing respective sizes of the face of the first person before and after motion of the first person. 13. the robot of claim 1, wherein the body is further configured to rotate in a lateral direction, and to tilt in an vertical direction. 14. an electronic device, comprising: a camera coupled to the body and configured to rotate and to tilt, wherein the camera is configured to acquire a video of a space within which one or more persons are positioned; and a processor configured to: recognize respective faces of the one or more persons in the video; track motion of each of the recognized faces of the one or more persons; calculate a respective size of each of the faces of the one or more persons; select a first person, from among the one or more persons, based on the calculated sizes of the faces; and control at least one of a direction of the rotation of the camera, an angle of the tilt of the camera and a focal distance of the camera, based on the tracked motion of the recognized face of the first person. 15. a method, comprising: acquiring, by a camera, a video of a space within which one or more persons are positioned; recognizing respective faces of the one or more persons in the video; tracking motion of each of the recognized faces of the one or more persons; calculating a respective size of each of the faces of the one or more persons; selecting a first person, from among the one or more persons, based on the calculated sizes of the faces; and controlling at least one of a direction of rotation of the camera, an angle of tilt of the camera and a focal distance of the camera, based on the tracked motion of the recognized face of the first person.1. a method of inferring topics from a multimodal file, the method comprising: receiving a multimodal file; extracting a set of entities from the multimodal file; linking the set of entities to produce a set of linked entities; obtaining reference information for the set of entities; based at least on the reference information, generating a graph of the set of linked entities, the graph comprising nodes and edges; based at least on the nodes and edges of the graph, determining clusters in the graph; based at least on the clusters in the graph, identifying topic candidates; extracting features from the clusters in the graph; based at least on the extracted features, selecting at least one topicid from among the topic candidates to represent at least one cluster; and indexing the multimodal file with the at least one topicid. 2. the method of claim 1 wherein the multimodal file comprises a video portion and an audio portion and wherein extracting a set of entities from the multimodal file comprises: detecting objects in the video portion of the multimodal file; and detecting text in the audio portion of the multimodal file. 3. the method of claim 2 wherein detecting objects comprises performing face recognition. 4. the method of claim 2 wherein detecting text comprises performing a speech to text process. 5. the method of claim 4 further comprising: identifying a language used in the audio portion of the multimodal file, and wherein performing a speech to text process comprises performing a speech to text process in the identified language. 6. the method of claim 4 further comprising: translating the detected text. 7. the method of claim 1 further comprising: determining significant clusters and insignificant clusters in the determined clusters, and wherein extracting features from the clusters in the graph comprises extracting features from the significant clusters in the graph. 8. the method of claim 1 wherein extracting features from the clusters in the graph comprises at least one process selected from the list consisting of: determining a graph diameter and determining a jaccard coefficient. 9. the method of claim 1 wherein selecting at least one topicid to represent at least one cluster comprises: based at least on the extracted features, mapping topic candidates into a probability interval; and based at least on the mapping, ranking topic candidates within the at least one cluster, and selecting the at least one topicid based at least on the ranking. 10. the method of claim 1 further comprising: translating the at least one topicid, and wherein indexing the multimodal file with the at least one topicid comprises indexing the multimodal file with the at least one translated topicid. 11. a system for inferring topics from a multimodal file, the system comprising: an entity extraction component comprising an object detection component and a speech to text component, operative to extract a set of entities from a multimodal file comprising a video portion and an audio portion; an entity linking component operative to link the extracted set of entities to produce a set of linked entities; an information retrieval component operative to obtain reference information for the extracted set of entities; a graphing and analysis component operative to: generate a graph of the set of linked entities, the graph comprising nodes and edges; based at least on the nodes and edges of the graph, determine clusters in the graph; based at least on the clusters in the graph, identify topic candidates; and extract features from the clusters in the graph; a topicid selection component operative to: rank the topic candidates within at least one cluster; and based at least on the ranking, select at least one topicid from among the topic candidates to represent at least one cluster; and a video indexer operative to index the multimodal file with the at least one topicid. 12. the system of claim 11 wherein the object detection component is operative to perform face recognition. 13. the system of claim 11 wherein the speech to text component is operative to extract entity information in at least two different languages. 14. one or more computer storage devices having computer-executable instructions stored thereon for inferring topics from a multimodal file, which, on execution by a computer, cause the computer to perform operations comprising: receiving a multimodal file comprising a video portion and an audio portion; extracting a set of entities from the multimodal file, wherein extracting a set of entities from the multimodal file comprises: detecting objects in the video portion of the multimodal file with face recognition; detecting text in the audio portion of the multimodal file with a speech to text process; and disambiguating among a set of detected entity names; linking the set of entities to produce a set of linked entities; obtaining reference information for the set of entities; based at least on the reference information, generating a graph of the set of linked entities, the graph comprising nodes and edges; based at least on the nodes and edges of the graph, determining clusters in the graph; determining significant clusters and insignificant clusters in the determined clusters; based at least on the significant clusters in the graph, identifying topic candidates; extracting features from the significant clusters in the graph; based at least on the extracted features, mapping the topic candidates into a probability interval; based at least on the mapping, ranking the topic candidates within at least one significant cluster, based on the ranking, selecting at least one topicid from among the topic candidates to represent the at least one significant cluster; and indexing the multimodal file with the at least one topicid. 15. the one or more computer storage devices of claim 14 wherein the operations further comprise: identifying a language used in the audio portion of the multimodal file, and detecting text in the audio portion of the multimodal file with a speech to text process comprises performing a speech to text process in the identified language.权利要求 1、 一种人脸识别方法,其特征在于,包括: 通过第一摄像头获取第一人脸图像; 提取所述第一人脸图像的第一人脸特征; 将所述第一人脸特征与预先存储的第二人脸特征进行对比,获得参考相似度,所述第 二人脸特征经第二摄像头获取的第二人脸图像的特征提取而得,所述第二摄像头与所述第 一摄像头属于不同类型的摄像头; 根据所述参考相似度确定所述第一人脸特征与所述第二人脸特征是否对应相同人。 2、 根据权利要求 1所述的方法,其特征在于, 所述第一摄像头为热成像摄像头,所述第二摄像头为可见光摄像头; 或者,所述第一摄像头为可见光摄像头,所述第一摄像头为热成像摄像头。 3、 根据权利要求 1或 2所述的方法,其特征在于,所述根据所述参考相似度确定所 述第一人脸特征与所述第二人脸特征是否对应相同人,包括: 根据所述参考相似度、 参考误报率以及相似度阈值确定所述第一人脸特征与所述第二 人脸特征是否对应相同人;其中,不同的误报率对应不同的相似度阈值。 4、 根据权利要求 1或 2所述的方法,其特征在于,所述根据所述参考相似度确定所 述第一人脸特征与所述第二人脸特征是否对应相同人,包括: 根据所述参考相似度以及阈值信息确定归一化后的参考相似度; 根据所述归一化后的参考相似度确定所述第一人脸特征与所述第二人脸特征是否对 应相同人。 5、 根据权利要求 1-4任一项所述的方法,其特征在于,所述提取所述第一人脸图像的 第_人脸特征,包括: 将所述第一人脸图像输入预先训练完成的神经网络,通过所述神经网络输出所述第一 人脸图像的第一人脸特征;其中,所述神经网络基于第一类型图像样本和第二类型图像样 本训练得到,所述第一类型图像样本和所述第二类型图像样本由不同类型的摄像头拍摄得 到,且所述第一类型图像样本和所述第二类型图像样本中包括人脸。 6、 根据权利要求 5 所述的方法,其特征在于,所述神经网络基于所述第一类型图像 样本、 所述第二类型图像样本和混合类型图像样本训练得到,所述混合类型图像样本由所 述第一类型图像样本和所述第二类型图像样本配对而得。 1、 根据权利要求 1-6任一项所述的方法,其特征在于,所述第一摄像头包括车载摄像 头,所述通过第一摄像头获取第一人脸图像,包括: 通过所述车载摄像头获取所述第一人脸图像,所述第一人脸图像包括车辆的用车人的 人脸图像。 8、 根据权利要求 7 所述的方法,其特征在于,所述用车人包括驾驶所述车辆的人、 乘坐所述车辆的人、 对所述车辆进行修理的人、 给所述车辆加油的人以及控制所述车辆的 人中的一项或多项。 9、 根据权利要求 7 所述的方法,其特征在于,所述用车人包括驾驶所述车辆的人, 所述通过所述车载摄像头获取所述第一人脸图像,包括: 在接收到触发指令的情况下,通过所述车载摄像头获取所述第一人脸图像; 或者,在所述车辆运行时,通过所述车载摄像头获取所述第一人脸图像; 或者,在所述车辆的运行速度达到参考速度的情况下,通过所述车载摄像头获取所述 第一人脸图像。 10、 根据权利要求 7-9任一项所述的方法,其特征在于,所述第二人脸图像为对所述 用车人进行人脸注册的图像,所述将所述第一人脸特征与预先存储的第二人脸特征进行对 比之前,所述方法还包括: 通过所述第二摄像头获取所述第二人脸图像; 提取所述第二人脸图像的第二人脸特征; 保存所述第二人脸图像的第二人脸特征。 11、 一种神经网络训练方法,其特征在于,包括: 获取第一类型图像样本和第二类型图像样本,所述第一类型图像样本和所述第二类型 图像样本由不同类型的摄像头拍摄得到,且所述第一类型图像样本和所述第二类型图像样 本中包括人脸; 根据所述第一类型图像样本和所述第二类型图像样本训练神经网络。 12、 根据权利要求 11所述的方法,其特征在于,所述根据所述第一类型图像样本和所 述第二类型图像样本训练神经网络,包括: 将所述第一类型图像样本和所述第二类型图像样本配对,得到所述第一类型图像样本 和所述第二类型图像样本的混合类型图像样本; 根据所述第一类型图像样本、 所述第二类型图像样本和所述混合类型图像样本,训练 所述神经网络。 13、 根据权利要求 12 所述的方法,其特征在于,所述根据所述第一类型图像样本、 所述第二类型图像样本和所述混合类型图像样本,训练所述神经网络,包括: 通过所述神经网络获取所述第一类型图像样本的人脸预测结果、 所述第二类型图像样 本的人脸预测结果和所述混合类型图像样本的人脸预测结果; 根据所述第一类型图像样本的人脸预测结果和人脸标注结果的差异、 所述第二类型图 像样本的人脸预测结果和人脸标注结果之间的差异、 以及所述混合类型图像样本的人脸预 测结果和人脸标注结果的差异,训练所述神经网络。 14、 根据权利要求 13 所述的方法,其特征在于,所述神经网络中包括第一分类器、 第二分类器和混合分类器,所述通过所述神经网络获取所述第一类型图像样本的人脸预测 结果、 所述第二类型图像样本的人脸预测结果和所述混合类型图像样本的人脸预测结果, 包括: 将所述第一类型图像样本的人脸特征输入至所述第一分类器中,得到所述第一类型图 像样本的人脸预测结果; 将所述第二类型图像样本的人脸特征输入至所述第二分类器中,得到所述第二类型图 像样本的人脸预测结果; 将所述混合类型图像样本的人脸特征输入至所述混合分类器中,得到所述混合类型图 像样本的人脸预测结果。 15、 根据权利要求 14所述的方法,其特征在于,所述方法还包括: 在训练完成的所述神经网络中去除所述第一分类器、 所述第二分类器和所述混合分类 器,得到用于进行人脸识别的神经网络。 16、 一种人脸识别装置,其特征在于,包括: 第一获取单元,用于通过第一摄像头获取第一人脸图像; 第一提取单元,用于提取所述第一人脸图像的第一人脸特征; 对比单元,用于将所述第一人脸特征与预先存储的第二人脸特征进行对比,获得参考 相似度,所述第二人脸特征经第二摄像头获取的第二人脸图像的特征提取而得,所述第二 摄像头与所述第一摄像头属于不同类型的摄像头; 确定单元,用于根据所述参考相似度确定所述第一人脸特征与所述第二人脸特征是否 对应相同人。 17、 根据权利要求 16所述的装置,其特征在于, 所述第一摄像头为热成像摄像头,所述第二摄像头为可见光摄像头; 或者,所述第一摄像头为可见光摄像头,所述第一摄像头为热成像摄像头。 18、 根据权利要求 16或 17所述的装置,其特征在于, 所述确定单元,具体用于根据所述参考相似度、 参考误报率以及相似度阈值确定所述 第一人脸特征与所述第二人脸特征是否对应相同人;其中,不同的误报率对应不同的相似 度阈值。 19、 根据权利要求 16或 17所述的装置,其特征在于, 所述确定单元,具体用于根据所述参考相似度以及阈值信息确定归一化后的参考相似 度;以及根据所述归一化后的参考相似度确定所述第一人脸特征与所述第二人脸特征是否 对应相同人。 20、 根据权利要求 16-19任_项所述的装置,其特征在于, 所述第一提取单元,具体用于将所述第一人脸图像输入预先训练完成的神经网络,通 过所述神经网络输出所述第一人脸图像的第一人脸特征;其中,所述神经网络基于第一类 型图像样本和第二类型图像样本训练得到,所述第一类型图像样本和所述第二类型图像样 本由不同类型的摄像头拍摄得到,且所述第一类型图像样本和所述第二类型图像样本中包 括人脸。 21、 根据权利要求 20 所述的装置,其特征在于,所述神经网络基于所述第一类型图 像样本、 所述第二类型图像样本和混合类型图像样本训练得到,所述混合类型图像样本由 所述第一类型图像样本和所述第二类型图像样本配对而得。 22、 根据权利要求 16-21任一项所述的装置,其特征在于,所述第一摄像头包括车载 摄像头, 所述第一获取单元,具体用于通过所述车载摄像头获取所述第一人脸图像,所述第一 人脸图像包括车辆的用车人的人脸图像。 23、 根据权利要求 22所述的装置,其特征在于,所述用车人包括驾驶所述车辆的人、 乘坐所述车辆的人、 对所述车辆进行修理的人、 给所述车辆加油的人以及控制所述车辆的 人中的一项或多项。 24、 根据权利要求 22所述的装置,其特征在于,所述用车人包括驾驶所述车辆的人, 所述第一获取单元,具体用于在接收到触发指令的情况下,通过所述车载摄像头获取所述 第一人脸图像; 或者,所述第一获取单元,具体用于在所述车辆运行时,通过所述车载摄像头获取所 述第 _人脸图像; 或者,所述第一获取单元,具体用于在所述车辆的运行速度达到参考速度的情况下, 通过所述车载摄像头获取所述第一人脸图像。 25、 根据权利要求 22-24任一项所述的装置,其特征在于,所述第二人脸图像为对所 述用车人进行人脸注册的图像,所述装置还包括: 第二获取单元,用于通过所述第二摄像头获取所述第二人脸图像; 第二提取单元,用于提取所述第二人脸图像的第二人脸特征; 保存单元,用于保存所述第二人脸图像的第二人脸特征。 26、 一种神经网络训练装置,其特征在于,包括: 获取单元,用于获取第一类型图像样本和第二类型图像样本,所述第一类型图像样本 和所述第二类型图像样本由不同类型的摄像头拍摄得到,且所述第一类型图像样本和所述 第二类型图像样本中包括人脸; 训练单元,用于根据所述第一类型图像样本和所述第二类型图像样本训练神经网络。 27、 根据权利要求 26所述的装置,其特征在于,所述训练单元包括: 配对子单元,用于将所述第一类型图像样本和所述第二类型图像样本配对,得到所述 第一类型图像样本和所述第二类型图像样本的混合类型图像样本; 训练子单元,用于根据所述第一类型图像样本、 所述第二类型图像样本和所述混合类 型图像样本,训练所述神经网络。 28、 根据权利要求 27所述的装置,其特征在于, 所述训练子单元,具体用于通过所述神经网络获取所述第一类型图像样本的人脸预测 结果、 所述第二类型图像样本的人脸预测结果和所述混合类型图像样本的人脸预测结果; 以及根据所述第一类型图像样本的人脸预测结果和人脸标注结果的差异、 所述第二类型图 像样本的人脸预测结果和人脸标注结果之间的差异、 以及所述混合类型图像样本的人脸预 测结果和人脸标注结果的差异,训练所述神经网络。 29、 根据权利要求 28 所述的装置,其特征在于,所述神经网络中包括第一分类器、 第二分类器和混合分类器, 所述训练子单元,具体用于将所述第一类型图像样本的人脸特征输入至所述第一分类 器中,得到所述第一类型图像样本的人脸预测结果;以及将所述第二类型图像样本的人脸 特征输入至所述第二分类器中,得到所述第二类型图像样本的人脸预测结果;以及将所述 混合类型图像样本的人脸特征输入至所述混合分类器中,得到所述混合类型图像样本的人 脸预测结果。 30、 根据权利要求 29所述的装置,其特征在于,所述装置还包括: 神经网络应用单元,用于在训练完成的所述神经网络中去除所述第一分类器、 所述第 二分类器和所述混合分类器,得到用于进行人脸识别的神经网络。 31、 一种电子设备,其特征在于,包括处理器和存储器,所述处理器和所述存储器耦 合;其中,所述存储器用于存储程序指令,所述程序指令被所述处理器执行时,使所述处 理器执行权利要求 1-10任一项所述的方法;和/或,使所述处理器执行权利要求 11-15任一 项所述的方法。 32、 一种计算机可读存储介质,其特征在于,所述计算机可读存储介质中存储有计算 机程序,所述计算机程序包括程序指令,所述程序指令当被处理器执行时,使所述处理器 执行权利要求 1-10任一项所述的方法;和/或,使所述处理器执行权利要求 11-15任一项所 述的方法。1. a system for alerting on vision impairment, said system comprising a processing unit configured and operable for receiving scene data being indicative of a scene of at least one consumer in an environment, identifying in the scene data a certain consumer, identifying an event being indicative of a behavioral compensation for vision impairment, and, upon identification of such an event, sending a notification relating to the vision impairment. 2. the system of claim 1, further comprising at least one sensing unit configured and operable for detecting the scene data. 3. the system of claim 2, wherein said at least one sensing unit comprises at least one of: at least one imaging unit configured and operable for capturing at least one image of at least a portion of a consumer\\'s body, at least one motion detector configured and operable for detecting consumer data being indicative of a motion of a consumer, or at least one eye tracker configured and operable for tracking eye motion of a consumer. 4. the system of claim 3, wherein the at least one imaging unit comprises a plurality of cameras placed at different heights. 5. the system of any one of claims 2 to 4, wherein said sensing unit is accommodated in an optical or digital eyewear frame display. 6. the system of any one of claims 1 to 5, wherein said processing unit is configured and operable for identifying a consumer\\'s condition, said consumer\\'s condition comprising consumer data being indicative of the consumer\\'s position and location relative to at least one object in the consumer\\'s environment; said consumer data comprises at least one of a consumer\\'s face, eyewear, posture, position, sound or motion. 7. the system of any one of claims 1 to 6, wherein said event comprises at least one position and orientation of head increase or decrease of viewing distance between the consumer and viewed object and changing the position of eyeglasses worn by the consumer. 8. the system of any one of claims 1 to 7, wherein said event is identified by identifying images having an image feature being indicative of behavioral compensation, performing a bruckner test, performing a hirschberg test, and measuring blink count/ frequency. 9. the system of claim 8, wherein the image feature being indicative of behavioral compensation comprises squinting, head orientation, certain distances between an object and consumer\\'s eyes, certain position of eyeglasses on the consumer\\'s face, strabismus, cataracts, and reflections from the eye. 10. the system of any one of claims 1 to 9, wherein the notification includes at least one of the data indicative of the identified event, data indicative of the identified consumer, ophthalmologic recommendations based on the identified event, or lack of events, or an appointment for a vision test. 11. the system of any one of claims 1 to 10, wherein said processing unit comprises a memory for storing at least one of a reference data indicative of behavioral compensation for vision impairment, data indicative of the notification, or data indicative of a follow-up of the notification. 12. the system of claim 11 , wherein said processing unit is configured for at least one of identifying the event upon comparison between the detected data and the reference data or determining a probability for a vision impairment of the consumer based on the comparison. 13. the system of any one of claims 1 to 12, wherein said processing unit comprises a communication interface being configured for sending the notification to at least one of the identified consumer or a third party. 14. the system of any one of claims 1 to 13, wherein said processing unit is configured for providing a frame recommendation. 15. the system of any one of claims 11 to 14, wherein said memory is configured for storing a database including a multiplicity of data sets related to a plurality of spectacle frame models and sizes. 16. the system according to claim 14 or 15, wherein said processing unit is configured and operable to correlate between frames parameters and ophthalmic prescriptions. 17. the system according to any of claims 14 to 16, wherein said processing unit is configured and operable to correlate between frames parameters and facial features. 18. the system according to any of claims 14 to 17, wherein said processing unit is configured and operable to correlate between frames parameters and eyewear preferences. 19. the system according to any of claims 14 to 18, comprising a server and at least one computer entity linked to the server via a network, wherein said network is configured to receive and respond to requests sent across the network; transmitting one or more modules of computer executable program instructions and displayable data to the network connected user computer platform in response to a request, wherein said modules include modules configured to: receive and transmit image information, transmitting a frame recommendation and an optical lens option recommendation based on received image information, for display by the network connected user computer platform. 20. a computer program instructions stored in the local storage that, when executed by a processing unit, cause the processing unit to: receive data being indicative of a scene of at least one consumer in an environment, identify in the data a certain consumer, identify an event being indicative of a behavioral compensation for vision impairment, and, upon identification of such an event, send a notification relating to the vision impairment. 21. a computer program product stored on a tangible computer readable medium, comprising: a library of software modules which cause a computer executing them to prompt for information pertinent to at least one of an eyeglasses recommendation and an optical lens option recommendation, to store said information or to display eyewear recommendations . 22. the computer program product of claim 21 , wherein said library further comprises a module for frame selection, point of sales and advertising. 23. a computer platform for facilitating eye glasses marketing or selection, comprising: a camera; a processor configured to execute computer program instructions to cause the processor to take an image of a consumer, identify in the image a certain consumer, identify an event being indicative of a behavioral compensation for vision impairment, and, upon identification of such an event, sending a notification relating to the vision impairment; local storage for processor executable instructions for carrying out storage of information. 24. a method for alerting on vision impairment; said method comprising: identifying a certain individual in scene data being indicative of a scene of at least one consumer in an environment; identifying an event being indicative of a behavioral compensation for vision impairment; and upon identification of such an event, sending a notification on the vision impairment. 25. the method of claim 24, further comprising detecting data being indicative of a scene of at least one consumer in a retail environment. 26. the method of claim 24, wherein detecting the data being indicative of at least one consumer comprises at least one of capturing at least one image of at least one consumer, detecting data being indicative of a motion of a consumer, or tracking an eye motion of a consumer. 27. the method of claim 26, wherein capturing at least one image of at least one consumer comprises continuously recording a scene. 28. the method of any one of claims 24 to 27, further comprising identifying, in the data, the consumer\\' s condition including data being indicative of the consumer\\'s position and location relative to the consumer\\'s environment; said data comprising at least one of the consumer\\'s face, posture, position, sound or motion. 29. the method of any one of claims 26 to 28, wherein said event comprises at least one of position and orientation of head, increase or decrease of viewing distance between the consumer and viewed object, or changing the position of eyeglasses worn by the consumer. 30. the method of any one of claims 26 to 29, wherein identifying of the event comprises identifying images having an image feature being indicative of behavioral compensation, performing a bruckner test, performing a hirschberg test, and measuring blink count/frequency. 31. the method of claim 30, wherein the image feature being indicative of behavioral compensation comprises squinting, head orientation, certain distances between an object and a consumer\\'s eyes, certain position of eyeglasses on the consumer\\'s face, strabismus, cataracts, and reflections from the eye. 32. the method of any one of claims 27 to 31, wherein identifying in the at least one image a consumer in a retail environment, comprising at least one of receiving data characterizing the retail environment, or performing face recognition. 33. the method of any one of claims 24 to 32, wherein sending a notification comprising sending the notification to at least one of the identified consumer or a third party. 34. the method of any one of claims 24 to 33, wherein the notification includes at least one of the data indicative of the identified event, data indicative of the identified consumer, ophthalmologic recommendations based on the identified event, or lack of events, and an appointment for a vision test. 35. the method of any one of claims 24 to 34, further comprising storing at least one of a reference data indicative of behavioral compensation for vision impairment, data indicative of the notification, or data indicative of a follow-up of the notification. 36. the method of claim 35, further comprising identifying the event upon comparison between the detected data and the reference data and determining a probability for a vision impairment of the consumer, based on the comparison. 37. a computer program intended to be stored in a memory of a processor unit of a computer system, or in a removable memory medium adapted to cooperate with a reader of the processor unit, comprising instructions for implementing the method according to any of claims 24 to 36.'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#white space removal for both sections\n",
    "def remove_whitespace(text):\n",
    "    return  \" \".join(text.split())\n",
    "\n",
    "lowera_text = remove_whitespace(lower_atext)\n",
    "lowera_text\n",
    "lowerc_text = remove_whitespace(lower_ctext)\n",
    "lowerc_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "94d36101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "an electronic apparatus including an image capturing device a storage device and a processor and an operation method thereof are provided the image capturing device captures an image for a user and the storage device records a plurality of modules the processor is coupled to the image capturing device and the storage device and is configured to configure the image capturing device to capture a head image of a user perform a face recognition operation to obtain a face region detect a plurality of facial landmarks within the face region estimate a head posture angle of the user according to the facial landmarks calculate a gaze position where the user gazes on the screen according to the head posture angle a plurality of rotation reference angle and a plurality of predetermined calibration positions and configure the screen to display a corresponding visual effect according to the gaze positionthe present disclosure provides a computation method and product thereof the computation method adopts a fusion method to perform machine learning computations technical effects of the present disclosure include fewer computations and less power consumptiona method for detecting body information on passengers of a vehicle based on humans' status recognition is provided the method includes steps of a passenger body information-detecting device a inputting an interior image of the vehicle into a face recognition network to detect faces of the passengers and output passenger feature information and inputting the interior image into a body recognition network to detect bodies and output body-part length information and b retrieving specific height mapping information by referring to a height mapping table of ratios of segment body portions of human groups to heights per the human groups acquiring a specific height of the specific passenger retrieving specific weight mapping information from a weight mapping table of correlations between the heights and weights per the human groups and acquiring a weight of the specific passenger by referring to the specific heighttechniques related to improved video coding based on face detection region extraction and tracking are discussed such techniques may include performing a facial search of a video frame to determine candidate face regions in the video frame testing the candidate face regions based on skin tone information to determine valid and invalid face regions rejecting invalid face regions and encoding the video frame based on valid face regions to generate a coded bitstreama method for managing a smart database which stores facial images for face recognition is provided the method includes steps of a managing device a counting specific facial images corresponding to a specific person in the smart database where new facial images are continuously stored and determining whether a first counted value representing a count of the specific facial images satisfies a first set value and b if the first counted value satisfies the first set value inputting the specific facial images into a neural aggregation network to generate quality scores of the specific facial images by aggregation of the specific facial images and if a second counted value representing a count of specific quality scores among the quality scores from a highest during counting thereof satisfies a second set value deleting part of the specific facial images corresponding to the uncounted quality scores from the smart databasea system capable of determining which recognition algorithms should be applied to regions of interest within digital representations is presented a preprocessing module utilizes one or more feature identification algorithms to determine regions of interest based on feature density the preprocessing modules leverages the feature density signature for each region to determine which of a plurality of diverse recognition modules should operate on the region of interest a specific embodiment that focuses on structured documents is also presented further the disclosed approach can be enhanced by addition of an object classifier that classifies types of objects found in the regions of interestdisclosed is a mobile terminal the mobile terminal may include a front camera obtaining a d face image of a user a glance sensor tilted by a certain angle and disposed adjacent to the front camera to obtain metadata of the d face image and a controller obtaining a distance between the glance sensor and the front camera the distance enabling an area of an overlap region where a first region representing a range photographable by the front camera overlaps a second region representing a range photographable by the glance sensor to be the maximumthis disclosure provides systems methods and apparatus including computer programs encoded on computer storage media for intelligent routing of notifications related to media programming in one aspect a smart television tv can be implemented to track a user's tv watching behavior and anticipate programming based on that behavior in some other aspects the smart tv can be implemented to detect a user's presence and based on that detection can automatically change the tv channel to media programming analyzed to be desirable to the user in some further aspects the smart tv can be implemented to transmit notification instructions to electronic devices within a network in an attempt to alert the user to upcoming media programming additionally the smart tv can be implemented to transmit detection instructions to the electronic devices within the network whereby the electronic devices attempt to detect a user's presence through voice or facial recognitiona camera is configured to output a test depth+multi-spectral image including a plurality of pixels each pixel corresponds to one of the plurality of sensors of a sensor array of the camera and includes at least a depth value and a spectral value for each spectral light sub-band of a plurality of spectral illuminators of the camera a face recognition machine is previously trained with a set of labeled training depth+multi-spectral images having a same structure as the test depth+multi-spectral image the face recognition machine is configured to output a confidence value indicating a likelihood that the test depth+multi-spectral image includes a faceembodiments of the present disclosure relate to an image processing method and apparatus and an electronic device the method includes acquiring a photo album obtained from face clustering collecting face information of respective images in the photo album and acquiring a face parameter of each image according to the face information selecting a cover image according to the face parameter of each image and taking a face-region image from the cover image and setting the face-region image as a cover of the photo albumtechniques described herein provide location-based access control to secured resources generally described configurations disclosed herein enable a system to dynamically modify access to secured resources based on one or more location-related actions for example techniques disclosed herein can enable a computing system to control access to resources such as computing devices display devices secured locations and secured data in some configurations the techniques disclosed herein can enable controlled access to secured resources based at least in part on an invitation associated with a location and positioning data indicating a location of a userone embodiment provides a method comprising receiving a piece of content and salient moments data for the piece of content the method further comprises based on the salient moments data determining a first path for a viewport for the piece of content the method further comprises displaying the viewport on a display device movement of the viewport is based on the first path during playback of the piece of content the method further comprises generating an augmentation for a salient moment occurring in the piece of content and presenting the augmentation in the viewport during a portion of the playback the augmentation comprises an interactive hint for guiding the viewport to the salient momenta computer-implemented method system and computer program product are provided for facial recognition the method includes receiving by a processor device a plurality of images the method also includes extracting by the processor device with a feature extractor utilizing a convolutional neural network cnn with an enlarged intra-class variance of long-tail classes feature vectors for each of the plurality of images the method additionally includes generating by the processor device with a feature generator discriminative feature vectors for each of the feature vectors the method further includes classifying by the processor device utilizing a fully connected classifier an identity from the discriminative feature vector the method also includes control an operation of a processor-based machine to react in accordance with the identitysome embodiments of the invention provide efficient expressive machine-trained networks for performing machine learning the machine-trained mt networks of some embodiments use novel processing nodes with novel activation functions that allow the mt network to efficiently define with fewer processing node layers a complex mathematical expression that solves a particular problem eg face recognition speech recognition etc in some embodiments the same activation function eg a cup function is used for numerous processing nodes of the mt network but through the machine learning this activation function is configured differently for different processing nodes so that different nodes can emulate or implement two or more different functions eg two or more boolean logical operators such as xor and and the activation function in some embodiments is a periodic function that can be configured to implement different functions eg different sinusoidal functionsmethods and systems may provide for facial recognition of at least one input image utilizing hierarchical feature learning and pair-wise classification receptive field theory may be used on the input image to generate a pre-processed multi-channel image channels in the pre-processed image may be activated based on the amount of feature rich details within the channels similarly local patches may be activated based on the discriminant features within the local patches features may be extracted from the local patches and the most discriminant features may be selected in order to perform feature matching on pair sets the system may utilize patch feature pooling pair-wise matching and large-scale training in order to quickly and accurately perform facial recognition at a low cost for both system memory and computationa method for controlling a terminal is provided the terminal includes a capturing apparatus and at least one processor an image is acquired by the capturing apparatus a motion parameter of the terminal is obtained image processing on the acquired image is controlled to be performed based on the motion parameter being equal to or less than a preset parameter threshold and skipped based on the motion parameter being greater than the preset parameter thresholda drive-through order processing method and apparatus are disclosed the drive-through order processing method includes receiving customer information detected through vision recognition providing product information based on the customer information and processing a product order of a customer according to the present disclosure it is possible to rapidly process an order using customer information based on customer recognition using an artificial intelligence ai model of machine learning through a g networkan image processing method performed at a computing device includes identifying using face recognition one or more faces each face corresponding to a respective person captured in a first image for each identified face extracting a set of profile parameters of a corresponding person in the first image and selecting from a plurality of image tiles a first image tile that matches the face of the corresponding person in the first image in accordance with a predefined correspondence between the set of profile parameters of the corresponding person and a set of pre-stored description parameters of the first image tile generating a second image by covering the faces of respective persons in the first image with their corresponding first image tiles and sharing the first image and the second image in a predefined order via a group chat sessionin one embodiment the artificial reality system determines that a performance metric of an eye tracking system is below a first performance threshold the eye tracking system is associated with a head-mounted display worn by a user the artificial reality system receives first inputs associated with the body of a user and determines a region that the user is looking at within a field of view of a head-mounted display based on the received first inputs the system determines a vergence distance of the user based at least on the first inputs associated with the body of the user the region that the user is looking at and locations of one or more objects in a scene displayed by the head-mounted display the system adjusts one or more configurations of the head-mounted display based on the determined vergence distance of the usera computer-implemented method is provided for image-based self-guided object detection the method includes receiving by a processor device a set of images each of the images has a respective grid thereon that is labeled regarding a respective object to be detected using grid level label data the method further includes training by the processor device a grid-based object detector using the grid level label data the method also includes determining by the processor device a respective bounding box for the respective object in each of the images by applying local segmentation to each of the images the method additionally includes training by the processor device a region-based convolutional neural network rcnn for joint object localization and object classification using the respective bounding box for the respective object in each of the images as an input to the rcnna system and method of face recognition comprising multiple phases implemented in a parallel architecture the first phase is a normalization phase whereby a captured image is normalized to the same size orientation and illumination of stored images in a preexisting database the second phase is a feature extractiondistance matrix phase where a distance matrix is generated for the captured image in a coarse recognition phase the generated distance matrix is compared with distance matrices in the database using euclidean distance matches to create candidate lists and in a detailed recognition phase multiple face recognition algorithms are applied to the candidate lists to produce a final result the distance matrices in the normalized database may be broken into parallel lists for parallelization in the feature extractiondistance matrix phase and the candidate lists may also be grouped according to a dissimilarity algorithm for parallel processing in the detailed recognition phasean imaging device including a pixel matrix and a processor is provided the pixel matrix includes a plurality of phase detection pixels and a plurality of regular pixels the processor performs autofocusing according to pixel data of the phase detection pixels and determines an operating resolution of the regular pixels according to autofocused pixel data of the phase detection pixels wherein the phase detection pixels are always-on pixels and the regular pixels are selectively turned on after the autofocusing is accomplishedan apparatus includes a first camera module providing a first image of an object with a first field of view a second camera module providing a second image of the object with a second field of view different from the first field of view a first depth map generator that generates a first depth map of the first image based on the first image and the second image and a second depth map generator that generates a second depth map of the second image based on the first image the second image and the first depth mapmethods systems and apparatus including computer programs encoded on computer storage media for a payment based on a face recognition are provided one of the methods includes acquiring first face image information of a target user extracting first characteristic information from the first face image information wherein the first characteristic information includes head posture information of the target user and gaze information of the target user determining whether the target user has a willingness to pay according to the head posture information of the target user and the gaze information of the target user including determining whether an angle of rotation in each preset direction is less than an angle threshold and whether a probability value that a user gazes at a payment screen is greater than a probability threshold and in response to determining that the target user has a willingness to pay completing a payment operation based on the face recognitiona novel method and apparatus for face authentication is disclosed the disclosed method comprises detecting a motion by a subject within a predetermined area of view assigning a unique session identification number to the subject detected within a predetermined area of view detecting a facial area of the subject detected within a predetermined area of view generating an image of the facial area of the subject assessing a quality of the image of the facial area of the subject conducing an incremental training of the image of the facial area of the subject determining an identity of the subject based on the image of the facial area of the subject identifying an intent of the subject and authorizing access to a point of entry based on the determined identity of the subject and based on the intent of the subjectdisclosed herein is a robot and an electronic device for acquiring video and a method for acquiring video using the robot the robot includes a camera configured to rotate in the lateral direction and tilt in the vertical direction and controls at least one of a direction of the rotation of the camera an angle of the tilt of the camera and a focal distance of the camera by recognizing and tracking users in a video acquired by the camerasystems and methods are disclosed for inferring topics from a file containing both audio and video for example a multimodal or multimedia file in order to facilitate video indexing a set of entities is extracted from the file and linked to produce a graph and reference information is also obtained for the set of entities entities may be drawn for example from wikipedia categories or other large ontological data sources analysis of the graph using unsupervised learning permits determining clusters in the graph extracting features from the clusters possibly using supervised learning provides for selection of topic identifiers the topic identifiers are then used for indexing the filea face recognition method a neural network training method an apparatus and an electronic device the method comprises obtaining a first face image by means of a first camera  extracting a first face feature of the first face image  comparing the first face feature with a pre-stored second face feature to obtain a reference similarity the second face feature being obtained by extracting a feature of a second face image obtained by a second camera and the second camera and the first camera being different types of cameras  and determining according to the reference similarity whether the first face feature and the second face feature correspond to a same person the present invention discloses a technique for alerting on vision impairment the system comprises a processing unit configured and operable for receiving scene data being indicative of a scene of at least one consumer in an environment identifying in the scene data a certain consumer identifying an event being indicative of a behavioral compensation for vision impairment and upon identification of such an event sending a notification relating to the vision impairment\n",
      " an electronic device  configured to make a screen  to display a plurality of image frames comprising an image capturing device  a storage device  storing a plurality of modules and a processor  coupled to the image capturing device  and the storage device  configured to execute the modules in the storage device  to configure the screen  to display a plurality of marker objects at a plurality of predetermined calibration positions configure the image capturing device  to capture a plurality of first head images when a user is looking at the predetermined calibration positions s perform a plurality of first face recognition operations on the first head images to obtain a plurality of first face regions corresponding to the predetermined calibration positions s detect a plurality of first facial landmarks corresponding to the first face regions s calculate a plurality of rotation reference angles of the user looking at the predetermined calibration positions according to the first facial landmarks configure the image capturing device  to capture a second head image of the user perform a second face recognition operation on the second head image to obtain a second face region detect a plurality of second facial landmarks within the second face region s estimate a head posture angle of the user according to the second facial landmarks calculate a gaze position of the user on the screen  according to the head posture angle the rotation reference angles and the predetermined calibration positions and configure the screen  to display a corresponding visual effect according to the gaze position  the electronic device  according to claim  wherein the gaze position comprises a first coordinate value in a first axial direction and a second coordinate value in a second axial direction  the electronic device  according to claim  wherein the head posture angles comprise a head pitch angle and a head yaw angle and the rotation reference angles comprise a first pitch angle a second pitch angle a first yaw angle and a second yaw angle corresponding to the predetermined calibration positions  the electronic device  according to claim  wherein the processor  performs interpolation operation or extrapolation operation according to the first yaw angle the second yaw angle a first position corresponding to the first yaw angle among the predetermined calibration positions a second position corresponding to the second yaw angle among the predetermined calibration positions and the head yaw angle thereby obtaining the first coordinate value of the gaze position and the processor  performs interpolation operation or extrapolation operation according to the first pitch angle the second pitch angle a third position corresponding to the first pitch angle among the predetermined calibration positions a fourth position corresponding to the second pitch angle among the predetermined calibration positions and the head pitch angle thereby obtaining the second coordinate value of the gaze position  the electronic device  according to claim  wherein the processor  calculates a plurality of first viewing distances between the user and the screen  according to the first facial landmarks the processor  estimates a second viewing distance between the user and the screen  according to the second facial landmarks and the processor  adjusts the rotation reference angles or the gaze position according to the second viewing distance and the first viewing distances  the electronic device  according to claim  wherein the processor  maps a plurality of two-dimensional position coordinates of the second facial landmarks under a plane coordinate system to a plurality of three-dimensional position coordinates under a three-dimensional coordinate system and the processor  estimates the head posture angle according to the three-dimensional position coordinates of the second facial landmarks  the electronic device  according to claim  wherein the second head image comprises a wearable device and the second facial landmarks do not comprise a plurality of third facial landmarks of the user covered by the wearable device  the electronic device  according to claim  wherein the second head image comprises a wearable device and the second facial landmarks comprise one or more simulated landmarks marked by the wearable device  an operating method adapted for an electronic device  comprising an image capturing device  and making a screen  to display a plurality of image frames the method comprising configuring the screen  to display a plurality of marker objects at a plurality of predetermined calibration positions configuring the image capturing device  to capture a plurality of first head images when a user is looking at the predetermined calibration positions s performing a plurality of first face recognition operations on the first head images to obtain a plurality of first face regions corresponding to the predetermined calibration positions s detecting a plurality of first facial landmarks corresponding to the first face regions s calculating a plurality of rotation reference angles of the user looking at the predetermined calibration positions according to the first facial landmarks configuring the image capturing device  to capture a second head image of the user performing a second face recognition operation on the second head image to obtain a second face region s detecting a plurality of second facial landmarks within the second face region estimating a head posture angle of the user according to the second facial landmarks calculating a gaze position of the user on the screen  according to the head posture angle the rotation reference angles and the predetermined calibration positions and s configuring the screen  to display a corresponding visual effect according to the gaze position  the operation method according to claim  wherein the gaze position comprises a first coordinate value in a first axial direction and a second coordinate value in a second axial direction  the operation method according to claim  wherein the head posture angles comprise a head pitch angle and a head yaw angle and the rotation reference angles comprise a first pitch angle a second pitch angle a first yaw angle and a second yaw angle corresponding to the predetermined calibration positions  the operation method according to claim  wherein the step of calculating the gaze position of the user on the screen  according to the head posture angle the rotation reference angles and the predetermined calibration positions comprises performing interpolation operation or extrapolation operation according to the first yaw angle the second yaw angle a first position corresponding to the first yaw angle among the predetermined calibration positions a second position corresponding to the second yaw angle among the predetermined calibration positions and the head yaw angle thereby obtaining the first coordinate value of the gaze position and performing interpolation operation or extrapolation operation according to the first pitch angle the second pitch angle a third position corresponding to the first pitch angle among the predetermined calibration positions a fourth position corresponding to the second pitch angle among the predetermined calibration positions and the head pitch angle thereby obtaining the second coordinate value of the gaze position  the operation method according to claim  wherein the method further comprises calculating a plurality of first viewing distances between the user and the screen  according to the first facial landmarks estimating a second viewing distance between the user and the screen  according to the second facial landmarks and adjusting the rotation reference angles or the gaze position according to the second viewing distance and the first viewing distances  the operation method according to claim  wherein the method further comprises mapping a plurality of two-dimensional position coordinates of the second facial landmarks under a plane coordinate system to a plurality of three-dimensional position coordinates under a three-dimensional coordinate system and estimating the head posture angle according to the three-dimensional position coordinates of the second facial landmarks  the operation method according to claim  wherein the second head image comprises a wearable device and the second facial landmarks do not comprise a plurality of third facial landmarks of the user covered by the wearable device  the operation method according to claim  wherein the second head image comprises a wearable device and the second facial landmarks comprise one or more simulated landmarks marked by the wearable device a computation method applied to a computing system wherein the computing system comprises a control unit a computation group and a general storage unit wherein the control unit comprises a first memory a decoding logic and a controller wherein the computation group comprises a group controller and a plurality of computing units the general storage unit is configured to store data and the computation method comprises receiving by the controller a first level instruction sequence and partitioning by the decoding logic the first level instruction sequence into a plurality of second level instruction sequences creating by the controller m threads for the plurality of second level instruction sequences and allocating by the controller an independent register as well as configuring an independent addressing function for each thread of the m threads wherein m is an integer greater than or equal to  and obtaining by the group controller a plurality of computation types of the plurality of second level instruction sequences obtaining a corresponding fusion computation manner of the computation types according to the plurality of computation types and adopting by the plurality of computing units the fusion computation manner to call the m threads for performing computations on the plurality of second level instruction sequences to obtain a final result  the method of claim  wherein the obtaining by the group controller a plurality of computation types of the plurality of second level instruction sequences obtaining a corresponding fusion computation manner of the computation types according to the plurality of computation types and adopting by the plurality of computing units the fusion computation manner to call the m threads for performing computations on the plurality of second instruction sequences to obtain a final result if the computation types represent computation operations of the same type the group controller calls a combined computation manner in which single instruction multiple data of the same type is in combination with single instruction multiple threads and uses the m threads to perform the combined computation manner to obtain a final result which includes partitioning by the decoding logic the m threads into n wraps for allocating to the the plurality of computing units converting by the group controller the plurality of second instruction sequences into a plurality of second control signals and sending the second control signals to the plurality of computing units calling by the plurality of computing units wraps that are allocated to the computing units and the second control signals to fetch corresponding data according to the independent addressing function performing by the plurality of computing units computations on the data to obtain a plurality of intermediate results and splicing the plurality of intermediate results to obtain a final result  the method of claim  wherein the obtaining by the group controller a plurality of computation types of the plurality of second level instruction sequences obtaining a corresponding fusion computation manner of the computation types according to the plurality of computation types and adopting by the plurality of computing units the fusion computation manner to call the m threads for performing computations on the plurality of second instruction sequences to obtain a final result if the computation types represent computation operations of different types the group controller calls simultaneous multi-threading and the m threads to perform computations to obtain a final result which includes partitioning by the decoding logic the m threads into n wraps converting the plurality of second instruction sequences into a plurality of second control signals obtaining by the group controller computation types supported by the plurality of computing units allocating by the controller the n wraps and the plurality of second control signals to corresponding computing units that support computation types of the wraps and the second control signals calling by the plurality of computing units wraps that are allocated to the computing units and the second control signals fetching by the plurality of computing units corresponding data performing by the plurality of computing units computations on the data to obtain a plurality of intermediate results and splicing all the intermediate results to obtain a final result  the method of claim  or  further comprising if a wrap a in the plurality of wraps is blocked adding the wrap a to a waiting queue and if data of the wrap a are already fetched adding the wrap a to a preparation queue wherein the preparation queue is a queue where a wrap to be scheduled for executing is located when a computing resource is idle  the method of claim  wherein the first level instruction sequence includes a very long instruction and the second level instruction sequence includes an instruction sequence  the method of claim  wherein the computing system further includes a tree module wherein the tree module includes a root port and a plurality of branch ports wherein the root port of the tree module is connected to the group controller and the plurality of branch ports of the tree module are connected to a computing unit of the plurality of computing units respectively and the tree module is configured to forward data blocks wraps or instruction sequences between the group controller and the plurality of computing units  the method of claim  wherein the tree module is an n-ary tree wherein n is an integer greater than or equal to   the method of claim  wherein the computing system further includes a branch processing circuit wherein the branch processing circuit is connected between the group controller and the plurality of computing units and the branch processing circuit is configured to forward data wraps or instruction sequences between the group controller and the plurality of computing units  a computing system comprising a control unit a computation group and a general storage unit wherein the control unit includes a first memory a decoding logic and a controller the computation group includes a group controller and a plurality of computing units the general storage unit is configured to store data the controller is configured to receive a first level instruction sequence and control the first memory and the decoding logic the decoding logic is configured to partition the first level instruction sequence into a plurality of second level instruction sequences the the controller is further configured to create m threads for the plurality of second level instruction sequences and allocate an independent register and configure an independent addressing function for each thread of the m threads m is an integer greater than or equal to  and the controller is further configured to convert the plurality of second instruction sequences into a plurality of control signals for sending to the group controller the group controller is configured to receive the plurality of control signals obtain a plurality of computational types if the plurality of control signals divide the m threads into n wraps and allocate the n wraps and the plurality of control signals to the plurality of computing units according to the plurality of computational types the plurality of computing units are configured to fetch data from the general storage unit through allocated wraps and control signals and perform computations to obtain an intermediate result and the group controller is configured to splice all intermediate results to obtain a final computation result  the computing system of claim  wherein the plurality of computing units includes an addition computing unit a multiplication computing unit an activation computing unit or a dedicated computing unit  the computing system of claim  wherein the dedicated computing unit includes a face recognition computing unit a graphics computing unit a fingerprint computing unit or a neural network computing unit  the computing system of claim  wherein the group controller is configured to if computation types of a plurality of control signals are graphics computations fingerprint identification face recognition or neural network operations allocate the plurality of control signals to the face recognition computing unit the graphics computing unit the fingerprint computing unit or the neural network computing unit respectively  the computing system of claim  wherein the first level instruction sequence includes a very long instruction and the second level instruction sequence includes an instruction sequence  the computing system of claim  further comprising a tree module wherein the tree module includes a root port and a plurality of branch ports wherein the root port of the tree module is connected to the group controller and the plurality of branch ports of the tree module are connected to a computing unit of the plurality of computing units respectively and the tree module is configured to forward data blocks wraps or instruction sequences between the group controller and the plurality of computing units  the computing system of claim  wherein the tree module is an n-ary tree wherein n is an integer greater than or equal to   the computing system of claim  wherein the computing system includes a branch processing circuit the branch processing circuit is connected between the group controller and the plurality of computing units and the branch processing circuit is configured to forward data wraps or instruction sequences between the group controller and the plurality of computing units  a computer program product comprising a non-instant computer readable storage medium wherein a computer program is stored in the non-instant computer readable storage medium and the computer program is capable of causing a computer to perform the method of any of claims - through operations a method for detecting body information on one or more passengers of a vehicle based on humans' status recognition comprising steps of a if at least one interior image of an interior of the vehicle is acquired a passenger body information-detecting device performing i a process of inputting the interior image into a face recognition network to thereby allow the face recognition network to detect each of faces of each of the passengers from the interior image and thus to output multiple pieces of passenger feature information corresponding to each of the detected faces and ii a process of inputting the interior image into a body recognition network to thereby allow the body recognition network to detect each of bodies of each of the passengers from the interior image and thus to output body-part length information of each of the detected bodies and b the passenger body information-detecting device performing a process of retrieving specific height mapping information corresponding to specific passenger feature information on a specific passenger from a height mapping table which stores height mapping information representing respective one or more predetermined ratios of one or more segment body portions of each of human groups to each of heights per each of the human groups a process of acquiring a specific height of the specific passenger from the specific height mapping information by referring to specific body-part length information of the specific passenger a process of retrieving specific weight mapping information corresponding to the specific passenger feature information from a weight mapping table which stores multiple pieces of weight mapping information representing predetermined correlations between each of the heights and each of weights per each of the human groups and a process of acquiring a weight of the specific passenger from the specific weight mapping information by referring to the specific height of the specific passenger  the method of claim  wherein at the step of a the passenger body information-detecting device performs a process of inputting the interior image into the body recognition network to thereby allow the body recognition network to i output one or more feature tensors with one or more channels corresponding to the interior image via a feature extraction network ii generate at least one keypoint heatmap and at least one part affinity field with one or more channels corresponding to each of the feature tensors via a keypoint heatmap & part affinity field extractor and iii extract keypoints from the keypoint heatmap via a keypoint detector to group the extracted keypoints by referring to the part affinity field and thus to generate body parts per the passengers and as a result allow the body recognition network to output multiple pieces of body-part length information on each of the passengers by referring to the body parts per the passengers  the method of claim  wherein the feature extraction network includes at least one convolutional layer and applies at least one convolution operation to the interior image to thereby output the feature tensors  the method of claim  wherein the keypoint heatmap & part affinity field extractor includes one of a fully convolutional network and a × convolutional layer and applies a fully-convolution operation or × convolution operation to the feature tensors to thereby generate the keypoint heatmap and the part affinity field  the method of claim  wherein the keypoint detector connects by referring to the part affinity field pairs respectively having highest mutual connection probabilities of being connected among the extracted keypoints to thereby group the extracted keypoints  the method of claim  wherein the feature extraction network and the keypoint heatmap & part affinity field extractor have been learned by a learning device performing i a process of inputting at least one training image including one or more objects for training into the feature extraction network to thereby allow the feature extraction network to generate one or more feature tensors for training having one or more channels by applying at least one convolutional operation to the training image ii a process of inputting the feature tensors for training into the keypoint heatmap & part affinity field extractor to thereby allow the keypoint heatmap & part affinity field extractor to generate one or more keypoint heatmaps for training and one or more part affinity fields for training having one or more channels for each of the feature tensors for training iii a process of inputting the keypoint heatmaps for training and the part affinity fields for training into the keypoint detector to thereby allow the keypoint detector to extract keypoints for training from each of the keypoint heatmaps for training and a process of grouping the extracted keypoints for training by referring to each of the part affinity fields for training to thereby detect keypoints per each of the objects for training and iv a process of allowing a loss layer to calculate one or more losses by referring to the keypoints per each of the objects for training and their corresponding ground truths to thereby adjust one or more parameters of the feature extraction network and the keypoint heatmap & part affinity field extractor such that the losses are minimized by backpropagation using the losses  the method of claim  wherein at the step of a the passenger body information-detecting device performs a process of inputting the interior image into the face recognition network to thereby allow the face recognition network to detect each of the faces of each of the passengers located in the interior image via a face detector and to output multiple pieces of the passenger feature information on each of the facial images via a facial feature classifier  the method of claim  wherein at the step of a the passenger body information-detecting device performs a process of inputting the interior image into the face recognition network to thereby allow the face recognition network to i apply at least one convolution operation to the interior image and thus to output at least one feature map corresponding to the interior image via at least one convolutional layer ii output one or more proposal boxes where the passengers are estimated as located on the feature map via a region proposal network iii apply pooling operation to one or more regions corresponding to the proposal boxes on the feature map and thus to output at least one feature vector via a pooling layer and iv apply fully-connected operation to the feature vector and thus to output the multiple pieces of the passenger feature information corresponding to each of the faces of each of the passengers corresponding to each of the proposal boxes via a fully connected layer  the method of claim  wherein the multiple pieces of the passenger feature information include each of ages each of genders and each of races corresponding to each of the passengers  a passenger body information-detecting device for detecting body information on one or more passengers of a vehicle based on humans' status recognition comprising at least one memory that stores instructions and at least one processor configured to execute the instructions to perform or support another device to perform i if at least one interior image of an interior of the vehicle is acquired i a process of inputting the interior image into a face recognition network to thereby allow the face recognition network to detect each of faces of each of the passengers from the interior image and thus to output multiple pieces of passenger feature information corresponding to each of the detected faces and ii a process of inputting the interior image into a body recognition network to thereby allow the body recognition network to detect each of bodies of each of the passengers from the interior image and thus to output body-part length information of each of the detected bodies and ii a process of retrieving specific height mapping information corresponding to specific passenger feature information on a specific passenger from a height mapping table which stores height mapping information representing respective one or more predetermined ratios of one or more segment body portions of each of human groups to each of heights per each of the human groups a process of acquiring a specific height of the specific passenger from the specific height mapping information by referring to specific body-part length information of the specific passenger a process of retrieving specific weight mapping information corresponding to the specific passenger feature information from a weight mapping table which stores multiple pieces of weight mapping information representing predetermined correlations between each of the heights and each of weights per each of the human groups and a process of acquiring a weight of the specific passenger from the specific weight mapping information by referring to the specific height of the specific passenger  the passenger body information-detecting device of claim  wherein at the process of i the processor performs a process of inputting the interior image into the body recognition network to thereby allow the body recognition network to i output one or more feature tensors with one or more channels corresponding to the interior image via a feature extraction network ii generate at least one keypoint heatmap and at least one part affinity field with one or more channels corresponding to each of the feature tensors via a keypoint heatmap & part affinity field extractor and iii extract keypoints from the keypoint heatmap via a keypoint detector to group the extracted keypoints by referring to the part affinity field and thus to generate body parts per the passengers and as a result allow the body recognition network to output multiple pieces of body-part length information on each of the passengers by referring to the body parts per the passengers  the passenger body information-detecting device of claim  wherein the keypoint heatmap & part affinity field extractor includes one of a fully convolutional network and a × convolutional layer and applies a fully-convolution operation or × convolution operation to the feature tensors to thereby generate the keypoint heatmap and the part affinity field  the passenger body information-detecting device of claim  wherein the keypoint detector connects by referring to the part affinity field pairs respectively having highest mutual connection probabilities of being connected among the extracted keypoints to thereby group the extracted keypoints  the passenger body information-detecting device of claim  wherein the feature extraction network and the keypoint heatmap & part affinity field extractor have been learned by a learning device performing i a process of inputting at least one training image including one or more objects for training into the feature extraction network to thereby allow the feature extraction network to generate one or more feature tensors for training having one or more channels by applying at least one convolutional operation to the training image ii a process of inputting the feature tensors for training into the keypoint heatmap & part affinity field extractor to thereby allow the keypoint heatmap & part affinity field extractor to generate one or more keypoint heatmaps for training and one or more part affinity fields for training having one or more channels for each of the feature tensors for training iii a process of inputting the keypoint heatmaps for training and the part affinity fields for training into the keypoint detector to thereby allow the keypoint detector to extract keypoints for training from each of the keypoint heatmaps for training and a process of grouping the extracted keypoints for training by referring to each of the part affinity fields for training to thereby detect keypoints per each of the objects for training and iv a process of allowing a loss layer to calculate one or more losses by referring to the keypoints per each of the objects for training and their corresponding ground truths to thereby adjust one or more parameters of the feature extraction network and the keypoint heatmap & part affinity field extractor such that the losses are minimized by backpropagation using the losses  the passenger body information-detecting device of claim  wherein at the process of i the processor performs a process of inputting the interior image into the face recognition network to thereby allow the face recognition network to i apply at least one convolution operation to the interior image and thus to output at least one feature map corresponding to the interior image via at least one convolutional layer ii output one or more proposal boxes where the passengers are estimated as located on the feature map via a region proposal network iii apply pooling operation to one or more regions corresponding to the proposal boxes on the feature map and thus to output at least one feature vector via a pooling layer and iv apply fully-connected operation to the feature vector and thus to output the multiple pieces of the passenger feature information corresponding to each of the faces of each of the passengers corresponding to each of the proposal boxes via a fully connected layer a computer implemented method for performing video coding based on face detection comprising receiving a video frame comprising one of a plurality of video frames of a video sequence determining the video frame is a key frame of the video sequence performing in response to the video frame being a key frame of the video sequence a multi-stage facial search of the video frame based on predetermined feature templates and a predetermined number of stages to determine a first candidate face region and a second candidate face region in the video frame testing the first and second candidate face regions based on skin tone information to determine the first candidate face region is a valid face region and the second candidate face region is an invalid face region rejecting the second candidate face region and outputting the first candidate face region and encoding the video frame based at least in part on the first candidate face region being a valid face region to generate a coded bitstream  the method of claim  wherein the skin tone information comprises a skin probability map  the method of claim  wherein said testing the first and second candidate face regions based on skin tone information is performed in response to the video frame being a key frame of the video sequence  the method of claim  wherein the first candidate face region comprises a rectangular region the method further comprising determining a free form shape face region corresponding to the first candidate face region wherein the free form shape face region has at least one of a pixel accuracy or a small block of pixels accuracy  the method of claim  wherein determining the free form shape face region comprises generating an enhanced skip probability map corresponding to the first candidate face region binarizing the enhanced skip probability map and overlaying the binarized enhanced skip probability map over at least a portion of the video frame to provide the free form shape face region  the method of claim  wherein a second video frame comprises a non-key frame of the video sequence the method further comprising performing face detection in the second video frame of the video sequence based on the free form shape face region  the method of claim  further comprising tracking a second free form shape face region in the second video frame based on the free form shape face region in the video frame  the method of claim  wherein tracking the second free form shape face region comprises determining a location of a second valid face region in the second video frame based on a displacement offset with respect to the first candidate face region  the method of claim  further comprising determining the displacement offset based on an offset between a centroid of a bounding box around a skin enhanced region corresponding to the first candidate face region and a second centroid of a second bounding box around a second skin enhanced region in the second video frame  the method of claim  wherein encoding the video frame based at least in part on the first candidate face region being a valid face region comprises at least one of reducing a quantization parameter corresponding to the first candidate face region adjusting a lambda value for the first candidate face region or disabling skip coding for the first candidate face region  the method of claim  wherein the bitstream comprises at least one of an hadvanced video coding avc compliant bitstream an hhigh efficiency video coding hevc compliant bitstream a vp compliant bitstream a vp compliant bitstream or an alliance for open media aom av compliant bitstream  a computer implemented method for performing face detection comprising receiving a video frame of a sequence of video frames performing a multi-stage facial search of the video frame based on predetermined feature templates and a predetermined number of stages to determine a first candidate face region and a second candidate face region in the video frame testing the first and second candidate face regions based on skin tone information to determine the first candidate face region is a valid face region and the second candidate face region is an invalid face region rejecting the second candidate face region and outputting the first candidate face region as a valid face region for further processing and providing an index indicative of a person being present in the video frame based on the valid face region  the method of claim  wherein the sequence of video frames comprises a sequence of surveillance video frames the method further comprising performing face recognition in the surveillance video frames based on the valid face region  the method of claim  wherein the sequence of video frames comprises a sequence of decoded video frames the method further comprising adding a marker corresponding to the received video frame to perform face recognition on the received video frame based on the valid face region  the method of claim  wherein the sequence of video frames is received during a device login attempt the method further comprising performing face recognition based on the valid face region and allowing access to the device if a secured face is recognized  the method of claim  wherein the sequence of video frames comprises a sequence of videoconferencing frames the method further comprising encoding the video frame based at least in part on the valid face region to generate a coded bitstream  the method of claim  wherein encoding the video frame comprises not encoding a background region of the video frame into the bitstream  the method of claim  further comprising encoding the video frame based at least in part on the valid face region to generate a coded bitstream wherein encoding the video frame comprises including metadata corresponding to the valid face region in the bitstream  the method of claim  further comprising decoding the coded bitstream to generate a decoded video frame and to determine the metadata corresponding to the valid face region in the bitstream  the method of claim  further comprising at least one of replacing the valid face region based on the decoded metadata cropping and displaying image data corresponding only to the valid face region based on the decoded metadata or indexing the decoded video frame based on the decoded metadata  a system for performing video coding based on face detection comprising a memory configured to store a video frame comprising one of a plurality of video frames of a video sequence and a processor coupled to the memory the processor to receive the video frame to determine the video frame is a key frame of the video sequence to perform in response to the video frame being a key frame of the video sequence a multi-stage facial search of the video frame based on predetermined feature templates and a predetermined number of stages to determine a first candidate face region and a second candidate face region in the video frame to test the first and second candidate face regions based on skin tone information to determine the first candidate face region is a valid face region and the second candidate face region is an invalid face region to reject the second candidate face region and outputting the first candidate face region and to encode the video frame based at least in part on the first candidate face region being a valid face region to generate a coded bitstream  the system of claim  wherein the skin tone information comprises a skin probability map  the system of claim  wherein the first candidate face region comprises a rectangular region the processor further to determine a free form shape face region corresponding to the first candidate face region wherein the free form shape face region has at least one of a pixel accuracy or a small block of pixels accuracy  the system of claim  wherein the processor to determine the free form shape face region comprises the processor to generate an enhanced skip probability map corresponding to the first candidate face region to binarize the enhanced skip probability map and to overlay the binarized enhanced skip probability map over at least a portion of the video frame to provide the free form shape face region  the system of claim  wherein a second video frame comprises a non-key frame of the video sequence and the processor is further to perform face detection in the second video frame of the video sequence based on the free form shape face region  the system of claim  wherein the processor is further to track a second free form shape face region in the second video frame based on the free form shape face region in the video frame  the system of claim  wherein to encode the video frame based at least in part on the first candidate face region being a valid face region comprises the processor to reduce a quantization parameter corresponding to the first candidate face region adjust a lambda value for the first candidate face region or disable skip coding for the first candidate face region  at least one non-transitory machine readable medium comprising a plurality of instructions that in response to being executed on a device cause the device to perform video coding based on face detection by receiving a video frame comprising one of a plurality of video frames of a video sequence determining the video frame is a key frame of the video sequence performing in response to the video frame being a key frame of the video sequence a multi-stage facial search of the video frame based on predetermined feature templates and a predetermined number of stages to determine a first candidate face region and a second candidate face region in the video frame testing the first and second candidate face regions based on skin tone information to determine the first candidate face region is a valid face region and the second candidate face region is an invalid face region rejecting the second candidate face region and outputting the first candidate face region and encoding the video frame based at least in part on the first candidate face region being a valid face region to generate a coded bitstream  the non-transitory machine readable medium of claim  wherein the skin tone information comprises a skin probability map  the non-transitory machine readable medium of claim  wherein the first candidate face region comprises a rectangular region the machine readable medium comprising further instructions that in response to being executed on the device cause the device to perform video coding based on face detection by determining a free form shape face region corresponding to the first candidate face region wherein the free form shape face region has at least one of a pixel accuracy or a small block of pixels accuracy  the non-transitory machine readable medium of claim  wherein determining the free form shape face region comprises generating an enhanced skip probability map corresponding to the first candidate face region binarizing the enhanced skip probability map and overlaying the binarized enhanced skip probability map over at least a portion of the video frame to provide the free form shape face region  the non-transitory machine readable medium of claim  wherein a second video frame comprises a non-key frame of the video sequence the machine readable medium comprising further instructions that in response to being executed on the device cause the device to perform video coding based on face detection by performing face detection in the second video frame of the video sequence based on the free form shape face region  the non-transitory machine readable medium of claim  the machine readable medium comprising further instructions that in response to being executed on the device cause the device to perform video coding based on face detection by tracking a second free form shape face region in the second video frame based on the free form shape face region in the video frame  the non-transitory machine readable medium of claim  wherein encoding the video frame based at least in part on the first candidate face region being a valid face region comprises at least one of reducing a quantization parameter corresponding to the first candidate face region adjusting a lambda value for the first candidate face region or disabling skip coding for the first candidate face region a method for managing a smart database which stores facial images for face recognition comprising steps of a a managing device performing a process of counting one or more specific facial images corresponding to at least one specific person stored in the smart database where new facial images for the face recognition are continuously stored and a process of determining whether a first counted value representing a count of the specific facial images satisfies a preset first set value and b if the first counted value is determined as satisfying the first set value the managing device performing a process of inputting the specific facial images into a neural aggregation network to thereby allow the neural aggregation network to generate each of quality scores of each of the specific facial images by aggregation of the specific facial images and a process of sorting the quality scores corresponding to the specific facial images in a descending order of the quality scores a process of counting the sorted specific facial images in the descending order until a second counted value which represents the number of a counted part of the specific facial images becomes equal to a preset second set value and a process of deleting an uncounted part of the specific facial images from the smart database  the method of claim  further comprising a step of c the managing device performing a process of generating at least one optimal feature by weighted summation of one or more features of the specific facial images using the counted part of the quality scores and a process of setting the optimal feature as a representative face corresponding to the specific person  the method of claim  wherein at the step of b the managing device performs a process of inputting the specific facial images into a cnn of the neural aggregation network to thereby allow the cnn to generate one or more features corresponding to each of the specific facial images and a process of inputting at least one feature vector where the features are embedded into an aggregation module including at least two attention blocks to thereby allow the aggregation module to generate each of the quality scores of each of the features  the method of claim  wherein at the step of b the managing device performs a process of matching i i- one or more features corresponding to each of the specific facial images stored in the smart database and i- the quality scores with ii the specific person and a process of storing the matched features and the matched quality scores in the smart database  the method of claim  further comprising a step of d the managing device performing one of i a process of learning a face recognition system by using the specific facial images corresponding to the specific person stored in the smart database and ii a process of transmitting the specific facial images corresponding to the specific person to a learning device corresponding to the face recognition system to thereby allow the learning device to learn the face recognition system using the specific facial images  the method of claim  wherein the neural aggregation network has been learned by a learning device repeating more than once i a process of inputting multiple facial images for training corresponding to an image set of a single face or a video of the single face into a cnn of the neural aggregation network to thereby allow the cnn to generate one or more features for training by applying at least one convolution operation to the facial images for training ii a process of inputting at least one feature vector for training where the features for training are embedded into an aggregation module including at least two attention blocks of the neural aggregation network to thereby allow the aggregation module to generate each of quality scores for training of each of the features for training by aggregation of the features for training using one or more attention parameters learned in a previous iteration iii a process of outputting at least one optimal feature for training by weighted summation of the features for training using the quality scores for training and iv a process of updating the attention parameters learned in the previous iteration of the at least two attention blocks such that one or more losses are minimized which are outputted from a loss layer by referring to the optimal feature for training and its corresponding ground truth  a managing device for managing a smart database which stores facial images for face recognition comprising at least one memory that stores instructions and at least one processor configured to execute the instructions to perform or support another device to perform i a process of counting one or more specific facial images corresponding to at least one specific person stored in the smart database where new facial images for the face recognition are continuously stored and a process of determining whether a first counted value representing a count of the specific facial images satisfies a preset first set value and ii if the first counted value is determined as satisfying the first set value a process of inputting the specific facial images into a neural aggregation network to thereby allow the neural aggregation network to generate each of quality scores of each of the specific facial images by aggregation of the specific facial images and a process of sorting the quality scores corresponding to the specific facial images in a descending order of the quality scores a process of counting the sorted specific facial images in the descending order until a second counted value which represents the number of a counted part of the specific facial images becomes equal to a preset second set value and a process of deleting an uncounted part of the specific facial images from the smart database  the managing device of claim  wherein the processor further performs iii a process of generating at least one optimal feature by weighted summation of one or more features of the specific facial images using the counted part of the quality scores and a process of setting the optimal feature as a representative face corresponding to the specific person  the managing device of claim  wherein at the process of ii the processor performs a process of inputting the specific facial images into a cnn of the neural aggregation network to thereby allow the cnn to generate one or more features corresponding to each of the specific facial images and a process of inputting at least one feature vector where the features are embedded into an aggregation module including at least two attention blocks to thereby allow the aggregation module to generate each of the quality scores of each of the features  the managing device of claim  wherein at the process of ii the processor performs a process of matching i i- one or more features corresponding to each of the specific facial images stored in the smart database and i- the quality scores with ii the specific person and a process of storing the matched features and the matched quality scores in the smart database  the managing device of claim  wherein the processor further performs iv one of i a process of learning a face recognition system by using the specific facial images corresponding to the specific person stored in the smart database and ii a process of transmitting the specific facial images corresponding to the specific person to a learning device corresponding to the face recognition system to thereby allow the learning device to learn the face recognition system using the specific facial images  the managing device of claim  wherein the neural aggregation network has been learned by a learning device repeating more than once i a process of inputting multiple facial images for training corresponding to an image set of a single face or a video of the single face into a cnn of the neural aggregation network to thereby allow the cnn to generate one or more features for training by applying at least one convolution operation to the facial images for training ii a process of inputting at least one feature vector for training where the features for training are embedded into an aggregation module including at least two attention blocks of the neural aggregation network to thereby allow the aggregation module to generate each of quality scores for training of each of the features for training by aggregation of the features for training using one or more attention parameters learned in a previous iteration iii a process of outputting at least one optimal feature for training by weighted summation of the features for training using the quality scores for training and iv a process of updating the attention parameters learned in the previous iteration of the at least two attention blocks such that one or more losses are minimized which are outputted from a loss layer by referring to the optimal feature for training and its corresponding ground truth an object data processing system comprising at least one processor configured to execute at least one implementation of a plurality of recognition algorithms stored on at least one non-transitory computer-readable storage medium each recognition algorithm having feature density selection criteria and data preprocessing code executed by at least one processor the data preprocessing code comprising an invariant feature identification algorithm and configured to obtain a digital representation of a scene the scene comprising one or more textual media generate a set of invariant features by applying the invariant feature identification algorithm to the digital representation cluster the set of invariant features into regions of interest in the digital representation of the scene each region of interest having a region feature density classify by region classifier code at least one of the regions of interest according to object type as a function of attributes derived from the region feature density and the digital representation wherein the at least one of the classified regions of interest corresponds to text and use a classification result corresponding to the at least one of the regions of interest to classify another of the regions of interest according to object type wherein the another of the regions of interest corresponds to a region of interest for images  the system of claim  wherein preprocessing code based on the feature density selection criteria determines that an ocr algorithm is applicable to the text and that other recognition algorithms are applicable to aspects of the photographs and to logos  the system of claim  wherein a user creates a user profile for a camera-equipped smartphone that includes the information that the user is visually impaired which causes prioritized execution of the ocr algorithm such that a text reader program begins reading the text to the user as quickly as possible  the system of claim  further comprising an audio or tactile feedback mechanism that helps the user to position the smart phone relative to the text  the system of claim  further comprising a \"hold still\" audio feedback signal that is sent to the user when the text is at the center of the captured scene  the system of claim  wherein the digital representation comprises at least one of the following types of digital data image data video data and audio data  the system of claim  wherein invariant feature identification algorithm comprises at least one of the following feature identification algorithms fast sift freak brisk harris daisy and mser  the system of claim  wherein the invariant feature identification algorithm includes at least one of the following edge detection algorithm corner detection algorithm saliency map algorithm curve detection algorithm a texton identification algorithm and wavelets algorithm  the system of claim  wherein at least one region of interest represents at least one physical object in the scene  the system of claim  wherein at least one region of interest represents at least one textual media in the scene  the system of claim  wherein the region of interest represents a document as the textual media  the system of claim  wherein the region of interest represents a financial document  the system of claim  wherein the region of interest represents a structured document  the system of claim  wherein at least one implementation of a plurality of recognition algorithms includes at least one of the following a template driven algorithm a face recognition algorithm an optical character recognition algorithm a speech recognition algorithm and an object recognition algorithm  the system of claim  wherein data preprocessing code is further configured to assign each region of interest at least one recognition algorithm as a function of a scene context derived from the digital representation  the system of claim  wherein the scene context includes at least one of the following types of data a location a position a time a user identity a news event a medical event and a promotion  the system of claim  further comprising a mobile device comprising at least one implementation of a plurality of recognition algorithms and data preprocessing code  the system of claim  wherein the mobile device comprises at least one of the following a smart phone a tablet wearable glass a toy a vehicle a computer and a phablet  the system of claim  further comprising a network-accessible server device comprising at least one implementation of a plurality of recognition algorithms and data preprocessing code  the system of claim  wherein the object type includes at least one of the following a face an animal a vehicle a document a plant a building an appliance clothing a body part and a toy  an object data processing system comprising at least one processor configured to execute at least one implementation of a plurality of recognition algorithms stored on at least one non-transitory computer-readable storage medium each recognition algorithm having feature density selection criteria and data preprocessing code executed by at least one processor the data preprocessing code comprising an invariant feature identification algorithm and configured to obtain a digital representation of a scene the scene comprising one or more textual media generate a set of invariant features by applying the invariant feature identification algorithm to the digital representation cluster the set of invariant features into regions of interest in the digital representation of the scene each region of interest having a region feature density classify by region classifier code at least one of the regions of interest according to object type as a function of attributes derived from the region feature density and the digital representation wherein the at least one of the classified regions of interest corresponds to text and use a classification result corresponding to the at least one of the regions of interest to classify another of the regions of interest according to object type wherein the another of the regions of interest corresponds to a region of interest for images assign each region of interest at least one recognition algorithm from at least one implementation of a plurality of diverse recognition algorithms as a function of the region feature density of each region of interest and the feature density selection criteria of the at least one implementation of a plurality of diverse recognition algorithms and configure the assigned recognition algorithms to process their respective regions of interest wherein preprocessing code based on the feature density selection criteria determines that an ocr algorithm is applicable to the text and that other recognition algorithms are applicable to aspects of the photographs and to logos  a device comprising at least one processor configured to execute at least one implementation of a plurality of recognition algorithms stored on at least one non-transitory computer-readable storage medium each recognition algorithm having feature density selection criteria and data preprocessing code executed by at least one processor the data preprocessing code comprising an invariant feature identification algorithm and configured to obtain a digital representation of a scene the scene comprising one or more textual media generate a set of invariant features by applying the invariant feature identification algorithm to the digital representation cluster the set of invariant features into regions of interest in the digital representation of the scene each region of interest having a region feature density and classify by region classifier code at least one of the regions of interest according to object type as a function of attributes derived from the region feature density and the digital representation wherein the at least one of the classified regions of interest corresponds to text and use a classification result corresponding to the at least one of the regions of interest to classify another of the regions of interest according to object type wherein the another of the regions of interest corresponds to a region of interest for images a mobile terminal comprising a front camera configured to obtain a two-dimensional d face image of a user a glance sensor tilted by a certain angle and disposed adjacent to the front camera to obtain metadata of the d face image and a controller obtaining a distance between the glance sensor and the front camera the distance enabling an area of an overlap region where a first region representing a range photographable by the front camera overlaps a second region representing a range photographable by the glance sensor to be the maximum  the mobile terminal of claim  wherein the controller is configured to obtain the distance enabling the area of the overlap region to be the maximum between the glance sensor and the front camera by varying a tilting angle of the glance sensor  the mobile terminal of claim  wherein the controller is configured to set the distance enabling the area of the overlap region to be the maximum between the glance sensor and the front camera and the tilting angle of the glance sensor as an optimal disposition location of the glance sensor  the mobile terminal of claim  wherein the controller is configured to set a disposition location of the front camera as an original point and calculates coordinates of a first triangle representing the first region based on a field of view of the front camera and a maximum photographing distance of the front camera  the mobile terminal of claim  wherein the controller is configured to calculate coordinates of a second triangle representing the second region based on a field of view of the glance sensor a maximum photographing distance of the glance sensor a distance between the front camera and the glance sensor and a tilting angle of the glance sensor  the mobile terminal of claim  wherein before the glance sensor is tilted the controller is configured to calculate coordinates of a third triangle representing a third region photographable by the glance sensor and the controller is configured to rotation-convert the coordinates of the third triangle based on the tilting angle of the glance sensor and calculate the coordinates of the second triangle  the mobile terminal of claim  wherein the controller is configured to calculate coordinates of the overlap region based on the coordinates of the first triangle and the coordinates of the second triangle and calculates the area of the overlap region based on the coordinates of the overlap region  the mobile terminal of claim  wherein the controller is configured to generate three-dimensional d face information based on the d face image obtained by the front camera and metadata obtained by the glance sensor  the mobile terminal of claim  wherein the metadata comprises one or more of an angle of a face of the user a size of the face and a location of the face  the mobile terminal of claim  wherein the angle of the face comprises an angle by which the face is rotated about one or more of a pitch axis a roll axis and a yaw axis  the mobile terminal of claim  further comprising a memory storing the generated d face information wherein the controller is configured to performs a user authentication process by comparing the stored d face information with d face information obtained for user authentication  the mobile terminal of claim  wherein the glance sensor is controlled to be permanently activated with a low power to obtain a front image and metadata of the front image  the mobile terminal of claim  wherein the front camera and the glance sensor are disposed on the same line in an upper end of the mobile terminal  the mobile terminal of claim  wherein the glance sensor is tilted in one direction of an up direction a down direction a left direction and a right direction  the mobile terminal of claim  wherein the metadata is data which is changed when the mobile terminal is tilted by an external physical force a method comprising receiving by a smart television tv an indication of upcoming media programming wherein the upcoming media programming is based on a user profile identifying one or more devices in communication with the smart tv each of the one or more devices including at least one of a microphone or a camera instructing at least one identified device to detect audio signals using its respective microphone or to detect visual signals using its respective camera selecting at least one device of the one or more devices based on the detected audio signal or detected visual signal and providing instructions to the selected device to output a notification related to the upcoming media programming  the method of claim  wherein the upcoming media programming is one of a live television program a recorded television program a broadcast television program or an application-provided program  the method of claim  wherein selecting the first device based on the detected audio signal includes recognizing a voice  the method of claim  further comprising determining a distance to the recognized voice and wherein selecting the first device is further based on the determined distance  the method of claim  wherein selecting the first device based on the detected visual signals includes recognizing a face  the method of claim  wherein recognizing the face includes a face recognition technique  the method of claim  further comprising presenting on the smart tv the upcoming media programming in a favorite channel list  the method of claim  further comprising obtaining media programming viewing data wherein the media programming viewing data includes at least one of a historical time and a historical date that one or more media programs were viewed obtaining at least one of a current time and a current date processing the media programming viewing data to determine a probability of the one or more media programs being viewed based on at least one of the current time and the current date and presenting the favorite channel list based on the determined probability of the one or more media programs being viewed  the method of claim  wherein processing the media programming viewing data includes employing a neural network model  the method of claim  wherein employing the neural network model comprises determining a duration that the one or more media programs were viewed for each of the at least one of the historical time and the historical date setting a threshold time duration comparing the determined duration to the threshold time duration and filtering out the one or more media programs viewed below the threshold time duration  a smart television tv comprising a network interface a non-transitory computer-readable medium and a processor in communication with the network interface and the non-transitory computer-readable medium and capable of executing processor-executable program code stored in the non-transitory computer-readable medium to cause the smart tv to receive an indication of upcoming media programming wherein the upcoming media programming is based on a user profile identify one or more devices in communication with the smart tv each of the one or more devices including at least one of a microphone or a camera instruct at least one identified device to detect audio signals using its respective microphone or to detect visual signals using its respective camera select at least one device of the one or more devices based on the detected audio signal or detected visual signal and provide instructions to the selected device to output a notification related to the upcoming media programming  the smart tv of claim  wherein selecting the first device based on the detected audio signal includes recognizing a voice  the smart tv of claim  wherein the processor is further capable of executing processor-executable program code to determine a distance to the recognized voice and wherein selecting the first device is further based on the determined distance  the smart tv of claim  wherein selecting the first device based on the detected visual signals includes detecting the presence of a user  the smart tv of claim  wherein detecting the presence of the user includes employing one or more of a camera a microphone or a fingerprint sensor associated with at least one of the smart tv a mobile device a smartphone a laptop computer a tablet device a wearable device an internet of things iot device an internet of everything ioe device an iot hub or an ioe hub  a smart television tv comprising means for receiving an indication of upcoming media programming wherein the upcoming media programming is based on a user profile means for identifying one or more devices in communication with the smart tv each of the one or more devices including at least one of a microphone or a camera means for instructing at least one identified device to detect audio signals using its respective microphone or to detect visual signals using its respective camera means for selecting at least one device of the one or more devices based on the detected audio signal or detected visual signal and means for providing instructions to the selected device to output a notification related to the upcoming media programming  the smart tv of claim  wherein the one or more devices includes at least one of a mobile device a smartphone a laptop computer a tablet device a wearable device an internet of things iot device an internet of everything ioe device an iot hub an ioe hub or another smart tv  the smart tv of claim  wherein the upcoming media programming is one of a live television program a recorded television program a broadcast television program or an application-provided program  the smart tv of claim  wherein the notification includes at least one of a push message a sms message a waysms message an audio alert an audio message or an email message  the smart tv of claim  further comprising presenting the upcoming media programming in a favorite channel list  the smart tv of claim  further comprising means for obtaining media programming viewing data wherein the media programming viewing data includes at least one of a historical time and a historical date that one or more media programs were viewed on the smart tv means for obtaining at least one of a current time and a current date means for processing the media programming viewing data to determine a probability of the one or more media programs being viewed on the smart tv based on at least one of the current time and the current date and means for presenting the favorite channel list based on the determined probability of the one or more media programs being viewed  the smart tv of claim  wherein the means for processing the media programming viewing data includes employing a neural network model  the smart tv of claim  wherein employing the neural network model comprises determining a duration that the one or more media programs were viewed on the smart tv for each of the at least one of the historical time and the historical date setting a threshold time duration comparing the determined duration to the threshold time duration and filtering out the one or more media programs viewed below the threshold time duration  the smart tv of claim  further comprising means for adjusting at least one of a volume or a brightness of the smart tv wherein the adjusting is based on at least one of the historical time and the historical date  the smart tv of claim  further comprising means for restricting access to one or more media programs  a non-transitory computer-readable medium comprising processor-executable program code configured to cause a processor of a smart television tv to receive an indication of upcoming media programming wherein the upcoming media programming is based on a user profile identify one or more devices in communication with the smart tv each of the one or more devices including at least one of a microphone or a camera instruct at least one identified device to detect audio signals using its respective microphone or to detect visual signals using its respective camera select at least one device of the one or more devices based on the detected audio signal or detected visual signal and provide instructions to the selected device to output a notification related to the upcoming media programming  the non-transitory computer-readable medium of claim  wherein selecting the first device based on the detected audio signal includes recognizing a voice  the non-transitory computer-readable medium of claim  wherein the processor is further capable of executing processor-executable program code to determine a distance to the recognized voice and wherein selecting the first device is further based on the determined distance  the non-transitory computer-readable medium of claim  wherein selecting the first device based on the detected visual signals includes recognizing a face  the non-transitory computer-readable medium of claim  wherein recognizing the face includes a face recognition technique a camera comprising a sensor array including a plurality of sensors an infrared ir illuminator configured to emit active ir light in an ir light sub-band a plurality of spectral illuminators each spectral illuminator configured to emit active spectral light in a different spectral light sub-band a depth controller machine configured to determine a depth value for each of the plurality of sensors based on the active ir light a spectral controller machine configured to for each of the plurality of sensors determine a spectral value for each spectral light sub-band of the plurality of spectral illuminators and an output machine configured to output a test depth+multi-spectral image including a plurality of pixels each pixel corresponding to one of the plurality of sensors of the sensor array and including at least a depth value and a spectral value for each spectral light sub-band of the plurality of spectral illuminators a face recognition machine previously trained with a set of labeled training depth+multi-spectral images having a same structure as the test depth+multi-spectral image the face recognition machine configured to output a confidence value indicating a likelihood that the test depth+multi-spectral image includes a face  the camera of claim  wherein each spectral value is calculated based on the depth value determined for the sensor that corresponds to the pixel  the camera of claim  wherein the face recognition machine is configured to use a convolutional neural network to determine the confidence value  the camera of claim  wherein the face recognition machine includes a plurality of input nodes wherein each input node is configured to receive a pixel value array corresponding to a different pixel of the plurality of pixels of the test depth+multi-spectral image and wherein the pixel value array includes the depth value and the plurality of multi-spectral values for the pixel  the camera of claim  wherein the plurality of multi-spectral values for the pixel include more than three spectral values  the camera of claim  wherein the output machine is configured to output a surface normal for each pixel of the test depth+multi-spectral image and wherein the pixel value array includes the surface normal  the camera of claim  wherein the output machine is configured to output a curvature for each pixel of the test depth+multi-spectral image and wherein the pixel value array includes the curvature  the camera of claim  wherein the face recognition machine is configured to use a plurality of models to determine the confidence value wherein the plurality of models includes a plurality of channel-specific models wherein each channel-specific model is configured to process a different pixel parameter for the plurality of pixels of the test depth+multi-spectral image wherein each channel-specific model includes a plurality of input nodes and wherein for each channel-specific model each input node is configured to receive a pixel parameter value for a different pixel of the plurality of pixels of the test depth+multi-spectral image  the camera of claim  wherein the face recognition machine is configured to use a statistical model to determine the confidence value  the camera of claim  wherein the statistical model includes a nearest neighbor algorithm  the camera of claim  wherein the statistical model includes a support vector machine  the camera of claim  wherein the face recognition machine is further configured to output a location on the test depth+multi-spectral image of a bounding box around a recognized face  the camera of claim  wherein the face recognition machine is further configured to output a location on the test depth+multi-spectral image of an identified two-dimensional d facial feature of a recognized face  the camera of claim  wherein the face recognition machine is further configured to output a location on the test depth+multi-spectral image of an identified three-dimensional d facial feature of a recognized face  the camera of claim  wherein the face recognition machine is further configured to output a location on the test depth+multi-spectral image of an identified spectral feature on a recognized face  the camera of claim  wherein the face recognition machine is further configured to output for each pixel of the test depth+multi-spectral image a confidence value indicating a likelihood that the pixel is included in a face  the camera of claim  wherein the face recognition machine is further configured to output an identity of a face recognized in the test depth+multi-spectral image  the camera of claim  wherein the plurality of sensors of the sensor array are differential sensors and wherein each spectral value is determined based on a depth value and a differential measurement for that differential sensor  a camera comprising a sensor array including a plurality of sensors an infrared ir illuminator configured to emit active ir light in an ir light sub-band a plurality of spectral illuminators each spectral illuminator configured to emit active spectral light in a different spectral light sub-band a depth controller machine configured to determine a depth value for each of the plurality of sensors based on the active ir light a spectral controller machine configured to for each of the plurality of sensors determine a spectral value for each spectral light sub-band of the plurality of spectral illuminators wherein each spectral value is calculated based on the depth value determined for the sensor that corresponds to the pixel and an output machine configured to output a test depth+multi-spectral image including a plurality of pixels each pixel corresponding to one of the plurality of sensors of the sensor array and including at least a depth value and a spectral value for each spectral light sub-band of the plurality of spectral illuminators and a face recognition machine including a convolutional neural network previously trained with a set of labeled training depth+multi-spectral images having a same structure as the test depth+multi-spectral image the face recognition machine configured to output a confidence value indicating a likelihood that the test depth+multi-spectral image includes a face an image processing method comprising acquiring a photo album obtained from face clustering collecting face information of respective images in the photo album and acquiring a face parameter of each image according to the face information selecting a cover image according to the face parameter of each image and taking a face-region image from the cover image and setting the face-region image as a cover of the photo album wherein selecting the cover image according to the face parameter of each image comprises performing calculation on the face parameter of each image in a preset way to obtain a cover score of each image selecting the image with a highest cover score as the cover image wherein selecting the image with the highest cover score as the cover image comprises acquiring a source of each image and selecting the image with the highest cover score in images coming from a preset source as the cover image  the method according to claim  wherein selecting the image with the highest cover score as the cover image comprises acquiring the number of faces contained in each image determining single-person images according to the number of faces and selecting the single-person image with the highest cover score as the cover image  the method according to claim  wherein selecting the image with the highest cover score as the cover image further comprises when there is no single-person image in the photo album determining images including two faces from the photo album and selecting the image with the highest cover score from the images including two faces as the cover image  the method according to claim  wherein the face information comprises face feature points and the face parameter comprises a face turning angle acquiring the face parameter of each image according to the face information comprises acquiring coordinate values of the face feature points determining distances and angles between the face feature points and determining the face turning angle according to the distances and the angles  the method according to claim  wherein the face parameter comprises a face ratio acquiring the face parameter of each image according to the face information comprises determining a face region of the image according to the face information and calculating a ratio of an area of the face region to an area of the image to obtain the face ratio  the method according to claim  wherein calculating the face ratio comprises when there is more than one face in the image subtracting an area occupied faces other than a face corresponding to the photo album from the face region to obtain a remaining area and calculating a ratio of the remaining area to the area of the image to obtain the face ratio  the method according to claim  wherein collecting face information of respective images in the photo album comprises acquiring image identifications of images in the photo album extracting face information corresponding to the image identifications from a face database the face database being stored with face recognition results of images the face recognition results including the face information  an image processing apparatus comprising a processor and a memory configured to store instructions executable by the processor wherein the processor is configured to run a program corresponding to the instructions by reading the instructions stored in the memory so as to perform acquiring a photo album obtained from face clustering collecting face information of each image in the photo album acquiring a face parameter of each image according to the face information selecting a cover image according to the face parameter of each image taking a face-region image from the cover image and setting the face-region image as a cover of the photo album wherein the processor is configured to perform calculation on the face parameter of each image in a preset way to obtain a cover score of each image and select the image with a highest cover score as the cover image and wherein the processor is configured to acquire a source of each image and select the image with the highest cover score in images coming from a preset source as the cover image  the apparatus according to claim  wherein the processor is configured to acquire the number of faces contained in each image determine single-person images according to the number of faces and select the single-person image with the highest cover score as the cover image  the apparatus according to claim  wherein the processor is further configured to when there is no single-person image in the photo album determine images including two faces from the photo album and select the image with the highest cover score from the images including two faces as the cover image  the apparatus according to claim  wherein the face information comprises face feature points and the face parameter comprises a face turning angle the processor is configured to acquire coordinate values of the face feature points determine distances and angles between the face feature points and determine the face turning angle according to the distances and the angles  the apparatus according to claim  wherein the face parameter comprises a face ratio the processor is configured to determine a face region of the image according to the face information and calculate a ratio of an area of the face region to an area of the image to obtain the face ratio  the apparatus according to claim  wherein the processor is configured to when there is more than one face in the image subtract an area occupied faces other than a face corresponding to the photo album from the face region to obtain a remaining area and calculate a ratio of the remaining area to the area of the image to obtain the face ratio  the apparatus according to claim  wherein the processor is configured to acquire image identifications of images in the photo album extract face information corresponding to the image identifications from a face database the face database being stored with face recognition results of images the face recognition results including the face information  an electronic device comprising a processor a memory a display screen and an input device connected via a system bus wherein the memory is stored with computer programs that when executed by the processor cause the processor to implement an image processing method the image processing method comprising acquiring a photo album obtained from face clustering collecting face information of respective images in the photo album and acquiring a face parameter of each image according to the face information selecting a cover image according to the face parameter of each image and taking a face-region image from the cover image and setting the face-region image as a cover of the photo album wherein selecting the cover image according to the face parameter of each image comprises performing calculation on the face parameter of each image in a preset way to obtain a cover score of each image and selecting the image with a highest cover score as the cover image and wherein selecting the image with the highest cover score as the cover image comprises acquiring a source of each image and selecting the image with the highest cover score in images coming from a preset source as the cover image  the electronic device according to claim  wherein the electronic device comprises at least one of a mobile phone a tablet computer a personal digital assistant and a wearable device a computer-implemented method comprising receiving at a computing device a meeting invitation identifying a location and at least one invitee the meeting invitation configured to provide the at least one invitee with physical access to the location wherein the meeting invitation causes a system to control a pathway allowing physical access to the location providing based on the meeting invitation the at least one invitee with physical access to the location by controlling the pathway allowing the at least one invitee to physically access the location through the pathway in response to positioning data indicating that the at least one invitee is at a predetermined location near the location wherein the positioning data is based in part on a face recognition camera system identifying the at least one invitee receiving the positioning data from the face recognition camera system identifying the at least one invitee wherein the positioning data indicates a pattern of movement of the at least one invitee determining that the pattern of movement indicates that the at least one invitee has exited the location and revoking physical access to the location identified in the meeting invitation by controlling the pathway to restrict the at least one invitee identified in the meeting invitation from physical access to the location through the pathway in response to determining that the pattern of movement indicates that the at least one invitee has exited the location  the computer-implemented method of claim  wherein determining that the at least one invitee has exited the location comprises determining that the at least one invitee has passed through an egress associated with the location in a predetermined direction  the computer-implemented method of claim  wherein determining that the at least one invitee has exited the location comprises determining that the at least one invitee has moved through an area in a predetermined direction  the computer-implemented method of claim  wherein the positioning data indicates a second pattern of movement of the at least one invitee and wherein access to secured data associated with the location is provided in response to detecting the second pattern of movement  the computer-implemented method of claim  further comprising collating secured data and public data to generate resource data and communicating the resource data to a client computing device associated with the at least one invitee when access of the location is provided  the computer-implemented method of claim  wherein the positioning data indicates that the at least one invitee is at the predetermined location when the at least one invitee passes through the predetermined location  the computer-implemented method of claim  wherein the positioning data indicates that the at least one invitee is at the predetermined location when the at least one invitee passes through the predetermined location near the location in a predetermined direction  a system comprising a processor and a memory in communication with the processor the memory having computer-readable instructions stored thereupon that when executed by the processor cause the processor to receive a meeting invitation indicating a location and an identity the meeting invitation configured to provide at least one invitee with physical access to the location wherein the meeting invitation causes the system to control a pathway allowing physical access to the location provide the at least one invitee associated with the identity access to the location by controlling the pathway allowing the at least one invitee to physically access the location through the pathway in response to positioning data indicating that the at least one invitee is at a predetermined location near the location wherein the positioning data is based in part on a face recognition camera system identifying the at least one invitee receive the positioning data from the face recognition camera system identifying the at least one invitee wherein the positioning data indicates a pattern of movement of the at least one invitee determine that the pattern of movement indicates that the at least one invitee has exited the location and revoke physical access to the location identified in the meeting invitation by controlling the pathway to restrict the at least one invitee identified in the meeting invitation from physical access to the location through the pathway in response to determining that the pattern of movement indicates that the at least one invitee has exited the location  the system of claim  wherein determining that the at least one invitee has exited the location comprises determining that the at least one invitee has passed through an egress associated with the location  the system of claim  wherein determining that the at least one invitee has exited the location comprises determining that the at least one invitee has moved through an area in a predetermined direction  the system of claim  wherein the positioning data indicates a second pattern of movement of the at least one invitee and wherein access to secured data associated with the location is provided in response to detecting the second pattern of movement  the system of claim  wherein the instructions further cause the processor to collate secured data and public data to generate resource data and communicate the resource data to a client computing device associated with the at least one invitee when access of the location is provided  a non-transitory computer-readable storage medium having computer-executable instructions stored thereupon which when executed by one or more processors of a computing device cause the one or more processors of the computing device to receive a meeting invitation indicating a location and an identity the meeting invitation configured to provide at least one invitee with physical access to the location wherein the meeting invitation causes a system to control a pathway allowing physical access to the location provide the at least one invitee associated with the identity access to the location by controlling the pathway allowing the at least one invitee to physically access the location through the pathway in response to positioning data indicating that the at least one invitee is at a predetermined location near the location wherein the positioning data is based in part on a face recognition camera system identifying the at least one invitee receive the positioning data from the face recognition camera system identifying the at least one invitee wherein the positioning data indicates a pattern of movement of the at least one invitee determine that the pattern of movement indicates that the at least one invitee has exited the location and revoke physical access to the location identified in the meeting invitation by controlling the pathway to restrict the at least one invitee identified in the meeting invitation from physical access to the location through the pathway in response to determining that the pattern of movement indicates that the at least one invitee has exited the location  the non-transitory computer-readable storage medium of claim  wherein determining that the at least one invitee has exited the location comprises determining that the at least one invitee has passed through an egress associated with the location  the non-transitory computer-readable storage medium of claim  wherein the positioning data indicates a second pattern of movement of the at least one invitee and wherein access to secured data associated with the location is provided in response to detecting the second pattern of movement  the non-transitory computer-readable storage medium of claim  wherein the instructions further cause the one or more processors to collate secured data and public data to generate resource data and communicate the resource data to a client computing device associated with the at least one invitee when access of the location is provided a method comprising receiving a piece of content and salient data for the piece of content based on the salient data determining a first path for a viewport for the piece of content wherein the first path for the viewport includes different salient events occurring in the piece of content at different times during playback of the piece of content providing the viewport on a display device wherein movement of the viewport is based on the first path for the viewport and the salient data during the playback detecting an additional salient event in the piece of content that is not included in the first path for the viewport and providing an indication for the additional salient event in the viewport during the playback  the method of claim  wherein the salient data identifies each salient event in the piece of content and the salient data indicates for each salient event in the piece of content a corresponding point location of the salient event in the piece of content and a corresponding time at which the salient event occurs during the playback  the method of claim  wherein the salient data further indicates for each salient event in the piece of content a corresponding type of the salient event and a corresponding strength value of the salient event  the method of claim  wherein the first path for the viewport controls the movement of the viewport to put the different salient events in a view of the viewport at the different times during the playback  the method of claim  further comprising detecting one or more salient events in the piece of content based on at least one of the following visual data of the piece of content audio data of the piece of content or content consumption experience data for the piece of content wherein the salient data is indicative of each salient event detected  the method of claim  further comprising detecting one or more salient events in the piece of content based on at least one of the following face recognition facial emotion recognition object recognition motion recognition or metadata of the piece of content wherein the salient data is indicative of each salient event detected  the method of claim  further comprising detecting user interaction with the indication wherein the indication comprises an interactive hint and in response to detecting the user interaction adapting the first path for the viewport to a second path for the viewport based on the user interaction wherein the second path for the viewport includes the additional salient event and providing an updated viewport for the piece of content on the display device wherein movement of the updated viewport is based on the second path for the viewport and the salient data during the playback and the second path for the viewport controls the movement of the updated viewport to put the additional salient event in a view of the updated viewport  the method of claim  further comprising changing a weight assigned to the additional salient event and one or more other salient events in the piece of content having the same type as the additional salient event  the method of claim  wherein the second path for the viewport includes one or more other salient events in the piece of content having the same type as the additional salient event  a system comprising at least one processor and a non-transitory processor-readable memory device storing instructions that when executed by the at least one processor causes the at least one processor to perform operations including receiving a piece of content and salient data for the piece of content based on the salient data determining a first path for a viewport for the piece of content wherein the first path for the viewport includes different salient events occurring in the piece of content at different times during playback of the piece of content providing the viewport on a display device wherein movement of the viewport is based on the first path for the viewport and the salient data during the playback detecting an additional salient event in the piece of content that is not included in the first path for the viewport and providing an indication for the additional salient event in the viewport during the playback  the system of claim  wherein the salient data identifies each salient event in the piece of content and the salient data indicates for each salient event in the piece of content a corresponding point location of the salient event in the piece of content and a corresponding time at which the salient event occurs during the playback  the system of claim  wherein the salient data further indicates for each salient event in the piece of content a corresponding type of the salient event and a corresponding strength value of the salient event  the system of claim  wherein the salient data is generated offline on a server  the system of claim  the operations further comprising detecting one or more salient events in the piece of content based on at least one of the following visual data of the piece of content audio data of the piece of content or content consumption experience data for the piece of content wherein the salient data is indicative of each salient event detected  the system of claim  the operations further comprising detecting one or more salient events in the piece of content based on at least one of the following face recognition facial emotion recognition object recognition motion recognition or metadata of the piece of content wherein the salient data is indicative of each salient event detected  the system of claim  the operations further comprising detecting user interaction with the indication wherein the indication comprises an interactive hint and in response to detecting the user interaction adapting the first path for the viewport to a second path for the viewport based on the user interaction wherein the second path for the viewport includes the additional salient event and providing an updated viewport for the piece of content on the display device wherein movement of the updated viewport is based on the second path for the viewport and the salient data during the playback and the second path for the viewport controls the movement of the updated viewport to put the additional salient event in a view of the updated viewport  the system of claim  the operations further comprising changing a weight assigned to the additional salient event and one or more other salient events in the piece of content having the same type as the additional salient event  the system of claim  wherein the second path for the viewport includes one or more other salient events in the piece of content having the same type as the additional salient event  a non-transitory computer readable storage medium including instructions to perform a method comprising receiving a piece of content and salient data for the piece of content based on the salient data determining a first path for a viewport for the piece of content wherein the first path for the viewport includes different salient events occurring in the piece of content at different times during playback of the piece of content providing the viewport on a display device wherein movement of the viewport is based on the first path for the viewport and the salient data during the playback detecting an additional salient event in the piece of content that is not included in the first path for the viewport and providing an indication for the additional salient event in the viewport during the playback  the computer readable storage medium of claim  the method further comprising detecting user interaction with the indication wherein the indication comprises an interactive hint and in response to detecting the user interaction adapting the first path for the viewport to a second path for the viewport based on the user interaction wherein the second path for the viewport includes the additional salient event and providing an updated viewport for the piece of content on the display device wherein movement of the updated viewport is based on the second path for the viewport and the salient data during the playback and the second path for the viewport controls the movement of the updated viewport to put the additional salient event in a view of the updated viewport a mobile device with facial recognition the mobile device comprising one or more cameras a processor device and memory coupled to the processor device the processing system programmed to receive a plurality of images from the one or more cameras extract with a feature extractor utilizing a convolutional neural network cnn with an enlarged intra-class variance of long-tail classes feature vectors from each of the plurality of images generate with a feature generator discriminative feature vectors for each of the feature vectors classify with a fully connected classifier an identity from the discriminative feature vectors and control an operation of the mobile device to react in accordance with the identity  the mobile device as recited in claim  further includes a communication system  the mobile device as recited in claim  wherein the operation tags the video with the identity and uploads the video to social media  the mobile device as recited in claim  wherein the operation tags the video with the identity and sends the video to a user  the mobile device as recited in claim  wherein the mobile device is a smart phone  the mobile device as recited in claim  wherein the mobile device is a body cam  the mobile device as recited in claim  further programmed to train the feature extractor the feature generator and the fully connected classifier with an alternative bi-stage strategy  the mobile device as recited in claim  wherein the feature extractor shares covariance matrices across all classes to transfer intra-class variance from regular classes to the long-tail classes  the mobile device as recited in claim  wherein the feature generator optimizes a softmax loss by joint regularization of weights and features through a magnitude of an inner product of the weights and features  the mobile device as recited in claim  wherein the feature extractor averages the feature vector with a flipped feature vector the flipped feature vector being generated from a horizontally flipped frame from one of the plurality of images  the mobile device as recited in claim  wherein each of the plurality of images is selected from the group consisting of an image a video and a frame from the video  the mobile device as recited in claim  wherein the communication system connects to a remote server that includes a facial recognition network  the mobile device as recited in claim  wherein one stage of the alternative bi-stage strategy fixes the feature extractor and applies the feature generator to generate new transferred features that are more diverse and violate a decision boundary  the mobile device as recited in claim  wherein one stage of the alternative bi-stage strategy fixes the fully connected classifier and updates the feature extractor and the feature generator  a computer program product for a mobile device with facial recognition the computer program product comprising a non-transitory computer readable storage medium having program instructions embodied therewith the program instructions executable by a computer to cause the computer to perform a method comprising receiving by a processor device a plurality of images extracting by the processor device with a feature extractor utilizing a convolutional neural network cnn with an enlarged intra-class variance of long-tail classes feature vectors for each of the plurality of images generating by the processor device with a feature generator discriminative feature vectors for each of the feature vectors classifying by the processor device utilizing a fully connected classifier an identity from the discriminative feature vector and controlling an operation of the mobile device to react in accordance with the identity  a computer-implemented method for facial recognition in a mobile device the method comprising receiving by a processor device a plurality of images extracting by the processor device with a feature extractor utilizing a convolutional neural network cnn with an enlarged intra-class variance of long-tail classes feature vectors for each of the plurality of images generating by the processor device with a feature generator discriminative feature vectors for each of the feature vectors classifying by the processor device utilizing a fully connected classifier an identity from the discriminative feature vector and controlling an operation of the mobile device to react in accordance with the identity  the computer-implemented method as recited in claim  wherein controlling includes tagging the video with the identity and uploading the video to social media  the computer-implemented method as recited in claim  wherein controlling includes tagging the video with the identity and sending the video to a user  the computer-implemented method as recited in claim  wherein extracting includes sharing covariance matrices across all classes to transfer intra-class variance from regular classes to the long-tail classes a computing device comprising a non-transitory machine readable medium storing a machine trained mt network comprising a plurality of layers of processing nodes each processing node configured to compute a first output value by combining a set of output values from a set of processing nodes and use a piecewise linear cup function to compute a second output value from the first output value of the processing node wherein the piecewise linear cup function prior to training of the mt network comprises at least i a first linear section with a first slope followed by ii a second linear section with a negative second slope followed by iii a third linear section with a negative third slope that is different from the second slope followed by iv a fourth linear section with a positive fourth slope followed by v a fifth linear section with a positive fifth slope that is different from the fourth slope followed by vi a sixth linear section with a sixth slope wherein the piecewise linear cup function is symmetric about a vertical axis between the third and fourth linear sections prior to training of the mt network a content capturing circuit for capturing content for processing by the mt network and a set of processing units for executing the processing nodes to process content captured by the content capturing circuit wherein by training a set of parameters that define the piecewise linear cup function of each node in first and second pluralities of processing nodes i each processing node in the first plurality of processing nodes is configured to emulate a boolean and operator such that an output value of the processing node is in a range associated with a \"\" value only when a set of inputs to the processing node have a set of values in a range associated with \"\" and ii each processing node in the second plurality of processing nodes is configured to emulate a boolean xnor operator such that an output value of the processing node is in the range associated with \"\" only when a a set of inputs to the node have a set of values in a range associated with \"\" or b the set of inputs to the node have a set of values in a range associated with a \"\" value  the computing device of claim  wherein the third linear section of the piecewise linear cup function of a first processing node in the mt network has a different slope from the third linear section of a second processing node in the mt network  the computing device of claim  wherein the length of the third section of a piecewise linear cup function of a first processing node in the mt network is different from the length of the third section of a piecewise linear cup function of a second processing node in the mt network  the computing device of claim  wherein the sets of parameters are trained in part by a back propagating module for back propagating errors in output values of later layers of processing nodes to earlier layers of processing nodes by adjusting the set of parameters that define the piecewise linear cup functions of the earlier layers of processing nodes  the computing device of claim  wherein each processing node uses a linear function that is defined by a set of parameters to compute the first output value of the processing node wherein the back propagating module back propagates errors in output values of later layers of processing nodes to earlier layers of processing nodes by adjusting the set of parameters that define the linear functions of the earlier layers of processing nodes  the computing device of claim  wherein the first plurality of processing nodes that emulate the boolean and operator and the second plurality of processing nodes that emulate the boolean xnor operator enable the mt network to implement mathematical problems  the computing device of claim  wherein each of a plurality of processing node layers has a plurality of processing nodes that receive as input values the output values from a plurality of processing nodes in a set of prior layers  the computing device of claim  wherein each processing node uses a linear function to compute the first output value of the processing node wherein each processing node's piecewise linear cup function is defined along first and second axes the first axis defining a range of output values from the processing node's linear function and the second axis defining a range of output values produced by the piecewise linear cup function for the range of output values from the processing node's linear function  the computing device of claim  further comprising a content output circuit for presenting an output based on the processing of the content by the mt network  the computing device of claim  wherein the captured content is one of an image and an audio segment and wherein the presented output is an output display on a display screen of the computing device or an audio presentation output on a speaker of the computing device  the computing device of claim  wherein the computing device is a mobile device  the computing device of claim  wherein the mt network is a mt neural network and the processing nodes are mt neurons  the computing device of claim  wherein the set of parameters configured through training for a plurality of the processing nodes comprise at least one of the negative second and third slopes for the second and third linear sections the positive fourth and fifth slopes for the fourth and fifth linear sections a first intercept for the second linear section a second intercept for the fifth linear section and a set of lengths for at least the second third fourth and fifth sections  the computing device of claim  wherein the trained set of parameters that define the piecewise linear cup function of each node comprise a plurality of output values  the computing device of claim  wherein the first and sixth slopes are zerowe claim  a system comprising a memory device to store an input image a processor including an image input interface to receive the input image a pre-processor to model the input image to yield a multi-channel image a feature extractor to extract a set of features based on the multi-channel image a feature selector to select one or more features from the set of features of the multi-channel image wherein the one or more features are selected based on an ability to differentiate features a feature matcher to match the one or more features to a learned feature set and a similarity detector to determine whether the one or more features meet a pre-defined similarity threshold  the system of claim  wherein the pre-processor further is to activate one or more channels of the multi-channel image to yield one or more activated channels  the system of claim  wherein the one or more activated channels are to be determined based on their ability to differentiate features  the system of claim  wherein the pre-processor further is to activate one or more local patches of the one or more activated channels  the system of claim  wherein the one or more local patches are to be determined based on their ability to differentiate features  the system of claim  wherein the feature matcher further is to utilize a large-scale data learning process to perform the feature matching  an apparatus comprising an image input interface to receive an input image a pre-processor to model the input image to yield a multi-channel image a feature extractor to extract a set of features based on the multi-channel image a feature selector to select one or more features from the set of features of the multi-channel image wherein the one or more features are selected based on an ability to differentiate features a feature matcher to match the one or more features to a learned feature set and a similarity detector to determine whether the one or more features meet a pre-defined similarity threshold  the apparatus of claim  wherein the pre-processor further is to activate one or more channels of the multi-channel image to yield one or more activated channels  the apparatus of claim  wherein the one or more activated channels are to be determined based on their ability to differentiate features  the apparatus of claim  wherein the pre-processor further is to activate one or more local patches of the one or more activated channels  the apparatus of claim  wherein the one or more local patches are to be determined based on their ability to differentiate features  the apparatus of claim  wherein the feature matcher further is to utilize a large-scale data learning process to perform the feature matching  a method comprising modeling an input image to yield a multi-channel image extracting a set of features based on the multi-channel image selecting one or more features from the set of features of the multi-channel image wherein the one or more features are selected based on an ability to differentiate features matching the one or more features to a learned feature set and determining whether the one or more features meet a pre-defined similarity threshold  the method of claim  wherein modeling the input image further is to include activating one or more channels of the multi-channel image to yield one or more activated channels  the method of claim  wherein the one or more activated channels are to be determined based on their ability to differentiate features  the method of claim  wherein extracting features of the input image further is to include activating one or more local patches of the one or more activated channels  the method of claim  wherein the one or more local patches are to be determined based on their ability to differentiate features  the method of claim  wherein the feature matcher utilizes a large-scale data learning process to perform the feature matching  at least one non-transitory computer readable storage medium comprising a set of instructions which when executed by a computing device cause the computing device to model an input image to yield a multi-channel image extract a set of features based on the multi-channel image select one or more features from the set of features of the multi-channel image wherein the features are selected based on an ability to differentiate features match the one or more features to a learned feature set and determine whether the one or more features meet a pre-defined similarity threshold  the at least one non-transitory computer readable storage medium of claim  wherein the instructions when executed cause a computing device to activate one or more channels of the multi-channel image to yield one or more activated channels  the at least one non-transitory computer readable storage medium of claim  wherein the instructions when executed cause a computing device to determine the one or more activated channels based on their ability to differentiate features  the at least one non-transitory computer readable storage medium of claim  wherein extracting features of the input image is to further include activating one or more local patches of the one or more activated channels  the at least one non-transitory computer readable storage medium of claim  wherein the one or more local patches are to be determined based on their ability to differentiate features  the at least one non-transitory computer readable storage medium of claim  wherein the feature matcher further is to utilize a large-scale data learning process to perform the feature matching  an apparatus comprising means for modeling an input image to yield a multi-channel image means for extracting a set of features based on the multi-channel image means for selecting one or more features from the set of features of the multi-channel image wherein the one or more features are selected based on an ability to differentiate features means for matching the one or more features to a learned feature set and means for determining whether the one or more features meet a pre-defined similarity threshold a method for controlling a terminal the terminal comprising a capturing apparatus and at least one processor the method comprising acquiring by the capturing apparatus an image obtaining by the at least one processor a motion parameter of the terminal the motion parameter comprising at least one of a motion frequency or a motion time and two or more parameters from among an acceleration an angular velocity a motion amplitude the motion frequency and the motion time transmitting by the at least one processor a parameter threshold obtaining request to a data management server the parameter threshold obtaining request comprising configuration information of the terminal receiving corresponding preset thresholds that correspond to the configuration information in response to the parameter threshold obtaining request comparing the two or more parameters with the corresponding preset thresholds and controlling by the at least one processor not to perform image processing on the acquired image based on at least one of the two or more parameters of the motion parameter being greater than a corresponding preset threshold or based on the two or more parameters of the motion parameter being respectively greater than the corresponding preset thresholds wherein the acquiring comprises acquiring the image in real time and the obtaining comprises obtaining the motion parameter of the terminal in real time the method further comprising in response to the at least one of the two or more parameters of the motion parameter being greater than the corresponding preset threshold obtaining the motion parameter of the terminal again and in response to the two or more parameters of the motion parameter obtained at a latest time being less than or equal to the corresponding preset thresholds performing the image processing on the image acquired at the latest time  the method according to claim  wherein the acquiring comprises controlling by the at least one processor to turn on the capturing apparatus based on a face recognition instruction and acquiring by the capturing apparatus a face image when the capturing apparatus is turned on  the method according to claim  wherein the controlling not to perform the image processing comprises skipping performing face recognition on the acquired face image based on the at least one of the two or more parameters of the motion parameter being greater than the corresponding preset threshold or based on the two or more parameters of the motion parameter being respectively greater than the corresponding preset thresholds  the method according to claim  wherein the obtaining comprises at least one of obtaining the acceleration of the terminal by using an acceleration sensor or obtaining the angular velocity of the terminal by using a gyro sensor  the method according to claim  wherein the transmitting comprises transmitting the parameter threshold obtaining request to the data management server according to a preset time period  the method according to claim  further comprising generating prompt information based on the at least one of the two or more parameters of the motion parameter being greater than the corresponding preset threshold the prompt information being used for prompting the terminal to stop moving  the method according to claim  wherein the motion parameter comprises the motion frequency and the motion time  a terminal comprising a capturing apparatus at least one memory configured to store program code and at least one processor configured to access the at least one memory and operate according to the program code the program code comprising motion parameter obtaining code configured to cause the at least one processor to acquire an image by using the capturing apparatus and obtain a motion parameter of the terminal the motion parameter comprising at least one of a motion frequency or a motion time and two or more parameters from among an acceleration an angular velocity a motion amplitude the motion frequency and the motion time request transmitting code configured to cause the at least one processor to transmit a parameter threshold obtaining request to a data management server the parameter threshold obtaining request comprising configuration information of the terminal parameter threshold receiving code configured to cause the at least one processor to receive corresponding preset thresholds that correspond to the configuration information in response to the parameter threshold obtaining request comparing code configured to cause the at least one processor to compare the two or more parameters with the corresponding preset thresholds and control code configured to cause the at least one processor not to perform image processing on the acquired image based on at least one of the two or more parameters of the motion parameter being greater than a corresponding preset threshold or based on the two or more parameters of the motion parameter being respectively greater than the corresponding preset thresholds wherein the motion parameter obtaining code causes the at least one processor to acquire the image in real time and obtain the motion parameter of the terminal in real time and in response to the at least one of the two or more parameters of the motion parameter being greater than the corresponding preset threshold obtain the motion parameter of the terminal again and wherein the control code causes the at least one processor to in response to the two or more parameters of the motion parameter obtained at a latest time being less than or equal to the corresponding preset thresholds perform the image processing on the image acquired at the latest time  the terminal according to claim  wherein the program code further comprises face instruction receiving code configured to cause the at least one processor to receive a face recognition instruction wherein the motion parameter obtaining code causes the at least one processor to control according to the face recognition instruction the capturing apparatus to turn on and acquire a face image by using the capturing apparatus when the capturing apparatus is turned on and wherein the control code causes the at least one processor to skip performing face recognition on the acquired face image based on the at least one of the two or more parameters of the motion parameter being greater than the corresponding preset threshold or based on the two or more parameters of the motion parameter being respectively greater than the corresponding preset thresholds  the terminal according to claim  wherein the request transmitting code causes the at least one processor to transmit the parameter threshold obtaining request to the data management server according to a preset time period  the terminal according to claim  wherein the program code further comprises prompt information generation code configured to cause the at least one processor to generate prompt information based on at least one of the two or more parameters of the motion parameter being greater than the corresponding preset threshold the prompt information being used for prompting the terminal to stop moving  the terminal according to claim  wherein the motion parameter comprises the motion frequency and the motion time  a non-transitory computer-readable storage medium storing a machine instruction which when executed by one or more processors causes the one or more processors to perform obtaining an image acquired by a capturing apparatus obtaining a motion parameter of a terminal the terminal comprising the capturing apparatus the motion parameter comprising at least one of a motion frequency or a motion time and two or more parameters from among an acceleration an angular velocity a motion amplitude the motion frequency and the motion time transmitting a parameter threshold obtaining request to a data management server the parameter threshold obtaining request comprising configuration information of the terminal receiving corresponding preset thresholds that correspond to the configuration information in response to the parameter threshold obtaining request comparing the two or more parameters with the corresponding preset thresholds and controlling not to perform image processing on an acquired image based on at least one of the two or more parameters of the motion parameter being greater than a corresponding preset threshold or based on the two or more parameters of the motion parameter being respectively greater than the corresponding preset thresholds wherein the acquiring comprises acquiring the image in real time and the obtaining comprises obtaining the motion parameter of the terminal in real time the method further comprising in response to the at least one of the two or more parameters of the motion parameter being greater than the corresponding preset threshold obtaining the motion parameter of the terminal again and in response to the two or more parameters of the motion parameter obtained at a latest time being less than or equal to the corresponding preset thresholds performing the image processing on the image acquired at the latest time  the non-transitory computer-readable storage medium according to claim  wherein the acquired image is a face image and the image processing comprises performing face recognition  the non-transitory computer-readable storage medium according to claim  wherein the obtaining the motion parameter comprises at least one of obtaining the acceleration of the terminal by using an acceleration sensor or obtaining the angular velocity of the terminal by using a gyro sensor  the non-transitory computer-readable storage medium according to claim  wherein the motion parameter comprises the motion frequency and the motion time a method of processing a drive-through order the method comprising receiving customer information detected through vision recognition providing product information to a customer based on the customer information and processing a product order of the customer  the method according to claim  wherein the receiving of customer information comprises at least one of receiving customer information associated with vehicle information detected through vehicle recognition or receiving customer information associated with identification information detected through face recognition  the method according to claim  further comprising determining whether the customer is a pre-order customer based on the customer information wherein when the customer is determined to be a pre-order customer the providing of product information based on the customer information comprises providing pre-order information using at least one of audio or video and the processing of the product order of the customer comprises providing information for promptly guiding a vehicle to a pickup stand using at least one of audio or video and providing information that an additional order is available  the method according to claim  wherein the product information based on the customer information comprises a most recently ordered product component and a most frequently ordered product component in an order history of the customer information  the method according to claim  wherein the receiving of customer information comprises receiving information about an age and gender of a passenger detected through face recognition and the providing of product information to a customer based on the customer information comprises providing recommended menu information differentiated according to the age and gender  the method according to claim  wherein the processing of a product order of the customer comprises determining a product component in a past order history or a component modified from the product component as a product order  the method according to claim  wherein the processing of a product order of the customer comprises paying a product price according to biometrics-based authentication through a communication system of a vehicle or a mobile terminal  the method according to claim  wherein the processing of a product order of the customer comprises issuing a payment number for a divided payment and performing the divided payments according to payment requests of a plurality of mobile terminals to which the payment numbers are inputted  the method according to claim  wherein the processing of a product order of the customer further comprises accumulating mileage in an account corresponding to the mobile terminal undergoing a payment  the method according to claim  wherein the processing of a product order of the customer further comprises suggesting a takeout packaging method according to a temperature of a product an atmospheric temperature weather and a vehicle type  an apparatus configured to process a drive-through order the apparatus comprising a transceiver configured to receive customer information detected through vision recognition a digital signage configured to provide product information to a customer based on the customer information and a processor configured to process a product order of the customer  the apparatus according to claim  wherein the transceiver receives at least one of customer information associated with vehicle information detected through vehicle recognition or customer information associated with identification information detected through face recognition  the apparatus according to claim  wherein the processor is configured to determine whether the customer is a pre-order customer based on the customer information and when the customer is determined to be a pre-order customer perform a control operation to provide pre-order information and control the digital signage to output information for promptly guiding a vehicle to a pickup stand and provide information that an additional order is available  the apparatus according to claim  wherein the product information based on the customer information comprises a most recently ordered product component and a most frequently ordered product component in an order history of the customer information  the apparatus according to claim  wherein the transceiver is configured to receive information about an age and gender of a passenger detected through face recognition and the processor is configured to control the digital signage to provide recommended menu information differentiated according to the age and gender  the apparatus according to claim  wherein the processor is configured to determine a product component in a past order history or a component modified from the product component as the product order  the apparatus according to claim  wherein the processor is configured to pay a product price according to biometrics-based authentication through a communication system of a vehicle or a mobile terminal  the apparatus according to claim  wherein the processor is configured to issue a payment number for a divided payment and perform the divided payments according to requests of a plurality of mobile terminals to which the payment numbers are inputted  the apparatus according to claim  wherein the processor is configured to accumulate mileage in an account corresponding to the mobile terminal undergoing a payment  the apparatus according to claim  wherein the processor is configured to control the digital signage to suggest a takeout packaging method according to a temperature of a product an atmospheric temperature weather and a vehicle type an image information processing method performed at a computing device having one or more processors and memory storing a plurality of programs to be executed by the one or more processors the method comprising identifying using face recognition one or more faces each face corresponding to a respective person captured in a first image for each identified face extracting a set of profile parameters of a corresponding person in the first image and selecting from a plurality of image tiles a first image tile that matches the face of the corresponding person in the first image in accordance with a predefined correspondence between the set of profile parameters of the corresponding person and a set of pre-stored description parameters of the first image tile generating a second image by covering the faces of respective persons in the first image with their corresponding first image tiles and sharing the first image and the second image in a predefined order via a group chat session  the method of claim  wherein the first image and the second image are displayed in the group chat session one image at a time such that one of the two images is replaced by the other of the two images periodically  the method of claim  wherein extracting a set of profile parameters of a corresponding person in the first image includes determining one or more descriptive labels corresponding to the identified face of the corresponding person using a first machine learning model wherein the first machine learning model is trained with the facial images and corresponding descriptive labels  the method of claim  wherein extracting a set of profile parameters of a corresponding person in the first image includes determining an identity of the corresponding person based on the identified face of the corresponding person locating respective profile information of the first person based on the determined identity of the corresponding person and using one or more characteristics in the respective profile information of the first person as the set of profile parameters corresponding to the identified face of the corresponding person  the method of claim  wherein at least a first one of the first image tiles is a dynamic image tile and at least a second one of the first image tiles is a static image tile  the method of claim  including receiving a plurality of user comments from different users of the group chat session each user comment including a descriptive term for a respective person identified in the first image choosing a descriptive label for the respective person according to the plurality of user comments and updating the second image by adding the descriptive label adjacent to the first image tile of the respective person  a computing device for image information processing comprising one or more processors and memory storing instructions which when executed by the one or more processors cause the processors to perform a plurality of operations comprising identifying using face recognition one or more faces each face corresponding to a respective person captured in a first image for each identified face extracting a set of profile parameters of a corresponding person in the first image and selecting from a plurality of image tiles a first image tile that matches the face of the corresponding person in the first image in accordance with a predefined correspondence between the set of profile parameters of the corresponding person and a set of pre-stored description parameters of the first image tile generating a second image by covering the faces of respective persons in the first image with their corresponding first image tiles and sharing the first image and the second image in a predefined order via a group chat session  the computing device of claim  wherein the first image and the second image are displayed in the group chat session one image at a time such that one of the two images is replaced by the other of the two images periodically  the computing device of claim  wherein extracting a set of profile parameters of a corresponding person in the first image includes determining one or more descriptive labels corresponding to the identified face of the corresponding person using a first machine learning model wherein the first machine learning model is trained with the facial images and corresponding descriptive labels  the computing device of claim  wherein extracting a set of profile parameters of a corresponding person in the first image includes determining an identity of the corresponding person based on the identified face of the corresponding person locating respective profile information of the first person based on the determined identity of the corresponding person and using one or more characteristics in the respective profile information of the first person as the set of profile parameters corresponding to the identified face of the corresponding person  the computing device of claim  wherein at least a first one of the first image tiles is a dynamic image tile and at least a second one of the first image tiles is a static image tile  the computing device of claim  wherein the plurality of operations further include receiving a plurality of user comments from different users of the group chat session each user comment including a descriptive term for a respective person identified in the first image choosing a descriptive label for the respective person according to the plurality of user comments and updating the second image by adding the descriptive label adjacent to the first image tile of the respective person  a non-transitory computer-readable storage medium storing instructions which when executed by a computing device having one or more processors cause the computing device to perform a plurality of operations comprising identifying using face recognition one or more faces each face corresponding to a respective person captured in a first image for each identified face extracting a set of profile parameters of a corresponding person in the first image and selecting from a plurality of image tiles a first image tile that matches the face of the corresponding person in the first image in accordance with a predefined correspondence between the set of profile parameters of the corresponding person and a set of pre-stored description parameters of the first image tile generating a second image by covering the faces of respective persons in the first image with their corresponding first image tiles and sharing the first image and the second image in a predefined order via a group chat session  the non-transitory computer-readable storage medium of claim  wherein the first image and the second image are displayed in the group chat session one image at a time such that one of the two images is replaced by the other of the two images periodically  the non-transitory computer-readable storage medium of claim  wherein extracting a set of profile parameters of a corresponding person in the first image includes determining one or more descriptive labels corresponding to the identified face of the corresponding person using a first machine learning model wherein the first machine learning model is trained with the facial images and corresponding descriptive labels  the non-transitory computer-readable storage medium of claim  wherein extracting a set of profile parameters of a corresponding person in the first image includes determining an identity of the corresponding person based on the identified face of the corresponding person locating respective profile information of the first person based on the determined identity of the corresponding person and using one or more characteristics in the respective profile information of the first person as the set of profile parameters corresponding to the identified face of the corresponding person  the non-transitory computer-readable storage medium of claim  wherein at least a first one of the first image tiles is a dynamic image tile and at least a second one of the first image tiles is a static image tile  the non-transitory computer-readable storage medium of claim  wherein the plurality of operations further include receiving a plurality of user comments from different users of the group chat session each user comment including a descriptive term for a respective person identified in the first image choosing a descriptive label for the respective person according to the plurality of user comments and updating the second image by adding the descriptive label adjacent to the first image tile of the respective person a method comprising by a computing system determining that a performance metric of an eye tracking system is below a first performance threshold wherein the eye tracking system is associated with a head-mounted display worn by a user based on the determination of the performance metric of the eye tracking system being below the first performance threshold the computer system performing receiving one or more first inputs associated with a body of the user estimating a region that the user is looking at within a field of view of the head-mounted display based on the received one or more first inputs associated with the body of the user determining a vergence distance of the user based at least on the one or more first inputs associated with the body of the user the estimated region that the user is looking at and locations of one or more objects in a scene displayed by the head-mounted display and adjusting one or more configurations of the head-mounted display based on the determined vergence distance of the user  the method of claim  wherein the one or more configurations of the head-mounted display comprise one or more of a rendering image a position of a display screen or a position of an optics block  the method of claim  further comprising determining that the performance metric of the eye tracking system is above a second performance threshold receiving eye tracking data from the eye tracking system and determining the vergence distance of the user based on the eye tracking data and the one or more first inputs associated with the body of the user  the method of claim  further comprising receiving one or more second inputs associated with one or more displaying elements in the scene displayed by the head-mounted display and determining the vergence distance of the user based at least on the eye tracking data the one or more first inputs associated with the body of the user and the one or more second inputs associated with the one or more displaying elements of the scene  the method of claim  further comprising feeding the one or more first inputs associated with the body of the user to a fusion algorithm wherein the fusion algorithm assigns a weight score to each input of the one or more first inputs determining the vergence distance of the user using the fusion algorithm based on the one or more first inputs associated with the body of the user and determining a z-depth of a display screen and a confidence score based on the one or more first inputs associated with the body of the user  the method of claim  further comprising comparing the confidence score to a confidence level threshold in response to a determination that the confidence score is below the confidence level threshold feeding the one or more second inputs associated with the one or more displaying elements of the scene to the fusion algorithm and determining the z-depth of the display screen using the fusion algorithm based on the one or more first inputs associated with the body of the user and the one or more second inputs associated with the one or more displaying elements of the scene  the method of claim  further comparing comparing by the fusion algorithm confidence scores associated with a plurality of combinations of inputs and determining by the fusion algorithm the z-depth of the display screen based on a combination of inputs associated with a highest confidence score  the method of claim  wherein the z-depth and the confidence score are determined by the fusion algorithm using a piecewise comparison of the one or more first inputs and the one or more second inputs  the method of claim  wherein the z-depth and the confidence score are determined based on a correlation between two or more inputs of the one or more first inputs and the one or more second inputs  the method of claim  wherein the fusion algorithm comprises a machine learning ml algorithm and wherein the machine learning ml algorithm determines a combination of first inputs fed to the fusion algorithm  the method of claim  wherein the one or more first inputs associated with the body of the user comprise one or more of a hand position a hand direction a hand movement a hand gesture a head position a head direction a head movement a head gesture a gaze angle rea body gesture a body posture a body movement a behavior of the user or a weighted combination of one or more related parameters  the method of claim  wherein the one or more first inputs associated with the body of the user are received from one or more of a controller a sensor a camera a microphone an accelerometer a headset worn by the user or a mobile device  the method of claim  wherein the one or more second inputs associated with the one or more displaying elements comprise one or more of a z-buffer value associated with a displaying element a displaying element marked by a developer an image analysis result a shape of a displaying element a face recognition result an object recognition result a person identified in a displaying content an object identified in a displaying content a correlation of two or more displaying elements or a weighted combination of the one or more second inputs  the method of claim  further comprising determining that the performance metric of the eye tracking system is below a second performance threshold receiving one or more second inputs associated with one or more displaying elements in the scene displayed by the head-mounted display and determining the vergence distance of the user based at least on the one or more first inputs associated with the body of the user and the one or more second inputs associated with the one or more displaying elements  the method of claim  wherein determining that the performance metric of the eye tracking system is below the second performance threshold comprises determining that the eye tracking system does not exist or fails to provide eye tracking data  the method of claim  wherein the performance metric of the eye tracking system comprises one or more of an accuracy of a parameter from the eye tracking system a precision of a parameter from the eye tracking system a value of a parameter from the eye tracking system a detectability of a pupil a metric based on one or more parameters associated with the user a parameter change a parameter changing trend a data availability or a weighted combination of one or more performance related parameters  the method of claim  wherein the one or more parameters associated with the user comprise one or more of an eye distance of the user a pupil position a pupil status a correlation of two pupils of the user a head size of the user a position of a headset worn by the user an angle of the headset worn by the user a direction of the headset worn by the user an alignment of the eyes of the user or a weighted combination of one or more related parameters associated with the user  the method of claim  wherein the first performance threshold comprises one or more of a pre-determined value a pre-determined range a state of a data a changing speed of a data or a trend of a data change  one or more non-transitory computer-readable storage media embodying software that is operable when executed by a computing system to determine that a performance metric of an eye tracking system is below a first performance threshold wherein the eye tracking system is associated with a head-mounted display worn by a user based on the determination of the performance metric of the eye tracking system being below the first performance threshold the media embodying software operable when executed by the computing system to receive one or more first inputs associated with a body of the user estimate a region that the user is looking at within a field of view of the head-mounted display based on the received one or more first inputs associated with the body of the user determine a vergence distance of the user based at least on the one or more first inputs associated with the body of the user the estimated region that the user is looking at and locations of one or more objects in a scene displayed by the head-mounted display and adjust one or more configurations of the head-mounted display based on the determined vergence distance of the user  a system comprising one or more non-transitory computer-readable storage media embodying instructions one or more processors coupled to the storage media and operable to execute the instructions to determine that a performance metric of an eye tracking system is below a first performance threshold wherein the eye tracking system is associated with a head-mounted display worn by a user based on the determination of the performance metric of the eye tracking system being below the first performance threshold the system is configured to receive one or more first inputs associated with a body of the user estimate a region that the user is looking at within a field of view of the head-mounted display based on the received one or more first inputs associated with the body of the user determine a vergence distance of the user based at least on the one or more first inputs associated with the body of the user the estimated region that the user is looking at and locations of one or more objects in a scene displayed by the head-mounted display and adjust one or more configurations of the head-mounted display based on the determined vergence distance of the user a computer-implemented method for image-based self-guided object detection comprising receiving by a processor device a set of images each of the images having a respective grid thereon that is labeled regarding a respective object to be detected using grid level label data training by the processor device a grid-based object detector using the grid level label data determining by the processor device a respective bounding box for the respective object in each of the images by applying local segmentation to each of the images and training by the processor device a region-based convolutional neural network rcnn for joint object localization and object classification using the respective bounding box for the respective object in each of the images as an input to the rcnn  the computer-implemented method of claim  further comprising performing an action responsive to the object localization and object classification for a respective new object in a new image to which the rcnn is applied  the computer-implemented method of claim  wherein the action comprises autonomously controlling a motor vehicle to avoid a collision with the new object responsive to the object localization and object classification for the respective new object  the computer-implemented method of claim  wherein the local segmentation is performed using a self-similarity search and template matching to provide the respective bounding box around the respective object in the set of images  the computer-implemented method of claim  wherein the local segmentation is applied to each of the images to segment a respective target region therein  the computer-implemented method of claim  wherein the region-based convolutional neural network rcnn forms a model during an object training stage that is to detect objects in new images during an inference stage  the computer-implemented method of claim  wherein the method is performed by a system selected from the group consisting of a surveillance system a face detection system a face recognition system a cancer detection system an object tracking system and an advanced driver-assistance system  a computer program product for image-based self-guided object detection the computer program product comprising a non-transitory computer readable storage medium having program instructions embodied therewith the program instructions executable by a computer to cause the computer to perform a method comprising receiving by a processor device a set of images each of the images having a respective grid thereon that is labeled regarding a respective object to be detected using grid level label data training by the processor device a grid-based object detector using the grid level label data determining by the processor device a respective bounding box for the respective object in each of the images by applying local segmentation to each of the images and training by the processor device a region-based convolutional neural network rcnn for joint object localization and object classification using the respective bounding box for the respective object in each of the images as an input to the rcnn  the computer program product of claim  wherein the method further comprises performing an action responsive to the object localization and object classification for a respective new object in a new image to which the rcnn is applied  the computer program product of claim  wherein the action comprises autonomously controlling a motor vehicle to avoid a collision with the new object responsive to the object localization and object classification for the respective new object  the computer program product of claim  wherein the local segmentation is performed using a self-similarity search and template matching to provide the respective bounding box around the respective object in the set of images  the computer program product of claim  wherein the local segmentation is applied to each of the images to segment a respective target region therein  the computer program product of claim  wherein the region-based convolutional neural network rcnn forms a model during an object training stage that is to detect objects in new images during an inference stage  the computer program product of claim  wherein the method is performed by a system selected from the group consisting of a surveillance system a face detection system a face recognition system a cancer detection system an object tracking system and an advanced driver-assistance system  a computer processing system for image-based self-guided object detection comprising a memory device for storing program code and a processor device for running the program code to receive a set of images each of the images having a respective grid thereon that is labeled regarding a respective object to be detected using grid level label data train a grid-based object detector using the grid level label data determine a respective bounding box for the respective object in each of the images by applying local segmentation to each of the images and train a region-based convolutional neural network rcnn for joint object localization and object classification using the respective bounding box for the respective object in each of the images as an input to the rcnn  the computer processing system of claim  wherein the processor device further runs the program code to perform an action responsive to the object localization and object classification for a respective new object in a new image to which the rcnn is applied  the computer processing system of claim  wherein the action comprises autonomously controlling a motor vehicle to avoid a collision with the new object responsive to the object localization and object classification for the respective new object  the computer processing system of claim  wherein the local segmentation is performed using a self-similarity search and template matching to provide the respective bounding box around the respective object in the set of images  the computer processing system of claim  wherein the region-based convolutional neural network rcnn forms a model during an object training stage that is to detect objects in new images during an inference stage  the computer processing system of claim  wherein the computer processing system is comprised in a system selected from the group consisting of a surveillance system a face detection system a face recognition system a cancer detection system an object tracking system and an advanced driver-assistance system a method of scalable parallel cloud-based face recognition utilizing a database of normalized stored images comprising capturing an image using a camera detecting a face in the captured image normalizing the detected facial image to match the normalized stored images identifying facial features in the normalized detected facial image generating a plurality of facial metrics from the facial features calculating euclidean distances between the facial metrics of the normalized detected facial image with corresponding facial metrics of each of the stored images comparing each euclidean distance against a predetermined threshold responsive to the euclidean distance comparison producing a reduced candidate list of best possible image matches from the normalized stored images comparing in parallel the normalized detected facial image with each of the normalized stored images of the reduced candidate list utilizing a plurality of face recognition algorithms where each processor of a parallel processing system uses a different face recognition algorithm responsive to the comparison producing best match results from each parallel subset of the reduced candidate list and selecting a final match from the best match results using a deep learning neural network face recognition algorithm trained on outputs of individual face recognition algorithms  the method of scalable parallel cloud-based face recognition of claim  wherein detecting a face in the captured image comprises utilizing opencv to detect a face in the captured image extracting the location of the eyes and a tip of the nose in the face determining a distance between the eyes cropping the face from the captured image where the width and the height of a cropped face image is a function of the distance between the eyes and rotating the face by an angle of rotation that is a function of the distance between the eyes  the method of scalable parallel cloud-based face recognition of claim  wherein the width of the cropped face image is  times the distance between the eyes the height of the cropped face image is  times the distance between the eyes and the angle of rotation is an angle formed by a straight line joining the eyes and an x-axis of the face  the method of scalable parallel cloud-based face recognition of claim  wherein rotating the face comprises rotating the face to provide a frontal face pattern  the method of scalable parallel cloud-based face recognition of claim  further comprising the step of proportionally rescaling the cropped and rotated image  the method of scalable parallel cloud-based face recognition of claim  where the proportional rescaling yields a cropped and rotated image with a size of = pixels  the method of scalable parallel cloud-based face recognition of claim  wherein the facial features identified in the normalized detected facial image comprise a pair of eyes a tip of a nose a mouth a center of the mouth and a chin area comprising a bottom a top left landmark and a top right landmark  the method of scalable parallel cloud-based face recognition of claim  wherein generating a plurality of facial metrics comprises calculating a distance between the pair of eyes a distance between the eyes and the tip of the nose a distance equal to the width of the mouth a distance between the tip of the nose and the center of mouth a distance between the bottom of chin and the center of mouth a distance between the top left landmark on the chin and the tip of the nose and a distance between the top right landmark on the chin and the tip of the nose  the method of scalable parallel cloud-based face recognition of claim  wherein performing a euclidean distance match further comprises partitioning the normalized stored images into a plurality of substantially equal subsets performing a euclidean distance match between the facial metrics of the normalized detected facial image and corresponding facial metrics of each of the stored images of the subsets of the normalized stored images with a separate processor of a parallel processing system to generate a euclidean distance for each stored image of the subset comparing each euclidean distance against a predetermined threshold with the separate processors responsive to the euclidean distance comparison producing a reduced candidate list of best possible image matches from the normalized stored images of each subset and combining the reduced candidate lists from each subset to produce a single reduced candidate list  the method of scalable parallel cloud-based face recognition of claim  wherein the plurality of face recognition algorithms utilized in comparing in parallel the normalized detected facial image with each of the normalized stored images of the reduced candidate list consists of face recognition algorithms selected from a group consisting of principle component analysis pca-based algorithms linear discriminant analysis lda algorithms independent component analysis ica algorithms kernel-based algorithms feature-based techniques algorithms based on neural networks algorithms based on transforms and model-based face recognition algorithms  the method of scalable parallel cloud-based face recognition of claim  wherein the pca-based algorithms include eigenfaces for face detectionrecognition and the lda algorithms include the fisherfaces method of face recognition  the method of scalable parallel cloud-based face recognition of claim  wherein comparing in parallel the captured image with each of the normalized stored images of the reduced candidate list further comprises partitioning the reduced candidate list into a plurality of substantially equal subsets processing each subset in a different processor of the parallel processing system uses a unique face recognition algorithm to produce the best match results and using a reduce function of a mapreduce program to combine the best match results from each of the subsets to produce a single set of the best match results  the method of scalable parallel cloud-based face recognition of claim  wherein partitioning the reduced candidate list comprises selecting the images comprising each subset by optimizing the variance between of each of the images according to the following equation where m and n are the number of rows and columns of the face vector image n is the number of groups and σij is the standard deviation of image dimension i in the group j of the face image vector  the method of scalable parallel cloud-based face recognition of claim  wherein selecting the images comprising each subset by optimizing the variance between each of the images according to the following equation dμi μj is the euclidean distance between the mean of the group i and the mean of group j i is the face image vector and l is the number of group levels  the method of scalable parallel cloud-based face recognition of claim  where selecting a final match from the best match results utilizing a deep learning neural network face recognition algorithm comprises utilizing either an adaboost machine-learning algorithm or a neural networks machine-learning model  the method of scalable parallel cloud-based face recognition of claim  where normalizing the detected facial image to match the normalized stored images includes normalizing the detected facial image to the same size orientation and illumination of the normalized stored images  a non-transitory computer-readable medium containing executable program instructions for causing a computer to perform a method of face recognition the method comprising detecting a face in an image captured by a camera normalizing the detected facial image to match the normalized stored images identifying facial features in the normalized detected facial image generating a plurality of facial metrics from the facial features calculating euclidean distances between the facial metrics of the normalized detected facial image with corresponding facial metrics of each of the stored images comparing each euclidean distance against a predetermined threshold responsive to the euclidean distance comparison producing a reduced candidate list of best possible image matches from the normalized stored images comparing in parallel the captured image with each of the normalized stored images of the reduced candidate list utilizing a plurality of face recognition algorithms where each processor of a parallel processing system uses a different face recognition algorithm responsive to the comparison producing best match results from each parallel subset of the reduced candidate list and selecting a final match from the best match results using a deep learning neural network face recognition algorithm trained on outputs of individual face recognition algorithms  the non-transitory computer-readable medium containing executable program instructions of claim  wherein the plurality of face recognition algorithms utilized in comparing in parallel the normalized detected facial image with each of the normalized stored images of the reduced candidate list consists of face recognition algorithms selected from a group consisting of principle component analysis pca-based algorithms linear discriminant analysis lda algorithms independent component analysis ica algorithms kernel-based algorithms feature-based techniques algorithms based on neural networks algorithms based on transforms and model-based face recognition algorithms  the non-transitory computer-readable medium containing executable program instructions of claim  wherein the pca-based algorithms include eigenfaces for face detectionrecognition and the lda algorithms include the fisherfaces method of face recognition  the non-transitory computer-readable medium containing executable program instructions of claim  where selecting a final match from the best match results utilizing a deep learning neural network face recognition algorithm comprises utilizing either an adaboost machine-learning algorithm or a neural networks machine-learning model an imaging device comprising a condensing lens an image sensor configured to detect light passing through the condensing lens and comprising a pixel matrix wherein the pixel matrix comprises a plurality of phase detection pixel pairs and a plurality of regular pixels and a processor configured to turn on the phase detection pixel pairs for autofocusing and output autofocused pixel data after completing the autofocusing divide the autofocused pixel data into a first subframe and a second subframe calculate image features of at least one of the first subframe and the second subframe wherein the image features comprise module widths of a finder pattern and the finder pattern has a predetermined ratio a harr-like feature or a gabor feature and determine an operating resolution of the regular pixels according to the image features calculated from at least one of the first subframe and the second subframe divided from the autofocused pixel data  the imaging device as claimed in claim  wherein each of the phase detection pixel pairs comprises a first pixel and a second pixel a cover layer covering upon a first region of the first pixel and upon a second region of the second pixel wherein the first region and the second region are mirror symmetrical to each other and a microlens aligned with at least one of the first pixel and the second pixel  the imaging device as claimed in claim  wherein the first region and the second region are % to % of an area of a single pixel  the imaging device as claimed in claim  wherein the processor is configured to perform the autofocusing using a dual pixel autofocus technique according to pixel data of the phase detection pixel pairs before completing the autofocusing  the imaging device as claimed in claim  wherein the processor is configured to divide pixel data of the phase detection pixel pairs into a third subframe and a fourth subframe before completing the autofocusing and perform the autofocusing according to the third subframe and the fourth subframe  the imaging device as claimed in claim  wherein the processor is further configured to calibrate brightness of the third subframe and the fourth subframe to be identical using a shading algorithm  the imaging device as claimed in claim  wherein the operating resolution is selected as a first resolution smaller than a number of the regular pixels or as a second resolution larger than the first resolution  the imaging device as claimed in claim  wherein the regular pixels are turned off in the autofocusing  the imaging device as claimed in claim  wherein a number of the phase detection pixel pairs is smaller than that of the regular pixels  an imaging device comprising a condensing lens an image sensor configured to detect light passing through the condensing lens and comprising a pixel matrix wherein the pixel matrix comprises a plurality of phase detection pixel pairs and a plurality of regular pixels and a processor configured to turn on the phase detection pixel pairs for autofocusing and output autofocused pixel data after completing the autofocusing divide the autofocused pixel data into a first subframe and a second subframe calculate image features of at least one of the first subframe and the second subframe wherein the image features comprise module widths of a finder pattern and the finder pattern has a predetermined ratio a harr-like feature or a gabor feature and select an image decoding or an image recognition using pixel data of the regular pixels according to the image features calculated from at least one of the first subframe and the second subframe divided from the autofocused pixel data  the imaging device as claimed in claim  wherein each of the phase detection pixel pairs comprises a first pixel and a second pixel a cover layer covering upon a first region of the first pixel and upon a second region of the second pixel wherein the first region and the second region are mirror symmetrical to each other and a microlens aligned with at least one of the first pixel and the second pixel  the imaging device as claimed in claim  wherein the processor is configured to perform the autofocusing using a dual pixel autofocus technique according to pixel data of the phase detection pixel pairs before completing the autofocusing  the imaging device as claimed in claim  wherein the processor is configured to divide the pixel data of the phase detection pixel pairs into a third subframe and a fourth subframe before completing the autofocusing calibrate brightness of the third subframe and the fourth subframe to be identical using a shading algorithm and perform the autofocusing according to the third subframe and the fourth subframe  the imaging device as claimed in claim  wherein the processor is configured to calculate the image features using at least one of a rule based algorithm and a machine learning algorithm  the imaging device as claimed in claim  wherein the image decoding is decoding qr codes and the image recognition is face recognition  an operating method of an imaging device the imaging device comprising a plurality of phase detection pixel pairs and a plurality of regular pixels the operating method comprising turning on the phase detection pixel pairs for autofocusing and outputting autofocused image frame after completing the autofocusing dividing the autofocused image frame acquired by the phase detection pixel pairs into a first subframe and a second subframe calculating image features of at least one of the first subframe and the second subframe wherein the image feature comprise module widths of a finder pattern and the finder pattern has a predetermined ratio a harr-like feature or a gabor feature and selectively activating at least a part of the regular pixels according to the image features calculated from at least one of the first subframe and the second subframe divided from the autofocused image frame  the operating method as claimed in claim  wherein the selectively activating comprises activating a first part of the regular pixels to perform an image decoding according to pixel data of the first part of the regular pixels or activating all the regular pixels to perform an image recognition according to pixel data of the all regular pixels  the operating method as claimed in claim  wherein pixel data of the phase detection pixel pairs captured in a same frame with the pixel data of the regular pixels is also used in performing the image decoding and the image recognition  the operating method as claimed in claim  wherein the image decoding is decoding qr codes and the image recognition is face recognition  the operating method as claimed in claim  wherein the phase detection pixel pairs are partially covered pixels or have a structure of dual pixel an apparatus comprising a first camera module configured to obtain a first image of an object with a first field of view a second camera module configured to obtain a second image of the object with a second field of view different from the first field of view a first depth map generator configured to generate a first depth map of the first image based on the first image and the second image and a second depth map generator configured to generate a second depth map of the second image based on the first image the second image and the first depth map  the apparatus of claim  wherein the first field of view is a narrow angle and the second field of view is a wider angle  the apparatus of claim  wherein the second image is divided into a primary region and a residual region and the second depth map generator comprises a relationship estimating module configured to estimate a relationship between the primary region and the residual region based on the first image and the second image and a depth map estimating module configured to estimate a depth map of the residual region based on the estimated relationship and the first depth map  the apparatus of claim  wherein at least one of the relationship estimating module and the depth map estimating module performs an estimating operation based on a neural network module  the apparatus of claim  further comprising a depth map fusion unit configured to generate a third depth map of the second image by performing a fusion operation based on the first depth map and the second depth map  the apparatus of claim  wherein the depth map fusion unit comprises a tone mapping module configured to generate a tone-mapped second depth map to correspond to the first depth map by performing a bias removing operation on the second depth map and a fusion module configured to generate the third depth map by fusing the tone-mapped second depth map and the first depth map  the apparatus of claim  wherein the depth map fusion unit further comprises a propagating module configured to generate a propagated first depth map in the second image by iterated propagating of the first depth map based on the first depth map and the second image and the fusion module generates the third depth map by fusing the tone-mapped second depth map and the propagated first depth map  the apparatus of claim  wherein the depth map fusion unit further comprises a post-processing module configured to perform a post-processing operation on the third depth map generated by the fusion module to provide the post-processed third depth map  the apparatus of claim  wherein the post-processing module performs the post-processing operation by filtering an interface generated in the third depth map in accordance with fusion of the fusion module  the apparatus of claim  wherein the post-processing module removes artifacts generated in the third depth map in accordance with fusion of the fusion module  the apparatus of claim  wherein the first depth map generator analyses a distance relationship between the first image and the second image and generates a first depth map of the first image based on the distance relationship  a method of processing an image of an electronic apparatus the method comprising obtaining a first image of an object using a first camera module obtaining a second image of the object using a second camera module generating a first depth map of the first image based on the first image and the second image estimating a relationship between a primary region of the second image and a residual region of the second image based on the first image and the second image and generating a second depth map of the second image based on the estimated relationship between the primary region and the residual region and the first depth map  the method of claim  wherein the electronic apparatus comprises a first camera module including a first lens having a first field of view and a second camera module including a second lens having a second field of view wider than the first field of view  the method of claim  wherein the generating of the second depth map comprises estimating a depth map of the residual region based on the estimated relationship between the primary region and the residual region and the first depth map and generating the second depth map based on a depth map of the residual region and the first depth map  the method of claim  wherein the estimating of the relationship between a primary region of the second image is performed using a neural network model  the method of claim  further comprising performing a pre-processing operation on the second depth map and generating a third depth map of the residual image by fusing the second depth map on which the pre-processing operation is performed and the first depth map  the method of claim  wherein the performing of the pre-processing operation comprises performing a tone mapping operation between a depth map of the primary region and a depth map of the residual region based on the second depth map  an operating method for an electronic apparatus the electronic apparatus including a first camera module providing a first image of an object using a first field of view and a second camera module providing a second image of the object using second field of view wider than the first field of view and a processor generating a depth map of the second image based on a primary region of the second image and a residual region of the second image the operating method comprising generating a first depth map of the primary region by estimating a relationship between the first image and the second image estimating a relationship between the primary region and the residual region based on the first image and the second image generating a second depth map of the second image by estimating a depth map of the second region based on the estimated relationship between the primary region and the residual region and generating a depth map of the second image by fusing the first depth map and the second depth map  the operation method of claim  further comprising executing an application that applies an image effect to the second image based on a depth map of the residual image  the operation method of claim  wherein the application applies at least one image effect of auto-focusing out-focusing forebackground separation face recognition object detection within a frame and augmented reality to the second image based on a depth map of the second image a payment method based on a face recognition comprising acquiring first face image information of a target user extracting first characteristic information from the first face image information wherein the first characteristic information includes head posture information of the target user and gaze information of the target user determining whether the target user has a willingness to pay according to the head posture information of the target user and the gaze information of the target user including determining whether an angle of rotation in each preset direction is less than an angle threshold wherein the head posture information includes the angle of rotation in each preset direction determining whether a probability value that a user gazes at a payment screen is greater than a probability threshold wherein the gaze information includes the probability value that a user gazes at a payment screen and in response to determining that the angle of rotation in each preset direction is less than the angle threshold and that the probability value that a user gazes at a payment screen is greater than the probability threshold determining that the target user has a willingness to pay and in response to determining that the target user has a willingness to pay completing a payment operation based on the face recognition  the method as claimed in claim  wherein the completing a payment operation based on the face recognition comprises triggering and performing a payment initiating operation to acquire second face image information based on the face recognition determining whether second characteristic information extracted from the second face image information indicates that the user has a willingness to pay and in response to determining that the second characteristic information indicates that the user has a willingness to pay triggering and performing a payment confirmation operation to complete the payment operation based on payment account information corresponding to the target user  the method as claimed in claim  wherein the determining whether second characteristic information extracted from the second face image information indicates that the user has a willingness to pay comprises determining whether a current user corresponding to the second face image information is consistent with the target user and in response to determining that the current user is consistent with the target user determining whether the target user has a willingness to pay according to the second characteristic information extracted from the second face image information  the method as claimed in claim  wherein the extracting first characteristic information from the first face image information comprises determining the head posture information of the target user using a head posture recognition model based on the first face image information and determining the gaze information of the target user using a gaze information recognition model based on characteristics of an eye region in the first face image information  the method as claimed in claim  wherein the head posture recognition model is obtained through training by acquiring a first sample data set wherein the first sample data set includes a plurality of pieces of first sample data and each of the plurality of pieces of first sample data includes a correspondence between a sample face image and head posture information determining mean image data and variance image data of a plurality of sample face images for each of the plurality of pieces of first sample data preprocessing the sample face image contained in each of the plurality of pieces of first sample data based on the mean image data and the variance image data to obtain a preprocessed sample face image setting the preprocessed sample face image and the corresponding head posture information as a first model training sample and performing training using a machine learning method and based on a plurality of first model training samples to obtain the head posture recognition model  the method as claimed in claim  wherein the gaze information recognition model is obtained through training by acquiring a second sample data set wherein the second sample data set includes a plurality of pieces of second sample data and each of the plurality of pieces of second sample data includes a correspondence between a sample eye image and gaze information determining mean image data and variance image data of a plurality of sample eye images for each of the plurality of pieces of second sample data preprocessing the sample eye image contained in each of the plurality of pieces of second sample data based on the mean image data and the variance image data to obtain a preprocessed sample eye image setting the preprocessed sample eye image and the corresponding gaze information as a second model training sample and performing training using a machine learning method and based on a plurality of second model training samples to obtain the gaze information recognition model  the method as claimed in claim  wherein the angle of rotation in each preset direction comprises a pitch angle a yaw angle and a roll angle wherein the pitch angle refers to an angle of rotation around a x-axis the yaw angle refers to an angle of rotation around a y-axis and the roll angle refers to an angle of rotation around a z-axis  a payment device based on a face recognition comprising a processor and a non-transitory computer-readable storage medium storing instructions executable by the processor to cause the device to perform operations comprising acquiring first face image information of a target user extracting first characteristic information from the first face image information wherein the first characteristic information includes head posture information of the target user and gaze information of the target user determining whether the target user has a willingness to pay according to the head posture information of the target user and the gaze information of the target user including determining whether an angle of rotation in each preset direction is less than an angle threshold wherein the head posture information includes the angle of rotation in each preset direction determining whether a probability value that a user gazes at a payment screen is greater than a probability threshold wherein the gaze information includes the probability value that a user gazes at a payment screen and in response to determining that the angle of rotation in each preset direction is less than the angle threshold and that the probability value that a user gazes at a payment screen is greater than the probability threshold determining that the target user has a willingness to pay and in response to determining that the target user has a willingness to pay completing a payment operation based on the face recognition  the device as claimed in claim  wherein the completing a payment operation based on the face recognition comprises triggering and performing a payment initiating operation to acquire second face image information based on the face recognition determining whether second characteristic information extracted from the second face image information indicates that the user has a willingness to pay and in response to determining that the second characteristic information indicates that the user has a willingness to pay triggering and performing a payment confirmation operation to complete the payment operation based on payment account information corresponding to the target user  the device as claimed in claim  wherein the determining whether second characteristic information extracted from the second face image information indicates that the user has a willingness to pay comprises determining whether a current user corresponding to the second face image information is consistent with the target user and in response to determining that the current user is consistent with the target user determining whether the target user has a willingness to pay according to the second characteristic information extracted from the second face image information  the device as claimed in claim  wherein the extracting first characteristic information from the first face image information comprises determining the head posture information of the target user using a head posture recognition model based on the first face image information and determining the gaze information of the target user using a gaze information recognition model based on characteristics of an eye region in the first face image information  the device as claimed in claim  wherein the head posture recognition model is obtained through training by acquiring a first sample data set wherein the first sample data set includes a plurality of pieces of first sample data and each of the plurality of pieces of first sample data includes a correspondence between a sample face image and head posture information determining mean image data and variance image data of a plurality of sample face images for each of the plurality of pieces of first sample data preprocessing the sample face image contained in each of the plurality of pieces of first sample data based on the mean image data and the variance image data to obtain a preprocessed sample face image setting the preprocessed sample face image and the corresponding head posture information as a first model training sample and performing training using a machine learning method and based on a plurality of first model training samples to obtain the head posture recognition model  the device as claimed in claim  wherein the gaze information recognition model is obtained through training by acquiring a second sample data set wherein the second sample data set includes a plurality of pieces of second sample data and each of the plurality of pieces of second sample data includes a correspondence between a sample eye image and gaze information determining mean image data and variance image data of a plurality of sample eye images for each of the plurality of pieces of second sample data preprocessing the sample eye image contained in each of the plurality of pieces of second sample data based on the mean image data and the variance image data to obtain a preprocessed sample eye image setting the preprocessed sample eye image and the corresponding gaze information as a second model training sample and performing training using a machine learning method and on a plurality of second model training samples to obtain the gaze information recognition model  the device as claimed in claim  wherein the angle of rotation in each preset direction comprises a pitch angle a yaw angle and a roll angle wherein the pitch angle refers to an angle of rotation around a x-axis the yaw angle refers to an angle of rotation around a y-axis and the roll angle refers to an angle of rotation around a z-axis  a non-transitory computer-readable storage medium for a payment based on a face recognition configured with instructions executable by one or more processors to cause the one or more processors to perform operations comprising acquiring first face image information of a target user extracting first characteristic information from the first face image information wherein the first characteristic information includes head posture information of the target user and gaze information of the target user determining whether the target user has a willingness to pay according to the head posture information of the target user and the gaze information of the target user including determining whether an angle of rotation in each preset direction is less than an angle threshold wherein the head posture information includes the angle of rotation in each preset direction determining whether a probability value that a user gazes at a payment screen is greater than a probability threshold wherein the gaze information includes the probability value that a user gazes at a payment screen and in response to determining that the angle of rotation in each preset direction is less than the angle threshold and that the probability value that a user gazes at a payment screen is greater than the probability threshold determining that the target user has a willingness to pay and in response to determining that the target user has a willingness to pay completing a payment operation based on the face recognition  the storage medium as claimed in claim  wherein the completing a payment operation based on the face recognition comprises triggering and performing a payment initiating operation to acquire second face image information based on the face recognition determining whether second characteristic information extracted from the second face image information indicates that the user has a willingness to pay and in response to determining that the second characteristic information indicates that the user has a willingness to pay triggering and performing a payment confirmation operation to complete the payment operation based on payment account information corresponding to the target user  the storage medium as claimed in claim  wherein the determining whether second characteristic information extracted from the second face image information indicates that the user has a willingness to pay comprises determining whether a current user corresponding to the second face image information is consistent with the target user and in response to determining that the current user is consistent with the target user determining whether the target user has a willingness to pay according to the second characteristic information extracted from the second face image information  the storage medium as claimed in claim  wherein the extracting first characteristic information from the first face image information comprises determining the head posture information of the target user using a head posture recognition model based on the first face image information and determining the gaze information of the target user using a gaze information recognition model based on characteristics of an eye region in the first face image information  the storage medium as claimed in claim  wherein the head posture recognition model is obtained through training by acquiring a first sample data set wherein the first sample data set includes a plurality of pieces of first sample data and each of the plurality of pieces of first sample data includes a correspondence between a sample face image and head posture information determining mean image data and variance image data of a plurality of sample face images for each of the plurality of pieces of first sample data preprocessing the sample face image contained in each of the plurality of pieces of first sample data based on the mean image data and the variance image data to obtain a preprocessed sample face image setting the preprocessed sample face image and the corresponding head posture information as a first model training sample and performing training using a machine learning method and based on a plurality of first model training samples to obtain the head posture recognition model and wherein the gaze information recognition model is obtained through training by acquiring a second sample data set wherein the second sample data set includes a plurality of pieces of second sample data and each of the plurality of pieces of second sample data includes a correspondence between a sample eye image and gaze information determining mean image data and variance image data of a plurality of sample eye images for each of the plurality of pieces of second sample data preprocessing the sample eye image contained in each of the plurality of pieces of second sample data based on the mean image data and the variance image data to obtain a preprocessed sample eye image setting the preprocessed sample eye image and the corresponding gaze information as a second model training sample and performing training using a machine learning method and based on a plurality of second model training samples to obtain the gaze information recognition model  the storage medium as claimed in claim  wherein the angle of rotation in each preset direction comprises a pitch angle a yaw angle and a roll angle wherein the pitch angle refers to an angle of rotation around a x-axis the yaw angle refers to an angle of rotation around a y-axis and the roll angle refers to an angle of rotation around a z-axis a method comprising detecting by a motion detection module a motion by a subject within a predetermined area of view assigning a unique session identification number to the subject detected within a predetermined area of view detecting a facial area of the subject detected within a predetermined area of view generating an image of the facial area of the subject assessing a quality of the image of the facial area of the subject determining an identity of the subject based on the image of the facial area of the subject identifying an intent of the subject and authorizing access to a point of entry based on the determined identity of the subject and based on the intent of the subject  the method of claim  further comprising determining one or more additional subjects within the predetermined area of view and assigning a unique session identification number to each of the one or more additional subjects detected within a predetermined area of view  the method of claim  wherein the assessing a quality of the image of the facial area of the subject comprises assessing whether the quality of the image of the facial area of the object equates predetermined metric of quality and upon determining that the quality of the image of the facial area of the object is inferior to the predetermined metric of quality discarding the image of the facial area of the subject and generating a second image of the facial area of the subject  the method of claim  further comprising detecting whether the facial area of the subject is photographic image and upon detecting that the facial area of the subject is a photographic image generating a warning and restrict access to the point of entry  the method of claim  further comprising conducing an incremental training of the image of the facial area of the subject  the method of claim  wherein conducing an incremental training of the image of the facial area of the subject comprises capturing a first image of the facial area having facial landmarks converting the first image of the facial area into a first numeric vector capturing a second image of the facial area having facial landmarks converting the second image of the facial area into a second numeric vector calculating a weighted mean of the first numeric vector and the second numeric vector wherein the weighted mean represents a change in a facial area and storing the weighted mean in the database  the method of claim  wherein determining an identity of the subject based on the image of the facial area of the subject comprises comparing the image of the facial area of the subject with a plurality of images stored in a database and authenticating the subject  the method of claim  wherein identifying an intent of the subject comprises upon detecting the facial area in a bounding box commencing authentication of the subject calculating a directional vector of a face of the subject determine an intent of the subject to gain access to the point of entry based on the directional vector of the face of the subject granting the access to the point of entry based on authentication of the subject and based on determining the intent of the subject  a non-transitory computer readable medium having program instructions stored thereon that in response to execution by a computing device cause the computing device to perform operations comprising detecting a motion by a subject within a predetermined area of view assigning a unique session identification number to the subject detected within a predetermined area of view detecting a facial area of the subject detected within a predetermined area of view generating an image of the facial area of the subject assessing a quality of the image of the facial area of the subject determining an identity of the subject based on the image of the facial area of the subject identifying an intent of the subject and authorizing access to a point of entry based on the determined identity of the subject and based on the intent of the subject  the non-transitory computer readable medium of claim  further comprising determining one or more additional subjects within the predetermined area of view and assigning a unique session identification number to each of the one or more additional subjects detected within a predetermined area of view  the non-transitory computer readable medium of claim  wherein the assessing a quality of the image of the facial area of the subject comprises assessing whether the quality of the image of the facial area of the object equates predetermined metric of quality and upon determining that the quality of the image of the facial area of the object is inferior to the predetermined metric of quality discarding the image of the facial area of the subject and generating a second image of the facial area of the subject  the non-transitory computer readable medium of claim  further comprising detecting whether the facial area of the subject is photographic image and upon detecting that the facial area of the subject is a photographic image generating a warning and restrict access to the access point  the non-transitory computer readable medium of claim  further comprising conducing an incremental training of the image of the facial area of the subject  the non-transitory computer readable medium of claim  wherein conducing an incremental training of the image of the facial area of the subject comprises capturing a first image of the facial area having facial landmarks converting the first image of the facial area into a first numeric vector capturing a second image of the facial area having facial landmarks converting the second image of the facial area into a second numeric vector calculating a weighted mean of the first numeric vector and the second numeric vector wherein the weighted mean represents a change in a facial area and storing the weighted mean in the database  an apparatus for face recognition comprising a processor and a memory to store computer program instructions the computer program instructions when executed on the processor cause the processor to perform operations comprising detecting a motion by a subject within a predetermined area of view assigning a unique session identification number to the subject detected within a predetermined area of view detecting a facial area of the subject detected within a predetermined area of view generating an image of the facial area of the subject assessing a quality of the image of the facial area of the subject determining an identity of the subject based on the image of the facial area of the subject identifying an intent of the subject and authorizing access to a point of entry based on the determined identity of the subject and based on the intent of the subject  the apparatus of claim  further comprising determining one or more additional subjects within the predetermined area of view and assigning a unique session identification number to each of the one or more additional subjects detected within a predetermined area of view  the apparatus of claim  wherein the assessing a quality of the image of the facial area of the subject comprises assessing whether the quality of the image of the facial area of the object equates predetermined metric of quality and upon determining that the quality of the image of the facial area of the object is inferior to the predetermined metric of quality discarding the image of the facial area of the subject and generating a second image of the facial area of the subject  the apparatus of claim  further comprising detecting whether the facial area of the subject is photographic image and upon detecting that the facial area of the subject is a photographic image generating a warning and restrict access to the access point  the apparatus of claim  further comprising conducing an incremental training of the image of the facial area of the subject  the apparatus of claim  wherein conducing an incremental training of the image of the facial area of the subject comprises capturing a first image of the facial area having facial landmarks converting the first image of the facial area into a first numeric vector capturing a second image of the facial area having facial landmarks converting the second image of the facial area into a second numeric vector calculating a weighted mean of the first numeric vector and the second numeric vector wherein the weighted mean represents a change in a facial area and storing the weighted mean in the database a robot comprising a body configured to rotate and to tilt a camera coupled to the body and configured to rotate and tilt according to the rotate and the tilt of the body wherein the camera is configured to acquire a video of a space a face recognition unit configured to recognize respective faces of one or more persons in the video a tracking unit configured to track motion of each of the recognized faces of the one or more persons and a controller configured to calculate a respective size of each of the faces of the one or more persons select a first person from among the one or more persons based on the calculated sizes of the faces and control at least one of a direction of the rotation of the camera an angle of the tilt of the camera and a focal distance of the camera based on the tracked motion of the recognized face of the first person  the robot of claim  wherein the controller is configured to control the direction of the rotation of the camera and the angle of the tilt of the camera to achieve an particular orientation of the camera relative to the face of the first person and control a focal distance of the camera by comparing respective sizes of the face of the first person before and after motion of the first person  the robot of claim  wherein the particular orientation occurs when the camera faces a general direction of the face of the first person  the robot of claim  wherein the controller is configured to normalize sizes of the faces of the one or more persons based on an interocular distance and select the first person based on the normalized sizes of the faces of the one or more persons  the robot of claim  wherein the controller is configured to select a person having a largest face size from among the one or more persons as the first person  the robot of claim  further comprising a microphone configured to receive a spoken audio that is present in the space wherein the controller is further configured to select the first person further based on the received spoken audio  the robot of claim  wherein the controller is further configured to control gain of the microphone by comparing respective sizes of the face of the first person before and after motion of the first person  the robot of claim  wherein the controller is configured to calculate a position from which the spoken audio is provided and select the first person further based on whether the one or more persons are in the position from which the voice signal is provided  the robot of claim  wherein the controller is configured to select a second person as the first person from among the one or more persons when the second person is located in the position from which the spoken audio is provided  the robot of claim  wherein the controller is configured to select a second person having a largest face size as the first person from among the one or more persons when none of the one or more persons is located in the position from which the spoken audio is provided  the robot of claim  wherein the controller is configured to select a second person having a largest face size as the first person from among the one or more persons when a plurality of persons from among the one or more persons are located in the position from which the spoken audio is provided  the robot of claim  further comprising a speaker wherein the controller is configured to control volume of the speaker by comparing respective sizes of the face of the first person before and after motion of the first person  the robot of claim  wherein the body is further configured to rotate in a lateral direction and to tilt in an vertical direction  an electronic device comprising a camera coupled to the body and configured to rotate and to tilt wherein the camera is configured to acquire a video of a space within which one or more persons are positioned and a processor configured to recognize respective faces of the one or more persons in the video track motion of each of the recognized faces of the one or more persons calculate a respective size of each of the faces of the one or more persons select a first person from among the one or more persons based on the calculated sizes of the faces and control at least one of a direction of the rotation of the camera an angle of the tilt of the camera and a focal distance of the camera based on the tracked motion of the recognized face of the first person  a method comprising acquiring by a camera a video of a space within which one or more persons are positioned recognizing respective faces of the one or more persons in the video tracking motion of each of the recognized faces of the one or more persons calculating a respective size of each of the faces of the one or more persons selecting a first person from among the one or more persons based on the calculated sizes of the faces and controlling at least one of a direction of rotation of the camera an angle of tilt of the camera and a focal distance of the camera based on the tracked motion of the recognized face of the first person a method of inferring topics from a multimodal file the method comprising receiving a multimodal file extracting a set of entities from the multimodal file linking the set of entities to produce a set of linked entities obtaining reference information for the set of entities based at least on the reference information generating a graph of the set of linked entities the graph comprising nodes and edges based at least on the nodes and edges of the graph determining clusters in the graph based at least on the clusters in the graph identifying topic candidates extracting features from the clusters in the graph based at least on the extracted features selecting at least one topicid from among the topic candidates to represent at least one cluster and indexing the multimodal file with the at least one topicid  the method of claim  wherein the multimodal file comprises a video portion and an audio portion and wherein extracting a set of entities from the multimodal file comprises detecting objects in the video portion of the multimodal file and detecting text in the audio portion of the multimodal file  the method of claim  wherein detecting objects comprises performing face recognition  the method of claim  wherein detecting text comprises performing a speech to text process  the method of claim  further comprising identifying a language used in the audio portion of the multimodal file and wherein performing a speech to text process comprises performing a speech to text process in the identified language  the method of claim  further comprising translating the detected text  the method of claim  further comprising determining significant clusters and insignificant clusters in the determined clusters and wherein extracting features from the clusters in the graph comprises extracting features from the significant clusters in the graph  the method of claim  wherein extracting features from the clusters in the graph comprises at least one process selected from the list consisting of determining a graph diameter and determining a jaccard coefficient  the method of claim  wherein selecting at least one topicid to represent at least one cluster comprises based at least on the extracted features mapping topic candidates into a probability interval and based at least on the mapping ranking topic candidates within the at least one cluster and selecting the at least one topicid based at least on the ranking  the method of claim  further comprising translating the at least one topicid and wherein indexing the multimodal file with the at least one topicid comprises indexing the multimodal file with the at least one translated topicid  a system for inferring topics from a multimodal file the system comprising an entity extraction component comprising an object detection component and a speech to text component operative to extract a set of entities from a multimodal file comprising a video portion and an audio portion an entity linking component operative to link the extracted set of entities to produce a set of linked entities an information retrieval component operative to obtain reference information for the extracted set of entities a graphing and analysis component operative to generate a graph of the set of linked entities the graph comprising nodes and edges based at least on the nodes and edges of the graph determine clusters in the graph based at least on the clusters in the graph identify topic candidates and extract features from the clusters in the graph a topicid selection component operative to rank the topic candidates within at least one cluster and based at least on the ranking select at least one topicid from among the topic candidates to represent at least one cluster and a video indexer operative to index the multimodal file with the at least one topicid  the system of claim  wherein the object detection component is operative to perform face recognition  the system of claim  wherein the speech to text component is operative to extract entity information in at least two different languages  one or more computer storage devices having computer-executable instructions stored thereon for inferring topics from a multimodal file which on execution by a computer cause the computer to perform operations comprising receiving a multimodal file comprising a video portion and an audio portion extracting a set of entities from the multimodal file wherein extracting a set of entities from the multimodal file comprises detecting objects in the video portion of the multimodal file with face recognition detecting text in the audio portion of the multimodal file with a speech to text process and disambiguating among a set of detected entity names linking the set of entities to produce a set of linked entities obtaining reference information for the set of entities based at least on the reference information generating a graph of the set of linked entities the graph comprising nodes and edges based at least on the nodes and edges of the graph determining clusters in the graph determining significant clusters and insignificant clusters in the determined clusters based at least on the significant clusters in the graph identifying topic candidates extracting features from the significant clusters in the graph based at least on the extracted features mapping the topic candidates into a probability interval based at least on the mapping ranking the topic candidates within at least one significant cluster based on the ranking selecting at least one topicid from among the topic candidates to represent the at least one significant cluster and indexing the multimodal file with the at least one topicid  the one or more computer storage devices of claim  wherein the operations further comprise identifying a language used in the audio portion of the multimodal file and detecting text in the audio portion of the multimodal file with a speech to text process comprises performing a speech to text process in the identified language权利要求 、 一种人脸识别方法其特征在于包括 通过第一摄像头获取第一人脸图像 提取所述第一人脸图像的第一人脸特征 将所述第一人脸特征与预先存储的第二人脸特征进行对比获得参考相似度所述第 二人脸特征经第二摄像头获取的第二人脸图像的特征提取而得所述第二摄像头与所述第 一摄像头属于不同类型的摄像头 根据所述参考相似度确定所述第一人脸特征与所述第二人脸特征是否对应相同人。 、 根据权利要求 所述的方法其特征在于 所述第一摄像头为热成像摄像头所述第二摄像头为可见光摄像头 或者所述第一摄像头为可见光摄像头所述第一摄像头为热成像摄像头。 、 根据权利要求 或 所述的方法其特征在于所述根据所述参考相似度确定所 述第一人脸特征与所述第二人脸特征是否对应相同人包括 根据所述参考相似度、 参考误报率以及相似度阈值确定所述第一人脸特征与所述第二 人脸特征是否对应相同人其中不同的误报率对应不同的相似度阈值。 、 根据权利要求 或 所述的方法其特征在于所述根据所述参考相似度确定所 述第一人脸特征与所述第二人脸特征是否对应相同人包括 根据所述参考相似度以及阈值信息确定归一化后的参考相似度 根据所述归一化后的参考相似度确定所述第一人脸特征与所述第二人脸特征是否对 应相同人。 、 根据权利要求 -任一项所述的方法其特征在于所述提取所述第一人脸图像的 第_人脸特征包括 将所述第一人脸图像输入预先训练完成的神经网络通过所述神经网络输出所述第一 人脸图像的第一人脸特征其中所述神经网络基于第一类型图像样本和第二类型图像样 本训练得到所述第一类型图像样本和所述第二类型图像样本由不同类型的摄像头拍摄得 到且所述第一类型图像样本和所述第二类型图像样本中包括人脸。 、 根据权利要求  所述的方法其特征在于所述神经网络基于所述第一类型图像 样本、 所述第二类型图像样本和混合类型图像样本训练得到所述混合类型图像样本由所 述第一类型图像样本和所述第二类型图像样本配对而得。 、 根据权利要求 -任一项所述的方法其特征在于所述第一摄像头包括车载摄像 头所述通过第一摄像头获取第一人脸图像包括 通过所述车载摄像头获取所述第一人脸图像所述第一人脸图像包括车辆的用车人的 人脸图像。 、 根据权利要求  所述的方法其特征在于所述用车人包括驾驶所述车辆的人、 乘坐所述车辆的人、 对所述车辆进行修理的人、 给所述车辆加油的人以及控制所述车辆的 人中的一项或多项。 、 根据权利要求  所述的方法其特征在于所述用车人包括驾驶所述车辆的人 所述通过所述车载摄像头获取所述第一人脸图像包括 在接收到触发指令的情况下通过所述车载摄像头获取所述第一人脸图像 或者在所述车辆运行时通过所述车载摄像头获取所述第一人脸图像 或者在所述车辆的运行速度达到参考速度的情况下通过所述车载摄像头获取所述 第一人脸图像。 、 根据权利要求 -任一项所述的方法其特征在于所述第二人脸图像为对所述 用车人进行人脸注册的图像所述将所述第一人脸特征与预先存储的第二人脸特征进行对 比之前所述方法还包括 通过所述第二摄像头获取所述第二人脸图像 提取所述第二人脸图像的第二人脸特征 保存所述第二人脸图像的第二人脸特征。 、 一种神经网络训练方法其特征在于包括 获取第一类型图像样本和第二类型图像样本所述第一类型图像样本和所述第二类型 图像样本由不同类型的摄像头拍摄得到且所述第一类型图像样本和所述第二类型图像样 本中包括人脸 根据所述第一类型图像样本和所述第二类型图像样本训练神经网络。 、 根据权利要求 所述的方法其特征在于所述根据所述第一类型图像样本和所 述第二类型图像样本训练神经网络包括 将所述第一类型图像样本和所述第二类型图像样本配对得到所述第一类型图像样本 和所述第二类型图像样本的混合类型图像样本 根据所述第一类型图像样本、 所述第二类型图像样本和所述混合类型图像样本训练 所述神经网络。 、 根据权利要求  所述的方法其特征在于所述根据所述第一类型图像样本、 所述第二类型图像样本和所述混合类型图像样本训练所述神经网络包括 通过所述神经网络获取所述第一类型图像样本的人脸预测结果、 所述第二类型图像样 本的人脸预测结果和所述混合类型图像样本的人脸预测结果 根据所述第一类型图像样本的人脸预测结果和人脸标注结果的差异、 所述第二类型图 像样本的人脸预测结果和人脸标注结果之间的差异、 以及所述混合类型图像样本的人脸预 测结果和人脸标注结果的差异训练所述神经网络。 、 根据权利要求  所述的方法其特征在于所述神经网络中包括第一分类器、 第二分类器和混合分类器所述通过所述神经网络获取所述第一类型图像样本的人脸预测 结果、 所述第二类型图像样本的人脸预测结果和所述混合类型图像样本的人脸预测结果 包括 将所述第一类型图像样本的人脸特征输入至所述第一分类器中得到所述第一类型图 像样本的人脸预测结果 将所述第二类型图像样本的人脸特征输入至所述第二分类器中得到所述第二类型图 像样本的人脸预测结果 将所述混合类型图像样本的人脸特征输入至所述混合分类器中得到所述混合类型图 像样本的人脸预测结果。 、 根据权利要求 所述的方法其特征在于所述方法还包括 在训练完成的所述神经网络中去除所述第一分类器、 所述第二分类器和所述混合分类 器得到用于进行人脸识别的神经网络。 、 一种人脸识别装置其特征在于包括 第一获取单元用于通过第一摄像头获取第一人脸图像 第一提取单元用于提取所述第一人脸图像的第一人脸特征 对比单元用于将所述第一人脸特征与预先存储的第二人脸特征进行对比获得参考 相似度所述第二人脸特征经第二摄像头获取的第二人脸图像的特征提取而得所述第二 摄像头与所述第一摄像头属于不同类型的摄像头 确定单元用于根据所述参考相似度确定所述第一人脸特征与所述第二人脸特征是否 对应相同人。 、 根据权利要求 所述的装置其特征在于 所述第一摄像头为热成像摄像头所述第二摄像头为可见光摄像头 或者所述第一摄像头为可见光摄像头所述第一摄像头为热成像摄像头。 、 根据权利要求 或 所述的装置其特征在于 所述确定单元具体用于根据所述参考相似度、 参考误报率以及相似度阈值确定所述 第一人脸特征与所述第二人脸特征是否对应相同人其中不同的误报率对应不同的相似 度阈值。 、 根据权利要求 或 所述的装置其特征在于 所述确定单元具体用于根据所述参考相似度以及阈值信息确定归一化后的参考相似 度以及根据所述归一化后的参考相似度确定所述第一人脸特征与所述第二人脸特征是否 对应相同人。 、 根据权利要求 -任_项所述的装置其特征在于 所述第一提取单元具体用于将所述第一人脸图像输入预先训练完成的神经网络通 过所述神经网络输出所述第一人脸图像的第一人脸特征其中所述神经网络基于第一类 型图像样本和第二类型图像样本训练得到所述第一类型图像样本和所述第二类型图像样 本由不同类型的摄像头拍摄得到且所述第一类型图像样本和所述第二类型图像样本中包 括人脸。 、 根据权利要求  所述的装置其特征在于所述神经网络基于所述第一类型图 像样本、 所述第二类型图像样本和混合类型图像样本训练得到所述混合类型图像样本由 所述第一类型图像样本和所述第二类型图像样本配对而得。 、 根据权利要求 -任一项所述的装置其特征在于所述第一摄像头包括车载 摄像头 所述第一获取单元具体用于通过所述车载摄像头获取所述第一人脸图像所述第一 人脸图像包括车辆的用车人的人脸图像。 、 根据权利要求 所述的装置其特征在于所述用车人包括驾驶所述车辆的人、 乘坐所述车辆的人、 对所述车辆进行修理的人、 给所述车辆加油的人以及控制所述车辆的 人中的一项或多项。 、 根据权利要求 所述的装置其特征在于所述用车人包括驾驶所述车辆的人 所述第一获取单元具体用于在接收到触发指令的情况下通过所述车载摄像头获取所述 第一人脸图像 或者所述第一获取单元具体用于在所述车辆运行时通过所述车载摄像头获取所 述第 _人脸图像 或者所述第一获取单元具体用于在所述车辆的运行速度达到参考速度的情况下 通过所述车载摄像头获取所述第一人脸图像。 、 根据权利要求 -任一项所述的装置其特征在于所述第二人脸图像为对所 述用车人进行人脸注册的图像所述装置还包括 第二获取单元用于通过所述第二摄像头获取所述第二人脸图像 第二提取单元用于提取所述第二人脸图像的第二人脸特征 保存单元用于保存所述第二人脸图像的第二人脸特征。 、 一种神经网络训练装置其特征在于包括 获取单元用于获取第一类型图像样本和第二类型图像样本所述第一类型图像样本 和所述第二类型图像样本由不同类型的摄像头拍摄得到且所述第一类型图像样本和所述 第二类型图像样本中包括人脸 训练单元用于根据所述第一类型图像样本和所述第二类型图像样本训练神经网络。 、 根据权利要求 所述的装置其特征在于所述训练单元包括 配对子单元用于将所述第一类型图像样本和所述第二类型图像样本配对得到所述 第一类型图像样本和所述第二类型图像样本的混合类型图像样本 训练子单元用于根据所述第一类型图像样本、 所述第二类型图像样本和所述混合类 型图像样本训练所述神经网络。 、 根据权利要求 所述的装置其特征在于 所述训练子单元具体用于通过所述神经网络获取所述第一类型图像样本的人脸预测 结果、 所述第二类型图像样本的人脸预测结果和所述混合类型图像样本的人脸预测结果 以及根据所述第一类型图像样本的人脸预测结果和人脸标注结果的差异、 所述第二类型图 像样本的人脸预测结果和人脸标注结果之间的差异、 以及所述混合类型图像样本的人脸预 测结果和人脸标注结果的差异训练所述神经网络。 、 根据权利要求  所述的装置其特征在于所述神经网络中包括第一分类器、 第二分类器和混合分类器 所述训练子单元具体用于将所述第一类型图像样本的人脸特征输入至所述第一分类 器中得到所述第一类型图像样本的人脸预测结果以及将所述第二类型图像样本的人脸 特征输入至所述第二分类器中得到所述第二类型图像样本的人脸预测结果以及将所述 混合类型图像样本的人脸特征输入至所述混合分类器中得到所述混合类型图像样本的人 脸预测结果。 、 根据权利要求 所述的装置其特征在于所述装置还包括 神经网络应用单元用于在训练完成的所述神经网络中去除所述第一分类器、 所述第 二分类器和所述混合分类器得到用于进行人脸识别的神经网络。 、 一种电子设备其特征在于包括处理器和存储器所述处理器和所述存储器耦 合其中所述存储器用于存储程序指令所述程序指令被所述处理器执行时使所述处 理器执行权利要求 -任一项所述的方法和或使所述处理器执行权利要求 -任一 项所述的方法。 、 一种计算机可读存储介质其特征在于所述计算机可读存储介质中存储有计算 机程序所述计算机程序包括程序指令所述程序指令当被处理器执行时使所述处理器 执行权利要求 -任一项所述的方法和或使所述处理器执行权利要求 -任一项所 述的方法。 a system for alerting on vision impairment said system comprising a processing unit configured and operable for receiving scene data being indicative of a scene of at least one consumer in an environment identifying in the scene data a certain consumer identifying an event being indicative of a behavioral compensation for vision impairment and upon identification of such an event sending a notification relating to the vision impairment  the system of claim  further comprising at least one sensing unit configured and operable for detecting the scene data  the system of claim  wherein said at least one sensing unit comprises at least one of at least one imaging unit configured and operable for capturing at least one image of at least a portion of a consumer's body at least one motion detector configured and operable for detecting consumer data being indicative of a motion of a consumer or at least one eye tracker configured and operable for tracking eye motion of a consumer  the system of claim  wherein the at least one imaging unit comprises a plurality of cameras placed at different heights  the system of any one of claims  to  wherein said sensing unit is accommodated in an optical or digital eyewear frame display  the system of any one of claims  to  wherein said processing unit is configured and operable for identifying a consumer's condition said consumer's condition comprising consumer data being indicative of the consumer's position and location relative to at least one object in the consumer's environment said consumer data comprises at least one of a consumer's face eyewear posture position sound or motion  the system of any one of claims  to  wherein said event comprises at least one position and orientation of head increase or decrease of viewing distance between the consumer and viewed object and changing the position of eyeglasses worn by the consumer  the system of any one of claims  to  wherein said event is identified by identifying images having an image feature being indicative of behavioral compensation performing a bruckner test performing a hirschberg test and measuring blink count frequency  the system of claim  wherein the image feature being indicative of behavioral compensation comprises squinting head orientation certain distances between an object and consumer's eyes certain position of eyeglasses on the consumer's face strabismus cataracts and reflections from the eye  the system of any one of claims  to  wherein the notification includes at least one of the data indicative of the identified event data indicative of the identified consumer ophthalmologic recommendations based on the identified event or lack of events or an appointment for a vision test  the system of any one of claims  to  wherein said processing unit comprises a memory for storing at least one of a reference data indicative of behavioral compensation for vision impairment data indicative of the notification or data indicative of a follow-up of the notification  the system of claim   wherein said processing unit is configured for at least one of identifying the event upon comparison between the detected data and the reference data or determining a probability for a vision impairment of the consumer based on the comparison  the system of any one of claims  to  wherein said processing unit comprises a communication interface being configured for sending the notification to at least one of the identified consumer or a third party  the system of any one of claims  to  wherein said processing unit is configured for providing a frame recommendation  the system of any one of claims  to  wherein said memory is configured for storing a database including a multiplicity of data sets related to a plurality of spectacle frame models and sizes  the system according to claim  or  wherein said processing unit is configured and operable to correlate between frames parameters and ophthalmic prescriptions  the system according to any of claims  to  wherein said processing unit is configured and operable to correlate between frames parameters and facial features  the system according to any of claims  to  wherein said processing unit is configured and operable to correlate between frames parameters and eyewear preferences  the system according to any of claims  to  comprising a server and at least one computer entity linked to the server via a network wherein said network is configured to receive and respond to requests sent across the network transmitting one or more modules of computer executable program instructions and displayable data to the network connected user computer platform in response to a request wherein said modules include modules configured to receive and transmit image information transmitting a frame recommendation and an optical lens option recommendation based on received image information for display by the network connected user computer platform  a computer program instructions stored in the local storage that when executed by a processing unit cause the processing unit to receive data being indicative of a scene of at least one consumer in an environment identify in the data a certain consumer identify an event being indicative of a behavioral compensation for vision impairment and upon identification of such an event send a notification relating to the vision impairment  a computer program product stored on a tangible computer readable medium comprising a library of software modules which cause a computer executing them to prompt for information pertinent to at least one of an eyeglasses recommendation and an optical lens option recommendation to store said information or to display eyewear recommendations   the computer program product of claim   wherein said library further comprises a module for frame selection point of sales and advertising  a computer platform for facilitating eye glasses marketing or selection comprising a camera a processor configured to execute computer program instructions to cause the processor to take an image of a consumer identify in the image a certain consumer identify an event being indicative of a behavioral compensation for vision impairment and upon identification of such an event sending a notification relating to the vision impairment local storage for processor executable instructions for carrying out storage of information  a method for alerting on vision impairment said method comprising identifying a certain individual in scene data being indicative of a scene of at least one consumer in an environment identifying an event being indicative of a behavioral compensation for vision impairment and upon identification of such an event sending a notification on the vision impairment  the method of claim  further comprising detecting data being indicative of a scene of at least one consumer in a retail environment  the method of claim  wherein detecting the data being indicative of at least one consumer comprises at least one of capturing at least one image of at least one consumer detecting data being indicative of a motion of a consumer or tracking an eye motion of a consumer  the method of claim  wherein capturing at least one image of at least one consumer comprises continuously recording a scene  the method of any one of claims  to  further comprising identifying in the data the consumer' s condition including data being indicative of the consumer's position and location relative to the consumer's environment said data comprising at least one of the consumer's face posture position sound or motion  the method of any one of claims  to  wherein said event comprises at least one of position and orientation of head increase or decrease of viewing distance between the consumer and viewed object or changing the position of eyeglasses worn by the consumer  the method of any one of claims  to  wherein identifying of the event comprises identifying images having an image feature being indicative of behavioral compensation performing a bruckner test performing a hirschberg test and measuring blink countfrequency  the method of claim  wherein the image feature being indicative of behavioral compensation comprises squinting head orientation certain distances between an object and a consumer's eyes certain position of eyeglasses on the consumer's face strabismus cataracts and reflections from the eye  the method of any one of claims  to  wherein identifying in the at least one image a consumer in a retail environment comprising at least one of receiving data characterizing the retail environment or performing face recognition  the method of any one of claims  to  wherein sending a notification comprising sending the notification to at least one of the identified consumer or a third party  the method of any one of claims  to  wherein the notification includes at least one of the data indicative of the identified event data indicative of the identified consumer ophthalmologic recommendations based on the identified event or lack of events and an appointment for a vision test  the method of any one of claims  to  further comprising storing at least one of a reference data indicative of behavioral compensation for vision impairment data indicative of the notification or data indicative of a follow-up of the notification  the method of claim  further comprising identifying the event upon comparison between the detected data and the reference data and determining a probability for a vision impairment of the consumer based on the comparison  a computer program intended to be stored in a memory of a processor unit of a computer system or in a removable memory medium adapted to cooperate with a reader of the processor unit comprising instructions for implementing the method according to any of claims  to \n"
     ]
    }
   ],
   "source": [
    "#punctuation and digits removal: we replace any undesired character with a ''\n",
    "for char in '?.,!/;:()1234567890':  \n",
    "    lowera_text = lowera_text.replace(char,'')\n",
    "print(lowera_text)\n",
    "for char in '?.,!/;:()1234567890':  \n",
    "    lowerc_text = lowerc_text.replace(char,'')\n",
    "print(lowerc_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81ef35c",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "In this step we tokenize the text of both sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "102a8bcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' an electronic device  configured to make a screen  to display a plurality of image frames comprising an image capturing device  a storage device  storing a plurality of modules and a processor  coupled to the image capturing device  and the storage device  configured to execute the modules in the storage device  to configure the screen  to display a plurality of marker objects at a plurality of predetermined calibration positions configure the image capturing device  to capture a plurality of first head images when a user is looking at the predetermined calibration positions s perform a plurality of first face recognition operations on the first head images to obtain a plurality of first face regions corresponding to the predetermined calibration positions s detect a plurality of first facial landmarks corresponding to the first face regions s calculate a plurality of rotation reference angles of the user looking at the predetermined calibration positions according to the first facial landmarks configure the image capturing device  to capture a second head image of the user perform a second face recognition operation on the second head image to obtain a second face region detect a plurality of second facial landmarks within the second face region s estimate a head posture angle of the user according to the second facial landmarks calculate a gaze position of the user on the screen  according to the head posture angle the rotation reference angles and the predetermined calibration positions and configure the screen  to display a corresponding visual effect according to the gaze position  the electronic device  according to claim  wherein the gaze position comprises a first coordinate value in a first axial direction and a second coordinate value in a second axial direction  the electronic device  according to claim  wherein the head posture angles comprise a head pitch angle and a head yaw angle and the rotation reference angles comprise a first pitch angle a second pitch angle a first yaw angle and a second yaw angle corresponding to the predetermined calibration positions  the electronic device  according to claim  wherein the processor  performs interpolation operation or extrapolation operation according to the first yaw angle the second yaw angle a first position corresponding to the first yaw angle among the predetermined calibration positions a second position corresponding to the second yaw angle among the predetermined calibration positions and the head yaw angle thereby obtaining the first coordinate value of the gaze position and the processor  performs interpolation operation or extrapolation operation according to the first pitch angle the second pitch angle a third position corresponding to the first pitch angle among the predetermined calibration positions a fourth position corresponding to the second pitch angle among the predetermined calibration positions and the head pitch angle thereby obtaining the second coordinate value of the gaze position  the electronic device  according to claim  wherein the processor  calculates a plurality of first viewing distances between the user and the screen  according to the first facial landmarks the processor  estimates a second viewing distance between the user and the screen  according to the second facial landmarks and the processor  adjusts the rotation reference angles or the gaze position according to the second viewing distance and the first viewing distances  the electronic device  according to claim  wherein the processor  maps a plurality of two-dimensional position coordinates of the second facial landmarks under a plane coordinate system to a plurality of three-dimensional position coordinates under a three-dimensional coordinate system and the processor  estimates the head posture angle according to the three-dimensional position coordinates of the second facial landmarks  the electronic device  according to claim  wherein the second head image comprises a wearable device and the second facial landmarks do not comprise a plurality of third facial landmarks of the user covered by the wearable device  the electronic device  according to claim  wherein the second head image comprises a wearable device and the second facial landmarks comprise one or more simulated landmarks marked by the wearable device  an operating method adapted for an electronic device  comprising an image capturing device  and making a screen  to display a plurality of image frames the method comprising configuring the screen  to display a plurality of marker objects at a plurality of predetermined calibration positions configuring the image capturing device  to capture a plurality of first head images when a user is looking at the predetermined calibration positions s performing a plurality of first face recognition operations on the first head images to obtain a plurality of first face regions corresponding to the predetermined calibration positions s detecting a plurality of first facial landmarks corresponding to the first face regions s calculating a plurality of rotation reference angles of the user looking at the predetermined calibration positions according to the first facial landmarks configuring the image capturing device  to capture a second head image of the user performing a second face recognition operation on the second head image to obtain a second face region s detecting a plurality of second facial landmarks within the second face region estimating a head posture angle of the user according to the second facial landmarks calculating a gaze position of the user on the screen  according to the head posture angle the rotation reference angles and the predetermined calibration positions and s configuring the screen  to display a corresponding visual effect according to the gaze position  the operation method according to claim  wherein the gaze position comprises a first coordinate value in a first axial direction and a second coordinate value in a second axial direction  the operation method according to claim  wherein the head posture angles comprise a head pitch angle and a head yaw angle and the rotation reference angles comprise a first pitch angle a second pitch angle a first yaw angle and a second yaw angle corresponding to the predetermined calibration positions  the operation method according to claim  wherein the step of calculating the gaze position of the user on the screen  according to the head posture angle the rotation reference angles and the predetermined calibration positions comprises performing interpolation operation or extrapolation operation according to the first yaw angle the second yaw angle a first position corresponding to the first yaw angle among the predetermined calibration positions a second position corresponding to the second yaw angle among the predetermined calibration positions and the head yaw angle thereby obtaining the first coordinate value of the gaze position and performing interpolation operation or extrapolation operation according to the first pitch angle the second pitch angle a third position corresponding to the first pitch angle among the predetermined calibration positions a fourth position corresponding to the second pitch angle among the predetermined calibration positions and the head pitch angle thereby obtaining the second coordinate value of the gaze position  the operation method according to claim  wherein the method further comprises calculating a plurality of first viewing distances between the user and the screen  according to the first facial landmarks estimating a second viewing distance between the user and the screen  according to the second facial landmarks and adjusting the rotation reference angles or the gaze position according to the second viewing distance and the first viewing distances  the operation method according to claim  wherein the method further comprises mapping a plurality of two-dimensional position coordinates of the second facial landmarks under a plane coordinate system to a plurality of three-dimensional position coordinates under a three-dimensional coordinate system and estimating the head posture angle according to the three-dimensional position coordinates of the second facial landmarks  the operation method according to claim  wherein the second head image comprises a wearable device and the second facial landmarks do not comprise a plurality of third facial landmarks of the user covered by the wearable device  the operation method according to claim  wherein the second head image comprises a wearable device and the second facial landmarks comprise one or more simulated landmarks marked by the wearable device a computation method applied to a computing system wherein the computing system comprises a control unit a computation group and a general storage unit wherein the control unit comprises a first memory a decoding logic and a controller wherein the computation group comprises a group controller and a plurality of computing units the general storage unit is configured to store data and the computation method comprises receiving by the controller a first level instruction sequence and partitioning by the decoding logic the first level instruction sequence into a plurality of second level instruction sequences creating by the controller m threads for the plurality of second level instruction sequences and allocating by the controller an independent register as well as configuring an independent addressing function for each thread of the m threads wherein m is an integer greater than or equal to  and obtaining by the group controller a plurality of computation types of the plurality of second level instruction sequences obtaining a corresponding fusion computation manner of the computation types according to the plurality of computation types and adopting by the plurality of computing units the fusion computation manner to call the m threads for performing computations on the plurality of second level instruction sequences to obtain a final result  the method of claim  wherein the obtaining by the group controller a plurality of computation types of the plurality of second level instruction sequences obtaining a corresponding fusion computation manner of the computation types according to the plurality of computation types and adopting by the plurality of computing units the fusion computation manner to call the m threads for performing computations on the plurality of second instruction sequences to obtain a final result if the computation types represent computation operations of the same type the group controller calls a combined computation manner in which single instruction multiple data of the same type is in combination with single instruction multiple threads and uses the m threads to perform the combined computation manner to obtain a final result which includes partitioning by the decoding logic the m threads into n wraps for allocating to the the plurality of computing units converting by the group controller the plurality of second instruction sequences into a plurality of second control signals and sending the second control signals to the plurality of computing units calling by the plurality of computing units wraps that are allocated to the computing units and the second control signals to fetch corresponding data according to the independent addressing function performing by the plurality of computing units computations on the data to obtain a plurality of intermediate results and splicing the plurality of intermediate results to obtain a final result  the method of claim  wherein the obtaining by the group controller a plurality of computation types of the plurality of second level instruction sequences obtaining a corresponding fusion computation manner of the computation types according to the plurality of computation types and adopting by the plurality of computing units the fusion computation manner to call the m threads for performing computations on the plurality of second instruction sequences to obtain a final result if the computation types represent computation operations of different types the group controller calls simultaneous multi-threading and the m threads to perform computations to obtain a final result which includes partitioning by the decoding logic the m threads into n wraps converting the plurality of second instruction sequences into a plurality of second control signals obtaining by the group controller computation types supported by the plurality of computing units allocating by the controller the n wraps and the plurality of second control signals to corresponding computing units that support computation types of the wraps and the second control signals calling by the plurality of computing units wraps that are allocated to the computing units and the second control signals fetching by the plurality of computing units corresponding data performing by the plurality of computing units computations on the data to obtain a plurality of intermediate results and splicing all the intermediate results to obtain a final result  the method of claim  or  further comprising if a wrap a in the plurality of wraps is blocked adding the wrap a to a waiting queue and if data of the wrap a are already fetched adding the wrap a to a preparation queue wherein the preparation queue is a queue where a wrap to be scheduled for executing is located when a computing resource is idle  the method of claim  wherein the first level instruction sequence includes a very long instruction and the second level instruction sequence includes an instruction sequence  the method of claim  wherein the computing system further includes a tree module wherein the tree module includes a root port and a plurality of branch ports wherein the root port of the tree module is connected to the group controller and the plurality of branch ports of the tree module are connected to a computing unit of the plurality of computing units respectively and the tree module is configured to forward data blocks wraps or instruction sequences between the group controller and the plurality of computing units  the method of claim  wherein the tree module is an n-ary tree wherein n is an integer greater than or equal to   the method of claim  wherein the computing system further includes a branch processing circuit wherein the branch processing circuit is connected between the group controller and the plurality of computing units and the branch processing circuit is configured to forward data wraps or instruction sequences between the group controller and the plurality of computing units  a computing system comprising a control unit a computation group and a general storage unit wherein the control unit includes a first memory a decoding logic and a controller the computation group includes a group controller and a plurality of computing units the general storage unit is configured to store data the controller is configured to receive a first level instruction sequence and control the first memory and the decoding logic the decoding logic is configured to partition the first level instruction sequence into a plurality of second level instruction sequences the the controller is further configured to create m threads for the plurality of second level instruction sequences and allocate an independent register and configure an independent addressing function for each thread of the m threads m is an integer greater than or equal to  and the controller is further configured to convert the plurality of second instruction sequences into a plurality of control signals for sending to the group controller the group controller is configured to receive the plurality of control signals obtain a plurality of computational types if the plurality of control signals divide the m threads into n wraps and allocate the n wraps and the plurality of control signals to the plurality of computing units according to the plurality of computational types the plurality of computing units are configured to fetch data from the general storage unit through allocated wraps and control signals and perform computations to obtain an intermediate result and the group controller is configured to splice all intermediate results to obtain a final computation result  the computing system of claim  wherein the plurality of computing units includes an addition computing unit a multiplication computing unit an activation computing unit or a dedicated computing unit  the computing system of claim  wherein the dedicated computing unit includes a face recognition computing unit a graphics computing unit a fingerprint computing unit or a neural network computing unit  the computing system of claim  wherein the group controller is configured to if computation types of a plurality of control signals are graphics computations fingerprint identification face recognition or neural network operations allocate the plurality of control signals to the face recognition computing unit the graphics computing unit the fingerprint computing unit or the neural network computing unit respectively  the computing system of claim  wherein the first level instruction sequence includes a very long instruction and the second level instruction sequence includes an instruction sequence  the computing system of claim  further comprising a tree module wherein the tree module includes a root port and a plurality of branch ports wherein the root port of the tree module is connected to the group controller and the plurality of branch ports of the tree module are connected to a computing unit of the plurality of computing units respectively and the tree module is configured to forward data blocks wraps or instruction sequences between the group controller and the plurality of computing units  the computing system of claim  wherein the tree module is an n-ary tree wherein n is an integer greater than or equal to   the computing system of claim  wherein the computing system includes a branch processing circuit the branch processing circuit is connected between the group controller and the plurality of computing units and the branch processing circuit is configured to forward data wraps or instruction sequences between the group controller and the plurality of computing units  a computer program product comprising a non-instant computer readable storage medium wherein a computer program is stored in the non-instant computer readable storage medium and the computer program is capable of causing a computer to perform the method of any of claims - through operations a method for detecting body information on one or more passengers of a vehicle based on humans\\' status recognition comprising steps of a if at least one interior image of an interior of the vehicle is acquired a passenger body information-detecting device performing i a process of inputting the interior image into a face recognition network to thereby allow the face recognition network to detect each of faces of each of the passengers from the interior image and thus to output multiple pieces of passenger feature information corresponding to each of the detected faces and ii a process of inputting the interior image into a body recognition network to thereby allow the body recognition network to detect each of bodies of each of the passengers from the interior image and thus to output body-part length information of each of the detected bodies and b the passenger body information-detecting device performing a process of retrieving specific height mapping information corresponding to specific passenger feature information on a specific passenger from a height mapping table which stores height mapping information representing respective one or more predetermined ratios of one or more segment body portions of each of human groups to each of heights per each of the human groups a process of acquiring a specific height of the specific passenger from the specific height mapping information by referring to specific body-part length information of the specific passenger a process of retrieving specific weight mapping information corresponding to the specific passenger feature information from a weight mapping table which stores multiple pieces of weight mapping information representing predetermined correlations between each of the heights and each of weights per each of the human groups and a process of acquiring a weight of the specific passenger from the specific weight mapping information by referring to the specific height of the specific passenger  the method of claim  wherein at the step of a the passenger body information-detecting device performs a process of inputting the interior image into the body recognition network to thereby allow the body recognition network to i output one or more feature tensors with one or more channels corresponding to the interior image via a feature extraction network ii generate at least one keypoint heatmap and at least one part affinity field with one or more channels corresponding to each of the feature tensors via a keypoint heatmap & part affinity field extractor and iii extract keypoints from the keypoint heatmap via a keypoint detector to group the extracted keypoints by referring to the part affinity field and thus to generate body parts per the passengers and as a result allow the body recognition network to output multiple pieces of body-part length information on each of the passengers by referring to the body parts per the passengers  the method of claim  wherein the feature extraction network includes at least one convolutional layer and applies at least one convolution operation to the interior image to thereby output the feature tensors  the method of claim  wherein the keypoint heatmap & part affinity field extractor includes one of a fully convolutional network and a × convolutional layer and applies a fully-convolution operation or × convolution operation to the feature tensors to thereby generate the keypoint heatmap and the part affinity field  the method of claim  wherein the keypoint detector connects by referring to the part affinity field pairs respectively having highest mutual connection probabilities of being connected among the extracted keypoints to thereby group the extracted keypoints  the method of claim  wherein the feature extraction network and the keypoint heatmap & part affinity field extractor have been learned by a learning device performing i a process of inputting at least one training image including one or more objects for training into the feature extraction network to thereby allow the feature extraction network to generate one or more feature tensors for training having one or more channels by applying at least one convolutional operation to the training image ii a process of inputting the feature tensors for training into the keypoint heatmap & part affinity field extractor to thereby allow the keypoint heatmap & part affinity field extractor to generate one or more keypoint heatmaps for training and one or more part affinity fields for training having one or more channels for each of the feature tensors for training iii a process of inputting the keypoint heatmaps for training and the part affinity fields for training into the keypoint detector to thereby allow the keypoint detector to extract keypoints for training from each of the keypoint heatmaps for training and a process of grouping the extracted keypoints for training by referring to each of the part affinity fields for training to thereby detect keypoints per each of the objects for training and iv a process of allowing a loss layer to calculate one or more losses by referring to the keypoints per each of the objects for training and their corresponding ground truths to thereby adjust one or more parameters of the feature extraction network and the keypoint heatmap & part affinity field extractor such that the losses are minimized by backpropagation using the losses  the method of claim  wherein at the step of a the passenger body information-detecting device performs a process of inputting the interior image into the face recognition network to thereby allow the face recognition network to detect each of the faces of each of the passengers located in the interior image via a face detector and to output multiple pieces of the passenger feature information on each of the facial images via a facial feature classifier  the method of claim  wherein at the step of a the passenger body information-detecting device performs a process of inputting the interior image into the face recognition network to thereby allow the face recognition network to i apply at least one convolution operation to the interior image and thus to output at least one feature map corresponding to the interior image via at least one convolutional layer ii output one or more proposal boxes where the passengers are estimated as located on the feature map via a region proposal network iii apply pooling operation to one or more regions corresponding to the proposal boxes on the feature map and thus to output at least one feature vector via a pooling layer and iv apply fully-connected operation to the feature vector and thus to output the multiple pieces of the passenger feature information corresponding to each of the faces of each of the passengers corresponding to each of the proposal boxes via a fully connected layer  the method of claim  wherein the multiple pieces of the passenger feature information include each of ages each of genders and each of races corresponding to each of the passengers  a passenger body information-detecting device for detecting body information on one or more passengers of a vehicle based on humans\\' status recognition comprising at least one memory that stores instructions and at least one processor configured to execute the instructions to perform or support another device to perform i if at least one interior image of an interior of the vehicle is acquired i a process of inputting the interior image into a face recognition network to thereby allow the face recognition network to detect each of faces of each of the passengers from the interior image and thus to output multiple pieces of passenger feature information corresponding to each of the detected faces and ii a process of inputting the interior image into a body recognition network to thereby allow the body recognition network to detect each of bodies of each of the passengers from the interior image and thus to output body-part length information of each of the detected bodies and ii a process of retrieving specific height mapping information corresponding to specific passenger feature information on a specific passenger from a height mapping table which stores height mapping information representing respective one or more predetermined ratios of one or more segment body portions of each of human groups to each of heights per each of the human groups a process of acquiring a specific height of the specific passenger from the specific height mapping information by referring to specific body-part length information of the specific passenger a process of retrieving specific weight mapping information corresponding to the specific passenger feature information from a weight mapping table which stores multiple pieces of weight mapping information representing predetermined correlations between each of the heights and each of weights per each of the human groups and a process of acquiring a weight of the specific passenger from the specific weight mapping information by referring to the specific height of the specific passenger  the passenger body information-detecting device of claim  wherein at the process of i the processor performs a process of inputting the interior image into the body recognition network to thereby allow the body recognition network to i output one or more feature tensors with one or more channels corresponding to the interior image via a feature extraction network ii generate at least one keypoint heatmap and at least one part affinity field with one or more channels corresponding to each of the feature tensors via a keypoint heatmap & part affinity field extractor and iii extract keypoints from the keypoint heatmap via a keypoint detector to group the extracted keypoints by referring to the part affinity field and thus to generate body parts per the passengers and as a result allow the body recognition network to output multiple pieces of body-part length information on each of the passengers by referring to the body parts per the passengers  the passenger body information-detecting device of claim  wherein the keypoint heatmap & part affinity field extractor includes one of a fully convolutional network and a × convolutional layer and applies a fully-convolution operation or × convolution operation to the feature tensors to thereby generate the keypoint heatmap and the part affinity field  the passenger body information-detecting device of claim  wherein the keypoint detector connects by referring to the part affinity field pairs respectively having highest mutual connection probabilities of being connected among the extracted keypoints to thereby group the extracted keypoints  the passenger body information-detecting device of claim  wherein the feature extraction network and the keypoint heatmap & part affinity field extractor have been learned by a learning device performing i a process of inputting at least one training image including one or more objects for training into the feature extraction network to thereby allow the feature extraction network to generate one or more feature tensors for training having one or more channels by applying at least one convolutional operation to the training image ii a process of inputting the feature tensors for training into the keypoint heatmap & part affinity field extractor to thereby allow the keypoint heatmap & part affinity field extractor to generate one or more keypoint heatmaps for training and one or more part affinity fields for training having one or more channels for each of the feature tensors for training iii a process of inputting the keypoint heatmaps for training and the part affinity fields for training into the keypoint detector to thereby allow the keypoint detector to extract keypoints for training from each of the keypoint heatmaps for training and a process of grouping the extracted keypoints for training by referring to each of the part affinity fields for training to thereby detect keypoints per each of the objects for training and iv a process of allowing a loss layer to calculate one or more losses by referring to the keypoints per each of the objects for training and their corresponding ground truths to thereby adjust one or more parameters of the feature extraction network and the keypoint heatmap & part affinity field extractor such that the losses are minimized by backpropagation using the losses  the passenger body information-detecting device of claim  wherein at the process of i the processor performs a process of inputting the interior image into the face recognition network to thereby allow the face recognition network to i apply at least one convolution operation to the interior image and thus to output at least one feature map corresponding to the interior image via at least one convolutional layer ii output one or more proposal boxes where the passengers are estimated as located on the feature map via a region proposal network iii apply pooling operation to one or more regions corresponding to the proposal boxes on the feature map and thus to output at least one feature vector via a pooling layer and iv apply fully-connected operation to the feature vector and thus to output the multiple pieces of the passenger feature information corresponding to each of the faces of each of the passengers corresponding to each of the proposal boxes via a fully connected layer a computer implemented method for performing video coding based on face detection comprising receiving a video frame comprising one of a plurality of video frames of a video sequence determining the video frame is a key frame of the video sequence performing in response to the video frame being a key frame of the video sequence a multi-stage facial search of the video frame based on predetermined feature templates and a predetermined number of stages to determine a first candidate face region and a second candidate face region in the video frame testing the first and second candidate face regions based on skin tone information to determine the first candidate face region is a valid face region and the second candidate face region is an invalid face region rejecting the second candidate face region and outputting the first candidate face region and encoding the video frame based at least in part on the first candidate face region being a valid face region to generate a coded bitstream  the method of claim  wherein the skin tone information comprises a skin probability map  the method of claim  wherein said testing the first and second candidate face regions based on skin tone information is performed in response to the video frame being a key frame of the video sequence  the method of claim  wherein the first candidate face region comprises a rectangular region the method further comprising determining a free form shape face region corresponding to the first candidate face region wherein the free form shape face region has at least one of a pixel accuracy or a small block of pixels accuracy  the method of claim  wherein determining the free form shape face region comprises generating an enhanced skip probability map corresponding to the first candidate face region binarizing the enhanced skip probability map and overlaying the binarized enhanced skip probability map over at least a portion of the video frame to provide the free form shape face region  the method of claim  wherein a second video frame comprises a non-key frame of the video sequence the method further comprising performing face detection in the second video frame of the video sequence based on the free form shape face region  the method of claim  further comprising tracking a second free form shape face region in the second video frame based on the free form shape face region in the video frame  the method of claim  wherein tracking the second free form shape face region comprises determining a location of a second valid face region in the second video frame based on a displacement offset with respect to the first candidate face region  the method of claim  further comprising determining the displacement offset based on an offset between a centroid of a bounding box around a skin enhanced region corresponding to the first candidate face region and a second centroid of a second bounding box around a second skin enhanced region in the second video frame  the method of claim  wherein encoding the video frame based at least in part on the first candidate face region being a valid face region comprises at least one of reducing a quantization parameter corresponding to the first candidate face region adjusting a lambda value for the first candidate face region or disabling skip coding for the first candidate face region  the method of claim  wherein the bitstream comprises at least one of an hadvanced video coding avc compliant bitstream an hhigh efficiency video coding hevc compliant bitstream a vp compliant bitstream a vp compliant bitstream or an alliance for open media aom av compliant bitstream  a computer implemented method for performing face detection comprising receiving a video frame of a sequence of video frames performing a multi-stage facial search of the video frame based on predetermined feature templates and a predetermined number of stages to determine a first candidate face region and a second candidate face region in the video frame testing the first and second candidate face regions based on skin tone information to determine the first candidate face region is a valid face region and the second candidate face region is an invalid face region rejecting the second candidate face region and outputting the first candidate face region as a valid face region for further processing and providing an index indicative of a person being present in the video frame based on the valid face region  the method of claim  wherein the sequence of video frames comprises a sequence of surveillance video frames the method further comprising performing face recognition in the surveillance video frames based on the valid face region  the method of claim  wherein the sequence of video frames comprises a sequence of decoded video frames the method further comprising adding a marker corresponding to the received video frame to perform face recognition on the received video frame based on the valid face region  the method of claim  wherein the sequence of video frames is received during a device login attempt the method further comprising performing face recognition based on the valid face region and allowing access to the device if a secured face is recognized  the method of claim  wherein the sequence of video frames comprises a sequence of videoconferencing frames the method further comprising encoding the video frame based at least in part on the valid face region to generate a coded bitstream  the method of claim  wherein encoding the video frame comprises not encoding a background region of the video frame into the bitstream  the method of claim  further comprising encoding the video frame based at least in part on the valid face region to generate a coded bitstream wherein encoding the video frame comprises including metadata corresponding to the valid face region in the bitstream  the method of claim  further comprising decoding the coded bitstream to generate a decoded video frame and to determine the metadata corresponding to the valid face region in the bitstream  the method of claim  further comprising at least one of replacing the valid face region based on the decoded metadata cropping and displaying image data corresponding only to the valid face region based on the decoded metadata or indexing the decoded video frame based on the decoded metadata  a system for performing video coding based on face detection comprising a memory configured to store a video frame comprising one of a plurality of video frames of a video sequence and a processor coupled to the memory the processor to receive the video frame to determine the video frame is a key frame of the video sequence to perform in response to the video frame being a key frame of the video sequence a multi-stage facial search of the video frame based on predetermined feature templates and a predetermined number of stages to determine a first candidate face region and a second candidate face region in the video frame to test the first and second candidate face regions based on skin tone information to determine the first candidate face region is a valid face region and the second candidate face region is an invalid face region to reject the second candidate face region and outputting the first candidate face region and to encode the video frame based at least in part on the first candidate face region being a valid face region to generate a coded bitstream  the system of claim  wherein the skin tone information comprises a skin probability map  the system of claim  wherein the first candidate face region comprises a rectangular region the processor further to determine a free form shape face region corresponding to the first candidate face region wherein the free form shape face region has at least one of a pixel accuracy or a small block of pixels accuracy  the system of claim  wherein the processor to determine the free form shape face region comprises the processor to generate an enhanced skip probability map corresponding to the first candidate face region to binarize the enhanced skip probability map and to overlay the binarized enhanced skip probability map over at least a portion of the video frame to provide the free form shape face region  the system of claim  wherein a second video frame comprises a non-key frame of the video sequence and the processor is further to perform face detection in the second video frame of the video sequence based on the free form shape face region  the system of claim  wherein the processor is further to track a second free form shape face region in the second video frame based on the free form shape face region in the video frame  the system of claim  wherein to encode the video frame based at least in part on the first candidate face region being a valid face region comprises the processor to reduce a quantization parameter corresponding to the first candidate face region adjust a lambda value for the first candidate face region or disable skip coding for the first candidate face region  at least one non-transitory machine readable medium comprising a plurality of instructions that in response to being executed on a device cause the device to perform video coding based on face detection by receiving a video frame comprising one of a plurality of video frames of a video sequence determining the video frame is a key frame of the video sequence performing in response to the video frame being a key frame of the video sequence a multi-stage facial search of the video frame based on predetermined feature templates and a predetermined number of stages to determine a first candidate face region and a second candidate face region in the video frame testing the first and second candidate face regions based on skin tone information to determine the first candidate face region is a valid face region and the second candidate face region is an invalid face region rejecting the second candidate face region and outputting the first candidate face region and encoding the video frame based at least in part on the first candidate face region being a valid face region to generate a coded bitstream  the non-transitory machine readable medium of claim  wherein the skin tone information comprises a skin probability map  the non-transitory machine readable medium of claim  wherein the first candidate face region comprises a rectangular region the machine readable medium comprising further instructions that in response to being executed on the device cause the device to perform video coding based on face detection by determining a free form shape face region corresponding to the first candidate face region wherein the free form shape face region has at least one of a pixel accuracy or a small block of pixels accuracy  the non-transitory machine readable medium of claim  wherein determining the free form shape face region comprises generating an enhanced skip probability map corresponding to the first candidate face region binarizing the enhanced skip probability map and overlaying the binarized enhanced skip probability map over at least a portion of the video frame to provide the free form shape face region  the non-transitory machine readable medium of claim  wherein a second video frame comprises a non-key frame of the video sequence the machine readable medium comprising further instructions that in response to being executed on the device cause the device to perform video coding based on face detection by performing face detection in the second video frame of the video sequence based on the free form shape face region  the non-transitory machine readable medium of claim  the machine readable medium comprising further instructions that in response to being executed on the device cause the device to perform video coding based on face detection by tracking a second free form shape face region in the second video frame based on the free form shape face region in the video frame  the non-transitory machine readable medium of claim  wherein encoding the video frame based at least in part on the first candidate face region being a valid face region comprises at least one of reducing a quantization parameter corresponding to the first candidate face region adjusting a lambda value for the first candidate face region or disabling skip coding for the first candidate face region a method for managing a smart database which stores facial images for face recognition comprising steps of a a managing device performing a process of counting one or more specific facial images corresponding to at least one specific person stored in the smart database where new facial images for the face recognition are continuously stored and a process of determining whether a first counted value representing a count of the specific facial images satisfies a preset first set value and b if the first counted value is determined as satisfying the first set value the managing device performing a process of inputting the specific facial images into a neural aggregation network to thereby allow the neural aggregation network to generate each of quality scores of each of the specific facial images by aggregation of the specific facial images and a process of sorting the quality scores corresponding to the specific facial images in a descending order of the quality scores a process of counting the sorted specific facial images in the descending order until a second counted value which represents the number of a counted part of the specific facial images becomes equal to a preset second set value and a process of deleting an uncounted part of the specific facial images from the smart database  the method of claim  further comprising a step of c the managing device performing a process of generating at least one optimal feature by weighted summation of one or more features of the specific facial images using the counted part of the quality scores and a process of setting the optimal feature as a representative face corresponding to the specific person  the method of claim  wherein at the step of b the managing device performs a process of inputting the specific facial images into a cnn of the neural aggregation network to thereby allow the cnn to generate one or more features corresponding to each of the specific facial images and a process of inputting at least one feature vector where the features are embedded into an aggregation module including at least two attention blocks to thereby allow the aggregation module to generate each of the quality scores of each of the features  the method of claim  wherein at the step of b the managing device performs a process of matching i i- one or more features corresponding to each of the specific facial images stored in the smart database and i- the quality scores with ii the specific person and a process of storing the matched features and the matched quality scores in the smart database  the method of claim  further comprising a step of d the managing device performing one of i a process of learning a face recognition system by using the specific facial images corresponding to the specific person stored in the smart database and ii a process of transmitting the specific facial images corresponding to the specific person to a learning device corresponding to the face recognition system to thereby allow the learning device to learn the face recognition system using the specific facial images  the method of claim  wherein the neural aggregation network has been learned by a learning device repeating more than once i a process of inputting multiple facial images for training corresponding to an image set of a single face or a video of the single face into a cnn of the neural aggregation network to thereby allow the cnn to generate one or more features for training by applying at least one convolution operation to the facial images for training ii a process of inputting at least one feature vector for training where the features for training are embedded into an aggregation module including at least two attention blocks of the neural aggregation network to thereby allow the aggregation module to generate each of quality scores for training of each of the features for training by aggregation of the features for training using one or more attention parameters learned in a previous iteration iii a process of outputting at least one optimal feature for training by weighted summation of the features for training using the quality scores for training and iv a process of updating the attention parameters learned in the previous iteration of the at least two attention blocks such that one or more losses are minimized which are outputted from a loss layer by referring to the optimal feature for training and its corresponding ground truth  a managing device for managing a smart database which stores facial images for face recognition comprising at least one memory that stores instructions and at least one processor configured to execute the instructions to perform or support another device to perform i a process of counting one or more specific facial images corresponding to at least one specific person stored in the smart database where new facial images for the face recognition are continuously stored and a process of determining whether a first counted value representing a count of the specific facial images satisfies a preset first set value and ii if the first counted value is determined as satisfying the first set value a process of inputting the specific facial images into a neural aggregation network to thereby allow the neural aggregation network to generate each of quality scores of each of the specific facial images by aggregation of the specific facial images and a process of sorting the quality scores corresponding to the specific facial images in a descending order of the quality scores a process of counting the sorted specific facial images in the descending order until a second counted value which represents the number of a counted part of the specific facial images becomes equal to a preset second set value and a process of deleting an uncounted part of the specific facial images from the smart database  the managing device of claim  wherein the processor further performs iii a process of generating at least one optimal feature by weighted summation of one or more features of the specific facial images using the counted part of the quality scores and a process of setting the optimal feature as a representative face corresponding to the specific person  the managing device of claim  wherein at the process of ii the processor performs a process of inputting the specific facial images into a cnn of the neural aggregation network to thereby allow the cnn to generate one or more features corresponding to each of the specific facial images and a process of inputting at least one feature vector where the features are embedded into an aggregation module including at least two attention blocks to thereby allow the aggregation module to generate each of the quality scores of each of the features  the managing device of claim  wherein at the process of ii the processor performs a process of matching i i- one or more features corresponding to each of the specific facial images stored in the smart database and i- the quality scores with ii the specific person and a process of storing the matched features and the matched quality scores in the smart database  the managing device of claim  wherein the processor further performs iv one of i a process of learning a face recognition system by using the specific facial images corresponding to the specific person stored in the smart database and ii a process of transmitting the specific facial images corresponding to the specific person to a learning device corresponding to the face recognition system to thereby allow the learning device to learn the face recognition system using the specific facial images  the managing device of claim  wherein the neural aggregation network has been learned by a learning device repeating more than once i a process of inputting multiple facial images for training corresponding to an image set of a single face or a video of the single face into a cnn of the neural aggregation network to thereby allow the cnn to generate one or more features for training by applying at least one convolution operation to the facial images for training ii a process of inputting at least one feature vector for training where the features for training are embedded into an aggregation module including at least two attention blocks of the neural aggregation network to thereby allow the aggregation module to generate each of quality scores for training of each of the features for training by aggregation of the features for training using one or more attention parameters learned in a previous iteration iii a process of outputting at least one optimal feature for training by weighted summation of the features for training using the quality scores for training and iv a process of updating the attention parameters learned in the previous iteration of the at least two attention blocks such that one or more losses are minimized which are outputted from a loss layer by referring to the optimal feature for training and its corresponding ground truth an object data processing system comprising at least one processor configured to execute at least one implementation of a plurality of recognition algorithms stored on at least one non-transitory computer-readable storage medium each recognition algorithm having feature density selection criteria and data preprocessing code executed by at least one processor the data preprocessing code comprising an invariant feature identification algorithm and configured to obtain a digital representation of a scene the scene comprising one or more textual media generate a set of invariant features by applying the invariant feature identification algorithm to the digital representation cluster the set of invariant features into regions of interest in the digital representation of the scene each region of interest having a region feature density classify by region classifier code at least one of the regions of interest according to object type as a function of attributes derived from the region feature density and the digital representation wherein the at least one of the classified regions of interest corresponds to text and use a classification result corresponding to the at least one of the regions of interest to classify another of the regions of interest according to object type wherein the another of the regions of interest corresponds to a region of interest for images  the system of claim  wherein preprocessing code based on the feature density selection criteria determines that an ocr algorithm is applicable to the text and that other recognition algorithms are applicable to aspects of the photographs and to logos  the system of claim  wherein a user creates a user profile for a camera-equipped smartphone that includes the information that the user is visually impaired which causes prioritized execution of the ocr algorithm such that a text reader program begins reading the text to the user as quickly as possible  the system of claim  further comprising an audio or tactile feedback mechanism that helps the user to position the smart phone relative to the text  the system of claim  further comprising a \"hold still\" audio feedback signal that is sent to the user when the text is at the center of the captured scene  the system of claim  wherein the digital representation comprises at least one of the following types of digital data image data video data and audio data  the system of claim  wherein invariant feature identification algorithm comprises at least one of the following feature identification algorithms fast sift freak brisk harris daisy and mser  the system of claim  wherein the invariant feature identification algorithm includes at least one of the following edge detection algorithm corner detection algorithm saliency map algorithm curve detection algorithm a texton identification algorithm and wavelets algorithm  the system of claim  wherein at least one region of interest represents at least one physical object in the scene  the system of claim  wherein at least one region of interest represents at least one textual media in the scene  the system of claim  wherein the region of interest represents a document as the textual media  the system of claim  wherein the region of interest represents a financial document  the system of claim  wherein the region of interest represents a structured document  the system of claim  wherein at least one implementation of a plurality of recognition algorithms includes at least one of the following a template driven algorithm a face recognition algorithm an optical character recognition algorithm a speech recognition algorithm and an object recognition algorithm  the system of claim  wherein data preprocessing code is further configured to assign each region of interest at least one recognition algorithm as a function of a scene context derived from the digital representation  the system of claim  wherein the scene context includes at least one of the following types of data a location a position a time a user identity a news event a medical event and a promotion  the system of claim  further comprising a mobile device comprising at least one implementation of a plurality of recognition algorithms and data preprocessing code  the system of claim  wherein the mobile device comprises at least one of the following a smart phone a tablet wearable glass a toy a vehicle a computer and a phablet  the system of claim  further comprising a network-accessible server device comprising at least one implementation of a plurality of recognition algorithms and data preprocessing code  the system of claim  wherein the object type includes at least one of the following a face an animal a vehicle a document a plant a building an appliance clothing a body part and a toy  an object data processing system comprising at least one processor configured to execute at least one implementation of a plurality of recognition algorithms stored on at least one non-transitory computer-readable storage medium each recognition algorithm having feature density selection criteria and data preprocessing code executed by at least one processor the data preprocessing code comprising an invariant feature identification algorithm and configured to obtain a digital representation of a scene the scene comprising one or more textual media generate a set of invariant features by applying the invariant feature identification algorithm to the digital representation cluster the set of invariant features into regions of interest in the digital representation of the scene each region of interest having a region feature density classify by region classifier code at least one of the regions of interest according to object type as a function of attributes derived from the region feature density and the digital representation wherein the at least one of the classified regions of interest corresponds to text and use a classification result corresponding to the at least one of the regions of interest to classify another of the regions of interest according to object type wherein the another of the regions of interest corresponds to a region of interest for images assign each region of interest at least one recognition algorithm from at least one implementation of a plurality of diverse recognition algorithms as a function of the region feature density of each region of interest and the feature density selection criteria of the at least one implementation of a plurality of diverse recognition algorithms and configure the assigned recognition algorithms to process their respective regions of interest wherein preprocessing code based on the feature density selection criteria determines that an ocr algorithm is applicable to the text and that other recognition algorithms are applicable to aspects of the photographs and to logos  a device comprising at least one processor configured to execute at least one implementation of a plurality of recognition algorithms stored on at least one non-transitory computer-readable storage medium each recognition algorithm having feature density selection criteria and data preprocessing code executed by at least one processor the data preprocessing code comprising an invariant feature identification algorithm and configured to obtain a digital representation of a scene the scene comprising one or more textual media generate a set of invariant features by applying the invariant feature identification algorithm to the digital representation cluster the set of invariant features into regions of interest in the digital representation of the scene each region of interest having a region feature density and classify by region classifier code at least one of the regions of interest according to object type as a function of attributes derived from the region feature density and the digital representation wherein the at least one of the classified regions of interest corresponds to text and use a classification result corresponding to the at least one of the regions of interest to classify another of the regions of interest according to object type wherein the another of the regions of interest corresponds to a region of interest for images a mobile terminal comprising a front camera configured to obtain a two-dimensional d face image of a user a glance sensor tilted by a certain angle and disposed adjacent to the front camera to obtain metadata of the d face image and a controller obtaining a distance between the glance sensor and the front camera the distance enabling an area of an overlap region where a first region representing a range photographable by the front camera overlaps a second region representing a range photographable by the glance sensor to be the maximum  the mobile terminal of claim  wherein the controller is configured to obtain the distance enabling the area of the overlap region to be the maximum between the glance sensor and the front camera by varying a tilting angle of the glance sensor  the mobile terminal of claim  wherein the controller is configured to set the distance enabling the area of the overlap region to be the maximum between the glance sensor and the front camera and the tilting angle of the glance sensor as an optimal disposition location of the glance sensor  the mobile terminal of claim  wherein the controller is configured to set a disposition location of the front camera as an original point and calculates coordinates of a first triangle representing the first region based on a field of view of the front camera and a maximum photographing distance of the front camera  the mobile terminal of claim  wherein the controller is configured to calculate coordinates of a second triangle representing the second region based on a field of view of the glance sensor a maximum photographing distance of the glance sensor a distance between the front camera and the glance sensor and a tilting angle of the glance sensor  the mobile terminal of claim  wherein before the glance sensor is tilted the controller is configured to calculate coordinates of a third triangle representing a third region photographable by the glance sensor and the controller is configured to rotation-convert the coordinates of the third triangle based on the tilting angle of the glance sensor and calculate the coordinates of the second triangle  the mobile terminal of claim  wherein the controller is configured to calculate coordinates of the overlap region based on the coordinates of the first triangle and the coordinates of the second triangle and calculates the area of the overlap region based on the coordinates of the overlap region  the mobile terminal of claim  wherein the controller is configured to generate three-dimensional d face information based on the d face image obtained by the front camera and metadata obtained by the glance sensor  the mobile terminal of claim  wherein the metadata comprises one or more of an angle of a face of the user a size of the face and a location of the face  the mobile terminal of claim  wherein the angle of the face comprises an angle by which the face is rotated about one or more of a pitch axis a roll axis and a yaw axis  the mobile terminal of claim  further comprising a memory storing the generated d face information wherein the controller is configured to performs a user authentication process by comparing the stored d face information with d face information obtained for user authentication  the mobile terminal of claim  wherein the glance sensor is controlled to be permanently activated with a low power to obtain a front image and metadata of the front image  the mobile terminal of claim  wherein the front camera and the glance sensor are disposed on the same line in an upper end of the mobile terminal  the mobile terminal of claim  wherein the glance sensor is tilted in one direction of an up direction a down direction a left direction and a right direction  the mobile terminal of claim  wherein the metadata is data which is changed when the mobile terminal is tilted by an external physical force a method comprising receiving by a smart television tv an indication of upcoming media programming wherein the upcoming media programming is based on a user profile identifying one or more devices in communication with the smart tv each of the one or more devices including at least one of a microphone or a camera instructing at least one identified device to detect audio signals using its respective microphone or to detect visual signals using its respective camera selecting at least one device of the one or more devices based on the detected audio signal or detected visual signal and providing instructions to the selected device to output a notification related to the upcoming media programming  the method of claim  wherein the upcoming media programming is one of a live television program a recorded television program a broadcast television program or an application-provided program  the method of claim  wherein selecting the first device based on the detected audio signal includes recognizing a voice  the method of claim  further comprising determining a distance to the recognized voice and wherein selecting the first device is further based on the determined distance  the method of claim  wherein selecting the first device based on the detected visual signals includes recognizing a face  the method of claim  wherein recognizing the face includes a face recognition technique  the method of claim  further comprising presenting on the smart tv the upcoming media programming in a favorite channel list  the method of claim  further comprising obtaining media programming viewing data wherein the media programming viewing data includes at least one of a historical time and a historical date that one or more media programs were viewed obtaining at least one of a current time and a current date processing the media programming viewing data to determine a probability of the one or more media programs being viewed based on at least one of the current time and the current date and presenting the favorite channel list based on the determined probability of the one or more media programs being viewed  the method of claim  wherein processing the media programming viewing data includes employing a neural network model  the method of claim  wherein employing the neural network model comprises determining a duration that the one or more media programs were viewed for each of the at least one of the historical time and the historical date setting a threshold time duration comparing the determined duration to the threshold time duration and filtering out the one or more media programs viewed below the threshold time duration  a smart television tv comprising a network interface a non-transitory computer-readable medium and a processor in communication with the network interface and the non-transitory computer-readable medium and capable of executing processor-executable program code stored in the non-transitory computer-readable medium to cause the smart tv to receive an indication of upcoming media programming wherein the upcoming media programming is based on a user profile identify one or more devices in communication with the smart tv each of the one or more devices including at least one of a microphone or a camera instruct at least one identified device to detect audio signals using its respective microphone or to detect visual signals using its respective camera select at least one device of the one or more devices based on the detected audio signal or detected visual signal and provide instructions to the selected device to output a notification related to the upcoming media programming  the smart tv of claim  wherein selecting the first device based on the detected audio signal includes recognizing a voice  the smart tv of claim  wherein the processor is further capable of executing processor-executable program code to determine a distance to the recognized voice and wherein selecting the first device is further based on the determined distance  the smart tv of claim  wherein selecting the first device based on the detected visual signals includes detecting the presence of a user  the smart tv of claim  wherein detecting the presence of the user includes employing one or more of a camera a microphone or a fingerprint sensor associated with at least one of the smart tv a mobile device a smartphone a laptop computer a tablet device a wearable device an internet of things iot device an internet of everything ioe device an iot hub or an ioe hub  a smart television tv comprising means for receiving an indication of upcoming media programming wherein the upcoming media programming is based on a user profile means for identifying one or more devices in communication with the smart tv each of the one or more devices including at least one of a microphone or a camera means for instructing at least one identified device to detect audio signals using its respective microphone or to detect visual signals using its respective camera means for selecting at least one device of the one or more devices based on the detected audio signal or detected visual signal and means for providing instructions to the selected device to output a notification related to the upcoming media programming  the smart tv of claim  wherein the one or more devices includes at least one of a mobile device a smartphone a laptop computer a tablet device a wearable device an internet of things iot device an internet of everything ioe device an iot hub an ioe hub or another smart tv  the smart tv of claim  wherein the upcoming media programming is one of a live television program a recorded television program a broadcast television program or an application-provided program  the smart tv of claim  wherein the notification includes at least one of a push message a sms message a waysms message an audio alert an audio message or an email message  the smart tv of claim  further comprising presenting the upcoming media programming in a favorite channel list  the smart tv of claim  further comprising means for obtaining media programming viewing data wherein the media programming viewing data includes at least one of a historical time and a historical date that one or more media programs were viewed on the smart tv means for obtaining at least one of a current time and a current date means for processing the media programming viewing data to determine a probability of the one or more media programs being viewed on the smart tv based on at least one of the current time and the current date and means for presenting the favorite channel list based on the determined probability of the one or more media programs being viewed  the smart tv of claim  wherein the means for processing the media programming viewing data includes employing a neural network model  the smart tv of claim  wherein employing the neural network model comprises determining a duration that the one or more media programs were viewed on the smart tv for each of the at least one of the historical time and the historical date setting a threshold time duration comparing the determined duration to the threshold time duration and filtering out the one or more media programs viewed below the threshold time duration  the smart tv of claim  further comprising means for adjusting at least one of a volume or a brightness of the smart tv wherein the adjusting is based on at least one of the historical time and the historical date  the smart tv of claim  further comprising means for restricting access to one or more media programs  a non-transitory computer-readable medium comprising processor-executable program code configured to cause a processor of a smart television tv to receive an indication of upcoming media programming wherein the upcoming media programming is based on a user profile identify one or more devices in communication with the smart tv each of the one or more devices including at least one of a microphone or a camera instruct at least one identified device to detect audio signals using its respective microphone or to detect visual signals using its respective camera select at least one device of the one or more devices based on the detected audio signal or detected visual signal and provide instructions to the selected device to output a notification related to the upcoming media programming  the non-transitory computer-readable medium of claim  wherein selecting the first device based on the detected audio signal includes recognizing a voice  the non-transitory computer-readable medium of claim  wherein the processor is further capable of executing processor-executable program code to determine a distance to the recognized voice and wherein selecting the first device is further based on the determined distance  the non-transitory computer-readable medium of claim  wherein selecting the first device based on the detected visual signals includes recognizing a face  the non-transitory computer-readable medium of claim  wherein recognizing the face includes a face recognition technique a camera comprising a sensor array including a plurality of sensors an infrared ir illuminator configured to emit active ir light in an ir light sub-band a plurality of spectral illuminators each spectral illuminator configured to emit active spectral light in a different spectral light sub-band a depth controller machine configured to determine a depth value for each of the plurality of sensors based on the active ir light a spectral controller machine configured to for each of the plurality of sensors determine a spectral value for each spectral light sub-band of the plurality of spectral illuminators and an output machine configured to output a test depth+multi-spectral image including a plurality of pixels each pixel corresponding to one of the plurality of sensors of the sensor array and including at least a depth value and a spectral value for each spectral light sub-band of the plurality of spectral illuminators a face recognition machine previously trained with a set of labeled training depth+multi-spectral images having a same structure as the test depth+multi-spectral image the face recognition machine configured to output a confidence value indicating a likelihood that the test depth+multi-spectral image includes a face  the camera of claim  wherein each spectral value is calculated based on the depth value determined for the sensor that corresponds to the pixel  the camera of claim  wherein the face recognition machine is configured to use a convolutional neural network to determine the confidence value  the camera of claim  wherein the face recognition machine includes a plurality of input nodes wherein each input node is configured to receive a pixel value array corresponding to a different pixel of the plurality of pixels of the test depth+multi-spectral image and wherein the pixel value array includes the depth value and the plurality of multi-spectral values for the pixel  the camera of claim  wherein the plurality of multi-spectral values for the pixel include more than three spectral values  the camera of claim  wherein the output machine is configured to output a surface normal for each pixel of the test depth+multi-spectral image and wherein the pixel value array includes the surface normal  the camera of claim  wherein the output machine is configured to output a curvature for each pixel of the test depth+multi-spectral image and wherein the pixel value array includes the curvature  the camera of claim  wherein the face recognition machine is configured to use a plurality of models to determine the confidence value wherein the plurality of models includes a plurality of channel-specific models wherein each channel-specific model is configured to process a different pixel parameter for the plurality of pixels of the test depth+multi-spectral image wherein each channel-specific model includes a plurality of input nodes and wherein for each channel-specific model each input node is configured to receive a pixel parameter value for a different pixel of the plurality of pixels of the test depth+multi-spectral image  the camera of claim  wherein the face recognition machine is configured to use a statistical model to determine the confidence value  the camera of claim  wherein the statistical model includes a nearest neighbor algorithm  the camera of claim  wherein the statistical model includes a support vector machine  the camera of claim  wherein the face recognition machine is further configured to output a location on the test depth+multi-spectral image of a bounding box around a recognized face  the camera of claim  wherein the face recognition machine is further configured to output a location on the test depth+multi-spectral image of an identified two-dimensional d facial feature of a recognized face  the camera of claim  wherein the face recognition machine is further configured to output a location on the test depth+multi-spectral image of an identified three-dimensional d facial feature of a recognized face  the camera of claim  wherein the face recognition machine is further configured to output a location on the test depth+multi-spectral image of an identified spectral feature on a recognized face  the camera of claim  wherein the face recognition machine is further configured to output for each pixel of the test depth+multi-spectral image a confidence value indicating a likelihood that the pixel is included in a face  the camera of claim  wherein the face recognition machine is further configured to output an identity of a face recognized in the test depth+multi-spectral image  the camera of claim  wherein the plurality of sensors of the sensor array are differential sensors and wherein each spectral value is determined based on a depth value and a differential measurement for that differential sensor  a camera comprising a sensor array including a plurality of sensors an infrared ir illuminator configured to emit active ir light in an ir light sub-band a plurality of spectral illuminators each spectral illuminator configured to emit active spectral light in a different spectral light sub-band a depth controller machine configured to determine a depth value for each of the plurality of sensors based on the active ir light a spectral controller machine configured to for each of the plurality of sensors determine a spectral value for each spectral light sub-band of the plurality of spectral illuminators wherein each spectral value is calculated based on the depth value determined for the sensor that corresponds to the pixel and an output machine configured to output a test depth+multi-spectral image including a plurality of pixels each pixel corresponding to one of the plurality of sensors of the sensor array and including at least a depth value and a spectral value for each spectral light sub-band of the plurality of spectral illuminators and a face recognition machine including a convolutional neural network previously trained with a set of labeled training depth+multi-spectral images having a same structure as the test depth+multi-spectral image the face recognition machine configured to output a confidence value indicating a likelihood that the test depth+multi-spectral image includes a face an image processing method comprising acquiring a photo album obtained from face clustering collecting face information of respective images in the photo album and acquiring a face parameter of each image according to the face information selecting a cover image according to the face parameter of each image and taking a face-region image from the cover image and setting the face-region image as a cover of the photo album wherein selecting the cover image according to the face parameter of each image comprises performing calculation on the face parameter of each image in a preset way to obtain a cover score of each image selecting the image with a highest cover score as the cover image wherein selecting the image with the highest cover score as the cover image comprises acquiring a source of each image and selecting the image with the highest cover score in images coming from a preset source as the cover image  the method according to claim  wherein selecting the image with the highest cover score as the cover image comprises acquiring the number of faces contained in each image determining single-person images according to the number of faces and selecting the single-person image with the highest cover score as the cover image  the method according to claim  wherein selecting the image with the highest cover score as the cover image further comprises when there is no single-person image in the photo album determining images including two faces from the photo album and selecting the image with the highest cover score from the images including two faces as the cover image  the method according to claim  wherein the face information comprises face feature points and the face parameter comprises a face turning angle acquiring the face parameter of each image according to the face information comprises acquiring coordinate values of the face feature points determining distances and angles between the face feature points and determining the face turning angle according to the distances and the angles  the method according to claim  wherein the face parameter comprises a face ratio acquiring the face parameter of each image according to the face information comprises determining a face region of the image according to the face information and calculating a ratio of an area of the face region to an area of the image to obtain the face ratio  the method according to claim  wherein calculating the face ratio comprises when there is more than one face in the image subtracting an area occupied faces other than a face corresponding to the photo album from the face region to obtain a remaining area and calculating a ratio of the remaining area to the area of the image to obtain the face ratio  the method according to claim  wherein collecting face information of respective images in the photo album comprises acquiring image identifications of images in the photo album extracting face information corresponding to the image identifications from a face database the face database being stored with face recognition results of images the face recognition results including the face information  an image processing apparatus comprising a processor and a memory configured to store instructions executable by the processor wherein the processor is configured to run a program corresponding to the instructions by reading the instructions stored in the memory so as to perform acquiring a photo album obtained from face clustering collecting face information of each image in the photo album acquiring a face parameter of each image according to the face information selecting a cover image according to the face parameter of each image taking a face-region image from the cover image and setting the face-region image as a cover of the photo album wherein the processor is configured to perform calculation on the face parameter of each image in a preset way to obtain a cover score of each image and select the image with a highest cover score as the cover image and wherein the processor is configured to acquire a source of each image and select the image with the highest cover score in images coming from a preset source as the cover image  the apparatus according to claim  wherein the processor is configured to acquire the number of faces contained in each image determine single-person images according to the number of faces and select the single-person image with the highest cover score as the cover image  the apparatus according to claim  wherein the processor is further configured to when there is no single-person image in the photo album determine images including two faces from the photo album and select the image with the highest cover score from the images including two faces as the cover image  the apparatus according to claim  wherein the face information comprises face feature points and the face parameter comprises a face turning angle the processor is configured to acquire coordinate values of the face feature points determine distances and angles between the face feature points and determine the face turning angle according to the distances and the angles  the apparatus according to claim  wherein the face parameter comprises a face ratio the processor is configured to determine a face region of the image according to the face information and calculate a ratio of an area of the face region to an area of the image to obtain the face ratio  the apparatus according to claim  wherein the processor is configured to when there is more than one face in the image subtract an area occupied faces other than a face corresponding to the photo album from the face region to obtain a remaining area and calculate a ratio of the remaining area to the area of the image to obtain the face ratio  the apparatus according to claim  wherein the processor is configured to acquire image identifications of images in the photo album extract face information corresponding to the image identifications from a face database the face database being stored with face recognition results of images the face recognition results including the face information  an electronic device comprising a processor a memory a display screen and an input device connected via a system bus wherein the memory is stored with computer programs that when executed by the processor cause the processor to implement an image processing method the image processing method comprising acquiring a photo album obtained from face clustering collecting face information of respective images in the photo album and acquiring a face parameter of each image according to the face information selecting a cover image according to the face parameter of each image and taking a face-region image from the cover image and setting the face-region image as a cover of the photo album wherein selecting the cover image according to the face parameter of each image comprises performing calculation on the face parameter of each image in a preset way to obtain a cover score of each image and selecting the image with a highest cover score as the cover image and wherein selecting the image with the highest cover score as the cover image comprises acquiring a source of each image and selecting the image with the highest cover score in images coming from a preset source as the cover image  the electronic device according to claim  wherein the electronic device comprises at least one of a mobile phone a tablet computer a personal digital assistant and a wearable device a computer-implemented method comprising receiving at a computing device a meeting invitation identifying a location and at least one invitee the meeting invitation configured to provide the at least one invitee with physical access to the location wherein the meeting invitation causes a system to control a pathway allowing physical access to the location providing based on the meeting invitation the at least one invitee with physical access to the location by controlling the pathway allowing the at least one invitee to physically access the location through the pathway in response to positioning data indicating that the at least one invitee is at a predetermined location near the location wherein the positioning data is based in part on a face recognition camera system identifying the at least one invitee receiving the positioning data from the face recognition camera system identifying the at least one invitee wherein the positioning data indicates a pattern of movement of the at least one invitee determining that the pattern of movement indicates that the at least one invitee has exited the location and revoking physical access to the location identified in the meeting invitation by controlling the pathway to restrict the at least one invitee identified in the meeting invitation from physical access to the location through the pathway in response to determining that the pattern of movement indicates that the at least one invitee has exited the location  the computer-implemented method of claim  wherein determining that the at least one invitee has exited the location comprises determining that the at least one invitee has passed through an egress associated with the location in a predetermined direction  the computer-implemented method of claim  wherein determining that the at least one invitee has exited the location comprises determining that the at least one invitee has moved through an area in a predetermined direction  the computer-implemented method of claim  wherein the positioning data indicates a second pattern of movement of the at least one invitee and wherein access to secured data associated with the location is provided in response to detecting the second pattern of movement  the computer-implemented method of claim  further comprising collating secured data and public data to generate resource data and communicating the resource data to a client computing device associated with the at least one invitee when access of the location is provided  the computer-implemented method of claim  wherein the positioning data indicates that the at least one invitee is at the predetermined location when the at least one invitee passes through the predetermined location  the computer-implemented method of claim  wherein the positioning data indicates that the at least one invitee is at the predetermined location when the at least one invitee passes through the predetermined location near the location in a predetermined direction  a system comprising a processor and a memory in communication with the processor the memory having computer-readable instructions stored thereupon that when executed by the processor cause the processor to receive a meeting invitation indicating a location and an identity the meeting invitation configured to provide at least one invitee with physical access to the location wherein the meeting invitation causes the system to control a pathway allowing physical access to the location provide the at least one invitee associated with the identity access to the location by controlling the pathway allowing the at least one invitee to physically access the location through the pathway in response to positioning data indicating that the at least one invitee is at a predetermined location near the location wherein the positioning data is based in part on a face recognition camera system identifying the at least one invitee receive the positioning data from the face recognition camera system identifying the at least one invitee wherein the positioning data indicates a pattern of movement of the at least one invitee determine that the pattern of movement indicates that the at least one invitee has exited the location and revoke physical access to the location identified in the meeting invitation by controlling the pathway to restrict the at least one invitee identified in the meeting invitation from physical access to the location through the pathway in response to determining that the pattern of movement indicates that the at least one invitee has exited the location  the system of claim  wherein determining that the at least one invitee has exited the location comprises determining that the at least one invitee has passed through an egress associated with the location  the system of claim  wherein determining that the at least one invitee has exited the location comprises determining that the at least one invitee has moved through an area in a predetermined direction  the system of claim  wherein the positioning data indicates a second pattern of movement of the at least one invitee and wherein access to secured data associated with the location is provided in response to detecting the second pattern of movement  the system of claim  wherein the instructions further cause the processor to collate secured data and public data to generate resource data and communicate the resource data to a client computing device associated with the at least one invitee when access of the location is provided  a non-transitory computer-readable storage medium having computer-executable instructions stored thereupon which when executed by one or more processors of a computing device cause the one or more processors of the computing device to receive a meeting invitation indicating a location and an identity the meeting invitation configured to provide at least one invitee with physical access to the location wherein the meeting invitation causes a system to control a pathway allowing physical access to the location provide the at least one invitee associated with the identity access to the location by controlling the pathway allowing the at least one invitee to physically access the location through the pathway in response to positioning data indicating that the at least one invitee is at a predetermined location near the location wherein the positioning data is based in part on a face recognition camera system identifying the at least one invitee receive the positioning data from the face recognition camera system identifying the at least one invitee wherein the positioning data indicates a pattern of movement of the at least one invitee determine that the pattern of movement indicates that the at least one invitee has exited the location and revoke physical access to the location identified in the meeting invitation by controlling the pathway to restrict the at least one invitee identified in the meeting invitation from physical access to the location through the pathway in response to determining that the pattern of movement indicates that the at least one invitee has exited the location  the non-transitory computer-readable storage medium of claim  wherein determining that the at least one invitee has exited the location comprises determining that the at least one invitee has passed through an egress associated with the location  the non-transitory computer-readable storage medium of claim  wherein the positioning data indicates a second pattern of movement of the at least one invitee and wherein access to secured data associated with the location is provided in response to detecting the second pattern of movement  the non-transitory computer-readable storage medium of claim  wherein the instructions further cause the one or more processors to collate secured data and public data to generate resource data and communicate the resource data to a client computing device associated with the at least one invitee when access of the location is provided a method comprising receiving a piece of content and salient data for the piece of content based on the salient data determining a first path for a viewport for the piece of content wherein the first path for the viewport includes different salient events occurring in the piece of content at different times during playback of the piece of content providing the viewport on a display device wherein movement of the viewport is based on the first path for the viewport and the salient data during the playback detecting an additional salient event in the piece of content that is not included in the first path for the viewport and providing an indication for the additional salient event in the viewport during the playback  the method of claim  wherein the salient data identifies each salient event in the piece of content and the salient data indicates for each salient event in the piece of content a corresponding point location of the salient event in the piece of content and a corresponding time at which the salient event occurs during the playback  the method of claim  wherein the salient data further indicates for each salient event in the piece of content a corresponding type of the salient event and a corresponding strength value of the salient event  the method of claim  wherein the first path for the viewport controls the movement of the viewport to put the different salient events in a view of the viewport at the different times during the playback  the method of claim  further comprising detecting one or more salient events in the piece of content based on at least one of the following visual data of the piece of content audio data of the piece of content or content consumption experience data for the piece of content wherein the salient data is indicative of each salient event detected  the method of claim  further comprising detecting one or more salient events in the piece of content based on at least one of the following face recognition facial emotion recognition object recognition motion recognition or metadata of the piece of content wherein the salient data is indicative of each salient event detected  the method of claim  further comprising detecting user interaction with the indication wherein the indication comprises an interactive hint and in response to detecting the user interaction adapting the first path for the viewport to a second path for the viewport based on the user interaction wherein the second path for the viewport includes the additional salient event and providing an updated viewport for the piece of content on the display device wherein movement of the updated viewport is based on the second path for the viewport and the salient data during the playback and the second path for the viewport controls the movement of the updated viewport to put the additional salient event in a view of the updated viewport  the method of claim  further comprising changing a weight assigned to the additional salient event and one or more other salient events in the piece of content having the same type as the additional salient event  the method of claim  wherein the second path for the viewport includes one or more other salient events in the piece of content having the same type as the additional salient event  a system comprising at least one processor and a non-transitory processor-readable memory device storing instructions that when executed by the at least one processor causes the at least one processor to perform operations including receiving a piece of content and salient data for the piece of content based on the salient data determining a first path for a viewport for the piece of content wherein the first path for the viewport includes different salient events occurring in the piece of content at different times during playback of the piece of content providing the viewport on a display device wherein movement of the viewport is based on the first path for the viewport and the salient data during the playback detecting an additional salient event in the piece of content that is not included in the first path for the viewport and providing an indication for the additional salient event in the viewport during the playback  the system of claim  wherein the salient data identifies each salient event in the piece of content and the salient data indicates for each salient event in the piece of content a corresponding point location of the salient event in the piece of content and a corresponding time at which the salient event occurs during the playback  the system of claim  wherein the salient data further indicates for each salient event in the piece of content a corresponding type of the salient event and a corresponding strength value of the salient event  the system of claim  wherein the salient data is generated offline on a server  the system of claim  the operations further comprising detecting one or more salient events in the piece of content based on at least one of the following visual data of the piece of content audio data of the piece of content or content consumption experience data for the piece of content wherein the salient data is indicative of each salient event detected  the system of claim  the operations further comprising detecting one or more salient events in the piece of content based on at least one of the following face recognition facial emotion recognition object recognition motion recognition or metadata of the piece of content wherein the salient data is indicative of each salient event detected  the system of claim  the operations further comprising detecting user interaction with the indication wherein the indication comprises an interactive hint and in response to detecting the user interaction adapting the first path for the viewport to a second path for the viewport based on the user interaction wherein the second path for the viewport includes the additional salient event and providing an updated viewport for the piece of content on the display device wherein movement of the updated viewport is based on the second path for the viewport and the salient data during the playback and the second path for the viewport controls the movement of the updated viewport to put the additional salient event in a view of the updated viewport  the system of claim  the operations further comprising changing a weight assigned to the additional salient event and one or more other salient events in the piece of content having the same type as the additional salient event  the system of claim  wherein the second path for the viewport includes one or more other salient events in the piece of content having the same type as the additional salient event  a non-transitory computer readable storage medium including instructions to perform a method comprising receiving a piece of content and salient data for the piece of content based on the salient data determining a first path for a viewport for the piece of content wherein the first path for the viewport includes different salient events occurring in the piece of content at different times during playback of the piece of content providing the viewport on a display device wherein movement of the viewport is based on the first path for the viewport and the salient data during the playback detecting an additional salient event in the piece of content that is not included in the first path for the viewport and providing an indication for the additional salient event in the viewport during the playback  the computer readable storage medium of claim  the method further comprising detecting user interaction with the indication wherein the indication comprises an interactive hint and in response to detecting the user interaction adapting the first path for the viewport to a second path for the viewport based on the user interaction wherein the second path for the viewport includes the additional salient event and providing an updated viewport for the piece of content on the display device wherein movement of the updated viewport is based on the second path for the viewport and the salient data during the playback and the second path for the viewport controls the movement of the updated viewport to put the additional salient event in a view of the updated viewport a mobile device with facial recognition the mobile device comprising one or more cameras a processor device and memory coupled to the processor device the processing system programmed to receive a plurality of images from the one or more cameras extract with a feature extractor utilizing a convolutional neural network cnn with an enlarged intra-class variance of long-tail classes feature vectors from each of the plurality of images generate with a feature generator discriminative feature vectors for each of the feature vectors classify with a fully connected classifier an identity from the discriminative feature vectors and control an operation of the mobile device to react in accordance with the identity  the mobile device as recited in claim  further includes a communication system  the mobile device as recited in claim  wherein the operation tags the video with the identity and uploads the video to social media  the mobile device as recited in claim  wherein the operation tags the video with the identity and sends the video to a user  the mobile device as recited in claim  wherein the mobile device is a smart phone  the mobile device as recited in claim  wherein the mobile device is a body cam  the mobile device as recited in claim  further programmed to train the feature extractor the feature generator and the fully connected classifier with an alternative bi-stage strategy  the mobile device as recited in claim  wherein the feature extractor shares covariance matrices across all classes to transfer intra-class variance from regular classes to the long-tail classes  the mobile device as recited in claim  wherein the feature generator optimizes a softmax loss by joint regularization of weights and features through a magnitude of an inner product of the weights and features  the mobile device as recited in claim  wherein the feature extractor averages the feature vector with a flipped feature vector the flipped feature vector being generated from a horizontally flipped frame from one of the plurality of images  the mobile device as recited in claim  wherein each of the plurality of images is selected from the group consisting of an image a video and a frame from the video  the mobile device as recited in claim  wherein the communication system connects to a remote server that includes a facial recognition network  the mobile device as recited in claim  wherein one stage of the alternative bi-stage strategy fixes the feature extractor and applies the feature generator to generate new transferred features that are more diverse and violate a decision boundary  the mobile device as recited in claim  wherein one stage of the alternative bi-stage strategy fixes the fully connected classifier and updates the feature extractor and the feature generator  a computer program product for a mobile device with facial recognition the computer program product comprising a non-transitory computer readable storage medium having program instructions embodied therewith the program instructions executable by a computer to cause the computer to perform a method comprising receiving by a processor device a plurality of images extracting by the processor device with a feature extractor utilizing a convolutional neural network cnn with an enlarged intra-class variance of long-tail classes feature vectors for each of the plurality of images generating by the processor device with a feature generator discriminative feature vectors for each of the feature vectors classifying by the processor device utilizing a fully connected classifier an identity from the discriminative feature vector and controlling an operation of the mobile device to react in accordance with the identity  a computer-implemented method for facial recognition in a mobile device the method comprising receiving by a processor device a plurality of images extracting by the processor device with a feature extractor utilizing a convolutional neural network cnn with an enlarged intra-class variance of long-tail classes feature vectors for each of the plurality of images generating by the processor device with a feature generator discriminative feature vectors for each of the feature vectors classifying by the processor device utilizing a fully connected classifier an identity from the discriminative feature vector and controlling an operation of the mobile device to react in accordance with the identity  the computer-implemented method as recited in claim  wherein controlling includes tagging the video with the identity and uploading the video to social media  the computer-implemented method as recited in claim  wherein controlling includes tagging the video with the identity and sending the video to a user  the computer-implemented method as recited in claim  wherein extracting includes sharing covariance matrices across all classes to transfer intra-class variance from regular classes to the long-tail classes a computing device comprising a non-transitory machine readable medium storing a machine trained mt network comprising a plurality of layers of processing nodes each processing node configured to compute a first output value by combining a set of output values from a set of processing nodes and use a piecewise linear cup function to compute a second output value from the first output value of the processing node wherein the piecewise linear cup function prior to training of the mt network comprises at least i a first linear section with a first slope followed by ii a second linear section with a negative second slope followed by iii a third linear section with a negative third slope that is different from the second slope followed by iv a fourth linear section with a positive fourth slope followed by v a fifth linear section with a positive fifth slope that is different from the fourth slope followed by vi a sixth linear section with a sixth slope wherein the piecewise linear cup function is symmetric about a vertical axis between the third and fourth linear sections prior to training of the mt network a content capturing circuit for capturing content for processing by the mt network and a set of processing units for executing the processing nodes to process content captured by the content capturing circuit wherein by training a set of parameters that define the piecewise linear cup function of each node in first and second pluralities of processing nodes i each processing node in the first plurality of processing nodes is configured to emulate a boolean and operator such that an output value of the processing node is in a range associated with a \"\" value only when a set of inputs to the processing node have a set of values in a range associated with \"\" and ii each processing node in the second plurality of processing nodes is configured to emulate a boolean xnor operator such that an output value of the processing node is in the range associated with \"\" only when a a set of inputs to the node have a set of values in a range associated with \"\" or b the set of inputs to the node have a set of values in a range associated with a \"\" value  the computing device of claim  wherein the third linear section of the piecewise linear cup function of a first processing node in the mt network has a different slope from the third linear section of a second processing node in the mt network  the computing device of claim  wherein the length of the third section of a piecewise linear cup function of a first processing node in the mt network is different from the length of the third section of a piecewise linear cup function of a second processing node in the mt network  the computing device of claim  wherein the sets of parameters are trained in part by a back propagating module for back propagating errors in output values of later layers of processing nodes to earlier layers of processing nodes by adjusting the set of parameters that define the piecewise linear cup functions of the earlier layers of processing nodes  the computing device of claim  wherein each processing node uses a linear function that is defined by a set of parameters to compute the first output value of the processing node wherein the back propagating module back propagates errors in output values of later layers of processing nodes to earlier layers of processing nodes by adjusting the set of parameters that define the linear functions of the earlier layers of processing nodes  the computing device of claim  wherein the first plurality of processing nodes that emulate the boolean and operator and the second plurality of processing nodes that emulate the boolean xnor operator enable the mt network to implement mathematical problems  the computing device of claim  wherein each of a plurality of processing node layers has a plurality of processing nodes that receive as input values the output values from a plurality of processing nodes in a set of prior layers  the computing device of claim  wherein each processing node uses a linear function to compute the first output value of the processing node wherein each processing node\\'s piecewise linear cup function is defined along first and second axes the first axis defining a range of output values from the processing node\\'s linear function and the second axis defining a range of output values produced by the piecewise linear cup function for the range of output values from the processing node\\'s linear function  the computing device of claim  further comprising a content output circuit for presenting an output based on the processing of the content by the mt network  the computing device of claim  wherein the captured content is one of an image and an audio segment and wherein the presented output is an output display on a display screen of the computing device or an audio presentation output on a speaker of the computing device  the computing device of claim  wherein the computing device is a mobile device  the computing device of claim  wherein the mt network is a mt neural network and the processing nodes are mt neurons  the computing device of claim  wherein the set of parameters configured through training for a plurality of the processing nodes comprise at least one of the negative second and third slopes for the second and third linear sections the positive fourth and fifth slopes for the fourth and fifth linear sections a first intercept for the second linear section a second intercept for the fifth linear section and a set of lengths for at least the second third fourth and fifth sections  the computing device of claim  wherein the trained set of parameters that define the piecewise linear cup function of each node comprise a plurality of output values  the computing device of claim  wherein the first and sixth slopes are zerowe claim  a system comprising a memory device to store an input image a processor including an image input interface to receive the input image a pre-processor to model the input image to yield a multi-channel image a feature extractor to extract a set of features based on the multi-channel image a feature selector to select one or more features from the set of features of the multi-channel image wherein the one or more features are selected based on an ability to differentiate features a feature matcher to match the one or more features to a learned feature set and a similarity detector to determine whether the one or more features meet a pre-defined similarity threshold  the system of claim  wherein the pre-processor further is to activate one or more channels of the multi-channel image to yield one or more activated channels  the system of claim  wherein the one or more activated channels are to be determined based on their ability to differentiate features  the system of claim  wherein the pre-processor further is to activate one or more local patches of the one or more activated channels  the system of claim  wherein the one or more local patches are to be determined based on their ability to differentiate features  the system of claim  wherein the feature matcher further is to utilize a large-scale data learning process to perform the feature matching  an apparatus comprising an image input interface to receive an input image a pre-processor to model the input image to yield a multi-channel image a feature extractor to extract a set of features based on the multi-channel image a feature selector to select one or more features from the set of features of the multi-channel image wherein the one or more features are selected based on an ability to differentiate features a feature matcher to match the one or more features to a learned feature set and a similarity detector to determine whether the one or more features meet a pre-defined similarity threshold  the apparatus of claim  wherein the pre-processor further is to activate one or more channels of the multi-channel image to yield one or more activated channels  the apparatus of claim  wherein the one or more activated channels are to be determined based on their ability to differentiate features  the apparatus of claim  wherein the pre-processor further is to activate one or more local patches of the one or more activated channels  the apparatus of claim  wherein the one or more local patches are to be determined based on their ability to differentiate features  the apparatus of claim  wherein the feature matcher further is to utilize a large-scale data learning process to perform the feature matching  a method comprising modeling an input image to yield a multi-channel image extracting a set of features based on the multi-channel image selecting one or more features from the set of features of the multi-channel image wherein the one or more features are selected based on an ability to differentiate features matching the one or more features to a learned feature set and determining whether the one or more features meet a pre-defined similarity threshold  the method of claim  wherein modeling the input image further is to include activating one or more channels of the multi-channel image to yield one or more activated channels  the method of claim  wherein the one or more activated channels are to be determined based on their ability to differentiate features  the method of claim  wherein extracting features of the input image further is to include activating one or more local patches of the one or more activated channels  the method of claim  wherein the one or more local patches are to be determined based on their ability to differentiate features  the method of claim  wherein the feature matcher utilizes a large-scale data learning process to perform the feature matching  at least one non-transitory computer readable storage medium comprising a set of instructions which when executed by a computing device cause the computing device to model an input image to yield a multi-channel image extract a set of features based on the multi-channel image select one or more features from the set of features of the multi-channel image wherein the features are selected based on an ability to differentiate features match the one or more features to a learned feature set and determine whether the one or more features meet a pre-defined similarity threshold  the at least one non-transitory computer readable storage medium of claim  wherein the instructions when executed cause a computing device to activate one or more channels of the multi-channel image to yield one or more activated channels  the at least one non-transitory computer readable storage medium of claim  wherein the instructions when executed cause a computing device to determine the one or more activated channels based on their ability to differentiate features  the at least one non-transitory computer readable storage medium of claim  wherein extracting features of the input image is to further include activating one or more local patches of the one or more activated channels  the at least one non-transitory computer readable storage medium of claim  wherein the one or more local patches are to be determined based on their ability to differentiate features  the at least one non-transitory computer readable storage medium of claim  wherein the feature matcher further is to utilize a large-scale data learning process to perform the feature matching  an apparatus comprising means for modeling an input image to yield a multi-channel image means for extracting a set of features based on the multi-channel image means for selecting one or more features from the set of features of the multi-channel image wherein the one or more features are selected based on an ability to differentiate features means for matching the one or more features to a learned feature set and means for determining whether the one or more features meet a pre-defined similarity threshold a method for controlling a terminal the terminal comprising a capturing apparatus and at least one processor the method comprising acquiring by the capturing apparatus an image obtaining by the at least one processor a motion parameter of the terminal the motion parameter comprising at least one of a motion frequency or a motion time and two or more parameters from among an acceleration an angular velocity a motion amplitude the motion frequency and the motion time transmitting by the at least one processor a parameter threshold obtaining request to a data management server the parameter threshold obtaining request comprising configuration information of the terminal receiving corresponding preset thresholds that correspond to the configuration information in response to the parameter threshold obtaining request comparing the two or more parameters with the corresponding preset thresholds and controlling by the at least one processor not to perform image processing on the acquired image based on at least one of the two or more parameters of the motion parameter being greater than a corresponding preset threshold or based on the two or more parameters of the motion parameter being respectively greater than the corresponding preset thresholds wherein the acquiring comprises acquiring the image in real time and the obtaining comprises obtaining the motion parameter of the terminal in real time the method further comprising in response to the at least one of the two or more parameters of the motion parameter being greater than the corresponding preset threshold obtaining the motion parameter of the terminal again and in response to the two or more parameters of the motion parameter obtained at a latest time being less than or equal to the corresponding preset thresholds performing the image processing on the image acquired at the latest time  the method according to claim  wherein the acquiring comprises controlling by the at least one processor to turn on the capturing apparatus based on a face recognition instruction and acquiring by the capturing apparatus a face image when the capturing apparatus is turned on  the method according to claim  wherein the controlling not to perform the image processing comprises skipping performing face recognition on the acquired face image based on the at least one of the two or more parameters of the motion parameter being greater than the corresponding preset threshold or based on the two or more parameters of the motion parameter being respectively greater than the corresponding preset thresholds  the method according to claim  wherein the obtaining comprises at least one of obtaining the acceleration of the terminal by using an acceleration sensor or obtaining the angular velocity of the terminal by using a gyro sensor  the method according to claim  wherein the transmitting comprises transmitting the parameter threshold obtaining request to the data management server according to a preset time period  the method according to claim  further comprising generating prompt information based on the at least one of the two or more parameters of the motion parameter being greater than the corresponding preset threshold the prompt information being used for prompting the terminal to stop moving  the method according to claim  wherein the motion parameter comprises the motion frequency and the motion time  a terminal comprising a capturing apparatus at least one memory configured to store program code and at least one processor configured to access the at least one memory and operate according to the program code the program code comprising motion parameter obtaining code configured to cause the at least one processor to acquire an image by using the capturing apparatus and obtain a motion parameter of the terminal the motion parameter comprising at least one of a motion frequency or a motion time and two or more parameters from among an acceleration an angular velocity a motion amplitude the motion frequency and the motion time request transmitting code configured to cause the at least one processor to transmit a parameter threshold obtaining request to a data management server the parameter threshold obtaining request comprising configuration information of the terminal parameter threshold receiving code configured to cause the at least one processor to receive corresponding preset thresholds that correspond to the configuration information in response to the parameter threshold obtaining request comparing code configured to cause the at least one processor to compare the two or more parameters with the corresponding preset thresholds and control code configured to cause the at least one processor not to perform image processing on the acquired image based on at least one of the two or more parameters of the motion parameter being greater than a corresponding preset threshold or based on the two or more parameters of the motion parameter being respectively greater than the corresponding preset thresholds wherein the motion parameter obtaining code causes the at least one processor to acquire the image in real time and obtain the motion parameter of the terminal in real time and in response to the at least one of the two or more parameters of the motion parameter being greater than the corresponding preset threshold obtain the motion parameter of the terminal again and wherein the control code causes the at least one processor to in response to the two or more parameters of the motion parameter obtained at a latest time being less than or equal to the corresponding preset thresholds perform the image processing on the image acquired at the latest time  the terminal according to claim  wherein the program code further comprises face instruction receiving code configured to cause the at least one processor to receive a face recognition instruction wherein the motion parameter obtaining code causes the at least one processor to control according to the face recognition instruction the capturing apparatus to turn on and acquire a face image by using the capturing apparatus when the capturing apparatus is turned on and wherein the control code causes the at least one processor to skip performing face recognition on the acquired face image based on the at least one of the two or more parameters of the motion parameter being greater than the corresponding preset threshold or based on the two or more parameters of the motion parameter being respectively greater than the corresponding preset thresholds  the terminal according to claim  wherein the request transmitting code causes the at least one processor to transmit the parameter threshold obtaining request to the data management server according to a preset time period  the terminal according to claim  wherein the program code further comprises prompt information generation code configured to cause the at least one processor to generate prompt information based on at least one of the two or more parameters of the motion parameter being greater than the corresponding preset threshold the prompt information being used for prompting the terminal to stop moving  the terminal according to claim  wherein the motion parameter comprises the motion frequency and the motion time  a non-transitory computer-readable storage medium storing a machine instruction which when executed by one or more processors causes the one or more processors to perform obtaining an image acquired by a capturing apparatus obtaining a motion parameter of a terminal the terminal comprising the capturing apparatus the motion parameter comprising at least one of a motion frequency or a motion time and two or more parameters from among an acceleration an angular velocity a motion amplitude the motion frequency and the motion time transmitting a parameter threshold obtaining request to a data management server the parameter threshold obtaining request comprising configuration information of the terminal receiving corresponding preset thresholds that correspond to the configuration information in response to the parameter threshold obtaining request comparing the two or more parameters with the corresponding preset thresholds and controlling not to perform image processing on an acquired image based on at least one of the two or more parameters of the motion parameter being greater than a corresponding preset threshold or based on the two or more parameters of the motion parameter being respectively greater than the corresponding preset thresholds wherein the acquiring comprises acquiring the image in real time and the obtaining comprises obtaining the motion parameter of the terminal in real time the method further comprising in response to the at least one of the two or more parameters of the motion parameter being greater than the corresponding preset threshold obtaining the motion parameter of the terminal again and in response to the two or more parameters of the motion parameter obtained at a latest time being less than or equal to the corresponding preset thresholds performing the image processing on the image acquired at the latest time  the non-transitory computer-readable storage medium according to claim  wherein the acquired image is a face image and the image processing comprises performing face recognition  the non-transitory computer-readable storage medium according to claim  wherein the obtaining the motion parameter comprises at least one of obtaining the acceleration of the terminal by using an acceleration sensor or obtaining the angular velocity of the terminal by using a gyro sensor  the non-transitory computer-readable storage medium according to claim  wherein the motion parameter comprises the motion frequency and the motion time a method of processing a drive-through order the method comprising receiving customer information detected through vision recognition providing product information to a customer based on the customer information and processing a product order of the customer  the method according to claim  wherein the receiving of customer information comprises at least one of receiving customer information associated with vehicle information detected through vehicle recognition or receiving customer information associated with identification information detected through face recognition  the method according to claim  further comprising determining whether the customer is a pre-order customer based on the customer information wherein when the customer is determined to be a pre-order customer the providing of product information based on the customer information comprises providing pre-order information using at least one of audio or video and the processing of the product order of the customer comprises providing information for promptly guiding a vehicle to a pickup stand using at least one of audio or video and providing information that an additional order is available  the method according to claim  wherein the product information based on the customer information comprises a most recently ordered product component and a most frequently ordered product component in an order history of the customer information  the method according to claim  wherein the receiving of customer information comprises receiving information about an age and gender of a passenger detected through face recognition and the providing of product information to a customer based on the customer information comprises providing recommended menu information differentiated according to the age and gender  the method according to claim  wherein the processing of a product order of the customer comprises determining a product component in a past order history or a component modified from the product component as a product order  the method according to claim  wherein the processing of a product order of the customer comprises paying a product price according to biometrics-based authentication through a communication system of a vehicle or a mobile terminal  the method according to claim  wherein the processing of a product order of the customer comprises issuing a payment number for a divided payment and performing the divided payments according to payment requests of a plurality of mobile terminals to which the payment numbers are inputted  the method according to claim  wherein the processing of a product order of the customer further comprises accumulating mileage in an account corresponding to the mobile terminal undergoing a payment  the method according to claim  wherein the processing of a product order of the customer further comprises suggesting a takeout packaging method according to a temperature of a product an atmospheric temperature weather and a vehicle type  an apparatus configured to process a drive-through order the apparatus comprising a transceiver configured to receive customer information detected through vision recognition a digital signage configured to provide product information to a customer based on the customer information and a processor configured to process a product order of the customer  the apparatus according to claim  wherein the transceiver receives at least one of customer information associated with vehicle information detected through vehicle recognition or customer information associated with identification information detected through face recognition  the apparatus according to claim  wherein the processor is configured to determine whether the customer is a pre-order customer based on the customer information and when the customer is determined to be a pre-order customer perform a control operation to provide pre-order information and control the digital signage to output information for promptly guiding a vehicle to a pickup stand and provide information that an additional order is available  the apparatus according to claim  wherein the product information based on the customer information comprises a most recently ordered product component and a most frequently ordered product component in an order history of the customer information  the apparatus according to claim  wherein the transceiver is configured to receive information about an age and gender of a passenger detected through face recognition and the processor is configured to control the digital signage to provide recommended menu information differentiated according to the age and gender  the apparatus according to claim  wherein the processor is configured to determine a product component in a past order history or a component modified from the product component as the product order  the apparatus according to claim  wherein the processor is configured to pay a product price according to biometrics-based authentication through a communication system of a vehicle or a mobile terminal  the apparatus according to claim  wherein the processor is configured to issue a payment number for a divided payment and perform the divided payments according to requests of a plurality of mobile terminals to which the payment numbers are inputted  the apparatus according to claim  wherein the processor is configured to accumulate mileage in an account corresponding to the mobile terminal undergoing a payment  the apparatus according to claim  wherein the processor is configured to control the digital signage to suggest a takeout packaging method according to a temperature of a product an atmospheric temperature weather and a vehicle type an image information processing method performed at a computing device having one or more processors and memory storing a plurality of programs to be executed by the one or more processors the method comprising identifying using face recognition one or more faces each face corresponding to a respective person captured in a first image for each identified face extracting a set of profile parameters of a corresponding person in the first image and selecting from a plurality of image tiles a first image tile that matches the face of the corresponding person in the first image in accordance with a predefined correspondence between the set of profile parameters of the corresponding person and a set of pre-stored description parameters of the first image tile generating a second image by covering the faces of respective persons in the first image with their corresponding first image tiles and sharing the first image and the second image in a predefined order via a group chat session  the method of claim  wherein the first image and the second image are displayed in the group chat session one image at a time such that one of the two images is replaced by the other of the two images periodically  the method of claim  wherein extracting a set of profile parameters of a corresponding person in the first image includes determining one or more descriptive labels corresponding to the identified face of the corresponding person using a first machine learning model wherein the first machine learning model is trained with the facial images and corresponding descriptive labels  the method of claim  wherein extracting a set of profile parameters of a corresponding person in the first image includes determining an identity of the corresponding person based on the identified face of the corresponding person locating respective profile information of the first person based on the determined identity of the corresponding person and using one or more characteristics in the respective profile information of the first person as the set of profile parameters corresponding to the identified face of the corresponding person  the method of claim  wherein at least a first one of the first image tiles is a dynamic image tile and at least a second one of the first image tiles is a static image tile  the method of claim  including receiving a plurality of user comments from different users of the group chat session each user comment including a descriptive term for a respective person identified in the first image choosing a descriptive label for the respective person according to the plurality of user comments and updating the second image by adding the descriptive label adjacent to the first image tile of the respective person  a computing device for image information processing comprising one or more processors and memory storing instructions which when executed by the one or more processors cause the processors to perform a plurality of operations comprising identifying using face recognition one or more faces each face corresponding to a respective person captured in a first image for each identified face extracting a set of profile parameters of a corresponding person in the first image and selecting from a plurality of image tiles a first image tile that matches the face of the corresponding person in the first image in accordance with a predefined correspondence between the set of profile parameters of the corresponding person and a set of pre-stored description parameters of the first image tile generating a second image by covering the faces of respective persons in the first image with their corresponding first image tiles and sharing the first image and the second image in a predefined order via a group chat session  the computing device of claim  wherein the first image and the second image are displayed in the group chat session one image at a time such that one of the two images is replaced by the other of the two images periodically  the computing device of claim  wherein extracting a set of profile parameters of a corresponding person in the first image includes determining one or more descriptive labels corresponding to the identified face of the corresponding person using a first machine learning model wherein the first machine learning model is trained with the facial images and corresponding descriptive labels  the computing device of claim  wherein extracting a set of profile parameters of a corresponding person in the first image includes determining an identity of the corresponding person based on the identified face of the corresponding person locating respective profile information of the first person based on the determined identity of the corresponding person and using one or more characteristics in the respective profile information of the first person as the set of profile parameters corresponding to the identified face of the corresponding person  the computing device of claim  wherein at least a first one of the first image tiles is a dynamic image tile and at least a second one of the first image tiles is a static image tile  the computing device of claim  wherein the plurality of operations further include receiving a plurality of user comments from different users of the group chat session each user comment including a descriptive term for a respective person identified in the first image choosing a descriptive label for the respective person according to the plurality of user comments and updating the second image by adding the descriptive label adjacent to the first image tile of the respective person  a non-transitory computer-readable storage medium storing instructions which when executed by a computing device having one or more processors cause the computing device to perform a plurality of operations comprising identifying using face recognition one or more faces each face corresponding to a respective person captured in a first image for each identified face extracting a set of profile parameters of a corresponding person in the first image and selecting from a plurality of image tiles a first image tile that matches the face of the corresponding person in the first image in accordance with a predefined correspondence between the set of profile parameters of the corresponding person and a set of pre-stored description parameters of the first image tile generating a second image by covering the faces of respective persons in the first image with their corresponding first image tiles and sharing the first image and the second image in a predefined order via a group chat session  the non-transitory computer-readable storage medium of claim  wherein the first image and the second image are displayed in the group chat session one image at a time such that one of the two images is replaced by the other of the two images periodically  the non-transitory computer-readable storage medium of claim  wherein extracting a set of profile parameters of a corresponding person in the first image includes determining one or more descriptive labels corresponding to the identified face of the corresponding person using a first machine learning model wherein the first machine learning model is trained with the facial images and corresponding descriptive labels  the non-transitory computer-readable storage medium of claim  wherein extracting a set of profile parameters of a corresponding person in the first image includes determining an identity of the corresponding person based on the identified face of the corresponding person locating respective profile information of the first person based on the determined identity of the corresponding person and using one or more characteristics in the respective profile information of the first person as the set of profile parameters corresponding to the identified face of the corresponding person  the non-transitory computer-readable storage medium of claim  wherein at least a first one of the first image tiles is a dynamic image tile and at least a second one of the first image tiles is a static image tile  the non-transitory computer-readable storage medium of claim  wherein the plurality of operations further include receiving a plurality of user comments from different users of the group chat session each user comment including a descriptive term for a respective person identified in the first image choosing a descriptive label for the respective person according to the plurality of user comments and updating the second image by adding the descriptive label adjacent to the first image tile of the respective person a method comprising by a computing system determining that a performance metric of an eye tracking system is below a first performance threshold wherein the eye tracking system is associated with a head-mounted display worn by a user based on the determination of the performance metric of the eye tracking system being below the first performance threshold the computer system performing receiving one or more first inputs associated with a body of the user estimating a region that the user is looking at within a field of view of the head-mounted display based on the received one or more first inputs associated with the body of the user determining a vergence distance of the user based at least on the one or more first inputs associated with the body of the user the estimated region that the user is looking at and locations of one or more objects in a scene displayed by the head-mounted display and adjusting one or more configurations of the head-mounted display based on the determined vergence distance of the user  the method of claim  wherein the one or more configurations of the head-mounted display comprise one or more of a rendering image a position of a display screen or a position of an optics block  the method of claim  further comprising determining that the performance metric of the eye tracking system is above a second performance threshold receiving eye tracking data from the eye tracking system and determining the vergence distance of the user based on the eye tracking data and the one or more first inputs associated with the body of the user  the method of claim  further comprising receiving one or more second inputs associated with one or more displaying elements in the scene displayed by the head-mounted display and determining the vergence distance of the user based at least on the eye tracking data the one or more first inputs associated with the body of the user and the one or more second inputs associated with the one or more displaying elements of the scene  the method of claim  further comprising feeding the one or more first inputs associated with the body of the user to a fusion algorithm wherein the fusion algorithm assigns a weight score to each input of the one or more first inputs determining the vergence distance of the user using the fusion algorithm based on the one or more first inputs associated with the body of the user and determining a z-depth of a display screen and a confidence score based on the one or more first inputs associated with the body of the user  the method of claim  further comprising comparing the confidence score to a confidence level threshold in response to a determination that the confidence score is below the confidence level threshold feeding the one or more second inputs associated with the one or more displaying elements of the scene to the fusion algorithm and determining the z-depth of the display screen using the fusion algorithm based on the one or more first inputs associated with the body of the user and the one or more second inputs associated with the one or more displaying elements of the scene  the method of claim  further comparing comparing by the fusion algorithm confidence scores associated with a plurality of combinations of inputs and determining by the fusion algorithm the z-depth of the display screen based on a combination of inputs associated with a highest confidence score  the method of claim  wherein the z-depth and the confidence score are determined by the fusion algorithm using a piecewise comparison of the one or more first inputs and the one or more second inputs  the method of claim  wherein the z-depth and the confidence score are determined based on a correlation between two or more inputs of the one or more first inputs and the one or more second inputs  the method of claim  wherein the fusion algorithm comprises a machine learning ml algorithm and wherein the machine learning ml algorithm determines a combination of first inputs fed to the fusion algorithm  the method of claim  wherein the one or more first inputs associated with the body of the user comprise one or more of a hand position a hand direction a hand movement a hand gesture a head position a head direction a head movement a head gesture a gaze angle rea body gesture a body posture a body movement a behavior of the user or a weighted combination of one or more related parameters  the method of claim  wherein the one or more first inputs associated with the body of the user are received from one or more of a controller a sensor a camera a microphone an accelerometer a headset worn by the user or a mobile device  the method of claim  wherein the one or more second inputs associated with the one or more displaying elements comprise one or more of a z-buffer value associated with a displaying element a displaying element marked by a developer an image analysis result a shape of a displaying element a face recognition result an object recognition result a person identified in a displaying content an object identified in a displaying content a correlation of two or more displaying elements or a weighted combination of the one or more second inputs  the method of claim  further comprising determining that the performance metric of the eye tracking system is below a second performance threshold receiving one or more second inputs associated with one or more displaying elements in the scene displayed by the head-mounted display and determining the vergence distance of the user based at least on the one or more first inputs associated with the body of the user and the one or more second inputs associated with the one or more displaying elements  the method of claim  wherein determining that the performance metric of the eye tracking system is below the second performance threshold comprises determining that the eye tracking system does not exist or fails to provide eye tracking data  the method of claim  wherein the performance metric of the eye tracking system comprises one or more of an accuracy of a parameter from the eye tracking system a precision of a parameter from the eye tracking system a value of a parameter from the eye tracking system a detectability of a pupil a metric based on one or more parameters associated with the user a parameter change a parameter changing trend a data availability or a weighted combination of one or more performance related parameters  the method of claim  wherein the one or more parameters associated with the user comprise one or more of an eye distance of the user a pupil position a pupil status a correlation of two pupils of the user a head size of the user a position of a headset worn by the user an angle of the headset worn by the user a direction of the headset worn by the user an alignment of the eyes of the user or a weighted combination of one or more related parameters associated with the user  the method of claim  wherein the first performance threshold comprises one or more of a pre-determined value a pre-determined range a state of a data a changing speed of a data or a trend of a data change  one or more non-transitory computer-readable storage media embodying software that is operable when executed by a computing system to determine that a performance metric of an eye tracking system is below a first performance threshold wherein the eye tracking system is associated with a head-mounted display worn by a user based on the determination of the performance metric of the eye tracking system being below the first performance threshold the media embodying software operable when executed by the computing system to receive one or more first inputs associated with a body of the user estimate a region that the user is looking at within a field of view of the head-mounted display based on the received one or more first inputs associated with the body of the user determine a vergence distance of the user based at least on the one or more first inputs associated with the body of the user the estimated region that the user is looking at and locations of one or more objects in a scene displayed by the head-mounted display and adjust one or more configurations of the head-mounted display based on the determined vergence distance of the user  a system comprising one or more non-transitory computer-readable storage media embodying instructions one or more processors coupled to the storage media and operable to execute the instructions to determine that a performance metric of an eye tracking system is below a first performance threshold wherein the eye tracking system is associated with a head-mounted display worn by a user based on the determination of the performance metric of the eye tracking system being below the first performance threshold the system is configured to receive one or more first inputs associated with a body of the user estimate a region that the user is looking at within a field of view of the head-mounted display based on the received one or more first inputs associated with the body of the user determine a vergence distance of the user based at least on the one or more first inputs associated with the body of the user the estimated region that the user is looking at and locations of one or more objects in a scene displayed by the head-mounted display and adjust one or more configurations of the head-mounted display based on the determined vergence distance of the user a computer-implemented method for image-based self-guided object detection comprising receiving by a processor device a set of images each of the images having a respective grid thereon that is labeled regarding a respective object to be detected using grid level label data training by the processor device a grid-based object detector using the grid level label data determining by the processor device a respective bounding box for the respective object in each of the images by applying local segmentation to each of the images and training by the processor device a region-based convolutional neural network rcnn for joint object localization and object classification using the respective bounding box for the respective object in each of the images as an input to the rcnn  the computer-implemented method of claim  further comprising performing an action responsive to the object localization and object classification for a respective new object in a new image to which the rcnn is applied  the computer-implemented method of claim  wherein the action comprises autonomously controlling a motor vehicle to avoid a collision with the new object responsive to the object localization and object classification for the respective new object  the computer-implemented method of claim  wherein the local segmentation is performed using a self-similarity search and template matching to provide the respective bounding box around the respective object in the set of images  the computer-implemented method of claim  wherein the local segmentation is applied to each of the images to segment a respective target region therein  the computer-implemented method of claim  wherein the region-based convolutional neural network rcnn forms a model during an object training stage that is to detect objects in new images during an inference stage  the computer-implemented method of claim  wherein the method is performed by a system selected from the group consisting of a surveillance system a face detection system a face recognition system a cancer detection system an object tracking system and an advanced driver-assistance system  a computer program product for image-based self-guided object detection the computer program product comprising a non-transitory computer readable storage medium having program instructions embodied therewith the program instructions executable by a computer to cause the computer to perform a method comprising receiving by a processor device a set of images each of the images having a respective grid thereon that is labeled regarding a respective object to be detected using grid level label data training by the processor device a grid-based object detector using the grid level label data determining by the processor device a respective bounding box for the respective object in each of the images by applying local segmentation to each of the images and training by the processor device a region-based convolutional neural network rcnn for joint object localization and object classification using the respective bounding box for the respective object in each of the images as an input to the rcnn  the computer program product of claim  wherein the method further comprises performing an action responsive to the object localization and object classification for a respective new object in a new image to which the rcnn is applied  the computer program product of claim  wherein the action comprises autonomously controlling a motor vehicle to avoid a collision with the new object responsive to the object localization and object classification for the respective new object  the computer program product of claim  wherein the local segmentation is performed using a self-similarity search and template matching to provide the respective bounding box around the respective object in the set of images  the computer program product of claim  wherein the local segmentation is applied to each of the images to segment a respective target region therein  the computer program product of claim  wherein the region-based convolutional neural network rcnn forms a model during an object training stage that is to detect objects in new images during an inference stage  the computer program product of claim  wherein the method is performed by a system selected from the group consisting of a surveillance system a face detection system a face recognition system a cancer detection system an object tracking system and an advanced driver-assistance system  a computer processing system for image-based self-guided object detection comprising a memory device for storing program code and a processor device for running the program code to receive a set of images each of the images having a respective grid thereon that is labeled regarding a respective object to be detected using grid level label data train a grid-based object detector using the grid level label data determine a respective bounding box for the respective object in each of the images by applying local segmentation to each of the images and train a region-based convolutional neural network rcnn for joint object localization and object classification using the respective bounding box for the respective object in each of the images as an input to the rcnn  the computer processing system of claim  wherein the processor device further runs the program code to perform an action responsive to the object localization and object classification for a respective new object in a new image to which the rcnn is applied  the computer processing system of claim  wherein the action comprises autonomously controlling a motor vehicle to avoid a collision with the new object responsive to the object localization and object classification for the respective new object  the computer processing system of claim  wherein the local segmentation is performed using a self-similarity search and template matching to provide the respective bounding box around the respective object in the set of images  the computer processing system of claim  wherein the region-based convolutional neural network rcnn forms a model during an object training stage that is to detect objects in new images during an inference stage  the computer processing system of claim  wherein the computer processing system is comprised in a system selected from the group consisting of a surveillance system a face detection system a face recognition system a cancer detection system an object tracking system and an advanced driver-assistance system a method of scalable parallel cloud-based face recognition utilizing a database of normalized stored images comprising capturing an image using a camera detecting a face in the captured image normalizing the detected facial image to match the normalized stored images identifying facial features in the normalized detected facial image generating a plurality of facial metrics from the facial features calculating euclidean distances between the facial metrics of the normalized detected facial image with corresponding facial metrics of each of the stored images comparing each euclidean distance against a predetermined threshold responsive to the euclidean distance comparison producing a reduced candidate list of best possible image matches from the normalized stored images comparing in parallel the normalized detected facial image with each of the normalized stored images of the reduced candidate list utilizing a plurality of face recognition algorithms where each processor of a parallel processing system uses a different face recognition algorithm responsive to the comparison producing best match results from each parallel subset of the reduced candidate list and selecting a final match from the best match results using a deep learning neural network face recognition algorithm trained on outputs of individual face recognition algorithms  the method of scalable parallel cloud-based face recognition of claim  wherein detecting a face in the captured image comprises utilizing opencv to detect a face in the captured image extracting the location of the eyes and a tip of the nose in the face determining a distance between the eyes cropping the face from the captured image where the width and the height of a cropped face image is a function of the distance between the eyes and rotating the face by an angle of rotation that is a function of the distance between the eyes  the method of scalable parallel cloud-based face recognition of claim  wherein the width of the cropped face image is  times the distance between the eyes the height of the cropped face image is  times the distance between the eyes and the angle of rotation is an angle formed by a straight line joining the eyes and an x-axis of the face  the method of scalable parallel cloud-based face recognition of claim  wherein rotating the face comprises rotating the face to provide a frontal face pattern  the method of scalable parallel cloud-based face recognition of claim  further comprising the step of proportionally rescaling the cropped and rotated image  the method of scalable parallel cloud-based face recognition of claim  where the proportional rescaling yields a cropped and rotated image with a size of = pixels  the method of scalable parallel cloud-based face recognition of claim  wherein the facial features identified in the normalized detected facial image comprise a pair of eyes a tip of a nose a mouth a center of the mouth and a chin area comprising a bottom a top left landmark and a top right landmark  the method of scalable parallel cloud-based face recognition of claim  wherein generating a plurality of facial metrics comprises calculating a distance between the pair of eyes a distance between the eyes and the tip of the nose a distance equal to the width of the mouth a distance between the tip of the nose and the center of mouth a distance between the bottom of chin and the center of mouth a distance between the top left landmark on the chin and the tip of the nose and a distance between the top right landmark on the chin and the tip of the nose  the method of scalable parallel cloud-based face recognition of claim  wherein performing a euclidean distance match further comprises partitioning the normalized stored images into a plurality of substantially equal subsets performing a euclidean distance match between the facial metrics of the normalized detected facial image and corresponding facial metrics of each of the stored images of the subsets of the normalized stored images with a separate processor of a parallel processing system to generate a euclidean distance for each stored image of the subset comparing each euclidean distance against a predetermined threshold with the separate processors responsive to the euclidean distance comparison producing a reduced candidate list of best possible image matches from the normalized stored images of each subset and combining the reduced candidate lists from each subset to produce a single reduced candidate list  the method of scalable parallel cloud-based face recognition of claim  wherein the plurality of face recognition algorithms utilized in comparing in parallel the normalized detected facial image with each of the normalized stored images of the reduced candidate list consists of face recognition algorithms selected from a group consisting of principle component analysis pca-based algorithms linear discriminant analysis lda algorithms independent component analysis ica algorithms kernel-based algorithms feature-based techniques algorithms based on neural networks algorithms based on transforms and model-based face recognition algorithms  the method of scalable parallel cloud-based face recognition of claim  wherein the pca-based algorithms include eigenfaces for face detectionrecognition and the lda algorithms include the fisherfaces method of face recognition  the method of scalable parallel cloud-based face recognition of claim  wherein comparing in parallel the captured image with each of the normalized stored images of the reduced candidate list further comprises partitioning the reduced candidate list into a plurality of substantially equal subsets processing each subset in a different processor of the parallel processing system uses a unique face recognition algorithm to produce the best match results and using a reduce function of a mapreduce program to combine the best match results from each of the subsets to produce a single set of the best match results  the method of scalable parallel cloud-based face recognition of claim  wherein partitioning the reduced candidate list comprises selecting the images comprising each subset by optimizing the variance between of each of the images according to the following equation where m and n are the number of rows and columns of the face vector image n is the number of groups and σij is the standard deviation of image dimension i in the group j of the face image vector  the method of scalable parallel cloud-based face recognition of claim  wherein selecting the images comprising each subset by optimizing the variance between each of the images according to the following equation dμi μj is the euclidean distance between the mean of the group i and the mean of group j i is the face image vector and l is the number of group levels  the method of scalable parallel cloud-based face recognition of claim  where selecting a final match from the best match results utilizing a deep learning neural network face recognition algorithm comprises utilizing either an adaboost machine-learning algorithm or a neural networks machine-learning model  the method of scalable parallel cloud-based face recognition of claim  where normalizing the detected facial image to match the normalized stored images includes normalizing the detected facial image to the same size orientation and illumination of the normalized stored images  a non-transitory computer-readable medium containing executable program instructions for causing a computer to perform a method of face recognition the method comprising detecting a face in an image captured by a camera normalizing the detected facial image to match the normalized stored images identifying facial features in the normalized detected facial image generating a plurality of facial metrics from the facial features calculating euclidean distances between the facial metrics of the normalized detected facial image with corresponding facial metrics of each of the stored images comparing each euclidean distance against a predetermined threshold responsive to the euclidean distance comparison producing a reduced candidate list of best possible image matches from the normalized stored images comparing in parallel the captured image with each of the normalized stored images of the reduced candidate list utilizing a plurality of face recognition algorithms where each processor of a parallel processing system uses a different face recognition algorithm responsive to the comparison producing best match results from each parallel subset of the reduced candidate list and selecting a final match from the best match results using a deep learning neural network face recognition algorithm trained on outputs of individual face recognition algorithms  the non-transitory computer-readable medium containing executable program instructions of claim  wherein the plurality of face recognition algorithms utilized in comparing in parallel the normalized detected facial image with each of the normalized stored images of the reduced candidate list consists of face recognition algorithms selected from a group consisting of principle component analysis pca-based algorithms linear discriminant analysis lda algorithms independent component analysis ica algorithms kernel-based algorithms feature-based techniques algorithms based on neural networks algorithms based on transforms and model-based face recognition algorithms  the non-transitory computer-readable medium containing executable program instructions of claim  wherein the pca-based algorithms include eigenfaces for face detectionrecognition and the lda algorithms include the fisherfaces method of face recognition  the non-transitory computer-readable medium containing executable program instructions of claim  where selecting a final match from the best match results utilizing a deep learning neural network face recognition algorithm comprises utilizing either an adaboost machine-learning algorithm or a neural networks machine-learning model an imaging device comprising a condensing lens an image sensor configured to detect light passing through the condensing lens and comprising a pixel matrix wherein the pixel matrix comprises a plurality of phase detection pixel pairs and a plurality of regular pixels and a processor configured to turn on the phase detection pixel pairs for autofocusing and output autofocused pixel data after completing the autofocusing divide the autofocused pixel data into a first subframe and a second subframe calculate image features of at least one of the first subframe and the second subframe wherein the image features comprise module widths of a finder pattern and the finder pattern has a predetermined ratio a harr-like feature or a gabor feature and determine an operating resolution of the regular pixels according to the image features calculated from at least one of the first subframe and the second subframe divided from the autofocused pixel data  the imaging device as claimed in claim  wherein each of the phase detection pixel pairs comprises a first pixel and a second pixel a cover layer covering upon a first region of the first pixel and upon a second region of the second pixel wherein the first region and the second region are mirror symmetrical to each other and a microlens aligned with at least one of the first pixel and the second pixel  the imaging device as claimed in claim  wherein the first region and the second region are % to % of an area of a single pixel  the imaging device as claimed in claim  wherein the processor is configured to perform the autofocusing using a dual pixel autofocus technique according to pixel data of the phase detection pixel pairs before completing the autofocusing  the imaging device as claimed in claim  wherein the processor is configured to divide pixel data of the phase detection pixel pairs into a third subframe and a fourth subframe before completing the autofocusing and perform the autofocusing according to the third subframe and the fourth subframe  the imaging device as claimed in claim  wherein the processor is further configured to calibrate brightness of the third subframe and the fourth subframe to be identical using a shading algorithm  the imaging device as claimed in claim  wherein the operating resolution is selected as a first resolution smaller than a number of the regular pixels or as a second resolution larger than the first resolution  the imaging device as claimed in claim  wherein the regular pixels are turned off in the autofocusing  the imaging device as claimed in claim  wherein a number of the phase detection pixel pairs is smaller than that of the regular pixels  an imaging device comprising a condensing lens an image sensor configured to detect light passing through the condensing lens and comprising a pixel matrix wherein the pixel matrix comprises a plurality of phase detection pixel pairs and a plurality of regular pixels and a processor configured to turn on the phase detection pixel pairs for autofocusing and output autofocused pixel data after completing the autofocusing divide the autofocused pixel data into a first subframe and a second subframe calculate image features of at least one of the first subframe and the second subframe wherein the image features comprise module widths of a finder pattern and the finder pattern has a predetermined ratio a harr-like feature or a gabor feature and select an image decoding or an image recognition using pixel data of the regular pixels according to the image features calculated from at least one of the first subframe and the second subframe divided from the autofocused pixel data  the imaging device as claimed in claim  wherein each of the phase detection pixel pairs comprises a first pixel and a second pixel a cover layer covering upon a first region of the first pixel and upon a second region of the second pixel wherein the first region and the second region are mirror symmetrical to each other and a microlens aligned with at least one of the first pixel and the second pixel  the imaging device as claimed in claim  wherein the processor is configured to perform the autofocusing using a dual pixel autofocus technique according to pixel data of the phase detection pixel pairs before completing the autofocusing  the imaging device as claimed in claim  wherein the processor is configured to divide the pixel data of the phase detection pixel pairs into a third subframe and a fourth subframe before completing the autofocusing calibrate brightness of the third subframe and the fourth subframe to be identical using a shading algorithm and perform the autofocusing according to the third subframe and the fourth subframe  the imaging device as claimed in claim  wherein the processor is configured to calculate the image features using at least one of a rule based algorithm and a machine learning algorithm  the imaging device as claimed in claim  wherein the image decoding is decoding qr codes and the image recognition is face recognition  an operating method of an imaging device the imaging device comprising a plurality of phase detection pixel pairs and a plurality of regular pixels the operating method comprising turning on the phase detection pixel pairs for autofocusing and outputting autofocused image frame after completing the autofocusing dividing the autofocused image frame acquired by the phase detection pixel pairs into a first subframe and a second subframe calculating image features of at least one of the first subframe and the second subframe wherein the image feature comprise module widths of a finder pattern and the finder pattern has a predetermined ratio a harr-like feature or a gabor feature and selectively activating at least a part of the regular pixels according to the image features calculated from at least one of the first subframe and the second subframe divided from the autofocused image frame  the operating method as claimed in claim  wherein the selectively activating comprises activating a first part of the regular pixels to perform an image decoding according to pixel data of the first part of the regular pixels or activating all the regular pixels to perform an image recognition according to pixel data of the all regular pixels  the operating method as claimed in claim  wherein pixel data of the phase detection pixel pairs captured in a same frame with the pixel data of the regular pixels is also used in performing the image decoding and the image recognition  the operating method as claimed in claim  wherein the image decoding is decoding qr codes and the image recognition is face recognition  the operating method as claimed in claim  wherein the phase detection pixel pairs are partially covered pixels or have a structure of dual pixel an apparatus comprising a first camera module configured to obtain a first image of an object with a first field of view a second camera module configured to obtain a second image of the object with a second field of view different from the first field of view a first depth map generator configured to generate a first depth map of the first image based on the first image and the second image and a second depth map generator configured to generate a second depth map of the second image based on the first image the second image and the first depth map  the apparatus of claim  wherein the first field of view is a narrow angle and the second field of view is a wider angle  the apparatus of claim  wherein the second image is divided into a primary region and a residual region and the second depth map generator comprises a relationship estimating module configured to estimate a relationship between the primary region and the residual region based on the first image and the second image and a depth map estimating module configured to estimate a depth map of the residual region based on the estimated relationship and the first depth map  the apparatus of claim  wherein at least one of the relationship estimating module and the depth map estimating module performs an estimating operation based on a neural network module  the apparatus of claim  further comprising a depth map fusion unit configured to generate a third depth map of the second image by performing a fusion operation based on the first depth map and the second depth map  the apparatus of claim  wherein the depth map fusion unit comprises a tone mapping module configured to generate a tone-mapped second depth map to correspond to the first depth map by performing a bias removing operation on the second depth map and a fusion module configured to generate the third depth map by fusing the tone-mapped second depth map and the first depth map  the apparatus of claim  wherein the depth map fusion unit further comprises a propagating module configured to generate a propagated first depth map in the second image by iterated propagating of the first depth map based on the first depth map and the second image and the fusion module generates the third depth map by fusing the tone-mapped second depth map and the propagated first depth map  the apparatus of claim  wherein the depth map fusion unit further comprises a post-processing module configured to perform a post-processing operation on the third depth map generated by the fusion module to provide the post-processed third depth map  the apparatus of claim  wherein the post-processing module performs the post-processing operation by filtering an interface generated in the third depth map in accordance with fusion of the fusion module  the apparatus of claim  wherein the post-processing module removes artifacts generated in the third depth map in accordance with fusion of the fusion module  the apparatus of claim  wherein the first depth map generator analyses a distance relationship between the first image and the second image and generates a first depth map of the first image based on the distance relationship  a method of processing an image of an electronic apparatus the method comprising obtaining a first image of an object using a first camera module obtaining a second image of the object using a second camera module generating a first depth map of the first image based on the first image and the second image estimating a relationship between a primary region of the second image and a residual region of the second image based on the first image and the second image and generating a second depth map of the second image based on the estimated relationship between the primary region and the residual region and the first depth map  the method of claim  wherein the electronic apparatus comprises a first camera module including a first lens having a first field of view and a second camera module including a second lens having a second field of view wider than the first field of view  the method of claim  wherein the generating of the second depth map comprises estimating a depth map of the residual region based on the estimated relationship between the primary region and the residual region and the first depth map and generating the second depth map based on a depth map of the residual region and the first depth map  the method of claim  wherein the estimating of the relationship between a primary region of the second image is performed using a neural network model  the method of claim  further comprising performing a pre-processing operation on the second depth map and generating a third depth map of the residual image by fusing the second depth map on which the pre-processing operation is performed and the first depth map  the method of claim  wherein the performing of the pre-processing operation comprises performing a tone mapping operation between a depth map of the primary region and a depth map of the residual region based on the second depth map  an operating method for an electronic apparatus the electronic apparatus including a first camera module providing a first image of an object using a first field of view and a second camera module providing a second image of the object using second field of view wider than the first field of view and a processor generating a depth map of the second image based on a primary region of the second image and a residual region of the second image the operating method comprising generating a first depth map of the primary region by estimating a relationship between the first image and the second image estimating a relationship between the primary region and the residual region based on the first image and the second image generating a second depth map of the second image by estimating a depth map of the second region based on the estimated relationship between the primary region and the residual region and generating a depth map of the second image by fusing the first depth map and the second depth map  the operation method of claim  further comprising executing an application that applies an image effect to the second image based on a depth map of the residual image  the operation method of claim  wherein the application applies at least one image effect of auto-focusing out-focusing forebackground separation face recognition object detection within a frame and augmented reality to the second image based on a depth map of the second image a payment method based on a face recognition comprising acquiring first face image information of a target user extracting first characteristic information from the first face image information wherein the first characteristic information includes head posture information of the target user and gaze information of the target user determining whether the target user has a willingness to pay according to the head posture information of the target user and the gaze information of the target user including determining whether an angle of rotation in each preset direction is less than an angle threshold wherein the head posture information includes the angle of rotation in each preset direction determining whether a probability value that a user gazes at a payment screen is greater than a probability threshold wherein the gaze information includes the probability value that a user gazes at a payment screen and in response to determining that the angle of rotation in each preset direction is less than the angle threshold and that the probability value that a user gazes at a payment screen is greater than the probability threshold determining that the target user has a willingness to pay and in response to determining that the target user has a willingness to pay completing a payment operation based on the face recognition  the method as claimed in claim  wherein the completing a payment operation based on the face recognition comprises triggering and performing a payment initiating operation to acquire second face image information based on the face recognition determining whether second characteristic information extracted from the second face image information indicates that the user has a willingness to pay and in response to determining that the second characteristic information indicates that the user has a willingness to pay triggering and performing a payment confirmation operation to complete the payment operation based on payment account information corresponding to the target user  the method as claimed in claim  wherein the determining whether second characteristic information extracted from the second face image information indicates that the user has a willingness to pay comprises determining whether a current user corresponding to the second face image information is consistent with the target user and in response to determining that the current user is consistent with the target user determining whether the target user has a willingness to pay according to the second characteristic information extracted from the second face image information  the method as claimed in claim  wherein the extracting first characteristic information from the first face image information comprises determining the head posture information of the target user using a head posture recognition model based on the first face image information and determining the gaze information of the target user using a gaze information recognition model based on characteristics of an eye region in the first face image information  the method as claimed in claim  wherein the head posture recognition model is obtained through training by acquiring a first sample data set wherein the first sample data set includes a plurality of pieces of first sample data and each of the plurality of pieces of first sample data includes a correspondence between a sample face image and head posture information determining mean image data and variance image data of a plurality of sample face images for each of the plurality of pieces of first sample data preprocessing the sample face image contained in each of the plurality of pieces of first sample data based on the mean image data and the variance image data to obtain a preprocessed sample face image setting the preprocessed sample face image and the corresponding head posture information as a first model training sample and performing training using a machine learning method and based on a plurality of first model training samples to obtain the head posture recognition model  the method as claimed in claim  wherein the gaze information recognition model is obtained through training by acquiring a second sample data set wherein the second sample data set includes a plurality of pieces of second sample data and each of the plurality of pieces of second sample data includes a correspondence between a sample eye image and gaze information determining mean image data and variance image data of a plurality of sample eye images for each of the plurality of pieces of second sample data preprocessing the sample eye image contained in each of the plurality of pieces of second sample data based on the mean image data and the variance image data to obtain a preprocessed sample eye image setting the preprocessed sample eye image and the corresponding gaze information as a second model training sample and performing training using a machine learning method and based on a plurality of second model training samples to obtain the gaze information recognition model  the method as claimed in claim  wherein the angle of rotation in each preset direction comprises a pitch angle a yaw angle and a roll angle wherein the pitch angle refers to an angle of rotation around a x-axis the yaw angle refers to an angle of rotation around a y-axis and the roll angle refers to an angle of rotation around a z-axis  a payment device based on a face recognition comprising a processor and a non-transitory computer-readable storage medium storing instructions executable by the processor to cause the device to perform operations comprising acquiring first face image information of a target user extracting first characteristic information from the first face image information wherein the first characteristic information includes head posture information of the target user and gaze information of the target user determining whether the target user has a willingness to pay according to the head posture information of the target user and the gaze information of the target user including determining whether an angle of rotation in each preset direction is less than an angle threshold wherein the head posture information includes the angle of rotation in each preset direction determining whether a probability value that a user gazes at a payment screen is greater than a probability threshold wherein the gaze information includes the probability value that a user gazes at a payment screen and in response to determining that the angle of rotation in each preset direction is less than the angle threshold and that the probability value that a user gazes at a payment screen is greater than the probability threshold determining that the target user has a willingness to pay and in response to determining that the target user has a willingness to pay completing a payment operation based on the face recognition  the device as claimed in claim  wherein the completing a payment operation based on the face recognition comprises triggering and performing a payment initiating operation to acquire second face image information based on the face recognition determining whether second characteristic information extracted from the second face image information indicates that the user has a willingness to pay and in response to determining that the second characteristic information indicates that the user has a willingness to pay triggering and performing a payment confirmation operation to complete the payment operation based on payment account information corresponding to the target user  the device as claimed in claim  wherein the determining whether second characteristic information extracted from the second face image information indicates that the user has a willingness to pay comprises determining whether a current user corresponding to the second face image information is consistent with the target user and in response to determining that the current user is consistent with the target user determining whether the target user has a willingness to pay according to the second characteristic information extracted from the second face image information  the device as claimed in claim  wherein the extracting first characteristic information from the first face image information comprises determining the head posture information of the target user using a head posture recognition model based on the first face image information and determining the gaze information of the target user using a gaze information recognition model based on characteristics of an eye region in the first face image information  the device as claimed in claim  wherein the head posture recognition model is obtained through training by acquiring a first sample data set wherein the first sample data set includes a plurality of pieces of first sample data and each of the plurality of pieces of first sample data includes a correspondence between a sample face image and head posture information determining mean image data and variance image data of a plurality of sample face images for each of the plurality of pieces of first sample data preprocessing the sample face image contained in each of the plurality of pieces of first sample data based on the mean image data and the variance image data to obtain a preprocessed sample face image setting the preprocessed sample face image and the corresponding head posture information as a first model training sample and performing training using a machine learning method and based on a plurality of first model training samples to obtain the head posture recognition model  the device as claimed in claim  wherein the gaze information recognition model is obtained through training by acquiring a second sample data set wherein the second sample data set includes a plurality of pieces of second sample data and each of the plurality of pieces of second sample data includes a correspondence between a sample eye image and gaze information determining mean image data and variance image data of a plurality of sample eye images for each of the plurality of pieces of second sample data preprocessing the sample eye image contained in each of the plurality of pieces of second sample data based on the mean image data and the variance image data to obtain a preprocessed sample eye image setting the preprocessed sample eye image and the corresponding gaze information as a second model training sample and performing training using a machine learning method and on a plurality of second model training samples to obtain the gaze information recognition model  the device as claimed in claim  wherein the angle of rotation in each preset direction comprises a pitch angle a yaw angle and a roll angle wherein the pitch angle refers to an angle of rotation around a x-axis the yaw angle refers to an angle of rotation around a y-axis and the roll angle refers to an angle of rotation around a z-axis  a non-transitory computer-readable storage medium for a payment based on a face recognition configured with instructions executable by one or more processors to cause the one or more processors to perform operations comprising acquiring first face image information of a target user extracting first characteristic information from the first face image information wherein the first characteristic information includes head posture information of the target user and gaze information of the target user determining whether the target user has a willingness to pay according to the head posture information of the target user and the gaze information of the target user including determining whether an angle of rotation in each preset direction is less than an angle threshold wherein the head posture information includes the angle of rotation in each preset direction determining whether a probability value that a user gazes at a payment screen is greater than a probability threshold wherein the gaze information includes the probability value that a user gazes at a payment screen and in response to determining that the angle of rotation in each preset direction is less than the angle threshold and that the probability value that a user gazes at a payment screen is greater than the probability threshold determining that the target user has a willingness to pay and in response to determining that the target user has a willingness to pay completing a payment operation based on the face recognition  the storage medium as claimed in claim  wherein the completing a payment operation based on the face recognition comprises triggering and performing a payment initiating operation to acquire second face image information based on the face recognition determining whether second characteristic information extracted from the second face image information indicates that the user has a willingness to pay and in response to determining that the second characteristic information indicates that the user has a willingness to pay triggering and performing a payment confirmation operation to complete the payment operation based on payment account information corresponding to the target user  the storage medium as claimed in claim  wherein the determining whether second characteristic information extracted from the second face image information indicates that the user has a willingness to pay comprises determining whether a current user corresponding to the second face image information is consistent with the target user and in response to determining that the current user is consistent with the target user determining whether the target user has a willingness to pay according to the second characteristic information extracted from the second face image information  the storage medium as claimed in claim  wherein the extracting first characteristic information from the first face image information comprises determining the head posture information of the target user using a head posture recognition model based on the first face image information and determining the gaze information of the target user using a gaze information recognition model based on characteristics of an eye region in the first face image information  the storage medium as claimed in claim  wherein the head posture recognition model is obtained through training by acquiring a first sample data set wherein the first sample data set includes a plurality of pieces of first sample data and each of the plurality of pieces of first sample data includes a correspondence between a sample face image and head posture information determining mean image data and variance image data of a plurality of sample face images for each of the plurality of pieces of first sample data preprocessing the sample face image contained in each of the plurality of pieces of first sample data based on the mean image data and the variance image data to obtain a preprocessed sample face image setting the preprocessed sample face image and the corresponding head posture information as a first model training sample and performing training using a machine learning method and based on a plurality of first model training samples to obtain the head posture recognition model and wherein the gaze information recognition model is obtained through training by acquiring a second sample data set wherein the second sample data set includes a plurality of pieces of second sample data and each of the plurality of pieces of second sample data includes a correspondence between a sample eye image and gaze information determining mean image data and variance image data of a plurality of sample eye images for each of the plurality of pieces of second sample data preprocessing the sample eye image contained in each of the plurality of pieces of second sample data based on the mean image data and the variance image data to obtain a preprocessed sample eye image setting the preprocessed sample eye image and the corresponding gaze information as a second model training sample and performing training using a machine learning method and based on a plurality of second model training samples to obtain the gaze information recognition model  the storage medium as claimed in claim  wherein the angle of rotation in each preset direction comprises a pitch angle a yaw angle and a roll angle wherein the pitch angle refers to an angle of rotation around a x-axis the yaw angle refers to an angle of rotation around a y-axis and the roll angle refers to an angle of rotation around a z-axis a method comprising detecting by a motion detection module a motion by a subject within a predetermined area of view assigning a unique session identification number to the subject detected within a predetermined area of view detecting a facial area of the subject detected within a predetermined area of view generating an image of the facial area of the subject assessing a quality of the image of the facial area of the subject determining an identity of the subject based on the image of the facial area of the subject identifying an intent of the subject and authorizing access to a point of entry based on the determined identity of the subject and based on the intent of the subject  the method of claim  further comprising determining one or more additional subjects within the predetermined area of view and assigning a unique session identification number to each of the one or more additional subjects detected within a predetermined area of view  the method of claim  wherein the assessing a quality of the image of the facial area of the subject comprises assessing whether the quality of the image of the facial area of the object equates predetermined metric of quality and upon determining that the quality of the image of the facial area of the object is inferior to the predetermined metric of quality discarding the image of the facial area of the subject and generating a second image of the facial area of the subject  the method of claim  further comprising detecting whether the facial area of the subject is photographic image and upon detecting that the facial area of the subject is a photographic image generating a warning and restrict access to the point of entry  the method of claim  further comprising conducing an incremental training of the image of the facial area of the subject  the method of claim  wherein conducing an incremental training of the image of the facial area of the subject comprises capturing a first image of the facial area having facial landmarks converting the first image of the facial area into a first numeric vector capturing a second image of the facial area having facial landmarks converting the second image of the facial area into a second numeric vector calculating a weighted mean of the first numeric vector and the second numeric vector wherein the weighted mean represents a change in a facial area and storing the weighted mean in the database  the method of claim  wherein determining an identity of the subject based on the image of the facial area of the subject comprises comparing the image of the facial area of the subject with a plurality of images stored in a database and authenticating the subject  the method of claim  wherein identifying an intent of the subject comprises upon detecting the facial area in a bounding box commencing authentication of the subject calculating a directional vector of a face of the subject determine an intent of the subject to gain access to the point of entry based on the directional vector of the face of the subject granting the access to the point of entry based on authentication of the subject and based on determining the intent of the subject  a non-transitory computer readable medium having program instructions stored thereon that in response to execution by a computing device cause the computing device to perform operations comprising detecting a motion by a subject within a predetermined area of view assigning a unique session identification number to the subject detected within a predetermined area of view detecting a facial area of the subject detected within a predetermined area of view generating an image of the facial area of the subject assessing a quality of the image of the facial area of the subject determining an identity of the subject based on the image of the facial area of the subject identifying an intent of the subject and authorizing access to a point of entry based on the determined identity of the subject and based on the intent of the subject  the non-transitory computer readable medium of claim  further comprising determining one or more additional subjects within the predetermined area of view and assigning a unique session identification number to each of the one or more additional subjects detected within a predetermined area of view  the non-transitory computer readable medium of claim  wherein the assessing a quality of the image of the facial area of the subject comprises assessing whether the quality of the image of the facial area of the object equates predetermined metric of quality and upon determining that the quality of the image of the facial area of the object is inferior to the predetermined metric of quality discarding the image of the facial area of the subject and generating a second image of the facial area of the subject  the non-transitory computer readable medium of claim  further comprising detecting whether the facial area of the subject is photographic image and upon detecting that the facial area of the subject is a photographic image generating a warning and restrict access to the access point  the non-transitory computer readable medium of claim  further comprising conducing an incremental training of the image of the facial area of the subject  the non-transitory computer readable medium of claim  wherein conducing an incremental training of the image of the facial area of the subject comprises capturing a first image of the facial area having facial landmarks converting the first image of the facial area into a first numeric vector capturing a second image of the facial area having facial landmarks converting the second image of the facial area into a second numeric vector calculating a weighted mean of the first numeric vector and the second numeric vector wherein the weighted mean represents a change in a facial area and storing the weighted mean in the database  an apparatus for face recognition comprising a processor and a memory to store computer program instructions the computer program instructions when executed on the processor cause the processor to perform operations comprising detecting a motion by a subject within a predetermined area of view assigning a unique session identification number to the subject detected within a predetermined area of view detecting a facial area of the subject detected within a predetermined area of view generating an image of the facial area of the subject assessing a quality of the image of the facial area of the subject determining an identity of the subject based on the image of the facial area of the subject identifying an intent of the subject and authorizing access to a point of entry based on the determined identity of the subject and based on the intent of the subject  the apparatus of claim  further comprising determining one or more additional subjects within the predetermined area of view and assigning a unique session identification number to each of the one or more additional subjects detected within a predetermined area of view  the apparatus of claim  wherein the assessing a quality of the image of the facial area of the subject comprises assessing whether the quality of the image of the facial area of the object equates predetermined metric of quality and upon determining that the quality of the image of the facial area of the object is inferior to the predetermined metric of quality discarding the image of the facial area of the subject and generating a second image of the facial area of the subject  the apparatus of claim  further comprising detecting whether the facial area of the subject is photographic image and upon detecting that the facial area of the subject is a photographic image generating a warning and restrict access to the access point  the apparatus of claim  further comprising conducing an incremental training of the image of the facial area of the subject  the apparatus of claim  wherein conducing an incremental training of the image of the facial area of the subject comprises capturing a first image of the facial area having facial landmarks converting the first image of the facial area into a first numeric vector capturing a second image of the facial area having facial landmarks converting the second image of the facial area into a second numeric vector calculating a weighted mean of the first numeric vector and the second numeric vector wherein the weighted mean represents a change in a facial area and storing the weighted mean in the database a robot comprising a body configured to rotate and to tilt a camera coupled to the body and configured to rotate and tilt according to the rotate and the tilt of the body wherein the camera is configured to acquire a video of a space a face recognition unit configured to recognize respective faces of one or more persons in the video a tracking unit configured to track motion of each of the recognized faces of the one or more persons and a controller configured to calculate a respective size of each of the faces of the one or more persons select a first person from among the one or more persons based on the calculated sizes of the faces and control at least one of a direction of the rotation of the camera an angle of the tilt of the camera and a focal distance of the camera based on the tracked motion of the recognized face of the first person  the robot of claim  wherein the controller is configured to control the direction of the rotation of the camera and the angle of the tilt of the camera to achieve an particular orientation of the camera relative to the face of the first person and control a focal distance of the camera by comparing respective sizes of the face of the first person before and after motion of the first person  the robot of claim  wherein the particular orientation occurs when the camera faces a general direction of the face of the first person  the robot of claim  wherein the controller is configured to normalize sizes of the faces of the one or more persons based on an interocular distance and select the first person based on the normalized sizes of the faces of the one or more persons  the robot of claim  wherein the controller is configured to select a person having a largest face size from among the one or more persons as the first person  the robot of claim  further comprising a microphone configured to receive a spoken audio that is present in the space wherein the controller is further configured to select the first person further based on the received spoken audio  the robot of claim  wherein the controller is further configured to control gain of the microphone by comparing respective sizes of the face of the first person before and after motion of the first person  the robot of claim  wherein the controller is configured to calculate a position from which the spoken audio is provided and select the first person further based on whether the one or more persons are in the position from which the voice signal is provided  the robot of claim  wherein the controller is configured to select a second person as the first person from among the one or more persons when the second person is located in the position from which the spoken audio is provided  the robot of claim  wherein the controller is configured to select a second person having a largest face size as the first person from among the one or more persons when none of the one or more persons is located in the position from which the spoken audio is provided  the robot of claim  wherein the controller is configured to select a second person having a largest face size as the first person from among the one or more persons when a plurality of persons from among the one or more persons are located in the position from which the spoken audio is provided  the robot of claim  further comprising a speaker wherein the controller is configured to control volume of the speaker by comparing respective sizes of the face of the first person before and after motion of the first person  the robot of claim  wherein the body is further configured to rotate in a lateral direction and to tilt in an vertical direction  an electronic device comprising a camera coupled to the body and configured to rotate and to tilt wherein the camera is configured to acquire a video of a space within which one or more persons are positioned and a processor configured to recognize respective faces of the one or more persons in the video track motion of each of the recognized faces of the one or more persons calculate a respective size of each of the faces of the one or more persons select a first person from among the one or more persons based on the calculated sizes of the faces and control at least one of a direction of the rotation of the camera an angle of the tilt of the camera and a focal distance of the camera based on the tracked motion of the recognized face of the first person  a method comprising acquiring by a camera a video of a space within which one or more persons are positioned recognizing respective faces of the one or more persons in the video tracking motion of each of the recognized faces of the one or more persons calculating a respective size of each of the faces of the one or more persons selecting a first person from among the one or more persons based on the calculated sizes of the faces and controlling at least one of a direction of rotation of the camera an angle of tilt of the camera and a focal distance of the camera based on the tracked motion of the recognized face of the first person a method of inferring topics from a multimodal file the method comprising receiving a multimodal file extracting a set of entities from the multimodal file linking the set of entities to produce a set of linked entities obtaining reference information for the set of entities based at least on the reference information generating a graph of the set of linked entities the graph comprising nodes and edges based at least on the nodes and edges of the graph determining clusters in the graph based at least on the clusters in the graph identifying topic candidates extracting features from the clusters in the graph based at least on the extracted features selecting at least one topicid from among the topic candidates to represent at least one cluster and indexing the multimodal file with the at least one topicid  the method of claim  wherein the multimodal file comprises a video portion and an audio portion and wherein extracting a set of entities from the multimodal file comprises detecting objects in the video portion of the multimodal file and detecting text in the audio portion of the multimodal file  the method of claim  wherein detecting objects comprises performing face recognition  the method of claim  wherein detecting text comprises performing a speech to text process  the method of claim  further comprising identifying a language used in the audio portion of the multimodal file and wherein performing a speech to text process comprises performing a speech to text process in the identified language  the method of claim  further comprising translating the detected text  the method of claim  further comprising determining significant clusters and insignificant clusters in the determined clusters and wherein extracting features from the clusters in the graph comprises extracting features from the significant clusters in the graph  the method of claim  wherein extracting features from the clusters in the graph comprises at least one process selected from the list consisting of determining a graph diameter and determining a jaccard coefficient  the method of claim  wherein selecting at least one topicid to represent at least one cluster comprises based at least on the extracted features mapping topic candidates into a probability interval and based at least on the mapping ranking topic candidates within the at least one cluster and selecting the at least one topicid based at least on the ranking  the method of claim  further comprising translating the at least one topicid and wherein indexing the multimodal file with the at least one topicid comprises indexing the multimodal file with the at least one translated topicid  a system for inferring topics from a multimodal file the system comprising an entity extraction component comprising an object detection component and a speech to text component operative to extract a set of entities from a multimodal file comprising a video portion and an audio portion an entity linking component operative to link the extracted set of entities to produce a set of linked entities an information retrieval component operative to obtain reference information for the extracted set of entities a graphing and analysis component operative to generate a graph of the set of linked entities the graph comprising nodes and edges based at least on the nodes and edges of the graph determine clusters in the graph based at least on the clusters in the graph identify topic candidates and extract features from the clusters in the graph a topicid selection component operative to rank the topic candidates within at least one cluster and based at least on the ranking select at least one topicid from among the topic candidates to represent at least one cluster and a video indexer operative to index the multimodal file with the at least one topicid  the system of claim  wherein the object detection component is operative to perform face recognition  the system of claim  wherein the speech to text component is operative to extract entity information in at least two different languages  one or more computer storage devices having computer-executable instructions stored thereon for inferring topics from a multimodal file which on execution by a computer cause the computer to perform operations comprising receiving a multimodal file comprising a video portion and an audio portion extracting a set of entities from the multimodal file wherein extracting a set of entities from the multimodal file comprises detecting objects in the video portion of the multimodal file with face recognition detecting text in the audio portion of the multimodal file with a speech to text process and disambiguating among a set of detected entity names linking the set of entities to produce a set of linked entities obtaining reference information for the set of entities based at least on the reference information generating a graph of the set of linked entities the graph comprising nodes and edges based at least on the nodes and edges of the graph determining clusters in the graph determining significant clusters and insignificant clusters in the determined clusters based at least on the significant clusters in the graph identifying topic candidates extracting features from the significant clusters in the graph based at least on the extracted features mapping the topic candidates into a probability interval based at least on the mapping ranking the topic candidates within at least one significant cluster based on the ranking selecting at least one topicid from among the topic candidates to represent the at least one significant cluster and indexing the multimodal file with the at least one topicid  the one or more computer storage devices of claim  wherein the operations further comprise identifying a language used in the audio portion of the multimodal file and detecting text in the audio portion of the multimodal file with a speech to text process comprises performing a speech to text process in the identified language权利要求 、 一种人脸识别方法其特征在于包括 通过第一摄像头获取第一人脸图像 提取所述第一人脸图像的第一人脸特征 将所述第一人脸特征与预先存储的第二人脸特征进行对比获得参考相似度所述第 二人脸特征经第二摄像头获取的第二人脸图像的特征提取而得所述第二摄像头与所述第 一摄像头属于不同类型的摄像头 根据所述参考相似度确定所述第一人脸特征与所述第二人脸特征是否对应相同人。 、 根据权利要求 所述的方法其特征在于 所述第一摄像头为热成像摄像头所述第二摄像头为可见光摄像头 或者所述第一摄像头为可见光摄像头所述第一摄像头为热成像摄像头。 、 根据权利要求 或 所述的方法其特征在于所述根据所述参考相似度确定所 述第一人脸特征与所述第二人脸特征是否对应相同人包括 根据所述参考相似度、 参考误报率以及相似度阈值确定所述第一人脸特征与所述第二 人脸特征是否对应相同人其中不同的误报率对应不同的相似度阈值。 、 根据权利要求 或 所述的方法其特征在于所述根据所述参考相似度确定所 述第一人脸特征与所述第二人脸特征是否对应相同人包括 根据所述参考相似度以及阈值信息确定归一化后的参考相似度 根据所述归一化后的参考相似度确定所述第一人脸特征与所述第二人脸特征是否对 应相同人。 、 根据权利要求 -任一项所述的方法其特征在于所述提取所述第一人脸图像的 第_人脸特征包括 将所述第一人脸图像输入预先训练完成的神经网络通过所述神经网络输出所述第一 人脸图像的第一人脸特征其中所述神经网络基于第一类型图像样本和第二类型图像样 本训练得到所述第一类型图像样本和所述第二类型图像样本由不同类型的摄像头拍摄得 到且所述第一类型图像样本和所述第二类型图像样本中包括人脸。 、 根据权利要求  所述的方法其特征在于所述神经网络基于所述第一类型图像 样本、 所述第二类型图像样本和混合类型图像样本训练得到所述混合类型图像样本由所 述第一类型图像样本和所述第二类型图像样本配对而得。 、 根据权利要求 -任一项所述的方法其特征在于所述第一摄像头包括车载摄像 头所述通过第一摄像头获取第一人脸图像包括 通过所述车载摄像头获取所述第一人脸图像所述第一人脸图像包括车辆的用车人的 人脸图像。 、 根据权利要求  所述的方法其特征在于所述用车人包括驾驶所述车辆的人、 乘坐所述车辆的人、 对所述车辆进行修理的人、 给所述车辆加油的人以及控制所述车辆的 人中的一项或多项。 、 根据权利要求  所述的方法其特征在于所述用车人包括驾驶所述车辆的人 所述通过所述车载摄像头获取所述第一人脸图像包括 在接收到触发指令的情况下通过所述车载摄像头获取所述第一人脸图像 或者在所述车辆运行时通过所述车载摄像头获取所述第一人脸图像 或者在所述车辆的运行速度达到参考速度的情况下通过所述车载摄像头获取所述 第一人脸图像。 、 根据权利要求 -任一项所述的方法其特征在于所述第二人脸图像为对所述 用车人进行人脸注册的图像所述将所述第一人脸特征与预先存储的第二人脸特征进行对 比之前所述方法还包括 通过所述第二摄像头获取所述第二人脸图像 提取所述第二人脸图像的第二人脸特征 保存所述第二人脸图像的第二人脸特征。 、 一种神经网络训练方法其特征在于包括 获取第一类型图像样本和第二类型图像样本所述第一类型图像样本和所述第二类型 图像样本由不同类型的摄像头拍摄得到且所述第一类型图像样本和所述第二类型图像样 本中包括人脸 根据所述第一类型图像样本和所述第二类型图像样本训练神经网络。 、 根据权利要求 所述的方法其特征在于所述根据所述第一类型图像样本和所 述第二类型图像样本训练神经网络包括 将所述第一类型图像样本和所述第二类型图像样本配对得到所述第一类型图像样本 和所述第二类型图像样本的混合类型图像样本 根据所述第一类型图像样本、 所述第二类型图像样本和所述混合类型图像样本训练 所述神经网络。 、 根据权利要求  所述的方法其特征在于所述根据所述第一类型图像样本、 所述第二类型图像样本和所述混合类型图像样本训练所述神经网络包括 通过所述神经网络获取所述第一类型图像样本的人脸预测结果、 所述第二类型图像样 本的人脸预测结果和所述混合类型图像样本的人脸预测结果 根据所述第一类型图像样本的人脸预测结果和人脸标注结果的差异、 所述第二类型图 像样本的人脸预测结果和人脸标注结果之间的差异、 以及所述混合类型图像样本的人脸预 测结果和人脸标注结果的差异训练所述神经网络。 、 根据权利要求  所述的方法其特征在于所述神经网络中包括第一分类器、 第二分类器和混合分类器所述通过所述神经网络获取所述第一类型图像样本的人脸预测 结果、 所述第二类型图像样本的人脸预测结果和所述混合类型图像样本的人脸预测结果 包括 将所述第一类型图像样本的人脸特征输入至所述第一分类器中得到所述第一类型图 像样本的人脸预测结果 将所述第二类型图像样本的人脸特征输入至所述第二分类器中得到所述第二类型图 像样本的人脸预测结果 将所述混合类型图像样本的人脸特征输入至所述混合分类器中得到所述混合类型图 像样本的人脸预测结果。 、 根据权利要求 所述的方法其特征在于所述方法还包括 在训练完成的所述神经网络中去除所述第一分类器、 所述第二分类器和所述混合分类 器得到用于进行人脸识别的神经网络。 、 一种人脸识别装置其特征在于包括 第一获取单元用于通过第一摄像头获取第一人脸图像 第一提取单元用于提取所述第一人脸图像的第一人脸特征 对比单元用于将所述第一人脸特征与预先存储的第二人脸特征进行对比获得参考 相似度所述第二人脸特征经第二摄像头获取的第二人脸图像的特征提取而得所述第二 摄像头与所述第一摄像头属于不同类型的摄像头 确定单元用于根据所述参考相似度确定所述第一人脸特征与所述第二人脸特征是否 对应相同人。 、 根据权利要求 所述的装置其特征在于 所述第一摄像头为热成像摄像头所述第二摄像头为可见光摄像头 或者所述第一摄像头为可见光摄像头所述第一摄像头为热成像摄像头。 、 根据权利要求 或 所述的装置其特征在于 所述确定单元具体用于根据所述参考相似度、 参考误报率以及相似度阈值确定所述 第一人脸特征与所述第二人脸特征是否对应相同人其中不同的误报率对应不同的相似 度阈值。 、 根据权利要求 或 所述的装置其特征在于 所述确定单元具体用于根据所述参考相似度以及阈值信息确定归一化后的参考相似 度以及根据所述归一化后的参考相似度确定所述第一人脸特征与所述第二人脸特征是否 对应相同人。 、 根据权利要求 -任_项所述的装置其特征在于 所述第一提取单元具体用于将所述第一人脸图像输入预先训练完成的神经网络通 过所述神经网络输出所述第一人脸图像的第一人脸特征其中所述神经网络基于第一类 型图像样本和第二类型图像样本训练得到所述第一类型图像样本和所述第二类型图像样 本由不同类型的摄像头拍摄得到且所述第一类型图像样本和所述第二类型图像样本中包 括人脸。 、 根据权利要求  所述的装置其特征在于所述神经网络基于所述第一类型图 像样本、 所述第二类型图像样本和混合类型图像样本训练得到所述混合类型图像样本由 所述第一类型图像样本和所述第二类型图像样本配对而得。 、 根据权利要求 -任一项所述的装置其特征在于所述第一摄像头包括车载 摄像头 所述第一获取单元具体用于通过所述车载摄像头获取所述第一人脸图像所述第一 人脸图像包括车辆的用车人的人脸图像。 、 根据权利要求 所述的装置其特征在于所述用车人包括驾驶所述车辆的人、 乘坐所述车辆的人、 对所述车辆进行修理的人、 给所述车辆加油的人以及控制所述车辆的 人中的一项或多项。 、 根据权利要求 所述的装置其特征在于所述用车人包括驾驶所述车辆的人 所述第一获取单元具体用于在接收到触发指令的情况下通过所述车载摄像头获取所述 第一人脸图像 或者所述第一获取单元具体用于在所述车辆运行时通过所述车载摄像头获取所 述第 _人脸图像 或者所述第一获取单元具体用于在所述车辆的运行速度达到参考速度的情况下 通过所述车载摄像头获取所述第一人脸图像。 、 根据权利要求 -任一项所述的装置其特征在于所述第二人脸图像为对所 述用车人进行人脸注册的图像所述装置还包括 第二获取单元用于通过所述第二摄像头获取所述第二人脸图像 第二提取单元用于提取所述第二人脸图像的第二人脸特征 保存单元用于保存所述第二人脸图像的第二人脸特征。 、 一种神经网络训练装置其特征在于包括 获取单元用于获取第一类型图像样本和第二类型图像样本所述第一类型图像样本 和所述第二类型图像样本由不同类型的摄像头拍摄得到且所述第一类型图像样本和所述 第二类型图像样本中包括人脸 训练单元用于根据所述第一类型图像样本和所述第二类型图像样本训练神经网络。 、 根据权利要求 所述的装置其特征在于所述训练单元包括 配对子单元用于将所述第一类型图像样本和所述第二类型图像样本配对得到所述 第一类型图像样本和所述第二类型图像样本的混合类型图像样本 训练子单元用于根据所述第一类型图像样本、 所述第二类型图像样本和所述混合类 型图像样本训练所述神经网络。 、 根据权利要求 所述的装置其特征在于 所述训练子单元具体用于通过所述神经网络获取所述第一类型图像样本的人脸预测 结果、 所述第二类型图像样本的人脸预测结果和所述混合类型图像样本的人脸预测结果 以及根据所述第一类型图像样本的人脸预测结果和人脸标注结果的差异、 所述第二类型图 像样本的人脸预测结果和人脸标注结果之间的差异、 以及所述混合类型图像样本的人脸预 测结果和人脸标注结果的差异训练所述神经网络。 、 根据权利要求  所述的装置其特征在于所述神经网络中包括第一分类器、 第二分类器和混合分类器 所述训练子单元具体用于将所述第一类型图像样本的人脸特征输入至所述第一分类 器中得到所述第一类型图像样本的人脸预测结果以及将所述第二类型图像样本的人脸 特征输入至所述第二分类器中得到所述第二类型图像样本的人脸预测结果以及将所述 混合类型图像样本的人脸特征输入至所述混合分类器中得到所述混合类型图像样本的人 脸预测结果。 、 根据权利要求 所述的装置其特征在于所述装置还包括 神经网络应用单元用于在训练完成的所述神经网络中去除所述第一分类器、 所述第 二分类器和所述混合分类器得到用于进行人脸识别的神经网络。 、 一种电子设备其特征在于包括处理器和存储器所述处理器和所述存储器耦 合其中所述存储器用于存储程序指令所述程序指令被所述处理器执行时使所述处 理器执行权利要求 -任一项所述的方法和或使所述处理器执行权利要求 -任一 项所述的方法。 、 一种计算机可读存储介质其特征在于所述计算机可读存储介质中存储有计算 机程序所述计算机程序包括程序指令所述程序指令当被处理器执行时使所述处理器 执行权利要求 -任一项所述的方法和或使所述处理器执行权利要求 -任一项所 述的方法。 a system for alerting on vision impairment said system comprising a processing unit configured and operable for receiving scene data being indicative of a scene of at least one consumer in an environment identifying in the scene data a certain consumer identifying an event being indicative of a behavioral compensation for vision impairment and upon identification of such an event sending a notification relating to the vision impairment  the system of claim  further comprising at least one sensing unit configured and operable for detecting the scene data  the system of claim  wherein said at least one sensing unit comprises at least one of at least one imaging unit configured and operable for capturing at least one image of at least a portion of a consumer\\'s body at least one motion detector configured and operable for detecting consumer data being indicative of a motion of a consumer or at least one eye tracker configured and operable for tracking eye motion of a consumer  the system of claim  wherein the at least one imaging unit comprises a plurality of cameras placed at different heights  the system of any one of claims  to  wherein said sensing unit is accommodated in an optical or digital eyewear frame display  the system of any one of claims  to  wherein said processing unit is configured and operable for identifying a consumer\\'s condition said consumer\\'s condition comprising consumer data being indicative of the consumer\\'s position and location relative to at least one object in the consumer\\'s environment said consumer data comprises at least one of a consumer\\'s face eyewear posture position sound or motion  the system of any one of claims  to  wherein said event comprises at least one position and orientation of head increase or decrease of viewing distance between the consumer and viewed object and changing the position of eyeglasses worn by the consumer  the system of any one of claims  to  wherein said event is identified by identifying images having an image feature being indicative of behavioral compensation performing a bruckner test performing a hirschberg test and measuring blink count frequency  the system of claim  wherein the image feature being indicative of behavioral compensation comprises squinting head orientation certain distances between an object and consumer\\'s eyes certain position of eyeglasses on the consumer\\'s face strabismus cataracts and reflections from the eye  the system of any one of claims  to  wherein the notification includes at least one of the data indicative of the identified event data indicative of the identified consumer ophthalmologic recommendations based on the identified event or lack of events or an appointment for a vision test  the system of any one of claims  to  wherein said processing unit comprises a memory for storing at least one of a reference data indicative of behavioral compensation for vision impairment data indicative of the notification or data indicative of a follow-up of the notification  the system of claim   wherein said processing unit is configured for at least one of identifying the event upon comparison between the detected data and the reference data or determining a probability for a vision impairment of the consumer based on the comparison  the system of any one of claims  to  wherein said processing unit comprises a communication interface being configured for sending the notification to at least one of the identified consumer or a third party  the system of any one of claims  to  wherein said processing unit is configured for providing a frame recommendation  the system of any one of claims  to  wherein said memory is configured for storing a database including a multiplicity of data sets related to a plurality of spectacle frame models and sizes  the system according to claim  or  wherein said processing unit is configured and operable to correlate between frames parameters and ophthalmic prescriptions  the system according to any of claims  to  wherein said processing unit is configured and operable to correlate between frames parameters and facial features  the system according to any of claims  to  wherein said processing unit is configured and operable to correlate between frames parameters and eyewear preferences  the system according to any of claims  to  comprising a server and at least one computer entity linked to the server via a network wherein said network is configured to receive and respond to requests sent across the network transmitting one or more modules of computer executable program instructions and displayable data to the network connected user computer platform in response to a request wherein said modules include modules configured to receive and transmit image information transmitting a frame recommendation and an optical lens option recommendation based on received image information for display by the network connected user computer platform  a computer program instructions stored in the local storage that when executed by a processing unit cause the processing unit to receive data being indicative of a scene of at least one consumer in an environment identify in the data a certain consumer identify an event being indicative of a behavioral compensation for vision impairment and upon identification of such an event send a notification relating to the vision impairment  a computer program product stored on a tangible computer readable medium comprising a library of software modules which cause a computer executing them to prompt for information pertinent to at least one of an eyeglasses recommendation and an optical lens option recommendation to store said information or to display eyewear recommendations   the computer program product of claim   wherein said library further comprises a module for frame selection point of sales and advertising  a computer platform for facilitating eye glasses marketing or selection comprising a camera a processor configured to execute computer program instructions to cause the processor to take an image of a consumer identify in the image a certain consumer identify an event being indicative of a behavioral compensation for vision impairment and upon identification of such an event sending a notification relating to the vision impairment local storage for processor executable instructions for carrying out storage of information  a method for alerting on vision impairment said method comprising identifying a certain individual in scene data being indicative of a scene of at least one consumer in an environment identifying an event being indicative of a behavioral compensation for vision impairment and upon identification of such an event sending a notification on the vision impairment  the method of claim  further comprising detecting data being indicative of a scene of at least one consumer in a retail environment  the method of claim  wherein detecting the data being indicative of at least one consumer comprises at least one of capturing at least one image of at least one consumer detecting data being indicative of a motion of a consumer or tracking an eye motion of a consumer  the method of claim  wherein capturing at least one image of at least one consumer comprises continuously recording a scene  the method of any one of claims  to  further comprising identifying in the data the consumer\\' s condition including data being indicative of the consumer\\'s position and location relative to the consumer\\'s environment said data comprising at least one of the consumer\\'s face posture position sound or motion  the method of any one of claims  to  wherein said event comprises at least one of position and orientation of head increase or decrease of viewing distance between the consumer and viewed object or changing the position of eyeglasses worn by the consumer  the method of any one of claims  to  wherein identifying of the event comprises identifying images having an image feature being indicative of behavioral compensation performing a bruckner test performing a hirschberg test and measuring blink countfrequency  the method of claim  wherein the image feature being indicative of behavioral compensation comprises squinting head orientation certain distances between an object and a consumer\\'s eyes certain position of eyeglasses on the consumer\\'s face strabismus cataracts and reflections from the eye  the method of any one of claims  to  wherein identifying in the at least one image a consumer in a retail environment comprising at least one of receiving data characterizing the retail environment or performing face recognition  the method of any one of claims  to  wherein sending a notification comprising sending the notification to at least one of the identified consumer or a third party  the method of any one of claims  to  wherein the notification includes at least one of the data indicative of the identified event data indicative of the identified consumer ophthalmologic recommendations based on the identified event or lack of events and an appointment for a vision test  the method of any one of claims  to  further comprising storing at least one of a reference data indicative of behavioral compensation for vision impairment data indicative of the notification or data indicative of a follow-up of the notification  the method of claim  further comprising identifying the event upon comparison between the detected data and the reference data and determining a probability for a vision impairment of the consumer based on the comparison  a computer program intended to be stored in a memory of a processor unit of a computer system or in a removable memory medium adapted to cooperate with a reader of the processor unit comprising instructions for implementing the method according to any of claims  to']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "# the output is a list, where each element is a sentence of the original text\n",
    "nltk.sent_tokenize(lowera_text)\n",
    "nltk.sent_tokenize(lowerc_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d1afb3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['an', 'electronic', 'apparatus', 'including', 'an', 'image', 'capturing', 'device', 'a', 'storage', 'device', 'and', 'a', 'processor', 'and', 'an', 'operation', 'method', 'thereof', 'are', 'provided', 'the', 'image', 'capturing', 'device', 'captures', 'an', 'image', 'for', 'a', 'user', 'and', 'the', 'storage', 'device', 'records', 'a', 'plurality', 'of', 'modules', 'the', 'processor', 'is', 'coupled', 'to', 'the', 'image', 'capturing', 'device', 'and', 'the', 'storage', 'device', 'and', 'is', 'configured', 'to', 'configure', 'the', 'image', 'capturing', 'device', 'to', 'capture', 'a', 'head', 'image', 'of', 'a', 'user', 'perform', 'a', 'face', 'recognition', 'operation', 'to', 'obtain', 'a', 'face', 'region', 'detect', 'a', 'plurality', 'of', 'facial', 'landmarks', 'within', 'the', 'face', 'region', 'estimate', 'a', 'head', 'posture', 'angle', 'of', 'the', 'user', 'according', 'to', 'the', 'facial', 'landmarks', 'calculate', 'a', 'gaze', 'position', 'where', 'the', 'user', 'gazes', 'on', 'the', 'screen', 'according', 'to', 'the', 'head', 'posture', 'angle', 'a', 'plurality', 'of', 'rotation', 'reference', 'angle', 'and', 'a', 'plurality', 'of', 'predetermined', 'calibration', 'positions', 'and', 'configure', 'the', 'screen', 'to', 'display', 'a', 'corresponding', 'visual', 'effect', 'according', 'to', 'the', 'gaze', 'positionthe', 'present', 'disclosure', 'provides', 'a', 'computation', 'method', 'and', 'product', 'thereof', 'the', 'computation', 'method', 'adopts', 'a', 'fusion', 'method', 'to', 'perform', 'machine', 'learning', 'computations', 'technical', 'effects', 'of', 'the', 'present', 'disclosure', 'include', 'fewer', 'computations', 'and', 'less', 'power', 'consumptiona', 'method', 'for', 'detecting', 'body', 'information', 'on', 'passengers', 'of', 'a', 'vehicle', 'based', 'on', 'humans', \"'\", 'status', 'recognition', 'is', 'provided', 'the', 'method', 'includes', 'steps', 'of', 'a', 'passenger', 'body', 'information-detecting', 'device', 'a', 'inputting', 'an', 'interior', 'image', 'of', 'the', 'vehicle', 'into', 'a', 'face', 'recognition', 'network', 'to', 'detect', 'faces', 'of', 'the', 'passengers', 'and', 'output', 'passenger', 'feature', 'information', 'and', 'inputting', 'the', 'interior', 'image', 'into', 'a', 'body', 'recognition', 'network', 'to', 'detect', 'bodies', 'and', 'output', 'body-part', 'length', 'information', 'and', 'b', 'retrieving', 'specific', 'height', 'mapping', 'information', 'by', 'referring', 'to', 'a', 'height', 'mapping', 'table', 'of', 'ratios', 'of', 'segment', 'body', 'portions', 'of', 'human', 'groups', 'to', 'heights', 'per', 'the', 'human', 'groups', 'acquiring', 'a', 'specific', 'height', 'of', 'the', 'specific', 'passenger', 'retrieving', 'specific', 'weight', 'mapping', 'information', 'from', 'a', 'weight', 'mapping', 'table', 'of', 'correlations', 'between', 'the', 'heights', 'and', 'weights', 'per', 'the', 'human', 'groups', 'and', 'acquiring', 'a', 'weight', 'of', 'the', 'specific', 'passenger', 'by', 'referring', 'to', 'the', 'specific', 'heighttechniques', 'related', 'to', 'improved', 'video', 'coding', 'based', 'on', 'face', 'detection', 'region', 'extraction', 'and', 'tracking', 'are', 'discussed', 'such', 'techniques', 'may', 'include', 'performing', 'a', 'facial', 'search', 'of', 'a', 'video', 'frame', 'to', 'determine', 'candidate', 'face', 'regions', 'in', 'the', 'video', 'frame', 'testing', 'the', 'candidate', 'face', 'regions', 'based', 'on', 'skin', 'tone', 'information', 'to', 'determine', 'valid', 'and', 'invalid', 'face', 'regions', 'rejecting', 'invalid', 'face', 'regions', 'and', 'encoding', 'the', 'video', 'frame', 'based', 'on', 'valid', 'face', 'regions', 'to', 'generate', 'a', 'coded', 'bitstreama', 'method', 'for', 'managing', 'a', 'smart', 'database', 'which', 'stores', 'facial', 'images', 'for', 'face', 'recognition', 'is', 'provided', 'the', 'method', 'includes', 'steps', 'of', 'a', 'managing', 'device', 'a', 'counting', 'specific', 'facial', 'images', 'corresponding', 'to', 'a', 'specific', 'person', 'in', 'the', 'smart', 'database', 'where', 'new', 'facial', 'images', 'are', 'continuously', 'stored', 'and', 'determining', 'whether', 'a', 'first', 'counted', 'value', 'representing', 'a', 'count', 'of', 'the', 'specific', 'facial', 'images', 'satisfies', 'a', 'first', 'set', 'value', 'and', 'b', 'if', 'the', 'first', 'counted', 'value', 'satisfies', 'the', 'first', 'set', 'value', 'inputting', 'the', 'specific', 'facial', 'images', 'into', 'a', 'neural', 'aggregation', 'network', 'to', 'generate', 'quality', 'scores', 'of', 'the', 'specific', 'facial', 'images', 'by', 'aggregation', 'of', 'the', 'specific', 'facial', 'images', 'and', 'if', 'a', 'second', 'counted', 'value', 'representing', 'a', 'count', 'of', 'specific', 'quality', 'scores', 'among', 'the', 'quality', 'scores', 'from', 'a', 'highest', 'during', 'counting', 'thereof', 'satisfies', 'a', 'second', 'set', 'value', 'deleting', 'part', 'of', 'the', 'specific', 'facial', 'images', 'corresponding', 'to', 'the', 'uncounted', 'quality', 'scores', 'from', 'the', 'smart', 'databasea', 'system', 'capable', 'of', 'determining', 'which', 'recognition', 'algorithms', 'should', 'be', 'applied', 'to', 'regions', 'of', 'interest', 'within', 'digital', 'representations', 'is', 'presented', 'a', 'preprocessing', 'module', 'utilizes', 'one', 'or', 'more', 'feature', 'identification', 'algorithms', 'to', 'determine', 'regions', 'of', 'interest', 'based', 'on', 'feature', 'density', 'the', 'preprocessing', 'modules', 'leverages', 'the', 'feature', 'density', 'signature', 'for', 'each', 'region', 'to', 'determine', 'which', 'of', 'a', 'plurality', 'of', 'diverse', 'recognition', 'modules', 'should', 'operate', 'on', 'the', 'region', 'of', 'interest', 'a', 'specific', 'embodiment', 'that', 'focuses', 'on', 'structured', 'documents', 'is', 'also', 'presented', 'further', 'the', 'disclosed', 'approach', 'can', 'be', 'enhanced', 'by', 'addition', 'of', 'an', 'object', 'classifier', 'that', 'classifies', 'types', 'of', 'objects', 'found', 'in', 'the', 'regions', 'of', 'interestdisclosed', 'is', 'a', 'mobile', 'terminal', 'the', 'mobile', 'terminal', 'may', 'include', 'a', 'front', 'camera', 'obtaining', 'a', 'd', 'face', 'image', 'of', 'a', 'user', 'a', 'glance', 'sensor', 'tilted', 'by', 'a', 'certain', 'angle', 'and', 'disposed', 'adjacent', 'to', 'the', 'front', 'camera', 'to', 'obtain', 'metadata', 'of', 'the', 'd', 'face', 'image', 'and', 'a', 'controller', 'obtaining', 'a', 'distance', 'between', 'the', 'glance', 'sensor', 'and', 'the', 'front', 'camera', 'the', 'distance', 'enabling', 'an', 'area', 'of', 'an', 'overlap', 'region', 'where', 'a', 'first', 'region', 'representing', 'a', 'range', 'photographable', 'by', 'the', 'front', 'camera', 'overlaps', 'a', 'second', 'region', 'representing', 'a', 'range', 'photographable', 'by', 'the', 'glance', 'sensor', 'to', 'be', 'the', 'maximumthis', 'disclosure', 'provides', 'systems', 'methods', 'and', 'apparatus', 'including', 'computer', 'programs', 'encoded', 'on', 'computer', 'storage', 'media', 'for', 'intelligent', 'routing', 'of', 'notifications', 'related', 'to', 'media', 'programming', 'in', 'one', 'aspect', 'a', 'smart', 'television', 'tv', 'can', 'be', 'implemented', 'to', 'track', 'a', 'user', \"'s\", 'tv', 'watching', 'behavior', 'and', 'anticipate', 'programming', 'based', 'on', 'that', 'behavior', 'in', 'some', 'other', 'aspects', 'the', 'smart', 'tv', 'can', 'be', 'implemented', 'to', 'detect', 'a', 'user', \"'s\", 'presence', 'and', 'based', 'on', 'that', 'detection', 'can', 'automatically', 'change', 'the', 'tv', 'channel', 'to', 'media', 'programming', 'analyzed', 'to', 'be', 'desirable', 'to', 'the', 'user', 'in', 'some', 'further', 'aspects', 'the', 'smart', 'tv', 'can', 'be', 'implemented', 'to', 'transmit', 'notification', 'instructions', 'to', 'electronic', 'devices', 'within', 'a', 'network', 'in', 'an', 'attempt', 'to', 'alert', 'the', 'user', 'to', 'upcoming', 'media', 'programming', 'additionally', 'the', 'smart', 'tv', 'can', 'be', 'implemented', 'to', 'transmit', 'detection', 'instructions', 'to', 'the', 'electronic', 'devices', 'within', 'the', 'network', 'whereby', 'the', 'electronic', 'devices', 'attempt', 'to', 'detect', 'a', 'user', \"'s\", 'presence', 'through', 'voice', 'or', 'facial', 'recognitiona', 'camera', 'is', 'configured', 'to', 'output', 'a', 'test', 'depth+multi-spectral', 'image', 'including', 'a', 'plurality', 'of', 'pixels', 'each', 'pixel', 'corresponds', 'to', 'one', 'of', 'the', 'plurality', 'of', 'sensors', 'of', 'a', 'sensor', 'array', 'of', 'the', 'camera', 'and', 'includes', 'at', 'least', 'a', 'depth', 'value', 'and', 'a', 'spectral', 'value', 'for', 'each', 'spectral', 'light', 'sub-band', 'of', 'a', 'plurality', 'of', 'spectral', 'illuminators', 'of', 'the', 'camera', 'a', 'face', 'recognition', 'machine', 'is', 'previously', 'trained', 'with', 'a', 'set', 'of', 'labeled', 'training', 'depth+multi-spectral', 'images', 'having', 'a', 'same', 'structure', 'as', 'the', 'test', 'depth+multi-spectral', 'image', 'the', 'face', 'recognition', 'machine', 'is', 'configured', 'to', 'output', 'a', 'confidence', 'value', 'indicating', 'a', 'likelihood', 'that', 'the', 'test', 'depth+multi-spectral', 'image', 'includes', 'a', 'faceembodiments', 'of', 'the', 'present', 'disclosure', 'relate', 'to', 'an', 'image', 'processing', 'method', 'and', 'apparatus', 'and', 'an', 'electronic', 'device', 'the', 'method', 'includes', 'acquiring', 'a', 'photo', 'album', 'obtained', 'from', 'face', 'clustering', 'collecting', 'face', 'information', 'of', 'respective', 'images', 'in', 'the', 'photo', 'album', 'and', 'acquiring', 'a', 'face', 'parameter', 'of', 'each', 'image', 'according', 'to', 'the', 'face', 'information', 'selecting', 'a', 'cover', 'image', 'according', 'to', 'the', 'face', 'parameter', 'of', 'each', 'image', 'and', 'taking', 'a', 'face-region', 'image', 'from', 'the', 'cover', 'image', 'and', 'setting', 'the', 'face-region', 'image', 'as', 'a', 'cover', 'of', 'the', 'photo', 'albumtechniques', 'described', 'herein', 'provide', 'location-based', 'access', 'control', 'to', 'secured', 'resources', 'generally', 'described', 'configurations', 'disclosed', 'herein', 'enable', 'a', 'system', 'to', 'dynamically', 'modify', 'access', 'to', 'secured', 'resources', 'based', 'on', 'one', 'or', 'more', 'location-related', 'actions', 'for', 'example', 'techniques', 'disclosed', 'herein', 'can', 'enable', 'a', 'computing', 'system', 'to', 'control', 'access', 'to', 'resources', 'such', 'as', 'computing', 'devices', 'display', 'devices', 'secured', 'locations', 'and', 'secured', 'data', 'in', 'some', 'configurations', 'the', 'techniques', 'disclosed', 'herein', 'can', 'enable', 'controlled', 'access', 'to', 'secured', 'resources', 'based', 'at', 'least', 'in', 'part', 'on', 'an', 'invitation', 'associated', 'with', 'a', 'location', 'and', 'positioning', 'data', 'indicating', 'a', 'location', 'of', 'a', 'userone', 'embodiment', 'provides', 'a', 'method', 'comprising', 'receiving', 'a', 'piece', 'of', 'content', 'and', 'salient', 'moments', 'data', 'for', 'the', 'piece', 'of', 'content', 'the', 'method', 'further', 'comprises', 'based', 'on', 'the', 'salient', 'moments', 'data', 'determining', 'a', 'first', 'path', 'for', 'a', 'viewport', 'for', 'the', 'piece', 'of', 'content', 'the', 'method', 'further', 'comprises', 'displaying', 'the', 'viewport', 'on', 'a', 'display', 'device', 'movement', 'of', 'the', 'viewport', 'is', 'based', 'on', 'the', 'first', 'path', 'during', 'playback', 'of', 'the', 'piece', 'of', 'content', 'the', 'method', 'further', 'comprises', 'generating', 'an', 'augmentation', 'for', 'a', 'salient', 'moment', 'occurring', 'in', 'the', 'piece', 'of', 'content', 'and', 'presenting', 'the', 'augmentation', 'in', 'the', 'viewport', 'during', 'a', 'portion', 'of', 'the', 'playback', 'the', 'augmentation', 'comprises', 'an', 'interactive', 'hint', 'for', 'guiding', 'the', 'viewport', 'to', 'the', 'salient', 'momenta', 'computer-implemented', 'method', 'system', 'and', 'computer', 'program', 'product', 'are', 'provided', 'for', 'facial', 'recognition', 'the', 'method', 'includes', 'receiving', 'by', 'a', 'processor', 'device', 'a', 'plurality', 'of', 'images', 'the', 'method', 'also', 'includes', 'extracting', 'by', 'the', 'processor', 'device', 'with', 'a', 'feature', 'extractor', 'utilizing', 'a', 'convolutional', 'neural', 'network', 'cnn', 'with', 'an', 'enlarged', 'intra-class', 'variance', 'of', 'long-tail', 'classes', 'feature', 'vectors', 'for', 'each', 'of', 'the', 'plurality', 'of', 'images', 'the', 'method', 'additionally', 'includes', 'generating', 'by', 'the', 'processor', 'device', 'with', 'a', 'feature', 'generator', 'discriminative', 'feature', 'vectors', 'for', 'each', 'of', 'the', 'feature', 'vectors', 'the', 'method', 'further', 'includes', 'classifying', 'by', 'the', 'processor', 'device', 'utilizing', 'a', 'fully', 'connected', 'classifier', 'an', 'identity', 'from', 'the', 'discriminative', 'feature', 'vector', 'the', 'method', 'also', 'includes', 'control', 'an', 'operation', 'of', 'a', 'processor-based', 'machine', 'to', 'react', 'in', 'accordance', 'with', 'the', 'identitysome', 'embodiments', 'of', 'the', 'invention', 'provide', 'efficient', 'expressive', 'machine-trained', 'networks', 'for', 'performing', 'machine', 'learning', 'the', 'machine-trained', 'mt', 'networks', 'of', 'some', 'embodiments', 'use', 'novel', 'processing', 'nodes', 'with', 'novel', 'activation', 'functions', 'that', 'allow', 'the', 'mt', 'network', 'to', 'efficiently', 'define', 'with', 'fewer', 'processing', 'node', 'layers', 'a', 'complex', 'mathematical', 'expression', 'that', 'solves', 'a', 'particular', 'problem', 'eg', 'face', 'recognition', 'speech', 'recognition', 'etc', 'in', 'some', 'embodiments', 'the', 'same', 'activation', 'function', 'eg', 'a', 'cup', 'function', 'is', 'used', 'for', 'numerous', 'processing', 'nodes', 'of', 'the', 'mt', 'network', 'but', 'through', 'the', 'machine', 'learning', 'this', 'activation', 'function', 'is', 'configured', 'differently', 'for', 'different', 'processing', 'nodes', 'so', 'that', 'different', 'nodes', 'can', 'emulate', 'or', 'implement', 'two', 'or', 'more', 'different', 'functions', 'eg', 'two', 'or', 'more', 'boolean', 'logical', 'operators', 'such', 'as', 'xor', 'and', 'and', 'the', 'activation', 'function', 'in', 'some', 'embodiments', 'is', 'a', 'periodic', 'function', 'that', 'can', 'be', 'configured', 'to', 'implement', 'different', 'functions', 'eg', 'different', 'sinusoidal', 'functionsmethods', 'and', 'systems', 'may', 'provide', 'for', 'facial', 'recognition', 'of', 'at', 'least', 'one', 'input', 'image', 'utilizing', 'hierarchical', 'feature', 'learning', 'and', 'pair-wise', 'classification', 'receptive', 'field', 'theory', 'may', 'be', 'used', 'on', 'the', 'input', 'image', 'to', 'generate', 'a', 'pre-processed', 'multi-channel', 'image', 'channels', 'in', 'the', 'pre-processed', 'image', 'may', 'be', 'activated', 'based', 'on', 'the', 'amount', 'of', 'feature', 'rich', 'details', 'within', 'the', 'channels', 'similarly', 'local', 'patches', 'may', 'be', 'activated', 'based', 'on', 'the', 'discriminant', 'features', 'within', 'the', 'local', 'patches', 'features', 'may', 'be', 'extracted', 'from', 'the', 'local', 'patches', 'and', 'the', 'most', 'discriminant', 'features', 'may', 'be', 'selected', 'in', 'order', 'to', 'perform', 'feature', 'matching', 'on', 'pair', 'sets', 'the', 'system', 'may', 'utilize', 'patch', 'feature', 'pooling', 'pair-wise', 'matching', 'and', 'large-scale', 'training', 'in', 'order', 'to', 'quickly', 'and', 'accurately', 'perform', 'facial', 'recognition', 'at', 'a', 'low', 'cost', 'for', 'both', 'system', 'memory', 'and', 'computationa', 'method', 'for', 'controlling', 'a', 'terminal', 'is', 'provided', 'the', 'terminal', 'includes', 'a', 'capturing', 'apparatus', 'and', 'at', 'least', 'one', 'processor', 'an', 'image', 'is', 'acquired', 'by', 'the', 'capturing', 'apparatus', 'a', 'motion', 'parameter', 'of', 'the', 'terminal', 'is', 'obtained', 'image', 'processing', 'on', 'the', 'acquired', 'image', 'is', 'controlled', 'to', 'be', 'performed', 'based', 'on', 'the', 'motion', 'parameter', 'being', 'equal', 'to', 'or', 'less', 'than', 'a', 'preset', 'parameter', 'threshold', 'and', 'skipped', 'based', 'on', 'the', 'motion', 'parameter', 'being', 'greater', 'than', 'the', 'preset', 'parameter', 'thresholda', 'drive-through', 'order', 'processing', 'method', 'and', 'apparatus', 'are', 'disclosed', 'the', 'drive-through', 'order', 'processing', 'method', 'includes', 'receiving', 'customer', 'information', 'detected', 'through', 'vision', 'recognition', 'providing', 'product', 'information', 'based', 'on', 'the', 'customer', 'information', 'and', 'processing', 'a', 'product', 'order', 'of', 'a', 'customer', 'according', 'to', 'the', 'present', 'disclosure', 'it', 'is', 'possible', 'to', 'rapidly', 'process', 'an', 'order', 'using', 'customer', 'information', 'based', 'on', 'customer', 'recognition', 'using', 'an', 'artificial', 'intelligence', 'ai', 'model', 'of', 'machine', 'learning', 'through', 'a', 'g', 'networkan', 'image', 'processing', 'method', 'performed', 'at', 'a', 'computing', 'device', 'includes', 'identifying', 'using', 'face', 'recognition', 'one', 'or', 'more', 'faces', 'each', 'face', 'corresponding', 'to', 'a', 'respective', 'person', 'captured', 'in', 'a', 'first', 'image', 'for', 'each', 'identified', 'face', 'extracting', 'a', 'set', 'of', 'profile', 'parameters', 'of', 'a', 'corresponding', 'person', 'in', 'the', 'first', 'image', 'and', 'selecting', 'from', 'a', 'plurality', 'of', 'image', 'tiles', 'a', 'first', 'image', 'tile', 'that', 'matches', 'the', 'face', 'of', 'the', 'corresponding', 'person', 'in', 'the', 'first', 'image', 'in', 'accordance', 'with', 'a', 'predefined', 'correspondence', 'between', 'the', 'set', 'of', 'profile', 'parameters', 'of', 'the', 'corresponding', 'person', 'and', 'a', 'set', 'of', 'pre-stored', 'description', 'parameters', 'of', 'the', 'first', 'image', 'tile', 'generating', 'a', 'second', 'image', 'by', 'covering', 'the', 'faces', 'of', 'respective', 'persons', 'in', 'the', 'first', 'image', 'with', 'their', 'corresponding', 'first', 'image', 'tiles', 'and', 'sharing', 'the', 'first', 'image', 'and', 'the', 'second', 'image', 'in', 'a', 'predefined', 'order', 'via', 'a', 'group', 'chat', 'sessionin', 'one', 'embodiment', 'the', 'artificial', 'reality', 'system', 'determines', 'that', 'a', 'performance', 'metric', 'of', 'an', 'eye', 'tracking', 'system', 'is', 'below', 'a', 'first', 'performance', 'threshold', 'the', 'eye', 'tracking', 'system', 'is', 'associated', 'with', 'a', 'head-mounted', 'display', 'worn', 'by', 'a', 'user', 'the', 'artificial', 'reality', 'system', 'receives', 'first', 'inputs', 'associated', 'with', 'the', 'body', 'of', 'a', 'user', 'and', 'determines', 'a', 'region', 'that', 'the', 'user', 'is', 'looking', 'at', 'within', 'a', 'field', 'of', 'view', 'of', 'a', 'head-mounted', 'display', 'based', 'on', 'the', 'received', 'first', 'inputs', 'the', 'system', 'determines', 'a', 'vergence', 'distance', 'of', 'the', 'user', 'based', 'at', 'least', 'on', 'the', 'first', 'inputs', 'associated', 'with', 'the', 'body', 'of', 'the', 'user', 'the', 'region', 'that', 'the', 'user', 'is', 'looking', 'at', 'and', 'locations', 'of', 'one', 'or', 'more', 'objects', 'in', 'a', 'scene', 'displayed', 'by', 'the', 'head-mounted', 'display', 'the', 'system', 'adjusts', 'one', 'or', 'more', 'configurations', 'of', 'the', 'head-mounted', 'display', 'based', 'on', 'the', 'determined', 'vergence', 'distance', 'of', 'the', 'usera', 'computer-implemented', 'method', 'is', 'provided', 'for', 'image-based', 'self-guided', 'object', 'detection', 'the', 'method', 'includes', 'receiving', 'by', 'a', 'processor', 'device', 'a', 'set', 'of', 'images', 'each', 'of', 'the', 'images', 'has', 'a', 'respective', 'grid', 'thereon', 'that', 'is', 'labeled', 'regarding', 'a', 'respective', 'object', 'to', 'be', 'detected', 'using', 'grid', 'level', 'label', 'data', 'the', 'method', 'further', 'includes', 'training', 'by', 'the', 'processor', 'device', 'a', 'grid-based', 'object', 'detector', 'using', 'the', 'grid', 'level', 'label', 'data', 'the', 'method', 'also', 'includes', 'determining', 'by', 'the', 'processor', 'device', 'a', 'respective', 'bounding', 'box', 'for', 'the', 'respective', 'object', 'in', 'each', 'of', 'the', 'images', 'by', 'applying', 'local', 'segmentation', 'to', 'each', 'of', 'the', 'images', 'the', 'method', 'additionally', 'includes', 'training', 'by', 'the', 'processor', 'device', 'a', 'region-based', 'convolutional', 'neural', 'network', 'rcnn', 'for', 'joint', 'object', 'localization', 'and', 'object', 'classification', 'using', 'the', 'respective', 'bounding', 'box', 'for', 'the', 'respective', 'object', 'in', 'each', 'of', 'the', 'images', 'as', 'an', 'input', 'to', 'the', 'rcnna', 'system', 'and', 'method', 'of', 'face', 'recognition', 'comprising', 'multiple', 'phases', 'implemented', 'in', 'a', 'parallel', 'architecture', 'the', 'first', 'phase', 'is', 'a', 'normalization', 'phase', 'whereby', 'a', 'captured', 'image', 'is', 'normalized', 'to', 'the', 'same', 'size', 'orientation', 'and', 'illumination', 'of', 'stored', 'images', 'in', 'a', 'preexisting', 'database', 'the', 'second', 'phase', 'is', 'a', 'feature', 'extractiondistance', 'matrix', 'phase', 'where', 'a', 'distance', 'matrix', 'is', 'generated', 'for', 'the', 'captured', 'image', 'in', 'a', 'coarse', 'recognition', 'phase', 'the', 'generated', 'distance', 'matrix', 'is', 'compared', 'with', 'distance', 'matrices', 'in', 'the', 'database', 'using', 'euclidean', 'distance', 'matches', 'to', 'create', 'candidate', 'lists', 'and', 'in', 'a', 'detailed', 'recognition', 'phase', 'multiple', 'face', 'recognition', 'algorithms', 'are', 'applied', 'to', 'the', 'candidate', 'lists', 'to', 'produce', 'a', 'final', 'result', 'the', 'distance', 'matrices', 'in', 'the', 'normalized', 'database', 'may', 'be', 'broken', 'into', 'parallel', 'lists', 'for', 'parallelization', 'in', 'the', 'feature', 'extractiondistance', 'matrix', 'phase', 'and', 'the', 'candidate', 'lists', 'may', 'also', 'be', 'grouped', 'according', 'to', 'a', 'dissimilarity', 'algorithm', 'for', 'parallel', 'processing', 'in', 'the', 'detailed', 'recognition', 'phasean', 'imaging', 'device', 'including', 'a', 'pixel', 'matrix', 'and', 'a', 'processor', 'is', 'provided', 'the', 'pixel', 'matrix', 'includes', 'a', 'plurality', 'of', 'phase', 'detection', 'pixels', 'and', 'a', 'plurality', 'of', 'regular', 'pixels', 'the', 'processor', 'performs', 'autofocusing', 'according', 'to', 'pixel', 'data', 'of', 'the', 'phase', 'detection', 'pixels', 'and', 'determines', 'an', 'operating', 'resolution', 'of', 'the', 'regular', 'pixels', 'according', 'to', 'autofocused', 'pixel', 'data', 'of', 'the', 'phase', 'detection', 'pixels', 'wherein', 'the', 'phase', 'detection', 'pixels', 'are', 'always-on', 'pixels', 'and', 'the', 'regular', 'pixels', 'are', 'selectively', 'turned', 'on', 'after', 'the', 'autofocusing', 'is', 'accomplishedan', 'apparatus', 'includes', 'a', 'first', 'camera', 'module', 'providing', 'a', 'first', 'image', 'of', 'an', 'object', 'with', 'a', 'first', 'field', 'of', 'view', 'a', 'second', 'camera', 'module', 'providing', 'a', 'second', 'image', 'of', 'the', 'object', 'with', 'a', 'second', 'field', 'of', 'view', 'different', 'from', 'the', 'first', 'field', 'of', 'view', 'a', 'first', 'depth', 'map', 'generator', 'that', 'generates', 'a', 'first', 'depth', 'map', 'of', 'the', 'first', 'image', 'based', 'on', 'the', 'first', 'image', 'and', 'the', 'second', 'image', 'and', 'a', 'second', 'depth', 'map', 'generator', 'that', 'generates', 'a', 'second', 'depth', 'map', 'of', 'the', 'second', 'image', 'based', 'on', 'the', 'first', 'image', 'the', 'second', 'image', 'and', 'the', 'first', 'depth', 'mapmethods', 'systems', 'and', 'apparatus', 'including', 'computer', 'programs', 'encoded', 'on', 'computer', 'storage', 'media', 'for', 'a', 'payment', 'based', 'on', 'a', 'face', 'recognition', 'are', 'provided', 'one', 'of', 'the', 'methods', 'includes', 'acquiring', 'first', 'face', 'image', 'information', 'of', 'a', 'target', 'user', 'extracting', 'first', 'characteristic', 'information', 'from', 'the', 'first', 'face', 'image', 'information', 'wherein', 'the', 'first', 'characteristic', 'information', 'includes', 'head', 'posture', 'information', 'of', 'the', 'target', 'user', 'and', 'gaze', 'information', 'of', 'the', 'target', 'user', 'determining', 'whether', 'the', 'target', 'user', 'has', 'a', 'willingness', 'to', 'pay', 'according', 'to', 'the', 'head', 'posture', 'information', 'of', 'the', 'target', 'user', 'and', 'the', 'gaze', 'information', 'of', 'the', 'target', 'user', 'including', 'determining', 'whether', 'an', 'angle', 'of', 'rotation', 'in', 'each', 'preset', 'direction', 'is', 'less', 'than', 'an', 'angle', 'threshold', 'and', 'whether', 'a', 'probability', 'value', 'that', 'a', 'user', 'gazes', 'at', 'a', 'payment', 'screen', 'is', 'greater', 'than', 'a', 'probability', 'threshold', 'and', 'in', 'response', 'to', 'determining', 'that', 'the', 'target', 'user', 'has', 'a', 'willingness', 'to', 'pay', 'completing', 'a', 'payment', 'operation', 'based', 'on', 'the', 'face', 'recognitiona', 'novel', 'method', 'and', 'apparatus', 'for', 'face', 'authentication', 'is', 'disclosed', 'the', 'disclosed', 'method', 'comprises', 'detecting', 'a', 'motion', 'by', 'a', 'subject', 'within', 'a', 'predetermined', 'area', 'of', 'view', 'assigning', 'a', 'unique', 'session', 'identification', 'number', 'to', 'the', 'subject', 'detected', 'within', 'a', 'predetermined', 'area', 'of', 'view', 'detecting', 'a', 'facial', 'area', 'of', 'the', 'subject', 'detected', 'within', 'a', 'predetermined', 'area', 'of', 'view', 'generating', 'an', 'image', 'of', 'the', 'facial', 'area', 'of', 'the', 'subject', 'assessing', 'a', 'quality', 'of', 'the', 'image', 'of', 'the', 'facial', 'area', 'of', 'the', 'subject', 'conducing', 'an', 'incremental', 'training', 'of', 'the', 'image', 'of', 'the', 'facial', 'area', 'of', 'the', 'subject', 'determining', 'an', 'identity', 'of', 'the', 'subject', 'based', 'on', 'the', 'image', 'of', 'the', 'facial', 'area', 'of', 'the', 'subject', 'identifying', 'an', 'intent', 'of', 'the', 'subject', 'and', 'authorizing', 'access', 'to', 'a', 'point', 'of', 'entry', 'based', 'on', 'the', 'determined', 'identity', 'of', 'the', 'subject', 'and', 'based', 'on', 'the', 'intent', 'of', 'the', 'subjectdisclosed', 'herein', 'is', 'a', 'robot', 'and', 'an', 'electronic', 'device', 'for', 'acquiring', 'video', 'and', 'a', 'method', 'for', 'acquiring', 'video', 'using', 'the', 'robot', 'the', 'robot', 'includes', 'a', 'camera', 'configured', 'to', 'rotate', 'in', 'the', 'lateral', 'direction', 'and', 'tilt', 'in', 'the', 'vertical', 'direction', 'and', 'controls', 'at', 'least', 'one', 'of', 'a', 'direction', 'of', 'the', 'rotation', 'of', 'the', 'camera', 'an', 'angle', 'of', 'the', 'tilt', 'of', 'the', 'camera', 'and', 'a', 'focal', 'distance', 'of', 'the', 'camera', 'by', 'recognizing', 'and', 'tracking', 'users', 'in', 'a', 'video', 'acquired', 'by', 'the', 'camerasystems', 'and', 'methods', 'are', 'disclosed', 'for', 'inferring', 'topics', 'from', 'a', 'file', 'containing', 'both', 'audio', 'and', 'video', 'for', 'example', 'a', 'multimodal', 'or', 'multimedia', 'file', 'in', 'order', 'to', 'facilitate', 'video', 'indexing', 'a', 'set', 'of', 'entities', 'is', 'extracted', 'from', 'the', 'file', 'and', 'linked', 'to', 'produce', 'a', 'graph', 'and', 'reference', 'information', 'is', 'also', 'obtained', 'for', 'the', 'set', 'of', 'entities', 'entities', 'may', 'be', 'drawn', 'for', 'example', 'from', 'wikipedia', 'categories', 'or', 'other', 'large', 'ontological', 'data', 'sources', 'analysis', 'of', 'the', 'graph', 'using', 'unsupervised', 'learning', 'permits', 'determining', 'clusters', 'in', 'the', 'graph', 'extracting', 'features', 'from', 'the', 'clusters', 'possibly', 'using', 'supervised', 'learning', 'provides', 'for', 'selection', 'of', 'topic', 'identifiers', 'the', 'topic', 'identifiers', 'are', 'then', 'used', 'for', 'indexing', 'the', 'filea', 'face', 'recognition', 'method', 'a', 'neural', 'network', 'training', 'method', 'an', 'apparatus', 'and', 'an', 'electronic', 'device', 'the', 'method', 'comprises', 'obtaining', 'a', 'first', 'face', 'image', 'by', 'means', 'of', 'a', 'first', 'camera', 'extracting', 'a', 'first', 'face', 'feature', 'of', 'the', 'first', 'face', 'image', 'comparing', 'the', 'first', 'face', 'feature', 'with', 'a', 'pre-stored', 'second', 'face', 'feature', 'to', 'obtain', 'a', 'reference', 'similarity', 'the', 'second', 'face', 'feature', 'being', 'obtained', 'by', 'extracting', 'a', 'feature', 'of', 'a', 'second', 'face', 'image', 'obtained', 'by', 'a', 'second', 'camera', 'and', 'the', 'second', 'camera', 'and', 'the', 'first', 'camera', 'being', 'different', 'types', 'of', 'cameras', 'and', 'determining', 'according', 'to', 'the', 'reference', 'similarity', 'whether', 'the', 'first', 'face', 'feature', 'and', 'the', 'second', 'face', 'feature', 'correspond', 'to', 'a', 'same', 'person', 'the', 'present', 'invention', 'discloses', 'a', 'technique', 'for', 'alerting', 'on', 'vision', 'impairment', 'the', 'system', 'comprises', 'a', 'processing', 'unit', 'configured', 'and', 'operable', 'for', 'receiving', 'scene', 'data', 'being', 'indicative', 'of', 'a', 'scene', 'of', 'at', 'least', 'one', 'consumer', 'in', 'an', 'environment', 'identifying', 'in', 'the', 'scene', 'data', 'a', 'certain', 'consumer', 'identifying', 'an', 'event', 'being', 'indicative', 'of', 'a', 'behavioral', 'compensation', 'for', 'vision', 'impairment', 'and', 'upon', 'identification', 'of', 'such', 'an', 'event', 'sending', 'a', 'notification', 'relating', 'to', 'the', 'vision', 'impairment']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['an', 'electronic', 'device', 'configured', 'to', 'make', 'a', 'screen', 'to', 'display', 'a', 'plurality', 'of', 'image', 'frames', 'comprising', 'an', 'image', 'capturing', 'device', 'a', 'storage', 'device', 'storing', 'a', 'plurality', 'of', 'modules', 'and', 'a', 'processor', 'coupled', 'to', 'the', 'image', 'capturing', 'device', 'and', 'the', 'storage', 'device', 'configured', 'to', 'execute', 'the', 'modules', 'in', 'the', 'storage', 'device', 'to', 'configure', 'the', 'screen', 'to', 'display', 'a', 'plurality', 'of', 'marker', 'objects', 'at', 'a', 'plurality', 'of', 'predetermined', 'calibration', 'positions', 'configure', 'the', 'image', 'capturing', 'device', 'to', 'capture', 'a', 'plurality', 'of', 'first', 'head', 'images', 'when', 'a', 'user', 'is', 'looking', 'at', 'the', 'predetermined', 'calibration', 'positions', 's', 'perform', 'a', 'plurality', 'of', 'first', 'face', 'recognition', 'operations', 'on', 'the', 'first', 'head', 'images', 'to', 'obtain', 'a', 'plurality', 'of', 'first', 'face', 'regions', 'corresponding', 'to', 'the', 'predetermined', 'calibration', 'positions', 's', 'detect', 'a', 'plurality', 'of', 'first', 'facial', 'landmarks', 'corresponding', 'to', 'the', 'first', 'face', 'regions', 's', 'calculate', 'a', 'plurality', 'of', 'rotation', 'reference', 'angles', 'of', 'the', 'user', 'looking', 'at', 'the', 'predetermined', 'calibration', 'positions', 'according', 'to', 'the', 'first', 'facial', 'landmarks', 'configure', 'the', 'image', 'capturing', 'device', 'to', 'capture', 'a', 'second', 'head', 'image', 'of', 'the', 'user', 'perform', 'a', 'second', 'face', 'recognition', 'operation', 'on', 'the', 'second', 'head', 'image', 'to', 'obtain', 'a', 'second', 'face', 'region', 'detect', 'a', 'plurality', 'of', 'second', 'facial', 'landmarks', 'within', 'the', 'second', 'face', 'region', 's', 'estimate', 'a', 'head', 'posture', 'angle', 'of', 'the', 'user', 'according', 'to', 'the', 'second', 'facial', 'landmarks', 'calculate', 'a', 'gaze', 'position', 'of', 'the', 'user', 'on', 'the', 'screen', 'according', 'to', 'the', 'head', 'posture', 'angle', 'the', 'rotation', 'reference', 'angles', 'and', 'the', 'predetermined', 'calibration', 'positions', 'and', 'configure', 'the', 'screen', 'to', 'display', 'a', 'corresponding', 'visual', 'effect', 'according', 'to', 'the', 'gaze', 'position', 'the', 'electronic', 'device', 'according', 'to', 'claim', 'wherein', 'the', 'gaze', 'position', 'comprises', 'a', 'first', 'coordinate', 'value', 'in', 'a', 'first', 'axial', 'direction', 'and', 'a', 'second', 'coordinate', 'value', 'in', 'a', 'second', 'axial', 'direction', 'the', 'electronic', 'device', 'according', 'to', 'claim', 'wherein', 'the', 'head', 'posture', 'angles', 'comprise', 'a', 'head', 'pitch', 'angle', 'and', 'a', 'head', 'yaw', 'angle', 'and', 'the', 'rotation', 'reference', 'angles', 'comprise', 'a', 'first', 'pitch', 'angle', 'a', 'second', 'pitch', 'angle', 'a', 'first', 'yaw', 'angle', 'and', 'a', 'second', 'yaw', 'angle', 'corresponding', 'to', 'the', 'predetermined', 'calibration', 'positions', 'the', 'electronic', 'device', 'according', 'to', 'claim', 'wherein', 'the', 'processor', 'performs', 'interpolation', 'operation', 'or', 'extrapolation', 'operation', 'according', 'to', 'the', 'first', 'yaw', 'angle', 'the', 'second', 'yaw', 'angle', 'a', 'first', 'position', 'corresponding', 'to', 'the', 'first', 'yaw', 'angle', 'among', 'the', 'predetermined', 'calibration', 'positions', 'a', 'second', 'position', 'corresponding', 'to', 'the', 'second', 'yaw', 'angle', 'among', 'the', 'predetermined', 'calibration', 'positions', 'and', 'the', 'head', 'yaw', 'angle', 'thereby', 'obtaining', 'the', 'first', 'coordinate', 'value', 'of', 'the', 'gaze', 'position', 'and', 'the', 'processor', 'performs', 'interpolation', 'operation', 'or', 'extrapolation', 'operation', 'according', 'to', 'the', 'first', 'pitch', 'angle', 'the', 'second', 'pitch', 'angle', 'a', 'third', 'position', 'corresponding', 'to', 'the', 'first', 'pitch', 'angle', 'among', 'the', 'predetermined', 'calibration', 'positions', 'a', 'fourth', 'position', 'corresponding', 'to', 'the', 'second', 'pitch', 'angle', 'among', 'the', 'predetermined', 'calibration', 'positions', 'and', 'the', 'head', 'pitch', 'angle', 'thereby', 'obtaining', 'the', 'second', 'coordinate', 'value', 'of', 'the', 'gaze', 'position', 'the', 'electronic', 'device', 'according', 'to', 'claim', 'wherein', 'the', 'processor', 'calculates', 'a', 'plurality', 'of', 'first', 'viewing', 'distances', 'between', 'the', 'user', 'and', 'the', 'screen', 'according', 'to', 'the', 'first', 'facial', 'landmarks', 'the', 'processor', 'estimates', 'a', 'second', 'viewing', 'distance', 'between', 'the', 'user', 'and', 'the', 'screen', 'according', 'to', 'the', 'second', 'facial', 'landmarks', 'and', 'the', 'processor', 'adjusts', 'the', 'rotation', 'reference', 'angles', 'or', 'the', 'gaze', 'position', 'according', 'to', 'the', 'second', 'viewing', 'distance', 'and', 'the', 'first', 'viewing', 'distances', 'the', 'electronic', 'device', 'according', 'to', 'claim', 'wherein', 'the', 'processor', 'maps', 'a', 'plurality', 'of', 'two-dimensional', 'position', 'coordinates', 'of', 'the', 'second', 'facial', 'landmarks', 'under', 'a', 'plane', 'coordinate', 'system', 'to', 'a', 'plurality', 'of', 'three-dimensional', 'position', 'coordinates', 'under', 'a', 'three-dimensional', 'coordinate', 'system', 'and', 'the', 'processor', 'estimates', 'the', 'head', 'posture', 'angle', 'according', 'to', 'the', 'three-dimensional', 'position', 'coordinates', 'of', 'the', 'second', 'facial', 'landmarks', 'the', 'electronic', 'device', 'according', 'to', 'claim', 'wherein', 'the', 'second', 'head', 'image', 'comprises', 'a', 'wearable', 'device', 'and', 'the', 'second', 'facial', 'landmarks', 'do', 'not', 'comprise', 'a', 'plurality', 'of', 'third', 'facial', 'landmarks', 'of', 'the', 'user', 'covered', 'by', 'the', 'wearable', 'device', 'the', 'electronic', 'device', 'according', 'to', 'claim', 'wherein', 'the', 'second', 'head', 'image', 'comprises', 'a', 'wearable', 'device', 'and', 'the', 'second', 'facial', 'landmarks', 'comprise', 'one', 'or', 'more', 'simulated', 'landmarks', 'marked', 'by', 'the', 'wearable', 'device', 'an', 'operating', 'method', 'adapted', 'for', 'an', 'electronic', 'device', 'comprising', 'an', 'image', 'capturing', 'device', 'and', 'making', 'a', 'screen', 'to', 'display', 'a', 'plurality', 'of', 'image', 'frames', 'the', 'method', 'comprising', 'configuring', 'the', 'screen', 'to', 'display', 'a', 'plurality', 'of', 'marker', 'objects', 'at', 'a', 'plurality', 'of', 'predetermined', 'calibration', 'positions', 'configuring', 'the', 'image', 'capturing', 'device', 'to', 'capture', 'a', 'plurality', 'of', 'first', 'head', 'images', 'when', 'a', 'user', 'is', 'looking', 'at', 'the', 'predetermined', 'calibration', 'positions', 's', 'performing', 'a', 'plurality', 'of', 'first', 'face', 'recognition', 'operations', 'on', 'the', 'first', 'head', 'images', 'to', 'obtain', 'a', 'plurality', 'of', 'first', 'face', 'regions', 'corresponding', 'to', 'the', 'predetermined', 'calibration', 'positions', 's', 'detecting', 'a', 'plurality', 'of', 'first', 'facial', 'landmarks', 'corresponding', 'to', 'the', 'first', 'face', 'regions', 's', 'calculating', 'a', 'plurality', 'of', 'rotation', 'reference', 'angles', 'of', 'the', 'user', 'looking', 'at', 'the', 'predetermined', 'calibration', 'positions', 'according', 'to', 'the', 'first', 'facial', 'landmarks', 'configuring', 'the', 'image', 'capturing', 'device', 'to', 'capture', 'a', 'second', 'head', 'image', 'of', 'the', 'user', 'performing', 'a', 'second', 'face', 'recognition', 'operation', 'on', 'the', 'second', 'head', 'image', 'to', 'obtain', 'a', 'second', 'face', 'region', 's', 'detecting', 'a', 'plurality', 'of', 'second', 'facial', 'landmarks', 'within', 'the', 'second', 'face', 'region', 'estimating', 'a', 'head', 'posture', 'angle', 'of', 'the', 'user', 'according', 'to', 'the', 'second', 'facial', 'landmarks', 'calculating', 'a', 'gaze', 'position', 'of', 'the', 'user', 'on', 'the', 'screen', 'according', 'to', 'the', 'head', 'posture', 'angle', 'the', 'rotation', 'reference', 'angles', 'and', 'the', 'predetermined', 'calibration', 'positions', 'and', 's', 'configuring', 'the', 'screen', 'to', 'display', 'a', 'corresponding', 'visual', 'effect', 'according', 'to', 'the', 'gaze', 'position', 'the', 'operation', 'method', 'according', 'to', 'claim', 'wherein', 'the', 'gaze', 'position', 'comprises', 'a', 'first', 'coordinate', 'value', 'in', 'a', 'first', 'axial', 'direction', 'and', 'a', 'second', 'coordinate', 'value', 'in', 'a', 'second', 'axial', 'direction', 'the', 'operation', 'method', 'according', 'to', 'claim', 'wherein', 'the', 'head', 'posture', 'angles', 'comprise', 'a', 'head', 'pitch', 'angle', 'and', 'a', 'head', 'yaw', 'angle', 'and', 'the', 'rotation', 'reference', 'angles', 'comprise', 'a', 'first', 'pitch', 'angle', 'a', 'second', 'pitch', 'angle', 'a', 'first', 'yaw', 'angle', 'and', 'a', 'second', 'yaw', 'angle', 'corresponding', 'to', 'the', 'predetermined', 'calibration', 'positions', 'the', 'operation', 'method', 'according', 'to', 'claim', 'wherein', 'the', 'step', 'of', 'calculating', 'the', 'gaze', 'position', 'of', 'the', 'user', 'on', 'the', 'screen', 'according', 'to', 'the', 'head', 'posture', 'angle', 'the', 'rotation', 'reference', 'angles', 'and', 'the', 'predetermined', 'calibration', 'positions', 'comprises', 'performing', 'interpolation', 'operation', 'or', 'extrapolation', 'operation', 'according', 'to', 'the', 'first', 'yaw', 'angle', 'the', 'second', 'yaw', 'angle', 'a', 'first', 'position', 'corresponding', 'to', 'the', 'first', 'yaw', 'angle', 'among', 'the', 'predetermined', 'calibration', 'positions', 'a', 'second', 'position', 'corresponding', 'to', 'the', 'second', 'yaw', 'angle', 'among', 'the', 'predetermined', 'calibration', 'positions', 'and', 'the', 'head', 'yaw', 'angle', 'thereby', 'obtaining', 'the', 'first', 'coordinate', 'value', 'of', 'the', 'gaze', 'position', 'and', 'performing', 'interpolation', 'operation', 'or', 'extrapolation', 'operation', 'according', 'to', 'the', 'first', 'pitch', 'angle', 'the', 'second', 'pitch', 'angle', 'a', 'third', 'position', 'corresponding', 'to', 'the', 'first', 'pitch', 'angle', 'among', 'the', 'predetermined', 'calibration', 'positions', 'a', 'fourth', 'position', 'corresponding', 'to', 'the', 'second', 'pitch', 'angle', 'among', 'the', 'predetermined', 'calibration', 'positions', 'and', 'the', 'head', 'pitch', 'angle', 'thereby', 'obtaining', 'the', 'second', 'coordinate', 'value', 'of', 'the', 'gaze', 'position', 'the', 'operation', 'method', 'according', 'to', 'claim', 'wherein', 'the', 'method', 'further', 'comprises', 'calculating', 'a', 'plurality', 'of', 'first', 'viewing', 'distances', 'between', 'the', 'user', 'and', 'the', 'screen', 'according', 'to', 'the', 'first', 'facial', 'landmarks', 'estimating', 'a', 'second', 'viewing', 'distance', 'between', 'the', 'user', 'and', 'the', 'screen', 'according', 'to', 'the', 'second', 'facial', 'landmarks', 'and', 'adjusting', 'the', 'rotation', 'reference', 'angles', 'or', 'the', 'gaze', 'position', 'according', 'to', 'the', 'second', 'viewing', 'distance', 'and', 'the', 'first', 'viewing', 'distances', 'the', 'operation', 'method', 'according', 'to', 'claim', 'wherein', 'the', 'method', 'further', 'comprises', 'mapping', 'a', 'plurality', 'of', 'two-dimensional', 'position', 'coordinates', 'of', 'the', 'second', 'facial', 'landmarks', 'under', 'a', 'plane', 'coordinate', 'system', 'to', 'a', 'plurality', 'of', 'three-dimensional', 'position', 'coordinates', 'under', 'a', 'three-dimensional', 'coordinate', 'system', 'and', 'estimating', 'the', 'head', 'posture', 'angle', 'according', 'to', 'the', 'three-dimensional', 'position', 'coordinates', 'of', 'the', 'second', 'facial', 'landmarks', 'the', 'operation', 'method', 'according', 'to', 'claim', 'wherein', 'the', 'second', 'head', 'image', 'comprises', 'a', 'wearable', 'device', 'and', 'the', 'second', 'facial', 'landmarks', 'do', 'not', 'comprise', 'a', 'plurality', 'of', 'third', 'facial', 'landmarks', 'of', 'the', 'user', 'covered', 'by', 'the', 'wearable', 'device', 'the', 'operation', 'method', 'according', 'to', 'claim', 'wherein', 'the', 'second', 'head', 'image', 'comprises', 'a', 'wearable', 'device', 'and', 'the', 'second', 'facial', 'landmarks', 'comprise', 'one', 'or', 'more', 'simulated', 'landmarks', 'marked', 'by', 'the', 'wearable', 'device', 'a', 'computation', 'method', 'applied', 'to', 'a', 'computing', 'system', 'wherein', 'the', 'computing', 'system', 'comprises', 'a', 'control', 'unit', 'a', 'computation', 'group', 'and', 'a', 'general', 'storage', 'unit', 'wherein', 'the', 'control', 'unit', 'comprises', 'a', 'first', 'memory', 'a', 'decoding', 'logic', 'and', 'a', 'controller', 'wherein', 'the', 'computation', 'group', 'comprises', 'a', 'group', 'controller', 'and', 'a', 'plurality', 'of', 'computing', 'units', 'the', 'general', 'storage', 'unit', 'is', 'configured', 'to', 'store', 'data', 'and', 'the', 'computation', 'method', 'comprises', 'receiving', 'by', 'the', 'controller', 'a', 'first', 'level', 'instruction', 'sequence', 'and', 'partitioning', 'by', 'the', 'decoding', 'logic', 'the', 'first', 'level', 'instruction', 'sequence', 'into', 'a', 'plurality', 'of', 'second', 'level', 'instruction', 'sequences', 'creating', 'by', 'the', 'controller', 'm', 'threads', 'for', 'the', 'plurality', 'of', 'second', 'level', 'instruction', 'sequences', 'and', 'allocating', 'by', 'the', 'controller', 'an', 'independent', 'register', 'as', 'well', 'as', 'configuring', 'an', 'independent', 'addressing', 'function', 'for', 'each', 'thread', 'of', 'the', 'm', 'threads', 'wherein', 'm', 'is', 'an', 'integer', 'greater', 'than', 'or', 'equal', 'to', 'and', 'obtaining', 'by', 'the', 'group', 'controller', 'a', 'plurality', 'of', 'computation', 'types', 'of', 'the', 'plurality', 'of', 'second', 'level', 'instruction', 'sequences', 'obtaining', 'a', 'corresponding', 'fusion', 'computation', 'manner', 'of', 'the', 'computation', 'types', 'according', 'to', 'the', 'plurality', 'of', 'computation', 'types', 'and', 'adopting', 'by', 'the', 'plurality', 'of', 'computing', 'units', 'the', 'fusion', 'computation', 'manner', 'to', 'call', 'the', 'm', 'threads', 'for', 'performing', 'computations', 'on', 'the', 'plurality', 'of', 'second', 'level', 'instruction', 'sequences', 'to', 'obtain', 'a', 'final', 'result', 'the', 'method', 'of', 'claim', 'wherein', 'the', 'obtaining', 'by', 'the', 'group', 'controller', 'a', 'plurality', 'of', 'computation', 'types', 'of', 'the', 'plurality', 'of', 'second', 'level', 'instruction', 'sequences', 'obtaining', 'a', 'corresponding', 'fusion', 'computation', 'manner', 'of', 'the', 'computation', 'types', 'according', 'to', 'the', 'plurality', 'of', 'computation', 'types', 'and', 'adopting', 'by', 'the', 'plurality', 'of', 'computing', 'units', 'the', 'fusion', 'computation', 'manner', 'to', 'call', 'the', 'm', 'threads', 'for', 'performing', 'computations', 'on', 'the', 'plurality', 'of', 'second', 'instruction', 'sequences', 'to', 'obtain', 'a', 'final', 'result', 'if', 'the', 'computation', 'types', 'represent', 'computation', 'operations', 'of', 'the', 'same', 'type', 'the', 'group', 'controller', 'calls', 'a', 'combined', 'computation', 'manner', 'in', 'which', 'single', 'instruction', 'multiple', 'data', 'of', 'the', 'same', 'type', 'is', 'in', 'combination', 'with', 'single', 'instruction', 'multiple', 'threads', 'and', 'uses', 'the', 'm', 'threads', 'to', 'perform', 'the', 'combined', 'computation', 'manner', 'to', 'obtain', 'a', 'final', 'result', 'which', 'includes', 'partitioning', 'by', 'the', 'decoding', 'logic', 'the', 'm', 'threads', 'into', 'n', 'wraps', 'for', 'allocating', 'to', 'the', 'the', 'plurality', 'of', 'computing', 'units', 'converting', 'by', 'the', 'group', 'controller', 'the', 'plurality', 'of', 'second', 'instruction', 'sequences', 'into', 'a', 'plurality', 'of', 'second', 'control', 'signals', 'and', 'sending', 'the', 'second', 'control', 'signals', 'to', 'the', 'plurality', 'of', 'computing', 'units', 'calling', 'by', 'the', 'plurality', 'of', 'computing', 'units', 'wraps', 'that', 'are', 'allocated', 'to', 'the', 'computing', 'units', 'and', 'the', 'second', 'control', 'signals', 'to', 'fetch', 'corresponding', 'data', 'according', 'to', 'the', 'independent', 'addressing', 'function', 'performing', 'by', 'the', 'plurality', 'of', 'computing', 'units', 'computations', 'on', 'the', 'data', 'to', 'obtain', 'a', 'plurality', 'of', 'intermediate', 'results', 'and', 'splicing', 'the', 'plurality', 'of', 'intermediate', 'results', 'to', 'obtain', 'a', 'final', 'result', 'the', 'method', 'of', 'claim', 'wherein', 'the', 'obtaining', 'by', 'the', 'group', 'controller', 'a', 'plurality', 'of', 'computation', 'types', 'of', 'the', 'plurality', 'of', 'second', 'level', 'instruction', 'sequences', 'obtaining', 'a', 'corresponding', 'fusion', 'computation', 'manner', 'of', 'the', 'computation', 'types', 'according', 'to', 'the', 'plurality', 'of', 'computation', 'types', 'and', 'adopting', 'by', 'the', 'plurality', 'of', 'computing', 'units', 'the', 'fusion', 'computation', 'manner', 'to', 'call', 'the', 'm', 'threads', 'for', 'performing', 'computations', 'on', 'the', 'plurality', 'of', 'second', 'instruction', 'sequences', 'to', 'obtain', 'a', 'final', 'result', 'if', 'the', 'computation', 'types', 'represent', 'computation', 'operations', 'of', 'different', 'types', 'the', 'group', 'controller', 'calls', 'simultaneous', 'multi-threading', 'and', 'the', 'm', 'threads', 'to', 'perform', 'computations', 'to', 'obtain', 'a', 'final', 'result', 'which', 'includes', 'partitioning', 'by', 'the', 'decoding', 'logic', 'the', 'm', 'threads', 'into', 'n', 'wraps', 'converting', 'the', 'plurality', 'of', 'second', 'instruction', 'sequences', 'into', 'a', 'plurality', 'of', 'second', 'control', 'signals', 'obtaining', 'by', 'the', 'group', 'controller', 'computation', 'types', 'supported', 'by', 'the', 'plurality', 'of', 'computing', 'units', 'allocating', 'by', 'the', 'controller', 'the', 'n', 'wraps', 'and', 'the', 'plurality', 'of', 'second', 'control', 'signals', 'to', 'corresponding', 'computing', 'units', 'that', 'support', 'computation', 'types', 'of', 'the', 'wraps', 'and', 'the', 'second', 'control', 'signals', 'calling', 'by', 'the', 'plurality', 'of', 'computing', 'units', 'wraps', 'that', 'are', 'allocated', 'to', 'the', 'computing', 'units', 'and', 'the', 'second', 'control', 'signals', 'fetching', 'by', 'the', 'plurality', 'of', 'computing', 'units', 'corresponding', 'data', 'performing', 'by', 'the', 'plurality', 'of', 'computing', 'units', 'computations', 'on', 'the', 'data', 'to', 'obtain', 'a', 'plurality', 'of', 'intermediate', 'results', 'and', 'splicing', 'all', 'the', 'intermediate', 'results', 'to', 'obtain', 'a', 'final', 'result', 'the', 'method', 'of', 'claim', 'or', 'further', 'comprising', 'if', 'a', 'wrap', 'a', 'in', 'the', 'plurality', 'of', 'wraps', 'is', 'blocked', 'adding', 'the', 'wrap', 'a', 'to', 'a', 'waiting', 'queue', 'and', 'if', 'data', 'of', 'the', 'wrap', 'a', 'are', 'already', 'fetched', 'adding', 'the', 'wrap', 'a', 'to', 'a', 'preparation', 'queue', 'wherein', 'the', 'preparation', 'queue', 'is', 'a', 'queue', 'where', 'a', 'wrap', 'to', 'be', 'scheduled', 'for', 'executing', 'is', 'located', 'when', 'a', 'computing', 'resource', 'is', 'idle', 'the', 'method', 'of', 'claim', 'wherein', 'the', 'first', 'level', 'instruction', 'sequence', 'includes', 'a', 'very', 'long', 'instruction', 'and', 'the', 'second', 'level', 'instruction', 'sequence', 'includes', 'an', 'instruction', 'sequence', 'the', 'method', 'of', 'claim', 'wherein', 'the', 'computing', 'system', 'further', 'includes', 'a', 'tree', 'module', 'wherein', 'the', 'tree', 'module', 'includes', 'a', 'root', 'port', 'and', 'a', 'plurality', 'of', 'branch', 'ports', 'wherein', 'the', 'root', 'port', 'of', 'the', 'tree', 'module', 'is', 'connected', 'to', 'the', 'group', 'controller', 'and', 'the', 'plurality', 'of', 'branch', 'ports', 'of', 'the', 'tree', 'module', 'are', 'connected', 'to', 'a', 'computing', 'unit', 'of', 'the', 'plurality', 'of', 'computing', 'units', 'respectively', 'and', 'the', 'tree', 'module', 'is', 'configured', 'to', 'forward', 'data', 'blocks', 'wraps', 'or', 'instruction', 'sequences', 'between', 'the', 'group', 'controller', 'and', 'the', 'plurality', 'of', 'computing', 'units', 'the', 'method', 'of', 'claim', 'wherein', 'the', 'tree', 'module', 'is', 'an', 'n-ary', 'tree', 'wherein', 'n', 'is', 'an', 'integer', 'greater', 'than', 'or', 'equal', 'to', 'the', 'method', 'of', 'claim', 'wherein', 'the', 'computing', 'system', 'further', 'includes', 'a', 'branch', 'processing', 'circuit', 'wherein', 'the', 'branch', 'processing', 'circuit', 'is', 'connected', 'between', 'the', 'group', 'controller', 'and', 'the', 'plurality', 'of', 'computing', 'units', 'and', 'the', 'branch', 'processing', 'circuit', 'is', 'configured', 'to', 'forward', 'data', 'wraps', 'or', 'instruction', 'sequences', 'between', 'the', 'group', 'controller', 'and', 'the', 'plurality', 'of', 'computing', 'units', 'a', 'computing', 'system', 'comprising', 'a', 'control', 'unit', 'a', 'computation', 'group', 'and', 'a', 'general', 'storage', 'unit', 'wherein', 'the', 'control', 'unit', 'includes', 'a', 'first', 'memory', 'a', 'decoding', 'logic', 'and', 'a', 'controller', 'the', 'computation', 'group', 'includes', 'a', 'group', 'controller', 'and', 'a', 'plurality', 'of', 'computing', 'units', 'the', 'general', 'storage', 'unit', 'is', 'configured', 'to', 'store', 'data', 'the', 'controller', 'is', 'configured', 'to', 'receive', 'a', 'first', 'level', 'instruction', 'sequence', 'and', 'control', 'the', 'first', 'memory', 'and', 'the', 'decoding', 'logic', 'the', 'decoding', 'logic', 'is', 'configured', 'to', 'partition', 'the', 'first', 'level', 'instruction', 'sequence', 'into', 'a', 'plurality', 'of', 'second', 'level', 'instruction', 'sequences', 'the', 'the', 'controller', 'is', 'further', 'configured', 'to', 'create', 'm', 'threads', 'for', 'the', 'plurality', 'of', 'second', 'level', 'instruction', 'sequences', 'and', 'allocate', 'an', 'independent', 'register', 'and', 'configure', 'an', 'independent', 'addressing', 'function', 'for', 'each', 'thread', 'of', 'the', 'm', 'threads', 'm', 'is', 'an', 'integer', 'greater', 'than', 'or', 'equal', 'to', 'and', 'the', 'controller', 'is', 'further', 'configured', 'to', 'convert', 'the', 'plurality', 'of', 'second', 'instruction', 'sequences', 'into', 'a', 'plurality', 'of', 'control', 'signals', 'for', 'sending', 'to', 'the', 'group', 'controller', 'the', 'group', 'controller', 'is', 'configured', 'to', 'receive', 'the', 'plurality', 'of', 'control', 'signals', 'obtain', 'a', 'plurality', 'of', 'computational', 'types', 'if', 'the', 'plurality', 'of', 'control', 'signals', 'divide', 'the', 'm', 'threads', 'into', 'n', 'wraps', 'and', 'allocate', 'the', 'n', 'wraps', 'and', 'the', 'plurality', 'of', 'control', 'signals', 'to', 'the', 'plurality', 'of', 'computing', 'units', 'according', 'to', 'the', 'plurality', 'of', 'computational', 'types', 'the', 'plurality', 'of', 'computing', 'units', 'are', 'configured', 'to', 'fetch', 'data', 'from', 'the', 'general', 'storage', 'unit', 'through', 'allocated', 'wraps', 'and', 'control', 'signals', 'and', 'perform', 'computations', 'to', 'obtain', 'an', 'intermediate', 'result', 'and', 'the', 'group', 'controller', 'is', 'configured', 'to', 'splice', 'all', 'intermediate', 'results', 'to', 'obtain', 'a', 'final', 'computation', 'result', 'the', 'computing', 'system', 'of', 'claim', 'wherein', 'the', 'plurality', 'of', 'computing', 'units', 'includes', 'an', 'addition', 'computing', 'unit', 'a', 'multiplication', 'computing', 'unit', 'an', 'activation', 'computing', 'unit', 'or', 'a', 'dedicated', 'computing', 'unit', 'the', 'computing', 'system', 'of', 'claim', 'wherein', 'the', 'dedicated', 'computing', 'unit', 'includes', 'a', 'face', 'recognition', 'computing', 'unit', 'a', 'graphics', 'computing', 'unit', 'a', 'fingerprint', 'computing', 'unit', 'or', 'a', 'neural', 'network', 'computing', 'unit', 'the', 'computing', 'system', 'of', 'claim', 'wherein', 'the', 'group', 'controller', 'is', 'configured', 'to', 'if', 'computation', 'types', 'of', 'a', 'plurality', 'of', 'control', 'signals', 'are', 'graphics', 'computations', 'fingerprint', 'identification', 'face', 'recognition', 'or', 'neural', 'network', 'operations', 'allocate', 'the', 'plurality', 'of', 'control', 'signals', 'to', 'the', 'face', 'recognition', 'computing', 'unit', 'the', 'graphics', 'computing', 'unit', 'the', 'fingerprint', 'computing', 'unit', 'or', 'the', 'neural', 'network', 'computing', 'unit', 'respectively', 'the', 'computing', 'system', 'of', 'claim', 'wherein', 'the', 'first', 'level', 'instruction', 'sequence', 'includes', 'a', 'very', 'long', 'instruction', 'and', 'the', 'second', 'level', 'instruction', 'sequence', 'includes', 'an', 'instruction', 'sequence', 'the', 'computing', 'system', 'of', 'claim', 'further', 'comprising', 'a', 'tree', 'module', 'wherein', 'the', 'tree', 'module', 'includes', 'a', 'root', 'port', 'and', 'a', 'plurality', 'of', 'branch', 'ports', 'wherein', 'the', 'root', 'port', 'of', 'the', 'tree', 'module', 'is', 'connected', 'to', 'the', 'group', 'controller', 'and', 'the', 'plurality', 'of', 'branch', 'ports', 'of', 'the', 'tree', 'module', 'are', 'connected', 'to', 'a', 'computing', 'unit', 'of', 'the', 'plurality', 'of', 'computing', 'units', 'respectively', 'and', 'the', 'tree', 'module', 'is', 'configured', 'to', 'forward', 'data', 'blocks', 'wraps', 'or', 'instruction', 'sequences', 'between', 'the', 'group', 'controller', 'and', 'the', 'plurality', 'of', 'computing', 'units', 'the', 'computing', 'system', 'of', 'claim', 'wherein', 'the', 'tree', 'module', 'is', 'an', 'n-ary', 'tree', 'wherein', 'n', 'is', 'an', 'integer', 'greater', 'than', 'or', 'equal', 'to', 'the', 'computing', 'system', 'of', 'claim', 'wherein', 'the', 'computing', 'system', 'includes', 'a', 'branch', 'processing', 'circuit', 'the', 'branch', 'processing', 'circuit', 'is', 'connected', 'between', 'the', 'group', 'controller', 'and', 'the', 'plurality', 'of', 'computing', 'units', 'and', 'the', 'branch', 'processing', 'circuit', 'is', 'configured', 'to', 'forward', 'data', 'wraps', 'or', 'instruction', 'sequences', 'between', 'the', 'group', 'controller', 'and', 'the', 'plurality', 'of', 'computing', 'units', 'a', 'computer', 'program', 'product', 'comprising', 'a', 'non-instant', 'computer', 'readable', 'storage', 'medium', 'wherein', 'a', 'computer', 'program', 'is', 'stored', 'in', 'the', 'non-instant', 'computer', 'readable', 'storage', 'medium', 'and', 'the', 'computer', 'program', 'is', 'capable', 'of', 'causing', 'a', 'computer', 'to', 'perform', 'the', 'method', 'of', 'any', 'of', 'claims', '-', 'through', 'operations', 'a', 'method', 'for', 'detecting', 'body', 'information', 'on', 'one', 'or', 'more', 'passengers', 'of', 'a', 'vehicle', 'based', 'on', 'humans', \"'\", 'status', 'recognition', 'comprising', 'steps', 'of', 'a', 'if', 'at', 'least', 'one', 'interior', 'image', 'of', 'an', 'interior', 'of', 'the', 'vehicle', 'is', 'acquired', 'a', 'passenger', 'body', 'information-detecting', 'device', 'performing', 'i', 'a', 'process', 'of', 'inputting', 'the', 'interior', 'image', 'into', 'a', 'face', 'recognition', 'network', 'to', 'thereby', 'allow', 'the', 'face', 'recognition', 'network', 'to', 'detect', 'each', 'of', 'faces', 'of', 'each', 'of', 'the', 'passengers', 'from', 'the', 'interior', 'image', 'and', 'thus', 'to', 'output', 'multiple', 'pieces', 'of', 'passenger', 'feature', 'information', 'corresponding', 'to', 'each', 'of', 'the', 'detected', 'faces', 'and', 'ii', 'a', 'process', 'of', 'inputting', 'the', 'interior', 'image', 'into', 'a', 'body', 'recognition', 'network', 'to', 'thereby', 'allow', 'the', 'body', 'recognition', 'network', 'to', 'detect', 'each', 'of', 'bodies', 'of', 'each', 'of', 'the', 'passengers', 'from', 'the', 'interior', 'image', 'and', 'thus', 'to', 'output', 'body-part', 'length', 'information', 'of', 'each', 'of', 'the', 'detected', 'bodies', 'and', 'b', 'the', 'passenger', 'body', 'information-detecting', 'device', 'performing', 'a', 'process', 'of', 'retrieving', 'specific', 'height', 'mapping', 'information', 'corresponding', 'to', 'specific', 'passenger', 'feature', 'information', 'on', 'a', 'specific', 'passenger', 'from', 'a', 'height', 'mapping', 'table', 'which', 'stores', 'height', 'mapping', 'information', 'representing', 'respective', 'one', 'or', 'more', 'predetermined', 'ratios', 'of', 'one', 'or', 'more', 'segment', 'body', 'portions', 'of', 'each', 'of', 'human', 'groups', 'to', 'each', 'of', 'heights', 'per', 'each', 'of', 'the', 'human', 'groups', 'a', 'process', 'of', 'acquiring', 'a', 'specific', 'height', 'of', 'the', 'specific', 'passenger', 'from', 'the', 'specific', 'height', 'mapping', 'information', 'by', 'referring', 'to', 'specific', 'body-part', 'length', 'information', 'of', 'the', 'specific', 'passenger', 'a', 'process', 'of', 'retrieving', 'specific', 'weight', 'mapping', 'information', 'corresponding', 'to', 'the', 'specific', 'passenger', 'feature', 'information', 'from', 'a', 'weight', 'mapping', 'table', 'which', 'stores', 'multiple', 'pieces', 'of', 'weight', 'mapping', 'information', 'representing', 'predetermined', 'correlations', 'between', 'each', 'of', 'the', 'heights', 'and', 'each', 'of', 'weights', 'per', 'each', 'of', 'the', 'human', 'groups', 'and', 'a', 'process', 'of', 'acquiring', 'a', 'weight', 'of', 'the', 'specific', 'passenger', 'from', 'the', 'specific', 'weight', 'mapping', 'information', 'by', 'referring', 'to', 'the', 'specific', 'height', 'of', 'the', 'specific', 'passenger', 'the', 'method', 'of', 'claim', 'wherein', 'at', 'the', 'step', 'of', 'a', 'the', 'passenger', 'body', 'information-detecting', 'device', 'performs', 'a', 'process', 'of', 'inputting', 'the', 'interior', 'image', 'into', 'the', 'body', 'recognition', 'network', 'to', 'thereby', 'allow', 'the', 'body', 'recognition', 'network', 'to', 'i', 'output', 'one', 'or', 'more', 'feature', 'tensors', 'with', 'one', 'or', 'more', 'channels', 'corresponding', 'to', 'the', 'interior', 'image', 'via', 'a', 'feature', 'extraction', 'network', 'ii', 'generate', 'at', 'least', 'one', 'keypoint', 'heatmap', 'and', 'at', 'least', 'one', 'part', 'affinity', 'field', 'with', 'one', 'or', 'more', 'channels', 'corresponding', 'to', 'each', 'of', 'the', 'feature', 'tensors', 'via', 'a', 'keypoint', 'heatmap', '&', 'part', 'affinity', 'field', 'extractor', 'and', 'iii', 'extract', 'keypoints', 'from', 'the', 'keypoint', 'heatmap', 'via', 'a', 'keypoint', 'detector', 'to', 'group', 'the', 'extracted', 'keypoints', 'by', 'referring', 'to', 'the', 'part', 'affinity', 'field', 'and', 'thus', 'to', 'generate', 'body', 'parts', 'per', 'the', 'passengers', 'and', 'as', 'a', 'result', 'allow', 'the', 'body', 'recognition', 'network', 'to', 'output', 'multiple', 'pieces', 'of', 'body-part', 'length', 'information', 'on', 'each', 'of', 'the', 'passengers', 'by', 'referring', 'to', 'the', 'body', 'parts', 'per', 'the', 'passengers', 'the', 'method', 'of', 'claim', 'wherein', 'the', 'feature', 'extraction', 'network', 'includes', 'at', 'least', 'one', 'convolutional', 'layer', 'and', 'applies', 'at', 'least', 'one', 'convolution', 'operation', 'to', 'the', 'interior', 'image', 'to', 'thereby', 'output', 'the', 'feature', 'tensors', 'the', 'method', 'of', 'claim', 'wherein', 'the', 'keypoint', 'heatmap', '&', 'part', 'affinity', 'field', 'extractor', 'includes', 'one', 'of', 'a', 'fully', 'convolutional', 'network', 'and', 'a', '×', 'convolutional', 'layer', 'and', 'applies', 'a', 'fully-convolution', 'operation', 'or', '×', 'convolution', 'operation', 'to', 'the', 'feature', 'tensors', 'to', 'thereby', 'generate', 'the', 'keypoint', 'heatmap', 'and', 'the', 'part', 'affinity', 'field', 'the', 'method', 'of', 'claim', 'wherein', 'the', 'keypoint', 'detector', 'connects', 'by', 'referring', 'to', 'the', 'part', 'affinity', 'field', 'pairs', 'respectively', 'having', 'highest', 'mutual', 'connection', 'probabilities', 'of', 'being', 'connected', 'among', 'the', 'extracted', 'keypoints', 'to', 'thereby', 'group', 'the', 'extracted', 'keypoints', 'the', 'method', 'of', 'claim', 'wherein', 'the', 'feature', 'extraction', 'network', 'and', 'the', 'keypoint', 'heatmap', '&', 'part', 'affinity', 'field', 'extractor', 'have', 'been', 'learned', 'by', 'a', 'learning', 'device', 'performing', 'i', 'a', 'process', 'of', 'inputting', 'at', 'least', 'one', 'training', 'image', 'including', 'one', 'or', 'more', 'objects', 'for', 'training', 'into', 'the', 'feature', 'extraction', 'network', 'to', 'thereby', 'allow', 'the', 'feature', 'extraction', 'network', 'to', 'generate', 'one', 'or', 'more', 'feature', 'tensors', 'for', 'training', 'having', 'one', 'or', 'more', 'channels', 'by', 'applying', 'at', 'least', 'one', 'convolutional', 'operation', 'to', 'the', 'training', 'image', 'ii', 'a', 'process', 'of', 'inputting', 'the', 'feature', 'tensors', 'for', 'training', 'into', 'the', 'keypoint', 'heatmap', '&', 'part', 'affinity', 'field', 'extractor', 'to', 'thereby', 'allow', 'the', 'keypoint', 'heatmap', '&', 'part', 'affinity', 'field', 'extractor', 'to', 'generate', 'one', 'or', 'more', 'keypoint', 'heatmaps', 'for', 'training', 'and', 'one', 'or', 'more', 'part', 'affinity', 'fields', 'for', 'training', 'having', 'one', 'or', 'more', 'channels', 'for', 'each', 'of', 'the', 'feature', 'tensors', 'for', 'training', 'iii', 'a', 'process', 'of', 'inputting', 'the', 'keypoint', 'heatmaps', 'for', 'training', 'and', 'the', 'part', 'affinity', 'fields', 'for', 'training', 'into', 'the', 'keypoint', 'detector', 'to', 'thereby', 'allow', 'the', 'keypoint', 'detector', 'to', 'extract', 'keypoints', 'for', 'training', 'from', 'each', 'of', 'the', 'keypoint', 'heatmaps', 'for', 'training', 'and', 'a', 'process', 'of', 'grouping', 'the', 'extracted', 'keypoints', 'for', 'training', 'by', 'referring', 'to', 'each', 'of', 'the', 'part', 'affinity', 'fields', 'for', 'training', 'to', 'thereby', 'detect', 'keypoints', 'per', 'each', 'of', 'the', 'objects', 'for', 'training', 'and', 'iv', 'a', 'process', 'of', 'allowing', 'a', 'loss', 'layer', 'to', 'calculate', 'one', 'or', 'more', 'losses', 'by', 'referring', 'to', 'the', 'keypoints', 'per', 'each', 'of', 'the', 'objects', 'for', 'training', 'and', 'their', 'corresponding', 'ground', 'truths', 'to', 'thereby', 'adjust', 'one', 'or', 'more', 'parameters', 'of', 'the', 'feature', 'extraction', 'network', 'and', 'the', 'keypoint', 'heatmap', '&', 'part', 'affinity', 'field', 'extractor', 'such', 'that', 'the', 'losses', 'are', 'minimized', 'by', 'backpropagation', 'using', 'the', 'losses', 'the', 'method', 'of', 'claim', 'wherein', 'at', 'the', 'step', 'of', 'a', 'the', 'passenger', 'body', 'information-detecting', 'device', 'performs', 'a', 'process', 'of', 'inputting', 'the', 'interior', 'image', 'into', 'the', 'face', 'recognition', 'network', 'to', 'thereby', 'allow', 'the', 'face', 'recognition', 'network', 'to', 'detect', 'each', 'of', 'the', 'faces', 'of', 'each', 'of', 'the', 'passengers', 'located', 'in', 'the', 'interior', 'image', 'via', 'a', 'face', 'detector', 'and', 'to', 'output', 'multiple', 'pieces', 'of', 'the', 'passenger', 'feature', 'information', 'on', 'each', 'of', 'the', 'facial', 'images', 'via', 'a', 'facial', 'feature', 'classifier', 'the', 'method', 'of', 'claim', 'wherein', 'at', 'the', 'step', 'of', 'a', 'the', 'passenger', 'body', 'information-detecting', 'device', 'performs', 'a', 'process', 'of', 'inputting', 'the', 'interior', 'image', 'into', 'the', 'face', 'recognition', 'network', 'to', 'thereby', 'allow', 'the', 'face', 'recognition', 'network', 'to', 'i', 'apply', 'at', 'least', 'one', 'convolution', 'operation', 'to', 'the', 'interior', 'image', 'and', 'thus', 'to', 'output', 'at', 'least', 'one', 'feature', 'map', 'corresponding', 'to', 'the', 'interior', 'image', 'via', 'at', 'least', 'one', 'convolutional', 'layer', 'ii', 'output', 'one', 'or', 'more', 'proposal', 'boxes', 'where', 'the', 'passengers', 'are', 'estimated', 'as', 'located', 'on', 'the', 'feature', 'map', 'via', 'a', 'region', 'proposal', 'network', 'iii', 'apply', 'pooling', 'operation', 'to', 'one', 'or', 'more', 'regions', 'corresponding', 'to', 'the', 'proposal', 'boxes', 'on', 'the', 'feature', 'map', 'and', 'thus', 'to', 'output', 'at', 'least', 'one', 'feature', 'vector', 'via', 'a', 'pooling', 'layer', 'and', 'iv', 'apply', 'fully-connected', 'operation', 'to', 'the', 'feature', 'vector', 'and', 'thus', 'to', 'output', 'the', 'multiple', 'pieces', 'of', 'the', 'passenger', 'feature', 'information', 'corresponding', 'to', 'each', 'of', 'the', 'faces', 'of', 'each', 'of', 'the', 'passengers', 'corresponding', 'to', 'each', 'of', 'the', 'proposal', 'boxes', 'via', 'a', 'fully', 'connected', 'layer', 'the', 'method', 'of', 'claim', 'wherein', 'the', 'multiple', 'pieces', 'of', 'the', 'passenger', 'feature', 'information', 'include', 'each', 'of', 'ages', 'each', 'of', 'genders', 'and', 'each', 'of', 'races', 'corresponding', 'to', 'each', 'of', 'the', 'passengers', 'a', 'passenger', 'body', 'information-detecting', 'device', 'for', 'detecting', 'body', 'information', 'on', 'one', 'or', 'more', 'passengers', 'of', 'a', 'vehicle', 'based', 'on', 'humans', \"'\", 'status', 'recognition', 'comprising', 'at', 'least', 'one', 'memory', 'that', 'stores', 'instructions', 'and', 'at', 'least', 'one', 'processor', 'configured', 'to', 'execute', 'the', 'instructions', 'to', 'perform', 'or', 'support', 'another', 'device', 'to', 'perform', 'i', 'if', 'at', 'least', 'one', 'interior', 'image', 'of', 'an', 'interior', 'of', 'the', 'vehicle', 'is', 'acquired', 'i', 'a', 'process', 'of', 'inputting', 'the', 'interior', 'image', 'into', 'a', 'face', 'recognition', 'network', 'to', 'thereby', 'allow', 'the', 'face', 'recognition', 'network', 'to', 'detect', 'each', 'of', 'faces', 'of', 'each', 'of', 'the', 'passengers', 'from', 'the', 'interior', 'image', 'and', 'thus', 'to', 'output', 'multiple', 'pieces', 'of', 'passenger', 'feature', 'information', 'corresponding', 'to', 'each', 'of', 'the', 'detected', 'faces', 'and', 'ii', 'a', 'process', 'of', 'inputting', 'the', 'interior', 'image', 'into', 'a', 'body', 'recognition', 'network', 'to', 'thereby', 'allow', 'the', 'body', 'recognition', 'network', 'to', 'detect', 'each', 'of', 'bodies', 'of', 'each', 'of', 'the', 'passengers', 'from', 'the', 'interior', 'image', 'and', 'thus', 'to', 'output', 'body-part', 'length', 'information', 'of', 'each', 'of', 'the', 'detected', 'bodies', 'and', 'ii', 'a', 'process', 'of', 'retrieving', 'specific', 'height', 'mapping', 'information', 'corresponding', 'to', 'specific', 'passenger', 'feature', 'information', 'on', 'a', 'specific', 'passenger', 'from', 'a', 'height', 'mapping', 'table', 'which', 'stores', 'height', 'mapping', 'information', 'representing', 'respective', 'one', 'or', 'more', 'predetermined', 'ratios', 'of', 'one', 'or', 'more', 'segment', 'body', 'portions', 'of', 'each', 'of', 'human', 'groups', 'to', 'each', 'of', 'heights', 'per', 'each', 'of', 'the', 'human', 'groups', 'a', 'process', 'of', 'acquiring', 'a', 'specific', 'height', 'of', 'the', 'specific', 'passenger', 'from', 'the', 'specific', 'height', 'mapping', 'information', 'by', 'referring', 'to', 'specific', 'body-part', 'length', 'information', 'of', 'the', 'specific', 'passenger', 'a', 'process', 'of', 'retrieving', 'specific', 'weight', 'mapping', 'information', 'corresponding', 'to', 'the', 'specific', 'passenger', 'feature', 'information', 'from', 'a', 'weight', 'mapping', 'table', 'which', 'stores', 'multiple', 'pieces', 'of', 'weight', 'mapping', 'information', 'representing', 'predetermined', 'correlations', 'between', 'each', 'of', 'the', 'heights', 'and', 'each', 'of', 'weights', 'per', 'each', 'of', 'the', 'human', 'groups', 'and', 'a', 'process', 'of', 'acquiring', 'a', 'weight', 'of', 'the', 'specific', 'passenger', 'from', 'the', 'specific', 'weight', 'mapping', 'information', 'by', 'referring', 'to', 'the', 'specific', 'height', 'of', 'the', 'specific', 'passenger', 'the', 'passenger', 'body', 'information-detecting', 'device', 'of', 'claim', 'wherein', 'at', 'the', 'process', 'of', 'i', 'the', 'processor', 'performs', 'a', 'process', 'of', 'inputting', 'the', 'interior', 'image', 'into', 'the', 'body', 'recognition', 'network', 'to', 'thereby', 'allow', 'the', 'body', 'recognition', 'network', 'to', 'i', 'output', 'one', 'or', 'more', 'feature', 'tensors', 'with', 'one', 'or', 'more', 'channels', 'corresponding', 'to', 'the', 'interior', 'image', 'via', 'a', 'feature', 'extraction', 'network', 'ii', 'generate', 'at', 'least', 'one', 'keypoint', 'heatmap', 'and', 'at', 'least', 'one', 'part', 'affinity', 'field', 'with', 'one', 'or', 'more', 'channels', 'corresponding', 'to', 'each', 'of', 'the', 'feature', 'tensors', 'via', 'a', 'keypoint', 'heatmap', '&', 'part', 'affinity', 'field', 'extractor', 'and', 'iii', 'extract', 'keypoints', 'from', 'the', 'keypoint', 'heatmap', 'via', 'a', 'keypoint', 'detector', 'to', 'group', 'the', 'extracted', 'keypoints', 'by', 'referring', 'to', 'the', 'part', 'affinity', 'field', 'and', 'thus', 'to', 'generate', 'body', 'parts', 'per', 'the', 'passengers', 'and', 'as', 'a', 'result', 'allow', 'the', 'body', 'recognition', 'network', 'to', 'output', 'multiple', 'pieces', 'of', 'body-part', 'length', 'information', 'on', 'each', 'of', 'the', 'passengers', 'by', 'referring', 'to', 'the', 'body', 'parts', 'per', 'the', 'passengers', 'the', 'passenger', 'body', 'information-detecting', 'device', 'of', 'claim', 'wherein', 'the', 'keypoint', 'heatmap', '&', 'part', 'affinity', 'field', 'extractor', 'includes', 'one', 'of', 'a', 'fully', 'convolutional', 'network', 'and', 'a', '×', 'convolutional', 'layer', 'and', 'applies', 'a', 'fully-convolution', 'operation', 'or', '×', 'convolution', 'operation', 'to', 'the', 'feature', 'tensors', 'to', 'thereby', 'generate', 'the', 'keypoint', 'heatmap', 'and', 'the', 'part', 'affinity', 'field', 'the', 'passenger', 'body', 'information-detecting', 'device', 'of', 'claim', 'wherein', 'the', 'keypoint', 'detector', 'connects', 'by', 'referring', 'to', 'the', 'part', 'affinity', 'field', 'pairs', 'respectively', 'having', 'highest', 'mutual', 'connection', 'probabilities', 'of', 'being', 'connected', 'among', 'the', 'extracted', 'keypoints', 'to', 'thereby', 'group', 'the', 'extracted', 'keypoints', 'the', 'passenger', 'body', 'information-detecting', 'device', 'of', 'claim', 'wherein', 'the', 'feature', 'extraction', 'network', 'and', 'the', 'keypoint', 'heatmap', '&', 'part', 'affinity', 'field', 'extractor', 'have', 'been', 'learned', 'by', 'a', 'learning', 'device', 'performing', 'i', 'a', 'process', 'of', 'inputting', 'at', 'least', 'one', 'training', 'image', 'including', 'one', 'or', 'more', 'objects', 'for', 'training', 'into', 'the', 'feature', 'extraction', 'network', 'to', 'thereby', 'allow', 'the', 'feature', 'extraction', 'network', 'to', 'generate', 'one', 'or', 'more', 'feature', 'tensors', 'for', 'training', 'having', 'one', 'or', 'more', 'channels', 'by', 'applying', 'at', 'least', 'one', 'convolutional', 'operation', 'to', 'the', 'training', 'image', 'ii', 'a', 'process', 'of', 'inputting', 'the', 'feature', 'tensors', 'for', 'training', 'into', 'the', 'keypoint', 'heatmap', '&', 'part', 'affinity', 'field', 'extractor', 'to', 'thereby', 'allow', 'the', 'keypoint', 'heatmap', '&', 'part', 'affinity', 'field', 'extractor', 'to', 'generate', 'one', 'or', 'more', 'keypoint', 'heatmaps', 'for', 'training', 'and', 'one', 'or', 'more', 'part', 'affinity', 'fields', 'for', 'training', 'having', 'one', 'or', 'more', 'channels', 'for', 'each', 'of', 'the', 'feature', 'tensors', 'for', 'training', 'iii', 'a', 'process', 'of', 'inputting', 'the', 'keypoint', 'heatmaps', 'for', 'training', 'and', 'the', 'part', 'affinity', 'fields', 'for', 'training', 'into', 'the', 'keypoint', 'detector', 'to', 'thereby', 'allow', 'the', 'keypoint', 'detector', 'to', 'extract', 'keypoints', 'for', 'training', 'from', 'each', 'of', 'the', 'keypoint', 'heatmaps', 'for', 'training', 'and', 'a', 'process', 'of', 'grouping', 'the', 'extracted', 'keypoints', 'for', 'training', 'by', 'referring', 'to', 'each', 'of', 'the', 'part', 'affinity', 'fields', 'for', 'training', 'to', 'thereby', 'detect', 'keypoints', 'per', 'each', 'of', 'the', 'objects', 'for', 'training', 'and', 'iv', 'a', 'process', 'of', 'allowing', 'a', 'loss', 'layer', 'to', 'calculate', 'one', 'or', 'more', 'losses', 'by', 'referring', 'to', 'the', 'keypoints', 'per', 'each', 'of', 'the', 'objects', 'for', 'training', 'and', 'their', 'corresponding', 'ground', 'truths', 'to', 'thereby', 'adjust', 'one', 'or', 'more', 'parameters', 'of', 'the', 'feature', 'extraction', 'network', 'and', 'the', 'keypoint', 'heatmap', '&', 'part', 'affinity', 'field', 'extractor', 'such', 'that', 'the', 'losses', 'are', 'minimized', 'by', 'backpropagation', 'using', 'the', 'losses', 'the', 'passenger', 'body', 'information-detecting', 'device', 'of', 'claim', 'wherein', 'at', 'the', 'process', 'of', 'i', 'the', 'processor', 'performs', 'a', 'process', 'of', 'inputting', 'the', 'interior', 'image', 'into', 'the', 'face', 'recognition', 'network', 'to', 'thereby', 'allow', 'the', 'face', 'recognition', 'network', 'to', 'i', 'apply', 'at', 'least', 'one', 'convolution', 'operation', 'to', 'the', 'interior', 'image', 'and', 'thus', 'to', 'output', 'at', 'least', 'one', 'feature', 'map', 'corresponding', 'to', 'the', 'interior', 'image', 'via', 'at', 'least', 'one', 'convolutional', 'layer', 'ii', 'output', 'one', 'or', 'more', 'proposal', 'boxes', 'where', 'the', 'passengers', 'are', 'estimated', 'as', 'located', 'on', 'the', 'feature', 'map', 'via', 'a', 'region', 'proposal', 'network', 'iii', 'apply', 'pooling', 'operation', 'to', 'one', 'or', 'more', 'regions', 'corresponding', 'to', 'the', 'proposal', 'boxes', 'on', 'the', 'feature', 'map', 'and', 'thus', 'to', 'output', 'at', 'least', 'one', 'feature', 'vector', 'via', 'a', 'pooling', 'layer', 'and', 'iv', 'apply', 'fully-connected', 'operation', 'to', 'the', 'feature', 'vector', 'and', 'thus', 'to', 'output', 'the', 'multiple', 'pieces', 'of', 'the', 'passenger', 'feature', 'information', 'corresponding', 'to', 'each', 'of', 'the', 'faces', 'of', 'each', 'of', 'the', 'passengers', 'corresponding', 'to', 'each', 'of', 'the', 'proposal', 'boxes', 'via', 'a', 'fully', 'connected', 'layer', 'a', 'computer', 'implemented', 'method', 'for', 'performing', 'video', 'coding', 'based', 'on', 'face', 'detection', 'comprising', 'receiving', 'a', 'video', 'frame', 'comprising', 'one', 'of', 'a', 'plurality', 'of', 'video', 'frames', 'of', 'a', 'video', 'sequence', 'determining', 'the', 'video', 'frame', 'is', 'a', 'key', 'frame', 'of', 'the', 'video', 'sequence', 'performing', 'in', 'response', 'to', 'the', 'video', 'frame', 'being', 'a', 'key', 'frame', 'of', 'the', 'video', 'sequence', 'a', 'multi-stage', 'facial', 'search', 'of', 'the', 'video', 'frame', 'based', 'on', 'predetermined', 'feature', 'templates', 'and', 'a', 'predetermined', 'number', 'of', 'stages', 'to', 'determine', 'a', 'first', 'candidate', 'face', 'region', 'and', 'a', 'second', 'candidate', 'face', 'region', 'in', 'the', 'video', 'frame', 'testing', 'the', 'first', 'and', 'second', 'candidate', 'face', 'regions', 'based', 'on', 'skin', 'tone', 'information', 'to', 'determine', 'the', 'first', 'candidate', 'face', 'region', 'is', 'a', 'valid', 'face', 'region', 'and', 'the', 'second', 'candidate', 'face', 'region', 'is', 'an', 'invalid', 'face', 'region', 'rejecting', 'the', 'second', 'candidate', 'face', 'region', 'and', 'outputting', 'the', 'first', 'candidate', 'face', 'region', 'and', 'encoding', 'the', 'video', 'frame', 'based', 'at', 'least', 'in', 'part', 'on', 'the', 'first', 'candidate', 'face', 'region', 'being', 'a', 'valid', 'face', 'region', 'to', 'generate', 'a', 'coded', 'bitstream', 'the', 'method', 'of', 'claim', 'wherein', 'the', 'skin', 'tone', 'information', 'comprises', 'a', 'skin', 'probability', 'map', 'the', 'method', 'of', 'claim', 'wherein', 'said', 'testing', 'the', 'first', 'and', 'second', 'candidate', 'face', 'regions', 'based', 'on', 'skin', 'tone', 'information', 'is', 'performed', 'in', 'response', 'to', 'the', 'video', 'frame', 'being', 'a', 'key', 'frame', 'of', 'the', 'video', 'sequence', 'the', 'method', 'of', 'claim', 'wherein', 'the', 'first', 'candidate', 'face', 'region', 'comprises', 'a', 'rectangular', 'region', 'the', 'method', 'further', 'comprising', 'determining', 'a', 'free', 'form', 'shape', 'face', 'region', 'corresponding', 'to', 'the', 'first', 'candidate', 'face', 'region', 'wherein', 'the', 'free', 'form', 'shape', 'face', 'region', 'has', 'at', 'least', 'one', 'of', 'a', 'pixel', 'accuracy', 'or', 'a', 'small', 'block', 'of', 'pixels', 'accuracy', 'the', 'method', 'of', 'claim', 'wherein', 'determining', 'the', 'free', 'form', 'shape', 'face', 'region', 'comprises', 'generating', 'an', 'enhanced', 'skip', 'probability', 'map', 'corresponding', 'to', 'the', 'first', 'candidate', 'face', 'region', 'binarizing', 'the', 'enhanced', 'skip', 'probability', 'map', 'and', 'overlaying', 'the', 'binarized', 'enhanced', 'skip', 'probability', 'map', 'over', 'at', 'least', 'a', 'portion', 'of', 'the', 'video', 'frame', 'to', 'provide', 'the', 'free', 'form', 'shape', 'face', 'region', 'the', 'method', 'of', 'claim', 'wherein', 'a', 'second', 'video', 'frame', 'comprises', 'a', 'non-key', 'frame', 'of', 'the', 'video', 'sequence', 'the', 'method', 'further', 'comprising', 'performing', 'face', 'detection', 'in', 'the', 'second', 'video', 'frame', 'of', 'the', 'video', 'sequence', 'based', 'on', 'the', 'free', 'form', 'shape', 'face', 'region', 'the', 'method', 'of', 'claim', 'further', 'comprising', 'tracking', 'a', 'second', 'free', 'form', 'shape', 'face', 'region', 'in', 'the', 'second', 'video', 'frame', 'based', 'on', 'the', 'free', 'form', 'shape', 'face', 'region', 'in', 'the', 'video', 'frame', 'the', 'method', 'of', 'claim', 'wherein', 'tracking', 'the', 'second', 'free', 'form', 'shape', 'face', 'region', 'comprises', 'determining', 'a', 'location', 'of', 'a', 'second', 'valid', 'face', 'region', 'in', 'the', 'second', 'video', 'frame', 'based', 'on', 'a', 'displacement', 'offset', 'with', 'respect', 'to', 'the', 'first', 'candidate', 'face', 'region', 'the', 'method', 'of', 'claim', 'further', 'comprising', 'determining', 'the', 'displacement', 'offset', 'based', 'on', 'an', 'offset', 'between', 'a', 'centroid', 'of', 'a', 'bounding', 'box', 'around', 'a', 'skin', 'enhanced', 'region', 'corresponding', 'to', 'the', 'first', 'candidate', 'face', 'region', 'and', 'a', 'second', 'centroid', 'of', 'a', 'second', 'bounding', 'box', 'around', 'a', 'second', 'skin', 'enhanced', 'region', 'in', 'the', 'second', 'video', 'frame', 'the', 'method', 'of', 'claim', 'wherein', 'encoding', 'the', 'video', 'frame', 'based', 'at', 'least', 'in', 'part', 'on', 'the', 'first', 'candidate', 'face', 'region', 'being', 'a', 'valid', 'face', 'region', 'comprises', 'at', 'least', 'one', 'of', 'reducing', 'a', 'quantization', 'parameter', 'corresponding', 'to', 'the', 'first', 'candidate', 'face', 'region', 'adjusting', 'a', 'lambda', 'value', 'for', 'the', 'first', 'candidate', 'face', 'region', 'or', 'disabling', 'skip', 'coding', 'for', 'the', 'first', 'candidate', 'face', 'region', 'the', 'method', 'of', 'claim', 'wherein', 'the', 'bitstream', 'comprises', 'at', 'least', 'one', 'of', 'an', 'hadvanced', 'video', 'coding', 'avc', 'compliant', 'bitstream', 'an', 'hhigh', 'efficiency', 'video', 'coding', 'hevc', 'compliant', 'bitstream', 'a', 'vp', 'compliant', 'bitstream', 'a', 'vp', 'compliant', 'bitstream', 'or', 'an', 'alliance', 'for', 'open', 'media', 'aom', 'av', 'compliant', 'bitstream', 'a', 'computer', 'implemented', 'method', 'for', 'performing', 'face', 'detection', 'comprising', 'receiving', 'a', 'video', 'frame', 'of', 'a', 'sequence', 'of', 'video', 'frames', 'performing', 'a', 'multi-stage', 'facial', 'search', 'of', 'the', 'video', 'frame', 'based', 'on', 'predetermined', 'feature', 'templates', 'and', 'a', 'predetermined', 'number', 'of', 'stages', 'to', 'determine', 'a', 'first', 'candidate', 'face', 'region', 'and', 'a', 'second', 'candidate', 'face', 'region', 'in', 'the', 'video', 'frame', 'testing', 'the', 'first', 'and', 'second', 'candidate', 'face', 'regions', 'based', 'on', 'skin', 'tone', 'information', 'to', 'determine', 'the', 'first', 'candidate', 'face', 'region', 'is', 'a', 'valid', 'face', 'region', 'and', 'the', 'second', 'candidate', 'face', 'region', 'is', 'an', 'invalid', 'face', 'region', 'rejecting', 'the', 'second', 'candidate', 'face', 'region', 'and', 'outputting', 'the', 'first', 'candidate', 'face', 'region', 'as', 'a', 'valid', 'face', 'region', 'for', 'further', 'processing', 'and', 'providing', 'an', 'index', 'indicative', 'of', 'a', 'person', 'being', 'present', 'in', 'the', 'video', 'frame', 'based', 'on', 'the', 'valid', 'face', 'region', 'the', 'method', 'of', 'claim', 'wherein', 'the', 'sequence', 'of', 'video', 'frames', 'comprises', 'a', 'sequence', 'of', 'surveillance', 'video', 'frames', 'the', 'method', 'further', 'comprising', 'performing', 'face', 'recognition', 'in', 'the', 'surveillance', 'video', 'frames', 'based', 'on', 'the', 'valid', 'face', 'region', 'the', 'method', 'of', 'claim', 'wherein', 'the', 'sequence', 'of', 'video', 'frames', 'comprises', 'a', 'sequence', 'of', 'decoded', 'video', 'frames', 'the', 'method', 'further', 'comprising', 'adding', 'a', 'marker', 'corresponding', 'to', 'the', 'received', 'video', 'frame', 'to', 'perform', 'face', 'recognition', 'on', 'the', 'received', 'video', 'frame', 'based', 'on', 'the', 'valid', 'face', 'region', 'the', 'method', 'of', 'claim', 'wherein', 'the', 'sequence', 'of', 'video', 'frames', 'is', 'received', 'during', 'a', 'device', 'login', 'attempt', 'the', 'method', 'further', 'comprising', 'performing', 'face', 'recognition', 'based', 'on', 'the', 'valid', 'face', 'region', 'and', 'allowing', 'access', 'to', 'the', 'device', 'if', 'a', 'secured', 'face', 'is', 'recognized', 'the', 'method', 'of', 'claim', 'wherein', 'the', 'sequence', 'of', 'video', 'frames', 'comprises', 'a', 'sequence', 'of', 'videoconferencing', 'frames', 'the', 'method', 'further', 'comprising', 'encoding', 'the', 'video', 'frame', 'based', 'at', 'least', 'in', 'part', 'on', 'the', 'valid', 'face', 'region', 'to', 'generate', 'a', 'coded', 'bitstream', 'the', 'method', 'of', 'claim', 'wherein', 'encoding', 'the', 'video', 'frame', 'comprises', 'not', 'encoding', 'a', 'background', 'region', 'of', 'the', 'video', 'frame', 'into', 'the', 'bitstream', 'the', 'method', 'of', 'claim', 'further', 'comprising', 'encoding', 'the', 'video', 'frame', 'based', 'at', 'least', 'in', 'part', 'on', 'the', 'valid', 'face', 'region', 'to', 'generate', 'a', 'coded', 'bitstream', 'wherein', 'encoding', 'the', 'video', 'frame', 'comprises', 'including', 'metadata', 'corresponding', 'to', 'the', 'valid', 'face', 'region', 'in', 'the', 'bitstream', 'the', 'method', 'of', 'claim', 'further', 'comprising', 'decoding', 'the', 'coded', 'bitstream', 'to', 'generate', 'a', 'decoded', 'video', 'frame', 'and', 'to', 'determine', 'the', 'metadata', 'corresponding', 'to', 'the', 'valid', 'face', 'region', 'in', 'the', 'bitstream', 'the', 'method', 'of', 'claim', 'further', 'comprising', 'at', 'least', 'one', 'of', 'replacing', 'the', 'valid', 'face', 'region', 'based', 'on', 'the', 'decoded', 'metadata', 'cropping', 'and', 'displaying', 'image', 'data', 'corresponding', 'only', 'to', 'the', 'valid', 'face', 'region', 'based', 'on', 'the', 'decoded', 'metadata', 'or', 'indexing', 'the', 'decoded', 'video', 'frame', 'based', 'on', 'the', 'decoded', 'metadata', 'a', 'system', 'for', 'performing', 'video', 'coding', 'based', 'on', 'face', 'detection', 'comprising', 'a', 'memory', 'configured', 'to', 'store', 'a', 'video', 'frame', 'comprising', 'one', 'of', 'a', 'plurality', 'of', 'video', 'frames', 'of', 'a', 'video', 'sequence', 'and', 'a', 'processor', 'coupled', 'to', 'the', 'memory', 'the', 'processor', 'to', 'receive', 'the', 'video', 'frame', 'to', 'determine', 'the', 'video', 'frame', 'is', 'a', 'key', 'frame', 'of', 'the', 'video', 'sequence', 'to', 'perform', 'in', 'response', 'to', 'the', 'video', 'frame', 'being', 'a', 'key', 'frame', 'of', 'the', 'video', 'sequence', 'a', 'multi-stage', 'facial', 'search', 'of', 'the', 'video', 'frame', 'based', 'on', 'predetermined', 'feature', 'templates', 'and', 'a', 'predetermined', 'number', 'of', 'stages', 'to', 'determine', 'a', 'first', 'candidate', 'face', 'region', 'and', 'a', 'second', 'candidate', 'face', 'region', 'in', 'the', 'video', 'frame', 'to', 'test', 'the', 'first', 'and', 'second', 'candidate', 'face', 'regions', 'based', 'on', 'skin', 'tone', 'information', 'to', 'determine', 'the', 'first', 'candidate', 'face', 'region', 'is', 'a', 'valid', 'face', 'region', 'and', 'the', 'second', 'candidate', 'face', 'region', 'is', 'an', 'invalid', 'face', 'region', 'to', 'reject', 'the', 'second', 'candidate', 'face', 'region', 'and', 'outputting', 'the', 'first', 'candidate', 'face', 'region', 'and', 'to', 'encode', 'the', 'video', 'frame', 'based', 'at', 'least', 'in', 'part', 'on', 'the', 'first', 'candidate', 'face', 'region', 'being', 'a', 'valid', 'face', 'region', 'to', 'generate', 'a', 'coded', 'bitstream', 'the', 'system', 'of', 'claim', 'wherein', 'the', 'skin', 'tone', 'information', 'comprises', 'a', 'skin', 'probability', 'map', 'the', 'system', 'of', 'claim', 'wherein', 'the', 'first', 'candidate', 'face', 'region', 'comprises', 'a', 'rectangular', 'region', 'the', 'processor', 'further', 'to', 'determine', 'a', 'free', 'form', 'shape', 'face', 'region', 'corresponding', 'to', 'the', 'first', 'candidate', 'face', 'region', 'wherein', 'the', 'free', 'form', 'shape', 'face', 'region', 'has', 'at', 'least', 'one', 'of', 'a', 'pixel', 'accuracy', 'or', 'a', 'small', 'block', 'of', 'pixels', 'accuracy', 'the', 'system', 'of', 'claim', 'wherein', 'the', 'processor', 'to', 'determine', 'the', 'free', 'form', 'shape', 'face', 'region', 'comprises', 'the', 'processor', 'to', 'generate', 'an', 'enhanced', 'skip', 'probability', 'map', 'corresponding', 'to', 'the', 'first', 'candidate', 'face', 'region', 'to', 'binarize', 'the', 'enhanced', 'skip', 'probability', 'map', 'and', 'to', 'overlay', 'the', 'binarized', 'enhanced', 'skip', 'probability', 'map', 'over', 'at', 'least', 'a', 'portion', 'of', 'the', 'video', 'frame', 'to', 'provide', 'the', 'free', 'form', 'shape', 'face', 'region', 'the', 'system', 'of', 'claim', 'wherein', 'a', 'second', 'video', 'frame', 'comprises', 'a', 'non-key', 'frame', 'of', 'the', 'video', 'sequence', 'and', 'the', 'processor', 'is', 'further', 'to', 'perform', 'face', 'detection', 'in', 'the', 'second', 'video', 'frame', 'of', 'the', 'video', 'sequence', 'based', 'on', 'the', 'free', 'form', 'shape', 'face', 'region', 'the', 'system', 'of', 'claim', 'wherein', 'the', 'processor', 'is', 'further', 'to', 'track', 'a', 'second', 'free', 'form', 'shape', 'face', 'region', 'in', 'the', 'second', 'video', 'frame', 'based', 'on', 'the', 'free', 'form', 'shape', 'face', 'region', 'in', 'the', 'video', 'frame', 'the', 'system', 'of', 'claim', 'wherein', 'to', 'encode', 'the', 'video', 'frame', 'based', 'at', 'least', 'in', 'part', 'on', 'the', 'first', 'candidate', 'face', 'region', 'being', 'a', 'valid', 'face', 'region', 'comprises', 'the', 'processor', 'to', 'reduce', 'a', 'quantization', 'parameter', 'corresponding', 'to', 'the', 'first', 'candidate', 'face', 'region', 'adjust', 'a', 'lambda', 'value', 'for', 'the', 'first', 'candidate', 'face', 'region', 'or', 'disable', 'skip', 'coding', 'for', 'the', 'first', 'candidate', 'face', 'region', 'at', 'least', 'one', 'non-transitory', 'machine', 'readable', 'medium', 'comprising', 'a', 'plurality', 'of', 'instructions', 'that', 'in', 'response', 'to', 'being', 'executed', 'on', 'a', 'device', 'cause', 'the', 'device', 'to', 'perform', 'video', 'coding', 'based', 'on', 'face', 'detection', 'by', 'receiving', 'a', 'video', 'frame', 'comprising', 'one', 'of', 'a', 'plurality', 'of', 'video', 'frames', 'of', 'a', 'video', 'sequence', 'determining', 'the', 'video', 'frame', 'is', 'a', 'key', 'frame', 'of', 'the', 'video', 'sequence', 'performing', 'in', 'response', 'to', 'the', 'video', 'frame', 'being', 'a', 'key', 'frame', 'of', 'the', 'video', 'sequence', 'a', 'multi-stage', 'facial', 'search', 'of', 'the', 'video', 'frame', 'based', 'on', 'predetermined', 'feature', 'templates', 'and', 'a', 'predetermined', 'number', 'of', 'stages', 'to', 'determine', 'a', 'first', 'candidate', 'face', 'region', 'and', 'a', 'second', 'candidate', 'face', 'region', 'in', 'the', 'video', 'frame', 'testing', 'the', 'first', 'and', 'second', 'candidate', 'face', 'regions', 'based', 'on', 'skin', 'tone', 'information', 'to', 'determine', 'the', 'first', 'candidate', 'face', 'region', 'is', 'a', 'valid', 'face', 'region', 'and', 'the', 'second', 'candidate', 'face', 'region', 'is', 'an', 'invalid', 'face', 'region', 'rejecting', 'the', 'second', 'candidate', 'face', 'region', 'and', 'outputting', 'the', 'first', 'candidate', 'face', 'region', 'and', 'encoding', 'the', 'video', 'frame', 'based', 'at', 'least', 'in', 'part', 'on', 'the', 'first', 'candidate', 'face', 'region', 'being', 'a', 'valid', 'face', 'region', 'to', 'generate', 'a', 'coded', 'bitstream', 'the', 'non-transitory', 'machine', 'readable', 'medium', 'of', 'claim', 'wherein', 'the', 'skin', 'tone', 'information', 'comprises', 'a', 'skin', 'probability', 'map', 'the', 'non-transitory', 'machine', 'readable', 'medium', 'of', 'claim', 'wherein', 'the', 'first', 'candidate', 'face', 'region', 'comprises', 'a', 'rectangular', 'region', 'the', 'machine', 'readable', 'medium', 'comprising', 'further', 'instructions', 'that', 'in', 'response', 'to', 'being', 'executed', 'on', 'the', 'device', 'cause', 'the', 'device', 'to', 'perform', 'video', 'coding', 'based', 'on', 'face', 'detection', 'by', 'determining', 'a', 'free', 'form', 'shape', 'face', 'region', 'corresponding', 'to', 'the', 'first', 'candidate', 'face', 'region', 'wherein', 'the', 'free', 'form', 'shape', 'face', 'region', 'has', 'at', 'least', 'one', 'of', 'a', 'pixel', 'accuracy', 'or', 'a', 'small', 'block', 'of', 'pixels', 'accuracy', 'the', 'non-transitory', 'machine', 'readable', 'medium', 'of', 'claim', 'wherein', 'determining', 'the', 'free', 'form', 'shape', 'face', 'region', 'comprises', 'generating', 'an', 'enhanced', 'skip', 'probability', 'map', 'corresponding', 'to', 'the', 'first', 'candidate', 'face', 'region', 'binarizing', 'the', 'enhanced', 'skip', 'probability', 'map', 'and', 'overlaying', 'the', 'binarized', 'enhanced', 'skip', 'probability', 'map', 'over', 'at', 'least', 'a', 'portion', 'of', 'the', 'video', 'frame', 'to', 'provide', 'the', 'free', 'form', 'shape', 'face', 'region', 'the', 'non-transitory', 'machine', 'readable', 'medium', 'of', 'claim', 'wherein', 'a', 'second', 'video', 'frame', 'comprises', 'a', 'non-key', 'frame', 'of', 'the', 'video', 'sequence', 'the', 'machine', 'readable', 'medium', 'comprising', 'further', 'instructions', 'that', 'in', 'response', 'to', 'being', 'executed', 'on', 'the', 'device', 'cause', 'the', 'device', 'to', 'perform', 'video', 'coding', 'based', 'on', 'face', 'detection', 'by', 'performing', 'face', 'detection', 'in', 'the', 'second', 'video', 'frame', 'of', 'the', 'video', 'sequence', 'based', 'on', 'the', 'free', 'form', 'shape', 'face', 'region', 'the', 'non-transitory', 'machine', 'readable', 'medium', 'of', 'claim', 'the', 'machine', 'readable', 'medium', 'comprising', 'further', 'instructions', 'that', 'in', 'response', 'to', 'being', 'executed', 'on', 'the', 'device', 'cause', 'the', 'device', 'to', 'perform', 'video', 'coding', 'based', 'on', 'face', 'detection', 'by', 'tracking', 'a', 'second', 'free', 'form', 'shape', 'face', 'region', 'in', 'the', 'second', 'video', 'frame', 'based', 'on', 'the', 'free', 'form', 'shape', 'face', 'region', 'in', 'the', 'video', 'frame', 'the', 'non-transitory', 'machine', 'readable', 'medium', 'of', 'claim', 'wherein', 'encoding', 'the', 'video', 'frame', 'based', 'at', 'least', 'in', 'part', 'on', 'the', 'first', 'candidate', 'face', 'region', 'being', 'a', 'valid', 'face', 'region', 'comprises', 'at', 'least', 'one', 'of', 'reducing', 'a', 'quantization', 'parameter', 'corresponding', 'to', 'the', 'first', 'candidate', 'face', 'region', 'adjusting', 'a', 'lambda', 'value', 'for', 'the', 'first', 'candidate', 'face', 'region', 'or', 'disabling', 'skip', 'coding', 'for', 'the', 'first', 'candidate', 'face', 'region', 'a', 'method', 'for', 'managing', 'a', 'smart', 'database', 'which', 'stores', 'facial', 'images', 'for', 'face', 'recognition', 'comprising', 'steps', 'of', 'a', 'a', 'managing', 'device', 'performing', 'a', 'process', 'of', 'counting', 'one', 'or', 'more', 'specific', 'facial', 'images', 'corresponding', 'to', 'at', 'least', 'one', 'specific', 'person', 'stored', 'in', 'the', 'smart', 'database', 'where', 'new', 'facial', 'images', 'for', 'the', 'face', 'recognition', 'are', 'continuously', 'stored', 'and', 'a', 'process', 'of', 'determining', 'whether', 'a', 'first', 'counted', 'value', 'representing', 'a', 'count', 'of', 'the', 'specific', 'facial', 'images', 'satisfies', 'a', 'preset', 'first', 'set', 'value', 'and', 'b', 'if', 'the', 'first', 'counted', 'value', 'is', 'determined', 'as', 'satisfying', 'the', 'first', 'set', 'value', 'the', 'managing', 'device', 'performing', 'a', 'process', 'of', 'inputting', 'the', 'specific', 'facial', 'images', 'into', 'a', 'neural', 'aggregation', 'network', 'to', 'thereby', 'allow', 'the', 'neural', 'aggregation', 'network', 'to', 'generate', 'each', 'of', 'quality', 'scores', 'of', 'each', 'of', 'the', 'specific', 'facial', 'images', 'by', 'aggregation', 'of', 'the', 'specific', 'facial', 'images', 'and', 'a', 'process', 'of', 'sorting', 'the', 'quality', 'scores', 'corresponding', 'to', 'the', 'specific', 'facial', 'images', 'in', 'a', 'descending', 'order', 'of', 'the', 'quality', 'scores', 'a', 'process', 'of', 'counting', 'the', 'sorted', 'specific', 'facial', 'images', 'in', 'the', 'descending', 'order', 'until', 'a', 'second', 'counted', 'value', 'which', 'represents', 'the', 'number', 'of', 'a', 'counted', 'part', 'of', 'the', 'specific', 'facial', 'images', 'becomes', 'equal', 'to', 'a', 'preset', 'second', 'set', 'value', 'and', 'a', 'process', 'of', 'deleting', 'an', 'uncounted', 'part', 'of', 'the', 'specific', 'facial', 'images', 'from', 'the', 'smart', 'database', 'the', 'method', 'of', 'claim', 'further', 'comprising', 'a', 'step', 'of', 'c', 'the', 'managing', 'device', 'performing', 'a', 'process', 'of', 'generating', 'at', 'least', 'one', 'optimal', 'feature', 'by', 'weighted', 'summation', 'of', 'one', 'or', 'more', 'features', 'of', 'the', 'specific', 'facial', 'images', 'using', 'the', 'counted', 'part', 'of', 'the', 'quality', 'scores', 'and', 'a', 'process', 'of', 'setting', 'the', 'optimal', 'feature', 'as', 'a', 'representative', 'face', 'corresponding', 'to', 'the', 'specific', 'person', 'the', 'method', 'of', 'claim', 'wherein', 'at', 'the', 'step', 'of', 'b', 'the', 'managing', 'device', 'performs', 'a', 'process', 'of', 'inputting', 'the', 'specific', 'facial', 'images', 'into', 'a', 'cnn', 'of', 'the', 'neural', 'aggregation', 'network', 'to', 'thereby', 'allow', 'the', 'cnn', 'to', 'generate', 'one', 'or', 'more', 'features', 'corresponding', 'to', 'each', 'of', 'the', 'specific', 'facial', 'images', 'and', 'a', 'process', 'of', 'inputting', 'at', 'least', 'one', 'feature', 'vector', 'where', 'the', 'features', 'are', 'embedded', 'into', 'an', 'aggregation', 'module', 'including', 'at', 'least', 'two', 'attention', 'blocks', 'to', 'thereby', 'allow', 'the', 'aggregation', 'module', 'to', 'generate', 'each', 'of', 'the', 'quality', 'scores', 'of', 'each', 'of', 'the', 'features', 'the', 'method', 'of', 'claim', 'wherein', 'at', 'the', 'step', 'of', 'b', 'the', 'managing', 'device', 'performs', 'a', 'process', 'of', 'matching', 'i', 'i-', 'one', 'or', 'more', 'features', 'corresponding', 'to', 'each', 'of', 'the', 'specific', 'facial', 'images', 'stored', 'in', 'the', 'smart', 'database', 'and', 'i-', 'the', 'quality', 'scores', 'with', 'ii', 'the', 'specific', 'person', 'and', 'a', 'process', 'of', 'storing', 'the', 'matched', 'features', 'and', 'the', 'matched', 'quality', 'scores', 'in', 'the', 'smart', 'database', 'the', 'method', 'of', 'claim', 'further', 'comprising', 'a', 'step', 'of', 'd', 'the', 'managing', 'device', 'performing', 'one', 'of', 'i', 'a', 'process', 'of', 'learning', 'a', 'face', 'recognition', 'system', 'by', 'using', 'the', 'specific', 'facial', 'images', 'corresponding', 'to', 'the', 'specific', 'person', 'stored', 'in', 'the', 'smart', 'database', 'and', 'ii', 'a', 'process', 'of', 'transmitting', 'the', 'specific', 'facial', 'images', 'corresponding', 'to', 'the', 'specific', 'person', 'to', 'a', 'learning', 'device', 'corresponding', 'to', 'the', 'face', 'recognition', 'system', 'to', 'thereby', 'allow', 'the', 'learning', 'device', 'to', 'learn', 'the', 'face', 'recognition', 'system', 'using', 'the', 'specific', 'facial', 'images', 'the', 'method', 'of', 'claim', 'wherein', 'the', 'neural', 'aggregation', 'network', 'has', 'been', 'learned', 'by', 'a', 'learning', 'device', 'repeating', 'more', 'than', 'once', 'i', 'a', 'process', 'of', 'inputting', 'multiple', 'facial', 'images', 'for', 'training', 'corresponding', 'to', 'an', 'image', 'set', 'of', 'a', 'single', 'face', 'or', 'a', 'video', 'of', 'the', 'single', 'face', 'into', 'a', 'cnn', 'of', 'the', 'neural', 'aggregation', 'network', 'to', 'thereby', 'allow', 'the', 'cnn', 'to', 'generate', 'one', 'or', 'more', 'features', 'for', 'training', 'by', 'applying', 'at', 'least', 'one', 'convolution', 'operation', 'to', 'the', 'facial', 'images', 'for', 'training', 'ii', 'a', 'process', 'of', 'inputting', 'at', 'least', 'one', 'feature', 'vector', 'for', 'training', 'where', 'the', 'features', 'for', 'training', 'are', 'embedded', 'into', 'an', 'aggregation', 'module', 'including', 'at', 'least', 'two', 'attention', 'blocks', 'of', 'the', 'neural', 'aggregation', 'network', 'to', 'thereby', 'allow', 'the', 'aggregation', 'module', 'to', 'generate', 'each', 'of', 'quality', 'scores', 'for', 'training', 'of', 'each', 'of', 'the', 'features', 'for', 'training', 'by', 'aggregation', 'of', 'the', 'features', 'for', 'training', 'using', 'one', 'or', 'more', 'attention', 'parameters', 'learned', 'in', 'a', 'previous', 'iteration', 'iii', 'a', 'process', 'of', 'outputting', 'at', 'least', 'one', 'optimal', 'feature', 'for', 'training', 'by', 'weighted', 'summation', 'of', 'the', 'features', 'for', 'training', 'using', 'the', 'quality', 'scores', 'for', 'training', 'and', 'iv', 'a', 'process', 'of', 'updating', 'the', 'attention', 'parameters', 'learned', 'in', 'the', 'previous', 'iteration', 'of', 'the', 'at', 'least', 'two', 'attention', 'blocks', 'such', 'that', 'one', 'or', 'more', 'losses', 'are', 'minimized', 'which', 'are', 'outputted', 'from', 'a', 'loss', 'layer', 'by', 'referring', 'to', 'the', 'optimal', 'feature', 'for', 'training', 'and', 'its', 'corresponding', 'ground', 'truth', 'a', 'managing', 'device', 'for', 'managing', 'a', 'smart', 'database', 'which', 'stores', 'facial', 'images', 'for', 'face', 'recognition', 'comprising', 'at', 'least', 'one', 'memory', 'that', 'stores', 'instructions', 'and', 'at', 'least', 'one', 'processor', 'configured', 'to', 'execute', 'the', 'instructions', 'to', 'perform', 'or', 'support', 'another', 'device', 'to', 'perform', 'i', 'a', 'process', 'of', 'counting', 'one', 'or', 'more', 'specific', 'facial', 'images', 'corresponding', 'to', 'at', 'least', 'one', 'specific', 'person', 'stored', 'in', 'the', 'smart', 'database', 'where', 'new', 'facial', 'images', 'for', 'the', 'face', 'recognition', 'are', 'continuously', 'stored', 'and', 'a', 'process', 'of', 'determining', 'whether', 'a', 'first', 'counted', 'value', 'representing', 'a', 'count', 'of', 'the', 'specific', 'facial', 'images', 'satisfies', 'a', 'preset', 'first', 'set', 'value', 'and', 'ii', 'if', 'the', 'first', 'counted', 'value', 'is', 'determined', 'as', 'satisfying', 'the', 'first', 'set', 'value', 'a', 'process', 'of', 'inputting', 'the', 'specific', 'facial', 'images', 'into', 'a', 'neural', 'aggregation', 'network', 'to', 'thereby', 'allow', 'the', 'neural', 'aggregation', 'network', 'to', 'generate', 'each', 'of', 'quality', 'scores', 'of', 'each', 'of', 'the', 'specific', 'facial', 'images', 'by', 'aggregation', 'of', 'the', 'specific', 'facial', 'images', 'and', 'a', 'process', 'of', 'sorting', 'the', 'quality', 'scores', 'corresponding', 'to', 'the', 'specific', 'facial', 'images', 'in', 'a', 'descending', 'order', 'of', 'the', 'quality', 'scores', 'a', 'process', 'of', 'counting', 'the', 'sorted', 'specific', 'facial', 'images', 'in', 'the', 'descending', 'order', 'until', 'a', 'second', 'counted', 'value', 'which', 'represents', 'the', 'number', 'of', 'a', 'counted', 'part', 'of', 'the', 'specific', 'facial', 'images', 'becomes', 'equal', 'to', 'a', 'preset', 'second', 'set', 'value', 'and', 'a', 'process', 'of', 'deleting', 'an', 'uncounted', 'part', 'of', 'the', 'specific', 'facial', 'images', 'from', 'the', 'smart', 'database', 'the', 'managing', 'device', 'of', 'claim', 'wherein', 'the', 'processor', 'further', 'performs', 'iii', 'a', 'process', 'of', 'generating', 'at', 'least', 'one', 'optimal', 'feature', 'by', 'weighted', 'summation', 'of', 'one', 'or', 'more', 'features', 'of', 'the', 'specific', 'facial', 'images', 'using', 'the', 'counted', 'part', 'of', 'the', 'quality', 'scores', 'and', 'a', 'process', 'of', 'setting', 'the', 'optimal', 'feature', 'as', 'a', 'representative', 'face', 'corresponding', 'to', 'the', 'specific', 'person', 'the', 'managing', 'device', 'of', 'claim', 'wherein', 'at', 'the', 'process', 'of', 'ii', 'the', 'processor', 'performs', 'a', 'process', 'of', 'inputting', 'the', 'specific', 'facial', 'images', 'into', 'a', 'cnn', 'of', 'the', 'neural', 'aggregation', 'network', 'to', 'thereby', 'allow', 'the', 'cnn', 'to', 'generate', 'one', 'or', 'more', 'features', 'corresponding', 'to', 'each', 'of', 'the', 'specific', 'facial', 'images', 'and', 'a', 'process', 'of', 'inputting', 'at', 'least', 'one', 'feature', 'vector', 'where', 'the', 'features', 'are', 'embedded', 'into', 'an', 'aggregation', 'module', 'including', 'at', 'least', 'two', 'attention', 'blocks', 'to', 'thereby', 'allow', 'the', 'aggregation', 'module', 'to', 'generate', 'each', 'of', 'the', 'quality', 'scores', 'of', 'each', 'of', 'the', 'features', 'the', 'managing', 'device', 'of', 'claim', 'wherein', 'at', 'the', 'process', 'of', 'ii', 'the', 'processor', 'performs', 'a', 'process', 'of', 'matching', 'i', 'i-', 'one', 'or', 'more', 'features', 'corresponding', 'to', 'each', 'of', 'the', 'specific', 'facial', 'images', 'stored', 'in', 'the', 'smart', 'database', 'and', 'i-', 'the', 'quality', 'scores', 'with', 'ii', 'the', 'specific', 'person', 'and', 'a', 'process', 'of', 'storing', 'the', 'matched', 'features', 'and', 'the', 'matched', 'quality', 'scores', 'in', 'the', 'smart', 'database', 'the', 'managing', 'device', 'of', 'claim', 'wherein', 'the', 'processor', 'further', 'performs', 'iv', 'one', 'of', 'i', 'a', 'process', 'of', 'learning', 'a', 'face', 'recognition', 'system', 'by', 'using', 'the', 'specific', 'facial', 'images', 'corresponding', 'to', 'the', 'specific', 'person', 'stored', 'in', 'the', 'smart', 'database', 'and', 'ii', 'a', 'process', 'of', 'transmitting', 'the', 'specific', 'facial', 'images', 'corresponding', 'to', 'the', 'specific', 'person', 'to', 'a', 'learning', 'device', 'corresponding', 'to', 'the', 'face', 'recognition', 'system', 'to', 'thereby', 'allow', 'the', 'learning', 'device', 'to', 'learn', 'the', 'face', 'recognition', 'system', 'using', 'the', 'specific', 'facial', 'images', 'the', 'managing', 'device', 'of', 'claim', 'wherein', 'the', 'neural', 'aggregation', 'network', 'has', 'been', 'learned', 'by', 'a', 'learning', 'device', 'repeating', 'more', 'than', 'once', 'i', 'a', 'process', 'of', 'inputting', 'multiple', 'facial', 'images', 'for', 'training', 'corresponding', 'to', 'an', 'image', 'set', 'of', 'a', 'single', 'face', 'or', 'a', 'video', 'of', 'the', 'single', 'face', 'into', 'a', 'cnn', 'of', 'the', 'neural', 'aggregation', 'network', 'to', 'thereby', 'allow', 'the', 'cnn', 'to', 'generate', 'one', 'or', 'more', 'features', 'for', 'training', 'by', 'applying', 'at', 'least', 'one', 'convolution', 'operation', 'to', 'the', 'facial', 'images', 'for', 'training', 'ii', 'a', 'process', 'of', 'inputting', 'at', 'least', 'one', 'feature', 'vector', 'for', 'training', 'where', 'the', 'features', 'for', 'training', 'are', 'embedded', 'into', 'an', 'aggregation', 'module', 'including', 'at', 'least', 'two', 'attention', 'blocks', 'of', 'the', 'neural', 'aggregation', 'network', 'to', 'thereby', 'allow', 'the', 'aggregation', 'module', 'to', 'generate', 'each', 'of', 'quality', 'scores', 'for', 'training', 'of', 'each', 'of', 'the', 'features', 'for', 'training', 'by', 'aggregation', 'of', 'the', 'features', 'for', 'training', 'using', 'one', 'or', 'more', 'attention', 'parameters', 'learned', 'in', 'a', 'previous', 'iteration', 'iii', 'a', 'process', 'of', 'outputting', 'at', 'least', 'one', 'optimal', 'feature', 'for', 'training', 'by', 'weighted', 'summation', 'of', 'the', 'features', 'for', 'training', 'using', 'the', 'quality', 'scores', 'for', 'training', 'and', 'iv', 'a', 'process', 'of', 'updating', 'the', 'attention', 'parameters', 'learned', 'in', 'the', 'previous', 'iteration', 'of', 'the', 'at', 'least', 'two', 'attention', 'blocks', 'such', 'that', 'one', 'or', 'more', 'losses', 'are', 'minimized', 'which', 'are', 'outputted', 'from', 'a', 'loss', 'layer', 'by', 'referring', 'to', 'the', 'optimal', 'feature', 'for', 'training', 'and', 'its', 'corresponding', 'ground', 'truth', 'an', 'object', 'data', 'processing', 'system', 'comprising', 'at', 'least', 'one', 'processor', 'configured', 'to', 'execute', 'at', 'least', 'one', 'implementation', 'of', 'a', 'plurality', 'of', 'recognition', 'algorithms', 'stored', 'on', 'at', 'least', 'one', 'non-transitory', 'computer-readable', 'storage', 'medium', 'each', 'recognition', 'algorithm', 'having', 'feature', 'density', 'selection', 'criteria', 'and', 'data', 'preprocessing', 'code', 'executed', 'by', 'at', 'least', 'one', 'processor', 'the', 'data', 'preprocessing', 'code', 'comprising', 'an', 'invariant', 'feature', 'identification', 'algorithm', 'and', 'configured', 'to', 'obtain', 'a', 'digital', 'representation', 'of', 'a', 'scene', 'the', 'scene', 'comprising', 'one', 'or', 'more', 'textual', 'media', 'generate', 'a', 'set', 'of', 'invariant', 'features', 'by', 'applying', 'the', 'invariant', 'feature', 'identification', 'algorithm', 'to', 'the', 'digital', 'representation', 'cluster', 'the', 'set', 'of', 'invariant', 'features', 'into', 'regions', 'of', 'interest', 'in', 'the', 'digital', 'representation', 'of', 'the', 'scene', 'each', 'region', 'of', 'interest', 'having', 'a', 'region', 'feature', 'density', 'classify', 'by', 'region', 'classifier', 'code', 'at', 'least', 'one', 'of', 'the', 'regions', 'of', 'interest', 'according', 'to', 'object', 'type', 'as', 'a', 'function', 'of', 'attributes', 'derived', 'from', 'the', 'region', 'feature', 'density', 'and', 'the', 'digital', 'representation', 'wherein', 'the', 'at', 'least', 'one', 'of', 'the', 'classified', 'regions', 'of', 'interest', 'corresponds', 'to', 'text', 'and', 'use', 'a', 'classification', 'result', 'corresponding', 'to', 'the', 'at', 'least', 'one', 'of', 'the', 'regions', 'of', 'interest', 'to', 'classify', 'another', 'of', 'the', 'regions', 'of', 'interest', 'according', 'to', 'object', 'type', 'wherein', 'the', 'another', 'of', 'the', 'regions', 'of', 'interest', 'corresponds', 'to', 'a', 'region', 'of', 'interest', 'for', 'images', 'the', 'system', 'of', 'claim', 'wherein', 'preprocessing', 'code', 'based', 'on', 'the', 'feature', 'density', 'selection', 'criteria', 'determines', 'that', 'an', 'ocr', 'algorithm', 'is', 'applicable', 'to', 'the', 'text', 'and', 'that', 'other', 'recognition', 'algorithms', 'are', 'applicable', 'to', 'aspects', 'of', 'the', 'photographs', 'and', 'to', 'logos', 'the', 'system', 'of', 'claim', 'wherein', 'a', 'user', 'creates', 'a', 'user', 'profile', 'for', 'a', 'camera-equipped', 'smartphone', 'that', 'includes', 'the', 'information', 'that', 'the', 'user', 'is', 'visually', 'impaired', 'which', 'causes', 'prioritized', 'execution', 'of', 'the', 'ocr', 'algorithm', 'such', 'that', 'a', 'text', 'reader', 'program', 'begins', 'reading', 'the', 'text', 'to', 'the', 'user', 'as', 'quickly', 'as', 'possible', 'the', 'system', 'of', 'claim', 'further', 'comprising', 'an', 'audio', 'or', 'tactile', 'feedback', 'mechanism', 'that', 'helps', 'the', 'user', 'to', 'position', 'the', 'smart', 'phone', 'relative', 'to', 'the', 'text', 'the', 'system', 'of', 'claim', 'further', 'comprising', 'a', '``', 'hold', 'still', \"''\", 'audio', 'feedback', 'signal', 'that', 'is', 'sent', 'to', 'the', 'user', 'when', 'the', 'text', 'is', 'at', 'the', 'center', 'of', 'the', 'captured', 'scene', 'the', 'system', 'of', 'claim', 'wherein', 'the', 'digital', 'representation', 'comprises', 'at', 'least', 'one', 'of', 'the', 'following', 'types', 'of', 'digital', 'data', 'image', 'data', 'video', 'data', 'and', 'audio', 'data', 'the', 'system', 'of', 'claim', 'wherein', 'invariant', 'feature', 'identification', 'algorithm', 'comprises', 'at', 'least', 'one', 'of', 'the', 'following', 'feature', 'identification', 'algorithms', 'fast', 'sift', 'freak', 'brisk', 'harris', 'daisy', 'and', 'mser', 'the', 'system', 'of', 'claim', 'wherein', 'the', 'invariant', 'feature', 'identification', 'algorithm', 'includes', 'at', 'least', 'one', 'of', 'the', 'following', 'edge', 'detection', 'algorithm', 'corner', 'detection', 'algorithm', 'saliency', 'map', 'algorithm', 'curve', 'detection', 'algorithm', 'a', 'texton', 'identification', 'algorithm', 'and', 'wavelets', 'algorithm', 'the', 'system', 'of', 'claim', 'wherein', 'at', 'least', 'one', 'region', 'of', 'interest', 'represents', 'at', 'least', 'one', 'physical', 'object', 'in', 'the', 'scene', 'the', 'system', 'of', 'claim', 'wherein', 'at', 'least', 'one', 'region', 'of', 'interest', 'represents', 'at', 'least', 'one', 'textual', 'media', 'in', 'the', 'scene', 'the', 'system', 'of', 'claim', 'wherein', 'the', 'region', 'of', 'interest', 'represents', 'a', 'document', 'as', 'the', 'textual', 'media', 'the', 'system', 'of', 'claim', 'wherein', 'the', 'region', 'of', 'interest', 'represents', 'a', 'financial', 'document', 'the', 'system', 'of', 'claim', 'wherein', 'the', 'region', 'of', 'interest', 'represents', 'a', 'structured', 'document', 'the', 'system', 'of', 'claim', 'wherein', 'at', 'least', 'one', 'implementation', 'of', 'a', 'plurality', 'of', 'recognition', 'algorithms', 'includes', 'at', 'least', 'one', 'of', 'the', 'following', 'a', 'template', 'driven', 'algorithm', 'a', 'face', 'recognition', 'algorithm', 'an', 'optical', 'character', 'recognition', 'algorithm', 'a', 'speech', 'recognition', 'algorithm', 'and', 'an', 'object', 'recognition', 'algorithm', 'the', 'system', 'of', 'claim', 'wherein', 'data', 'preprocessing', 'code', 'is', 'further', 'configured', 'to', 'assign', 'each', 'region', 'of', 'interest', 'at', 'least', 'one', 'recognition', 'algorithm', 'as', 'a', 'function', 'of', 'a', 'scene', 'context', 'derived', 'from', 'the', 'digital', 'representation', 'the', 'system', 'of', 'claim', 'wherein', 'the', 'scene', 'context', 'includes', 'at', 'least', 'one', 'of', 'the', 'following', 'types', 'of', 'data', 'a', 'location', 'a', 'position', 'a', 'time', 'a', 'user', 'identity', 'a', 'news', 'event', 'a', 'medical', 'event', 'and', 'a', 'promotion', 'the', 'system', 'of', 'claim', 'further', 'comprising', 'a', 'mobile', 'device', 'comprising', 'at', 'least', 'one', 'implementation', 'of', 'a', 'plurality', 'of', 'recognition', 'algorithms', 'and', 'data', 'preprocessing', 'code', 'the', 'system', 'of', 'claim', 'wherein', 'the', 'mobile', 'device', 'comprises', 'at', 'least', 'one', 'of', 'the', 'following', 'a', 'smart', 'phone', 'a', 'tablet', 'wearable', 'glass', 'a', 'toy', 'a', 'vehicle', 'a', 'computer', 'and', 'a', 'phablet', 'the', 'system', 'of', 'claim', 'further', 'comprising', 'a', 'network-accessible', 'server', 'device', 'comprising', 'at', 'least', 'one', 'implementation', 'of', 'a', 'plurality', 'of', 'recognition', 'algorithms', 'and', 'data', 'preprocessing', 'code', 'the', 'system', 'of', 'claim', 'wherein', 'the', 'object', 'type', 'includes', 'at', 'least', 'one', 'of', 'the', 'following', 'a', 'face', 'an', 'animal', 'a', 'vehicle', 'a', 'document', 'a', 'plant', 'a', 'building', 'an', 'appliance', 'clothing', 'a', 'body', 'part', 'and', 'a', 'toy', 'an', 'object', 'data', 'processing', 'system', 'comprising', 'at', 'least', 'one', 'processor', 'configured', 'to', 'execute', 'at', 'least', 'one', 'implementation', 'of', 'a', 'plurality', 'of', 'recognition', 'algorithms', 'stored', 'on', 'at', 'least', 'one', 'non-transitory', 'computer-readable', 'storage', 'medium', 'each', 'recognition', 'algorithm', 'having', 'feature', 'density', 'selection', 'criteria', 'and', 'data', 'preprocessing', 'code', 'executed', 'by', 'at', 'least', 'one', 'processor', 'the', 'data', 'preprocessing', 'code', 'comprising', 'an', 'invariant', 'feature', 'identification', 'algorithm', 'and', 'configured', 'to', 'obtain', 'a', 'digital', 'representation', 'of', 'a', 'scene', 'the', 'scene', 'comprising', 'one', 'or', 'more', 'textual', 'media', 'generate', 'a', 'set', 'of', 'invariant', 'features', 'by', 'applying', 'the', 'invariant', 'feature', 'identification', 'algorithm', 'to', 'the', 'digital', 'representation', 'cluster', 'the', 'set', 'of', 'invariant', 'features', 'into', 'regions', 'of', 'interest', 'in', 'the', 'digital', 'representation', 'of', 'the', 'scene', 'each', 'region', 'of', 'interest', 'having', 'a', 'region', 'feature', 'density', 'classify', 'by', 'region', 'classifier', 'code', 'at', 'least', 'one', 'of', 'the', 'regions', 'of', 'interest', 'according', 'to', 'object', 'type', 'as', 'a', 'function', 'of', 'attributes', 'derived', 'from', 'the', 'region', 'feature', 'density', 'and', 'the', 'digital', 'representation', 'wherein', 'the', 'at', 'least', 'one', 'of', 'the', 'classified', 'regions', 'of', 'interest', 'corresponds', 'to', 'text', 'and', 'use', 'a', 'classification', 'result', 'corresponding', 'to', 'the', 'at', 'least', 'one', 'of', 'the', 'regions', 'of', 'interest', 'to', 'classify', 'another', 'of', 'the', 'regions', 'of', 'interest', 'according', 'to', 'object', 'type', 'wherein', 'the', 'another', 'of', 'the', 'regions', 'of', 'interest', 'corresponds', 'to', 'a', 'region', 'of', 'interest', 'for', 'images', 'assign', 'each', 'region', 'of', 'interest', 'at', 'least', 'one', 'recognition', 'algorithm', 'from', 'at', 'least', 'one', 'implementation', 'of', 'a', 'plurality', 'of', 'diverse', 'recognition', 'algorithms', 'as', 'a', 'function', 'of', 'the', 'region', 'feature', 'density', 'of', 'each', 'region', 'of', 'interest', 'and', 'the', 'feature', 'density', 'selection', 'criteria', 'of', 'the', 'at', 'least', 'one', 'implementation', 'of', 'a', 'plurality', 'of', 'diverse', 'recognition', 'algorithms', 'and', 'configure', 'the', 'assigned', 'recognition', 'algorithms', 'to', 'process', 'their', 'respective', 'regions', 'of', 'interest', 'wherein', 'preprocessing', 'code', 'based', 'on', 'the', 'feature', 'density', 'selection', 'criteria', 'determines', 'that', 'an', 'ocr', 'algorithm', 'is', 'applicable', 'to', 'the', 'text', 'and', 'that', 'other', 'recognition', 'algorithms', 'are', 'applicable', 'to', 'aspects', 'of', 'the', 'photographs', 'and', 'to', 'logos', 'a', 'device', 'comprising', 'at', 'least', 'one', 'processor', 'configured', 'to', 'execute', 'at', 'least', 'one', 'implementation', 'of', 'a', 'plurality', 'of', 'recognition', 'algorithms', 'stored', 'on', 'at', 'least', 'one', 'non-transitory', 'computer-readable', 'storage', 'medium', 'each', 'recognition', 'algorithm', 'having', 'feature', 'density', 'selection', 'criteria', 'and', 'data', 'preprocessing', 'code', 'executed', 'by', 'at', 'least', 'one', 'processor', 'the', 'data', 'preprocessing', 'code', 'comprising', 'an', 'invariant', 'feature', 'identification', 'algorithm', 'and', 'configured', 'to', 'obtain', 'a', 'digital', 'representation', 'of', 'a', 'scene', 'the', 'scene', 'comprising', 'one', 'or', 'more', 'textual', 'media', 'generate', 'a', 'set', 'of', 'invariant', 'features', 'by', 'applying', 'the', 'invariant', 'feature', 'identification', 'algorithm', 'to', 'the', 'digital', 'representation', 'cluster', 'the', 'set', 'of', 'invariant', 'features', 'into', 'regions', 'of', 'interest', 'in', 'the', 'digital', 'representation', 'of', 'the', 'scene', 'each', 'region', 'of', 'interest', 'having', 'a', 'region', 'feature', 'density', 'and', 'classify', 'by', 'region', 'classifier', 'code', 'at', 'least', 'one', 'of', 'the', 'regions', 'of', 'interest', 'according', 'to', 'object', 'type', 'as', 'a', 'function', 'of', 'attributes', 'derived', 'from', 'the', 'region', 'feature', 'density', 'and', 'the', 'digital', 'representation', 'wherein', 'the', 'at', 'least', 'one', 'of', 'the', 'classified', 'regions', 'of', 'interest', 'corresponds', 'to', 'text', 'and', 'use', 'a', 'classification', 'result', 'corresponding', 'to', 'the', 'at', 'least', 'one', 'of', 'the', 'regions', 'of', 'interest', 'to', 'classify', 'another', 'of', 'the', 'regions', 'of', 'interest', 'according', 'to', 'object', 'type', 'wherein', 'the', 'another', 'of', 'the', 'regions', 'of', 'interest', 'corresponds', 'to', 'a', 'region', 'of', 'interest', 'for', 'images', 'a', 'mobile', 'terminal', 'comprising', 'a', 'front', 'camera', 'configured', 'to', 'obtain', 'a', 'two-dimensional', 'd', 'face', 'image', 'of', 'a', 'user', 'a', 'glance', 'sensor', 'tilted', 'by', 'a', 'certain', 'angle', 'and', 'disposed', 'adjacent', 'to', 'the', 'front', 'camera', 'to', 'obtain', 'metadata', 'of', 'the', 'd', 'face', 'image', 'and', 'a', 'controller', 'obtaining', 'a', 'distance', 'between', 'the', 'glance', 'sensor', 'and', 'the', 'front', 'camera', 'the', 'distance', 'enabling', 'an', 'area', 'of', 'an', 'overlap', 'region', 'where', 'a', 'first', 'region', 'representing', 'a', 'range', 'photographable', 'by', 'the', 'front', 'camera', 'overlaps', 'a', 'second', 'region', 'representing', 'a', 'range', 'photographable', 'by', 'the', 'glance', 'sensor', 'to', 'be', 'the', 'maximum', 'the', 'mobile', 'terminal', 'of', 'claim', 'wherein', 'the', 'controller', 'is', 'configured', 'to', 'obtain', 'the', 'distance', 'enabling', 'the', 'area', 'of', 'the', 'overlap', 'region', 'to', 'be', 'the', 'maximum', 'between', 'the', 'glance', 'sensor', 'and', 'the', 'front', 'camera', 'by', 'varying', 'a', 'tilting', 'angle', 'of', 'the', 'glance', 'sensor', 'the', 'mobile', 'terminal', 'of', 'claim', 'wherein', 'the', 'controller', 'is', 'configured', 'to', 'set', 'the', 'distance', 'enabling', 'the', 'area', 'of', 'the', 'overlap', 'region', 'to', 'be', 'the', 'maximum', 'between', 'the', 'glance', 'sensor', 'and', 'the', 'front', 'camera', 'and', 'the', 'tilting', 'angle', 'of', 'the', 'glance', 'sensor', 'as', 'an', 'optimal', 'disposition', 'location', 'of', 'the', 'glance', 'sensor', 'the', 'mobile', 'terminal', 'of', 'claim', 'wherein', 'the', 'controller', 'is', 'configured', 'to', 'set', 'a', 'disposition', 'location', 'of', 'the', 'front', 'camera', 'as', 'an', 'original', 'point', 'and', 'calculates', 'coordinates', 'of', 'a', 'first', 'triangle', 'representing', 'the', 'first', 'region', 'based', 'on', 'a', 'field', 'of', 'view', 'of', 'the', 'front', 'camera', 'and', 'a', 'maximum', 'photographing', 'distance', 'of', 'the', 'front', 'camera', 'the', 'mobile', 'terminal', 'of', 'claim', 'wherein', 'the', 'controller', 'is', 'configured', 'to', 'calculate', 'coordinates', 'of', 'a', 'second', 'triangle', 'representing', 'the', 'second', 'region', 'based', 'on', 'a', 'field', 'of', 'view', 'of', 'the', 'glance', 'sensor', 'a', 'maximum', 'photographing', 'distance', 'of', 'the', 'glance', 'sensor', 'a', 'distance', 'between', 'the', 'front', 'camera', 'and', 'the', 'glance', 'sensor', 'and', 'a', 'tilting', 'angle', 'of', 'the', 'glance', 'sensor', 'the', 'mobile', 'terminal', 'of', 'claim', 'wherein', 'before', 'the', 'glance', 'sensor', 'is', 'tilted', 'the', 'controller', 'is', 'configured', 'to', 'calculate', 'coordinates', 'of', 'a', 'third', 'triangle', 'representing', 'a', 'third', 'region', 'photographable', 'by', 'the', 'glance', 'sensor', 'and', 'the', 'controller', 'is', 'configured', 'to', 'rotation-convert', 'the', 'coordinates', 'of', 'the', 'third', 'triangle', 'based', 'on', 'the', 'tilting', 'angle', 'of', 'the', 'glance', 'sensor', 'and', 'calculate', 'the', 'coordinates', 'of', 'the', 'second', 'triangle', 'the', 'mobile', 'terminal', 'of', 'claim', 'wherein', 'the', 'controller', 'is', 'configured', 'to', 'calculate', 'coordinates', 'of', 'the', 'overlap', 'region', 'based', 'on', 'the', 'coordinates', 'of', 'the', 'first', 'triangle', 'and', 'the', 'coordinates', 'of', 'the', 'second', 'triangle', 'and', 'calculates', 'the', 'area', 'of', 'the', 'overlap', 'region', 'based', 'on', 'the', 'coordinates', 'of', 'the', 'overlap', 'region', 'the', 'mobile', 'terminal', 'of', 'claim', 'wherein', 'the', 'controller', 'is', 'configured', 'to', 'generate', 'three-dimensional', 'd', 'face', 'information', 'based', 'on', 'the', 'd', 'face', 'image', 'obtained', 'by', 'the', 'front', 'camera', 'and', 'metadata', 'obtained', 'by', 'the', 'glance', 'sensor', 'the', 'mobile', 'terminal', 'of', 'claim', 'wherein', 'the', 'metadata', 'comprises', 'one', 'or', 'more', 'of', 'an', 'angle', 'of', 'a', 'face', 'of', 'the', 'user', 'a', 'size', 'of', 'the', 'face', 'and', 'a', 'location', 'of', 'the', 'face', 'the', 'mobile', 'terminal', 'of', 'claim', 'wherein', 'the', 'angle', 'of', 'the', 'face', 'comprises', 'an', 'angle', 'by', 'which', 'the', 'face', 'is', 'rotated', 'about', 'one', 'or', 'more', 'of', 'a', 'pitch', 'axis', 'a', 'roll', 'axis', 'and', 'a', 'yaw', 'axis', 'the', 'mobile', 'terminal', 'of', 'claim', 'further', 'comprising', 'a', 'memory', 'storing', 'the', 'generated', 'd', 'face', 'information', 'wherein', 'the', 'controller', 'is', 'configured', 'to', 'performs', 'a', 'user', 'authentication', 'process', 'by', 'comparing', 'the', 'stored', 'd', 'face', 'information', 'with', 'd', 'face', 'information', 'obtained', 'for', 'user', 'authentication', 'the', 'mobile', 'terminal', 'of', 'claim', 'wherein', 'the', 'glance', 'sensor', 'is', 'controlled', 'to', 'be', 'permanently', 'activated', 'with', 'a', 'low', 'power', 'to', 'obtain', 'a', 'front', 'image', 'and', 'metadata', 'of', 'the', 'front', 'image', 'the', 'mobile', 'terminal', 'of', 'claim', 'wherein', 'the', 'front', 'camera', 'and', 'the', 'glance', 'sensor', 'are', 'disposed', 'on', 'the', 'same', 'line', 'in', 'an', 'upper', 'end', 'of', 'the', 'mobile', 'terminal', 'the', 'mobile', 'terminal', 'of', 'claim', 'wherein', 'the', 'glance', 'sensor', 'is', 'tilted', 'in', 'one', 'direction', 'of', 'an', 'up', 'direction', 'a', 'down', 'direction', 'a', 'left', 'direction', 'and', 'a', 'right', 'direction', 'the', 'mobile', 'terminal', 'of', 'claim', 'wherein', 'the', 'metadata', 'is', 'data', 'which', 'is', 'changed', 'when', 'the', 'mobile', 'terminal', 'is', 'tilted', 'by', 'an', 'external', 'physical', 'force', 'a', 'method', 'comprising', 'receiving', 'by', 'a', 'smart', 'television', 'tv', 'an', 'indication', 'of', 'upcoming', 'media', 'programming', 'wherein', 'the', 'upcoming', 'media', 'programming', 'is', 'based', 'on', 'a', 'user', 'profile', 'identifying', 'one', 'or', 'more', 'devices', 'in', 'communication', 'with', 'the', 'smart', 'tv', 'each', 'of', 'the', 'one', 'or', 'more', 'devices', 'including', 'at', 'least', 'one', 'of', 'a', 'microphone', 'or', 'a', 'camera', 'instructing', 'at', 'least', 'one', 'identified', 'device', 'to', 'detect', 'audio', 'signals', 'using', 'its', 'respective', 'microphone', 'or', 'to', 'detect', 'visual', 'signals', 'using', 'its', 'respective', 'camera', 'selecting', 'at', 'least', 'one', 'device', 'of', 'the', 'one', 'or', 'more', 'devices', 'based', 'on', 'the', 'detected', 'audio', 'signal', 'or', 'detected', 'visual', 'signal', 'and', 'providing', 'instructions', 'to', 'the', 'selected', 'device', 'to', 'output', 'a', 'notification', 'related', 'to', 'the', 'upcoming', 'media', 'programming', 'the', 'method', 'of', 'claim', 'wherein', 'the', 'upcoming', 'media', 'programming', 'is', 'one', 'of', 'a', 'live', 'television', 'program', 'a', 'recorded', 'television', 'program', 'a', 'broadcast', 'television', 'program', 'or', 'an', 'application-provided', 'program', 'the', 'method', 'of', 'claim', 'wherein', 'selecting', 'the', 'first', 'device', 'based', 'on', 'the', 'detected', 'audio', 'signal', 'includes', 'recognizing', 'a', 'voice', 'the', 'method', 'of', 'claim', 'further', 'comprising', 'determining', 'a', 'distance', 'to', 'the', 'recognized', 'voice', 'and', 'wherein', 'selecting', 'the', 'first', 'device', 'is', 'further', 'based', 'on', 'the', 'determined', 'distance', 'the', 'method', 'of', 'claim', 'wherein', 'selecting', 'the', 'first', 'device', 'based', 'on', 'the', 'detected', 'visual', 'signals', 'includes', 'recognizing', 'a', 'face', 'the', 'method', 'of', 'claim', 'wherein', 'recognizing', 'the', 'face', 'includes', 'a', 'face', 'recognition', 'technique', 'the', 'method', 'of', 'claim', 'further', 'comprising', 'presenting', 'on', 'the', 'smart', 'tv', 'the', 'upcoming', 'media', 'programming', 'in', 'a', 'favorite', 'channel', 'list', 'the', 'method', 'of', 'claim', 'further', 'comprising', 'obtaining', 'media', 'programming', 'viewing', 'data', 'wherein', 'the', 'media', 'programming', 'viewing', 'data', 'includes', 'at', 'least', 'one', 'of', 'a', 'historical', 'time', 'and', 'a', 'historical', 'date', 'that', 'one', 'or', 'more', 'media', 'programs', 'were', 'viewed', 'obtaining', 'at', 'least', 'one', 'of', 'a', 'current', 'time', 'and', 'a', 'current', 'date', 'processing', 'the', 'media', 'programming', 'viewing', 'data', 'to', 'determine', 'a', 'probability', 'of', 'the', 'one', 'or', 'more', 'media', 'programs', 'being', 'viewed', 'based', 'on', 'at', 'least', 'one', 'of', 'the', 'current', 'time', 'and', 'the', 'current', 'date', 'and', 'presenting', 'the', 'favorite', 'channel', 'list', 'based', 'on', 'the', 'determined', 'probability', 'of', 'the', 'one', 'or', 'more', 'media', 'programs', 'being', 'viewed', 'the', 'method', 'of', 'claim', 'wherein', 'processing', 'the', 'media', 'programming', 'viewing', 'data', 'includes', 'employing', 'a', 'neural', 'network', 'model', 'the', 'method', 'of', 'claim', 'wherein', 'employing', 'the', 'neural', 'network', 'model', 'comprises', 'determining', 'a', 'duration', 'that', 'the', 'one', 'or', 'more', 'media', 'programs', 'were', 'viewed', 'for', 'each', 'of', 'the', 'at', 'least', 'one', 'of', 'the', 'historical', 'time', 'and', 'the', 'historical', 'date', 'setting', 'a', 'threshold', 'time', 'duration', 'comparing', 'the', 'determined', 'duration', 'to', 'the', 'threshold', 'time', 'duration', 'and', 'filtering', 'out', 'the', 'one', 'or', 'more', 'media', 'programs', 'viewed', 'below', 'the', 'threshold', 'time', 'duration', 'a', 'smart', 'television', 'tv', 'comprising', 'a', 'network', 'interface', 'a', 'non-transitory', 'computer-readable', 'medium', 'and', 'a', 'processor', 'in', 'communication', 'with', 'the', 'network', 'interface', 'and', 'the', 'non-transitory', 'computer-readable', 'medium', 'and', 'capable', 'of', 'executing', 'processor-executable', 'program', 'code', 'stored', 'in', 'the', 'non-transitory', 'computer-readable', 'medium', 'to', 'cause', 'the', 'smart', 'tv', 'to', 'receive', 'an', 'indication', 'of', 'upcoming', 'media', 'programming', 'wherein', 'the', 'upcoming', 'media', 'programming', 'is', 'based', 'on', 'a', 'user', 'profile', 'identify', 'one', 'or', 'more', 'devices', 'in', 'communication', 'with', 'the', 'smart', 'tv', 'each', 'of', 'the', 'one', 'or', 'more', 'devices', 'including', 'at', 'least', 'one', 'of', 'a', 'microphone', 'or', 'a', 'camera', 'instruct', 'at', 'least', 'one', 'identified', 'device', 'to', 'detect', 'audio', 'signals', 'using', 'its', 'respective', 'microphone', 'or', 'to', 'detect', 'visual', 'signals', 'using', 'its', 'respective', 'camera', 'select', 'at', 'least', 'one', 'device', 'of', 'the', 'one', 'or', 'more', 'devices', 'based', 'on', 'the', 'detected', 'audio', 'signal', 'or', 'detected', 'visual', 'signal', 'and', 'provide', 'instructions', 'to', 'the', 'selected', 'device', 'to', 'output', 'a', 'notification', 'related', 'to', 'the', 'upcoming', 'media', 'programming', 'the', 'smart', 'tv', 'of', 'claim', 'wherein', 'selecting', 'the', 'first', 'device', 'based', 'on', 'the', 'detected', 'audio', 'signal', 'includes', 'recognizing', 'a', 'voice', 'the', 'smart', 'tv', 'of', 'claim', 'wherein', 'the', 'processor', 'is', 'further', 'capable', 'of', 'executing', 'processor-executable', 'program', 'code', 'to', 'determine', 'a', 'distance', 'to', 'the', 'recognized', 'voice', 'and', 'wherein', 'selecting', 'the', 'first', 'device', 'is', 'further', 'based', 'on', 'the', 'determined', 'distance', 'the', 'smart', 'tv', 'of', 'claim', 'wherein', 'selecting', 'the', 'first', 'device', 'based', 'on', 'the', 'detected', 'visual', 'signals', 'includes', 'detecting', 'the', 'presence', 'of', 'a', 'user', 'the', 'smart', 'tv', 'of', 'claim', 'wherein', 'detecting', 'the', 'presence', 'of', 'the', 'user', 'includes', 'employing', 'one', 'or', 'more', 'of', 'a', 'camera', 'a', 'microphone', 'or', 'a', 'fingerprint', 'sensor', 'associated', 'with', 'at', 'least', 'one', 'of', 'the', 'smart', 'tv', 'a', 'mobile', 'device', 'a', 'smartphone', 'a', 'laptop', 'computer', 'a', 'tablet', 'device', 'a', 'wearable', 'device', 'an', 'internet', 'of', 'things', 'iot', 'device', 'an', 'internet', 'of', 'everything', 'ioe', 'device', 'an', 'iot', 'hub', 'or', 'an', 'ioe', 'hub', 'a', 'smart', 'television', 'tv', 'comprising', 'means', 'for', 'receiving', 'an', 'indication', 'of', 'upcoming', 'media', 'programming', 'wherein', 'the', 'upcoming', 'media', 'programming', 'is', 'based', 'on', 'a', 'user', 'profile', 'means', 'for', 'identifying', 'one', 'or', 'more', 'devices', 'in', 'communication', 'with', 'the', 'smart', 'tv', 'each', 'of', 'the', 'one', 'or', 'more', 'devices', 'including', 'at', 'least', 'one', 'of', 'a', 'microphone', 'or', 'a', 'camera', 'means', 'for', 'instructing', 'at', 'least', 'one', 'identified', 'device', 'to', 'detect', 'audio', 'signals', 'using', 'its', 'respective', 'microphone', 'or', 'to', 'detect', 'visual', 'signals', 'using', 'its', 'respective', 'camera', 'means', 'for', 'selecting', 'at', 'least', 'one', 'device', 'of', 'the', 'one', 'or', 'more', 'devices', 'based', 'on', 'the', 'detected', 'audio', 'signal', 'or', 'detected', 'visual', 'signal', 'and', 'means', 'for', 'providing', 'instructions', 'to', 'the', 'selected', 'device', 'to', 'output', 'a', 'notification', 'related', 'to', 'the', 'upcoming', 'media', 'programming', 'the', 'smart', 'tv', 'of', 'claim', 'wherein', 'the', 'one', 'or', 'more', 'devices', 'includes', 'at', 'least', 'one', 'of', 'a', 'mobile', 'device', 'a', 'smartphone', 'a', 'laptop', 'computer', 'a', 'tablet', 'device', 'a', 'wearable', 'device', 'an', 'internet', 'of', 'things', 'iot', 'device', 'an', 'internet', 'of', 'everything', 'ioe', 'device', 'an', 'iot', 'hub', 'an', 'ioe', 'hub', 'or', 'another', 'smart', 'tv', 'the', 'smart', 'tv', 'of', 'claim', 'wherein', 'the', 'upcoming', 'media', 'programming', 'is', 'one', 'of', 'a', 'live', 'television', 'program', 'a', 'recorded', 'television', 'program', 'a', 'broadcast', 'television', 'program', 'or', 'an', 'application-provided', 'program', 'the', 'smart', 'tv', 'of', 'claim', 'wherein', 'the', 'notification', 'includes', 'at', 'least', 'one', 'of', 'a', 'push', 'message', 'a', 'sms', 'message', 'a', 'waysms', 'message', 'an', 'audio', 'alert', 'an', 'audio', 'message', 'or', 'an', 'email', 'message', 'the', 'smart', 'tv', 'of', 'claim', 'further', 'comprising', 'presenting', 'the', 'upcoming', 'media', 'programming', 'in', 'a', 'favorite', 'channel', 'list', 'the', 'smart', 'tv', 'of', 'claim', 'further', 'comprising', 'means', 'for', 'obtaining', 'media', 'programming', 'viewing', 'data', 'wherein', 'the', 'media', 'programming', 'viewing', 'data', 'includes', 'at', 'least', 'one', 'of', 'a', 'historical', 'time', 'and', 'a', 'historical', 'date', 'that', 'one', 'or', 'more', 'media', 'programs', 'were', 'viewed', 'on', 'the', 'smart', 'tv', 'means', 'for', 'obtaining', 'at', 'least', 'one', 'of', 'a', 'current', 'time', 'and', 'a', 'current', 'date', 'means', 'for', 'processing', 'the', 'media', 'programming', 'viewing', 'data', 'to', 'determine', 'a', 'probability', 'of', 'the', 'one', 'or', 'more', 'media', 'programs', 'being', 'viewed', 'on', 'the', 'smart', 'tv', 'based', 'on', 'at', 'least', 'one', 'of', 'the', 'current', 'time', 'and', 'the', 'current', 'date', 'and', 'means', 'for', 'presenting', 'the', 'favorite', 'channel', 'list', 'based', 'on', 'the', 'determined', 'probability', 'of', 'the', 'one', 'or', 'more', 'media', 'programs', 'being', 'viewed', 'the', 'smart', 'tv', 'of', 'claim', 'wherein', 'the', 'means', 'for', 'processing', 'the', 'media', 'programming', 'viewing', 'data', 'includes', 'employing', 'a', 'neural', 'network', 'model', 'the', 'smart', 'tv', 'of', 'claim', 'wherein', 'employing', 'the', 'neural', 'network', 'model', 'comprises', 'determining', 'a', 'duration', 'that', 'the', 'one', 'or', 'more', 'media', 'programs', 'were', 'viewed', 'on', 'the', 'smart', 'tv', 'for', 'each', 'of', 'the', 'at', 'least', 'one', 'of', 'the', 'historical', 'time', 'and', 'the', 'historical', 'date', 'setting', 'a', 'threshold', 'time', 'duration', 'comparing', 'the', 'determined', 'duration', 'to', 'the', 'threshold', 'time', 'duration', 'and', 'filtering', 'out', 'the', 'one', 'or', 'more', 'media', 'programs', 'viewed', 'below', 'the', 'threshold', 'time', 'duration', 'the', 'smart', 'tv', 'of', 'claim', 'further', 'comprising', 'means', 'for', 'adjusting', 'at', 'least', 'one', 'of', 'a', 'volume', 'or', 'a', 'brightness', 'of', 'the', 'smart', 'tv', 'wherein', 'the', 'adjusting', 'is', 'based', 'on', 'at', 'least', 'one', 'of', 'the', 'historical', 'time', 'and', 'the', 'historical', 'date', 'the', 'smart', 'tv', 'of', 'claim', 'further', 'comprising', 'means', 'for', 'restricting', 'access', 'to', 'one', 'or', 'more', 'media', 'programs', 'a', 'non-transitory', 'computer-readable', 'medium', 'comprising', 'processor-executable', 'program', 'code', 'configured', 'to', 'cause', 'a', 'processor', 'of', 'a', 'smart', 'television', 'tv', 'to', 'receive', 'an', 'indication', 'of', 'upcoming', 'media', 'programming', 'wherein', 'the', 'upcoming', 'media', 'programming', 'is', 'based', 'on', 'a', 'user', 'profile', 'identify', 'one', 'or', 'more', 'devices', 'in', 'communication', 'with', 'the', 'smart', 'tv', 'each', 'of', 'the', 'one', 'or', 'more', 'devices', 'including', 'at', 'least', 'one', 'of', 'a', 'microphone', 'or', 'a', 'camera', 'instruct', 'at', 'least', 'one', 'identified', 'device', 'to', 'detect', 'audio', 'signals', 'using', 'its', 'respective', 'microphone', 'or', 'to', 'detect', 'visual', 'signals', 'using', 'its', 'respective', 'camera', 'select', 'at', 'least', 'one', 'device', 'of', 'the', 'one', 'or', 'more', 'devices', 'based', 'on', 'the', 'detected', 'audio', 'signal', 'or', 'detected', 'visual', 'signal', 'and', 'provide', 'instructions', 'to', 'the', 'selected', 'device', 'to', 'output', 'a', 'notification', 'related', 'to', 'the', 'upcoming', 'media', 'programming', 'the', 'non-transitory', 'computer-readable', 'medium', 'of', 'claim', 'wherein', 'selecting', 'the', 'first', 'device', 'based', 'on', 'the', 'detected', 'audio', 'signal', 'includes', 'recognizing', 'a', 'voice', 'the', 'non-transitory', 'computer-readable', 'medium', 'of', 'claim', 'wherein', 'the', 'processor', 'is', 'further', 'capable', 'of', 'executing', 'processor-executable', 'program', 'code', 'to', 'determine', 'a', 'distance', 'to', 'the', 'recognized', 'voice', 'and', 'wherein', 'selecting', 'the', 'first', 'device', 'is', 'further', 'based', 'on', 'the', 'determined', 'distance', 'the', 'non-transitory', 'computer-readable', 'medium', 'of', 'claim', 'wherein', 'selecting', 'the', 'first', 'device', 'based', 'on', 'the', 'detected', 'visual', 'signals', 'includes', 'recognizing', 'a', 'face', 'the', 'non-transitory', 'computer-readable', 'medium', 'of', 'claim', 'wherein', 'recognizing', 'the', 'face', 'includes', 'a', 'face', 'recognition', 'technique', 'a', 'camera', 'comprising', 'a', 'sensor', 'array', 'including', 'a', 'plurality', 'of', 'sensors', 'an', 'infrared', 'ir', 'illuminator', 'configured', 'to', 'emit', 'active', 'ir', 'light', 'in', 'an', 'ir', 'light', 'sub-band', 'a', 'plurality', 'of', 'spectral', 'illuminators', 'each', 'spectral', 'illuminator', 'configured', 'to', 'emit', 'active', 'spectral', 'light', 'in', 'a', 'different', 'spectral', 'light', 'sub-band', 'a', 'depth', 'controller', 'machine', 'configured', 'to', 'determine', 'a', 'depth', 'value', 'for', 'each', 'of', 'the', 'plurality', 'of', 'sensors', 'based', 'on', 'the', 'active', 'ir', 'light', 'a', 'spectral', 'controller', 'machine', 'configured', 'to', 'for', 'each', 'of', 'the', 'plurality', 'of', 'sensors', 'determine', 'a', 'spectral', 'value', 'for', 'each', 'spectral', 'light', 'sub-band', 'of', 'the', 'plurality', 'of', 'spectral', 'illuminators', 'and', 'an', 'output', 'machine', 'configured', 'to', 'output', 'a', 'test', 'depth+multi-spectral', 'image', 'including', 'a', 'plurality', 'of', 'pixels', 'each', 'pixel', 'corresponding', 'to', 'one', 'of', 'the', 'plurality', 'of', 'sensors', 'of', 'the', 'sensor', 'array', 'and', 'including', 'at', 'least', 'a', 'depth', 'value', 'and', 'a', 'spectral', 'value', 'for', 'each', 'spectral', 'light', 'sub-band', 'of', 'the', 'plurality', 'of', 'spectral', 'illuminators', 'a', 'face', 'recognition', 'machine', 'previously', 'trained', 'with', 'a', 'set', 'of', 'labeled', 'training', 'depth+multi-spectral', 'images', 'having', 'a', 'same', 'structure', 'as', 'the', 'test', 'depth+multi-spectral', 'image', 'the', 'face', 'recognition', 'machine', 'configured', 'to', 'output', 'a', 'confidence', 'value', 'indicating', 'a', 'likelihood', 'that', 'the', 'test', 'depth+multi-spectral', 'image', 'includes', 'a', 'face', 'the', 'camera', 'of', 'claim', 'wherein', 'each', 'spectral', 'value', 'is', 'calculated', 'based', 'on', 'the', 'depth', 'value', 'determined', 'for', 'the', 'sensor', 'that', 'corresponds', 'to', 'the', 'pixel', 'the', 'camera', 'of', 'claim', 'wherein', 'the', 'face', 'recognition', 'machine', 'is', 'configured', 'to', 'use', 'a', 'convolutional', 'neural', 'network', 'to', 'determine', 'the', 'confidence', 'value', 'the', 'camera', 'of', 'claim', 'wherein', 'the', 'face', 'recognition', 'machine', 'includes', 'a', 'plurality', 'of', 'input', 'nodes', 'wherein', 'each', 'input', 'node', 'is', 'configured', 'to', 'receive', 'a', 'pixel', 'value', 'array', 'corresponding', 'to', 'a', 'different', 'pixel', 'of', 'the', 'plurality', 'of', 'pixels', 'of', 'the', 'test', 'depth+multi-spectral', 'image', 'and', 'wherein', 'the', 'pixel', 'value', 'array', 'includes', 'the', 'depth', 'value', 'and', 'the', 'plurality', 'of', 'multi-spectral', 'values', 'for', 'the', 'pixel', 'the', 'camera', 'of', 'claim', 'wherein', 'the', 'plurality', 'of', 'multi-spectral', 'values', 'for', 'the', 'pixel', 'include', 'more', 'than', 'three', 'spectral', 'values', 'the', 'camera', 'of', 'claim', 'wherein', 'the', 'output', 'machine', 'is', 'configured', 'to', 'output', 'a', 'surface', 'normal', 'for', 'each', 'pixel', 'of', 'the', 'test', 'depth+multi-spectral', 'image', 'and', 'wherein', 'the', 'pixel', 'value', 'array', 'includes', 'the', 'surface', 'normal', 'the', 'camera', 'of', 'claim', 'wherein', 'the', 'output', 'machine', 'is', 'configured', 'to', 'output', 'a', 'curvature', 'for', 'each', 'pixel', 'of', 'the', 'test', 'depth+multi-spectral', 'image', 'and', 'wherein', 'the', 'pixel', 'value', 'array', 'includes', 'the', 'curvature', 'the', 'camera', 'of', 'claim', 'wherein', 'the', 'face', 'recognition', 'machine', 'is', 'configured', 'to', 'use', 'a', 'plurality', 'of', 'models', 'to', 'determine', 'the', 'confidence', 'value', 'wherein', 'the', 'plurality', 'of', 'models', 'includes', 'a', 'plurality', 'of', 'channel-specific', 'models', 'wherein', 'each', 'channel-specific', 'model', 'is', 'configured', 'to', 'process', 'a', 'different', 'pixel', 'parameter', 'for', 'the', 'plurality', 'of', 'pixels', 'of', 'the', 'test', 'depth+multi-spectral', 'image', 'wherein', 'each', 'channel-specific', 'model', 'includes', 'a', 'plurality', 'of', 'input', 'nodes', 'and', 'wherein', 'for', 'each', 'channel-specific', 'model', 'each', 'input', 'node', 'is', 'configured', 'to', 'receive', 'a', 'pixel', 'parameter', 'value', 'for', 'a', 'different', 'pixel', 'of', 'the', 'plurality', 'of', 'pixels', 'of', 'the', 'test', 'depth+multi-spectral', 'image', 'the', 'camera', 'of', 'claim', 'wherein', 'the', 'face', 'recognition', 'machine', 'is', 'configured', 'to', 'use', 'a', 'statistical', 'model', 'to', 'determine', 'the', 'confidence', 'value', 'the', 'camera', 'of', 'claim', 'wherein', 'the', 'statistical', 'model', 'includes', 'a', 'nearest', 'neighbor', 'algorithm', 'the', 'camera', 'of', 'claim', 'wherein', 'the', 'statistical', 'model', 'includes', 'a', 'support', 'vector', 'machine', 'the', 'camera', 'of', 'claim', 'wherein', 'the', 'face', 'recognition', 'machine', 'is', 'further', 'configured', 'to', 'output', 'a', 'location', 'on', 'the', 'test', 'depth+multi-spectral', 'image', 'of', 'a', 'bounding', 'box', 'around', 'a', 'recognized', 'face', 'the', 'camera', 'of', 'claim', 'wherein', 'the', 'face', 'recognition', 'machine', 'is', 'further', 'configured', 'to', 'output', 'a', 'location', 'on', 'the', 'test', 'depth+multi-spectral', 'image', 'of', 'an', 'identified', 'two-dimensional', 'd', 'facial', 'feature', 'of', 'a', 'recognized', 'face', 'the', 'camera', 'of', 'claim', 'wherein', 'the', 'face', 'recognition', 'machine', 'is', 'further', 'configured', 'to', 'output', 'a', 'location', 'on', 'the', 'test', 'depth+multi-spectral', 'image', 'of', 'an', 'identified', 'three-dimensional', 'd', 'facial', 'feature', 'of', 'a', 'recognized', 'face', 'the', 'camera', 'of', 'claim', 'wherein', 'the', 'face', 'recognition', 'machine', 'is', 'further', 'configured', 'to', 'output', 'a', 'location', 'on', 'the', 'test', 'depth+multi-spectral', 'image', 'of', 'an', 'identified', 'spectral', 'feature', 'on', 'a', 'recognized', 'face', 'the', 'camera', 'of', 'claim', 'wherein', 'the', 'face', 'recognition', 'machine', 'is', 'further', 'configured', 'to', 'output', 'for', 'each', 'pixel', 'of', 'the', 'test', 'depth+multi-spectral', 'image', 'a', 'confidence', 'value', 'indicating', 'a', 'likelihood', 'that', 'the', 'pixel', 'is', 'included', 'in', 'a', 'face', 'the', 'camera', 'of', 'claim', 'wherein', 'the', 'face', 'recognition', 'machine', 'is', 'further', 'configured', 'to', 'output', 'an', 'identity', 'of', 'a', 'face', 'recognized', 'in', 'the', 'test', 'depth+multi-spectral', 'image', 'the', 'camera', 'of', 'claim', 'wherein', 'the', 'plurality', 'of', 'sensors', 'of', 'the', 'sensor', 'array', 'are', 'differential', 'sensors', 'and', 'wherein', 'each', 'spectral', 'value', 'is', 'determined', 'based', 'on', 'a', 'depth', 'value', 'and', 'a', 'differential', 'measurement', 'for', 'that', 'differential', 'sensor', 'a', 'camera', 'comprising', 'a', 'sensor', 'array', 'including', 'a', 'plurality', 'of', 'sensors', 'an', 'infrared', 'ir', 'illuminator', 'configured', 'to', 'emit', 'active', 'ir', 'light', 'in', 'an', 'ir', 'light', 'sub-band', 'a', 'plurality', 'of', 'spectral', 'illuminators', 'each', 'spectral', 'illuminator', 'configured', 'to', 'emit', 'active', 'spectral', 'light', 'in', 'a', 'different', 'spectral', 'light', 'sub-band', 'a', 'depth', 'controller', 'machine', 'configured', 'to', 'determine', 'a', 'depth', 'value', 'for', 'each', 'of', 'the', 'plurality', 'of', 'sensors', 'based', 'on', 'the', 'active', 'ir', 'light', 'a', 'spectral', 'controller', 'machine', 'configured', 'to', 'for', 'each', 'of', 'the', 'plurality', 'of', 'sensors', 'determine', 'a', 'spectral', 'value', 'for', 'each', 'spectral', 'light', 'sub-band', 'of', 'the', 'plurality', 'of', 'spectral', 'illuminators', 'wherein', 'each', 'spectral', 'value', 'is', 'calculated', 'based', 'on', 'the', 'depth', 'value', 'determined', 'for', 'the', 'sensor', 'that', 'corresponds', 'to', 'the', 'pixel', 'and', 'an', 'output', 'machine', 'configured', 'to', 'output', 'a', 'test', 'depth+multi-spectral', 'image', 'including', 'a', 'plurality', 'of', 'pixels', 'each', 'pixel', 'corresponding', 'to', 'one', 'of', 'the', 'plurality', 'of', 'sensors', 'of', 'the', 'sensor', 'array', 'and', 'including', 'at', 'least', 'a', 'depth', 'value', 'and', 'a', 'spectral', 'value', 'for', 'each', 'spectral', 'light', 'sub-band', 'of', 'the', 'plurality', 'of', 'spectral', 'illuminators', 'and', 'a', 'face', 'recognition', 'machine', 'including', 'a', 'convolutional', 'neural', 'network', 'previously', 'trained', 'with', 'a', 'set', 'of', 'labeled', 'training', 'depth+multi-spectral', 'images', 'having', 'a', 'same', 'structure', 'as', 'the', 'test', 'depth+multi-spectral', 'image', 'the', 'face', 'recognition', 'machine', 'configured', 'to', 'output', 'a', 'confidence', 'value', 'indicating', 'a', 'likelihood', 'that', 'the', 'test', 'depth+multi-spectral', 'image', 'includes', 'a', 'face', 'an', 'image', 'processing', 'method', 'comprising', 'acquiring', 'a', 'photo', 'album', 'obtained', 'from', 'face', 'clustering', 'collecting', 'face', 'information', 'of', 'respective', 'images', 'in', 'the', 'photo', 'album', 'and', 'acquiring', 'a', 'face', 'parameter', 'of', 'each', 'image', 'according', 'to', 'the', 'face', 'information', 'selecting', 'a', 'cover', 'image', 'according', 'to', 'the', 'face', 'parameter', 'of', 'each', 'image', 'and', 'taking', 'a', 'face-region', 'image', 'from', 'the', 'cover', 'image', 'and', 'setting', 'the', 'face-region', 'image', 'as', 'a', 'cover', 'of', 'the', 'photo', 'album', 'wherein', 'selecting', 'the', 'cover', 'image', 'according', 'to', 'the', 'face', 'parameter', 'of', 'each', 'image', 'comprises', 'performing', 'calculation', 'on', 'the', 'face', 'parameter', 'of', 'each', 'image', 'in', 'a', 'preset', 'way', 'to', 'obtain', 'a', 'cover', 'score', 'of', 'each', 'image', 'selecting', 'the', 'image', 'with', 'a', 'highest', 'cover', 'score', 'as', 'the', 'cover', 'image', 'wherein', 'selecting', 'the', 'image', 'with', 'the', 'highest', 'cover', 'score', 'as', 'the', 'cover', 'image', 'comprises', 'acquiring', 'a', 'source', 'of', 'each', 'image', 'and', 'selecting', 'the', 'image', 'with', 'the', 'highest', 'cover', 'score', 'in', 'images', 'coming', 'from', 'a', 'preset', 'source', 'as', 'the', 'cover', 'image', 'the', 'method', 'according', 'to', 'claim', 'wherein', 'selecting', 'the', 'image', 'with', 'the', 'highest', 'cover', 'score', 'as', 'the', 'cover', 'image', 'comprises', 'acquiring', 'the', 'number', 'of', 'faces', 'contained', 'in', 'each', 'image', 'determining', 'single-person', 'images', 'according', 'to', 'the', 'number', 'of', 'faces', 'and', 'selecting', 'the', 'single-person', 'image', 'with', 'the', 'highest', 'cover', 'score', 'as', 'the', 'cover', 'image', 'the', 'method', 'according', 'to', 'claim', 'wherein', 'selecting', 'the', 'image', 'with', 'the', 'highest', 'cover', 'score', 'as', 'the', 'cover', 'image', 'further', 'comprises', 'when', 'there', 'is', 'no', 'single-person', 'image', 'in', 'the', 'photo', 'album', 'determining', 'images', 'including', 'two', 'faces', 'from', 'the', 'photo', 'album', 'and', 'selecting', 'the', 'image', 'with', 'the', 'highest', 'cover', 'score', 'from', 'the', 'images', 'including', 'two', 'faces', 'as', 'the', 'cover', 'image', 'the', 'method', 'according', 'to', 'claim', 'wherein', 'the', 'face', 'information', 'comprises', 'face', 'feature', 'points', 'and', 'the', 'face', 'parameter', 'comprises', 'a', 'face', 'turning', 'angle', 'acquiring', 'the', 'face', 'parameter', 'of', 'each', 'image', 'according', 'to', 'the', 'face', 'information', 'comprises', 'acquiring', 'coordinate', 'values', 'of', 'the', 'face', 'feature', 'points', 'determining', 'distances', 'and', 'angles', 'between', 'the', 'face', 'feature', 'points', 'and', 'determining', 'the', 'face', 'turning', 'angle', 'according', 'to', 'the', 'distances', 'and', 'the', 'angles', 'the', 'method', 'according', 'to', 'claim', 'wherein', 'the', 'face', 'parameter', 'comprises', 'a', 'face', 'ratio', 'acquiring', 'the', 'face', 'parameter', 'of', 'each', 'image', 'according', 'to', 'the', 'face', 'information', 'comprises', 'determining', 'a', 'face', 'region', 'of', 'the', 'image', 'according', 'to', 'the', 'face', 'information', 'and', 'calculating', 'a', 'ratio', 'of', 'an', 'area', 'of', 'the', 'face', 'region', 'to', 'an', 'area', 'of', 'the', 'image', 'to', 'obtain', 'the', 'face', 'ratio', 'the', 'method', 'according', 'to', 'claim', 'wherein', 'calculating', 'the', 'face', 'ratio', 'comprises', 'when', 'there', 'is', 'more', 'than', 'one', 'face', 'in', 'the', 'image', 'subtracting', 'an', 'area', 'occupied', 'faces', 'other', 'than', 'a', 'face', 'corresponding', 'to', 'the', 'photo', 'album', 'from', 'the', 'face', 'region', 'to', 'obtain', 'a', 'remaining', 'area', 'and', 'calculating', 'a', 'ratio', 'of', 'the', 'remaining', 'area', 'to', 'the', 'area', 'of', 'the', 'image', 'to', 'obtain', 'the', 'face', 'ratio', 'the', 'method', 'according', 'to', 'claim', 'wherein', 'collecting', 'face', 'information', 'of', 'respective', 'images', 'in', 'the', 'photo', 'album', 'comprises', 'acquiring', 'image', 'identifications', 'of', 'images', 'in', 'the', 'photo', 'album', 'extracting', 'face', 'information', 'corresponding', 'to', 'the', 'image', 'identifications', 'from', 'a', 'face', 'database', 'the', 'face', 'database', 'being', 'stored', 'with', 'face', 'recognition', 'results', 'of', 'images', 'the', 'face', 'recognition', 'results', 'including', 'the', 'face', 'information', 'an', 'image', 'processing', 'apparatus', 'comprising', 'a', 'processor', 'and', 'a', 'memory', 'configured', 'to', 'store', 'instructions', 'executable', 'by', 'the', 'processor', 'wherein', 'the', 'processor', 'is', 'configured', 'to', 'run', 'a', 'program', 'corresponding', 'to', 'the', 'instructions', 'by', 'reading', 'the', 'instructions', 'stored', 'in', 'the', 'memory', 'so', 'as', 'to', 'perform', 'acquiring', 'a', 'photo', 'album', 'obtained', 'from', 'face', 'clustering', 'collecting', 'face', 'information', 'of', 'each', 'image', 'in', 'the', 'photo', 'album', 'acquiring', 'a', 'face', 'parameter', 'of', 'each', 'image', 'according', 'to', 'the', 'face', 'information', 'selecting', 'a', 'cover', 'image', 'according', 'to', 'the', 'face', 'parameter', 'of', 'each', 'image', 'taking', 'a', 'face-region', 'image', 'from', 'the', 'cover', 'image', 'and', 'setting', 'the', 'face-region', 'image', 'as', 'a', 'cover', 'of', 'the', 'photo', 'album', 'wherein', 'the', 'processor', 'is', 'configured', 'to', 'perform', 'calculation', 'on', 'the', 'face', 'parameter', 'of', 'each', 'image', 'in', 'a', 'preset', 'way', 'to', 'obtain', 'a', 'cover', 'score', 'of', 'each', 'image', 'and', 'select', 'the', 'image', 'with', 'a', 'highest', 'cover', 'score', 'as', 'the', 'cover', 'image', 'and', 'wherein', 'the', 'processor', 'is', 'configured', 'to', 'acquire', 'a', 'source', 'of', 'each', 'image', 'and', 'select', 'the', 'image', 'with', 'the', 'highest', 'cover', 'score', 'in', 'images', 'coming', 'from', 'a', 'preset', 'source', 'as', 'the', 'cover', 'image', 'the', 'apparatus', 'according', 'to', 'claim', 'wherein', 'the', 'processor', 'is', 'configured', 'to', 'acquire', 'the', 'number', 'of', 'faces', 'contained', 'in', 'each', 'image', 'determine', 'single-person', 'images', 'according', 'to', 'the', 'number', 'of', 'faces', 'and', 'select', 'the', 'single-person', 'image', 'with', 'the', 'highest', 'cover', 'score', 'as', 'the', 'cover', 'image', 'the', 'apparatus', 'according', 'to', 'claim', 'wherein', 'the', 'processor', 'is', 'further', 'configured', 'to', 'when', 'there', 'is', 'no', 'single-person', 'image', 'in', 'the', 'photo', 'album', 'determine', 'images', 'including', 'two', 'faces', 'from', 'the', 'photo', 'album', 'and', 'select', 'the', 'image', 'with', 'the', 'highest', 'cover', 'score', 'from', 'the', 'images', 'including', 'two', 'faces', 'as', 'the', 'cover', 'image', 'the', 'apparatus', 'according', 'to', 'claim', 'wherein', 'the', 'face', 'information', 'comprises', 'face', 'feature', 'points', 'and', 'the', 'face', 'parameter', 'comprises', 'a', 'face', 'turning', 'angle', 'the', 'processor', 'is', 'configured', 'to', 'acquire', 'coordinate', 'values', 'of', 'the', 'face', 'feature', 'points', 'determine', 'distances', 'and', 'angles', 'between', 'the', 'face', 'feature', 'points', 'and', 'determine', 'the', 'face', 'turning', 'angle', 'according', 'to', 'the', 'distances', 'and', 'the', 'angles', 'the', 'apparatus', 'according', 'to', 'claim', 'wherein', 'the', 'face', 'parameter', 'comprises', 'a', 'face', 'ratio', 'the', 'processor', 'is', 'configured', 'to', 'determine', 'a', 'face', 'region', 'of', 'the', 'image', 'according', 'to', 'the', 'face', 'information', 'and', 'calculate', 'a', 'ratio', 'of', 'an', 'area', 'of', 'the', 'face', 'region', 'to', 'an', 'area', 'of', 'the', 'image', 'to', 'obtain', 'the', 'face', 'ratio', 'the', 'apparatus', 'according', 'to', 'claim', 'wherein', 'the', 'processor', 'is', 'configured', 'to', 'when', 'there', 'is', 'more', 'than', 'one', 'face', 'in', 'the', 'image', 'subtract', 'an', 'area', 'occupied', 'faces', 'other', 'than', 'a', 'face', 'corresponding', 'to', 'the', 'photo', 'album', 'from', 'the', 'face', 'region', 'to', 'obtain', 'a', 'remaining', 'area', 'and', 'calculate', 'a', 'ratio', 'of', 'the', 'remaining', 'area', 'to', 'the', 'area', 'of', 'the', 'image', 'to', 'obtain', 'the', 'face', 'ratio', 'the', 'apparatus', 'according', 'to', 'claim', 'wherein', 'the', 'processor', 'is', 'configured', 'to', 'acquire', 'image', 'identifications', 'of', 'images', 'in', 'the', 'photo', 'album', 'extract', 'face', 'information', 'corresponding', 'to', 'the', 'image', 'identifications', 'from', 'a', 'face', 'database', 'the', 'face', 'database', 'being', 'stored', 'with', 'face', 'recognition', 'results', 'of', 'images', 'the', 'face', 'recognition', 'results', 'including', 'the', 'face', 'information', 'an', 'electronic', 'device', 'comprising', 'a', 'processor', 'a', 'memory', 'a', 'display', 'screen', 'and', 'an', 'input', 'device', 'connected', 'via', 'a', 'system', 'bus', 'wherein', 'the', 'memory', 'is', 'stored', 'with', 'computer', 'programs', 'that', 'when', 'executed', 'by', 'the', 'processor', 'cause', 'the', 'processor', 'to', 'implement', 'an', 'image', 'processing', 'method', 'the', 'image', 'processing', 'method', 'comprising', 'acquiring', 'a', 'photo', 'album', 'obtained', 'from', 'face', 'clustering', 'collecting', 'face', 'information', 'of', 'respective', 'images', 'in', 'the', 'photo', 'album', 'and', 'acquiring', 'a', 'face', 'parameter', 'of', 'each', 'image', 'according', 'to', 'the', 'face', 'information', 'selecting', 'a', 'cover', 'image', 'according', 'to', 'the', 'face', 'parameter', 'of', 'each', 'image', 'and', 'taking', 'a', 'face-region', 'image', 'from', 'the', 'cover', 'image', 'and', 'setting', 'the', 'face-region', 'image', 'as', 'a', 'cover', 'of', 'the', 'photo', 'album', 'wherein', 'selecting', 'the', 'cover', 'image', 'according', 'to', 'the', 'face', 'parameter', 'of', 'each', 'image', 'comprises', 'performing', 'calculation', 'on', 'the', 'face', 'parameter', 'of', 'each', 'image', 'in', 'a', 'preset', 'way', 'to', 'obtain', 'a', 'cover', 'score', 'of', 'each', 'image', 'and', 'selecting', 'the', 'image', 'with', 'a', 'highest', 'cover', 'score', 'as', 'the', 'cover', 'image', 'and', 'wherein', 'selecting', 'the', 'image', 'with', 'the', 'highest', 'cover', 'score', 'as', 'the', 'cover', 'image', 'comprises', 'acquiring', 'a', 'source', 'of', 'each', 'image', 'and', 'selecting', 'the', 'image', 'with', 'the', 'highest', 'cover', 'score', 'in', 'images', 'coming', 'from', 'a', 'preset', 'source', 'as', 'the', 'cover', 'image', 'the', 'electronic', 'device', 'according', 'to', 'claim', 'wherein', 'the', 'electronic', 'device', 'comprises', 'at', 'least', 'one', 'of', 'a', 'mobile', 'phone', 'a', 'tablet', 'computer', 'a', 'personal', 'digital', 'assistant', 'and', 'a', 'wearable', 'device', 'a', 'computer-implemented', 'method', 'comprising', 'receiving', 'at', 'a', 'computing', 'device', 'a', 'meeting', 'invitation', 'identifying', 'a', 'location', 'and', 'at', 'least', 'one', 'invitee', 'the', 'meeting', 'invitation', 'configured', 'to', 'provide', 'the', 'at', 'least', 'one', 'invitee', 'with', 'physical', 'access', 'to', 'the', 'location', 'wherein', 'the', 'meeting', 'invitation', 'causes', 'a', 'system', 'to', 'control', 'a', 'pathway', 'allowing', 'physical', 'access', 'to', 'the', 'location', 'providing', 'based', 'on', 'the', 'meeting', 'invitation', 'the', 'at', 'least', 'one', 'invitee', 'with', 'physical', 'access', 'to', 'the', 'location', 'by', 'controlling', 'the', 'pathway', 'allowing', 'the', 'at', 'least', 'one', 'invitee', 'to', 'physically', 'access', 'the', 'location', 'through', 'the', 'pathway', 'in', 'response', 'to', 'positioning', 'data', 'indicating', 'that', 'the', 'at', 'least', 'one', 'invitee', 'is', 'at', 'a', 'predetermined', 'location', 'near', 'the', 'location', 'wherein', 'the', 'positioning', 'data', 'is', 'based', 'in', 'part', 'on', 'a', 'face', 'recognition', 'camera', 'system', 'identifying', 'the', 'at', 'least', 'one', 'invitee', 'receiving', 'the', 'positioning', 'data', 'from', 'the', 'face', 'recognition', 'camera', 'system', 'identifying', 'the', 'at', 'least', 'one', 'invitee', 'wherein', 'the', 'positioning', 'data', 'indicates', 'a', 'pattern', 'of', 'movement', 'of', 'the', 'at', 'least', 'one', 'invitee', 'determining', 'that', 'the', 'pattern', 'of', 'movement', 'indicates', 'that', 'the', 'at', 'least', 'one', 'invitee', 'has', 'exited', 'the', 'location', 'and', 'revoking', 'physical', 'access', 'to', 'the', 'location', 'identified', 'in', 'the', 'meeting', 'invitation', 'by', 'controlling', 'the', 'pathway', 'to', 'restrict', 'the', 'at', 'least', 'one', 'invitee', 'identified', 'in', 'the', 'meeting', 'invitation', 'from', 'physical', 'access', 'to', 'the', 'location', 'through', 'the', 'pathway', 'in', 'response', 'to', 'determining', 'that', 'the', 'pattern', 'of', 'movement', 'indicates', 'that', 'the', 'at', 'least', 'one', 'invitee', 'has', 'exited', 'the', 'location', 'the', 'computer-implemented', 'method', 'of', 'claim', 'wherein', 'determining', 'that', 'the', 'at', 'least', 'one', 'invitee', 'has', 'exited', 'the', 'location', 'comprises', 'determining', 'that', 'the', 'at', 'least', 'one', 'invitee', 'has', 'passed', 'through', 'an', 'egress', 'associated', 'with', 'the', 'location', 'in', 'a', 'predetermined', 'direction', 'the', 'computer-implemented', 'method', 'of', 'claim', 'wherein', 'determining', 'that', 'the', 'at', 'least', 'one', 'invitee', 'has', 'exited', 'the', 'location', 'comprises', 'determining', 'that', 'the', 'at', 'least', 'one', 'invitee', 'has', 'moved', 'through', 'an', 'area', 'in', 'a', 'predetermined', 'direction', 'the', 'computer-implemented', 'method', 'of', 'claim', 'wherein', 'the', 'positioning', 'data', 'indicates', 'a', 'second', 'pattern', 'of', 'movement', 'of', 'the', 'at', 'least', 'one', 'invitee', 'and', 'wherein', 'access', 'to', 'secured', 'data', 'associated', 'with', 'the', 'location', 'is', 'provided', 'in', 'response', 'to', 'detecting', 'the', 'second', 'pattern', 'of', 'movement', 'the', 'computer-implemented', 'method', 'of', 'claim', 'further', 'comprising', 'collating', 'secured', 'data', 'and', 'public', 'data', 'to', 'generate', 'resource', 'data', 'and', 'communicating', 'the', 'resource', 'data', 'to', 'a', 'client', 'computing', 'device', 'associated', 'with', 'the', 'at', 'least', 'one', 'invitee', 'when', 'access', 'of', 'the', 'location', 'is', 'provided', 'the', 'computer-implemented', 'method', 'of', 'claim', 'wherein', 'the', 'positioning', 'data', 'indicates', 'that', 'the', 'at', 'least', 'one', 'invitee', 'is', 'at', 'the', 'predetermined', 'location', 'when', 'the', 'at', 'least', 'one', 'invitee', 'passes', 'through', 'the', 'predetermined', 'location', 'the', 'computer-implemented', 'method', 'of', 'claim', 'wherein', 'the', 'positioning', 'data', 'indicates', 'that', 'the', 'at', 'least', 'one', 'invitee', 'is', 'at', 'the', 'predetermined', 'location', 'when', 'the', 'at', 'least', 'one', 'invitee', 'passes', 'through', 'the', 'predetermined', 'location', 'near', 'the', 'location', 'in', 'a', 'predetermined', 'direction', 'a', 'system', 'comprising', 'a', 'processor', 'and', 'a', 'memory', 'in', 'communication', 'with', 'the', 'processor', 'the', 'memory', 'having', 'computer-readable', 'instructions', 'stored', 'thereupon', 'that', 'when', 'executed', 'by', 'the', 'processor', 'cause', 'the', 'processor', 'to', 'receive', 'a', 'meeting', 'invitation', 'indicating', 'a', 'location', 'and', 'an', 'identity', 'the', 'meeting', 'invitation', 'configured', 'to', 'provide', 'at', 'least', 'one', 'invitee', 'with', 'physical', 'access', 'to', 'the', 'location', 'wherein', 'the', 'meeting', 'invitation', 'causes', 'the', 'system', 'to', 'control', 'a', 'pathway', 'allowing', 'physical', 'access', 'to', 'the', 'location', 'provide', 'the', 'at', 'least', 'one', 'invitee', 'associated', 'with', 'the', 'identity', 'access', 'to', 'the', 'location', 'by', 'controlling', 'the', 'pathway', 'allowing', 'the', 'at', 'least', 'one', 'invitee', 'to', 'physically', 'access', 'the', 'location', 'through', 'the', 'pathway', 'in', 'response', 'to', 'positioning', 'data', 'indicating', 'that', 'the', 'at', 'least', 'one', 'invitee', 'is', 'at', 'a', 'predetermined', 'location', 'near', 'the', 'location', 'wherein', 'the', 'positioning', 'data', 'is', 'based', 'in', 'part', 'on', 'a', 'face', 'recognition', 'camera', 'system', 'identifying', 'the', 'at', 'least', 'one', 'invitee', 'receive', 'the', 'positioning', 'data', 'from', 'the', 'face', 'recognition', 'camera', 'system', 'identifying', 'the', 'at', 'least', 'one', 'invitee', 'wherein', 'the', 'positioning', 'data', 'indicates', 'a', 'pattern', 'of', 'movement', 'of', 'the', 'at', 'least', 'one', 'invitee', 'determine', 'that', 'the', 'pattern', 'of', 'movement', 'indicates', 'that', 'the', 'at', 'least', 'one', 'invitee', 'has', 'exited', 'the', 'location', 'and', 'revoke', 'physical', 'access', 'to', 'the', 'location', 'identified', 'in', 'the', 'meeting', 'invitation', 'by', 'controlling', 'the', 'pathway', 'to', 'restrict', 'the', 'at', 'least', 'one', 'invitee', 'identified', 'in', 'the', 'meeting', 'invitation', 'from', 'physical', 'access', 'to', 'the', 'location', 'through', 'the', 'pathway', 'in', 'response', 'to', 'determining', 'that', 'the', 'pattern', 'of', 'movement', 'indicates', 'that', 'the', 'at', 'least', 'one', 'invitee', 'has', 'exited', 'the', 'location', 'the', 'system', 'of', 'claim', 'wherein', 'determining', 'that', 'the', 'at', 'least', 'one', 'invitee', 'has', 'exited', 'the', 'location', 'comprises', 'determining', 'that', 'the', 'at', 'least', 'one', 'invitee', 'has', 'passed', 'through', 'an', 'egress', 'associated', 'with', 'the', 'location', 'the', 'system', 'of', 'claim', 'wherein', 'determining', 'that', 'the', 'at', 'least', 'one', 'invitee', 'has', 'exited', 'the', 'location', 'comprises', 'determining', 'that', 'the', 'at', 'least', 'one', 'invitee', 'has', 'moved', 'through', 'an', 'area', 'in', 'a', 'predetermined', 'direction', 'the', 'system', 'of', 'claim', 'wherein', 'the', 'positioning', 'data', 'indicates', 'a', 'second', 'pattern', 'of', 'movement', 'of', 'the', 'at', 'least', 'one', 'invitee', 'and', 'wherein', 'access', 'to', 'secured', 'data', 'associated', 'with', 'the', 'location', 'is', 'provided', 'in', 'response', 'to', 'detecting', 'the', 'second', 'pattern', 'of', 'movement', 'the', 'system', 'of', 'claim', 'wherein', 'the', 'instructions', 'further', 'cause', 'the', 'processor', 'to', 'collate', 'secured', 'data', 'and', 'public', 'data', 'to', 'generate', 'resource', 'data', 'and', 'communicate', 'the', 'resource', 'data', 'to', 'a', 'client', 'computing', 'device', 'associated', 'with', 'the', 'at', 'least', 'one', 'invitee', 'when', 'access', 'of', 'the', 'location', 'is', 'provided', 'a', 'non-transitory', 'computer-readable', 'storage', 'medium', 'having', 'computer-executable', 'instructions', 'stored', 'thereupon', 'which', 'when', 'executed', 'by', 'one', 'or', 'more', 'processors', 'of', 'a', 'computing', 'device', 'cause', 'the', 'one', 'or', 'more', 'processors', 'of', 'the', 'computing', 'device', 'to', 'receive', 'a', 'meeting', 'invitation', 'indicating', 'a', 'location', 'and', 'an', 'identity', 'the', 'meeting', 'invitation', 'configured', 'to', 'provide', 'at', 'least', 'one', 'invitee', 'with', 'physical', 'access', 'to', 'the', 'location', 'wherein', 'the', 'meeting', 'invitation', 'causes', 'a', 'system', 'to', 'control', 'a', 'pathway', 'allowing', 'physical', 'access', 'to', 'the', 'location', 'provide', 'the', 'at', 'least', 'one', 'invitee', 'associated', 'with', 'the', 'identity', 'access', 'to', 'the', 'location', 'by', 'controlling', 'the', 'pathway', 'allowing', 'the', 'at', 'least', 'one', 'invitee', 'to', 'physically', 'access', 'the', 'location', 'through', 'the', 'pathway', 'in', 'response', 'to', 'positioning', 'data', 'indicating', 'that', 'the', 'at', 'least', 'one', 'invitee', 'is', 'at', 'a', 'predetermined', 'location', 'near', 'the', 'location', 'wherein', 'the', 'positioning', 'data', 'is', 'based', 'in', 'part', 'on', 'a', 'face', 'recognition', 'camera', 'system', 'identifying', 'the', 'at', 'least', 'one', 'invitee', 'receive', 'the', 'positioning', 'data', 'from', 'the', 'face', 'recognition', 'camera', 'system', 'identifying', 'the', 'at', 'least', 'one', 'invitee', 'wherein', 'the', 'positioning', 'data', 'indicates', 'a', 'pattern', 'of', 'movement', 'of', 'the', 'at', 'least', 'one', 'invitee', 'determine', 'that', 'the', 'pattern', 'of', 'movement', 'indicates', 'that', 'the', 'at', 'least', 'one', 'invitee', 'has', 'exited', 'the', 'location', 'and', 'revoke', 'physical', 'access', 'to', 'the', 'location', 'identified', 'in', 'the', 'meeting', 'invitation', 'by', 'controlling', 'the', 'pathway', 'to', 'restrict', 'the', 'at', 'least', 'one', 'invitee', 'identified', 'in', 'the', 'meeting', 'invitation', 'from', 'physical', 'access', 'to', 'the', 'location', 'through', 'the', 'pathway', 'in', 'response', 'to', 'determining', 'that', 'the', 'pattern', 'of', 'movement', 'indicates', 'that', 'the', 'at', 'least', 'one', 'invitee', 'has', 'exited', 'the', 'location', 'the', 'non-transitory', 'computer-readable', 'storage', 'medium', 'of', 'claim', 'wherein', 'determining', 'that', 'the', 'at', 'least', 'one', 'invitee', 'has', 'exited', 'the', 'location', 'comprises', 'determining', 'that', 'the', 'at', 'least', 'one', 'invitee', 'has', 'passed', 'through', 'an', 'egress', 'associated', 'with', 'the', 'location', 'the', 'non-transitory', 'computer-readable', 'storage', 'medium', 'of', 'claim', 'wherein', 'the', 'positioning', 'data', 'indicates', 'a', 'second', 'pattern', 'of', 'movement', 'of', 'the', 'at', 'least', 'one', 'invitee', 'and', 'wherein', 'access', 'to', 'secured', 'data', 'associated', 'with', 'the', 'location', 'is', 'provided', 'in', 'response', 'to', 'detecting', 'the', 'second', 'pattern', 'of', 'movement', 'the', 'non-transitory', 'computer-readable', 'storage', 'medium', 'of', 'claim', 'wherein', 'the', 'instructions', 'further', 'cause', 'the', 'one', 'or', 'more', 'processors', 'to', 'collate', 'secured', 'data', 'and', 'public', 'data', 'to', 'generate', 'resource', 'data', 'and', 'communicate', 'the', 'resource', 'data', 'to', 'a', 'client', 'computing', 'device', 'associated', 'with', 'the', 'at', 'least', 'one', 'invitee', 'when', 'access', 'of', 'the', 'location', 'is', 'provided', 'a', 'method', 'comprising', 'receiving', 'a', 'piece', 'of', 'content', 'and', 'salient', 'data', 'for', 'the', 'piece', 'of', 'content', 'based', 'on', 'the', 'salient', 'data', 'determining', 'a', 'first', 'path', 'for', 'a', 'viewport', 'for', 'the', 'piece', 'of', 'content', 'wherein', 'the', 'first', 'path', 'for', 'the', 'viewport', 'includes', 'different', 'salient', 'events', 'occurring', 'in', 'the', 'piece', 'of', 'content', 'at', 'different', 'times', 'during', 'playback', 'of', 'the', 'piece', 'of', 'content', 'providing', 'the', 'viewport', 'on', 'a', 'display', 'device', 'wherein', 'movement', 'of', 'the', 'viewport', 'is', 'based', 'on', 'the', 'first', 'path', 'for', 'the', 'viewport', 'and', 'the', 'salient', 'data', 'during', 'the', 'playback', 'detecting', 'an', 'additional', 'salient', 'event', 'in', 'the', 'piece', 'of', 'content', 'that', 'is', 'not', 'included', 'in', 'the', 'first', 'path', 'for', 'the', 'viewport', 'and', 'providing', 'an', 'indication', 'for', 'the', 'additional', 'salient', 'event', 'in', 'the', 'viewport', 'during', 'the', 'playback', 'the', 'method', 'of', 'claim', 'wherein', 'the', 'salient', 'data', 'identifies', 'each', 'salient', 'event', 'in', 'the', 'piece', 'of', 'content', 'and', 'the', 'salient', 'data', 'indicates', 'for', 'each', 'salient', 'event', 'in', 'the', 'piece', 'of', 'content', 'a', 'corresponding', 'point', 'location', 'of', 'the', 'salient', 'event', 'in', 'the', 'piece', 'of', 'content', 'and', 'a', 'corresponding', 'time', 'at', 'which', 'the', 'salient', 'event', 'occurs', 'during', 'the', 'playback', 'the', 'method', 'of', 'claim', 'wherein', 'the', 'salient', 'data', 'further', 'indicates', 'for', 'each', 'salient', 'event', 'in', 'the', 'piece', 'of', 'content', 'a', 'corresponding', 'type', 'of', 'the', 'salient', 'event', 'and', 'a', 'corresponding', 'strength', 'value', 'of', 'the', 'salient', 'event', 'the', 'method', 'of', 'claim', 'wherein', 'the', 'first', 'path', 'for', 'the', 'viewport', 'controls', 'the', 'movement', 'of', 'the', 'viewport', 'to', 'put', 'the', 'different', 'salient', 'events', 'in', 'a', 'view', 'of', 'the', 'viewport', 'at', 'the', 'different', 'times', 'during', 'the', 'playback', 'the', 'method', 'of', 'claim', 'further', 'comprising', 'detecting', 'one', 'or', 'more', 'salient', 'events', 'in', 'the', 'piece', 'of', 'content', 'based', 'on', 'at', 'least', 'one', 'of', 'the', 'following', 'visual', 'data', 'of', 'the', 'piece', 'of', 'content', 'audio', 'data', 'of', 'the', 'piece', 'of', 'content', 'or', 'content', 'consumption', 'experience', 'data', 'for', 'the', 'piece', 'of', 'content', 'wherein', 'the', 'salient', 'data', 'is', 'indicative', 'of', 'each', 'salient', 'event', 'detected', 'the', 'method', 'of', 'claim', 'further', 'comprising', 'detecting', 'one', 'or', 'more', 'salient', 'events', 'in', 'the', 'piece', 'of', 'content', 'based', 'on', 'at', 'least', 'one', 'of', 'the', 'following', 'face', 'recognition', 'facial', 'emotion', 'recognition', 'object', 'recognition', 'motion', 'recognition', 'or', 'metadata', 'of', 'the', 'piece', 'of', 'content', 'wherein', 'the', 'salient', 'data', 'is', 'indicative', 'of', 'each', 'salient', 'event', 'detected', 'the', 'method', 'of', 'claim', 'further', 'comprising', 'detecting', 'user', 'interaction', 'with', 'the', 'indication', 'wherein', 'the', 'indication', 'comprises', 'an', 'interactive', 'hint', 'and', 'in', 'response', 'to', 'detecting', 'the', 'user', 'interaction', 'adapting', 'the', 'first', 'path', 'for', 'the', 'viewport', 'to', 'a', 'second', 'path', 'for', 'the', 'viewport', 'based', 'on', 'the', 'user', 'interaction', 'wherein', 'the', 'second', 'path', 'for', 'the', 'viewport', 'includes', 'the', 'additional', 'salient', 'event', 'and', 'providing', 'an', 'updated', 'viewport', 'for', 'the', 'piece', 'of', 'content', 'on', 'the', 'display', 'device', 'wherein', 'movement', 'of', 'the', 'updated', 'viewport', 'is', 'based', 'on', 'the', 'second', 'path', 'for', 'the', 'viewport', 'and', 'the', 'salient', 'data', 'during', 'the', 'playback', 'and', 'the', 'second', 'path', 'for', 'the', 'viewport', 'controls', 'the', 'movement', 'of', 'the', 'updated', 'viewport', 'to', 'put', 'the', 'additional', 'salient', 'event', 'in', 'a', 'view', 'of', 'the', 'updated', 'viewport', 'the', 'method', 'of', 'claim', 'further', 'comprising', 'changing', 'a', 'weight', 'assigned', 'to', 'the', 'additional', 'salient', 'event', 'and', 'one', 'or', 'more', 'other', 'salient', 'events', 'in', 'the', 'piece', 'of', 'content', 'having', 'the', 'same', 'type', 'as', 'the', 'additional', 'salient', 'event', 'the', 'method', 'of', 'claim', 'wherein', 'the', 'second', 'path', 'for', 'the', 'viewport', 'includes', 'one', 'or', 'more', 'other', 'salient', 'events', 'in', 'the', 'piece', 'of', 'content', 'having', 'the', 'same', 'type', 'as', 'the', 'additional', 'salient', 'event', 'a', 'system', 'comprising', 'at', 'least', 'one', 'processor', 'and', 'a', 'non-transitory', 'processor-readable', 'memory', 'device', 'storing', 'instructions', 'that', 'when', 'executed', 'by', 'the', 'at', 'least', 'one', 'processor', 'causes', 'the', 'at', 'least', 'one', 'processor', 'to', 'perform', 'operations', 'including', 'receiving', 'a', 'piece', 'of', 'content', 'and', 'salient', 'data', 'for', 'the', 'piece', 'of', 'content', 'based', 'on', 'the', 'salient', 'data', 'determining', 'a', 'first', 'path', 'for', 'a', 'viewport', 'for', 'the', 'piece', 'of', 'content', 'wherein', 'the', 'first', 'path', 'for', 'the', 'viewport', 'includes', 'different', 'salient', 'events', 'occurring', 'in', 'the', 'piece', 'of', 'content', 'at', 'different', 'times', 'during', 'playback', 'of', 'the', 'piece', 'of', 'content', 'providing', 'the', 'viewport', 'on', 'a', 'display', 'device', 'wherein', 'movement', 'of', 'the', 'viewport', 'is', 'based', 'on', 'the', 'first', 'path', 'for', 'the', 'viewport', 'and', 'the', 'salient', 'data', 'during', 'the', 'playback', 'detecting', 'an', 'additional', 'salient', 'event', 'in', 'the', 'piece', 'of', 'content', 'that', 'is', 'not', 'included', 'in', 'the', 'first', 'path', 'for', 'the', 'viewport', 'and', 'providing', 'an', 'indication', 'for', 'the', 'additional', 'salient', 'event', 'in', 'the', 'viewport', 'during', 'the', 'playback', 'the', 'system', 'of', 'claim', 'wherein', 'the', 'salient', 'data', 'identifies', 'each', 'salient', 'event', 'in', 'the', 'piece', 'of', 'content', 'and', 'the', 'salient', 'data', 'indicates', 'for', 'each', 'salient', 'event', 'in', 'the', 'piece', 'of', 'content', 'a', 'corresponding', 'point', 'location', 'of', 'the', 'salient', 'event', 'in', 'the', 'piece', 'of', 'content', 'and', 'a', 'corresponding', 'time', 'at', 'which', 'the', 'salient', 'event', 'occurs', 'during', 'the', 'playback', 'the', 'system', 'of', 'claim', 'wherein', 'the', 'salient', 'data', 'further', 'indicates', 'for', 'each', 'salient', 'event', 'in', 'the', 'piece', 'of', 'content', 'a', 'corresponding', 'type', 'of', 'the', 'salient', 'event', 'and', 'a', 'corresponding', 'strength', 'value', 'of', 'the', 'salient', 'event', 'the', 'system', 'of', 'claim', 'wherein', 'the', 'salient', 'data', 'is', 'generated', 'offline', 'on', 'a', 'server', 'the', 'system', 'of', 'claim', 'the', 'operations', 'further', 'comprising', 'detecting', 'one', 'or', 'more', 'salient', 'events', 'in', 'the', 'piece', 'of', 'content', 'based', 'on', 'at', 'least', 'one', 'of', 'the', 'following', 'visual', 'data', 'of', 'the', 'piece', 'of', 'content', 'audio', 'data', 'of', 'the', 'piece', 'of', 'content', 'or', 'content', 'consumption', 'experience', 'data', 'for', 'the', 'piece', 'of', 'content', 'wherein', 'the', 'salient', 'data', 'is', 'indicative', 'of', 'each', 'salient', 'event', 'detected', 'the', 'system', 'of', 'claim', 'the', 'operations', 'further', 'comprising', 'detecting', 'one', 'or', 'more', 'salient', 'events', 'in', 'the', 'piece', 'of', 'content', 'based', 'on', 'at', 'least', 'one', 'of', 'the', 'following', 'face', 'recognition', 'facial', 'emotion', 'recognition', 'object', 'recognition', 'motion', 'recognition', 'or', 'metadata', 'of', 'the', 'piece', 'of', 'content', 'wherein', 'the', 'salient', 'data', 'is', 'indicative', 'of', 'each', 'salient', 'event', 'detected', 'the', 'system', 'of', 'claim', 'the', 'operations', 'further', 'comprising', 'detecting', 'user', 'interaction', 'with', 'the', 'indication', 'wherein', 'the', 'indication', 'comprises', 'an', 'interactive', 'hint', 'and', 'in', 'response', 'to', 'detecting', 'the', 'user', 'interaction', 'adapting', 'the', 'first', 'path', 'for', 'the', 'viewport', 'to', 'a', 'second', 'path', 'for', 'the', 'viewport', 'based', 'on', 'the', 'user', 'interaction', 'wherein', 'the', 'second', 'path', 'for', 'the', 'viewport', 'includes', 'the', 'additional', 'salient', 'event', 'and', 'providing', 'an', 'updated', 'viewport', 'for', 'the', 'piece', 'of', 'content', 'on', 'the', 'display', 'device', 'wherein', 'movement', 'of', 'the', 'updated', 'viewport', 'is', 'based', 'on', 'the', 'second', 'path', 'for', 'the', 'viewport', 'and', 'the', 'salient', 'data', 'during', 'the', 'playback', 'and', 'the', 'second', 'path', 'for', 'the', 'viewport', 'controls', 'the', 'movement', 'of', 'the', 'updated', 'viewport', 'to', 'put', 'the', 'additional', 'salient', 'event', 'in', 'a', 'view', 'of', 'the', 'updated', 'viewport', 'the', 'system', 'of', 'claim', 'the', 'operations', 'further', 'comprising', 'changing', 'a', 'weight', 'assigned', 'to', 'the', 'additional', 'salient', 'event', 'and', 'one', 'or', 'more', 'other', 'salient', 'events', 'in', 'the', 'piece', 'of', 'content', 'having', 'the', 'same', 'type', 'as', 'the', 'additional', 'salient', 'event', 'the', 'system', 'of', 'claim', 'wherein', 'the', 'second', 'path', 'for', 'the', 'viewport', 'includes', 'one', 'or', 'more', 'other', 'salient', 'events', 'in', 'the', 'piece', 'of', 'content', 'having', 'the', 'same', 'type', 'as', 'the', 'additional', 'salient', 'event', 'a', 'non-transitory', 'computer', 'readable', 'storage', 'medium', 'including', 'instructions', 'to', 'perform', 'a', 'method', 'comprising', 'receiving', 'a', 'piece', 'of', 'content', 'and', 'salient', 'data', 'for', 'the', 'piece', 'of', 'content', 'based', 'on', 'the', 'salient', 'data', 'determining', 'a', 'first', 'path', 'for', 'a', 'viewport', 'for', 'the', 'piece', 'of', 'content', 'wherein', 'the', 'first', 'path', 'for', 'the', 'viewport', 'includes', 'different', 'salient', 'events', 'occurring', 'in', 'the', 'piece', 'of', 'content', 'at', 'different', 'times', 'during', 'playback', 'of', 'the', 'piece', 'of', 'content', 'providing', 'the', 'viewport', 'on', 'a', 'display', 'device', 'wherein', 'movement', 'of', 'the', 'viewport', 'is', 'based', 'on', 'the', 'first', 'path', 'for', 'the', 'viewport', 'and', 'the', 'salient', 'data', 'during', 'the', 'playback', 'detecting', 'an', 'additional', 'salient', 'event', 'in', 'the', 'piece', 'of', 'content', 'that', 'is', 'not', 'included', 'in', 'the', 'first', 'path', 'for', 'the', 'viewport', 'and', 'providing', 'an', 'indication', 'for', 'the', 'additional', 'salient', 'event', 'in', 'the', 'viewport', 'during', 'the', 'playback', 'the', 'computer', 'readable', 'storage', 'medium', 'of', 'claim', 'the', 'method', 'further', 'comprising', 'detecting', 'user', 'interaction', 'with', 'the', 'indication', 'wherein', 'the', 'indication', 'comprises', 'an', 'interactive', 'hint', 'and', 'in', 'response', 'to', 'detecting', 'the', 'user', 'interaction', 'adapting', 'the', 'first', 'path', 'for', 'the', 'viewport', 'to', 'a', 'second', 'path', 'for', 'the', 'viewport', 'based', 'on', 'the', 'user', 'interaction', 'wherein', 'the', 'second', 'path', 'for', 'the', 'viewport', 'includes', 'the', 'additional', 'salient', 'event', 'and', 'providing', 'an', 'updated', 'viewport', 'for', 'the', 'piece', 'of', 'content', 'on', 'the', 'display', 'device', 'wherein', 'movement', 'of', 'the', 'updated', 'viewport', 'is', 'based', 'on', 'the', 'second', 'path', 'for', 'the', 'viewport', 'and', 'the', 'salient', 'data', 'during', 'the', 'playback', 'and', 'the', 'second', 'path', 'for', 'the', 'viewport', 'controls', 'the', 'movement', 'of', 'the', 'updated', 'viewport', 'to', 'put', 'the', 'additional', 'salient', 'event', 'in', 'a', 'view', 'of', 'the', 'updated', 'viewport', 'a', 'mobile', 'device', 'with', 'facial', 'recognition', 'the', 'mobile', 'device', 'comprising', 'one', 'or', 'more', 'cameras', 'a', 'processor', 'device', 'and', 'memory', 'coupled', 'to', 'the', 'processor', 'device', 'the', 'processing', 'system', 'programmed', 'to', 'receive', 'a', 'plurality', 'of', 'images', 'from', 'the', 'one', 'or', 'more', 'cameras', 'extract', 'with', 'a', 'feature', 'extractor', 'utilizing', 'a', 'convolutional', 'neural', 'network', 'cnn', 'with', 'an', 'enlarged', 'intra-class', 'variance', 'of', 'long-tail', 'classes', 'feature', 'vectors', 'from', 'each', 'of', 'the', 'plurality', 'of', 'images', 'generate', 'with', 'a', 'feature', 'generator', 'discriminative', 'feature', 'vectors', 'for', 'each', 'of', 'the', 'feature', 'vectors', 'classify', 'with', 'a', 'fully', 'connected', 'classifier', 'an', 'identity', 'from', 'the', 'discriminative', 'feature', 'vectors', 'and', 'control', 'an', 'operation', 'of', 'the', 'mobile', 'device', 'to', 'react', 'in', 'accordance', 'with', 'the', 'identity', 'the', 'mobile', 'device', 'as', 'recited', 'in', 'claim', 'further', 'includes', 'a', 'communication', 'system', 'the', 'mobile', 'device', 'as', 'recited', 'in', 'claim', 'wherein', 'the', 'operation', 'tags', 'the', 'video', 'with', 'the', 'identity', 'and', 'uploads', 'the', 'video', 'to', 'social', 'media', 'the', 'mobile', 'device', 'as', 'recited', 'in', 'claim', 'wherein', 'the', 'operation', 'tags', 'the', 'video', 'with', 'the', 'identity', 'and', 'sends', 'the', 'video', 'to', 'a', 'user', 'the', 'mobile', 'device', 'as', 'recited', 'in', 'claim', 'wherein', 'the', 'mobile', 'device', 'is', 'a', 'smart', 'phone', 'the', 'mobile', 'device', 'as', 'recited', 'in', 'claim', 'wherein', 'the', 'mobile', 'device', 'is', 'a', 'body', 'cam', 'the', 'mobile', 'device', 'as', 'recited', 'in', 'claim', 'further', 'programmed', 'to', 'train', 'the', 'feature', 'extractor', 'the', 'feature', 'generator', 'and', 'the', 'fully', 'connected', 'classifier', 'with', 'an', 'alternative', 'bi-stage', 'strategy', 'the', 'mobile', 'device', 'as', 'recited', 'in', 'claim', 'wherein', 'the', 'feature', 'extractor', 'shares', 'covariance', 'matrices', 'across', 'all', 'classes', 'to', 'transfer', 'intra-class', 'variance', 'from', 'regular', 'classes', 'to', 'the', 'long-tail', 'classes', 'the', 'mobile', 'device', 'as', 'recited', 'in', 'claim', 'wherein', 'the', 'feature', 'generator', 'optimizes', 'a', 'softmax', 'loss', 'by', 'joint', 'regularization', 'of', 'weights', 'and', 'features', 'through', 'a', 'magnitude', 'of', 'an', 'inner', 'product', 'of', 'the', 'weights', 'and', 'features', 'the', 'mobile', 'device', 'as', 'recited', 'in', 'claim', 'wherein', 'the', 'feature', 'extractor', 'averages', 'the', 'feature', 'vector', 'with', 'a', 'flipped', 'feature', 'vector', 'the', 'flipped', 'feature', 'vector', 'being', 'generated', 'from', 'a', 'horizontally', 'flipped', 'frame', 'from', 'one', 'of', 'the', 'plurality', 'of', 'images', 'the', 'mobile', 'device', 'as', 'recited', 'in', 'claim', 'wherein', 'each', 'of', 'the', 'plurality', 'of', 'images', 'is', 'selected', 'from', 'the', 'group', 'consisting', 'of', 'an', 'image', 'a', 'video', 'and', 'a', 'frame', 'from', 'the', 'video', 'the', 'mobile', 'device', 'as', 'recited', 'in', 'claim', 'wherein', 'the', 'communication', 'system', 'connects', 'to', 'a', 'remote', 'server', 'that', 'includes', 'a', 'facial', 'recognition', 'network', 'the', 'mobile', 'device', 'as', 'recited', 'in', 'claim', 'wherein', 'one', 'stage', 'of', 'the', 'alternative', 'bi-stage', 'strategy', 'fixes', 'the', 'feature', 'extractor', 'and', 'applies', 'the', 'feature', 'generator', 'to', 'generate', 'new', 'transferred', 'features', 'that', 'are', 'more', 'diverse', 'and', 'violate', 'a', 'decision', 'boundary', 'the', 'mobile', 'device', 'as', 'recited', 'in', 'claim', 'wherein', 'one', 'stage', 'of', 'the', 'alternative', 'bi-stage', 'strategy', 'fixes', 'the', 'fully', 'connected', 'classifier', 'and', 'updates', 'the', 'feature', 'extractor', 'and', 'the', 'feature', 'generator', 'a', 'computer', 'program', 'product', 'for', 'a', 'mobile', 'device', 'with', 'facial', 'recognition', 'the', 'computer', 'program', 'product', 'comprising', 'a', 'non-transitory', 'computer', 'readable', 'storage', 'medium', 'having', 'program', 'instructions', 'embodied', 'therewith', 'the', 'program', 'instructions', 'executable', 'by', 'a', 'computer', 'to', 'cause', 'the', 'computer', 'to', 'perform', 'a', 'method', 'comprising', 'receiving', 'by', 'a', 'processor', 'device', 'a', 'plurality', 'of', 'images', 'extracting', 'by', 'the', 'processor', 'device', 'with', 'a', 'feature', 'extractor', 'utilizing', 'a', 'convolutional', 'neural', 'network', 'cnn', 'with', 'an', 'enlarged', 'intra-class', 'variance', 'of', 'long-tail', 'classes', 'feature', 'vectors', 'for', 'each', 'of', 'the', 'plurality', 'of', 'images', 'generating', 'by', 'the', 'processor', 'device', 'with', 'a', 'feature', 'generator', 'discriminative', 'feature', 'vectors', 'for', 'each', 'of', 'the', 'feature', 'vectors', 'classifying', 'by', 'the', 'processor', 'device', 'utilizing', 'a', 'fully', 'connected', 'classifier', 'an', 'identity', 'from', 'the', 'discriminative', 'feature', 'vector', 'and', 'controlling', 'an', 'operation', 'of', 'the', 'mobile', 'device', 'to', 'react', 'in', 'accordance', 'with', 'the', 'identity', 'a', 'computer-implemented', 'method', 'for', 'facial', 'recognition', 'in', 'a', 'mobile', 'device', 'the', 'method', 'comprising', 'receiving', 'by', 'a', 'processor', 'device', 'a', 'plurality', 'of', 'images', 'extracting', 'by', 'the', 'processor', 'device', 'with', 'a', 'feature', 'extractor', 'utilizing', 'a', 'convolutional', 'neural', 'network', 'cnn', 'with', 'an', 'enlarged', 'intra-class', 'variance', 'of', 'long-tail', 'classes', 'feature', 'vectors', 'for', 'each', 'of', 'the', 'plurality', 'of', 'images', 'generating', 'by', 'the', 'processor', 'device', 'with', 'a', 'feature', 'generator', 'discriminative', 'feature', 'vectors', 'for', 'each', 'of', 'the', 'feature', 'vectors', 'classifying', 'by', 'the', 'processor', 'device', 'utilizing', 'a', 'fully', 'connected', 'classifier', 'an', 'identity', 'from', 'the', 'discriminative', 'feature', 'vector', 'and', 'controlling', 'an', 'operation', 'of', 'the', 'mobile', 'device', 'to', 'react', 'in', 'accordance', 'with', 'the', 'identity', 'the', 'computer-implemented', 'method', 'as', 'recited', 'in', 'claim', 'wherein', 'controlling', 'includes', 'tagging', 'the', 'video', 'with', 'the', 'identity', 'and', 'uploading', 'the', 'video', 'to', 'social', 'media', 'the', 'computer-implemented', 'method', 'as', 'recited', 'in', 'claim', 'wherein', 'controlling', 'includes', 'tagging', 'the', 'video', 'with', 'the', 'identity', 'and', 'sending', 'the', 'video', 'to', 'a', 'user', 'the', 'computer-implemented', 'method', 'as', 'recited', 'in', 'claim', 'wherein', 'extracting', 'includes', 'sharing', 'covariance', 'matrices', 'across', 'all', 'classes', 'to', 'transfer', 'intra-class', 'variance', 'from', 'regular', 'classes', 'to', 'the', 'long-tail', 'classes', 'a', 'computing', 'device', 'comprising', 'a', 'non-transitory', 'machine', 'readable', 'medium', 'storing', 'a', 'machine', 'trained', 'mt', 'network', 'comprising', 'a', 'plurality', 'of', 'layers', 'of', 'processing', 'nodes', 'each', 'processing', 'node', 'configured', 'to', 'compute', 'a', 'first', 'output', 'value', 'by', 'combining', 'a', 'set', 'of', 'output', 'values', 'from', 'a', 'set', 'of', 'processing', 'nodes', 'and', 'use', 'a', 'piecewise', 'linear', 'cup', 'function', 'to', 'compute', 'a', 'second', 'output', 'value', 'from', 'the', 'first', 'output', 'value', 'of', 'the', 'processing', 'node', 'wherein', 'the', 'piecewise', 'linear', 'cup', 'function', 'prior', 'to', 'training', 'of', 'the', 'mt', 'network', 'comprises', 'at', 'least', 'i', 'a', 'first', 'linear', 'section', 'with', 'a', 'first', 'slope', 'followed', 'by', 'ii', 'a', 'second', 'linear', 'section', 'with', 'a', 'negative', 'second', 'slope', 'followed', 'by', 'iii', 'a', 'third', 'linear', 'section', 'with', 'a', 'negative', 'third', 'slope', 'that', 'is', 'different', 'from', 'the', 'second', 'slope', 'followed', 'by', 'iv', 'a', 'fourth', 'linear', 'section', 'with', 'a', 'positive', 'fourth', 'slope', 'followed', 'by', 'v', 'a', 'fifth', 'linear', 'section', 'with', 'a', 'positive', 'fifth', 'slope', 'that', 'is', 'different', 'from', 'the', 'fourth', 'slope', 'followed', 'by', 'vi', 'a', 'sixth', 'linear', 'section', 'with', 'a', 'sixth', 'slope', 'wherein', 'the', 'piecewise', 'linear', 'cup', 'function', 'is', 'symmetric', 'about', 'a', 'vertical', 'axis', 'between', 'the', 'third', 'and', 'fourth', 'linear', 'sections', 'prior', 'to', 'training', 'of', 'the', 'mt', 'network', 'a', 'content', 'capturing', 'circuit', 'for', 'capturing', 'content', 'for', 'processing', 'by', 'the', 'mt', 'network', 'and', 'a', 'set', 'of', 'processing', 'units', 'for', 'executing', 'the', 'processing', 'nodes', 'to', 'process', 'content', 'captured', 'by', 'the', 'content', 'capturing', 'circuit', 'wherein', 'by', 'training', 'a', 'set', 'of', 'parameters', 'that', 'define', 'the', 'piecewise', 'linear', 'cup', 'function', 'of', 'each', 'node', 'in', 'first', 'and', 'second', 'pluralities', 'of', 'processing', 'nodes', 'i', 'each', 'processing', 'node', 'in', 'the', 'first', 'plurality', 'of', 'processing', 'nodes', 'is', 'configured', 'to', 'emulate', 'a', 'boolean', 'and', 'operator', 'such', 'that', 'an', 'output', 'value', 'of', 'the', 'processing', 'node', 'is', 'in', 'a', 'range', 'associated', 'with', 'a', '``', \"''\", 'value', 'only', 'when', 'a', 'set', 'of', 'inputs', 'to', 'the', 'processing', 'node', 'have', 'a', 'set', 'of', 'values', 'in', 'a', 'range', 'associated', 'with', '``', \"''\", 'and', 'ii', 'each', 'processing', 'node', 'in', 'the', 'second', 'plurality', 'of', 'processing', 'nodes', 'is', 'configured', 'to', 'emulate', 'a', 'boolean', 'xnor', 'operator', 'such', 'that', 'an', 'output', 'value', 'of', 'the', 'processing', 'node', 'is', 'in', 'the', 'range', 'associated', 'with', '``', \"''\", 'only', 'when', 'a', 'a', 'set', 'of', 'inputs', 'to', 'the', 'node', 'have', 'a', 'set', 'of', 'values', 'in', 'a', 'range', 'associated', 'with', '``', \"''\", 'or', 'b', 'the', 'set', 'of', 'inputs', 'to', 'the', 'node', 'have', 'a', 'set', 'of', 'values', 'in', 'a', 'range', 'associated', 'with', 'a', '``', \"''\", 'value', 'the', 'computing', 'device', 'of', 'claim', 'wherein', 'the', 'third', 'linear', 'section', 'of', 'the', 'piecewise', 'linear', 'cup', 'function', 'of', 'a', 'first', 'processing', 'node', 'in', 'the', 'mt', 'network', 'has', 'a', 'different', 'slope', 'from', 'the', 'third', 'linear', 'section', 'of', 'a', 'second', 'processing', 'node', 'in', 'the', 'mt', 'network', 'the', 'computing', 'device', 'of', 'claim', 'wherein', 'the', 'length', 'of', 'the', 'third', 'section', 'of', 'a', 'piecewise', 'linear', 'cup', 'function', 'of', 'a', 'first', 'processing', 'node', 'in', 'the', 'mt', 'network', 'is', 'different', 'from', 'the', 'length', 'of', 'the', 'third', 'section', 'of', 'a', 'piecewise', 'linear', 'cup', 'function', 'of', 'a', 'second', 'processing', 'node', 'in', 'the', 'mt', 'network', 'the', 'computing', 'device', 'of', 'claim', 'wherein', 'the', 'sets', 'of', 'parameters', 'are', 'trained', 'in', 'part', 'by', 'a', 'back', 'propagating', 'module', 'for', 'back', 'propagating', 'errors', 'in', 'output', 'values', 'of', 'later', 'layers', 'of', 'processing', 'nodes', 'to', 'earlier', 'layers', 'of', 'processing', 'nodes', 'by', 'adjusting', 'the', 'set', 'of', 'parameters', 'that', 'define', 'the', 'piecewise', 'linear', 'cup', 'functions', 'of', 'the', 'earlier', 'layers', 'of', 'processing', 'nodes', 'the', 'computing', 'device', 'of', 'claim', 'wherein', 'each', 'processing', 'node', 'uses', 'a', 'linear', 'function', 'that', 'is', 'defined', 'by', 'a', 'set', 'of', 'parameters', 'to', 'compute', 'the', 'first', 'output', 'value', 'of', 'the', 'processing', 'node', 'wherein', 'the', 'back', 'propagating', 'module', 'back', 'propagates', 'errors', 'in', 'output', 'values', 'of', 'later', 'layers', 'of', 'processing', 'nodes', 'to', 'earlier', 'layers', 'of', 'processing', 'nodes', 'by', 'adjusting', 'the', 'set', 'of', 'parameters', 'that', 'define', 'the', 'linear', 'functions', 'of', 'the', 'earlier', 'layers', 'of', 'processing', 'nodes', 'the', 'computing', 'device', 'of', 'claim', 'wherein', 'the', 'first', 'plurality', 'of', 'processing', 'nodes', 'that', 'emulate', 'the', 'boolean', 'and', 'operator', 'and', 'the', 'second', 'plurality', 'of', 'processing', 'nodes', 'that', 'emulate', 'the', 'boolean', 'xnor', 'operator', 'enable', 'the', 'mt', 'network', 'to', 'implement', 'mathematical', 'problems', 'the', 'computing', 'device', 'of', 'claim', 'wherein', 'each', 'of', 'a', 'plurality', 'of', 'processing', 'node', 'layers', 'has', 'a', 'plurality', 'of', 'processing', 'nodes', 'that', 'receive', 'as', 'input', 'values', 'the', 'output', 'values', 'from', 'a', 'plurality', 'of', 'processing', 'nodes', 'in', 'a', 'set', 'of', 'prior', 'layers', 'the', 'computing', 'device', 'of', 'claim', 'wherein', 'each', 'processing', 'node', 'uses', 'a', 'linear', 'function', 'to', 'compute', 'the', 'first', 'output', 'value', 'of', 'the', 'processing', 'node', 'wherein', 'each', 'processing', 'node', \"'s\", 'piecewise', 'linear', 'cup', 'function', 'is', 'defined', 'along', 'first', 'and', 'second', 'axes', 'the', 'first', 'axis', 'defining', 'a', 'range', 'of', 'output', 'values', 'from', 'the', 'processing', 'node', \"'s\", 'linear', 'function', 'and', 'the', 'second', 'axis', 'defining', 'a', 'range', 'of', 'output', 'values', 'produced', 'by', 'the', 'piecewise', 'linear', 'cup', 'function', 'for', 'the', 'range', 'of', 'output', 'values', 'from', 'the', 'processing', 'node', \"'s\", 'linear', 'function', 'the', 'computing', 'device', 'of', 'claim', 'further', 'comprising', 'a', 'content', 'output', 'circuit', 'for', 'presenting', 'an', 'output', 'based', 'on', 'the', 'processing', 'of', 'the', 'content', 'by', 'the', 'mt', 'network', 'the', 'computing', 'device', 'of', 'claim', 'wherein', 'the', 'captured', 'content', 'is', 'one', 'of', 'an', 'image', 'and', 'an', 'audio', 'segment', 'and', 'wherein', 'the', 'presented', 'output', 'is', 'an', 'output', 'display', 'on', 'a', 'display', 'screen', 'of', 'the', 'computing', 'device', 'or', 'an', 'audio', 'presentation', 'output', 'on', 'a', 'speaker', 'of', 'the', 'computing', 'device', 'the', 'computing', 'device', 'of', 'claim', 'wherein', 'the', 'computing', 'device', 'is', 'a', 'mobile', 'device', 'the', 'computing', 'device', 'of', 'claim', 'wherein', 'the', 'mt', 'network', 'is', 'a', 'mt', 'neural', 'network', 'and', 'the', 'processing', 'nodes', 'are', 'mt', 'neurons', 'the', 'computing', 'device', 'of', 'claim', 'wherein', 'the', 'set', 'of', 'parameters', 'configured', 'through', 'training', 'for', 'a', 'plurality', 'of', 'the', 'processing', 'nodes', 'comprise', 'at', 'least', 'one', 'of', 'the', 'negative', 'second', 'and', 'third', 'slopes', 'for', 'the', 'second', 'and', 'third', 'linear', 'sections', 'the', 'positive', 'fourth', 'and', 'fifth', 'slopes', 'for', 'the', 'fourth', 'and', 'fifth', 'linear', 'sections', 'a', 'first', 'intercept', 'for', 'the', 'second', 'linear', 'section', 'a', 'second', 'intercept', 'for', 'the', 'fifth', 'linear', 'section', 'and', 'a', 'set', 'of', 'lengths', 'for', 'at', 'least', 'the', 'second', 'third', 'fourth', 'and', 'fifth', 'sections', 'the', 'computing', 'device', 'of', 'claim', 'wherein', 'the', 'trained', 'set', 'of', 'parameters', 'that', 'define', 'the', 'piecewise', 'linear', 'cup', 'function', 'of', 'each', 'node', 'comprise', 'a', 'plurality', 'of', 'output', 'values', 'the', 'computing', 'device', 'of', 'claim', 'wherein', 'the', 'first', 'and', 'sixth', 'slopes', 'are', 'zerowe', 'claim', 'a', 'system', 'comprising', 'a', 'memory', 'device', 'to', 'store', 'an', 'input', 'image', 'a', 'processor', 'including', 'an', 'image', 'input', 'interface', 'to', 'receive', 'the', 'input', 'image', 'a', 'pre-processor', 'to', 'model', 'the', 'input', 'image', 'to', 'yield', 'a', 'multi-channel', 'image', 'a', 'feature', 'extractor', 'to', 'extract', 'a', 'set', 'of', 'features', 'based', 'on', 'the', 'multi-channel', 'image', 'a', 'feature', 'selector', 'to', 'select', 'one', 'or', 'more', 'features', 'from', 'the', 'set', 'of', 'features', 'of', 'the', 'multi-channel', 'image', 'wherein', 'the', 'one', 'or', 'more', 'features', 'are', 'selected', 'based', 'on', 'an', 'ability', 'to', 'differentiate', 'features', 'a', 'feature', 'matcher', 'to', 'match', 'the', 'one', 'or', 'more', 'features', 'to', 'a', 'learned', 'feature', 'set', 'and', 'a', 'similarity', 'detector', 'to', 'determine', 'whether', 'the', 'one', 'or', 'more', 'features', 'meet', 'a', 'pre-defined', 'similarity', 'threshold', 'the', 'system', 'of', 'claim', 'wherein', 'the', 'pre-processor', 'further', 'is', 'to', 'activate', 'one', 'or', 'more', 'channels', 'of', 'the', 'multi-channel', 'image', 'to', 'yield', 'one', 'or', 'more', 'activated', 'channels', 'the', 'system', 'of', 'claim', 'wherein', 'the', 'one', 'or', 'more', 'activated', 'channels', 'are', 'to', 'be', 'determined', 'based', 'on', 'their', 'ability', 'to', 'differentiate', 'features', 'the', 'system', 'of', 'claim', 'wherein', 'the', 'pre-processor', 'further', 'is', 'to', 'activate', 'one', 'or', 'more', 'local', 'patches', 'of', 'the', 'one', 'or', 'more', 'activated', 'channels', 'the', 'system', 'of', 'claim', 'wherein', 'the', 'one', 'or', 'more', 'local', 'patches', 'are', 'to', 'be', 'determined', 'based', 'on', 'their', 'ability', 'to', 'differentiate', 'features', 'the', 'system', 'of', 'claim', 'wherein', 'the', 'feature', 'matcher', 'further', 'is', 'to', 'utilize', 'a', 'large-scale', 'data', 'learning', 'process', 'to', 'perform', 'the', 'feature', 'matching', 'an', 'apparatus', 'comprising', 'an', 'image', 'input', 'interface', 'to', 'receive', 'an', 'input', 'image', 'a', 'pre-processor', 'to', 'model', 'the', 'input', 'image', 'to', 'yield', 'a', 'multi-channel', 'image', 'a', 'feature', 'extractor', 'to', 'extract', 'a', 'set', 'of', 'features', 'based', 'on', 'the', 'multi-channel', 'image', 'a', 'feature', 'selector', 'to', 'select', 'one', 'or', 'more', 'features', 'from', 'the', 'set', 'of', 'features', 'of', 'the', 'multi-channel', 'image', 'wherein', 'the', 'one', 'or', 'more', 'features', 'are', 'selected', 'based', 'on', 'an', 'ability', 'to', 'differentiate', 'features', 'a', 'feature', 'matcher', 'to', 'match', 'the', 'one', 'or', 'more', 'features', 'to', 'a', 'learned', 'feature', 'set', 'and', 'a', 'similarity', 'detector', 'to', 'determine', 'whether', 'the', 'one', 'or', 'more', 'features', 'meet', 'a', 'pre-defined', 'similarity', 'threshold', 'the', 'apparatus', 'of', 'claim', 'wherein', 'the', 'pre-processor', 'further', 'is', 'to', 'activate', 'one', 'or', 'more', 'channels', 'of', 'the', 'multi-channel', 'image', 'to', 'yield', 'one', 'or', 'more', 'activated', 'channels', 'the', 'apparatus', 'of', 'claim', 'wherein', 'the', 'one', 'or', 'more', 'activated', 'channels', 'are', 'to', 'be', 'determined', 'based', 'on', 'their', 'ability', 'to', 'differentiate', 'features', 'the', 'apparatus', 'of', 'claim', 'wherein', 'the', 'pre-processor', 'further', 'is', 'to', 'activate', 'one', 'or', 'more', 'local', 'patches', 'of', 'the', 'one', 'or', 'more', 'activated', 'channels', 'the', 'apparatus', 'of', 'claim', 'wherein', 'the', 'one', 'or', 'more', 'local', 'patches', 'are', 'to', 'be', 'determined', 'based', 'on', 'their', 'ability', 'to', 'differentiate', 'features', 'the', 'apparatus', 'of', 'claim', 'wherein', 'the', 'feature', 'matcher', 'further', 'is', 'to', 'utilize', 'a', 'large-scale', 'data', 'learning', 'process', 'to', 'perform', 'the', 'feature', 'matching', 'a', 'method', 'comprising', 'modeling', 'an', 'input', 'image', 'to', 'yield', 'a', 'multi-channel', 'image', 'extracting', 'a', 'set', 'of', 'features', 'based', 'on', 'the', 'multi-channel', 'image', 'selecting', 'one', 'or', 'more', 'features', 'from', 'the', 'set', 'of', 'features', 'of', 'the', 'multi-channel', 'image', 'wherein', 'the', 'one', 'or', 'more', 'features', 'are', 'selected', 'based', 'on', 'an', 'ability', 'to', 'differentiate', 'features', 'matching', 'the', 'one', 'or', 'more', 'features', 'to', 'a', 'learned', 'feature', 'set', 'and', 'determining', 'whether', 'the', 'one', 'or', 'more', 'features', 'meet', 'a', 'pre-defined', 'similarity', 'threshold', 'the', 'method', 'of', 'claim', 'wherein', 'modeling', 'the', 'input', 'image', 'further', 'is', 'to', 'include', 'activating', 'one', 'or', 'more', 'channels', 'of', 'the', 'multi-channel', 'image', 'to', 'yield', 'one', 'or', 'more', 'activated', 'channels', 'the', 'method', 'of', 'claim', 'wherein', 'the', 'one', 'or', 'more', 'activated', 'channels', 'are', 'to', 'be', 'determined', 'based', 'on', 'their', 'ability', 'to', 'differentiate', 'features', 'the', 'method', 'of', 'claim', 'wherein', 'extracting', 'features', 'of', 'the', 'input', 'image', 'further', 'is', 'to', 'include', 'activating', 'one', 'or', 'more', 'local', 'patches', 'of', 'the', 'one', 'or', 'more', 'activated', 'channels', 'the', 'method', 'of', 'claim', 'wherein', 'the', 'one', 'or', 'more', 'local', 'patches', 'are', 'to', 'be', 'determined', 'based', 'on', 'their', 'ability', 'to', 'differentiate', 'features', 'the', 'method', 'of', 'claim', 'wherein', 'the', 'feature', 'matcher', 'utilizes', 'a', 'large-scale', 'data', 'learning', 'process', 'to', 'perform', 'the', 'feature', 'matching', 'at', 'least', 'one', 'non-transitory', 'computer', 'readable', 'storage', 'medium', 'comprising', 'a', 'set', 'of', 'instructions', 'which', 'when', 'executed', 'by', 'a', 'computing', 'device', 'cause', 'the', 'computing', 'device', 'to', 'model', 'an', 'input', 'image', 'to', 'yield', 'a', 'multi-channel', 'image', 'extract', 'a', 'set', 'of', 'features', 'based', 'on', 'the', 'multi-channel', 'image', 'select', 'one', 'or', 'more', 'features', 'from', 'the', 'set', 'of', 'features', 'of', 'the', 'multi-channel', 'image', 'wherein', 'the', 'features', 'are', 'selected', 'based', 'on', 'an', 'ability', 'to', 'differentiate', 'features', 'match', 'the', 'one', 'or', 'more', 'features', 'to', 'a', 'learned', 'feature', 'set', 'and', 'determine', 'whether', 'the', 'one', 'or', 'more', 'features', 'meet', 'a', 'pre-defined', 'similarity', 'threshold', 'the', 'at', 'least', 'one', 'non-transitory', 'computer', 'readable', 'storage', 'medium', 'of', 'claim', 'wherein', 'the', 'instructions', 'when', 'executed', 'cause', 'a', 'computing', 'device', 'to', 'activate', 'one', 'or', 'more', 'channels', 'of', 'the', 'multi-channel', 'image', 'to', 'yield', 'one', 'or', 'more', 'activated', 'channels', 'the', 'at', 'least', 'one', 'non-transitory', 'computer', 'readable', 'storage', 'medium', 'of', 'claim', 'wherein', 'the', 'instructions', 'when', 'executed', 'cause', 'a', 'computing', 'device', 'to', 'determine', 'the', 'one', 'or', 'more', 'activated', 'channels', 'based', 'on', 'their', 'ability', 'to', 'differentiate', 'features', 'the', 'at', 'least', 'one', 'non-transitory', 'computer', 'readable', 'storage', 'medium', 'of', 'claim', 'wherein', 'extracting', 'features', 'of', 'the', 'input', 'image', 'is', 'to', 'further', 'include', 'activating', 'one', 'or', 'more', 'local', 'patches', 'of', 'the', 'one', 'or', 'more', 'activated', 'channels', 'the', 'at', 'least', 'one', 'non-transitory', 'computer', 'readable', 'storage', 'medium', 'of', 'claim', 'wherein', 'the', 'one', 'or', 'more', 'local', 'patches', 'are', 'to', 'be', 'determined', 'based', 'on', 'their', 'ability', 'to', 'differentiate', 'features', 'the', 'at', 'least', 'one', 'non-transitory', 'computer', 'readable', 'storage', 'medium', 'of', 'claim', 'wherein', 'the', 'feature', 'matcher', 'further', 'is', 'to', 'utilize', 'a', 'large-scale', 'data', 'learning', 'process', 'to', 'perform', 'the', 'feature', 'matching', 'an', 'apparatus', 'comprising', 'means', 'for', 'modeling', 'an', 'input', 'image', 'to', 'yield', 'a', 'multi-channel', 'image', 'means', 'for', 'extracting', 'a', 'set', 'of', 'features', 'based', 'on', 'the', 'multi-channel', 'image', 'means', 'for', 'selecting', 'one', 'or', 'more', 'features', 'from', 'the', 'set', 'of', 'features', 'of', 'the', 'multi-channel', 'image', 'wherein', 'the', 'one', 'or', 'more', 'features', 'are', 'selected', 'based', 'on', 'an', 'ability', 'to', 'differentiate', 'features', 'means', 'for', 'matching', 'the', 'one', 'or', 'more', 'features', 'to', 'a', 'learned', 'feature', 'set', 'and', 'means', 'for', 'determining', 'whether', 'the', 'one', 'or', 'more', 'features', 'meet', 'a', 'pre-defined', 'similarity', 'threshold', 'a', 'method', 'for', 'controlling', 'a', 'terminal', 'the', 'terminal', 'comprising', 'a', 'capturing', 'apparatus', 'and', 'at', 'least', 'one', 'processor', 'the', 'method', 'comprising', 'acquiring', 'by', 'the', 'capturing', 'apparatus', 'an', 'image', 'obtaining', 'by', 'the', 'at', 'least', 'one', 'processor', 'a', 'motion', 'parameter', 'of', 'the', 'terminal', 'the', 'motion', 'parameter', 'comprising', 'at', 'least', 'one', 'of', 'a', 'motion', 'frequency', 'or', 'a', 'motion', 'time', 'and', 'two', 'or', 'more', 'parameters', 'from', 'among', 'an', 'acceleration', 'an', 'angular', 'velocity', 'a', 'motion', 'amplitude', 'the', 'motion', 'frequency', 'and', 'the', 'motion', 'time', 'transmitting', 'by', 'the', 'at', 'least', 'one', 'processor', 'a', 'parameter', 'threshold', 'obtaining', 'request', 'to', 'a', 'data', 'management', 'server', 'the', 'parameter', 'threshold', 'obtaining', 'request', 'comprising', 'configuration', 'information', 'of', 'the', 'terminal', 'receiving', 'corresponding', 'preset', 'thresholds', 'that', 'correspond', 'to', 'the', 'configuration', 'information', 'in', 'response', 'to', 'the', 'parameter', 'threshold', 'obtaining', 'request', 'comparing', 'the', 'two', 'or', 'more', 'parameters', 'with', 'the', 'corresponding', 'preset', 'thresholds', 'and', 'controlling', 'by', 'the', 'at', 'least', 'one', 'processor', 'not', 'to', 'perform', 'image', 'processing', 'on', 'the', 'acquired', 'image', 'based', 'on', 'at', 'least', 'one', 'of', 'the', 'two', 'or', 'more', 'parameters', 'of', 'the', 'motion', 'parameter', 'being', 'greater', 'than', 'a', 'corresponding', 'preset', 'threshold', 'or', 'based', 'on', 'the', 'two', 'or', 'more', 'parameters', 'of', 'the', 'motion', 'parameter', 'being', 'respectively', 'greater', 'than', 'the', 'corresponding', 'preset', 'thresholds', 'wherein', 'the', 'acquiring', 'comprises', 'acquiring', 'the', 'image', 'in', 'real', 'time', 'and', 'the', 'obtaining', 'comprises', 'obtaining', 'the', 'motion', 'parameter', 'of', 'the', 'terminal', 'in', 'real', 'time', 'the', 'method', 'further', 'comprising', 'in', 'response', 'to', 'the', 'at', 'least', 'one', 'of', 'the', 'two', 'or', 'more', 'parameters', 'of', 'the', 'motion', 'parameter', 'being', 'greater', 'than', 'the', 'corresponding', 'preset', 'threshold', 'obtaining', 'the', 'motion', 'parameter', 'of', 'the', 'terminal', 'again', 'and', 'in', 'response', 'to', 'the', 'two', 'or', 'more', 'parameters', 'of', 'the', 'motion', 'parameter', 'obtained', 'at', 'a', 'latest', 'time', 'being', 'less', 'than', 'or', 'equal', 'to', 'the', 'corresponding', 'preset', 'thresholds', 'performing', 'the', 'image', 'processing', 'on', 'the', 'image', 'acquired', 'at', 'the', 'latest', 'time', 'the', 'method', 'according', 'to', 'claim', 'wherein', 'the', 'acquiring', 'comprises', 'controlling', 'by', 'the', 'at', 'least', 'one', 'processor', 'to', 'turn', 'on', 'the', 'capturing', 'apparatus', 'based', 'on', 'a', 'face', 'recognition', 'instruction', 'and', 'acquiring', 'by', 'the', 'capturing', 'apparatus', 'a', 'face', 'image', 'when', 'the', 'capturing', 'apparatus', 'is', 'turned', 'on', 'the', 'method', 'according', 'to', 'claim', 'wherein', 'the', 'controlling', 'not', 'to', 'perform', 'the', 'image', 'processing', 'comprises', 'skipping', 'performing', 'face', 'recognition', 'on', 'the', 'acquired', 'face', 'image', 'based', 'on', 'the', 'at', 'least', 'one', 'of', 'the', 'two', 'or', 'more', 'parameters', 'of', 'the', 'motion', 'parameter', 'being', 'greater', 'than', 'the', 'corresponding', 'preset', 'threshold', 'or', 'based', 'on', 'the', 'two', 'or', 'more', 'parameters', 'of', 'the', 'motion', 'parameter', 'being', 'respectively', 'greater', 'than', 'the', 'corresponding', 'preset', 'thresholds', 'the', 'method', 'according', 'to', 'claim', 'wherein', 'the', 'obtaining', 'comprises', 'at', 'least', 'one', 'of', 'obtaining', 'the', 'acceleration', 'of', 'the', 'terminal', 'by', 'using', 'an', 'acceleration', 'sensor', 'or', 'obtaining', 'the', 'angular', 'velocity', 'of', 'the', 'terminal', 'by', 'using', 'a', 'gyro', 'sensor', 'the', 'method', 'according', 'to', 'claim', 'wherein', 'the', 'transmitting', 'comprises', 'transmitting', 'the', 'parameter', 'threshold', 'obtaining', 'request', 'to', 'the', 'data', 'management', 'server', 'according', 'to', 'a', 'preset', 'time', 'period', 'the', 'method', 'according', 'to', 'claim', 'further', 'comprising', 'generating', 'prompt', 'information', 'based', 'on', 'the', 'at', 'least', 'one', 'of', 'the', 'two', 'or', 'more', 'parameters', 'of', 'the', 'motion', 'parameter', 'being', 'greater', 'than', 'the', 'corresponding', 'preset', 'threshold', 'the', 'prompt', 'information', 'being', 'used', 'for', 'prompting', 'the', 'terminal', 'to', 'stop', 'moving', 'the', 'method', 'according', 'to', 'claim', 'wherein', 'the', 'motion', 'parameter', 'comprises', 'the', 'motion', 'frequency', 'and', 'the', 'motion', 'time', 'a', 'terminal', 'comprising', 'a', 'capturing', 'apparatus', 'at', 'least', 'one', 'memory', 'configured', 'to', 'store', 'program', 'code', 'and', 'at', 'least', 'one', 'processor', 'configured', 'to', 'access', 'the', 'at', 'least', 'one', 'memory', 'and', 'operate', 'according', 'to', 'the', 'program', 'code', 'the', 'program', 'code', 'comprising', 'motion', 'parameter', 'obtaining', 'code', 'configured', 'to', 'cause', 'the', 'at', 'least', 'one', 'processor', 'to', 'acquire', 'an', 'image', 'by', 'using', 'the', 'capturing', 'apparatus', 'and', 'obtain', 'a', 'motion', 'parameter', 'of', 'the', 'terminal', 'the', 'motion', 'parameter', 'comprising', 'at', 'least', 'one', 'of', 'a', 'motion', 'frequency', 'or', 'a', 'motion', 'time', 'and', 'two', 'or', 'more', 'parameters', 'from', 'among', 'an', 'acceleration', 'an', 'angular', 'velocity', 'a', 'motion', 'amplitude', 'the', 'motion', 'frequency', 'and', 'the', 'motion', 'time', 'request', 'transmitting', 'code', 'configured', 'to', 'cause', 'the', 'at', 'least', 'one', 'processor', 'to', 'transmit', 'a', 'parameter', 'threshold', 'obtaining', 'request', 'to', 'a', 'data', 'management', 'server', 'the', 'parameter', 'threshold', 'obtaining', 'request', 'comprising', 'configuration', 'information', 'of', 'the', 'terminal', 'parameter', 'threshold', 'receiving', 'code', 'configured', 'to', 'cause', 'the', 'at', 'least', 'one', 'processor', 'to', 'receive', 'corresponding', 'preset', 'thresholds', 'that', 'correspond', 'to', 'the', 'configuration', 'information', 'in', 'response', 'to', 'the', 'parameter', 'threshold', 'obtaining', 'request', 'comparing', 'code', 'configured', 'to', 'cause', 'the', 'at', 'least', 'one', 'processor', 'to', 'compare', 'the', 'two', 'or', 'more', 'parameters', 'with', 'the', 'corresponding', 'preset', 'thresholds', 'and', 'control', 'code', 'configured', 'to', 'cause', 'the', 'at', 'least', 'one', 'processor', 'not', 'to', 'perform', 'image', 'processing', 'on', 'the', 'acquired', 'image', 'based', 'on', 'at', 'least', 'one', 'of', 'the', 'two', 'or', 'more', 'parameters', 'of', 'the', 'motion', 'parameter', 'being', 'greater', 'than', 'a', 'corresponding', 'preset', 'threshold', 'or', 'based', 'on', 'the', 'two', 'or', 'more', 'parameters', 'of', 'the', 'motion', 'parameter', 'being', 'respectively', 'greater', 'than', 'the', 'corresponding', 'preset', 'thresholds', 'wherein', 'the', 'motion', 'parameter', 'obtaining', 'code', 'causes', 'the', 'at', 'least', 'one', 'processor', 'to', 'acquire', 'the', 'image', 'in', 'real', 'time', 'and', 'obtain', 'the', 'motion', 'parameter', 'of', 'the', 'terminal', 'in', 'real', 'time', 'and', 'in', 'response', 'to', 'the', 'at', 'least', 'one', 'of', 'the', 'two', 'or', 'more', 'parameters', 'of', 'the', 'motion', 'parameter', 'being', 'greater', 'than', 'the', 'corresponding', 'preset', 'threshold', 'obtain', 'the', 'motion', 'parameter', 'of', 'the', 'terminal', 'again', 'and', 'wherein', 'the', 'control', 'code', 'causes', 'the', 'at', 'least', 'one', 'processor', 'to', 'in', 'response', 'to', 'the', 'two', 'or', 'more', 'parameters', 'of', 'the', 'motion', 'parameter', 'obtained', 'at', 'a', 'latest', 'time', 'being', 'less', 'than', 'or', 'equal', 'to', 'the', 'corresponding', 'preset', 'thresholds', 'perform', 'the', 'image', 'processing', 'on', 'the', 'image', 'acquired', 'at', 'the', 'latest', 'time', 'the', 'terminal', 'according', 'to', 'claim', 'wherein', 'the', 'program', 'code', 'further', 'comprises', 'face', 'instruction', 'receiving', 'code', 'configured', 'to', 'cause', 'the', 'at', 'least', 'one', 'processor', 'to', 'receive', 'a', 'face', 'recognition', 'instruction', 'wherein', 'the', 'motion', 'parameter', 'obtaining', 'code', 'causes', 'the', 'at', 'least', 'one', 'processor', 'to', 'control', 'according', 'to', 'the', 'face', 'recognition', 'instruction', 'the', 'capturing', 'apparatus', 'to', 'turn', 'on', 'and', 'acquire', 'a', 'face', 'image', 'by', 'using', 'the', 'capturing', 'apparatus', 'when', 'the', 'capturing', 'apparatus', 'is', 'turned', 'on', 'and', 'wherein', 'the', 'control', 'code', 'causes', 'the', 'at', 'least', 'one', 'processor', 'to', 'skip', 'performing', 'face', 'recognition', 'on', 'the', 'acquired', 'face', 'image', 'based', 'on', 'the', 'at', 'least', 'one', 'of', 'the', 'two', 'or', 'more', 'parameters', 'of', 'the', 'motion', 'parameter', 'being', 'greater', 'than', 'the', 'corresponding', 'preset', 'threshold', 'or', 'based', 'on', 'the', 'two', 'or', 'more', 'parameters', 'of', 'the', 'motion', 'parameter', 'being', 'respectively', 'greater', 'than', 'the', 'corresponding', 'preset', 'thresholds', 'the', 'terminal', 'according', 'to', 'claim', 'wherein', 'the', 'request', 'transmitting', 'code', 'causes', 'the', 'at', 'least', 'one', 'processor', 'to', 'transmit', 'the', 'parameter', 'threshold', 'obtaining', 'request', 'to', 'the', 'data', 'management', 'server', 'according', 'to', 'a', 'preset', 'time', 'period', 'the', 'terminal', 'according', 'to', 'claim', 'wherein', 'the', 'program', 'code', 'further', 'comprises', 'prompt', 'information', 'generation', 'code', 'configured', 'to', 'cause', 'the', 'at', 'least', 'one', 'processor', 'to', 'generate', 'prompt', 'information', 'based', 'on', 'at', 'least', 'one', 'of', 'the', 'two', 'or', 'more', 'parameters', 'of', 'the', 'motion', 'parameter', 'being', 'greater', 'than', 'the', 'corresponding', 'preset', 'threshold', 'the', 'prompt', 'information', 'being', 'used', 'for', 'prompting', 'the', 'terminal', 'to', 'stop', 'moving', 'the', 'terminal', 'according', 'to', 'claim', 'wherein', 'the', 'motion', 'parameter', 'comprises', 'the', 'motion', 'frequency', 'and', 'the', 'motion', 'time', 'a', 'non-transitory', 'computer-readable', 'storage', 'medium', 'storing', 'a', 'machine', 'instruction', 'which', 'when', 'executed', 'by', 'one', 'or', 'more', 'processors', 'causes', 'the', 'one', 'or', 'more', 'processors', 'to', 'perform', 'obtaining', 'an', 'image', 'acquired', 'by', 'a', 'capturing', 'apparatus', 'obtaining', 'a', 'motion', 'parameter', 'of', 'a', 'terminal', 'the', 'terminal', 'comprising', 'the', 'capturing', 'apparatus', 'the', 'motion', 'parameter', 'comprising', 'at', 'least', 'one', 'of', 'a', 'motion', 'frequency', 'or', 'a', 'motion', 'time', 'and', 'two', 'or', 'more', 'parameters', 'from', 'among', 'an', 'acceleration', 'an', 'angular', 'velocity', 'a', 'motion', 'amplitude', 'the', 'motion', 'frequency', 'and', 'the', 'motion', 'time', 'transmitting', 'a', 'parameter', 'threshold', 'obtaining', 'request', 'to', 'a', 'data', 'management', 'server', 'the', 'parameter', 'threshold', 'obtaining', 'request', 'comprising', 'configuration', 'information', 'of', 'the', 'terminal', 'receiving', 'corresponding', 'preset', 'thresholds', 'that', 'correspond', 'to', 'the', 'configuration', 'information', 'in', 'response', 'to', 'the', 'parameter', 'threshold', 'obtaining', 'request', 'comparing', 'the', 'two', 'or', 'more', 'parameters', 'with', 'the', 'corresponding', 'preset', 'thresholds', 'and', 'controlling', 'not', 'to', 'perform', 'image', 'processing', 'on', 'an', 'acquired', 'image', 'based', 'on', 'at', 'least', 'one', 'of', 'the', 'two', 'or', 'more', 'parameters', 'of', 'the', 'motion', 'parameter', 'being', 'greater', 'than', 'a', 'corresponding', 'preset', 'threshold', 'or', 'based', 'on', 'the', 'two', 'or', 'more', 'parameters', 'of', 'the', 'motion', 'parameter', 'being', 'respectively', 'greater', 'than', 'the', 'corresponding', 'preset', 'thresholds', 'wherein', 'the', 'acquiring', 'comprises', 'acquiring', 'the', 'image', 'in', 'real', 'time', 'and', 'the', 'obtaining', 'comprises', 'obtaining', 'the', 'motion', 'parameter', 'of', 'the', 'terminal', 'in', 'real', 'time', 'the', 'method', 'further', 'comprising', 'in', 'response', 'to', 'the', 'at', 'least', 'one', 'of', 'the', 'two', 'or', 'more', 'parameters', 'of', 'the', 'motion', 'parameter', 'being', 'greater', 'than', 'the', 'corresponding', 'preset', 'threshold', 'obtaining', 'the', 'motion', 'parameter', 'of', 'the', 'terminal', 'again', 'and', 'in', 'response', 'to', 'the', 'two', 'or', 'more', 'parameters', 'of', 'the', 'motion', 'parameter', 'obtained', 'at', 'a', 'latest', 'time', 'being', 'less', 'than', 'or', 'equal', 'to', 'the', 'corresponding', 'preset', 'thresholds', 'performing', 'the', 'image', 'processing', 'on', 'the', 'image', 'acquired', 'at', 'the', 'latest', 'time', 'the', 'non-transitory', 'computer-readable', 'storage', 'medium', 'according', 'to', 'claim', 'wherein', 'the', 'acquired', 'image', 'is', 'a', 'face', 'image', 'and', 'the', 'image', 'processing', 'comprises', 'performing', 'face', 'recognition', 'the', 'non-transitory', 'computer-readable', 'storage', 'medium', 'according', 'to', 'claim', 'wherein', 'the', 'obtaining', 'the', 'motion', 'parameter', 'comprises', 'at', 'least', 'one', 'of', 'obtaining', 'the', 'acceleration', 'of', 'the', 'terminal', 'by', 'using', 'an', 'acceleration', 'sensor', 'or', 'obtaining', 'the', 'angular', 'velocity', 'of', 'the', 'terminal', 'by', 'using', 'a', 'gyro', 'sensor', 'the', 'non-transitory', 'computer-readable', 'storage', 'medium', 'according', 'to', 'claim', 'wherein', 'the', 'motion', 'parameter', 'comprises', 'the', 'motion', 'frequency', 'and', 'the', 'motion', 'time', 'a', 'method', 'of', 'processing', 'a', 'drive-through', 'order', 'the', 'method', 'comprising', 'receiving', 'customer', 'information', 'detected', 'through', 'vision', 'recognition', 'providing', 'product', 'information', 'to', 'a', 'customer', 'based', 'on', 'the', 'customer', 'information', 'and', 'processing', 'a', 'product', 'order', 'of', 'the', 'customer', 'the', 'method', 'according', 'to', 'claim', 'wherein', 'the', 'receiving', 'of', 'customer', 'information', 'comprises', 'at', 'least', 'one', 'of', 'receiving', 'customer', 'information', 'associated', 'with', 'vehicle', 'information', 'detected', 'through', 'vehicle', 'recognition', 'or', 'receiving', 'customer', 'information', 'associated', 'with', 'identification', 'information', 'detected', 'through', 'face', 'recognition', 'the', 'method', 'according', 'to', 'claim', 'further', 'comprising', 'determining', 'whether', 'the', 'customer', 'is', 'a', 'pre-order', 'customer', 'based', 'on', 'the', 'customer', 'information', 'wherein', 'when', 'the', 'customer', 'is', 'determined', 'to', 'be', 'a', 'pre-order', 'customer', 'the', 'providing', 'of', 'product', 'information', 'based', 'on', 'the', 'customer', 'information', 'comprises', 'providing', 'pre-order', 'information', 'using', 'at', 'least', 'one', 'of', 'audio', 'or', 'video', 'and', 'the', 'processing', 'of', 'the', 'product', 'order', 'of', 'the', 'customer', 'comprises', 'providing', 'information', 'for', 'promptly', 'guiding', 'a', 'vehicle', 'to', 'a', 'pickup', 'stand', 'using', 'at', 'least', 'one', 'of', 'audio', 'or', 'video', 'and', 'providing', 'information', 'that', 'an', 'additional', 'order', 'is', 'available', 'the', 'method', 'according', 'to', 'claim', 'wherein', 'the', 'product', 'information', 'based', 'on', 'the', 'customer', 'information', 'comprises', 'a', 'most', 'recently', 'ordered', 'product', 'component', 'and', 'a', 'most', 'frequently', 'ordered', 'product', 'component', 'in', 'an', 'order', 'history', 'of', 'the', 'customer', 'information', 'the', 'method', 'according', 'to', 'claim', 'wherein', 'the', 'receiving', 'of', 'customer', 'information', 'comprises', 'receiving', 'information', 'about', 'an', 'age', 'and', 'gender', 'of', 'a', 'passenger', 'detected', 'through', 'face', 'recognition', 'and', 'the', 'providing', 'of', 'product', 'information', 'to', 'a', 'customer', 'based', 'on', 'the', 'customer', 'information', 'comprises', 'providing', 'recommended', 'menu', 'information', 'differentiated', 'according', 'to', 'the', 'age', 'and', 'gender', 'the', 'method', 'according', 'to', 'claim', 'wherein', 'the', 'processing', 'of', 'a', 'product', 'order', 'of', 'the', 'customer', 'comprises', 'determining', 'a', 'product', 'component', 'in', 'a', 'past', 'order', 'history', 'or', 'a', 'component', 'modified', 'from', 'the', 'product', 'component', 'as', 'a', 'product', 'order', 'the', 'method', 'according', 'to', 'claim', 'wherein', 'the', 'processing', 'of', 'a', 'product', 'order', 'of', 'the', 'customer', 'comprises', 'paying', 'a', 'product', 'price', 'according', 'to', 'biometrics-based', 'authentication', 'through', 'a', 'communication', 'system', 'of', 'a', 'vehicle', 'or', 'a', 'mobile', 'terminal', 'the', 'method', 'according', 'to', 'claim', 'wherein', 'the', 'processing', 'of', 'a', 'product', 'order', 'of', 'the', 'customer', 'comprises', 'issuing', 'a', 'payment', 'number', 'for', 'a', 'divided', 'payment', 'and', 'performing', 'the', 'divided', 'payments', 'according', 'to', 'payment', 'requests', 'of', 'a', 'plurality', 'of', 'mobile', 'terminals', 'to', 'which', 'the', 'payment', 'numbers', 'are', 'inputted', 'the', 'method', 'according', 'to', 'claim', 'wherein', 'the', 'processing', 'of', 'a', 'product', 'order', 'of', 'the', 'customer', 'further', 'comprises', 'accumulating', 'mileage', 'in', 'an', 'account', 'corresponding', 'to', 'the', 'mobile', 'terminal', 'undergoing', 'a', 'payment', 'the', 'method', 'according', 'to', 'claim', 'wherein', 'the', 'processing', 'of', 'a', 'product', 'order', 'of', 'the', 'customer', 'further', 'comprises', 'suggesting', 'a', 'takeout', 'packaging', 'method', 'according', 'to', 'a', 'temperature', 'of', 'a', 'product', 'an', 'atmospheric', 'temperature', 'weather', 'and', 'a', 'vehicle', 'type', 'an', 'apparatus', 'configured', 'to', 'process', 'a', 'drive-through', 'order', 'the', 'apparatus', 'comprising', 'a', 'transceiver', 'configured', 'to', 'receive', 'customer', 'information', 'detected', 'through', 'vision', 'recognition', 'a', 'digital', 'signage', 'configured', 'to', 'provide', 'product', 'information', 'to', 'a', 'customer', 'based', 'on', 'the', 'customer', 'information', 'and', 'a', 'processor', 'configured', 'to', 'process', 'a', 'product', 'order', 'of', 'the', 'customer', 'the', 'apparatus', 'according', 'to', 'claim', 'wherein', 'the', 'transceiver', 'receives', 'at', 'least', 'one', 'of', 'customer', 'information', 'associated', 'with', 'vehicle', 'information', 'detected', 'through', 'vehicle', 'recognition', 'or', 'customer', 'information', 'associated', 'with', 'identification', 'information', 'detected', 'through', 'face', 'recognition', 'the', 'apparatus', 'according', 'to', 'claim', 'wherein', 'the', 'processor', 'is', 'configured', 'to', 'determine', 'whether', 'the', 'customer', 'is', 'a', 'pre-order', 'customer', 'based', 'on', 'the', 'customer', 'information', 'and', 'when', 'the', 'customer', 'is', 'determined', 'to', 'be', 'a', 'pre-order', 'customer', 'perform', 'a', 'control', 'operation', 'to', 'provide', 'pre-order', 'information', 'and', 'control', 'the', 'digital', 'signage', 'to', 'output', 'information', 'for', 'promptly', 'guiding', 'a', 'vehicle', 'to', 'a', 'pickup', 'stand', 'and', 'provide', 'information', 'that', 'an', 'additional', 'order', 'is', 'available', 'the', 'apparatus', 'according', 'to', 'claim', 'wherein', 'the', 'product', 'information', 'based', 'on', 'the', 'customer', 'information', 'comprises', 'a', 'most', 'recently', 'ordered', 'product', 'component', 'and', 'a', 'most', 'frequently', 'ordered', 'product', 'component', 'in', 'an', 'order', 'history', 'of', 'the', 'customer', 'information', 'the', 'apparatus', 'according', 'to', 'claim', 'wherein', 'the', 'transceiver', 'is', 'configured', 'to', 'receive', 'information', 'about', 'an', 'age', 'and', 'gender', 'of', 'a', 'passenger', 'detected', 'through', 'face', 'recognition', 'and', 'the', 'processor', 'is', 'configured', 'to', 'control', 'the', 'digital', 'signage', 'to', 'provide', 'recommended', 'menu', 'information', 'differentiated', 'according', 'to', 'the', 'age', 'and', 'gender', 'the', 'apparatus', 'according', 'to', 'claim', 'wherein', 'the', 'processor', 'is', 'configured', 'to', 'determine', 'a', 'product', 'component', 'in', 'a', 'past', 'order', 'history', 'or', 'a', 'component', 'modified', 'from', 'the', 'product', 'component', 'as', 'the', 'product', 'order', 'the', 'apparatus', 'according', 'to', 'claim', 'wherein', 'the', 'processor', 'is', 'configured', 'to', 'pay', 'a', 'product', 'price', 'according', 'to', 'biometrics-based', 'authentication', 'through', 'a', 'communication', 'system', 'of', 'a', 'vehicle', 'or', 'a', 'mobile', 'terminal', 'the', 'apparatus', 'according', 'to', 'claim', 'wherein', 'the', 'processor', 'is', 'configured', 'to', 'issue', 'a', 'payment', 'number', 'for', 'a', 'divided', 'payment', 'and', 'perform', 'the', 'divided', 'payments', 'according', 'to', 'requests', 'of', 'a', 'plurality', 'of', 'mobile', 'terminals', 'to', 'which', 'the', 'payment', 'numbers', 'are', 'inputted', 'the', 'apparatus', 'according', 'to', 'claim', 'wherein', 'the', 'processor', 'is', 'configured', 'to', 'accumulate', 'mileage', 'in', 'an', 'account', 'corresponding', 'to', 'the', 'mobile', 'terminal', 'undergoing', 'a', 'payment', 'the', 'apparatus', 'according', 'to', 'claim', 'wherein', 'the', 'processor', 'is', 'configured', 'to', 'control', 'the', 'digital', 'signage', 'to', 'suggest', 'a', 'takeout', 'packaging', 'method', 'according', 'to', 'a', 'temperature', 'of', 'a', 'product', 'an', 'atmospheric', 'temperature', 'weather', 'and', 'a', 'vehicle', 'type', 'an', 'image', 'information', 'processing', 'method', 'performed', 'at', 'a', 'computing', 'device', 'having', 'one', 'or', 'more', 'processors', 'and', 'memory', 'storing', 'a', 'plurality', 'of', 'programs', 'to', 'be', 'executed', 'by', 'the', 'one', 'or', 'more', 'processors', 'the', 'method', 'comprising', 'identifying', 'using', 'face', 'recognition', 'one', 'or', 'more', 'faces', 'each', 'face', 'corresponding', 'to', 'a', 'respective', 'person', 'captured', 'in', 'a', 'first', 'image', 'for', 'each', 'identified', 'face', 'extracting', 'a', 'set', 'of', 'profile', 'parameters', 'of', 'a', 'corresponding', 'person', 'in', 'the', 'first', 'image', 'and', 'selecting', 'from', 'a', 'plurality', 'of', 'image', 'tiles', 'a', 'first', 'image', 'tile', 'that', 'matches', 'the', 'face', 'of', 'the', 'corresponding', 'person', 'in', 'the', 'first', 'image', 'in', 'accordance', 'with', 'a', 'predefined', 'correspondence', 'between', 'the', 'set', 'of', 'profile', 'parameters', 'of', 'the', 'corresponding', 'person', 'and', 'a', 'set', 'of', 'pre-stored', 'description', 'parameters', 'of', 'the', 'first', 'image', 'tile', 'generating', 'a', 'second', 'image', 'by', 'covering', 'the', 'faces', 'of', 'respective', 'persons', 'in', 'the', 'first', 'image', 'with', 'their', 'corresponding', 'first', 'image', 'tiles', 'and', 'sharing', 'the', 'first', 'image', 'and', 'the', 'second', 'image', 'in', 'a', 'predefined', 'order', 'via', 'a', 'group', 'chat', 'session', 'the', 'method', 'of', 'claim', 'wherein', 'the', 'first', 'image', 'and', 'the', 'second', 'image', 'are', 'displayed', 'in', 'the', 'group', 'chat', 'session', 'one', 'image', 'at', 'a', 'time', 'such', 'that', 'one', 'of', 'the', 'two', 'images', 'is', 'replaced', 'by', 'the', 'other', 'of', 'the', 'two', 'images', 'periodically', 'the', 'method', 'of', 'claim', 'wherein', 'extracting', 'a', 'set', 'of', 'profile', 'parameters', 'of', 'a', 'corresponding', 'person', 'in', 'the', 'first', 'image', 'includes', 'determining', 'one', 'or', 'more', 'descriptive', 'labels', 'corresponding', 'to', 'the', 'identified', 'face', 'of', 'the', 'corresponding', 'person', 'using', 'a', 'first', 'machine', 'learning', 'model', 'wherein', 'the', 'first', 'machine', 'learning', 'model', 'is', 'trained', 'with', 'the', 'facial', 'images', 'and', 'corresponding', 'descriptive', 'labels', 'the', 'method', 'of', 'claim', 'wherein', 'extracting', 'a', 'set', 'of', 'profile', 'parameters', 'of', 'a', 'corresponding', 'person', 'in', 'the', 'first', 'image', 'includes', 'determining', 'an', 'identity', 'of', 'the', 'corresponding', 'person', 'based', 'on', 'the', 'identified', 'face', 'of', 'the', 'corresponding', 'person', 'locating', 'respective', 'profile', 'information', 'of', 'the', 'first', 'person', 'based', 'on', 'the', 'determined', 'identity', 'of', 'the', 'corresponding', 'person', 'and', 'using', 'one', 'or', 'more', 'characteristics', 'in', 'the', 'respective', 'profile', 'information', 'of', 'the', 'first', 'person', 'as', 'the', 'set', 'of', 'profile', 'parameters', 'corresponding', 'to', 'the', 'identified', 'face', 'of', 'the', 'corresponding', 'person', 'the', 'method', 'of', 'claim', 'wherein', 'at', 'least', 'a', 'first', 'one', 'of', 'the', 'first', 'image', 'tiles', 'is', 'a', 'dynamic', 'image', 'tile', 'and', 'at', 'least', 'a', 'second', 'one', 'of', 'the', 'first', 'image', 'tiles', 'is', 'a', 'static', 'image', 'tile', 'the', 'method', 'of', 'claim', 'including', 'receiving', 'a', 'plurality', 'of', 'user', 'comments', 'from', 'different', 'users', 'of', 'the', 'group', 'chat', 'session', 'each', 'user', 'comment', 'including', 'a', 'descriptive', 'term', 'for', 'a', 'respective', 'person', 'identified', 'in', 'the', 'first', 'image', 'choosing', 'a', 'descriptive', 'label', 'for', 'the', 'respective', 'person', 'according', 'to', 'the', 'plurality', 'of', 'user', 'comments', 'and', 'updating', 'the', 'second', 'image', 'by', 'adding', 'the', 'descriptive', 'label', 'adjacent', 'to', 'the', 'first', 'image', 'tile', 'of', 'the', 'respective', 'person', 'a', 'computing', 'device', 'for', 'image', 'information', 'processing', 'comprising', 'one', 'or', 'more', 'processors', 'and', 'memory', 'storing', 'instructions', 'which', 'when', 'executed', 'by', 'the', 'one', 'or', 'more', 'processors', 'cause', 'the', 'processors', 'to', 'perform', 'a', 'plurality', 'of', 'operations', 'comprising', 'identifying', 'using', 'face', 'recognition', 'one', 'or', 'more', 'faces', 'each', 'face', 'corresponding', 'to', 'a', 'respective', 'person', 'captured', 'in', 'a', 'first', 'image', 'for', 'each', 'identified', 'face', 'extracting', 'a', 'set', 'of', 'profile', 'parameters', 'of', 'a', 'corresponding', 'person', 'in', 'the', 'first', 'image', 'and', 'selecting', 'from', 'a', 'plurality', 'of', 'image', 'tiles', 'a', 'first', 'image', 'tile', 'that', 'matches', 'the', 'face', 'of', 'the', 'corresponding', 'person', 'in', 'the', 'first', 'image', 'in', 'accordance', 'with', 'a', 'predefined', 'correspondence', 'between', 'the', 'set', 'of', 'profile', 'parameters', 'of', 'the', 'corresponding', 'person', 'and', 'a', 'set', 'of', 'pre-stored', 'description', 'parameters', 'of', 'the', 'first', 'image', 'tile', 'generating', 'a', 'second', 'image', 'by', 'covering', 'the', 'faces', 'of', 'respective', 'persons', 'in', 'the', 'first', 'image', 'with', 'their', 'corresponding', 'first', 'image', 'tiles', 'and', 'sharing', 'the', 'first', 'image', 'and', 'the', 'second', 'image', 'in', 'a', 'predefined', 'order', 'via', 'a', 'group', 'chat', 'session', 'the', 'computing', 'device', 'of', 'claim', 'wherein', 'the', 'first', 'image', 'and', 'the', 'second', 'image', 'are', 'displayed', 'in', 'the', 'group', 'chat', 'session', 'one', 'image', 'at', 'a', 'time', 'such', 'that', 'one', 'of', 'the', 'two', 'images', 'is', 'replaced', 'by', 'the', 'other', 'of', 'the', 'two', 'images', 'periodically', 'the', 'computing', 'device', 'of', 'claim', 'wherein', 'extracting', 'a', 'set', 'of', 'profile', 'parameters', 'of', 'a', 'corresponding', 'person', 'in', 'the', 'first', 'image', 'includes', 'determining', 'one', 'or', 'more', 'descriptive', 'labels', 'corresponding', 'to', 'the', 'identified', 'face', 'of', 'the', 'corresponding', 'person', 'using', 'a', 'first', 'machine', 'learning', 'model', 'wherein', 'the', 'first', 'machine', 'learning', 'model', 'is', 'trained', 'with', 'the', 'facial', 'images', 'and', 'corresponding', 'descriptive', 'labels', 'the', 'computing', 'device', 'of', 'claim', 'wherein', 'extracting', 'a', 'set', 'of', 'profile', 'parameters', 'of', 'a', 'corresponding', 'person', 'in', 'the', 'first', 'image', 'includes', 'determining', 'an', 'identity', 'of', 'the', 'corresponding', 'person', 'based', 'on', 'the', 'identified', 'face', 'of', 'the', 'corresponding', 'person', 'locating', 'respective', 'profile', 'information', 'of', 'the', 'first', 'person', 'based', 'on', 'the', 'determined', 'identity', 'of', 'the', 'corresponding', 'person', 'and', 'using', 'one', 'or', 'more', 'characteristics', 'in', 'the', 'respective', 'profile', 'information', 'of', 'the', 'first', 'person', 'as', 'the', 'set', 'of', 'profile', 'parameters', 'corresponding', 'to', 'the', 'identified', 'face', 'of', 'the', 'corresponding', 'person', 'the', 'computing', 'device', 'of', 'claim', 'wherein', 'at', 'least', 'a', 'first', 'one', 'of', 'the', 'first', 'image', 'tiles', 'is', 'a', 'dynamic', 'image', 'tile', 'and', 'at', 'least', 'a', 'second', 'one', 'of', 'the', 'first', 'image', 'tiles', 'is', 'a', 'static', 'image', 'tile', 'the', 'computing', 'device', 'of', 'claim', 'wherein', 'the', 'plurality', 'of', 'operations', 'further', 'include', 'receiving', 'a', 'plurality', 'of', 'user', 'comments', 'from', 'different', 'users', 'of', 'the', 'group', 'chat', 'session', 'each', 'user', 'comment', 'including', 'a', 'descriptive', 'term', 'for', 'a', 'respective', 'person', 'identified', 'in', 'the', 'first', 'image', 'choosing', 'a', 'descriptive', 'label', 'for', 'the', 'respective', 'person', 'according', 'to', 'the', 'plurality', 'of', 'user', 'comments', 'and', 'updating', 'the', 'second', 'image', 'by', 'adding', 'the', 'descriptive', 'label', 'adjacent', 'to', 'the', 'first', 'image', 'tile', 'of', 'the', 'respective', 'person', 'a', 'non-transitory', 'computer-readable', 'storage', 'medium', 'storing', 'instructions', 'which', 'when', 'executed', 'by', 'a', 'computing', 'device', 'having', 'one', 'or', 'more', 'processors', 'cause', 'the', 'computing', 'device', 'to', 'perform', 'a', 'plurality', 'of', 'operations', 'comprising', 'identifying', 'using', 'face', 'recognition', 'one', 'or', 'more', 'faces', 'each', 'face', 'corresponding', 'to', 'a', 'respective', 'person', 'captured', 'in', 'a', 'first', 'image', 'for', 'each', 'identified', 'face', 'extracting', 'a', 'set', 'of', 'profile', 'parameters', 'of', 'a', 'corresponding', 'person', 'in', 'the', 'first', 'image', 'and', 'selecting', 'from', 'a', 'plurality', 'of', 'image', 'tiles', 'a', 'first', 'image', 'tile', 'that', 'matches', 'the', 'face', 'of', 'the', 'corresponding', 'person', 'in', 'the', 'first', 'image', 'in', 'accordance', 'with', 'a', 'predefined', 'correspondence', 'between', 'the', 'set', 'of', 'profile', 'parameters', 'of', 'the', 'corresponding', 'person', 'and', 'a', 'set', 'of', 'pre-stored', 'description', 'parameters', 'of', 'the', 'first', 'image', 'tile', 'generating', 'a', 'second', 'image', 'by', 'covering', 'the', 'faces', 'of', 'respective', 'persons', 'in', 'the', 'first', 'image', 'with', 'their', 'corresponding', 'first', 'image', 'tiles', 'and', 'sharing', 'the', 'first', 'image', 'and', 'the', 'second', 'image', 'in', 'a', 'predefined', 'order', 'via', 'a', 'group', 'chat', 'session', 'the', 'non-transitory', 'computer-readable', 'storage', 'medium', 'of', 'claim', 'wherein', 'the', 'first', 'image', 'and', 'the', 'second', 'image', 'are', 'displayed', 'in', 'the', 'group', 'chat', 'session', 'one', 'image', 'at', 'a', 'time', 'such', 'that', 'one', 'of', 'the', 'two', 'images', 'is', 'replaced', 'by', 'the', 'other', 'of', 'the', 'two', 'images', 'periodically', 'the', 'non-transitory', 'computer-readable', 'storage', 'medium', 'of', 'claim', 'wherein', 'extracting', 'a', 'set', 'of', 'profile', 'parameters', 'of', 'a', 'corresponding', 'person', 'in', 'the', 'first', 'image', 'includes', 'determining', 'one', 'or', 'more', 'descriptive', 'labels', 'corresponding', 'to', 'the', 'identified', 'face', 'of', 'the', 'corresponding', 'person', 'using', 'a', 'first', 'machine', 'learning', 'model', 'wherein', 'the', 'first', 'machine', 'learning', 'model', 'is', 'trained', 'with', 'the', 'facial', 'images', 'and', 'corresponding', 'descriptive', 'labels', 'the', 'non-transitory', 'computer-readable', 'storage', 'medium', 'of', 'claim', 'wherein', 'extracting', 'a', 'set', 'of', 'profile', 'parameters', 'of', 'a', 'corresponding', 'person', 'in', 'the', 'first', 'image', 'includes', 'determining', 'an', 'identity', 'of', 'the', 'corresponding', 'person', 'based', 'on', 'the', 'identified', 'face', 'of', 'the', 'corresponding', 'person', 'locating', 'respective', 'profile', 'information', 'of', 'the', 'first', 'person', 'based', 'on', 'the', 'determined', 'identity', 'of', 'the', 'corresponding', 'person', 'and', 'using', 'one', 'or', 'more', 'characteristics', 'in', 'the', 'respective', 'profile', 'information', 'of', 'the', 'first', 'person', 'as', 'the', 'set', 'of', 'profile', 'parameters', 'corresponding', 'to', 'the', 'identified', 'face', 'of', 'the', 'corresponding', 'person', 'the', 'non-transitory', 'computer-readable', 'storage', 'medium', 'of', 'claim', 'wherein', 'at', 'least', 'a', 'first', 'one', 'of', 'the', 'first', 'image', 'tiles', 'is', 'a', 'dynamic', 'image', 'tile', 'and', 'at', 'least', 'a', 'second', 'one', 'of', 'the', 'first', 'image', 'tiles', 'is', 'a', 'static', 'image', 'tile', 'the', 'non-transitory', 'computer-readable', 'storage', 'medium', 'of', 'claim', 'wherein', 'the', 'plurality', 'of', 'operations', 'further', 'include', 'receiving', 'a', 'plurality', 'of', 'user', 'comments', 'from', 'different', 'users', 'of', 'the', 'group', 'chat', 'session', 'each', 'user', 'comment', 'including', 'a', 'descriptive', 'term', 'for', 'a', 'respective', 'person', 'identified', 'in', 'the', 'first', 'image', 'choosing', 'a', 'descriptive', 'label', 'for', 'the', 'respective', 'person', 'according', 'to', 'the', 'plurality', 'of', 'user', 'comments', 'and', 'updating', 'the', 'second', 'image', 'by', 'adding', 'the', 'descriptive', 'label', 'adjacent', 'to', 'the', 'first', 'image', 'tile', 'of', 'the', 'respective', 'person', 'a', 'method', 'comprising', 'by', 'a', 'computing', 'system', 'determining', 'that', 'a', 'performance', 'metric', 'of', 'an', 'eye', 'tracking', 'system', 'is', 'below', 'a', 'first', 'performance', 'threshold', 'wherein', 'the', 'eye', 'tracking', 'system', 'is', 'associated', 'with', 'a', 'head-mounted', 'display', 'worn', 'by', 'a', 'user', 'based', 'on', 'the', 'determination', 'of', 'the', 'performance', 'metric', 'of', 'the', 'eye', 'tracking', 'system', 'being', 'below', 'the', 'first', 'performance', 'threshold', 'the', 'computer', 'system', 'performing', 'receiving', 'one', 'or', 'more', 'first', 'inputs', 'associated', 'with', 'a', 'body', 'of', 'the', 'user', 'estimating', 'a', 'region', 'that', 'the', 'user', 'is', 'looking', 'at', 'within', 'a', 'field', 'of', 'view', 'of', 'the', 'head-mounted', 'display', 'based', 'on', 'the', 'received', 'one', 'or', 'more', 'first', 'inputs', 'associated', 'with', 'the', 'body', 'of', 'the', 'user', 'determining', 'a', 'vergence', 'distance', 'of', 'the', 'user', 'based', 'at', 'least', 'on', 'the', 'one', 'or', 'more', 'first', 'inputs', 'associated', 'with', 'the', 'body', 'of', 'the', 'user', 'the', 'estimated', 'region', 'that', 'the', 'user', 'is', 'looking', 'at', 'and', 'locations', 'of', 'one', 'or', 'more', 'objects', 'in', 'a', 'scene', 'displayed', 'by', 'the', 'head-mounted', 'display', 'and', 'adjusting', 'one', 'or', 'more', 'configurations', 'of', 'the', 'head-mounted', 'display', 'based', 'on', 'the', 'determined', 'vergence', 'distance', 'of', 'the', 'user', 'the', 'method', 'of', 'claim', 'wherein', 'the', 'one', 'or', 'more', 'configurations', 'of', 'the', 'head-mounted', 'display', 'comprise', 'one', 'or', 'more', 'of', 'a', 'rendering', 'image', 'a', 'position', 'of', 'a', 'display', 'screen', 'or', 'a', 'position', 'of', 'an', 'optics', 'block', 'the', 'method', 'of', 'claim', 'further', 'comprising', 'determining', 'that', 'the', 'performance', 'metric', 'of', 'the', 'eye', 'tracking', 'system', 'is', 'above', 'a', 'second', 'performance', 'threshold', 'receiving', 'eye', 'tracking', 'data', 'from', 'the', 'eye', 'tracking', 'system', 'and', 'determining', 'the', 'vergence', 'distance', 'of', 'the', 'user', 'based', 'on', 'the', 'eye', 'tracking', 'data', 'and', 'the', 'one', 'or', 'more', 'first', 'inputs', 'associated', 'with', 'the', 'body', 'of', 'the', 'user', 'the', 'method', 'of', 'claim', 'further', 'comprising', 'receiving', 'one', 'or', 'more', 'second', 'inputs', 'associated', 'with', 'one', 'or', 'more', 'displaying', 'elements', 'in', 'the', 'scene', 'displayed', 'by', 'the', 'head-mounted', 'display', 'and', 'determining', 'the', 'vergence', 'distance', 'of', 'the', 'user', 'based', 'at', 'least', 'on', 'the', 'eye', 'tracking', 'data', 'the', 'one', 'or', 'more', 'first', 'inputs', 'associated', 'with', 'the', 'body', 'of', 'the', 'user', 'and', 'the', 'one', 'or', 'more', 'second', 'inputs', 'associated', 'with', 'the', 'one', 'or', 'more', 'displaying', 'elements', 'of', 'the', 'scene', 'the', 'method', 'of', 'claim', 'further', 'comprising', 'feeding', 'the', 'one', 'or', 'more', 'first', 'inputs', 'associated', 'with', 'the', 'body', 'of', 'the', 'user', 'to', 'a', 'fusion', 'algorithm', 'wherein', 'the', 'fusion', 'algorithm', 'assigns', 'a', 'weight', 'score', 'to', 'each', 'input', 'of', 'the', 'one', 'or', 'more', 'first', 'inputs', 'determining', 'the', 'vergence', 'distance', 'of', 'the', 'user', 'using', 'the', 'fusion', 'algorithm', 'based', 'on', 'the', 'one', 'or', 'more', 'first', 'inputs', 'associated', 'with', 'the', 'body', 'of', 'the', 'user', 'and', 'determining', 'a', 'z-depth', 'of', 'a', 'display', 'screen', 'and', 'a', 'confidence', 'score', 'based', 'on', 'the', 'one', 'or', 'more', 'first', 'inputs', 'associated', 'with', 'the', 'body', 'of', 'the', 'user', 'the', 'method', 'of', 'claim', 'further', 'comprising', 'comparing', 'the', 'confidence', 'score', 'to', 'a', 'confidence', 'level', 'threshold', 'in', 'response', 'to', 'a', 'determination', 'that', 'the', 'confidence', 'score', 'is', 'below', 'the', 'confidence', 'level', 'threshold', 'feeding', 'the', 'one', 'or', 'more', 'second', 'inputs', 'associated', 'with', 'the', 'one', 'or', 'more', 'displaying', 'elements', 'of', 'the', 'scene', 'to', 'the', 'fusion', 'algorithm', 'and', 'determining', 'the', 'z-depth', 'of', 'the', 'display', 'screen', 'using', 'the', 'fusion', 'algorithm', 'based', 'on', 'the', 'one', 'or', 'more', 'first', 'inputs', 'associated', 'with', 'the', 'body', 'of', 'the', 'user', 'and', 'the', 'one', 'or', 'more', 'second', 'inputs', 'associated', 'with', 'the', 'one', 'or', 'more', 'displaying', 'elements', 'of', 'the', 'scene', 'the', 'method', 'of', 'claim', 'further', 'comparing', 'comparing', 'by', 'the', 'fusion', 'algorithm', 'confidence', 'scores', 'associated', 'with', 'a', 'plurality', 'of', 'combinations', 'of', 'inputs', 'and', 'determining', 'by', 'the', 'fusion', 'algorithm', 'the', 'z-depth', 'of', 'the', 'display', 'screen', 'based', 'on', 'a', 'combination', 'of', 'inputs', 'associated', 'with', 'a', 'highest', 'confidence', 'score', 'the', 'method', 'of', 'claim', 'wherein', 'the', 'z-depth', 'and', 'the', 'confidence', 'score', 'are', 'determined', 'by', 'the', 'fusion', 'algorithm', 'using', 'a', 'piecewise', 'comparison', 'of', 'the', 'one', 'or', 'more', 'first', 'inputs', 'and', 'the', 'one', 'or', 'more', 'second', 'inputs', 'the', 'method', 'of', 'claim', 'wherein', 'the', 'z-depth', 'and', 'the', 'confidence', 'score', 'are', 'determined', 'based', 'on', 'a', 'correlation', 'between', 'two', 'or', 'more', 'inputs', 'of', 'the', 'one', 'or', 'more', 'first', 'inputs', 'and', 'the', 'one', 'or', 'more', 'second', 'inputs', 'the', 'method', 'of', 'claim', 'wherein', 'the', 'fusion', 'algorithm', 'comprises', 'a', 'machine', 'learning', 'ml', 'algorithm', 'and', 'wherein', 'the', 'machine', 'learning', 'ml', 'algorithm', 'determines', 'a', 'combination', 'of', 'first', 'inputs', 'fed', 'to', 'the', 'fusion', 'algorithm', 'the', 'method', 'of', 'claim', 'wherein', 'the', 'one', 'or', 'more', 'first', 'inputs', 'associated', 'with', 'the', 'body', 'of', 'the', 'user', 'comprise', 'one', 'or', 'more', 'of', 'a', 'hand', 'position', 'a', 'hand', 'direction', 'a', 'hand', 'movement', 'a', 'hand', 'gesture', 'a', 'head', 'position', 'a', 'head', 'direction', 'a', 'head', 'movement', 'a', 'head', 'gesture', 'a', 'gaze', 'angle', 'rea', 'body', 'gesture', 'a', 'body', 'posture', 'a', 'body', 'movement', 'a', 'behavior', 'of', 'the', 'user', 'or', 'a', 'weighted', 'combination', 'of', 'one', 'or', 'more', 'related', 'parameters', 'the', 'method', 'of', 'claim', 'wherein', 'the', 'one', 'or', 'more', 'first', 'inputs', 'associated', 'with', 'the', 'body', 'of', 'the', 'user', 'are', 'received', 'from', 'one', 'or', 'more', 'of', 'a', 'controller', 'a', 'sensor', 'a', 'camera', 'a', 'microphone', 'an', 'accelerometer', 'a', 'headset', 'worn', 'by', 'the', 'user', 'or', 'a', 'mobile', 'device', 'the', 'method', 'of', 'claim', 'wherein', 'the', 'one', 'or', 'more', 'second', 'inputs', 'associated', 'with', 'the', 'one', 'or', 'more', 'displaying', 'elements', 'comprise', 'one', 'or', 'more', 'of', 'a', 'z-buffer', 'value', 'associated', 'with', 'a', 'displaying', 'element', 'a', 'displaying', 'element', 'marked', 'by', 'a', 'developer', 'an', 'image', 'analysis', 'result', 'a', 'shape', 'of', 'a', 'displaying', 'element', 'a', 'face', 'recognition', 'result', 'an', 'object', 'recognition', 'result', 'a', 'person', 'identified', 'in', 'a', 'displaying', 'content', 'an', 'object', 'identified', 'in', 'a', 'displaying', 'content', 'a', 'correlation', 'of', 'two', 'or', 'more', 'displaying', 'elements', 'or', 'a', 'weighted', 'combination', 'of', 'the', 'one', 'or', 'more', 'second', 'inputs', 'the', 'method', 'of', 'claim', 'further', 'comprising', 'determining', 'that', 'the', 'performance', 'metric', 'of', 'the', 'eye', 'tracking', 'system', 'is', 'below', 'a', 'second', 'performance', 'threshold', 'receiving', 'one', 'or', 'more', 'second', 'inputs', 'associated', 'with', 'one', 'or', 'more', 'displaying', 'elements', 'in', 'the', 'scene', 'displayed', 'by', 'the', 'head-mounted', 'display', 'and', 'determining', 'the', 'vergence', 'distance', 'of', 'the', 'user', 'based', 'at', 'least', 'on', 'the', 'one', 'or', 'more', 'first', 'inputs', 'associated', 'with', 'the', 'body', 'of', 'the', 'user', 'and', 'the', 'one', 'or', 'more', 'second', 'inputs', 'associated', 'with', 'the', 'one', 'or', 'more', 'displaying', 'elements', 'the', 'method', 'of', 'claim', 'wherein', 'determining', 'that', 'the', 'performance', 'metric', 'of', 'the', 'eye', 'tracking', 'system', 'is', 'below', 'the', 'second', 'performance', 'threshold', 'comprises', 'determining', 'that', 'the', 'eye', 'tracking', 'system', 'does', 'not', 'exist', 'or', 'fails', 'to', 'provide', 'eye', 'tracking', 'data', 'the', 'method', 'of', 'claim', 'wherein', 'the', 'performance', 'metric', 'of', 'the', 'eye', 'tracking', 'system', 'comprises', 'one', 'or', 'more', 'of', 'an', 'accuracy', 'of', 'a', 'parameter', 'from', 'the', 'eye', 'tracking', 'system', 'a', 'precision', 'of', 'a', 'parameter', 'from', 'the', 'eye', 'tracking', 'system', 'a', 'value', 'of', 'a', 'parameter', 'from', 'the', 'eye', 'tracking', 'system', 'a', 'detectability', 'of', 'a', 'pupil', 'a', 'metric', 'based', 'on', 'one', 'or', 'more', 'parameters', 'associated', 'with', 'the', 'user', 'a', 'parameter', 'change', 'a', 'parameter', 'changing', 'trend', 'a', 'data', 'availability', 'or', 'a', 'weighted', 'combination', 'of', 'one', 'or', 'more', 'performance', 'related', 'parameters', 'the', 'method', 'of', 'claim', 'wherein', 'the', 'one', 'or', 'more', 'parameters', 'associated', 'with', 'the', 'user', 'comprise', 'one', 'or', 'more', 'of', 'an', 'eye', 'distance', 'of', 'the', 'user', 'a', 'pupil', 'position', 'a', 'pupil', 'status', 'a', 'correlation', 'of', 'two', 'pupils', 'of', 'the', 'user', 'a', 'head', 'size', 'of', 'the', 'user', 'a', 'position', 'of', 'a', 'headset', 'worn', 'by', 'the', 'user', 'an', 'angle', 'of', 'the', 'headset', 'worn', 'by', 'the', 'user', 'a', 'direction', 'of', 'the', 'headset', 'worn', 'by', 'the', 'user', 'an', 'alignment', 'of', 'the', 'eyes', 'of', 'the', 'user', 'or', 'a', 'weighted', 'combination', 'of', 'one', 'or', 'more', 'related', 'parameters', 'associated', 'with', 'the', 'user', 'the', 'method', 'of', 'claim', 'wherein', 'the', 'first', 'performance', 'threshold', 'comprises', 'one', 'or', 'more', 'of', 'a', 'pre-determined', 'value', 'a', 'pre-determined', 'range', 'a', 'state', 'of', 'a', 'data', 'a', 'changing', 'speed', 'of', 'a', 'data', 'or', 'a', 'trend', 'of', 'a', 'data', 'change', 'one', 'or', 'more', 'non-transitory', 'computer-readable', 'storage', 'media', 'embodying', 'software', 'that', 'is', 'operable', 'when', 'executed', 'by', 'a', 'computing', 'system', 'to', 'determine', 'that', 'a', 'performance', 'metric', 'of', 'an', 'eye', 'tracking', 'system', 'is', 'below', 'a', 'first', 'performance', 'threshold', 'wherein', 'the', 'eye', 'tracking', 'system', 'is', 'associated', 'with', 'a', 'head-mounted', 'display', 'worn', 'by', 'a', 'user', 'based', 'on', 'the', 'determination', 'of', 'the', 'performance', 'metric', 'of', 'the', 'eye', 'tracking', 'system', 'being', 'below', 'the', 'first', 'performance', 'threshold', 'the', 'media', 'embodying', 'software', 'operable', 'when', 'executed', 'by', 'the', 'computing', 'system', 'to', 'receive', 'one', 'or', 'more', 'first', 'inputs', 'associated', 'with', 'a', 'body', 'of', 'the', 'user', 'estimate', 'a', 'region', 'that', 'the', 'user', 'is', 'looking', 'at', 'within', 'a', 'field', 'of', 'view', 'of', 'the', 'head-mounted', 'display', 'based', 'on', 'the', 'received', 'one', 'or', 'more', 'first', 'inputs', 'associated', 'with', 'the', 'body', 'of', 'the', 'user', 'determine', 'a', 'vergence', 'distance', 'of', 'the', 'user', 'based', 'at', 'least', 'on', 'the', 'one', 'or', 'more', 'first', 'inputs', 'associated', 'with', 'the', 'body', 'of', 'the', 'user', 'the', 'estimated', 'region', 'that', 'the', 'user', 'is', 'looking', 'at', 'and', 'locations', 'of', 'one', 'or', 'more', 'objects', 'in', 'a', 'scene', 'displayed', 'by', 'the', 'head-mounted', 'display', 'and', 'adjust', 'one', 'or', 'more', 'configurations', 'of', 'the', 'head-mounted', 'display', 'based', 'on', 'the', 'determined', 'vergence', 'distance', 'of', 'the', 'user', 'a', 'system', 'comprising', 'one', 'or', 'more', 'non-transitory', 'computer-readable', 'storage', 'media', 'embodying', 'instructions', 'one', 'or', 'more', 'processors', 'coupled', 'to', 'the', 'storage', 'media', 'and', 'operable', 'to', 'execute', 'the', 'instructions', 'to', 'determine', 'that', 'a', 'performance', 'metric', 'of', 'an', 'eye', 'tracking', 'system', 'is', 'below', 'a', 'first', 'performance', 'threshold', 'wherein', 'the', 'eye', 'tracking', 'system', 'is', 'associated', 'with', 'a', 'head-mounted', 'display', 'worn', 'by', 'a', 'user', 'based', 'on', 'the', 'determination', 'of', 'the', 'performance', 'metric', 'of', 'the', 'eye', 'tracking', 'system', 'being', 'below', 'the', 'first', 'performance', 'threshold', 'the', 'system', 'is', 'configured', 'to', 'receive', 'one', 'or', 'more', 'first', 'inputs', 'associated', 'with', 'a', 'body', 'of', 'the', 'user', 'estimate', 'a', 'region', 'that', 'the', 'user', 'is', 'looking', 'at', 'within', 'a', 'field', 'of', 'view', 'of', 'the', 'head-mounted', 'display', 'based', 'on', 'the', 'received', 'one', 'or', 'more', 'first', 'inputs', 'associated', 'with', 'the', 'body', 'of', 'the', 'user', 'determine', 'a', 'vergence', 'distance', 'of', 'the', 'user', 'based', 'at', 'least', 'on', 'the', 'one', 'or', 'more', 'first', 'inputs', 'associated', 'with', 'the', 'body', 'of', 'the', 'user', 'the', 'estimated', 'region', 'that', 'the', 'user', 'is', 'looking', 'at', 'and', 'locations', 'of', 'one', 'or', 'more', 'objects', 'in', 'a', 'scene', 'displayed', 'by', 'the', 'head-mounted', 'display', 'and', 'adjust', 'one', 'or', 'more', 'configurations', 'of', 'the', 'head-mounted', 'display', 'based', 'on', 'the', 'determined', 'vergence', 'distance', 'of', 'the', 'user', 'a', 'computer-implemented', 'method', 'for', 'image-based', 'self-guided', 'object', 'detection', 'comprising', 'receiving', 'by', 'a', 'processor', 'device', 'a', 'set', 'of', 'images', 'each', 'of', 'the', 'images', 'having', 'a', 'respective', 'grid', 'thereon', 'that', 'is', 'labeled', 'regarding', 'a', 'respective', 'object', 'to', 'be', 'detected', 'using', 'grid', 'level', 'label', 'data', 'training', 'by', 'the', 'processor', 'device', 'a', 'grid-based', 'object', 'detector', 'using', 'the', 'grid', 'level', 'label', 'data', 'determining', 'by', 'the', 'processor', 'device', 'a', 'respective', 'bounding', 'box', 'for', 'the', 'respective', 'object', 'in', 'each', 'of', 'the', 'images', 'by', 'applying', 'local', 'segmentation', 'to', 'each', 'of', 'the', 'images', 'and', 'training', 'by', 'the', 'processor', 'device', 'a', 'region-based', 'convolutional', 'neural', 'network', 'rcnn', 'for', 'joint', 'object', 'localization', 'and', 'object', 'classification', 'using', 'the', 'respective', 'bounding', 'box', 'for', 'the', 'respective', 'object', 'in', 'each', 'of', 'the', 'images', 'as', 'an', 'input', 'to', 'the', 'rcnn', 'the', 'computer-implemented', 'method', 'of', 'claim', 'further', 'comprising', 'performing', 'an', 'action', 'responsive', 'to', 'the', 'object', 'localization', 'and', 'object', 'classification', 'for', 'a', 'respective', 'new', 'object', 'in', 'a', 'new', 'image', 'to', 'which', 'the', 'rcnn', 'is', 'applied', 'the', 'computer-implemented', 'method', 'of', 'claim', 'wherein', 'the', 'action', 'comprises', 'autonomously', 'controlling', 'a', 'motor', 'vehicle', 'to', 'avoid', 'a', 'collision', 'with', 'the', 'new', 'object', 'responsive', 'to', 'the', 'object', 'localization', 'and', 'object', 'classification', 'for', 'the', 'respective', 'new', 'object', 'the', 'computer-implemented', 'method', 'of', 'claim', 'wherein', 'the', 'local', 'segmentation', 'is', 'performed', 'using', 'a', 'self-similarity', 'search', 'and', 'template', 'matching', 'to', 'provide', 'the', 'respective', 'bounding', 'box', 'around', 'the', 'respective', 'object', 'in', 'the', 'set', 'of', 'images', 'the', 'computer-implemented', 'method', 'of', 'claim', 'wherein', 'the', 'local', 'segmentation', 'is', 'applied', 'to', 'each', 'of', 'the', 'images', 'to', 'segment', 'a', 'respective', 'target', 'region', 'therein', 'the', 'computer-implemented', 'method', 'of', 'claim', 'wherein', 'the', 'region-based', 'convolutional', 'neural', 'network', 'rcnn', 'forms', 'a', 'model', 'during', 'an', 'object', 'training', 'stage', 'that', 'is', 'to', 'detect', 'objects', 'in', 'new', 'images', 'during', 'an', 'inference', 'stage', 'the', 'computer-implemented', 'method', 'of', 'claim', 'wherein', 'the', 'method', 'is', 'performed', 'by', 'a', 'system', 'selected', 'from', 'the', 'group', 'consisting', 'of', 'a', 'surveillance', 'system', 'a', 'face', 'detection', 'system', 'a', 'face', 'recognition', 'system', 'a', 'cancer', 'detection', 'system', 'an', 'object', 'tracking', 'system', 'and', 'an', 'advanced', 'driver-assistance', 'system', 'a', 'computer', 'program', 'product', 'for', 'image-based', 'self-guided', 'object', 'detection', 'the', 'computer', 'program', 'product', 'comprising', 'a', 'non-transitory', 'computer', 'readable', 'storage', 'medium', 'having', 'program', 'instructions', 'embodied', 'therewith', 'the', 'program', 'instructions', 'executable', 'by', 'a', 'computer', 'to', 'cause', 'the', 'computer', 'to', 'perform', 'a', 'method', 'comprising', 'receiving', 'by', 'a', 'processor', 'device', 'a', 'set', 'of', 'images', 'each', 'of', 'the', 'images', 'having', 'a', 'respective', 'grid', 'thereon', 'that', 'is', 'labeled', 'regarding', 'a', 'respective', 'object', 'to', 'be', 'detected', 'using', 'grid', 'level', 'label', 'data', 'training', 'by', 'the', 'processor', 'device', 'a', 'grid-based', 'object', 'detector', 'using', 'the', 'grid', 'level', 'label', 'data', 'determining', 'by', 'the', 'processor', 'device', 'a', 'respective', 'bounding', 'box', 'for', 'the', 'respective', 'object', 'in', 'each', 'of', 'the', 'images', 'by', 'applying', 'local', 'segmentation', 'to', 'each', 'of', 'the', 'images', 'and', 'training', 'by', 'the', 'processor', 'device', 'a', 'region-based', 'convolutional', 'neural', 'network', 'rcnn', 'for', 'joint', 'object', 'localization', 'and', 'object', 'classification', 'using', 'the', 'respective', 'bounding', 'box', 'for', 'the', 'respective', 'object', 'in', 'each', 'of', 'the', 'images', 'as', 'an', 'input', 'to', 'the', 'rcnn', 'the', 'computer', 'program', 'product', 'of', 'claim', 'wherein', 'the', 'method', 'further', 'comprises', 'performing', 'an', 'action', 'responsive', 'to', 'the', 'object', 'localization', 'and', 'object', 'classification', 'for', 'a', 'respective', 'new', 'object', 'in', 'a', 'new', 'image', 'to', 'which', 'the', 'rcnn', 'is', 'applied', 'the', 'computer', 'program', 'product', 'of', 'claim', 'wherein', 'the', 'action', 'comprises', 'autonomously', 'controlling', 'a', 'motor', 'vehicle', 'to', 'avoid', 'a', 'collision', 'with', 'the', 'new', 'object', 'responsive', 'to', 'the', 'object', 'localization', 'and', 'object', 'classification', 'for', 'the', 'respective', 'new', 'object', 'the', 'computer', 'program', 'product', 'of', 'claim', 'wherein', 'the', 'local', 'segmentation', 'is', 'performed', 'using', 'a', 'self-similarity', 'search', 'and', 'template', 'matching', 'to', 'provide', 'the', 'respective', 'bounding', 'box', 'around', 'the', 'respective', 'object', 'in', 'the', 'set', 'of', 'images', 'the', 'computer', 'program', 'product', 'of', 'claim', 'wherein', 'the', 'local', 'segmentation', 'is', 'applied', 'to', 'each', 'of', 'the', 'images', 'to', 'segment', 'a', 'respective', 'target', 'region', 'therein', 'the', 'computer', 'program', 'product', 'of', 'claim', 'wherein', 'the', 'region-based', 'convolutional', 'neural', 'network', 'rcnn', 'forms', 'a', 'model', 'during', 'an', 'object', 'training', 'stage', 'that', 'is', 'to', 'detect', 'objects', 'in', 'new', 'images', 'during', 'an', 'inference', 'stage', 'the', 'computer', 'program', 'product', 'of', 'claim', 'wherein', 'the', 'method', 'is', 'performed', 'by', 'a', 'system', 'selected', 'from', 'the', 'group', 'consisting', 'of', 'a', 'surveillance', 'system', 'a', 'face', 'detection', 'system', 'a', 'face', 'recognition', 'system', 'a', 'cancer', 'detection', 'system', 'an', 'object', 'tracking', 'system', 'and', 'an', 'advanced', 'driver-assistance', 'system', 'a', 'computer', 'processing', 'system', 'for', 'image-based', 'self-guided', 'object', 'detection', 'comprising', 'a', 'memory', 'device', 'for', 'storing', 'program', 'code', 'and', 'a', 'processor', 'device', 'for', 'running', 'the', 'program', 'code', 'to', 'receive', 'a', 'set', 'of', 'images', 'each', 'of', 'the', 'images', 'having', 'a', 'respective', 'grid', 'thereon', 'that', 'is', 'labeled', 'regarding', 'a', 'respective', 'object', 'to', 'be', 'detected', 'using', 'grid', 'level', 'label', 'data', 'train', 'a', 'grid-based', 'object', 'detector', 'using', 'the', 'grid', 'level', 'label', 'data', 'determine', 'a', 'respective', 'bounding', 'box', 'for', 'the', 'respective', 'object', 'in', 'each', 'of', 'the', 'images', 'by', 'applying', 'local', 'segmentation', 'to', 'each', 'of', 'the', 'images', 'and', 'train', 'a', 'region-based', 'convolutional', 'neural', 'network', 'rcnn', 'for', 'joint', 'object', 'localization', 'and', 'object', 'classification', 'using', 'the', 'respective', 'bounding', 'box', 'for', 'the', 'respective', 'object', 'in', 'each', 'of', 'the', 'images', 'as', 'an', 'input', 'to', 'the', 'rcnn', 'the', 'computer', 'processing', 'system', 'of', 'claim', 'wherein', 'the', 'processor', 'device', 'further', 'runs', 'the', 'program', 'code', 'to', 'perform', 'an', 'action', 'responsive', 'to', 'the', 'object', 'localization', 'and', 'object', 'classification', 'for', 'a', 'respective', 'new', 'object', 'in', 'a', 'new', 'image', 'to', 'which', 'the', 'rcnn', 'is', 'applied', 'the', 'computer', 'processing', 'system', 'of', 'claim', 'wherein', 'the', 'action', 'comprises', 'autonomously', 'controlling', 'a', 'motor', 'vehicle', 'to', 'avoid', 'a', 'collision', 'with', 'the', 'new', 'object', 'responsive', 'to', 'the', 'object', 'localization', 'and', 'object', 'classification', 'for', 'the', 'respective', 'new', 'object', 'the', 'computer', 'processing', 'system', 'of', 'claim', 'wherein', 'the', 'local', 'segmentation', 'is', 'performed', 'using', 'a', 'self-similarity', 'search', 'and', 'template', 'matching', 'to', 'provide', 'the', 'respective', 'bounding', 'box', 'around', 'the', 'respective', 'object', 'in', 'the', 'set', 'of', 'images', 'the', 'computer', 'processing', 'system', 'of', 'claim', 'wherein', 'the', 'region-based', 'convolutional', 'neural', 'network', 'rcnn', 'forms', 'a', 'model', 'during', 'an', 'object', 'training', 'stage', 'that', 'is', 'to', 'detect', 'objects', 'in', 'new', 'images', 'during', 'an', 'inference', 'stage', 'the', 'computer', 'processing', 'system', 'of', 'claim', 'wherein', 'the', 'computer', 'processing', 'system', 'is', 'comprised', 'in', 'a', 'system', 'selected', 'from', 'the', 'group', 'consisting', 'of', 'a', 'surveillance', 'system', 'a', 'face', 'detection', 'system', 'a', 'face', 'recognition', 'system', 'a', 'cancer', 'detection', 'system', 'an', 'object', 'tracking', 'system', 'and', 'an', 'advanced', 'driver-assistance', 'system', 'a', 'method', 'of', 'scalable', 'parallel', 'cloud-based', 'face', 'recognition', 'utilizing', 'a', 'database', 'of', 'normalized', 'stored', 'images', 'comprising', 'capturing', 'an', 'image', 'using', 'a', 'camera', 'detecting', 'a', 'face', 'in', 'the', 'captured', 'image', 'normalizing', 'the', 'detected', 'facial', 'image', 'to', 'match', 'the', 'normalized', 'stored', 'images', 'identifying', 'facial', 'features', 'in', 'the', 'normalized', 'detected', 'facial', 'image', 'generating', 'a', 'plurality', 'of', 'facial', 'metrics', 'from', 'the', 'facial', 'features', 'calculating', 'euclidean', 'distances', 'between', 'the', 'facial', 'metrics', 'of', 'the', 'normalized', 'detected', 'facial', 'image', 'with', 'corresponding', 'facial', 'metrics', 'of', 'each', 'of', 'the', 'stored', 'images', 'comparing', 'each', 'euclidean', 'distance', 'against', 'a', 'predetermined', 'threshold', 'responsive', 'to', 'the', 'euclidean', 'distance', 'comparison', 'producing', 'a', 'reduced', 'candidate', 'list', 'of', 'best', 'possible', 'image', 'matches', 'from', 'the', 'normalized', 'stored', 'images', 'comparing', 'in', 'parallel', 'the', 'normalized', 'detected', 'facial', 'image', 'with', 'each', 'of', 'the', 'normalized', 'stored', 'images', 'of', 'the', 'reduced', 'candidate', 'list', 'utilizing', 'a', 'plurality', 'of', 'face', 'recognition', 'algorithms', 'where', 'each', 'processor', 'of', 'a', 'parallel', 'processing', 'system', 'uses', 'a', 'different', 'face', 'recognition', 'algorithm', 'responsive', 'to', 'the', 'comparison', 'producing', 'best', 'match', 'results', 'from', 'each', 'parallel', 'subset', 'of', 'the', 'reduced', 'candidate', 'list', 'and', 'selecting', 'a', 'final', 'match', 'from', 'the', 'best', 'match', 'results', 'using', 'a', 'deep', 'learning', 'neural', 'network', 'face', 'recognition', 'algorithm', 'trained', 'on', 'outputs', 'of', 'individual', 'face', 'recognition', 'algorithms', 'the', 'method', 'of', 'scalable', 'parallel', 'cloud-based', 'face', 'recognition', 'of', 'claim', 'wherein', 'detecting', 'a', 'face', 'in', 'the', 'captured', 'image', 'comprises', 'utilizing', 'opencv', 'to', 'detect', 'a', 'face', 'in', 'the', 'captured', 'image', 'extracting', 'the', 'location', 'of', 'the', 'eyes', 'and', 'a', 'tip', 'of', 'the', 'nose', 'in', 'the', 'face', 'determining', 'a', 'distance', 'between', 'the', 'eyes', 'cropping', 'the', 'face', 'from', 'the', 'captured', 'image', 'where', 'the', 'width', 'and', 'the', 'height', 'of', 'a', 'cropped', 'face', 'image', 'is', 'a', 'function', 'of', 'the', 'distance', 'between', 'the', 'eyes', 'and', 'rotating', 'the', 'face', 'by', 'an', 'angle', 'of', 'rotation', 'that', 'is', 'a', 'function', 'of', 'the', 'distance', 'between', 'the', 'eyes', 'the', 'method', 'of', 'scalable', 'parallel', 'cloud-based', 'face', 'recognition', 'of', 'claim', 'wherein', 'the', 'width', 'of', 'the', 'cropped', 'face', 'image', 'is', 'times', 'the', 'distance', 'between', 'the', 'eyes', 'the', 'height', 'of', 'the', 'cropped', 'face', 'image', 'is', 'times', 'the', 'distance', 'between', 'the', 'eyes', 'and', 'the', 'angle', 'of', 'rotation', 'is', 'an', 'angle', 'formed', 'by', 'a', 'straight', 'line', 'joining', 'the', 'eyes', 'and', 'an', 'x-axis', 'of', 'the', 'face', 'the', 'method', 'of', 'scalable', 'parallel', 'cloud-based', 'face', 'recognition', 'of', 'claim', 'wherein', 'rotating', 'the', 'face', 'comprises', 'rotating', 'the', 'face', 'to', 'provide', 'a', 'frontal', 'face', 'pattern', 'the', 'method', 'of', 'scalable', 'parallel', 'cloud-based', 'face', 'recognition', 'of', 'claim', 'further', 'comprising', 'the', 'step', 'of', 'proportionally', 'rescaling', 'the', 'cropped', 'and', 'rotated', 'image', 'the', 'method', 'of', 'scalable', 'parallel', 'cloud-based', 'face', 'recognition', 'of', 'claim', 'where', 'the', 'proportional', 'rescaling', 'yields', 'a', 'cropped', 'and', 'rotated', 'image', 'with', 'a', 'size', 'of', '=', 'pixels', 'the', 'method', 'of', 'scalable', 'parallel', 'cloud-based', 'face', 'recognition', 'of', 'claim', 'wherein', 'the', 'facial', 'features', 'identified', 'in', 'the', 'normalized', 'detected', 'facial', 'image', 'comprise', 'a', 'pair', 'of', 'eyes', 'a', 'tip', 'of', 'a', 'nose', 'a', 'mouth', 'a', 'center', 'of', 'the', 'mouth', 'and', 'a', 'chin', 'area', 'comprising', 'a', 'bottom', 'a', 'top', 'left', 'landmark', 'and', 'a', 'top', 'right', 'landmark', 'the', 'method', 'of', 'scalable', 'parallel', 'cloud-based', 'face', 'recognition', 'of', 'claim', 'wherein', 'generating', 'a', 'plurality', 'of', 'facial', 'metrics', 'comprises', 'calculating', 'a', 'distance', 'between', 'the', 'pair', 'of', 'eyes', 'a', 'distance', 'between', 'the', 'eyes', 'and', 'the', 'tip', 'of', 'the', 'nose', 'a', 'distance', 'equal', 'to', 'the', 'width', 'of', 'the', 'mouth', 'a', 'distance', 'between', 'the', 'tip', 'of', 'the', 'nose', 'and', 'the', 'center', 'of', 'mouth', 'a', 'distance', 'between', 'the', 'bottom', 'of', 'chin', 'and', 'the', 'center', 'of', 'mouth', 'a', 'distance', 'between', 'the', 'top', 'left', 'landmark', 'on', 'the', 'chin', 'and', 'the', 'tip', 'of', 'the', 'nose', 'and', 'a', 'distance', 'between', 'the', 'top', 'right', 'landmark', 'on', 'the', 'chin', 'and', 'the', 'tip', 'of', 'the', 'nose', 'the', 'method', 'of', 'scalable', 'parallel', 'cloud-based', 'face', 'recognition', 'of', 'claim', 'wherein', 'performing', 'a', 'euclidean', 'distance', 'match', 'further', 'comprises', 'partitioning', 'the', 'normalized', 'stored', 'images', 'into', 'a', 'plurality', 'of', 'substantially', 'equal', 'subsets', 'performing', 'a', 'euclidean', 'distance', 'match', 'between', 'the', 'facial', 'metrics', 'of', 'the', 'normalized', 'detected', 'facial', 'image', 'and', 'corresponding', 'facial', 'metrics', 'of', 'each', 'of', 'the', 'stored', 'images', 'of', 'the', 'subsets', 'of', 'the', 'normalized', 'stored', 'images', 'with', 'a', 'separate', 'processor', 'of', 'a', 'parallel', 'processing', 'system', 'to', 'generate', 'a', 'euclidean', 'distance', 'for', 'each', 'stored', 'image', 'of', 'the', 'subset', 'comparing', 'each', 'euclidean', 'distance', 'against', 'a', 'predetermined', 'threshold', 'with', 'the', 'separate', 'processors', 'responsive', 'to', 'the', 'euclidean', 'distance', 'comparison', 'producing', 'a', 'reduced', 'candidate', 'list', 'of', 'best', 'possible', 'image', 'matches', 'from', 'the', 'normalized', 'stored', 'images', 'of', 'each', 'subset', 'and', 'combining', 'the', 'reduced', 'candidate', 'lists', 'from', 'each', 'subset', 'to', 'produce', 'a', 'single', 'reduced', 'candidate', 'list', 'the', 'method', 'of', 'scalable', 'parallel', 'cloud-based', 'face', 'recognition', 'of', 'claim', 'wherein', 'the', 'plurality', 'of', 'face', 'recognition', 'algorithms', 'utilized', 'in', 'comparing', 'in', 'parallel', 'the', 'normalized', 'detected', 'facial', 'image', 'with', 'each', 'of', 'the', 'normalized', 'stored', 'images', 'of', 'the', 'reduced', 'candidate', 'list', 'consists', 'of', 'face', 'recognition', 'algorithms', 'selected', 'from', 'a', 'group', 'consisting', 'of', 'principle', 'component', 'analysis', 'pca-based', 'algorithms', 'linear', 'discriminant', 'analysis', 'lda', 'algorithms', 'independent', 'component', 'analysis', 'ica', 'algorithms', 'kernel-based', 'algorithms', 'feature-based', 'techniques', 'algorithms', 'based', 'on', 'neural', 'networks', 'algorithms', 'based', 'on', 'transforms', 'and', 'model-based', 'face', 'recognition', 'algorithms', 'the', 'method', 'of', 'scalable', 'parallel', 'cloud-based', 'face', 'recognition', 'of', 'claim', 'wherein', 'the', 'pca-based', 'algorithms', 'include', 'eigenfaces', 'for', 'face', 'detectionrecognition', 'and', 'the', 'lda', 'algorithms', 'include', 'the', 'fisherfaces', 'method', 'of', 'face', 'recognition', 'the', 'method', 'of', 'scalable', 'parallel', 'cloud-based', 'face', 'recognition', 'of', 'claim', 'wherein', 'comparing', 'in', 'parallel', 'the', 'captured', 'image', 'with', 'each', 'of', 'the', 'normalized', 'stored', 'images', 'of', 'the', 'reduced', 'candidate', 'list', 'further', 'comprises', 'partitioning', 'the', 'reduced', 'candidate', 'list', 'into', 'a', 'plurality', 'of', 'substantially', 'equal', 'subsets', 'processing', 'each', 'subset', 'in', 'a', 'different', 'processor', 'of', 'the', 'parallel', 'processing', 'system', 'uses', 'a', 'unique', 'face', 'recognition', 'algorithm', 'to', 'produce', 'the', 'best', 'match', 'results', 'and', 'using', 'a', 'reduce', 'function', 'of', 'a', 'mapreduce', 'program', 'to', 'combine', 'the', 'best', 'match', 'results', 'from', 'each', 'of', 'the', 'subsets', 'to', 'produce', 'a', 'single', 'set', 'of', 'the', 'best', 'match', 'results', 'the', 'method', 'of', 'scalable', 'parallel', 'cloud-based', 'face', 'recognition', 'of', 'claim', 'wherein', 'partitioning', 'the', 'reduced', 'candidate', 'list', 'comprises', 'selecting', 'the', 'images', 'comprising', 'each', 'subset', 'by', 'optimizing', 'the', 'variance', 'between', 'of', 'each', 'of', 'the', 'images', 'according', 'to', 'the', 'following', 'equation', 'where', 'm', 'and', 'n', 'are', 'the', 'number', 'of', 'rows', 'and', 'columns', 'of', 'the', 'face', 'vector', 'image', 'n', 'is', 'the', 'number', 'of', 'groups', 'and', 'σij', 'is', 'the', 'standard', 'deviation', 'of', 'image', 'dimension', 'i', 'in', 'the', 'group', 'j', 'of', 'the', 'face', 'image', 'vector', 'the', 'method', 'of', 'scalable', 'parallel', 'cloud-based', 'face', 'recognition', 'of', 'claim', 'wherein', 'selecting', 'the', 'images', 'comprising', 'each', 'subset', 'by', 'optimizing', 'the', 'variance', 'between', 'each', 'of', 'the', 'images', 'according', 'to', 'the', 'following', 'equation', 'dμi', 'μj', 'is', 'the', 'euclidean', 'distance', 'between', 'the', 'mean', 'of', 'the', 'group', 'i', 'and', 'the', 'mean', 'of', 'group', 'j', 'i', 'is', 'the', 'face', 'image', 'vector', 'and', 'l', 'is', 'the', 'number', 'of', 'group', 'levels', 'the', 'method', 'of', 'scalable', 'parallel', 'cloud-based', 'face', 'recognition', 'of', 'claim', 'where', 'selecting', 'a', 'final', 'match', 'from', 'the', 'best', 'match', 'results', 'utilizing', 'a', 'deep', 'learning', 'neural', 'network', 'face', 'recognition', 'algorithm', 'comprises', 'utilizing', 'either', 'an', 'adaboost', 'machine-learning', 'algorithm', 'or', 'a', 'neural', 'networks', 'machine-learning', 'model', 'the', 'method', 'of', 'scalable', 'parallel', 'cloud-based', 'face', 'recognition', 'of', 'claim', 'where', 'normalizing', 'the', 'detected', 'facial', 'image', 'to', 'match', 'the', 'normalized', 'stored', 'images', 'includes', 'normalizing', 'the', 'detected', 'facial', 'image', 'to', 'the', 'same', 'size', 'orientation', 'and', 'illumination', 'of', 'the', 'normalized', 'stored', 'images', 'a', 'non-transitory', 'computer-readable', 'medium', 'containing', 'executable', 'program', 'instructions', 'for', 'causing', 'a', 'computer', 'to', 'perform', 'a', 'method', 'of', 'face', 'recognition', 'the', 'method', 'comprising', 'detecting', 'a', 'face', 'in', 'an', 'image', 'captured', 'by', 'a', 'camera', 'normalizing', 'the', 'detected', 'facial', 'image', 'to', 'match', 'the', 'normalized', 'stored', 'images', 'identifying', 'facial', 'features', 'in', 'the', 'normalized', 'detected', 'facial', 'image', 'generating', 'a', 'plurality', 'of', 'facial', 'metrics', 'from', 'the', 'facial', 'features', 'calculating', 'euclidean', 'distances', 'between', 'the', 'facial', 'metrics', 'of', 'the', 'normalized', 'detected', 'facial', 'image', 'with', 'corresponding', 'facial', 'metrics', 'of', 'each', 'of', 'the', 'stored', 'images', 'comparing', 'each', 'euclidean', 'distance', 'against', 'a', 'predetermined', 'threshold', 'responsive', 'to', 'the', 'euclidean', 'distance', 'comparison', 'producing', 'a', 'reduced', 'candidate', 'list', 'of', 'best', 'possible', 'image', 'matches', 'from', 'the', 'normalized', 'stored', 'images', 'comparing', 'in', 'parallel', 'the', 'captured', 'image', 'with', 'each', 'of', 'the', 'normalized', 'stored', 'images', 'of', 'the', 'reduced', 'candidate', 'list', 'utilizing', 'a', 'plurality', 'of', 'face', 'recognition', 'algorithms', 'where', 'each', 'processor', 'of', 'a', 'parallel', 'processing', 'system', 'uses', 'a', 'different', 'face', 'recognition', 'algorithm', 'responsive', 'to', 'the', 'comparison', 'producing', 'best', 'match', 'results', 'from', 'each', 'parallel', 'subset', 'of', 'the', 'reduced', 'candidate', 'list', 'and', 'selecting', 'a', 'final', 'match', 'from', 'the', 'best', 'match', 'results', 'using', 'a', 'deep', 'learning', 'neural', 'network', 'face', 'recognition', 'algorithm', 'trained', 'on', 'outputs', 'of', 'individual', 'face', 'recognition', 'algorithms', 'the', 'non-transitory', 'computer-readable', 'medium', 'containing', 'executable', 'program', 'instructions', 'of', 'claim', 'wherein', 'the', 'plurality', 'of', 'face', 'recognition', 'algorithms', 'utilized', 'in', 'comparing', 'in', 'parallel', 'the', 'normalized', 'detected', 'facial', 'image', 'with', 'each', 'of', 'the', 'normalized', 'stored', 'images', 'of', 'the', 'reduced', 'candidate', 'list', 'consists', 'of', 'face', 'recognition', 'algorithms', 'selected', 'from', 'a', 'group', 'consisting', 'of', 'principle', 'component', 'analysis', 'pca-based', 'algorithms', 'linear', 'discriminant', 'analysis', 'lda', 'algorithms', 'independent', 'component', 'analysis', 'ica', 'algorithms', 'kernel-based', 'algorithms', 'feature-based', 'techniques', 'algorithms', 'based', 'on', 'neural', 'networks', 'algorithms', 'based', 'on', 'transforms', 'and', 'model-based', 'face', 'recognition', 'algorithms', 'the', 'non-transitory', 'computer-readable', 'medium', 'containing', 'executable', 'program', 'instructions', 'of', 'claim', 'wherein', 'the', 'pca-based', 'algorithms', 'include', 'eigenfaces', 'for', 'face', 'detectionrecognition', 'and', 'the', 'lda', 'algorithms', 'include', 'the', 'fisherfaces', 'method', 'of', 'face', 'recognition', 'the', 'non-transitory', 'computer-readable', 'medium', 'containing', 'executable', 'program', 'instructions', 'of', 'claim', 'where', 'selecting', 'a', 'final', 'match', 'from', 'the', 'best', 'match', 'results', 'utilizing', 'a', 'deep', 'learning', 'neural', 'network', 'face', 'recognition', 'algorithm', 'comprises', 'utilizing', 'either', 'an', 'adaboost', 'machine-learning', 'algorithm', 'or', 'a', 'neural', 'networks', 'machine-learning', 'model', 'an', 'imaging', 'device', 'comprising', 'a', 'condensing', 'lens', 'an', 'image', 'sensor', 'configured', 'to', 'detect', 'light', 'passing', 'through', 'the', 'condensing', 'lens', 'and', 'comprising', 'a', 'pixel', 'matrix', 'wherein', 'the', 'pixel', 'matrix', 'comprises', 'a', 'plurality', 'of', 'phase', 'detection', 'pixel', 'pairs', 'and', 'a', 'plurality', 'of', 'regular', 'pixels', 'and', 'a', 'processor', 'configured', 'to', 'turn', 'on', 'the', 'phase', 'detection', 'pixel', 'pairs', 'for', 'autofocusing', 'and', 'output', 'autofocused', 'pixel', 'data', 'after', 'completing', 'the', 'autofocusing', 'divide', 'the', 'autofocused', 'pixel', 'data', 'into', 'a', 'first', 'subframe', 'and', 'a', 'second', 'subframe', 'calculate', 'image', 'features', 'of', 'at', 'least', 'one', 'of', 'the', 'first', 'subframe', 'and', 'the', 'second', 'subframe', 'wherein', 'the', 'image', 'features', 'comprise', 'module', 'widths', 'of', 'a', 'finder', 'pattern', 'and', 'the', 'finder', 'pattern', 'has', 'a', 'predetermined', 'ratio', 'a', 'harr-like', 'feature', 'or', 'a', 'gabor', 'feature', 'and', 'determine', 'an', 'operating', 'resolution', 'of', 'the', 'regular', 'pixels', 'according', 'to', 'the', 'image', 'features', 'calculated', 'from', 'at', 'least', 'one', 'of', 'the', 'first', 'subframe', 'and', 'the', 'second', 'subframe', 'divided', 'from', 'the', 'autofocused', 'pixel', 'data', 'the', 'imaging', 'device', 'as', 'claimed', 'in', 'claim', 'wherein', 'each', 'of', 'the', 'phase', 'detection', 'pixel', 'pairs', 'comprises', 'a', 'first', 'pixel', 'and', 'a', 'second', 'pixel', 'a', 'cover', 'layer', 'covering', 'upon', 'a', 'first', 'region', 'of', 'the', 'first', 'pixel', 'and', 'upon', 'a', 'second', 'region', 'of', 'the', 'second', 'pixel', 'wherein', 'the', 'first', 'region', 'and', 'the', 'second', 'region', 'are', 'mirror', 'symmetrical', 'to', 'each', 'other', 'and', 'a', 'microlens', 'aligned', 'with', 'at', 'least', 'one', 'of', 'the', 'first', 'pixel', 'and', 'the', 'second', 'pixel', 'the', 'imaging', 'device', 'as', 'claimed', 'in', 'claim', 'wherein', 'the', 'first', 'region', 'and', 'the', 'second', 'region', 'are', '%', 'to', '%', 'of', 'an', 'area', 'of', 'a', 'single', 'pixel', 'the', 'imaging', 'device', 'as', 'claimed', 'in', 'claim', 'wherein', 'the', 'processor', 'is', 'configured', 'to', 'perform', 'the', 'autofocusing', 'using', 'a', 'dual', 'pixel', 'autofocus', 'technique', 'according', 'to', 'pixel', 'data', 'of', 'the', 'phase', 'detection', 'pixel', 'pairs', 'before', 'completing', 'the', 'autofocusing', 'the', 'imaging', 'device', 'as', 'claimed', 'in', 'claim', 'wherein', 'the', 'processor', 'is', 'configured', 'to', 'divide', 'pixel', 'data', 'of', 'the', 'phase', 'detection', 'pixel', 'pairs', 'into', 'a', 'third', 'subframe', 'and', 'a', 'fourth', 'subframe', 'before', 'completing', 'the', 'autofocusing', 'and', 'perform', 'the', 'autofocusing', 'according', 'to', 'the', 'third', 'subframe', 'and', 'the', 'fourth', 'subframe', 'the', 'imaging', 'device', 'as', 'claimed', 'in', 'claim', 'wherein', 'the', 'processor', 'is', 'further', 'configured', 'to', 'calibrate', 'brightness', 'of', 'the', 'third', 'subframe', 'and', 'the', 'fourth', 'subframe', 'to', 'be', 'identical', 'using', 'a', 'shading', 'algorithm', 'the', 'imaging', 'device', 'as', 'claimed', 'in', 'claim', 'wherein', 'the', 'operating', 'resolution', 'is', 'selected', 'as', 'a', 'first', 'resolution', 'smaller', 'than', 'a', 'number', 'of', 'the', 'regular', 'pixels', 'or', 'as', 'a', 'second', 'resolution', 'larger', 'than', 'the', 'first', 'resolution', 'the', 'imaging', 'device', 'as', 'claimed', 'in', 'claim', 'wherein', 'the', 'regular', 'pixels', 'are', 'turned', 'off', 'in', 'the', 'autofocusing', 'the', 'imaging', 'device', 'as', 'claimed', 'in', 'claim', 'wherein', 'a', 'number', 'of', 'the', 'phase', 'detection', 'pixel', 'pairs', 'is', 'smaller', 'than', 'that', 'of', 'the', 'regular', 'pixels', 'an', 'imaging', 'device', 'comprising', 'a', 'condensing', 'lens', 'an', 'image', 'sensor', 'configured', 'to', 'detect', 'light', 'passing', 'through', 'the', 'condensing', 'lens', 'and', 'comprising', 'a', 'pixel', 'matrix', 'wherein', 'the', 'pixel', 'matrix', 'comprises', 'a', 'plurality', 'of', 'phase', 'detection', 'pixel', 'pairs', 'and', 'a', 'plurality', 'of', 'regular', 'pixels', 'and', 'a', 'processor', 'configured', 'to', 'turn', 'on', 'the', 'phase', 'detection', 'pixel', 'pairs', 'for', 'autofocusing', 'and', 'output', 'autofocused', 'pixel', 'data', 'after', 'completing', 'the', 'autofocusing', 'divide', 'the', 'autofocused', 'pixel', 'data', 'into', 'a', 'first', 'subframe', 'and', 'a', 'second', 'subframe', 'calculate', 'image', 'features', 'of', 'at', 'least', 'one', 'of', 'the', 'first', 'subframe', 'and', 'the', 'second', 'subframe', 'wherein', 'the', 'image', 'features', 'comprise', 'module', 'widths', 'of', 'a', 'finder', 'pattern', 'and', 'the', 'finder', 'pattern', 'has', 'a', 'predetermined', 'ratio', 'a', 'harr-like', 'feature', 'or', 'a', 'gabor', 'feature', 'and', 'select', 'an', 'image', 'decoding', 'or', 'an', 'image', 'recognition', 'using', 'pixel', 'data', 'of', 'the', 'regular', 'pixels', 'according', 'to', 'the', 'image', 'features', 'calculated', 'from', 'at', 'least', 'one', 'of', 'the', 'first', 'subframe', 'and', 'the', 'second', 'subframe', 'divided', 'from', 'the', 'autofocused', 'pixel', 'data', 'the', 'imaging', 'device', 'as', 'claimed', 'in', 'claim', 'wherein', 'each', 'of', 'the', 'phase', 'detection', 'pixel', 'pairs', 'comprises', 'a', 'first', 'pixel', 'and', 'a', 'second', 'pixel', 'a', 'cover', 'layer', 'covering', 'upon', 'a', 'first', 'region', 'of', 'the', 'first', 'pixel', 'and', 'upon', 'a', 'second', 'region', 'of', 'the', 'second', 'pixel', 'wherein', 'the', 'first', 'region', 'and', 'the', 'second', 'region', 'are', 'mirror', 'symmetrical', 'to', 'each', 'other', 'and', 'a', 'microlens', 'aligned', 'with', 'at', 'least', 'one', 'of', 'the', 'first', 'pixel', 'and', 'the', 'second', 'pixel', 'the', 'imaging', 'device', 'as', 'claimed', 'in', 'claim', 'wherein', 'the', 'processor', 'is', 'configured', 'to', 'perform', 'the', 'autofocusing', 'using', 'a', 'dual', 'pixel', 'autofocus', 'technique', 'according', 'to', 'pixel', 'data', 'of', 'the', 'phase', 'detection', 'pixel', 'pairs', 'before', 'completing', 'the', 'autofocusing', 'the', 'imaging', 'device', 'as', 'claimed', 'in', 'claim', 'wherein', 'the', 'processor', 'is', 'configured', 'to', 'divide', 'the', 'pixel', 'data', 'of', 'the', 'phase', 'detection', 'pixel', 'pairs', 'into', 'a', 'third', 'subframe', 'and', 'a', 'fourth', 'subframe', 'before', 'completing', 'the', 'autofocusing', 'calibrate', 'brightness', 'of', 'the', 'third', 'subframe', 'and', 'the', 'fourth', 'subframe', 'to', 'be', 'identical', 'using', 'a', 'shading', 'algorithm', 'and', 'perform', 'the', 'autofocusing', 'according', 'to', 'the', 'third', 'subframe', 'and', 'the', 'fourth', 'subframe', 'the', 'imaging', 'device', 'as', 'claimed', 'in', 'claim', 'wherein', 'the', 'processor', 'is', 'configured', 'to', 'calculate', 'the', 'image', 'features', 'using', 'at', 'least', 'one', 'of', 'a', 'rule', 'based', 'algorithm', 'and', 'a', 'machine', 'learning', 'algorithm', 'the', 'imaging', 'device', 'as', 'claimed', 'in', 'claim', 'wherein', 'the', 'image', 'decoding', 'is', 'decoding', 'qr', 'codes', 'and', 'the', 'image', 'recognition', 'is', 'face', 'recognition', 'an', 'operating', 'method', 'of', 'an', 'imaging', 'device', 'the', 'imaging', 'device', 'comprising', 'a', 'plurality', 'of', 'phase', 'detection', 'pixel', 'pairs', 'and', 'a', 'plurality', 'of', 'regular', 'pixels', 'the', 'operating', 'method', 'comprising', 'turning', 'on', 'the', 'phase', 'detection', 'pixel', 'pairs', 'for', 'autofocusing', 'and', 'outputting', 'autofocused', 'image', 'frame', 'after', 'completing', 'the', 'autofocusing', 'dividing', 'the', 'autofocused', 'image', 'frame', 'acquired', 'by', 'the', 'phase', 'detection', 'pixel', 'pairs', 'into', 'a', 'first', 'subframe', 'and', 'a', 'second', 'subframe', 'calculating', 'image', 'features', 'of', 'at', 'least', 'one', 'of', 'the', 'first', 'subframe', 'and', 'the', 'second', 'subframe', 'wherein', 'the', 'image', 'feature', 'comprise', 'module', 'widths', 'of', 'a', 'finder', 'pattern', 'and', 'the', 'finder', 'pattern', 'has', 'a', 'predetermined', 'ratio', 'a', 'harr-like', 'feature', 'or', 'a', 'gabor', 'feature', 'and', 'selectively', 'activating', 'at', 'least', 'a', 'part', 'of', 'the', 'regular', 'pixels', 'according', 'to', 'the', 'image', 'features', 'calculated', 'from', 'at', 'least', 'one', 'of', 'the', 'first', 'subframe', 'and', 'the', 'second', 'subframe', 'divided', 'from', 'the', 'autofocused', 'image', 'frame', 'the', 'operating', 'method', 'as', 'claimed', 'in', 'claim', 'wherein', 'the', 'selectively', 'activating', 'comprises', 'activating', 'a', 'first', 'part', 'of', 'the', 'regular', 'pixels', 'to', 'perform', 'an', 'image', 'decoding', 'according', 'to', 'pixel', 'data', 'of', 'the', 'first', 'part', 'of', 'the', 'regular', 'pixels', 'or', 'activating', 'all', 'the', 'regular', 'pixels', 'to', 'perform', 'an', 'image', 'recognition', 'according', 'to', 'pixel', 'data', 'of', 'the', 'all', 'regular', 'pixels', 'the', 'operating', 'method', 'as', 'claimed', 'in', 'claim', 'wherein', 'pixel', 'data', 'of', 'the', 'phase', 'detection', 'pixel', 'pairs', 'captured', 'in', 'a', 'same', 'frame', 'with', 'the', 'pixel', 'data', 'of', 'the', 'regular', 'pixels', 'is', 'also', 'used', 'in', 'performing', 'the', 'image', 'decoding', 'and', 'the', 'image', 'recognition', 'the', 'operating', 'method', 'as', 'claimed', 'in', 'claim', 'wherein', 'the', 'image', 'decoding', 'is', 'decoding', 'qr', 'codes', 'and', 'the', 'image', 'recognition', 'is', 'face', 'recognition', 'the', 'operating', 'method', 'as', 'claimed', 'in', 'claim', 'wherein', 'the', 'phase', 'detection', 'pixel', 'pairs', 'are', 'partially', 'covered', 'pixels', 'or', 'have', 'a', 'structure', 'of', 'dual', 'pixel', 'an', 'apparatus', 'comprising', 'a', 'first', 'camera', 'module', 'configured', 'to', 'obtain', 'a', 'first', 'image', 'of', 'an', 'object', 'with', 'a', 'first', 'field', 'of', 'view', 'a', 'second', 'camera', 'module', 'configured', 'to', 'obtain', 'a', 'second', 'image', 'of', 'the', 'object', 'with', 'a', 'second', 'field', 'of', 'view', 'different', 'from', 'the', 'first', 'field', 'of', 'view', 'a', 'first', 'depth', 'map', 'generator', 'configured', 'to', 'generate', 'a', 'first', 'depth', 'map', 'of', 'the', 'first', 'image', 'based', 'on', 'the', 'first', 'image', 'and', 'the', 'second', 'image', 'and', 'a', 'second', 'depth', 'map', 'generator', 'configured', 'to', 'generate', 'a', 'second', 'depth', 'map', 'of', 'the', 'second', 'image', 'based', 'on', 'the', 'first', 'image', 'the', 'second', 'image', 'and', 'the', 'first', 'depth', 'map', 'the', 'apparatus', 'of', 'claim', 'wherein', 'the', 'first', 'field', 'of', 'view', 'is', 'a', 'narrow', 'angle', 'and', 'the', 'second', 'field', 'of', 'view', 'is', 'a', 'wider', 'angle', 'the', 'apparatus', 'of', 'claim', 'wherein', 'the', 'second', 'image', 'is', 'divided', 'into', 'a', 'primary', 'region', 'and', 'a', 'residual', 'region', 'and', 'the', 'second', 'depth', 'map', 'generator', 'comprises', 'a', 'relationship', 'estimating', 'module', 'configured', 'to', 'estimate', 'a', 'relationship', 'between', 'the', 'primary', 'region', 'and', 'the', 'residual', 'region', 'based', 'on', 'the', 'first', 'image', 'and', 'the', 'second', 'image', 'and', 'a', 'depth', 'map', 'estimating', 'module', 'configured', 'to', 'estimate', 'a', 'depth', 'map', 'of', 'the', 'residual', 'region', 'based', 'on', 'the', 'estimated', 'relationship', 'and', 'the', 'first', 'depth', 'map', 'the', 'apparatus', 'of', 'claim', 'wherein', 'at', 'least', 'one', 'of', 'the', 'relationship', 'estimating', 'module', 'and', 'the', 'depth', 'map', 'estimating', 'module', 'performs', 'an', 'estimating', 'operation', 'based', 'on', 'a', 'neural', 'network', 'module', 'the', 'apparatus', 'of', 'claim', 'further', 'comprising', 'a', 'depth', 'map', 'fusion', 'unit', 'configured', 'to', 'generate', 'a', 'third', 'depth', 'map', 'of', 'the', 'second', 'image', 'by', 'performing', 'a', 'fusion', 'operation', 'based', 'on', 'the', 'first', 'depth', 'map', 'and', 'the', 'second', 'depth', 'map', 'the', 'apparatus', 'of', 'claim', 'wherein', 'the', 'depth', 'map', 'fusion', 'unit', 'comprises', 'a', 'tone', 'mapping', 'module', 'configured', 'to', 'generate', 'a', 'tone-mapped', 'second', 'depth', 'map', 'to', 'correspond', 'to', 'the', 'first', 'depth', 'map', 'by', 'performing', 'a', 'bias', 'removing', 'operation', 'on', 'the', 'second', 'depth', 'map', 'and', 'a', 'fusion', 'module', 'configured', 'to', 'generate', 'the', 'third', 'depth', 'map', 'by', 'fusing', 'the', 'tone-mapped', 'second', 'depth', 'map', 'and', 'the', 'first', 'depth', 'map', 'the', 'apparatus', 'of', 'claim', 'wherein', 'the', 'depth', 'map', 'fusion', 'unit', 'further', 'comprises', 'a', 'propagating', 'module', 'configured', 'to', 'generate', 'a', 'propagated', 'first', 'depth', 'map', 'in', 'the', 'second', 'image', 'by', 'iterated', 'propagating', 'of', 'the', 'first', 'depth', 'map', 'based', 'on', 'the', 'first', 'depth', 'map', 'and', 'the', 'second', 'image', 'and', 'the', 'fusion', 'module', 'generates', 'the', 'third', 'depth', 'map', 'by', 'fusing', 'the', 'tone-mapped', 'second', 'depth', 'map', 'and', 'the', 'propagated', 'first', 'depth', 'map', 'the', 'apparatus', 'of', 'claim', 'wherein', 'the', 'depth', 'map', 'fusion', 'unit', 'further', 'comprises', 'a', 'post-processing', 'module', 'configured', 'to', 'perform', 'a', 'post-processing', 'operation', 'on', 'the', 'third', 'depth', 'map', 'generated', 'by', 'the', 'fusion', 'module', 'to', 'provide', 'the', 'post-processed', 'third', 'depth', 'map', 'the', 'apparatus', 'of', 'claim', 'wherein', 'the', 'post-processing', 'module', 'performs', 'the', 'post-processing', 'operation', 'by', 'filtering', 'an', 'interface', 'generated', 'in', 'the', 'third', 'depth', 'map', 'in', 'accordance', 'with', 'fusion', 'of', 'the', 'fusion', 'module', 'the', 'apparatus', 'of', 'claim', 'wherein', 'the', 'post-processing', 'module', 'removes', 'artifacts', 'generated', 'in', 'the', 'third', 'depth', 'map', 'in', 'accordance', 'with', 'fusion', 'of', 'the', 'fusion', 'module', 'the', 'apparatus', 'of', 'claim', 'wherein', 'the', 'first', 'depth', 'map', 'generator', 'analyses', 'a', 'distance', 'relationship', 'between', 'the', 'first', 'image', 'and', 'the', 'second', 'image', 'and', 'generates', 'a', 'first', 'depth', 'map', 'of', 'the', 'first', 'image', 'based', 'on', 'the', 'distance', 'relationship', 'a', 'method', 'of', 'processing', 'an', 'image', 'of', 'an', 'electronic', 'apparatus', 'the', 'method', 'comprising', 'obtaining', 'a', 'first', 'image', 'of', 'an', 'object', 'using', 'a', 'first', 'camera', 'module', 'obtaining', 'a', 'second', 'image', 'of', 'the', 'object', 'using', 'a', 'second', 'camera', 'module', 'generating', 'a', 'first', 'depth', 'map', 'of', 'the', 'first', 'image', 'based', 'on', 'the', 'first', 'image', 'and', 'the', 'second', 'image', 'estimating', 'a', 'relationship', 'between', 'a', 'primary', 'region', 'of', 'the', 'second', 'image', 'and', 'a', 'residual', 'region', 'of', 'the', 'second', 'image', 'based', 'on', 'the', 'first', 'image', 'and', 'the', 'second', 'image', 'and', 'generating', 'a', 'second', 'depth', 'map', 'of', 'the', 'second', 'image', 'based', 'on', 'the', 'estimated', 'relationship', 'between', 'the', 'primary', 'region', 'and', 'the', 'residual', 'region', 'and', 'the', 'first', 'depth', 'map', 'the', 'method', 'of', 'claim', 'wherein', 'the', 'electronic', 'apparatus', 'comprises', 'a', 'first', 'camera', 'module', 'including', 'a', 'first', 'lens', 'having', 'a', 'first', 'field', 'of', 'view', 'and', 'a', 'second', 'camera', 'module', 'including', 'a', 'second', 'lens', 'having', 'a', 'second', 'field', 'of', 'view', 'wider', 'than', 'the', 'first', 'field', 'of', 'view', 'the', 'method', 'of', 'claim', 'wherein', 'the', 'generating', 'of', 'the', 'second', 'depth', 'map', 'comprises', 'estimating', 'a', 'depth', 'map', 'of', 'the', 'residual', 'region', 'based', 'on', 'the', 'estimated', 'relationship', 'between', 'the', 'primary', 'region', 'and', 'the', 'residual', 'region', 'and', 'the', 'first', 'depth', 'map', 'and', 'generating', 'the', 'second', 'depth', 'map', 'based', 'on', 'a', 'depth', 'map', 'of', 'the', 'residual', 'region', 'and', 'the', 'first', 'depth', 'map', 'the', 'method', 'of', 'claim', 'wherein', 'the', 'estimating', 'of', 'the', 'relationship', 'between', 'a', 'primary', 'region', 'of', 'the', 'second', 'image', 'is', 'performed', 'using', 'a', 'neural', 'network', 'model', 'the', 'method', 'of', 'claim', 'further', 'comprising', 'performing', 'a', 'pre-processing', 'operation', 'on', 'the', 'second', 'depth', 'map', 'and', 'generating', 'a', 'third', 'depth', 'map', 'of', 'the', 'residual', 'image', 'by', 'fusing', 'the', 'second', 'depth', 'map', 'on', 'which', 'the', 'pre-processing', 'operation', 'is', 'performed', 'and', 'the', 'first', 'depth', 'map', 'the', 'method', 'of', 'claim', 'wherein', 'the', 'performing', 'of', 'the', 'pre-processing', 'operation', 'comprises', 'performing', 'a', 'tone', 'mapping', 'operation', 'between', 'a', 'depth', 'map', 'of', 'the', 'primary', 'region', 'and', 'a', 'depth', 'map', 'of', 'the', 'residual', 'region', 'based', 'on', 'the', 'second', 'depth', 'map', 'an', 'operating', 'method', 'for', 'an', 'electronic', 'apparatus', 'the', 'electronic', 'apparatus', 'including', 'a', 'first', 'camera', 'module', 'providing', 'a', 'first', 'image', 'of', 'an', 'object', 'using', 'a', 'first', 'field', 'of', 'view', 'and', 'a', 'second', 'camera', 'module', 'providing', 'a', 'second', 'image', 'of', 'the', 'object', 'using', 'second', 'field', 'of', 'view', 'wider', 'than', 'the', 'first', 'field', 'of', 'view', 'and', 'a', 'processor', 'generating', 'a', 'depth', 'map', 'of', 'the', 'second', 'image', 'based', 'on', 'a', 'primary', 'region', 'of', 'the', 'second', 'image', 'and', 'a', 'residual', 'region', 'of', 'the', 'second', 'image', 'the', 'operating', 'method', 'comprising', 'generating', 'a', 'first', 'depth', 'map', 'of', 'the', 'primary', 'region', 'by', 'estimating', 'a', 'relationship', 'between', 'the', 'first', 'image', 'and', 'the', 'second', 'image', 'estimating', 'a', 'relationship', 'between', 'the', 'primary', 'region', 'and', 'the', 'residual', 'region', 'based', 'on', 'the', 'first', 'image', 'and', 'the', 'second', 'image', 'generating', 'a', 'second', 'depth', 'map', 'of', 'the', 'second', 'image', 'by', 'estimating', 'a', 'depth', 'map', 'of', 'the', 'second', 'region', 'based', 'on', 'the', 'estimated', 'relationship', 'between', 'the', 'primary', 'region', 'and', 'the', 'residual', 'region', 'and', 'generating', 'a', 'depth', 'map', 'of', 'the', 'second', 'image', 'by', 'fusing', 'the', 'first', 'depth', 'map', 'and', 'the', 'second', 'depth', 'map', 'the', 'operation', 'method', 'of', 'claim', 'further', 'comprising', 'executing', 'an', 'application', 'that', 'applies', 'an', 'image', 'effect', 'to', 'the', 'second', 'image', 'based', 'on', 'a', 'depth', 'map', 'of', 'the', 'residual', 'image', 'the', 'operation', 'method', 'of', 'claim', 'wherein', 'the', 'application', 'applies', 'at', 'least', 'one', 'image', 'effect', 'of', 'auto-focusing', 'out-focusing', 'forebackground', 'separation', 'face', 'recognition', 'object', 'detection', 'within', 'a', 'frame', 'and', 'augmented', 'reality', 'to', 'the', 'second', 'image', 'based', 'on', 'a', 'depth', 'map', 'of', 'the', 'second', 'image', 'a', 'payment', 'method', 'based', 'on', 'a', 'face', 'recognition', 'comprising', 'acquiring', 'first', 'face', 'image', 'information', 'of', 'a', 'target', 'user', 'extracting', 'first', 'characteristic', 'information', 'from', 'the', 'first', 'face', 'image', 'information', 'wherein', 'the', 'first', 'characteristic', 'information', 'includes', 'head', 'posture', 'information', 'of', 'the', 'target', 'user', 'and', 'gaze', 'information', 'of', 'the', 'target', 'user', 'determining', 'whether', 'the', 'target', 'user', 'has', 'a', 'willingness', 'to', 'pay', 'according', 'to', 'the', 'head', 'posture', 'information', 'of', 'the', 'target', 'user', 'and', 'the', 'gaze', 'information', 'of', 'the', 'target', 'user', 'including', 'determining', 'whether', 'an', 'angle', 'of', 'rotation', 'in', 'each', 'preset', 'direction', 'is', 'less', 'than', 'an', 'angle', 'threshold', 'wherein', 'the', 'head', 'posture', 'information', 'includes', 'the', 'angle', 'of', 'rotation', 'in', 'each', 'preset', 'direction', 'determining', 'whether', 'a', 'probability', 'value', 'that', 'a', 'user', 'gazes', 'at', 'a', 'payment', 'screen', 'is', 'greater', 'than', 'a', 'probability', 'threshold', 'wherein', 'the', 'gaze', 'information', 'includes', 'the', 'probability', 'value', 'that', 'a', 'user', 'gazes', 'at', 'a', 'payment', 'screen', 'and', 'in', 'response', 'to', 'determining', 'that', 'the', 'angle', 'of', 'rotation', 'in', 'each', 'preset', 'direction', 'is', 'less', 'than', 'the', 'angle', 'threshold', 'and', 'that', 'the', 'probability', 'value', 'that', 'a', 'user', 'gazes', 'at', 'a', 'payment', 'screen', 'is', 'greater', 'than', 'the', 'probability', 'threshold', 'determining', 'that', 'the', 'target', 'user', 'has', 'a', 'willingness', 'to', 'pay', 'and', 'in', 'response', 'to', 'determining', 'that', 'the', 'target', 'user', 'has', 'a', 'willingness', 'to', 'pay', 'completing', 'a', 'payment', 'operation', 'based', 'on', 'the', 'face', 'recognition', 'the', 'method', 'as', 'claimed', 'in', 'claim', 'wherein', 'the', 'completing', 'a', 'payment', 'operation', 'based', 'on', 'the', 'face', 'recognition', 'comprises', 'triggering', 'and', 'performing', 'a', 'payment', 'initiating', 'operation', 'to', 'acquire', 'second', 'face', 'image', 'information', 'based', 'on', 'the', 'face', 'recognition', 'determining', 'whether', 'second', 'characteristic', 'information', 'extracted', 'from', 'the', 'second', 'face', 'image', 'information', 'indicates', 'that', 'the', 'user', 'has', 'a', 'willingness', 'to', 'pay', 'and', 'in', 'response', 'to', 'determining', 'that', 'the', 'second', 'characteristic', 'information', 'indicates', 'that', 'the', 'user', 'has', 'a', 'willingness', 'to', 'pay', 'triggering', 'and', 'performing', 'a', 'payment', 'confirmation', 'operation', 'to', 'complete', 'the', 'payment', 'operation', 'based', 'on', 'payment', 'account', 'information', 'corresponding', 'to', 'the', 'target', 'user', 'the', 'method', 'as', 'claimed', 'in', 'claim', 'wherein', 'the', 'determining', 'whether', 'second', 'characteristic', 'information', 'extracted', 'from', 'the', 'second', 'face', 'image', 'information', 'indicates', 'that', 'the', 'user', 'has', 'a', 'willingness', 'to', 'pay', 'comprises', 'determining', 'whether', 'a', 'current', 'user', 'corresponding', 'to', 'the', 'second', 'face', 'image', 'information', 'is', 'consistent', 'with', 'the', 'target', 'user', 'and', 'in', 'response', 'to', 'determining', 'that', 'the', 'current', 'user', 'is', 'consistent', 'with', 'the', 'target', 'user', 'determining', 'whether', 'the', 'target', 'user', 'has', 'a', 'willingness', 'to', 'pay', 'according', 'to', 'the', 'second', 'characteristic', 'information', 'extracted', 'from', 'the', 'second', 'face', 'image', 'information', 'the', 'method', 'as', 'claimed', 'in', 'claim', 'wherein', 'the', 'extracting', 'first', 'characteristic', 'information', 'from', 'the', 'first', 'face', 'image', 'information', 'comprises', 'determining', 'the', 'head', 'posture', 'information', 'of', 'the', 'target', 'user', 'using', 'a', 'head', 'posture', 'recognition', 'model', 'based', 'on', 'the', 'first', 'face', 'image', 'information', 'and', 'determining', 'the', 'gaze', 'information', 'of', 'the', 'target', 'user', 'using', 'a', 'gaze', 'information', 'recognition', 'model', 'based', 'on', 'characteristics', 'of', 'an', 'eye', 'region', 'in', 'the', 'first', 'face', 'image', 'information', 'the', 'method', 'as', 'claimed', 'in', 'claim', 'wherein', 'the', 'head', 'posture', 'recognition', 'model', 'is', 'obtained', 'through', 'training', 'by', 'acquiring', 'a', 'first', 'sample', 'data', 'set', 'wherein', 'the', 'first', 'sample', 'data', 'set', 'includes', 'a', 'plurality', 'of', 'pieces', 'of', 'first', 'sample', 'data', 'and', 'each', 'of', 'the', 'plurality', 'of', 'pieces', 'of', 'first', 'sample', 'data', 'includes', 'a', 'correspondence', 'between', 'a', 'sample', 'face', 'image', 'and', 'head', 'posture', 'information', 'determining', 'mean', 'image', 'data', 'and', 'variance', 'image', 'data', 'of', 'a', 'plurality', 'of', 'sample', 'face', 'images', 'for', 'each', 'of', 'the', 'plurality', 'of', 'pieces', 'of', 'first', 'sample', 'data', 'preprocessing', 'the', 'sample', 'face', 'image', 'contained', 'in', 'each', 'of', 'the', 'plurality', 'of', 'pieces', 'of', 'first', 'sample', 'data', 'based', 'on', 'the', 'mean', 'image', 'data', 'and', 'the', 'variance', 'image', 'data', 'to', 'obtain', 'a', 'preprocessed', 'sample', 'face', 'image', 'setting', 'the', 'preprocessed', 'sample', 'face', 'image', 'and', 'the', 'corresponding', 'head', 'posture', 'information', 'as', 'a', 'first', 'model', 'training', 'sample', 'and', 'performing', 'training', 'using', 'a', 'machine', 'learning', 'method', 'and', 'based', 'on', 'a', 'plurality', 'of', 'first', 'model', 'training', 'samples', 'to', 'obtain', 'the', 'head', 'posture', 'recognition', 'model', 'the', 'method', 'as', 'claimed', 'in', 'claim', 'wherein', 'the', 'gaze', 'information', 'recognition', 'model', 'is', 'obtained', 'through', 'training', 'by', 'acquiring', 'a', 'second', 'sample', 'data', 'set', 'wherein', 'the', 'second', 'sample', 'data', 'set', 'includes', 'a', 'plurality', 'of', 'pieces', 'of', 'second', 'sample', 'data', 'and', 'each', 'of', 'the', 'plurality', 'of', 'pieces', 'of', 'second', 'sample', 'data', 'includes', 'a', 'correspondence', 'between', 'a', 'sample', 'eye', 'image', 'and', 'gaze', 'information', 'determining', 'mean', 'image', 'data', 'and', 'variance', 'image', 'data', 'of', 'a', 'plurality', 'of', 'sample', 'eye', 'images', 'for', 'each', 'of', 'the', 'plurality', 'of', 'pieces', 'of', 'second', 'sample', 'data', 'preprocessing', 'the', 'sample', 'eye', 'image', 'contained', 'in', 'each', 'of', 'the', 'plurality', 'of', 'pieces', 'of', 'second', 'sample', 'data', 'based', 'on', 'the', 'mean', 'image', 'data', 'and', 'the', 'variance', 'image', 'data', 'to', 'obtain', 'a', 'preprocessed', 'sample', 'eye', 'image', 'setting', 'the', 'preprocessed', 'sample', 'eye', 'image', 'and', 'the', 'corresponding', 'gaze', 'information', 'as', 'a', 'second', 'model', 'training', 'sample', 'and', 'performing', 'training', 'using', 'a', 'machine', 'learning', 'method', 'and', 'based', 'on', 'a', 'plurality', 'of', 'second', 'model', 'training', 'samples', 'to', 'obtain', 'the', 'gaze', 'information', 'recognition', 'model', 'the', 'method', 'as', 'claimed', 'in', 'claim', 'wherein', 'the', 'angle', 'of', 'rotation', 'in', 'each', 'preset', 'direction', 'comprises', 'a', 'pitch', 'angle', 'a', 'yaw', 'angle', 'and', 'a', 'roll', 'angle', 'wherein', 'the', 'pitch', 'angle', 'refers', 'to', 'an', 'angle', 'of', 'rotation', 'around', 'a', 'x-axis', 'the', 'yaw', 'angle', 'refers', 'to', 'an', 'angle', 'of', 'rotation', 'around', 'a', 'y-axis', 'and', 'the', 'roll', 'angle', 'refers', 'to', 'an', 'angle', 'of', 'rotation', 'around', 'a', 'z-axis', 'a', 'payment', 'device', 'based', 'on', 'a', 'face', 'recognition', 'comprising', 'a', 'processor', 'and', 'a', 'non-transitory', 'computer-readable', 'storage', 'medium', 'storing', 'instructions', 'executable', 'by', 'the', 'processor', 'to', 'cause', 'the', 'device', 'to', 'perform', 'operations', 'comprising', 'acquiring', 'first', 'face', 'image', 'information', 'of', 'a', 'target', 'user', 'extracting', 'first', 'characteristic', 'information', 'from', 'the', 'first', 'face', 'image', 'information', 'wherein', 'the', 'first', 'characteristic', 'information', 'includes', 'head', 'posture', 'information', 'of', 'the', 'target', 'user', 'and', 'gaze', 'information', 'of', 'the', 'target', 'user', 'determining', 'whether', 'the', 'target', 'user', 'has', 'a', 'willingness', 'to', 'pay', 'according', 'to', 'the', 'head', 'posture', 'information', 'of', 'the', 'target', 'user', 'and', 'the', 'gaze', 'information', 'of', 'the', 'target', 'user', 'including', 'determining', 'whether', 'an', 'angle', 'of', 'rotation', 'in', 'each', 'preset', 'direction', 'is', 'less', 'than', 'an', 'angle', 'threshold', 'wherein', 'the', 'head', 'posture', 'information', 'includes', 'the', 'angle', 'of', 'rotation', 'in', 'each', 'preset', 'direction', 'determining', 'whether', 'a', 'probability', 'value', 'that', 'a', 'user', 'gazes', 'at', 'a', 'payment', 'screen', 'is', 'greater', 'than', 'a', 'probability', 'threshold', 'wherein', 'the', 'gaze', 'information', 'includes', 'the', 'probability', 'value', 'that', 'a', 'user', 'gazes', 'at', 'a', 'payment', 'screen', 'and', 'in', 'response', 'to', 'determining', 'that', 'the', 'angle', 'of', 'rotation', 'in', 'each', 'preset', 'direction', 'is', 'less', 'than', 'the', 'angle', 'threshold', 'and', 'that', 'the', 'probability', 'value', 'that', 'a', 'user', 'gazes', 'at', 'a', 'payment', 'screen', 'is', 'greater', 'than', 'the', 'probability', 'threshold', 'determining', 'that', 'the', 'target', 'user', 'has', 'a', 'willingness', 'to', 'pay', 'and', 'in', 'response', 'to', 'determining', 'that', 'the', 'target', 'user', 'has', 'a', 'willingness', 'to', 'pay', 'completing', 'a', 'payment', 'operation', 'based', 'on', 'the', 'face', 'recognition', 'the', 'device', 'as', 'claimed', 'in', 'claim', 'wherein', 'the', 'completing', 'a', 'payment', 'operation', 'based', 'on', 'the', 'face', 'recognition', 'comprises', 'triggering', 'and', 'performing', 'a', 'payment', 'initiating', 'operation', 'to', 'acquire', 'second', 'face', 'image', 'information', 'based', 'on', 'the', 'face', 'recognition', 'determining', 'whether', 'second', 'characteristic', 'information', 'extracted', 'from', 'the', 'second', 'face', 'image', 'information', 'indicates', 'that', 'the', 'user', 'has', 'a', 'willingness', 'to', 'pay', 'and', 'in', 'response', 'to', 'determining', 'that', 'the', 'second', 'characteristic', 'information', 'indicates', 'that', 'the', 'user', 'has', 'a', 'willingness', 'to', 'pay', 'triggering', 'and', 'performing', 'a', 'payment', 'confirmation', 'operation', 'to', 'complete', 'the', 'payment', 'operation', 'based', 'on', 'payment', 'account', 'information', 'corresponding', 'to', 'the', 'target', 'user', 'the', 'device', 'as', 'claimed', 'in', 'claim', 'wherein', 'the', 'determining', 'whether', 'second', 'characteristic', 'information', 'extracted', 'from', 'the', 'second', 'face', 'image', 'information', 'indicates', 'that', 'the', 'user', 'has', 'a', 'willingness', 'to', 'pay', 'comprises', 'determining', 'whether', 'a', 'current', 'user', 'corresponding', 'to', 'the', 'second', 'face', 'image', 'information', 'is', 'consistent', 'with', 'the', 'target', 'user', 'and', 'in', 'response', 'to', 'determining', 'that', 'the', 'current', 'user', 'is', 'consistent', 'with', 'the', 'target', 'user', 'determining', 'whether', 'the', 'target', 'user', 'has', 'a', 'willingness', 'to', 'pay', 'according', 'to', 'the', 'second', 'characteristic', 'information', 'extracted', 'from', 'the', 'second', 'face', 'image', 'information', 'the', 'device', 'as', 'claimed', 'in', 'claim', 'wherein', 'the', 'extracting', 'first', 'characteristic', 'information', 'from', 'the', 'first', 'face', 'image', 'information', 'comprises', 'determining', 'the', 'head', 'posture', 'information', 'of', 'the', 'target', 'user', 'using', 'a', 'head', 'posture', 'recognition', 'model', 'based', 'on', 'the', 'first', 'face', 'image', 'information', 'and', 'determining', 'the', 'gaze', 'information', 'of', 'the', 'target', 'user', 'using', 'a', 'gaze', 'information', 'recognition', 'model', 'based', 'on', 'characteristics', 'of', 'an', 'eye', 'region', 'in', 'the', 'first', 'face', 'image', 'information', 'the', 'device', 'as', 'claimed', 'in', 'claim', 'wherein', 'the', 'head', 'posture', 'recognition', 'model', 'is', 'obtained', 'through', 'training', 'by', 'acquiring', 'a', 'first', 'sample', 'data', 'set', 'wherein', 'the', 'first', 'sample', 'data', 'set', 'includes', 'a', 'plurality', 'of', 'pieces', 'of', 'first', 'sample', 'data', 'and', 'each', 'of', 'the', 'plurality', 'of', 'pieces', 'of', 'first', 'sample', 'data', 'includes', 'a', 'correspondence', 'between', 'a', 'sample', 'face', 'image', 'and', 'head', 'posture', 'information', 'determining', 'mean', 'image', 'data', 'and', 'variance', 'image', 'data', 'of', 'a', 'plurality', 'of', 'sample', 'face', 'images', 'for', 'each', 'of', 'the', 'plurality', 'of', 'pieces', 'of', 'first', 'sample', 'data', 'preprocessing', 'the', 'sample', 'face', 'image', 'contained', 'in', 'each', 'of', 'the', 'plurality', 'of', 'pieces', 'of', 'first', 'sample', 'data', 'based', 'on', 'the', 'mean', 'image', 'data', 'and', 'the', 'variance', 'image', 'data', 'to', 'obtain', 'a', 'preprocessed', 'sample', 'face', 'image', 'setting', 'the', 'preprocessed', 'sample', 'face', 'image', 'and', 'the', 'corresponding', 'head', 'posture', 'information', 'as', 'a', 'first', 'model', 'training', 'sample', 'and', 'performing', 'training', 'using', 'a', 'machine', 'learning', 'method', 'and', 'based', 'on', 'a', 'plurality', 'of', 'first', 'model', 'training', 'samples', 'to', 'obtain', 'the', 'head', 'posture', 'recognition', 'model', 'the', 'device', 'as', 'claimed', 'in', 'claim', 'wherein', 'the', 'gaze', 'information', 'recognition', 'model', 'is', 'obtained', 'through', 'training', 'by', 'acquiring', 'a', 'second', 'sample', 'data', 'set', 'wherein', 'the', 'second', 'sample', 'data', 'set', 'includes', 'a', 'plurality', 'of', 'pieces', 'of', 'second', 'sample', 'data', 'and', 'each', 'of', 'the', 'plurality', 'of', 'pieces', 'of', 'second', 'sample', 'data', 'includes', 'a', 'correspondence', 'between', 'a', 'sample', 'eye', 'image', 'and', 'gaze', 'information', 'determining', 'mean', 'image', 'data', 'and', 'variance', 'image', 'data', 'of', 'a', 'plurality', 'of', 'sample', 'eye', 'images', 'for', 'each', 'of', 'the', 'plurality', 'of', 'pieces', 'of', 'second', 'sample', 'data', 'preprocessing', 'the', 'sample', 'eye', 'image', 'contained', 'in', 'each', 'of', 'the', 'plurality', 'of', 'pieces', 'of', 'second', 'sample', 'data', 'based', 'on', 'the', 'mean', 'image', 'data', 'and', 'the', 'variance', 'image', 'data', 'to', 'obtain', 'a', 'preprocessed', 'sample', 'eye', 'image', 'setting', 'the', 'preprocessed', 'sample', 'eye', 'image', 'and', 'the', 'corresponding', 'gaze', 'information', 'as', 'a', 'second', 'model', 'training', 'sample', 'and', 'performing', 'training', 'using', 'a', 'machine', 'learning', 'method', 'and', 'on', 'a', 'plurality', 'of', 'second', 'model', 'training', 'samples', 'to', 'obtain', 'the', 'gaze', 'information', 'recognition', 'model', 'the', 'device', 'as', 'claimed', 'in', 'claim', 'wherein', 'the', 'angle', 'of', 'rotation', 'in', 'each', 'preset', 'direction', 'comprises', 'a', 'pitch', 'angle', 'a', 'yaw', 'angle', 'and', 'a', 'roll', 'angle', 'wherein', 'the', 'pitch', 'angle', 'refers', 'to', 'an', 'angle', 'of', 'rotation', 'around', 'a', 'x-axis', 'the', 'yaw', 'angle', 'refers', 'to', 'an', 'angle', 'of', 'rotation', 'around', 'a', 'y-axis', 'and', 'the', 'roll', 'angle', 'refers', 'to', 'an', 'angle', 'of', 'rotation', 'around', 'a', 'z-axis', 'a', 'non-transitory', 'computer-readable', 'storage', 'medium', 'for', 'a', 'payment', 'based', 'on', 'a', 'face', 'recognition', 'configured', 'with', 'instructions', 'executable', 'by', 'one', 'or', 'more', 'processors', 'to', 'cause', 'the', 'one', 'or', 'more', 'processors', 'to', 'perform', 'operations', 'comprising', 'acquiring', 'first', 'face', 'image', 'information', 'of', 'a', 'target', 'user', 'extracting', 'first', 'characteristic', 'information', 'from', 'the', 'first', 'face', 'image', 'information', 'wherein', 'the', 'first', 'characteristic', 'information', 'includes', 'head', 'posture', 'information', 'of', 'the', 'target', 'user', 'and', 'gaze', 'information', 'of', 'the', 'target', 'user', 'determining', 'whether', 'the', 'target', 'user', 'has', 'a', 'willingness', 'to', 'pay', 'according', 'to', 'the', 'head', 'posture', 'information', 'of', 'the', 'target', 'user', 'and', 'the', 'gaze', 'information', 'of', 'the', 'target', 'user', 'including', 'determining', 'whether', 'an', 'angle', 'of', 'rotation', 'in', 'each', 'preset', 'direction', 'is', 'less', 'than', 'an', 'angle', 'threshold', 'wherein', 'the', 'head', 'posture', 'information', 'includes', 'the', 'angle', 'of', 'rotation', 'in', 'each', 'preset', 'direction', 'determining', 'whether', 'a', 'probability', 'value', 'that', 'a', 'user', 'gazes', 'at', 'a', 'payment', 'screen', 'is', 'greater', 'than', 'a', 'probability', 'threshold', 'wherein', 'the', 'gaze', 'information', 'includes', 'the', 'probability', 'value', 'that', 'a', 'user', 'gazes', 'at', 'a', 'payment', 'screen', 'and', 'in', 'response', 'to', 'determining', 'that', 'the', 'angle', 'of', 'rotation', 'in', 'each', 'preset', 'direction', 'is', 'less', 'than', 'the', 'angle', 'threshold', 'and', 'that', 'the', 'probability', 'value', 'that', 'a', 'user', 'gazes', 'at', 'a', 'payment', 'screen', 'is', 'greater', 'than', 'the', 'probability', 'threshold', 'determining', 'that', 'the', 'target', 'user', 'has', 'a', 'willingness', 'to', 'pay', 'and', 'in', 'response', 'to', 'determining', 'that', 'the', 'target', 'user', 'has', 'a', 'willingness', 'to', 'pay', 'completing', 'a', 'payment', 'operation', 'based', 'on', 'the', 'face', 'recognition', 'the', 'storage', 'medium', 'as', 'claimed', 'in', 'claim', 'wherein', 'the', 'completing', 'a', 'payment', 'operation', 'based', 'on', 'the', 'face', 'recognition', 'comprises', 'triggering', 'and', 'performing', 'a', 'payment', 'initiating', 'operation', 'to', 'acquire', 'second', 'face', 'image', 'information', 'based', 'on', 'the', 'face', 'recognition', 'determining', 'whether', 'second', 'characteristic', 'information', 'extracted', 'from', 'the', 'second', 'face', 'image', 'information', 'indicates', 'that', 'the', 'user', 'has', 'a', 'willingness', 'to', 'pay', 'and', 'in', 'response', 'to', 'determining', 'that', 'the', 'second', 'characteristic', 'information', 'indicates', 'that', 'the', 'user', 'has', 'a', 'willingness', 'to', 'pay', 'triggering', 'and', 'performing', 'a', 'payment', 'confirmation', 'operation', 'to', 'complete', 'the', 'payment', 'operation', 'based', 'on', 'payment', 'account', 'information', 'corresponding', 'to', 'the', 'target', 'user', 'the', 'storage', 'medium', 'as', 'claimed', 'in', 'claim', 'wherein', 'the', 'determining', 'whether', 'second', 'characteristic', 'information', 'extracted', 'from', 'the', 'second', 'face', 'image', 'information', 'indicates', 'that', 'the', 'user', 'has', 'a', 'willingness', 'to', 'pay', 'comprises', 'determining', 'whether', 'a', 'current', 'user', 'corresponding', 'to', 'the', 'second', 'face', 'image', 'information', 'is', 'consistent', 'with', 'the', 'target', 'user', 'and', 'in', 'response', 'to', 'determining', 'that', 'the', 'current', 'user', 'is', 'consistent', 'with', 'the', 'target', 'user', 'determining', 'whether', 'the', 'target', 'user', 'has', 'a', 'willingness', 'to', 'pay', 'according', 'to', 'the', 'second', 'characteristic', 'information', 'extracted', 'from', 'the', 'second', 'face', 'image', 'information', 'the', 'storage', 'medium', 'as', 'claimed', 'in', 'claim', 'wherein', 'the', 'extracting', 'first', 'characteristic', 'information', 'from', 'the', 'first', 'face', 'image', 'information', 'comprises', 'determining', 'the', 'head', 'posture', 'information', 'of', 'the', 'target', 'user', 'using', 'a', 'head', 'posture', 'recognition', 'model', 'based', 'on', 'the', 'first', 'face', 'image', 'information', 'and', 'determining', 'the', 'gaze', 'information', 'of', 'the', 'target', 'user', 'using', 'a', 'gaze', 'information', 'recognition', 'model', 'based', 'on', 'characteristics', 'of', 'an', 'eye', 'region', 'in', 'the', 'first', 'face', 'image', 'information', 'the', 'storage', 'medium', 'as', 'claimed', 'in', 'claim', 'wherein', 'the', 'head', 'posture', 'recognition', 'model', 'is', 'obtained', 'through', 'training', 'by', 'acquiring', 'a', 'first', 'sample', 'data', 'set', 'wherein', 'the', 'first', 'sample', 'data', 'set', 'includes', 'a', 'plurality', 'of', 'pieces', 'of', 'first', 'sample', 'data', 'and', 'each', 'of', 'the', 'plurality', 'of', 'pieces', 'of', 'first', 'sample', 'data', 'includes', 'a', 'correspondence', 'between', 'a', 'sample', 'face', 'image', 'and', 'head', 'posture', 'information', 'determining', 'mean', 'image', 'data', 'and', 'variance', 'image', 'data', 'of', 'a', 'plurality', 'of', 'sample', 'face', 'images', 'for', 'each', 'of', 'the', 'plurality', 'of', 'pieces', 'of', 'first', 'sample', 'data', 'preprocessing', 'the', 'sample', 'face', 'image', 'contained', 'in', 'each', 'of', 'the', 'plurality', 'of', 'pieces', 'of', 'first', 'sample', 'data', 'based', 'on', 'the', 'mean', 'image', 'data', 'and', 'the', 'variance', 'image', 'data', 'to', 'obtain', 'a', 'preprocessed', 'sample', 'face', 'image', 'setting', 'the', 'preprocessed', 'sample', 'face', 'image', 'and', 'the', 'corresponding', 'head', 'posture', 'information', 'as', 'a', 'first', 'model', 'training', 'sample', 'and', 'performing', 'training', 'using', 'a', 'machine', 'learning', 'method', 'and', 'based', 'on', 'a', 'plurality', 'of', 'first', 'model', 'training', 'samples', 'to', 'obtain', 'the', 'head', 'posture', 'recognition', 'model', 'and', 'wherein', 'the', 'gaze', 'information', 'recognition', 'model', 'is', 'obtained', 'through', 'training', 'by', 'acquiring', 'a', 'second', 'sample', 'data', 'set', 'wherein', 'the', 'second', 'sample', 'data', 'set', 'includes', 'a', 'plurality', 'of', 'pieces', 'of', 'second', 'sample', 'data', 'and', 'each', 'of', 'the', 'plurality', 'of', 'pieces', 'of', 'second', 'sample', 'data', 'includes', 'a', 'correspondence', 'between', 'a', 'sample', 'eye', 'image', 'and', 'gaze', 'information', 'determining', 'mean', 'image', 'data', 'and', 'variance', 'image', 'data', 'of', 'a', 'plurality', 'of', 'sample', 'eye', 'images', 'for', 'each', 'of', 'the', 'plurality', 'of', 'pieces', 'of', 'second', 'sample', 'data', 'preprocessing', 'the', 'sample', 'eye', 'image', 'contained', 'in', 'each', 'of', 'the', 'plurality', 'of', 'pieces', 'of', 'second', 'sample', 'data', 'based', 'on', 'the', 'mean', 'image', 'data', 'and', 'the', 'variance', 'image', 'data', 'to', 'obtain', 'a', 'preprocessed', 'sample', 'eye', 'image', 'setting', 'the', 'preprocessed', 'sample', 'eye', 'image', 'and', 'the', 'corresponding', 'gaze', 'information', 'as', 'a', 'second', 'model', 'training', 'sample', 'and', 'performing', 'training', 'using', 'a', 'machine', 'learning', 'method', 'and', 'based', 'on', 'a', 'plurality', 'of', 'second', 'model', 'training', 'samples', 'to', 'obtain', 'the', 'gaze', 'information', 'recognition', 'model', 'the', 'storage', 'medium', 'as', 'claimed', 'in', 'claim', 'wherein', 'the', 'angle', 'of', 'rotation', 'in', 'each', 'preset', 'direction', 'comprises', 'a', 'pitch', 'angle', 'a', 'yaw', 'angle', 'and', 'a', 'roll', 'angle', 'wherein', 'the', 'pitch', 'angle', 'refers', 'to', 'an', 'angle', 'of', 'rotation', 'around', 'a', 'x-axis', 'the', 'yaw', 'angle', 'refers', 'to', 'an', 'angle', 'of', 'rotation', 'around', 'a', 'y-axis', 'and', 'the', 'roll', 'angle', 'refers', 'to', 'an', 'angle', 'of', 'rotation', 'around', 'a', 'z-axis', 'a', 'method', 'comprising', 'detecting', 'by', 'a', 'motion', 'detection', 'module', 'a', 'motion', 'by', 'a', 'subject', 'within', 'a', 'predetermined', 'area', 'of', 'view', 'assigning', 'a', 'unique', 'session', 'identification', 'number', 'to', 'the', 'subject', 'detected', 'within', 'a', 'predetermined', 'area', 'of', 'view', 'detecting', 'a', 'facial', 'area', 'of', 'the', 'subject', 'detected', 'within', 'a', 'predetermined', 'area', 'of', 'view', 'generating', 'an', 'image', 'of', 'the', 'facial', 'area', 'of', 'the', 'subject', 'assessing', 'a', 'quality', 'of', 'the', 'image', 'of', 'the', 'facial', 'area', 'of', 'the', 'subject', 'determining', 'an', 'identity', 'of', 'the', 'subject', 'based', 'on', 'the', 'image', 'of', 'the', 'facial', 'area', 'of', 'the', 'subject', 'identifying', 'an', 'intent', 'of', 'the', 'subject', 'and', 'authorizing', 'access', 'to', 'a', 'point', 'of', 'entry', 'based', 'on', 'the', 'determined', 'identity', 'of', 'the', 'subject', 'and', 'based', 'on', 'the', 'intent', 'of', 'the', 'subject', 'the', 'method', 'of', 'claim', 'further', 'comprising', 'determining', 'one', 'or', 'more', 'additional', 'subjects', 'within', 'the', 'predetermined', 'area', 'of', 'view', 'and', 'assigning', 'a', 'unique', 'session', 'identification', 'number', 'to', 'each', 'of', 'the', 'one', 'or', 'more', 'additional', 'subjects', 'detected', 'within', 'a', 'predetermined', 'area', 'of', 'view', 'the', 'method', 'of', 'claim', 'wherein', 'the', 'assessing', 'a', 'quality', 'of', 'the', 'image', 'of', 'the', 'facial', 'area', 'of', 'the', 'subject', 'comprises', 'assessing', 'whether', 'the', 'quality', 'of', 'the', 'image', 'of', 'the', 'facial', 'area', 'of', 'the', 'object', 'equates', 'predetermined', 'metric', 'of', 'quality', 'and', 'upon', 'determining', 'that', 'the', 'quality', 'of', 'the', 'image', 'of', 'the', 'facial', 'area', 'of', 'the', 'object', 'is', 'inferior', 'to', 'the', 'predetermined', 'metric', 'of', 'quality', 'discarding', 'the', 'image', 'of', 'the', 'facial', 'area', 'of', 'the', 'subject', 'and', 'generating', 'a', 'second', 'image', 'of', 'the', 'facial', 'area', 'of', 'the', 'subject', 'the', 'method', 'of', 'claim', 'further', 'comprising', 'detecting', 'whether', 'the', 'facial', 'area', 'of', 'the', 'subject', 'is', 'photographic', 'image', 'and', 'upon', 'detecting', 'that', 'the', 'facial', 'area', 'of', 'the', 'subject', 'is', 'a', 'photographic', 'image', 'generating', 'a', 'warning', 'and', 'restrict', 'access', 'to', 'the', 'point', 'of', 'entry', 'the', 'method', 'of', 'claim', 'further', 'comprising', 'conducing', 'an', 'incremental', 'training', 'of', 'the', 'image', 'of', 'the', 'facial', 'area', 'of', 'the', 'subject', 'the', 'method', 'of', 'claim', 'wherein', 'conducing', 'an', 'incremental', 'training', 'of', 'the', 'image', 'of', 'the', 'facial', 'area', 'of', 'the', 'subject', 'comprises', 'capturing', 'a', 'first', 'image', 'of', 'the', 'facial', 'area', 'having', 'facial', 'landmarks', 'converting', 'the', 'first', 'image', 'of', 'the', 'facial', 'area', 'into', 'a', 'first', 'numeric', 'vector', 'capturing', 'a', 'second', 'image', 'of', 'the', 'facial', 'area', 'having', 'facial', 'landmarks', 'converting', 'the', 'second', 'image', 'of', 'the', 'facial', 'area', 'into', 'a', 'second', 'numeric', 'vector', 'calculating', 'a', 'weighted', 'mean', 'of', 'the', 'first', 'numeric', 'vector', 'and', 'the', 'second', 'numeric', 'vector', 'wherein', 'the', 'weighted', 'mean', 'represents', 'a', 'change', 'in', 'a', 'facial', 'area', 'and', 'storing', 'the', 'weighted', 'mean', 'in', 'the', 'database', 'the', 'method', 'of', 'claim', 'wherein', 'determining', 'an', 'identity', 'of', 'the', 'subject', 'based', 'on', 'the', 'image', 'of', 'the', 'facial', 'area', 'of', 'the', 'subject', 'comprises', 'comparing', 'the', 'image', 'of', 'the', 'facial', 'area', 'of', 'the', 'subject', 'with', 'a', 'plurality', 'of', 'images', 'stored', 'in', 'a', 'database', 'and', 'authenticating', 'the', 'subject', 'the', 'method', 'of', 'claim', 'wherein', 'identifying', 'an', 'intent', 'of', 'the', 'subject', 'comprises', 'upon', 'detecting', 'the', 'facial', 'area', 'in', 'a', 'bounding', 'box', 'commencing', 'authentication', 'of', 'the', 'subject', 'calculating', 'a', 'directional', 'vector', 'of', 'a', 'face', 'of', 'the', 'subject', 'determine', 'an', 'intent', 'of', 'the', 'subject', 'to', 'gain', 'access', 'to', 'the', 'point', 'of', 'entry', 'based', 'on', 'the', 'directional', 'vector', 'of', 'the', 'face', 'of', 'the', 'subject', 'granting', 'the', 'access', 'to', 'the', 'point', 'of', 'entry', 'based', 'on', 'authentication', 'of', 'the', 'subject', 'and', 'based', 'on', 'determining', 'the', 'intent', 'of', 'the', 'subject', 'a', 'non-transitory', 'computer', 'readable', 'medium', 'having', 'program', 'instructions', 'stored', 'thereon', 'that', 'in', 'response', 'to', 'execution', 'by', 'a', 'computing', 'device', 'cause', 'the', 'computing', 'device', 'to', 'perform', 'operations', 'comprising', 'detecting', 'a', 'motion', 'by', 'a', 'subject', 'within', 'a', 'predetermined', 'area', 'of', 'view', 'assigning', 'a', 'unique', 'session', 'identification', 'number', 'to', 'the', 'subject', 'detected', 'within', 'a', 'predetermined', 'area', 'of', 'view', 'detecting', 'a', 'facial', 'area', 'of', 'the', 'subject', 'detected', 'within', 'a', 'predetermined', 'area', 'of', 'view', 'generating', 'an', 'image', 'of', 'the', 'facial', 'area', 'of', 'the', 'subject', 'assessing', 'a', 'quality', 'of', 'the', 'image', 'of', 'the', 'facial', 'area', 'of', 'the', 'subject', 'determining', 'an', 'identity', 'of', 'the', 'subject', 'based', 'on', 'the', 'image', 'of', 'the', 'facial', 'area', 'of', 'the', 'subject', 'identifying', 'an', 'intent', 'of', 'the', 'subject', 'and', 'authorizing', 'access', 'to', 'a', 'point', 'of', 'entry', 'based', 'on', 'the', 'determined', 'identity', 'of', 'the', 'subject', 'and', 'based', 'on', 'the', 'intent', 'of', 'the', 'subject', 'the', 'non-transitory', 'computer', 'readable', 'medium', 'of', 'claim', 'further', 'comprising', 'determining', 'one', 'or', 'more', 'additional', 'subjects', 'within', 'the', 'predetermined', 'area', 'of', 'view', 'and', 'assigning', 'a', 'unique', 'session', 'identification', 'number', 'to', 'each', 'of', 'the', 'one', 'or', 'more', 'additional', 'subjects', 'detected', 'within', 'a', 'predetermined', 'area', 'of', 'view', 'the', 'non-transitory', 'computer', 'readable', 'medium', 'of', 'claim', 'wherein', 'the', 'assessing', 'a', 'quality', 'of', 'the', 'image', 'of', 'the', 'facial', 'area', 'of', 'the', 'subject', 'comprises', 'assessing', 'whether', 'the', 'quality', 'of', 'the', 'image', 'of', 'the', 'facial', 'area', 'of', 'the', 'object', 'equates', 'predetermined', 'metric', 'of', 'quality', 'and', 'upon', 'determining', 'that', 'the', 'quality', 'of', 'the', 'image', 'of', 'the', 'facial', 'area', 'of', 'the', 'object', 'is', 'inferior', 'to', 'the', 'predetermined', 'metric', 'of', 'quality', 'discarding', 'the', 'image', 'of', 'the', 'facial', 'area', 'of', 'the', 'subject', 'and', 'generating', 'a', 'second', 'image', 'of', 'the', 'facial', 'area', 'of', 'the', 'subject', 'the', 'non-transitory', 'computer', 'readable', 'medium', 'of', 'claim', 'further', 'comprising', 'detecting', 'whether', 'the', 'facial', 'area', 'of', 'the', 'subject', 'is', 'photographic', 'image', 'and', 'upon', 'detecting', 'that', 'the', 'facial', 'area', 'of', 'the', 'subject', 'is', 'a', 'photographic', 'image', 'generating', 'a', 'warning', 'and', 'restrict', 'access', 'to', 'the', 'access', 'point', 'the', 'non-transitory', 'computer', 'readable', 'medium', 'of', 'claim', 'further', 'comprising', 'conducing', 'an', 'incremental', 'training', 'of', 'the', 'image', 'of', 'the', 'facial', 'area', 'of', 'the', 'subject', 'the', 'non-transitory', 'computer', 'readable', 'medium', 'of', 'claim', 'wherein', 'conducing', 'an', 'incremental', 'training', 'of', 'the', 'image', 'of', 'the', 'facial', 'area', 'of', 'the', 'subject', 'comprises', 'capturing', 'a', 'first', 'image', 'of', 'the', 'facial', 'area', 'having', 'facial', 'landmarks', 'converting', 'the', 'first', 'image', 'of', 'the', 'facial', 'area', 'into', 'a', 'first', 'numeric', 'vector', 'capturing', 'a', 'second', 'image', 'of', 'the', 'facial', 'area', 'having', 'facial', 'landmarks', 'converting', 'the', 'second', 'image', 'of', 'the', 'facial', 'area', 'into', 'a', 'second', 'numeric', 'vector', 'calculating', 'a', 'weighted', 'mean', 'of', 'the', 'first', 'numeric', 'vector', 'and', 'the', 'second', 'numeric', 'vector', 'wherein', 'the', 'weighted', 'mean', 'represents', 'a', 'change', 'in', 'a', 'facial', 'area', 'and', 'storing', 'the', 'weighted', 'mean', 'in', 'the', 'database', 'an', 'apparatus', 'for', 'face', 'recognition', 'comprising', 'a', 'processor', 'and', 'a', 'memory', 'to', 'store', 'computer', 'program', 'instructions', 'the', 'computer', 'program', 'instructions', 'when', 'executed', 'on', 'the', 'processor', 'cause', 'the', 'processor', 'to', 'perform', 'operations', 'comprising', 'detecting', 'a', 'motion', 'by', 'a', 'subject', 'within', 'a', 'predetermined', 'area', 'of', 'view', 'assigning', 'a', 'unique', 'session', 'identification', 'number', 'to', 'the', 'subject', 'detected', 'within', 'a', 'predetermined', 'area', 'of', 'view', 'detecting', 'a', 'facial', 'area', 'of', 'the', 'subject', 'detected', 'within', 'a', 'predetermined', 'area', 'of', 'view', 'generating', 'an', 'image', 'of', 'the', 'facial', 'area', 'of', 'the', 'subject', 'assessing', 'a', 'quality', 'of', 'the', 'image', 'of', 'the', 'facial', 'area', 'of', 'the', 'subject', 'determining', 'an', 'identity', 'of', 'the', 'subject', 'based', 'on', 'the', 'image', 'of', 'the', 'facial', 'area', 'of', 'the', 'subject', 'identifying', 'an', 'intent', 'of', 'the', 'subject', 'and', 'authorizing', 'access', 'to', 'a', 'point', 'of', 'entry', 'based', 'on', 'the', 'determined', 'identity', 'of', 'the', 'subject', 'and', 'based', 'on', 'the', 'intent', 'of', 'the', 'subject', 'the', 'apparatus', 'of', 'claim', 'further', 'comprising', 'determining', 'one', 'or', 'more', 'additional', 'subjects', 'within', 'the', 'predetermined', 'area', 'of', 'view', 'and', 'assigning', 'a', 'unique', 'session', 'identification', 'number', 'to', 'each', 'of', 'the', 'one', 'or', 'more', 'additional', 'subjects', 'detected', 'within', 'a', 'predetermined', 'area', 'of', 'view', 'the', 'apparatus', 'of', 'claim', 'wherein', 'the', 'assessing', 'a', 'quality', 'of', 'the', 'image', 'of', 'the', 'facial', 'area', 'of', 'the', 'subject', 'comprises', 'assessing', 'whether', 'the', 'quality', 'of', 'the', 'image', 'of', 'the', 'facial', 'area', 'of', 'the', 'object', 'equates', 'predetermined', 'metric', 'of', 'quality', 'and', 'upon', 'determining', 'that', 'the', 'quality', 'of', 'the', 'image', 'of', 'the', 'facial', 'area', 'of', 'the', 'object', 'is', 'inferior', 'to', 'the', 'predetermined', 'metric', 'of', 'quality', 'discarding', 'the', 'image', 'of', 'the', 'facial', 'area', 'of', 'the', 'subject', 'and', 'generating', 'a', 'second', 'image', 'of', 'the', 'facial', 'area', 'of', 'the', 'subject', 'the', 'apparatus', 'of', 'claim', 'further', 'comprising', 'detecting', 'whether', 'the', 'facial', 'area', 'of', 'the', 'subject', 'is', 'photographic', 'image', 'and', 'upon', 'detecting', 'that', 'the', 'facial', 'area', 'of', 'the', 'subject', 'is', 'a', 'photographic', 'image', 'generating', 'a', 'warning', 'and', 'restrict', 'access', 'to', 'the', 'access', 'point', 'the', 'apparatus', 'of', 'claim', 'further', 'comprising', 'conducing', 'an', 'incremental', 'training', 'of', 'the', 'image', 'of', 'the', 'facial', 'area', 'of', 'the', 'subject', 'the', 'apparatus', 'of', 'claim', 'wherein', 'conducing', 'an', 'incremental', 'training', 'of', 'the', 'image', 'of', 'the', 'facial', 'area', 'of', 'the', 'subject', 'comprises', 'capturing', 'a', 'first', 'image', 'of', 'the', 'facial', 'area', 'having', 'facial', 'landmarks', 'converting', 'the', 'first', 'image', 'of', 'the', 'facial', 'area', 'into', 'a', 'first', 'numeric', 'vector', 'capturing', 'a', 'second', 'image', 'of', 'the', 'facial', 'area', 'having', 'facial', 'landmarks', 'converting', 'the', 'second', 'image', 'of', 'the', 'facial', 'area', 'into', 'a', 'second', 'numeric', 'vector', 'calculating', 'a', 'weighted', 'mean', 'of', 'the', 'first', 'numeric', 'vector', 'and', 'the', 'second', 'numeric', 'vector', 'wherein', 'the', 'weighted', 'mean', 'represents', 'a', 'change', 'in', 'a', 'facial', 'area', 'and', 'storing', 'the', 'weighted', 'mean', 'in', 'the', 'database', 'a', 'robot', 'comprising', 'a', 'body', 'configured', 'to', 'rotate', 'and', 'to', 'tilt', 'a', 'camera', 'coupled', 'to', 'the', 'body', 'and', 'configured', 'to', 'rotate', 'and', 'tilt', 'according', 'to', 'the', 'rotate', 'and', 'the', 'tilt', 'of', 'the', 'body', 'wherein', 'the', 'camera', 'is', 'configured', 'to', 'acquire', 'a', 'video', 'of', 'a', 'space', 'a', 'face', 'recognition', 'unit', 'configured', 'to', 'recognize', 'respective', 'faces', 'of', 'one', 'or', 'more', 'persons', 'in', 'the', 'video', 'a', 'tracking', 'unit', 'configured', 'to', 'track', 'motion', 'of', 'each', 'of', 'the', 'recognized', 'faces', 'of', 'the', 'one', 'or', 'more', 'persons', 'and', 'a', 'controller', 'configured', 'to', 'calculate', 'a', 'respective', 'size', 'of', 'each', 'of', 'the', 'faces', 'of', 'the', 'one', 'or', 'more', 'persons', 'select', 'a', 'first', 'person', 'from', 'among', 'the', 'one', 'or', 'more', 'persons', 'based', 'on', 'the', 'calculated', 'sizes', 'of', 'the', 'faces', 'and', 'control', 'at', 'least', 'one', 'of', 'a', 'direction', 'of', 'the', 'rotation', 'of', 'the', 'camera', 'an', 'angle', 'of', 'the', 'tilt', 'of', 'the', 'camera', 'and', 'a', 'focal', 'distance', 'of', 'the', 'camera', 'based', 'on', 'the', 'tracked', 'motion', 'of', 'the', 'recognized', 'face', 'of', 'the', 'first', 'person', 'the', 'robot', 'of', 'claim', 'wherein', 'the', 'controller', 'is', 'configured', 'to', 'control', 'the', 'direction', 'of', 'the', 'rotation', 'of', 'the', 'camera', 'and', 'the', 'angle', 'of', 'the', 'tilt', 'of', 'the', 'camera', 'to', 'achieve', 'an', 'particular', 'orientation', 'of', 'the', 'camera', 'relative', 'to', 'the', 'face', 'of', 'the', 'first', 'person', 'and', 'control', 'a', 'focal', 'distance', 'of', 'the', 'camera', 'by', 'comparing', 'respective', 'sizes', 'of', 'the', 'face', 'of', 'the', 'first', 'person', 'before', 'and', 'after', 'motion', 'of', 'the', 'first', 'person', 'the', 'robot', 'of', 'claim', 'wherein', 'the', 'particular', 'orientation', 'occurs', 'when', 'the', 'camera', 'faces', 'a', 'general', 'direction', 'of', 'the', 'face', 'of', 'the', 'first', 'person', 'the', 'robot', 'of', 'claim', 'wherein', 'the', 'controller', 'is', 'configured', 'to', 'normalize', 'sizes', 'of', 'the', 'faces', 'of', 'the', 'one', 'or', 'more', 'persons', 'based', 'on', 'an', 'interocular', 'distance', 'and', 'select', 'the', 'first', 'person', 'based', 'on', 'the', 'normalized', 'sizes', 'of', 'the', 'faces', 'of', 'the', 'one', 'or', 'more', 'persons', 'the', 'robot', 'of', 'claim', 'wherein', 'the', 'controller', 'is', 'configured', 'to', 'select', 'a', 'person', 'having', 'a', 'largest', 'face', 'size', 'from', 'among', 'the', 'one', 'or', 'more', 'persons', 'as', 'the', 'first', 'person', 'the', 'robot', 'of', 'claim', 'further', 'comprising', 'a', 'microphone', 'configured', 'to', 'receive', 'a', 'spoken', 'audio', 'that', 'is', 'present', 'in', 'the', 'space', 'wherein', 'the', 'controller', 'is', 'further', 'configured', 'to', 'select', 'the', 'first', 'person', 'further', 'based', 'on', 'the', 'received', 'spoken', 'audio', 'the', 'robot', 'of', 'claim', 'wherein', 'the', 'controller', 'is', 'further', 'configured', 'to', 'control', 'gain', 'of', 'the', 'microphone', 'by', 'comparing', 'respective', 'sizes', 'of', 'the', 'face', 'of', 'the', 'first', 'person', 'before', 'and', 'after', 'motion', 'of', 'the', 'first', 'person', 'the', 'robot', 'of', 'claim', 'wherein', 'the', 'controller', 'is', 'configured', 'to', 'calculate', 'a', 'position', 'from', 'which', 'the', 'spoken', 'audio', 'is', 'provided', 'and', 'select', 'the', 'first', 'person', 'further', 'based', 'on', 'whether', 'the', 'one', 'or', 'more', 'persons', 'are', 'in', 'the', 'position', 'from', 'which', 'the', 'voice', 'signal', 'is', 'provided', 'the', 'robot', 'of', 'claim', 'wherein', 'the', 'controller', 'is', 'configured', 'to', 'select', 'a', 'second', 'person', 'as', 'the', 'first', 'person', 'from', 'among', 'the', 'one', 'or', 'more', 'persons', 'when', 'the', 'second', 'person', 'is', 'located', 'in', 'the', 'position', 'from', 'which', 'the', 'spoken', 'audio', 'is', 'provided', 'the', 'robot', 'of', 'claim', 'wherein', 'the', 'controller', 'is', 'configured', 'to', 'select', 'a', 'second', 'person', 'having', 'a', 'largest', 'face', 'size', 'as', 'the', 'first', 'person', 'from', 'among', 'the', 'one', 'or', 'more', 'persons', 'when', 'none', 'of', 'the', 'one', 'or', 'more', 'persons', 'is', 'located', 'in', 'the', 'position', 'from', 'which', 'the', 'spoken', 'audio', 'is', 'provided', 'the', 'robot', 'of', 'claim', 'wherein', 'the', 'controller', 'is', 'configured', 'to', 'select', 'a', 'second', 'person', 'having', 'a', 'largest', 'face', 'size', 'as', 'the', 'first', 'person', 'from', 'among', 'the', 'one', 'or', 'more', 'persons', 'when', 'a', 'plurality', 'of', 'persons', 'from', 'among', 'the', 'one', 'or', 'more', 'persons', 'are', 'located', 'in', 'the', 'position', 'from', 'which', 'the', 'spoken', 'audio', 'is', 'provided', 'the', 'robot', 'of', 'claim', 'further', 'comprising', 'a', 'speaker', 'wherein', 'the', 'controller', 'is', 'configured', 'to', 'control', 'volume', 'of', 'the', 'speaker', 'by', 'comparing', 'respective', 'sizes', 'of', 'the', 'face', 'of', 'the', 'first', 'person', 'before', 'and', 'after', 'motion', 'of', 'the', 'first', 'person', 'the', 'robot', 'of', 'claim', 'wherein', 'the', 'body', 'is', 'further', 'configured', 'to', 'rotate', 'in', 'a', 'lateral', 'direction', 'and', 'to', 'tilt', 'in', 'an', 'vertical', 'direction', 'an', 'electronic', 'device', 'comprising', 'a', 'camera', 'coupled', 'to', 'the', 'body', 'and', 'configured', 'to', 'rotate', 'and', 'to', 'tilt', 'wherein', 'the', 'camera', 'is', 'configured', 'to', 'acquire', 'a', 'video', 'of', 'a', 'space', 'within', 'which', 'one', 'or', 'more', 'persons', 'are', 'positioned', 'and', 'a', 'processor', 'configured', 'to', 'recognize', 'respective', 'faces', 'of', 'the', 'one', 'or', 'more', 'persons', 'in', 'the', 'video', 'track', 'motion', 'of', 'each', 'of', 'the', 'recognized', 'faces', 'of', 'the', 'one', 'or', 'more', 'persons', 'calculate', 'a', 'respective', 'size', 'of', 'each', 'of', 'the', 'faces', 'of', 'the', 'one', 'or', 'more', 'persons', 'select', 'a', 'first', 'person', 'from', 'among', 'the', 'one', 'or', 'more', 'persons', 'based', 'on', 'the', 'calculated', 'sizes', 'of', 'the', 'faces', 'and', 'control', 'at', 'least', 'one', 'of', 'a', 'direction', 'of', 'the', 'rotation', 'of', 'the', 'camera', 'an', 'angle', 'of', 'the', 'tilt', 'of', 'the', 'camera', 'and', 'a', 'focal', 'distance', 'of', 'the', 'camera', 'based', 'on', 'the', 'tracked', 'motion', 'of', 'the', 'recognized', 'face', 'of', 'the', 'first', 'person', 'a', 'method', 'comprising', 'acquiring', 'by', 'a', 'camera', 'a', 'video', 'of', 'a', 'space', 'within', 'which', 'one', 'or', 'more', 'persons', 'are', 'positioned', 'recognizing', 'respective', 'faces', 'of', 'the', 'one', 'or', 'more', 'persons', 'in', 'the', 'video', 'tracking', 'motion', 'of', 'each', 'of', 'the', 'recognized', 'faces', 'of', 'the', 'one', 'or', 'more', 'persons', 'calculating', 'a', 'respective', 'size', 'of', 'each', 'of', 'the', 'faces', 'of', 'the', 'one', 'or', 'more', 'persons', 'selecting', 'a', 'first', 'person', 'from', 'among', 'the', 'one', 'or', 'more', 'persons', 'based', 'on', 'the', 'calculated', 'sizes', 'of', 'the', 'faces', 'and', 'controlling', 'at', 'least', 'one', 'of', 'a', 'direction', 'of', 'rotation', 'of', 'the', 'camera', 'an', 'angle', 'of', 'tilt', 'of', 'the', 'camera', 'and', 'a', 'focal', 'distance', 'of', 'the', 'camera', 'based', 'on', 'the', 'tracked', 'motion', 'of', 'the', 'recognized', 'face', 'of', 'the', 'first', 'person', 'a', 'method', 'of', 'inferring', 'topics', 'from', 'a', 'multimodal', 'file', 'the', 'method', 'comprising', 'receiving', 'a', 'multimodal', 'file', 'extracting', 'a', 'set', 'of', 'entities', 'from', 'the', 'multimodal', 'file', 'linking', 'the', 'set', 'of', 'entities', 'to', 'produce', 'a', 'set', 'of', 'linked', 'entities', 'obtaining', 'reference', 'information', 'for', 'the', 'set', 'of', 'entities', 'based', 'at', 'least', 'on', 'the', 'reference', 'information', 'generating', 'a', 'graph', 'of', 'the', 'set', 'of', 'linked', 'entities', 'the', 'graph', 'comprising', 'nodes', 'and', 'edges', 'based', 'at', 'least', 'on', 'the', 'nodes', 'and', 'edges', 'of', 'the', 'graph', 'determining', 'clusters', 'in', 'the', 'graph', 'based', 'at', 'least', 'on', 'the', 'clusters', 'in', 'the', 'graph', 'identifying', 'topic', 'candidates', 'extracting', 'features', 'from', 'the', 'clusters', 'in', 'the', 'graph', 'based', 'at', 'least', 'on', 'the', 'extracted', 'features', 'selecting', 'at', 'least', 'one', 'topicid', 'from', 'among', 'the', 'topic', 'candidates', 'to', 'represent', 'at', 'least', 'one', 'cluster', 'and', 'indexing', 'the', 'multimodal', 'file', 'with', 'the', 'at', 'least', 'one', 'topicid', 'the', 'method', 'of', 'claim', 'wherein', 'the', 'multimodal', 'file', 'comprises', 'a', 'video', 'portion', 'and', 'an', 'audio', 'portion', 'and', 'wherein', 'extracting', 'a', 'set', 'of', 'entities', 'from', 'the', 'multimodal', 'file', 'comprises', 'detecting', 'objects', 'in', 'the', 'video', 'portion', 'of', 'the', 'multimodal', 'file', 'and', 'detecting', 'text', 'in', 'the', 'audio', 'portion', 'of', 'the', 'multimodal', 'file', 'the', 'method', 'of', 'claim', 'wherein', 'detecting', 'objects', 'comprises', 'performing', 'face', 'recognition', 'the', 'method', 'of', 'claim', 'wherein', 'detecting', 'text', 'comprises', 'performing', 'a', 'speech', 'to', 'text', 'process', 'the', 'method', 'of', 'claim', 'further', 'comprising', 'identifying', 'a', 'language', 'used', 'in', 'the', 'audio', 'portion', 'of', 'the', 'multimodal', 'file', 'and', 'wherein', 'performing', 'a', 'speech', 'to', 'text', 'process', 'comprises', 'performing', 'a', 'speech', 'to', 'text', 'process', 'in', 'the', 'identified', 'language', 'the', 'method', 'of', 'claim', 'further', 'comprising', 'translating', 'the', 'detected', 'text', 'the', 'method', 'of', 'claim', 'further', 'comprising', 'determining', 'significant', 'clusters', 'and', 'insignificant', 'clusters', 'in', 'the', 'determined', 'clusters', 'and', 'wherein', 'extracting', 'features', 'from', 'the', 'clusters', 'in', 'the', 'graph', 'comprises', 'extracting', 'features', 'from', 'the', 'significant', 'clusters', 'in', 'the', 'graph', 'the', 'method', 'of', 'claim', 'wherein', 'extracting', 'features', 'from', 'the', 'clusters', 'in', 'the', 'graph', 'comprises', 'at', 'least', 'one', 'process', 'selected', 'from', 'the', 'list', 'consisting', 'of', 'determining', 'a', 'graph', 'diameter', 'and', 'determining', 'a', 'jaccard', 'coefficient', 'the', 'method', 'of', 'claim', 'wherein', 'selecting', 'at', 'least', 'one', 'topicid', 'to', 'represent', 'at', 'least', 'one', 'cluster', 'comprises', 'based', 'at', 'least', 'on', 'the', 'extracted', 'features', 'mapping', 'topic', 'candidates', 'into', 'a', 'probability', 'interval', 'and', 'based', 'at', 'least', 'on', 'the', 'mapping', 'ranking', 'topic', 'candidates', 'within', 'the', 'at', 'least', 'one', 'cluster', 'and', 'selecting', 'the', 'at', 'least', 'one', 'topicid', 'based', 'at', 'least', 'on', 'the', 'ranking', 'the', 'method', 'of', 'claim', 'further', 'comprising', 'translating', 'the', 'at', 'least', 'one', 'topicid', 'and', 'wherein', 'indexing', 'the', 'multimodal', 'file', 'with', 'the', 'at', 'least', 'one', 'topicid', 'comprises', 'indexing', 'the', 'multimodal', 'file', 'with', 'the', 'at', 'least', 'one', 'translated', 'topicid', 'a', 'system', 'for', 'inferring', 'topics', 'from', 'a', 'multimodal', 'file', 'the', 'system', 'comprising', 'an', 'entity', 'extraction', 'component', 'comprising', 'an', 'object', 'detection', 'component', 'and', 'a', 'speech', 'to', 'text', 'component', 'operative', 'to', 'extract', 'a', 'set', 'of', 'entities', 'from', 'a', 'multimodal', 'file', 'comprising', 'a', 'video', 'portion', 'and', 'an', 'audio', 'portion', 'an', 'entity', 'linking', 'component', 'operative', 'to', 'link', 'the', 'extracted', 'set', 'of', 'entities', 'to', 'produce', 'a', 'set', 'of', 'linked', 'entities', 'an', 'information', 'retrieval', 'component', 'operative', 'to', 'obtain', 'reference', 'information', 'for', 'the', 'extracted', 'set', 'of', 'entities', 'a', 'graphing', 'and', 'analysis', 'component', 'operative', 'to', 'generate', 'a', 'graph', 'of', 'the', 'set', 'of', 'linked', 'entities', 'the', 'graph', 'comprising', 'nodes', 'and', 'edges', 'based', 'at', 'least', 'on', 'the', 'nodes', 'and', 'edges', 'of', 'the', 'graph', 'determine', 'clusters', 'in', 'the', 'graph', 'based', 'at', 'least', 'on', 'the', 'clusters', 'in', 'the', 'graph', 'identify', 'topic', 'candidates', 'and', 'extract', 'features', 'from', 'the', 'clusters', 'in', 'the', 'graph', 'a', 'topicid', 'selection', 'component', 'operative', 'to', 'rank', 'the', 'topic', 'candidates', 'within', 'at', 'least', 'one', 'cluster', 'and', 'based', 'at', 'least', 'on', 'the', 'ranking', 'select', 'at', 'least', 'one', 'topicid', 'from', 'among', 'the', 'topic', 'candidates', 'to', 'represent', 'at', 'least', 'one', 'cluster', 'and', 'a', 'video', 'indexer', 'operative', 'to', 'index', 'the', 'multimodal', 'file', 'with', 'the', 'at', 'least', 'one', 'topicid', 'the', 'system', 'of', 'claim', 'wherein', 'the', 'object', 'detection', 'component', 'is', 'operative', 'to', 'perform', 'face', 'recognition', 'the', 'system', 'of', 'claim', 'wherein', 'the', 'speech', 'to', 'text', 'component', 'is', 'operative', 'to', 'extract', 'entity', 'information', 'in', 'at', 'least', 'two', 'different', 'languages', 'one', 'or', 'more', 'computer', 'storage', 'devices', 'having', 'computer-executable', 'instructions', 'stored', 'thereon', 'for', 'inferring', 'topics', 'from', 'a', 'multimodal', 'file', 'which', 'on', 'execution', 'by', 'a', 'computer', 'cause', 'the', 'computer', 'to', 'perform', 'operations', 'comprising', 'receiving', 'a', 'multimodal', 'file', 'comprising', 'a', 'video', 'portion', 'and', 'an', 'audio', 'portion', 'extracting', 'a', 'set', 'of', 'entities', 'from', 'the', 'multimodal', 'file', 'wherein', 'extracting', 'a', 'set', 'of', 'entities', 'from', 'the', 'multimodal', 'file', 'comprises', 'detecting', 'objects', 'in', 'the', 'video', 'portion', 'of', 'the', 'multimodal', 'file', 'with', 'face', 'recognition', 'detecting', 'text', 'in', 'the', 'audio', 'portion', 'of', 'the', 'multimodal', 'file', 'with', 'a', 'speech', 'to', 'text', 'process', 'and', 'disambiguating', 'among', 'a', 'set', 'of', 'detected', 'entity', 'names', 'linking', 'the', 'set', 'of', 'entities', 'to', 'produce', 'a', 'set', 'of', 'linked', 'entities', 'obtaining', 'reference', 'information', 'for', 'the', 'set', 'of', 'entities', 'based', 'at', 'least', 'on', 'the', 'reference', 'information', 'generating', 'a', 'graph', 'of', 'the', 'set', 'of', 'linked', 'entities', 'the', 'graph', 'comprising', 'nodes', 'and', 'edges', 'based', 'at', 'least', 'on', 'the', 'nodes', 'and', 'edges', 'of', 'the', 'graph', 'determining', 'clusters', 'in', 'the', 'graph', 'determining', 'significant', 'clusters', 'and', 'insignificant', 'clusters', 'in', 'the', 'determined', 'clusters', 'based', 'at', 'least', 'on', 'the', 'significant', 'clusters', 'in', 'the', 'graph', 'identifying', 'topic', 'candidates', 'extracting', 'features', 'from', 'the', 'significant', 'clusters', 'in', 'the', 'graph', 'based', 'at', 'least', 'on', 'the', 'extracted', 'features', 'mapping', 'the', 'topic', 'candidates', 'into', 'a', 'probability', 'interval', 'based', 'at', 'least', 'on', 'the', 'mapping', 'ranking', 'the', 'topic', 'candidates', 'within', 'at', 'least', 'one', 'significant', 'cluster', 'based', 'on', 'the', 'ranking', 'selecting', 'at', 'least', 'one', 'topicid', 'from', 'among', 'the', 'topic', 'candidates', 'to', 'represent', 'the', 'at', 'least', 'one', 'significant', 'cluster', 'and', 'indexing', 'the', 'multimodal', 'file', 'with', 'the', 'at', 'least', 'one', 'topicid', 'the', 'one', 'or', 'more', 'computer', 'storage', 'devices', 'of', 'claim', 'wherein', 'the', 'operations', 'further', 'comprise', 'identifying', 'a', 'language', 'used', 'in', 'the', 'audio', 'portion', 'of', 'the', 'multimodal', 'file', 'and', 'detecting', 'text', 'in', 'the', 'audio', 'portion', 'of', 'the', 'multimodal', 'file', 'with', 'a', 'speech', 'to', 'text', 'process', 'comprises', 'performing', 'a', 'speech', 'to', 'text', 'process', 'in', 'the', 'identified', 'language权利要求', '、', '一种人脸识别方法其特征在于包括', '通过第一摄像头获取第一人脸图像', '提取所述第一人脸图像的第一人脸特征', '将所述第一人脸特征与预先存储的第二人脸特征进行对比获得参考相似度所述第', '二人脸特征经第二摄像头获取的第二人脸图像的特征提取而得所述第二摄像头与所述第', '一摄像头属于不同类型的摄像头', '根据所述参考相似度确定所述第一人脸特征与所述第二人脸特征是否对应相同人。', '、', '根据权利要求', '所述的方法其特征在于', '所述第一摄像头为热成像摄像头所述第二摄像头为可见光摄像头', '或者所述第一摄像头为可见光摄像头所述第一摄像头为热成像摄像头。', '、', '根据权利要求', '或', '所述的方法其特征在于所述根据所述参考相似度确定所', '述第一人脸特征与所述第二人脸特征是否对应相同人包括', '根据所述参考相似度、', '参考误报率以及相似度阈值确定所述第一人脸特征与所述第二', '人脸特征是否对应相同人其中不同的误报率对应不同的相似度阈值。', '、', '根据权利要求', '或', '所述的方法其特征在于所述根据所述参考相似度确定所', '述第一人脸特征与所述第二人脸特征是否对应相同人包括', '根据所述参考相似度以及阈值信息确定归一化后的参考相似度', '根据所述归一化后的参考相似度确定所述第一人脸特征与所述第二人脸特征是否对', '应相同人。', '、', '根据权利要求', '-任一项所述的方法其特征在于所述提取所述第一人脸图像的', '第_人脸特征包括', '将所述第一人脸图像输入预先训练完成的神经网络通过所述神经网络输出所述第一', '人脸图像的第一人脸特征其中所述神经网络基于第一类型图像样本和第二类型图像样', '本训练得到所述第一类型图像样本和所述第二类型图像样本由不同类型的摄像头拍摄得', '到且所述第一类型图像样本和所述第二类型图像样本中包括人脸。', '、', '根据权利要求', '所述的方法其特征在于所述神经网络基于所述第一类型图像', '样本、', '所述第二类型图像样本和混合类型图像样本训练得到所述混合类型图像样本由所', '述第一类型图像样本和所述第二类型图像样本配对而得。', '、', '根据权利要求', '-任一项所述的方法其特征在于所述第一摄像头包括车载摄像', '头所述通过第一摄像头获取第一人脸图像包括', '通过所述车载摄像头获取所述第一人脸图像所述第一人脸图像包括车辆的用车人的', '人脸图像。', '、', '根据权利要求', '所述的方法其特征在于所述用车人包括驾驶所述车辆的人、', '乘坐所述车辆的人、', '对所述车辆进行修理的人、', '给所述车辆加油的人以及控制所述车辆的', '人中的一项或多项。', '、', '根据权利要求', '所述的方法其特征在于所述用车人包括驾驶所述车辆的人', '所述通过所述车载摄像头获取所述第一人脸图像包括', '在接收到触发指令的情况下通过所述车载摄像头获取所述第一人脸图像', '或者在所述车辆运行时通过所述车载摄像头获取所述第一人脸图像', '或者在所述车辆的运行速度达到参考速度的情况下通过所述车载摄像头获取所述', '第一人脸图像。', '、', '根据权利要求', '-任一项所述的方法其特征在于所述第二人脸图像为对所述', '用车人进行人脸注册的图像所述将所述第一人脸特征与预先存储的第二人脸特征进行对', '比之前所述方法还包括', '通过所述第二摄像头获取所述第二人脸图像', '提取所述第二人脸图像的第二人脸特征', '保存所述第二人脸图像的第二人脸特征。', '、', '一种神经网络训练方法其特征在于包括', '获取第一类型图像样本和第二类型图像样本所述第一类型图像样本和所述第二类型', '图像样本由不同类型的摄像头拍摄得到且所述第一类型图像样本和所述第二类型图像样', '本中包括人脸', '根据所述第一类型图像样本和所述第二类型图像样本训练神经网络。', '、', '根据权利要求', '所述的方法其特征在于所述根据所述第一类型图像样本和所', '述第二类型图像样本训练神经网络包括', '将所述第一类型图像样本和所述第二类型图像样本配对得到所述第一类型图像样本', '和所述第二类型图像样本的混合类型图像样本', '根据所述第一类型图像样本、', '所述第二类型图像样本和所述混合类型图像样本训练', '所述神经网络。', '、', '根据权利要求', '所述的方法其特征在于所述根据所述第一类型图像样本、', '所述第二类型图像样本和所述混合类型图像样本训练所述神经网络包括', '通过所述神经网络获取所述第一类型图像样本的人脸预测结果、', '所述第二类型图像样', '本的人脸预测结果和所述混合类型图像样本的人脸预测结果', '根据所述第一类型图像样本的人脸预测结果和人脸标注结果的差异、', '所述第二类型图', '像样本的人脸预测结果和人脸标注结果之间的差异、', '以及所述混合类型图像样本的人脸预', '测结果和人脸标注结果的差异训练所述神经网络。', '、', '根据权利要求', '所述的方法其特征在于所述神经网络中包括第一分类器、', '第二分类器和混合分类器所述通过所述神经网络获取所述第一类型图像样本的人脸预测', '结果、', '所述第二类型图像样本的人脸预测结果和所述混合类型图像样本的人脸预测结果', '包括', '将所述第一类型图像样本的人脸特征输入至所述第一分类器中得到所述第一类型图', '像样本的人脸预测结果', '将所述第二类型图像样本的人脸特征输入至所述第二分类器中得到所述第二类型图', '像样本的人脸预测结果', '将所述混合类型图像样本的人脸特征输入至所述混合分类器中得到所述混合类型图', '像样本的人脸预测结果。', '、', '根据权利要求', '所述的方法其特征在于所述方法还包括', '在训练完成的所述神经网络中去除所述第一分类器、', '所述第二分类器和所述混合分类', '器得到用于进行人脸识别的神经网络。', '、', '一种人脸识别装置其特征在于包括', '第一获取单元用于通过第一摄像头获取第一人脸图像', '第一提取单元用于提取所述第一人脸图像的第一人脸特征', '对比单元用于将所述第一人脸特征与预先存储的第二人脸特征进行对比获得参考', '相似度所述第二人脸特征经第二摄像头获取的第二人脸图像的特征提取而得所述第二', '摄像头与所述第一摄像头属于不同类型的摄像头', '确定单元用于根据所述参考相似度确定所述第一人脸特征与所述第二人脸特征是否', '对应相同人。', '、', '根据权利要求', '所述的装置其特征在于', '所述第一摄像头为热成像摄像头所述第二摄像头为可见光摄像头', '或者所述第一摄像头为可见光摄像头所述第一摄像头为热成像摄像头。', '、', '根据权利要求', '或', '所述的装置其特征在于', '所述确定单元具体用于根据所述参考相似度、', '参考误报率以及相似度阈值确定所述', '第一人脸特征与所述第二人脸特征是否对应相同人其中不同的误报率对应不同的相似', '度阈值。', '、', '根据权利要求', '或', '所述的装置其特征在于', '所述确定单元具体用于根据所述参考相似度以及阈值信息确定归一化后的参考相似', '度以及根据所述归一化后的参考相似度确定所述第一人脸特征与所述第二人脸特征是否', '对应相同人。', '、', '根据权利要求', '-任_项所述的装置其特征在于', '所述第一提取单元具体用于将所述第一人脸图像输入预先训练完成的神经网络通', '过所述神经网络输出所述第一人脸图像的第一人脸特征其中所述神经网络基于第一类', '型图像样本和第二类型图像样本训练得到所述第一类型图像样本和所述第二类型图像样', '本由不同类型的摄像头拍摄得到且所述第一类型图像样本和所述第二类型图像样本中包', '括人脸。', '、', '根据权利要求', '所述的装置其特征在于所述神经网络基于所述第一类型图', '像样本、', '所述第二类型图像样本和混合类型图像样本训练得到所述混合类型图像样本由', '所述第一类型图像样本和所述第二类型图像样本配对而得。', '、', '根据权利要求', '-任一项所述的装置其特征在于所述第一摄像头包括车载', '摄像头', '所述第一获取单元具体用于通过所述车载摄像头获取所述第一人脸图像所述第一', '人脸图像包括车辆的用车人的人脸图像。', '、', '根据权利要求', '所述的装置其特征在于所述用车人包括驾驶所述车辆的人、', '乘坐所述车辆的人、', '对所述车辆进行修理的人、', '给所述车辆加油的人以及控制所述车辆的', '人中的一项或多项。', '、', '根据权利要求', '所述的装置其特征在于所述用车人包括驾驶所述车辆的人', '所述第一获取单元具体用于在接收到触发指令的情况下通过所述车载摄像头获取所述', '第一人脸图像', '或者所述第一获取单元具体用于在所述车辆运行时通过所述车载摄像头获取所', '述第', '_人脸图像', '或者所述第一获取单元具体用于在所述车辆的运行速度达到参考速度的情况下', '通过所述车载摄像头获取所述第一人脸图像。', '、', '根据权利要求', '-任一项所述的装置其特征在于所述第二人脸图像为对所', '述用车人进行人脸注册的图像所述装置还包括', '第二获取单元用于通过所述第二摄像头获取所述第二人脸图像', '第二提取单元用于提取所述第二人脸图像的第二人脸特征', '保存单元用于保存所述第二人脸图像的第二人脸特征。', '、', '一种神经网络训练装置其特征在于包括', '获取单元用于获取第一类型图像样本和第二类型图像样本所述第一类型图像样本', '和所述第二类型图像样本由不同类型的摄像头拍摄得到且所述第一类型图像样本和所述', '第二类型图像样本中包括人脸', '训练单元用于根据所述第一类型图像样本和所述第二类型图像样本训练神经网络。', '、', '根据权利要求', '所述的装置其特征在于所述训练单元包括', '配对子单元用于将所述第一类型图像样本和所述第二类型图像样本配对得到所述', '第一类型图像样本和所述第二类型图像样本的混合类型图像样本', '训练子单元用于根据所述第一类型图像样本、', '所述第二类型图像样本和所述混合类', '型图像样本训练所述神经网络。', '、', '根据权利要求', '所述的装置其特征在于', '所述训练子单元具体用于通过所述神经网络获取所述第一类型图像样本的人脸预测', '结果、', '所述第二类型图像样本的人脸预测结果和所述混合类型图像样本的人脸预测结果', '以及根据所述第一类型图像样本的人脸预测结果和人脸标注结果的差异、', '所述第二类型图', '像样本的人脸预测结果和人脸标注结果之间的差异、', '以及所述混合类型图像样本的人脸预', '测结果和人脸标注结果的差异训练所述神经网络。', '、', '根据权利要求', '所述的装置其特征在于所述神经网络中包括第一分类器、', '第二分类器和混合分类器', '所述训练子单元具体用于将所述第一类型图像样本的人脸特征输入至所述第一分类', '器中得到所述第一类型图像样本的人脸预测结果以及将所述第二类型图像样本的人脸', '特征输入至所述第二分类器中得到所述第二类型图像样本的人脸预测结果以及将所述', '混合类型图像样本的人脸特征输入至所述混合分类器中得到所述混合类型图像样本的人', '脸预测结果。', '、', '根据权利要求', '所述的装置其特征在于所述装置还包括', '神经网络应用单元用于在训练完成的所述神经网络中去除所述第一分类器、', '所述第', '二分类器和所述混合分类器得到用于进行人脸识别的神经网络。', '、', '一种电子设备其特征在于包括处理器和存储器所述处理器和所述存储器耦', '合其中所述存储器用于存储程序指令所述程序指令被所述处理器执行时使所述处', '理器执行权利要求', '-任一项所述的方法和或使所述处理器执行权利要求', '-任一', '项所述的方法。', '、', '一种计算机可读存储介质其特征在于所述计算机可读存储介质中存储有计算', '机程序所述计算机程序包括程序指令所述程序指令当被处理器执行时使所述处理器', '执行权利要求', '-任一项所述的方法和或使所述处理器执行权利要求', '-任一项所', '述的方法。', 'a', 'system', 'for', 'alerting', 'on', 'vision', 'impairment', 'said', 'system', 'comprising', 'a', 'processing', 'unit', 'configured', 'and', 'operable', 'for', 'receiving', 'scene', 'data', 'being', 'indicative', 'of', 'a', 'scene', 'of', 'at', 'least', 'one', 'consumer', 'in', 'an', 'environment', 'identifying', 'in', 'the', 'scene', 'data', 'a', 'certain', 'consumer', 'identifying', 'an', 'event', 'being', 'indicative', 'of', 'a', 'behavioral', 'compensation', 'for', 'vision', 'impairment', 'and', 'upon', 'identification', 'of', 'such', 'an', 'event', 'sending', 'a', 'notification', 'relating', 'to', 'the', 'vision', 'impairment', 'the', 'system', 'of', 'claim', 'further', 'comprising', 'at', 'least', 'one', 'sensing', 'unit', 'configured', 'and', 'operable', 'for', 'detecting', 'the', 'scene', 'data', 'the', 'system', 'of', 'claim', 'wherein', 'said', 'at', 'least', 'one', 'sensing', 'unit', 'comprises', 'at', 'least', 'one', 'of', 'at', 'least', 'one', 'imaging', 'unit', 'configured', 'and', 'operable', 'for', 'capturing', 'at', 'least', 'one', 'image', 'of', 'at', 'least', 'a', 'portion', 'of', 'a', 'consumer', \"'s\", 'body', 'at', 'least', 'one', 'motion', 'detector', 'configured', 'and', 'operable', 'for', 'detecting', 'consumer', 'data', 'being', 'indicative', 'of', 'a', 'motion', 'of', 'a', 'consumer', 'or', 'at', 'least', 'one', 'eye', 'tracker', 'configured', 'and', 'operable', 'for', 'tracking', 'eye', 'motion', 'of', 'a', 'consumer', 'the', 'system', 'of', 'claim', 'wherein', 'the', 'at', 'least', 'one', 'imaging', 'unit', 'comprises', 'a', 'plurality', 'of', 'cameras', 'placed', 'at', 'different', 'heights', 'the', 'system', 'of', 'any', 'one', 'of', 'claims', 'to', 'wherein', 'said', 'sensing', 'unit', 'is', 'accommodated', 'in', 'an', 'optical', 'or', 'digital', 'eyewear', 'frame', 'display', 'the', 'system', 'of', 'any', 'one', 'of', 'claims', 'to', 'wherein', 'said', 'processing', 'unit', 'is', 'configured', 'and', 'operable', 'for', 'identifying', 'a', 'consumer', \"'s\", 'condition', 'said', 'consumer', \"'s\", 'condition', 'comprising', 'consumer', 'data', 'being', 'indicative', 'of', 'the', 'consumer', \"'s\", 'position', 'and', 'location', 'relative', 'to', 'at', 'least', 'one', 'object', 'in', 'the', 'consumer', \"'s\", 'environment', 'said', 'consumer', 'data', 'comprises', 'at', 'least', 'one', 'of', 'a', 'consumer', \"'s\", 'face', 'eyewear', 'posture', 'position', 'sound', 'or', 'motion', 'the', 'system', 'of', 'any', 'one', 'of', 'claims', 'to', 'wherein', 'said', 'event', 'comprises', 'at', 'least', 'one', 'position', 'and', 'orientation', 'of', 'head', 'increase', 'or', 'decrease', 'of', 'viewing', 'distance', 'between', 'the', 'consumer', 'and', 'viewed', 'object', 'and', 'changing', 'the', 'position', 'of', 'eyeglasses', 'worn', 'by', 'the', 'consumer', 'the', 'system', 'of', 'any', 'one', 'of', 'claims', 'to', 'wherein', 'said', 'event', 'is', 'identified', 'by', 'identifying', 'images', 'having', 'an', 'image', 'feature', 'being', 'indicative', 'of', 'behavioral', 'compensation', 'performing', 'a', 'bruckner', 'test', 'performing', 'a', 'hirschberg', 'test', 'and', 'measuring', 'blink', 'count', 'frequency', 'the', 'system', 'of', 'claim', 'wherein', 'the', 'image', 'feature', 'being', 'indicative', 'of', 'behavioral', 'compensation', 'comprises', 'squinting', 'head', 'orientation', 'certain', 'distances', 'between', 'an', 'object', 'and', 'consumer', \"'s\", 'eyes', 'certain', 'position', 'of', 'eyeglasses', 'on', 'the', 'consumer', \"'s\", 'face', 'strabismus', 'cataracts', 'and', 'reflections', 'from', 'the', 'eye', 'the', 'system', 'of', 'any', 'one', 'of', 'claims', 'to', 'wherein', 'the', 'notification', 'includes', 'at', 'least', 'one', 'of', 'the', 'data', 'indicative', 'of', 'the', 'identified', 'event', 'data', 'indicative', 'of', 'the', 'identified', 'consumer', 'ophthalmologic', 'recommendations', 'based', 'on', 'the', 'identified', 'event', 'or', 'lack', 'of', 'events', 'or', 'an', 'appointment', 'for', 'a', 'vision', 'test', 'the', 'system', 'of', 'any', 'one', 'of', 'claims', 'to', 'wherein', 'said', 'processing', 'unit', 'comprises', 'a', 'memory', 'for', 'storing', 'at', 'least', 'one', 'of', 'a', 'reference', 'data', 'indicative', 'of', 'behavioral', 'compensation', 'for', 'vision', 'impairment', 'data', 'indicative', 'of', 'the', 'notification', 'or', 'data', 'indicative', 'of', 'a', 'follow-up', 'of', 'the', 'notification', 'the', 'system', 'of', 'claim', 'wherein', 'said', 'processing', 'unit', 'is', 'configured', 'for', 'at', 'least', 'one', 'of', 'identifying', 'the', 'event', 'upon', 'comparison', 'between', 'the', 'detected', 'data', 'and', 'the', 'reference', 'data', 'or', 'determining', 'a', 'probability', 'for', 'a', 'vision', 'impairment', 'of', 'the', 'consumer', 'based', 'on', 'the', 'comparison', 'the', 'system', 'of', 'any', 'one', 'of', 'claims', 'to', 'wherein', 'said', 'processing', 'unit', 'comprises', 'a', 'communication', 'interface', 'being', 'configured', 'for', 'sending', 'the', 'notification', 'to', 'at', 'least', 'one', 'of', 'the', 'identified', 'consumer', 'or', 'a', 'third', 'party', 'the', 'system', 'of', 'any', 'one', 'of', 'claims', 'to', 'wherein', 'said', 'processing', 'unit', 'is', 'configured', 'for', 'providing', 'a', 'frame', 'recommendation', 'the', 'system', 'of', 'any', 'one', 'of', 'claims', 'to', 'wherein', 'said', 'memory', 'is', 'configured', 'for', 'storing', 'a', 'database', 'including', 'a', 'multiplicity', 'of', 'data', 'sets', 'related', 'to', 'a', 'plurality', 'of', 'spectacle', 'frame', 'models', 'and', 'sizes', 'the', 'system', 'according', 'to', 'claim', 'or', 'wherein', 'said', 'processing', 'unit', 'is', 'configured', 'and', 'operable', 'to', 'correlate', 'between', 'frames', 'parameters', 'and', 'ophthalmic', 'prescriptions', 'the', 'system', 'according', 'to', 'any', 'of', 'claims', 'to', 'wherein', 'said', 'processing', 'unit', 'is', 'configured', 'and', 'operable', 'to', 'correlate', 'between', 'frames', 'parameters', 'and', 'facial', 'features', 'the', 'system', 'according', 'to', 'any', 'of', 'claims', 'to', 'wherein', 'said', 'processing', 'unit', 'is', 'configured', 'and', 'operable', 'to', 'correlate', 'between', 'frames', 'parameters', 'and', 'eyewear', 'preferences', 'the', 'system', 'according', 'to', 'any', 'of', 'claims', 'to', 'comprising', 'a', 'server', 'and', 'at', 'least', 'one', 'computer', 'entity', 'linked', 'to', 'the', 'server', 'via', 'a', 'network', 'wherein', 'said', 'network', 'is', 'configured', 'to', 'receive', 'and', 'respond', 'to', 'requests', 'sent', 'across', 'the', 'network', 'transmitting', 'one', 'or', 'more', 'modules', 'of', 'computer', 'executable', 'program', 'instructions', 'and', 'displayable', 'data', 'to', 'the', 'network', 'connected', 'user', 'computer', 'platform', 'in', 'response', 'to', 'a', 'request', 'wherein', 'said', 'modules', 'include', 'modules', 'configured', 'to', 'receive', 'and', 'transmit', 'image', 'information', 'transmitting', 'a', 'frame', 'recommendation', 'and', 'an', 'optical', 'lens', 'option', 'recommendation', 'based', 'on', 'received', 'image', 'information', 'for', 'display', 'by', 'the', 'network', 'connected', 'user', 'computer', 'platform', 'a', 'computer', 'program', 'instructions', 'stored', 'in', 'the', 'local', 'storage', 'that', 'when', 'executed', 'by', 'a', 'processing', 'unit', 'cause', 'the', 'processing', 'unit', 'to', 'receive', 'data', 'being', 'indicative', 'of', 'a', 'scene', 'of', 'at', 'least', 'one', 'consumer', 'in', 'an', 'environment', 'identify', 'in', 'the', 'data', 'a', 'certain', 'consumer', 'identify', 'an', 'event', 'being', 'indicative', 'of', 'a', 'behavioral', 'compensation', 'for', 'vision', 'impairment', 'and', 'upon', 'identification', 'of', 'such', 'an', 'event', 'send', 'a', 'notification', 'relating', 'to', 'the', 'vision', 'impairment', 'a', 'computer', 'program', 'product', 'stored', 'on', 'a', 'tangible', 'computer', 'readable', 'medium', 'comprising', 'a', 'library', 'of', 'software', 'modules', 'which', 'cause', 'a', 'computer', 'executing', 'them', 'to', 'prompt', 'for', 'information', 'pertinent', 'to', 'at', 'least', 'one', 'of', 'an', 'eyeglasses', 'recommendation', 'and', 'an', 'optical', 'lens', 'option', 'recommendation', 'to', 'store', 'said', 'information', 'or', 'to', 'display', 'eyewear', 'recommendations', 'the', 'computer', 'program', 'product', 'of', 'claim', 'wherein', 'said', 'library', 'further', 'comprises', 'a', 'module', 'for', 'frame', 'selection', 'point', 'of', 'sales', 'and', 'advertising', 'a', 'computer', 'platform', 'for', 'facilitating', 'eye', 'glasses', 'marketing', 'or', 'selection', 'comprising', 'a', 'camera', 'a', 'processor', 'configured', 'to', 'execute', 'computer', 'program', 'instructions', 'to', 'cause', 'the', 'processor', 'to', 'take', 'an', 'image', 'of', 'a', 'consumer', 'identify', 'in', 'the', 'image', 'a', 'certain', 'consumer', 'identify', 'an', 'event', 'being', 'indicative', 'of', 'a', 'behavioral', 'compensation', 'for', 'vision', 'impairment', 'and', 'upon', 'identification', 'of', 'such', 'an', 'event', 'sending', 'a', 'notification', 'relating', 'to', 'the', 'vision', 'impairment', 'local', 'storage', 'for', 'processor', 'executable', 'instructions', 'for', 'carrying', 'out', 'storage', 'of', 'information', 'a', 'method', 'for', 'alerting', 'on', 'vision', 'impairment', 'said', 'method', 'comprising', 'identifying', 'a', 'certain', 'individual', 'in', 'scene', 'data', 'being', 'indicative', 'of', 'a', 'scene', 'of', 'at', 'least', 'one', 'consumer', 'in', 'an', 'environment', 'identifying', 'an', 'event', 'being', 'indicative', 'of', 'a', 'behavioral', 'compensation', 'for', 'vision', 'impairment', 'and', 'upon', 'identification', 'of', 'such', 'an', 'event', 'sending', 'a', 'notification', 'on', 'the', 'vision', 'impairment', 'the', 'method', 'of', 'claim', 'further', 'comprising', 'detecting', 'data', 'being', 'indicative', 'of', 'a', 'scene', 'of', 'at', 'least', 'one', 'consumer', 'in', 'a', 'retail', 'environment', 'the', 'method', 'of', 'claim', 'wherein', 'detecting', 'the', 'data', 'being', 'indicative', 'of', 'at', 'least', 'one', 'consumer', 'comprises', 'at', 'least', 'one', 'of', 'capturing', 'at', 'least', 'one', 'image', 'of', 'at', 'least', 'one', 'consumer', 'detecting', 'data', 'being', 'indicative', 'of', 'a', 'motion', 'of', 'a', 'consumer', 'or', 'tracking', 'an', 'eye', 'motion', 'of', 'a', 'consumer', 'the', 'method', 'of', 'claim', 'wherein', 'capturing', 'at', 'least', 'one', 'image', 'of', 'at', 'least', 'one', 'consumer', 'comprises', 'continuously', 'recording', 'a', 'scene', 'the', 'method', 'of', 'any', 'one', 'of', 'claims', 'to', 'further', 'comprising', 'identifying', 'in', 'the', 'data', 'the', 'consumer', \"'\", 's', 'condition', 'including', 'data', 'being', 'indicative', 'of', 'the', 'consumer', \"'s\", 'position', 'and', 'location', 'relative', 'to', 'the', 'consumer', \"'s\", 'environment', 'said', 'data', 'comprising', 'at', 'least', 'one', 'of', 'the', 'consumer', \"'s\", 'face', 'posture', 'position', 'sound', 'or', 'motion', 'the', 'method', 'of', 'any', 'one', 'of', 'claims', 'to', 'wherein', 'said', 'event', 'comprises', 'at', 'least', 'one', 'of', 'position', 'and', 'orientation', 'of', 'head', 'increase', 'or', 'decrease', 'of', 'viewing', 'distance', 'between', 'the', 'consumer', 'and', 'viewed', 'object', 'or', 'changing', 'the', 'position', 'of', 'eyeglasses', 'worn', 'by', 'the', 'consumer', 'the', 'method', 'of', 'any', 'one', 'of', 'claims', 'to', 'wherein', 'identifying', 'of', 'the', 'event', 'comprises', 'identifying', 'images', 'having', 'an', 'image', 'feature', 'being', 'indicative', 'of', 'behavioral', 'compensation', 'performing', 'a', 'bruckner', 'test', 'performing', 'a', 'hirschberg', 'test', 'and', 'measuring', 'blink', 'countfrequency', 'the', 'method', 'of', 'claim', 'wherein', 'the', 'image', 'feature', 'being', 'indicative', 'of', 'behavioral', 'compensation', 'comprises', 'squinting', 'head', 'orientation', 'certain', 'distances', 'between', 'an', 'object', 'and', 'a', 'consumer', \"'s\", 'eyes', 'certain', 'position', 'of', 'eyeglasses', 'on', 'the', 'consumer', \"'s\", 'face', 'strabismus', 'cataracts', 'and', 'reflections', 'from', 'the', 'eye', 'the', 'method', 'of', 'any', 'one', 'of', 'claims', 'to', 'wherein', 'identifying', 'in', 'the', 'at', 'least', 'one', 'image', 'a', 'consumer', 'in', 'a', 'retail', 'environment', 'comprising', 'at', 'least', 'one', 'of', 'receiving', 'data', 'characterizing', 'the', 'retail', 'environment', 'or', 'performing', 'face', 'recognition', 'the', 'method', 'of', 'any', 'one', 'of', 'claims', 'to', 'wherein', 'sending', 'a', 'notification', 'comprising', 'sending', 'the', 'notification', 'to', 'at', 'least', 'one', 'of', 'the', 'identified', 'consumer', 'or', 'a', 'third', 'party', 'the', 'method', 'of', 'any', 'one', 'of', 'claims', 'to', 'wherein', 'the', 'notification', 'includes', 'at', 'least', 'one', 'of', 'the', 'data', 'indicative', 'of', 'the', 'identified', 'event', 'data', 'indicative', 'of', 'the', 'identified', 'consumer', 'ophthalmologic', 'recommendations', 'based', 'on', 'the', 'identified', 'event', 'or', 'lack', 'of', 'events', 'and', 'an', 'appointment', 'for', 'a', 'vision', 'test', 'the', 'method', 'of', 'any', 'one', 'of', 'claims', 'to', 'further', 'comprising', 'storing', 'at', 'least', 'one', 'of', 'a', 'reference', 'data', 'indicative', 'of', 'behavioral', 'compensation', 'for', 'vision', 'impairment', 'data', 'indicative', 'of', 'the', 'notification', 'or', 'data', 'indicative', 'of', 'a', 'follow-up', 'of', 'the', 'notification', 'the', 'method', 'of', 'claim', 'further', 'comprising', 'identifying', 'the', 'event', 'upon', 'comparison', 'between', 'the', 'detected', 'data', 'and', 'the', 'reference', 'data', 'and', 'determining', 'a', 'probability', 'for', 'a', 'vision', 'impairment', 'of', 'the', 'consumer', 'based', 'on', 'the', 'comparison', 'a', 'computer', 'program', 'intended', 'to', 'be', 'stored', 'in', 'a', 'memory', 'of', 'a', 'processor', 'unit', 'of', 'a', 'computer', 'system', 'or', 'in', 'a', 'removable', 'memory', 'medium', 'adapted', 'to', 'cooperate', 'with', 'a', 'reader', 'of', 'the', 'processor', 'unit', 'comprising', 'instructions', 'for', 'implementing', 'the', 'method', 'according', 'to', 'any', 'of', 'claims', 'to']\n"
     ]
    }
   ],
   "source": [
    "# the output is a list, where each element is a token of the original text\n",
    "tokenized_text_a = nltk.word_tokenize(lowera_text)\n",
    "print(tokenized_text_a)\n",
    "\n",
    "tokenized_text_c = nltk.word_tokenize(lowerc_text)\n",
    "print(tokenized_text_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777e73d5",
   "metadata": {},
   "source": [
    "### StopWords removal\n",
    "We remove the stopwords from the text. The language we are using is english, so we remove the english stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "998af632",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords_en = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f7147530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['electronic', 'apparatus', 'including', 'image', 'capturing', 'device', 'storage', 'device', 'processor', 'operation', 'method', 'thereof', 'provided', 'image', 'capturing', 'device', 'captures', 'image', 'user', 'storage', 'device', 'records', 'plurality', 'modules', 'processor', 'coupled', 'image', 'capturing', 'device', 'storage', 'device', 'configured', 'configure', 'image', 'capturing', 'device', 'capture', 'head', 'image', 'user', 'perform', 'face', 'recognition', 'operation', 'obtain', 'face', 'region', 'detect', 'plurality', 'facial', 'landmarks', 'within', 'face', 'region', 'estimate', 'head', 'posture', 'angle', 'user', 'according', 'facial', 'landmarks', 'calculate', 'gaze', 'position', 'user', 'gazes', 'screen', 'according', 'head', 'posture', 'angle', 'plurality', 'rotation', 'reference', 'angle', 'plurality', 'predetermined', 'calibration', 'positions', 'configure', 'screen', 'display', 'corresponding', 'visual', 'effect', 'according', 'gaze', 'positionthe', 'present', 'disclosure', 'provides', 'computation', 'method', 'product', 'thereof', 'computation', 'method', 'adopts', 'fusion', 'method', 'perform', 'machine', 'learning', 'computations', 'technical', 'effects', 'present', 'disclosure', 'include', 'fewer', 'computations', 'less', 'power', 'consumptiona', 'method', 'detecting', 'body', 'information', 'passengers', 'vehicle', 'based', 'humans', \"'\", 'status', 'recognition', 'provided', 'method', 'includes', 'steps', 'passenger', 'body', 'information-detecting', 'device', 'inputting', 'interior', 'image', 'vehicle', 'face', 'recognition', 'network', 'detect', 'faces', 'passengers', 'output', 'passenger', 'feature', 'information', 'inputting', 'interior', 'image', 'body', 'recognition', 'network', 'detect', 'bodies', 'output', 'body-part', 'length', 'information', 'b', 'retrieving', 'specific', 'height', 'mapping', 'information', 'referring', 'height', 'mapping', 'table', 'ratios', 'segment', 'body', 'portions', 'human', 'groups', 'heights', 'per', 'human', 'groups', 'acquiring', 'specific', 'height', 'specific', 'passenger', 'retrieving', 'specific', 'weight', 'mapping', 'information', 'weight', 'mapping', 'table', 'correlations', 'heights', 'weights', 'per', 'human', 'groups', 'acquiring', 'weight', 'specific', 'passenger', 'referring', 'specific', 'heighttechniques', 'related', 'improved', 'video', 'coding', 'based', 'face', 'detection', 'region', 'extraction', 'tracking', 'discussed', 'techniques', 'may', 'include', 'performing', 'facial', 'search', 'video', 'frame', 'determine', 'candidate', 'face', 'regions', 'video', 'frame', 'testing', 'candidate', 'face', 'regions', 'based', 'skin', 'tone', 'information', 'determine', 'valid', 'invalid', 'face', 'regions', 'rejecting', 'invalid', 'face', 'regions', 'encoding', 'video', 'frame', 'based', 'valid', 'face', 'regions', 'generate', 'coded', 'bitstreama', 'method', 'managing', 'smart', 'database', 'stores', 'facial', 'images', 'face', 'recognition', 'provided', 'method', 'includes', 'steps', 'managing', 'device', 'counting', 'specific', 'facial', 'images', 'corresponding', 'specific', 'person', 'smart', 'database', 'new', 'facial', 'images', 'continuously', 'stored', 'determining', 'whether', 'first', 'counted', 'value', 'representing', 'count', 'specific', 'facial', 'images', 'satisfies', 'first', 'set', 'value', 'b', 'first', 'counted', 'value', 'satisfies', 'first', 'set', 'value', 'inputting', 'specific', 'facial', 'images', 'neural', 'aggregation', 'network', 'generate', 'quality', 'scores', 'specific', 'facial', 'images', 'aggregation', 'specific', 'facial', 'images', 'second', 'counted', 'value', 'representing', 'count', 'specific', 'quality', 'scores', 'among', 'quality', 'scores', 'highest', 'counting', 'thereof', 'satisfies', 'second', 'set', 'value', 'deleting', 'part', 'specific', 'facial', 'images', 'corresponding', 'uncounted', 'quality', 'scores', 'smart', 'databasea', 'system', 'capable', 'determining', 'recognition', 'algorithms', 'applied', 'regions', 'interest', 'within', 'digital', 'representations', 'presented', 'preprocessing', 'module', 'utilizes', 'one', 'feature', 'identification', 'algorithms', 'determine', 'regions', 'interest', 'based', 'feature', 'density', 'preprocessing', 'modules', 'leverages', 'feature', 'density', 'signature', 'region', 'determine', 'plurality', 'diverse', 'recognition', 'modules', 'operate', 'region', 'interest', 'specific', 'embodiment', 'focuses', 'structured', 'documents', 'also', 'presented', 'disclosed', 'approach', 'enhanced', 'addition', 'object', 'classifier', 'classifies', 'types', 'objects', 'found', 'regions', 'interestdisclosed', 'mobile', 'terminal', 'mobile', 'terminal', 'may', 'include', 'front', 'camera', 'obtaining', 'face', 'image', 'user', 'glance', 'sensor', 'tilted', 'certain', 'angle', 'disposed', 'adjacent', 'front', 'camera', 'obtain', 'metadata', 'face', 'image', 'controller', 'obtaining', 'distance', 'glance', 'sensor', 'front', 'camera', 'distance', 'enabling', 'area', 'overlap', 'region', 'first', 'region', 'representing', 'range', 'photographable', 'front', 'camera', 'overlaps', 'second', 'region', 'representing', 'range', 'photographable', 'glance', 'sensor', 'maximumthis', 'disclosure', 'provides', 'systems', 'methods', 'apparatus', 'including', 'computer', 'programs', 'encoded', 'computer', 'storage', 'media', 'intelligent', 'routing', 'notifications', 'related', 'media', 'programming', 'one', 'aspect', 'smart', 'television', 'tv', 'implemented', 'track', 'user', \"'s\", 'tv', 'watching', 'behavior', 'anticipate', 'programming', 'based', 'behavior', 'aspects', 'smart', 'tv', 'implemented', 'detect', 'user', \"'s\", 'presence', 'based', 'detection', 'automatically', 'change', 'tv', 'channel', 'media', 'programming', 'analyzed', 'desirable', 'user', 'aspects', 'smart', 'tv', 'implemented', 'transmit', 'notification', 'instructions', 'electronic', 'devices', 'within', 'network', 'attempt', 'alert', 'user', 'upcoming', 'media', 'programming', 'additionally', 'smart', 'tv', 'implemented', 'transmit', 'detection', 'instructions', 'electronic', 'devices', 'within', 'network', 'whereby', 'electronic', 'devices', 'attempt', 'detect', 'user', \"'s\", 'presence', 'voice', 'facial', 'recognitiona', 'camera', 'configured', 'output', 'test', 'depth+multi-spectral', 'image', 'including', 'plurality', 'pixels', 'pixel', 'corresponds', 'one', 'plurality', 'sensors', 'sensor', 'array', 'camera', 'includes', 'least', 'depth', 'value', 'spectral', 'value', 'spectral', 'light', 'sub-band', 'plurality', 'spectral', 'illuminators', 'camera', 'face', 'recognition', 'machine', 'previously', 'trained', 'set', 'labeled', 'training', 'depth+multi-spectral', 'images', 'structure', 'test', 'depth+multi-spectral', 'image', 'face', 'recognition', 'machine', 'configured', 'output', 'confidence', 'value', 'indicating', 'likelihood', 'test', 'depth+multi-spectral', 'image', 'includes', 'faceembodiments', 'present', 'disclosure', 'relate', 'image', 'processing', 'method', 'apparatus', 'electronic', 'device', 'method', 'includes', 'acquiring', 'photo', 'album', 'obtained', 'face', 'clustering', 'collecting', 'face', 'information', 'respective', 'images', 'photo', 'album', 'acquiring', 'face', 'parameter', 'image', 'according', 'face', 'information', 'selecting', 'cover', 'image', 'according', 'face', 'parameter', 'image', 'taking', 'face-region', 'image', 'cover', 'image', 'setting', 'face-region', 'image', 'cover', 'photo', 'albumtechniques', 'described', 'herein', 'provide', 'location-based', 'access', 'control', 'secured', 'resources', 'generally', 'described', 'configurations', 'disclosed', 'herein', 'enable', 'system', 'dynamically', 'modify', 'access', 'secured', 'resources', 'based', 'one', 'location-related', 'actions', 'example', 'techniques', 'disclosed', 'herein', 'enable', 'computing', 'system', 'control', 'access', 'resources', 'computing', 'devices', 'display', 'devices', 'secured', 'locations', 'secured', 'data', 'configurations', 'techniques', 'disclosed', 'herein', 'enable', 'controlled', 'access', 'secured', 'resources', 'based', 'least', 'part', 'invitation', 'associated', 'location', 'positioning', 'data', 'indicating', 'location', 'userone', 'embodiment', 'provides', 'method', 'comprising', 'receiving', 'piece', 'content', 'salient', 'moments', 'data', 'piece', 'content', 'method', 'comprises', 'based', 'salient', 'moments', 'data', 'determining', 'first', 'path', 'viewport', 'piece', 'content', 'method', 'comprises', 'displaying', 'viewport', 'display', 'device', 'movement', 'viewport', 'based', 'first', 'path', 'playback', 'piece', 'content', 'method', 'comprises', 'generating', 'augmentation', 'salient', 'moment', 'occurring', 'piece', 'content', 'presenting', 'augmentation', 'viewport', 'portion', 'playback', 'augmentation', 'comprises', 'interactive', 'hint', 'guiding', 'viewport', 'salient', 'momenta', 'computer-implemented', 'method', 'system', 'computer', 'program', 'product', 'provided', 'facial', 'recognition', 'method', 'includes', 'receiving', 'processor', 'device', 'plurality', 'images', 'method', 'also', 'includes', 'extracting', 'processor', 'device', 'feature', 'extractor', 'utilizing', 'convolutional', 'neural', 'network', 'cnn', 'enlarged', 'intra-class', 'variance', 'long-tail', 'classes', 'feature', 'vectors', 'plurality', 'images', 'method', 'additionally', 'includes', 'generating', 'processor', 'device', 'feature', 'generator', 'discriminative', 'feature', 'vectors', 'feature', 'vectors', 'method', 'includes', 'classifying', 'processor', 'device', 'utilizing', 'fully', 'connected', 'classifier', 'identity', 'discriminative', 'feature', 'vector', 'method', 'also', 'includes', 'control', 'operation', 'processor-based', 'machine', 'react', 'accordance', 'identitysome', 'embodiments', 'invention', 'provide', 'efficient', 'expressive', 'machine-trained', 'networks', 'performing', 'machine', 'learning', 'machine-trained', 'mt', 'networks', 'embodiments', 'use', 'novel', 'processing', 'nodes', 'novel', 'activation', 'functions', 'allow', 'mt', 'network', 'efficiently', 'define', 'fewer', 'processing', 'node', 'layers', 'complex', 'mathematical', 'expression', 'solves', 'particular', 'problem', 'eg', 'face', 'recognition', 'speech', 'recognition', 'etc', 'embodiments', 'activation', 'function', 'eg', 'cup', 'function', 'used', 'numerous', 'processing', 'nodes', 'mt', 'network', 'machine', 'learning', 'activation', 'function', 'configured', 'differently', 'different', 'processing', 'nodes', 'different', 'nodes', 'emulate', 'implement', 'two', 'different', 'functions', 'eg', 'two', 'boolean', 'logical', 'operators', 'xor', 'activation', 'function', 'embodiments', 'periodic', 'function', 'configured', 'implement', 'different', 'functions', 'eg', 'different', 'sinusoidal', 'functionsmethods', 'systems', 'may', 'provide', 'facial', 'recognition', 'least', 'one', 'input', 'image', 'utilizing', 'hierarchical', 'feature', 'learning', 'pair-wise', 'classification', 'receptive', 'field', 'theory', 'may', 'used', 'input', 'image', 'generate', 'pre-processed', 'multi-channel', 'image', 'channels', 'pre-processed', 'image', 'may', 'activated', 'based', 'amount', 'feature', 'rich', 'details', 'within', 'channels', 'similarly', 'local', 'patches', 'may', 'activated', 'based', 'discriminant', 'features', 'within', 'local', 'patches', 'features', 'may', 'extracted', 'local', 'patches', 'discriminant', 'features', 'may', 'selected', 'order', 'perform', 'feature', 'matching', 'pair', 'sets', 'system', 'may', 'utilize', 'patch', 'feature', 'pooling', 'pair-wise', 'matching', 'large-scale', 'training', 'order', 'quickly', 'accurately', 'perform', 'facial', 'recognition', 'low', 'cost', 'system', 'memory', 'computationa', 'method', 'controlling', 'terminal', 'provided', 'terminal', 'includes', 'capturing', 'apparatus', 'least', 'one', 'processor', 'image', 'acquired', 'capturing', 'apparatus', 'motion', 'parameter', 'terminal', 'obtained', 'image', 'processing', 'acquired', 'image', 'controlled', 'performed', 'based', 'motion', 'parameter', 'equal', 'less', 'preset', 'parameter', 'threshold', 'skipped', 'based', 'motion', 'parameter', 'greater', 'preset', 'parameter', 'thresholda', 'drive-through', 'order', 'processing', 'method', 'apparatus', 'disclosed', 'drive-through', 'order', 'processing', 'method', 'includes', 'receiving', 'customer', 'information', 'detected', 'vision', 'recognition', 'providing', 'product', 'information', 'based', 'customer', 'information', 'processing', 'product', 'order', 'customer', 'according', 'present', 'disclosure', 'possible', 'rapidly', 'process', 'order', 'using', 'customer', 'information', 'based', 'customer', 'recognition', 'using', 'artificial', 'intelligence', 'ai', 'model', 'machine', 'learning', 'g', 'networkan', 'image', 'processing', 'method', 'performed', 'computing', 'device', 'includes', 'identifying', 'using', 'face', 'recognition', 'one', 'faces', 'face', 'corresponding', 'respective', 'person', 'captured', 'first', 'image', 'identified', 'face', 'extracting', 'set', 'profile', 'parameters', 'corresponding', 'person', 'first', 'image', 'selecting', 'plurality', 'image', 'tiles', 'first', 'image', 'tile', 'matches', 'face', 'corresponding', 'person', 'first', 'image', 'accordance', 'predefined', 'correspondence', 'set', 'profile', 'parameters', 'corresponding', 'person', 'set', 'pre-stored', 'description', 'parameters', 'first', 'image', 'tile', 'generating', 'second', 'image', 'covering', 'faces', 'respective', 'persons', 'first', 'image', 'corresponding', 'first', 'image', 'tiles', 'sharing', 'first', 'image', 'second', 'image', 'predefined', 'order', 'via', 'group', 'chat', 'sessionin', 'one', 'embodiment', 'artificial', 'reality', 'system', 'determines', 'performance', 'metric', 'eye', 'tracking', 'system', 'first', 'performance', 'threshold', 'eye', 'tracking', 'system', 'associated', 'head-mounted', 'display', 'worn', 'user', 'artificial', 'reality', 'system', 'receives', 'first', 'inputs', 'associated', 'body', 'user', 'determines', 'region', 'user', 'looking', 'within', 'field', 'view', 'head-mounted', 'display', 'based', 'received', 'first', 'inputs', 'system', 'determines', 'vergence', 'distance', 'user', 'based', 'least', 'first', 'inputs', 'associated', 'body', 'user', 'region', 'user', 'looking', 'locations', 'one', 'objects', 'scene', 'displayed', 'head-mounted', 'display', 'system', 'adjusts', 'one', 'configurations', 'head-mounted', 'display', 'based', 'determined', 'vergence', 'distance', 'usera', 'computer-implemented', 'method', 'provided', 'image-based', 'self-guided', 'object', 'detection', 'method', 'includes', 'receiving', 'processor', 'device', 'set', 'images', 'images', 'respective', 'grid', 'thereon', 'labeled', 'regarding', 'respective', 'object', 'detected', 'using', 'grid', 'level', 'label', 'data', 'method', 'includes', 'training', 'processor', 'device', 'grid-based', 'object', 'detector', 'using', 'grid', 'level', 'label', 'data', 'method', 'also', 'includes', 'determining', 'processor', 'device', 'respective', 'bounding', 'box', 'respective', 'object', 'images', 'applying', 'local', 'segmentation', 'images', 'method', 'additionally', 'includes', 'training', 'processor', 'device', 'region-based', 'convolutional', 'neural', 'network', 'rcnn', 'joint', 'object', 'localization', 'object', 'classification', 'using', 'respective', 'bounding', 'box', 'respective', 'object', 'images', 'input', 'rcnna', 'system', 'method', 'face', 'recognition', 'comprising', 'multiple', 'phases', 'implemented', 'parallel', 'architecture', 'first', 'phase', 'normalization', 'phase', 'whereby', 'captured', 'image', 'normalized', 'size', 'orientation', 'illumination', 'stored', 'images', 'preexisting', 'database', 'second', 'phase', 'feature', 'extractiondistance', 'matrix', 'phase', 'distance', 'matrix', 'generated', 'captured', 'image', 'coarse', 'recognition', 'phase', 'generated', 'distance', 'matrix', 'compared', 'distance', 'matrices', 'database', 'using', 'euclidean', 'distance', 'matches', 'create', 'candidate', 'lists', 'detailed', 'recognition', 'phase', 'multiple', 'face', 'recognition', 'algorithms', 'applied', 'candidate', 'lists', 'produce', 'final', 'result', 'distance', 'matrices', 'normalized', 'database', 'may', 'broken', 'parallel', 'lists', 'parallelization', 'feature', 'extractiondistance', 'matrix', 'phase', 'candidate', 'lists', 'may', 'also', 'grouped', 'according', 'dissimilarity', 'algorithm', 'parallel', 'processing', 'detailed', 'recognition', 'phasean', 'imaging', 'device', 'including', 'pixel', 'matrix', 'processor', 'provided', 'pixel', 'matrix', 'includes', 'plurality', 'phase', 'detection', 'pixels', 'plurality', 'regular', 'pixels', 'processor', 'performs', 'autofocusing', 'according', 'pixel', 'data', 'phase', 'detection', 'pixels', 'determines', 'operating', 'resolution', 'regular', 'pixels', 'according', 'autofocused', 'pixel', 'data', 'phase', 'detection', 'pixels', 'wherein', 'phase', 'detection', 'pixels', 'always-on', 'pixels', 'regular', 'pixels', 'selectively', 'turned', 'autofocusing', 'accomplishedan', 'apparatus', 'includes', 'first', 'camera', 'module', 'providing', 'first', 'image', 'object', 'first', 'field', 'view', 'second', 'camera', 'module', 'providing', 'second', 'image', 'object', 'second', 'field', 'view', 'different', 'first', 'field', 'view', 'first', 'depth', 'map', 'generator', 'generates', 'first', 'depth', 'map', 'first', 'image', 'based', 'first', 'image', 'second', 'image', 'second', 'depth', 'map', 'generator', 'generates', 'second', 'depth', 'map', 'second', 'image', 'based', 'first', 'image', 'second', 'image', 'first', 'depth', 'mapmethods', 'systems', 'apparatus', 'including', 'computer', 'programs', 'encoded', 'computer', 'storage', 'media', 'payment', 'based', 'face', 'recognition', 'provided', 'one', 'methods', 'includes', 'acquiring', 'first', 'face', 'image', 'information', 'target', 'user', 'extracting', 'first', 'characteristic', 'information', 'first', 'face', 'image', 'information', 'wherein', 'first', 'characteristic', 'information', 'includes', 'head', 'posture', 'information', 'target', 'user', 'gaze', 'information', 'target', 'user', 'determining', 'whether', 'target', 'user', 'willingness', 'pay', 'according', 'head', 'posture', 'information', 'target', 'user', 'gaze', 'information', 'target', 'user', 'including', 'determining', 'whether', 'angle', 'rotation', 'preset', 'direction', 'less', 'angle', 'threshold', 'whether', 'probability', 'value', 'user', 'gazes', 'payment', 'screen', 'greater', 'probability', 'threshold', 'response', 'determining', 'target', 'user', 'willingness', 'pay', 'completing', 'payment', 'operation', 'based', 'face', 'recognitiona', 'novel', 'method', 'apparatus', 'face', 'authentication', 'disclosed', 'disclosed', 'method', 'comprises', 'detecting', 'motion', 'subject', 'within', 'predetermined', 'area', 'view', 'assigning', 'unique', 'session', 'identification', 'number', 'subject', 'detected', 'within', 'predetermined', 'area', 'view', 'detecting', 'facial', 'area', 'subject', 'detected', 'within', 'predetermined', 'area', 'view', 'generating', 'image', 'facial', 'area', 'subject', 'assessing', 'quality', 'image', 'facial', 'area', 'subject', 'conducing', 'incremental', 'training', 'image', 'facial', 'area', 'subject', 'determining', 'identity', 'subject', 'based', 'image', 'facial', 'area', 'subject', 'identifying', 'intent', 'subject', 'authorizing', 'access', 'point', 'entry', 'based', 'determined', 'identity', 'subject', 'based', 'intent', 'subjectdisclosed', 'herein', 'robot', 'electronic', 'device', 'acquiring', 'video', 'method', 'acquiring', 'video', 'using', 'robot', 'robot', 'includes', 'camera', 'configured', 'rotate', 'lateral', 'direction', 'tilt', 'vertical', 'direction', 'controls', 'least', 'one', 'direction', 'rotation', 'camera', 'angle', 'tilt', 'camera', 'focal', 'distance', 'camera', 'recognizing', 'tracking', 'users', 'video', 'acquired', 'camerasystems', 'methods', 'disclosed', 'inferring', 'topics', 'file', 'containing', 'audio', 'video', 'example', 'multimodal', 'multimedia', 'file', 'order', 'facilitate', 'video', 'indexing', 'set', 'entities', 'extracted', 'file', 'linked', 'produce', 'graph', 'reference', 'information', 'also', 'obtained', 'set', 'entities', 'entities', 'may', 'drawn', 'example', 'wikipedia', 'categories', 'large', 'ontological', 'data', 'sources', 'analysis', 'graph', 'using', 'unsupervised', 'learning', 'permits', 'determining', 'clusters', 'graph', 'extracting', 'features', 'clusters', 'possibly', 'using', 'supervised', 'learning', 'provides', 'selection', 'topic', 'identifiers', 'topic', 'identifiers', 'used', 'indexing', 'filea', 'face', 'recognition', 'method', 'neural', 'network', 'training', 'method', 'apparatus', 'electronic', 'device', 'method', 'comprises', 'obtaining', 'first', 'face', 'image', 'means', 'first', 'camera', 'extracting', 'first', 'face', 'feature', 'first', 'face', 'image', 'comparing', 'first', 'face', 'feature', 'pre-stored', 'second', 'face', 'feature', 'obtain', 'reference', 'similarity', 'second', 'face', 'feature', 'obtained', 'extracting', 'feature', 'second', 'face', 'image', 'obtained', 'second', 'camera', 'second', 'camera', 'first', 'camera', 'different', 'types', 'cameras', 'determining', 'according', 'reference', 'similarity', 'whether', 'first', 'face', 'feature', 'second', 'face', 'feature', 'correspond', 'person', 'present', 'invention', 'discloses', 'technique', 'alerting', 'vision', 'impairment', 'system', 'comprises', 'processing', 'unit', 'configured', 'operable', 'receiving', 'scene', 'data', 'indicative', 'scene', 'least', 'one', 'consumer', 'environment', 'identifying', 'scene', 'data', 'certain', 'consumer', 'identifying', 'event', 'indicative', 'behavioral', 'compensation', 'vision', 'impairment', 'upon', 'identification', 'event', 'sending', 'notification', 'relating', 'vision', 'impairment']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['electronic', 'device', 'configured', 'make', 'screen', 'display', 'plurality', 'image', 'frames', 'comprising', 'image', 'capturing', 'device', 'storage', 'device', 'storing', 'plurality', 'modules', 'processor', 'coupled', 'image', 'capturing', 'device', 'storage', 'device', 'configured', 'execute', 'modules', 'storage', 'device', 'configure', 'screen', 'display', 'plurality', 'marker', 'objects', 'plurality', 'predetermined', 'calibration', 'positions', 'configure', 'image', 'capturing', 'device', 'capture', 'plurality', 'first', 'head', 'images', 'user', 'looking', 'predetermined', 'calibration', 'positions', 'perform', 'plurality', 'first', 'face', 'recognition', 'operations', 'first', 'head', 'images', 'obtain', 'plurality', 'first', 'face', 'regions', 'corresponding', 'predetermined', 'calibration', 'positions', 'detect', 'plurality', 'first', 'facial', 'landmarks', 'corresponding', 'first', 'face', 'regions', 'calculate', 'plurality', 'rotation', 'reference', 'angles', 'user', 'looking', 'predetermined', 'calibration', 'positions', 'according', 'first', 'facial', 'landmarks', 'configure', 'image', 'capturing', 'device', 'capture', 'second', 'head', 'image', 'user', 'perform', 'second', 'face', 'recognition', 'operation', 'second', 'head', 'image', 'obtain', 'second', 'face', 'region', 'detect', 'plurality', 'second', 'facial', 'landmarks', 'within', 'second', 'face', 'region', 'estimate', 'head', 'posture', 'angle', 'user', 'according', 'second', 'facial', 'landmarks', 'calculate', 'gaze', 'position', 'user', 'screen', 'according', 'head', 'posture', 'angle', 'rotation', 'reference', 'angles', 'predetermined', 'calibration', 'positions', 'configure', 'screen', 'display', 'corresponding', 'visual', 'effect', 'according', 'gaze', 'position', 'electronic', 'device', 'according', 'claim', 'wherein', 'gaze', 'position', 'comprises', 'first', 'coordinate', 'value', 'first', 'axial', 'direction', 'second', 'coordinate', 'value', 'second', 'axial', 'direction', 'electronic', 'device', 'according', 'claim', 'wherein', 'head', 'posture', 'angles', 'comprise', 'head', 'pitch', 'angle', 'head', 'yaw', 'angle', 'rotation', 'reference', 'angles', 'comprise', 'first', 'pitch', 'angle', 'second', 'pitch', 'angle', 'first', 'yaw', 'angle', 'second', 'yaw', 'angle', 'corresponding', 'predetermined', 'calibration', 'positions', 'electronic', 'device', 'according', 'claim', 'wherein', 'processor', 'performs', 'interpolation', 'operation', 'extrapolation', 'operation', 'according', 'first', 'yaw', 'angle', 'second', 'yaw', 'angle', 'first', 'position', 'corresponding', 'first', 'yaw', 'angle', 'among', 'predetermined', 'calibration', 'positions', 'second', 'position', 'corresponding', 'second', 'yaw', 'angle', 'among', 'predetermined', 'calibration', 'positions', 'head', 'yaw', 'angle', 'thereby', 'obtaining', 'first', 'coordinate', 'value', 'gaze', 'position', 'processor', 'performs', 'interpolation', 'operation', 'extrapolation', 'operation', 'according', 'first', 'pitch', 'angle', 'second', 'pitch', 'angle', 'third', 'position', 'corresponding', 'first', 'pitch', 'angle', 'among', 'predetermined', 'calibration', 'positions', 'fourth', 'position', 'corresponding', 'second', 'pitch', 'angle', 'among', 'predetermined', 'calibration', 'positions', 'head', 'pitch', 'angle', 'thereby', 'obtaining', 'second', 'coordinate', 'value', 'gaze', 'position', 'electronic', 'device', 'according', 'claim', 'wherein', 'processor', 'calculates', 'plurality', 'first', 'viewing', 'distances', 'user', 'screen', 'according', 'first', 'facial', 'landmarks', 'processor', 'estimates', 'second', 'viewing', 'distance', 'user', 'screen', 'according', 'second', 'facial', 'landmarks', 'processor', 'adjusts', 'rotation', 'reference', 'angles', 'gaze', 'position', 'according', 'second', 'viewing', 'distance', 'first', 'viewing', 'distances', 'electronic', 'device', 'according', 'claim', 'wherein', 'processor', 'maps', 'plurality', 'two-dimensional', 'position', 'coordinates', 'second', 'facial', 'landmarks', 'plane', 'coordinate', 'system', 'plurality', 'three-dimensional', 'position', 'coordinates', 'three-dimensional', 'coordinate', 'system', 'processor', 'estimates', 'head', 'posture', 'angle', 'according', 'three-dimensional', 'position', 'coordinates', 'second', 'facial', 'landmarks', 'electronic', 'device', 'according', 'claim', 'wherein', 'second', 'head', 'image', 'comprises', 'wearable', 'device', 'second', 'facial', 'landmarks', 'comprise', 'plurality', 'third', 'facial', 'landmarks', 'user', 'covered', 'wearable', 'device', 'electronic', 'device', 'according', 'claim', 'wherein', 'second', 'head', 'image', 'comprises', 'wearable', 'device', 'second', 'facial', 'landmarks', 'comprise', 'one', 'simulated', 'landmarks', 'marked', 'wearable', 'device', 'operating', 'method', 'adapted', 'electronic', 'device', 'comprising', 'image', 'capturing', 'device', 'making', 'screen', 'display', 'plurality', 'image', 'frames', 'method', 'comprising', 'configuring', 'screen', 'display', 'plurality', 'marker', 'objects', 'plurality', 'predetermined', 'calibration', 'positions', 'configuring', 'image', 'capturing', 'device', 'capture', 'plurality', 'first', 'head', 'images', 'user', 'looking', 'predetermined', 'calibration', 'positions', 'performing', 'plurality', 'first', 'face', 'recognition', 'operations', 'first', 'head', 'images', 'obtain', 'plurality', 'first', 'face', 'regions', 'corresponding', 'predetermined', 'calibration', 'positions', 'detecting', 'plurality', 'first', 'facial', 'landmarks', 'corresponding', 'first', 'face', 'regions', 'calculating', 'plurality', 'rotation', 'reference', 'angles', 'user', 'looking', 'predetermined', 'calibration', 'positions', 'according', 'first', 'facial', 'landmarks', 'configuring', 'image', 'capturing', 'device', 'capture', 'second', 'head', 'image', 'user', 'performing', 'second', 'face', 'recognition', 'operation', 'second', 'head', 'image', 'obtain', 'second', 'face', 'region', 'detecting', 'plurality', 'second', 'facial', 'landmarks', 'within', 'second', 'face', 'region', 'estimating', 'head', 'posture', 'angle', 'user', 'according', 'second', 'facial', 'landmarks', 'calculating', 'gaze', 'position', 'user', 'screen', 'according', 'head', 'posture', 'angle', 'rotation', 'reference', 'angles', 'predetermined', 'calibration', 'positions', 'configuring', 'screen', 'display', 'corresponding', 'visual', 'effect', 'according', 'gaze', 'position', 'operation', 'method', 'according', 'claim', 'wherein', 'gaze', 'position', 'comprises', 'first', 'coordinate', 'value', 'first', 'axial', 'direction', 'second', 'coordinate', 'value', 'second', 'axial', 'direction', 'operation', 'method', 'according', 'claim', 'wherein', 'head', 'posture', 'angles', 'comprise', 'head', 'pitch', 'angle', 'head', 'yaw', 'angle', 'rotation', 'reference', 'angles', 'comprise', 'first', 'pitch', 'angle', 'second', 'pitch', 'angle', 'first', 'yaw', 'angle', 'second', 'yaw', 'angle', 'corresponding', 'predetermined', 'calibration', 'positions', 'operation', 'method', 'according', 'claim', 'wherein', 'step', 'calculating', 'gaze', 'position', 'user', 'screen', 'according', 'head', 'posture', 'angle', 'rotation', 'reference', 'angles', 'predetermined', 'calibration', 'positions', 'comprises', 'performing', 'interpolation', 'operation', 'extrapolation', 'operation', 'according', 'first', 'yaw', 'angle', 'second', 'yaw', 'angle', 'first', 'position', 'corresponding', 'first', 'yaw', 'angle', 'among', 'predetermined', 'calibration', 'positions', 'second', 'position', 'corresponding', 'second', 'yaw', 'angle', 'among', 'predetermined', 'calibration', 'positions', 'head', 'yaw', 'angle', 'thereby', 'obtaining', 'first', 'coordinate', 'value', 'gaze', 'position', 'performing', 'interpolation', 'operation', 'extrapolation', 'operation', 'according', 'first', 'pitch', 'angle', 'second', 'pitch', 'angle', 'third', 'position', 'corresponding', 'first', 'pitch', 'angle', 'among', 'predetermined', 'calibration', 'positions', 'fourth', 'position', 'corresponding', 'second', 'pitch', 'angle', 'among', 'predetermined', 'calibration', 'positions', 'head', 'pitch', 'angle', 'thereby', 'obtaining', 'second', 'coordinate', 'value', 'gaze', 'position', 'operation', 'method', 'according', 'claim', 'wherein', 'method', 'comprises', 'calculating', 'plurality', 'first', 'viewing', 'distances', 'user', 'screen', 'according', 'first', 'facial', 'landmarks', 'estimating', 'second', 'viewing', 'distance', 'user', 'screen', 'according', 'second', 'facial', 'landmarks', 'adjusting', 'rotation', 'reference', 'angles', 'gaze', 'position', 'according', 'second', 'viewing', 'distance', 'first', 'viewing', 'distances', 'operation', 'method', 'according', 'claim', 'wherein', 'method', 'comprises', 'mapping', 'plurality', 'two-dimensional', 'position', 'coordinates', 'second', 'facial', 'landmarks', 'plane', 'coordinate', 'system', 'plurality', 'three-dimensional', 'position', 'coordinates', 'three-dimensional', 'coordinate', 'system', 'estimating', 'head', 'posture', 'angle', 'according', 'three-dimensional', 'position', 'coordinates', 'second', 'facial', 'landmarks', 'operation', 'method', 'according', 'claim', 'wherein', 'second', 'head', 'image', 'comprises', 'wearable', 'device', 'second', 'facial', 'landmarks', 'comprise', 'plurality', 'third', 'facial', 'landmarks', 'user', 'covered', 'wearable', 'device', 'operation', 'method', 'according', 'claim', 'wherein', 'second', 'head', 'image', 'comprises', 'wearable', 'device', 'second', 'facial', 'landmarks', 'comprise', 'one', 'simulated', 'landmarks', 'marked', 'wearable', 'device', 'computation', 'method', 'applied', 'computing', 'system', 'wherein', 'computing', 'system', 'comprises', 'control', 'unit', 'computation', 'group', 'general', 'storage', 'unit', 'wherein', 'control', 'unit', 'comprises', 'first', 'memory', 'decoding', 'logic', 'controller', 'wherein', 'computation', 'group', 'comprises', 'group', 'controller', 'plurality', 'computing', 'units', 'general', 'storage', 'unit', 'configured', 'store', 'data', 'computation', 'method', 'comprises', 'receiving', 'controller', 'first', 'level', 'instruction', 'sequence', 'partitioning', 'decoding', 'logic', 'first', 'level', 'instruction', 'sequence', 'plurality', 'second', 'level', 'instruction', 'sequences', 'creating', 'controller', 'threads', 'plurality', 'second', 'level', 'instruction', 'sequences', 'allocating', 'controller', 'independent', 'register', 'well', 'configuring', 'independent', 'addressing', 'function', 'thread', 'threads', 'wherein', 'integer', 'greater', 'equal', 'obtaining', 'group', 'controller', 'plurality', 'computation', 'types', 'plurality', 'second', 'level', 'instruction', 'sequences', 'obtaining', 'corresponding', 'fusion', 'computation', 'manner', 'computation', 'types', 'according', 'plurality', 'computation', 'types', 'adopting', 'plurality', 'computing', 'units', 'fusion', 'computation', 'manner', 'call', 'threads', 'performing', 'computations', 'plurality', 'second', 'level', 'instruction', 'sequences', 'obtain', 'final', 'result', 'method', 'claim', 'wherein', 'obtaining', 'group', 'controller', 'plurality', 'computation', 'types', 'plurality', 'second', 'level', 'instruction', 'sequences', 'obtaining', 'corresponding', 'fusion', 'computation', 'manner', 'computation', 'types', 'according', 'plurality', 'computation', 'types', 'adopting', 'plurality', 'computing', 'units', 'fusion', 'computation', 'manner', 'call', 'threads', 'performing', 'computations', 'plurality', 'second', 'instruction', 'sequences', 'obtain', 'final', 'result', 'computation', 'types', 'represent', 'computation', 'operations', 'type', 'group', 'controller', 'calls', 'combined', 'computation', 'manner', 'single', 'instruction', 'multiple', 'data', 'type', 'combination', 'single', 'instruction', 'multiple', 'threads', 'uses', 'threads', 'perform', 'combined', 'computation', 'manner', 'obtain', 'final', 'result', 'includes', 'partitioning', 'decoding', 'logic', 'threads', 'n', 'wraps', 'allocating', 'plurality', 'computing', 'units', 'converting', 'group', 'controller', 'plurality', 'second', 'instruction', 'sequences', 'plurality', 'second', 'control', 'signals', 'sending', 'second', 'control', 'signals', 'plurality', 'computing', 'units', 'calling', 'plurality', 'computing', 'units', 'wraps', 'allocated', 'computing', 'units', 'second', 'control', 'signals', 'fetch', 'corresponding', 'data', 'according', 'independent', 'addressing', 'function', 'performing', 'plurality', 'computing', 'units', 'computations', 'data', 'obtain', 'plurality', 'intermediate', 'results', 'splicing', 'plurality', 'intermediate', 'results', 'obtain', 'final', 'result', 'method', 'claim', 'wherein', 'obtaining', 'group', 'controller', 'plurality', 'computation', 'types', 'plurality', 'second', 'level', 'instruction', 'sequences', 'obtaining', 'corresponding', 'fusion', 'computation', 'manner', 'computation', 'types', 'according', 'plurality', 'computation', 'types', 'adopting', 'plurality', 'computing', 'units', 'fusion', 'computation', 'manner', 'call', 'threads', 'performing', 'computations', 'plurality', 'second', 'instruction', 'sequences', 'obtain', 'final', 'result', 'computation', 'types', 'represent', 'computation', 'operations', 'different', 'types', 'group', 'controller', 'calls', 'simultaneous', 'multi-threading', 'threads', 'perform', 'computations', 'obtain', 'final', 'result', 'includes', 'partitioning', 'decoding', 'logic', 'threads', 'n', 'wraps', 'converting', 'plurality', 'second', 'instruction', 'sequences', 'plurality', 'second', 'control', 'signals', 'obtaining', 'group', 'controller', 'computation', 'types', 'supported', 'plurality', 'computing', 'units', 'allocating', 'controller', 'n', 'wraps', 'plurality', 'second', 'control', 'signals', 'corresponding', 'computing', 'units', 'support', 'computation', 'types', 'wraps', 'second', 'control', 'signals', 'calling', 'plurality', 'computing', 'units', 'wraps', 'allocated', 'computing', 'units', 'second', 'control', 'signals', 'fetching', 'plurality', 'computing', 'units', 'corresponding', 'data', 'performing', 'plurality', 'computing', 'units', 'computations', 'data', 'obtain', 'plurality', 'intermediate', 'results', 'splicing', 'intermediate', 'results', 'obtain', 'final', 'result', 'method', 'claim', 'comprising', 'wrap', 'plurality', 'wraps', 'blocked', 'adding', 'wrap', 'waiting', 'queue', 'data', 'wrap', 'already', 'fetched', 'adding', 'wrap', 'preparation', 'queue', 'wherein', 'preparation', 'queue', 'queue', 'wrap', 'scheduled', 'executing', 'located', 'computing', 'resource', 'idle', 'method', 'claim', 'wherein', 'first', 'level', 'instruction', 'sequence', 'includes', 'long', 'instruction', 'second', 'level', 'instruction', 'sequence', 'includes', 'instruction', 'sequence', 'method', 'claim', 'wherein', 'computing', 'system', 'includes', 'tree', 'module', 'wherein', 'tree', 'module', 'includes', 'root', 'port', 'plurality', 'branch', 'ports', 'wherein', 'root', 'port', 'tree', 'module', 'connected', 'group', 'controller', 'plurality', 'branch', 'ports', 'tree', 'module', 'connected', 'computing', 'unit', 'plurality', 'computing', 'units', 'respectively', 'tree', 'module', 'configured', 'forward', 'data', 'blocks', 'wraps', 'instruction', 'sequences', 'group', 'controller', 'plurality', 'computing', 'units', 'method', 'claim', 'wherein', 'tree', 'module', 'n-ary', 'tree', 'wherein', 'n', 'integer', 'greater', 'equal', 'method', 'claim', 'wherein', 'computing', 'system', 'includes', 'branch', 'processing', 'circuit', 'wherein', 'branch', 'processing', 'circuit', 'connected', 'group', 'controller', 'plurality', 'computing', 'units', 'branch', 'processing', 'circuit', 'configured', 'forward', 'data', 'wraps', 'instruction', 'sequences', 'group', 'controller', 'plurality', 'computing', 'units', 'computing', 'system', 'comprising', 'control', 'unit', 'computation', 'group', 'general', 'storage', 'unit', 'wherein', 'control', 'unit', 'includes', 'first', 'memory', 'decoding', 'logic', 'controller', 'computation', 'group', 'includes', 'group', 'controller', 'plurality', 'computing', 'units', 'general', 'storage', 'unit', 'configured', 'store', 'data', 'controller', 'configured', 'receive', 'first', 'level', 'instruction', 'sequence', 'control', 'first', 'memory', 'decoding', 'logic', 'decoding', 'logic', 'configured', 'partition', 'first', 'level', 'instruction', 'sequence', 'plurality', 'second', 'level', 'instruction', 'sequences', 'controller', 'configured', 'create', 'threads', 'plurality', 'second', 'level', 'instruction', 'sequences', 'allocate', 'independent', 'register', 'configure', 'independent', 'addressing', 'function', 'thread', 'threads', 'integer', 'greater', 'equal', 'controller', 'configured', 'convert', 'plurality', 'second', 'instruction', 'sequences', 'plurality', 'control', 'signals', 'sending', 'group', 'controller', 'group', 'controller', 'configured', 'receive', 'plurality', 'control', 'signals', 'obtain', 'plurality', 'computational', 'types', 'plurality', 'control', 'signals', 'divide', 'threads', 'n', 'wraps', 'allocate', 'n', 'wraps', 'plurality', 'control', 'signals', 'plurality', 'computing', 'units', 'according', 'plurality', 'computational', 'types', 'plurality', 'computing', 'units', 'configured', 'fetch', 'data', 'general', 'storage', 'unit', 'allocated', 'wraps', 'control', 'signals', 'perform', 'computations', 'obtain', 'intermediate', 'result', 'group', 'controller', 'configured', 'splice', 'intermediate', 'results', 'obtain', 'final', 'computation', 'result', 'computing', 'system', 'claim', 'wherein', 'plurality', 'computing', 'units', 'includes', 'addition', 'computing', 'unit', 'multiplication', 'computing', 'unit', 'activation', 'computing', 'unit', 'dedicated', 'computing', 'unit', 'computing', 'system', 'claim', 'wherein', 'dedicated', 'computing', 'unit', 'includes', 'face', 'recognition', 'computing', 'unit', 'graphics', 'computing', 'unit', 'fingerprint', 'computing', 'unit', 'neural', 'network', 'computing', 'unit', 'computing', 'system', 'claim', 'wherein', 'group', 'controller', 'configured', 'computation', 'types', 'plurality', 'control', 'signals', 'graphics', 'computations', 'fingerprint', 'identification', 'face', 'recognition', 'neural', 'network', 'operations', 'allocate', 'plurality', 'control', 'signals', 'face', 'recognition', 'computing', 'unit', 'graphics', 'computing', 'unit', 'fingerprint', 'computing', 'unit', 'neural', 'network', 'computing', 'unit', 'respectively', 'computing', 'system', 'claim', 'wherein', 'first', 'level', 'instruction', 'sequence', 'includes', 'long', 'instruction', 'second', 'level', 'instruction', 'sequence', 'includes', 'instruction', 'sequence', 'computing', 'system', 'claim', 'comprising', 'tree', 'module', 'wherein', 'tree', 'module', 'includes', 'root', 'port', 'plurality', 'branch', 'ports', 'wherein', 'root', 'port', 'tree', 'module', 'connected', 'group', 'controller', 'plurality', 'branch', 'ports', 'tree', 'module', 'connected', 'computing', 'unit', 'plurality', 'computing', 'units', 'respectively', 'tree', 'module', 'configured', 'forward', 'data', 'blocks', 'wraps', 'instruction', 'sequences', 'group', 'controller', 'plurality', 'computing', 'units', 'computing', 'system', 'claim', 'wherein', 'tree', 'module', 'n-ary', 'tree', 'wherein', 'n', 'integer', 'greater', 'equal', 'computing', 'system', 'claim', 'wherein', 'computing', 'system', 'includes', 'branch', 'processing', 'circuit', 'branch', 'processing', 'circuit', 'connected', 'group', 'controller', 'plurality', 'computing', 'units', 'branch', 'processing', 'circuit', 'configured', 'forward', 'data', 'wraps', 'instruction', 'sequences', 'group', 'controller', 'plurality', 'computing', 'units', 'computer', 'program', 'product', 'comprising', 'non-instant', 'computer', 'readable', 'storage', 'medium', 'wherein', 'computer', 'program', 'stored', 'non-instant', 'computer', 'readable', 'storage', 'medium', 'computer', 'program', 'capable', 'causing', 'computer', 'perform', 'method', 'claims', '-', 'operations', 'method', 'detecting', 'body', 'information', 'one', 'passengers', 'vehicle', 'based', 'humans', \"'\", 'status', 'recognition', 'comprising', 'steps', 'least', 'one', 'interior', 'image', 'interior', 'vehicle', 'acquired', 'passenger', 'body', 'information-detecting', 'device', 'performing', 'process', 'inputting', 'interior', 'image', 'face', 'recognition', 'network', 'thereby', 'allow', 'face', 'recognition', 'network', 'detect', 'faces', 'passengers', 'interior', 'image', 'thus', 'output', 'multiple', 'pieces', 'passenger', 'feature', 'information', 'corresponding', 'detected', 'faces', 'ii', 'process', 'inputting', 'interior', 'image', 'body', 'recognition', 'network', 'thereby', 'allow', 'body', 'recognition', 'network', 'detect', 'bodies', 'passengers', 'interior', 'image', 'thus', 'output', 'body-part', 'length', 'information', 'detected', 'bodies', 'b', 'passenger', 'body', 'information-detecting', 'device', 'performing', 'process', 'retrieving', 'specific', 'height', 'mapping', 'information', 'corresponding', 'specific', 'passenger', 'feature', 'information', 'specific', 'passenger', 'height', 'mapping', 'table', 'stores', 'height', 'mapping', 'information', 'representing', 'respective', 'one', 'predetermined', 'ratios', 'one', 'segment', 'body', 'portions', 'human', 'groups', 'heights', 'per', 'human', 'groups', 'process', 'acquiring', 'specific', 'height', 'specific', 'passenger', 'specific', 'height', 'mapping', 'information', 'referring', 'specific', 'body-part', 'length', 'information', 'specific', 'passenger', 'process', 'retrieving', 'specific', 'weight', 'mapping', 'information', 'corresponding', 'specific', 'passenger', 'feature', 'information', 'weight', 'mapping', 'table', 'stores', 'multiple', 'pieces', 'weight', 'mapping', 'information', 'representing', 'predetermined', 'correlations', 'heights', 'weights', 'per', 'human', 'groups', 'process', 'acquiring', 'weight', 'specific', 'passenger', 'specific', 'weight', 'mapping', 'information', 'referring', 'specific', 'height', 'specific', 'passenger', 'method', 'claim', 'wherein', 'step', 'passenger', 'body', 'information-detecting', 'device', 'performs', 'process', 'inputting', 'interior', 'image', 'body', 'recognition', 'network', 'thereby', 'allow', 'body', 'recognition', 'network', 'output', 'one', 'feature', 'tensors', 'one', 'channels', 'corresponding', 'interior', 'image', 'via', 'feature', 'extraction', 'network', 'ii', 'generate', 'least', 'one', 'keypoint', 'heatmap', 'least', 'one', 'part', 'affinity', 'field', 'one', 'channels', 'corresponding', 'feature', 'tensors', 'via', 'keypoint', 'heatmap', '&', 'part', 'affinity', 'field', 'extractor', 'iii', 'extract', 'keypoints', 'keypoint', 'heatmap', 'via', 'keypoint', 'detector', 'group', 'extracted', 'keypoints', 'referring', 'part', 'affinity', 'field', 'thus', 'generate', 'body', 'parts', 'per', 'passengers', 'result', 'allow', 'body', 'recognition', 'network', 'output', 'multiple', 'pieces', 'body-part', 'length', 'information', 'passengers', 'referring', 'body', 'parts', 'per', 'passengers', 'method', 'claim', 'wherein', 'feature', 'extraction', 'network', 'includes', 'least', 'one', 'convolutional', 'layer', 'applies', 'least', 'one', 'convolution', 'operation', 'interior', 'image', 'thereby', 'output', 'feature', 'tensors', 'method', 'claim', 'wherein', 'keypoint', 'heatmap', '&', 'part', 'affinity', 'field', 'extractor', 'includes', 'one', 'fully', 'convolutional', 'network', '×', 'convolutional', 'layer', 'applies', 'fully-convolution', 'operation', '×', 'convolution', 'operation', 'feature', 'tensors', 'thereby', 'generate', 'keypoint', 'heatmap', 'part', 'affinity', 'field', 'method', 'claim', 'wherein', 'keypoint', 'detector', 'connects', 'referring', 'part', 'affinity', 'field', 'pairs', 'respectively', 'highest', 'mutual', 'connection', 'probabilities', 'connected', 'among', 'extracted', 'keypoints', 'thereby', 'group', 'extracted', 'keypoints', 'method', 'claim', 'wherein', 'feature', 'extraction', 'network', 'keypoint', 'heatmap', '&', 'part', 'affinity', 'field', 'extractor', 'learned', 'learning', 'device', 'performing', 'process', 'inputting', 'least', 'one', 'training', 'image', 'including', 'one', 'objects', 'training', 'feature', 'extraction', 'network', 'thereby', 'allow', 'feature', 'extraction', 'network', 'generate', 'one', 'feature', 'tensors', 'training', 'one', 'channels', 'applying', 'least', 'one', 'convolutional', 'operation', 'training', 'image', 'ii', 'process', 'inputting', 'feature', 'tensors', 'training', 'keypoint', 'heatmap', '&', 'part', 'affinity', 'field', 'extractor', 'thereby', 'allow', 'keypoint', 'heatmap', '&', 'part', 'affinity', 'field', 'extractor', 'generate', 'one', 'keypoint', 'heatmaps', 'training', 'one', 'part', 'affinity', 'fields', 'training', 'one', 'channels', 'feature', 'tensors', 'training', 'iii', 'process', 'inputting', 'keypoint', 'heatmaps', 'training', 'part', 'affinity', 'fields', 'training', 'keypoint', 'detector', 'thereby', 'allow', 'keypoint', 'detector', 'extract', 'keypoints', 'training', 'keypoint', 'heatmaps', 'training', 'process', 'grouping', 'extracted', 'keypoints', 'training', 'referring', 'part', 'affinity', 'fields', 'training', 'thereby', 'detect', 'keypoints', 'per', 'objects', 'training', 'iv', 'process', 'allowing', 'loss', 'layer', 'calculate', 'one', 'losses', 'referring', 'keypoints', 'per', 'objects', 'training', 'corresponding', 'ground', 'truths', 'thereby', 'adjust', 'one', 'parameters', 'feature', 'extraction', 'network', 'keypoint', 'heatmap', '&', 'part', 'affinity', 'field', 'extractor', 'losses', 'minimized', 'backpropagation', 'using', 'losses', 'method', 'claim', 'wherein', 'step', 'passenger', 'body', 'information-detecting', 'device', 'performs', 'process', 'inputting', 'interior', 'image', 'face', 'recognition', 'network', 'thereby', 'allow', 'face', 'recognition', 'network', 'detect', 'faces', 'passengers', 'located', 'interior', 'image', 'via', 'face', 'detector', 'output', 'multiple', 'pieces', 'passenger', 'feature', 'information', 'facial', 'images', 'via', 'facial', 'feature', 'classifier', 'method', 'claim', 'wherein', 'step', 'passenger', 'body', 'information-detecting', 'device', 'performs', 'process', 'inputting', 'interior', 'image', 'face', 'recognition', 'network', 'thereby', 'allow', 'face', 'recognition', 'network', 'apply', 'least', 'one', 'convolution', 'operation', 'interior', 'image', 'thus', 'output', 'least', 'one', 'feature', 'map', 'corresponding', 'interior', 'image', 'via', 'least', 'one', 'convolutional', 'layer', 'ii', 'output', 'one', 'proposal', 'boxes', 'passengers', 'estimated', 'located', 'feature', 'map', 'via', 'region', 'proposal', 'network', 'iii', 'apply', 'pooling', 'operation', 'one', 'regions', 'corresponding', 'proposal', 'boxes', 'feature', 'map', 'thus', 'output', 'least', 'one', 'feature', 'vector', 'via', 'pooling', 'layer', 'iv', 'apply', 'fully-connected', 'operation', 'feature', 'vector', 'thus', 'output', 'multiple', 'pieces', 'passenger', 'feature', 'information', 'corresponding', 'faces', 'passengers', 'corresponding', 'proposal', 'boxes', 'via', 'fully', 'connected', 'layer', 'method', 'claim', 'wherein', 'multiple', 'pieces', 'passenger', 'feature', 'information', 'include', 'ages', 'genders', 'races', 'corresponding', 'passengers', 'passenger', 'body', 'information-detecting', 'device', 'detecting', 'body', 'information', 'one', 'passengers', 'vehicle', 'based', 'humans', \"'\", 'status', 'recognition', 'comprising', 'least', 'one', 'memory', 'stores', 'instructions', 'least', 'one', 'processor', 'configured', 'execute', 'instructions', 'perform', 'support', 'another', 'device', 'perform', 'least', 'one', 'interior', 'image', 'interior', 'vehicle', 'acquired', 'process', 'inputting', 'interior', 'image', 'face', 'recognition', 'network', 'thereby', 'allow', 'face', 'recognition', 'network', 'detect', 'faces', 'passengers', 'interior', 'image', 'thus', 'output', 'multiple', 'pieces', 'passenger', 'feature', 'information', 'corresponding', 'detected', 'faces', 'ii', 'process', 'inputting', 'interior', 'image', 'body', 'recognition', 'network', 'thereby', 'allow', 'body', 'recognition', 'network', 'detect', 'bodies', 'passengers', 'interior', 'image', 'thus', 'output', 'body-part', 'length', 'information', 'detected', 'bodies', 'ii', 'process', 'retrieving', 'specific', 'height', 'mapping', 'information', 'corresponding', 'specific', 'passenger', 'feature', 'information', 'specific', 'passenger', 'height', 'mapping', 'table', 'stores', 'height', 'mapping', 'information', 'representing', 'respective', 'one', 'predetermined', 'ratios', 'one', 'segment', 'body', 'portions', 'human', 'groups', 'heights', 'per', 'human', 'groups', 'process', 'acquiring', 'specific', 'height', 'specific', 'passenger', 'specific', 'height', 'mapping', 'information', 'referring', 'specific', 'body-part', 'length', 'information', 'specific', 'passenger', 'process', 'retrieving', 'specific', 'weight', 'mapping', 'information', 'corresponding', 'specific', 'passenger', 'feature', 'information', 'weight', 'mapping', 'table', 'stores', 'multiple', 'pieces', 'weight', 'mapping', 'information', 'representing', 'predetermined', 'correlations', 'heights', 'weights', 'per', 'human', 'groups', 'process', 'acquiring', 'weight', 'specific', 'passenger', 'specific', 'weight', 'mapping', 'information', 'referring', 'specific', 'height', 'specific', 'passenger', 'passenger', 'body', 'information-detecting', 'device', 'claim', 'wherein', 'process', 'processor', 'performs', 'process', 'inputting', 'interior', 'image', 'body', 'recognition', 'network', 'thereby', 'allow', 'body', 'recognition', 'network', 'output', 'one', 'feature', 'tensors', 'one', 'channels', 'corresponding', 'interior', 'image', 'via', 'feature', 'extraction', 'network', 'ii', 'generate', 'least', 'one', 'keypoint', 'heatmap', 'least', 'one', 'part', 'affinity', 'field', 'one', 'channels', 'corresponding', 'feature', 'tensors', 'via', 'keypoint', 'heatmap', '&', 'part', 'affinity', 'field', 'extractor', 'iii', 'extract', 'keypoints', 'keypoint', 'heatmap', 'via', 'keypoint', 'detector', 'group', 'extracted', 'keypoints', 'referring', 'part', 'affinity', 'field', 'thus', 'generate', 'body', 'parts', 'per', 'passengers', 'result', 'allow', 'body', 'recognition', 'network', 'output', 'multiple', 'pieces', 'body-part', 'length', 'information', 'passengers', 'referring', 'body', 'parts', 'per', 'passengers', 'passenger', 'body', 'information-detecting', 'device', 'claim', 'wherein', 'keypoint', 'heatmap', '&', 'part', 'affinity', 'field', 'extractor', 'includes', 'one', 'fully', 'convolutional', 'network', '×', 'convolutional', 'layer', 'applies', 'fully-convolution', 'operation', '×', 'convolution', 'operation', 'feature', 'tensors', 'thereby', 'generate', 'keypoint', 'heatmap', 'part', 'affinity', 'field', 'passenger', 'body', 'information-detecting', 'device', 'claim', 'wherein', 'keypoint', 'detector', 'connects', 'referring', 'part', 'affinity', 'field', 'pairs', 'respectively', 'highest', 'mutual', 'connection', 'probabilities', 'connected', 'among', 'extracted', 'keypoints', 'thereby', 'group', 'extracted', 'keypoints', 'passenger', 'body', 'information-detecting', 'device', 'claim', 'wherein', 'feature', 'extraction', 'network', 'keypoint', 'heatmap', '&', 'part', 'affinity', 'field', 'extractor', 'learned', 'learning', 'device', 'performing', 'process', 'inputting', 'least', 'one', 'training', 'image', 'including', 'one', 'objects', 'training', 'feature', 'extraction', 'network', 'thereby', 'allow', 'feature', 'extraction', 'network', 'generate', 'one', 'feature', 'tensors', 'training', 'one', 'channels', 'applying', 'least', 'one', 'convolutional', 'operation', 'training', 'image', 'ii', 'process', 'inputting', 'feature', 'tensors', 'training', 'keypoint', 'heatmap', '&', 'part', 'affinity', 'field', 'extractor', 'thereby', 'allow', 'keypoint', 'heatmap', '&', 'part', 'affinity', 'field', 'extractor', 'generate', 'one', 'keypoint', 'heatmaps', 'training', 'one', 'part', 'affinity', 'fields', 'training', 'one', 'channels', 'feature', 'tensors', 'training', 'iii', 'process', 'inputting', 'keypoint', 'heatmaps', 'training', 'part', 'affinity', 'fields', 'training', 'keypoint', 'detector', 'thereby', 'allow', 'keypoint', 'detector', 'extract', 'keypoints', 'training', 'keypoint', 'heatmaps', 'training', 'process', 'grouping', 'extracted', 'keypoints', 'training', 'referring', 'part', 'affinity', 'fields', 'training', 'thereby', 'detect', 'keypoints', 'per', 'objects', 'training', 'iv', 'process', 'allowing', 'loss', 'layer', 'calculate', 'one', 'losses', 'referring', 'keypoints', 'per', 'objects', 'training', 'corresponding', 'ground', 'truths', 'thereby', 'adjust', 'one', 'parameters', 'feature', 'extraction', 'network', 'keypoint', 'heatmap', '&', 'part', 'affinity', 'field', 'extractor', 'losses', 'minimized', 'backpropagation', 'using', 'losses', 'passenger', 'body', 'information-detecting', 'device', 'claim', 'wherein', 'process', 'processor', 'performs', 'process', 'inputting', 'interior', 'image', 'face', 'recognition', 'network', 'thereby', 'allow', 'face', 'recognition', 'network', 'apply', 'least', 'one', 'convolution', 'operation', 'interior', 'image', 'thus', 'output', 'least', 'one', 'feature', 'map', 'corresponding', 'interior', 'image', 'via', 'least', 'one', 'convolutional', 'layer', 'ii', 'output', 'one', 'proposal', 'boxes', 'passengers', 'estimated', 'located', 'feature', 'map', 'via', 'region', 'proposal', 'network', 'iii', 'apply', 'pooling', 'operation', 'one', 'regions', 'corresponding', 'proposal', 'boxes', 'feature', 'map', 'thus', 'output', 'least', 'one', 'feature', 'vector', 'via', 'pooling', 'layer', 'iv', 'apply', 'fully-connected', 'operation', 'feature', 'vector', 'thus', 'output', 'multiple', 'pieces', 'passenger', 'feature', 'information', 'corresponding', 'faces', 'passengers', 'corresponding', 'proposal', 'boxes', 'via', 'fully', 'connected', 'layer', 'computer', 'implemented', 'method', 'performing', 'video', 'coding', 'based', 'face', 'detection', 'comprising', 'receiving', 'video', 'frame', 'comprising', 'one', 'plurality', 'video', 'frames', 'video', 'sequence', 'determining', 'video', 'frame', 'key', 'frame', 'video', 'sequence', 'performing', 'response', 'video', 'frame', 'key', 'frame', 'video', 'sequence', 'multi-stage', 'facial', 'search', 'video', 'frame', 'based', 'predetermined', 'feature', 'templates', 'predetermined', 'number', 'stages', 'determine', 'first', 'candidate', 'face', 'region', 'second', 'candidate', 'face', 'region', 'video', 'frame', 'testing', 'first', 'second', 'candidate', 'face', 'regions', 'based', 'skin', 'tone', 'information', 'determine', 'first', 'candidate', 'face', 'region', 'valid', 'face', 'region', 'second', 'candidate', 'face', 'region', 'invalid', 'face', 'region', 'rejecting', 'second', 'candidate', 'face', 'region', 'outputting', 'first', 'candidate', 'face', 'region', 'encoding', 'video', 'frame', 'based', 'least', 'part', 'first', 'candidate', 'face', 'region', 'valid', 'face', 'region', 'generate', 'coded', 'bitstream', 'method', 'claim', 'wherein', 'skin', 'tone', 'information', 'comprises', 'skin', 'probability', 'map', 'method', 'claim', 'wherein', 'said', 'testing', 'first', 'second', 'candidate', 'face', 'regions', 'based', 'skin', 'tone', 'information', 'performed', 'response', 'video', 'frame', 'key', 'frame', 'video', 'sequence', 'method', 'claim', 'wherein', 'first', 'candidate', 'face', 'region', 'comprises', 'rectangular', 'region', 'method', 'comprising', 'determining', 'free', 'form', 'shape', 'face', 'region', 'corresponding', 'first', 'candidate', 'face', 'region', 'wherein', 'free', 'form', 'shape', 'face', 'region', 'least', 'one', 'pixel', 'accuracy', 'small', 'block', 'pixels', 'accuracy', 'method', 'claim', 'wherein', 'determining', 'free', 'form', 'shape', 'face', 'region', 'comprises', 'generating', 'enhanced', 'skip', 'probability', 'map', 'corresponding', 'first', 'candidate', 'face', 'region', 'binarizing', 'enhanced', 'skip', 'probability', 'map', 'overlaying', 'binarized', 'enhanced', 'skip', 'probability', 'map', 'least', 'portion', 'video', 'frame', 'provide', 'free', 'form', 'shape', 'face', 'region', 'method', 'claim', 'wherein', 'second', 'video', 'frame', 'comprises', 'non-key', 'frame', 'video', 'sequence', 'method', 'comprising', 'performing', 'face', 'detection', 'second', 'video', 'frame', 'video', 'sequence', 'based', 'free', 'form', 'shape', 'face', 'region', 'method', 'claim', 'comprising', 'tracking', 'second', 'free', 'form', 'shape', 'face', 'region', 'second', 'video', 'frame', 'based', 'free', 'form', 'shape', 'face', 'region', 'video', 'frame', 'method', 'claim', 'wherein', 'tracking', 'second', 'free', 'form', 'shape', 'face', 'region', 'comprises', 'determining', 'location', 'second', 'valid', 'face', 'region', 'second', 'video', 'frame', 'based', 'displacement', 'offset', 'respect', 'first', 'candidate', 'face', 'region', 'method', 'claim', 'comprising', 'determining', 'displacement', 'offset', 'based', 'offset', 'centroid', 'bounding', 'box', 'around', 'skin', 'enhanced', 'region', 'corresponding', 'first', 'candidate', 'face', 'region', 'second', 'centroid', 'second', 'bounding', 'box', 'around', 'second', 'skin', 'enhanced', 'region', 'second', 'video', 'frame', 'method', 'claim', 'wherein', 'encoding', 'video', 'frame', 'based', 'least', 'part', 'first', 'candidate', 'face', 'region', 'valid', 'face', 'region', 'comprises', 'least', 'one', 'reducing', 'quantization', 'parameter', 'corresponding', 'first', 'candidate', 'face', 'region', 'adjusting', 'lambda', 'value', 'first', 'candidate', 'face', 'region', 'disabling', 'skip', 'coding', 'first', 'candidate', 'face', 'region', 'method', 'claim', 'wherein', 'bitstream', 'comprises', 'least', 'one', 'hadvanced', 'video', 'coding', 'avc', 'compliant', 'bitstream', 'hhigh', 'efficiency', 'video', 'coding', 'hevc', 'compliant', 'bitstream', 'vp', 'compliant', 'bitstream', 'vp', 'compliant', 'bitstream', 'alliance', 'open', 'media', 'aom', 'av', 'compliant', 'bitstream', 'computer', 'implemented', 'method', 'performing', 'face', 'detection', 'comprising', 'receiving', 'video', 'frame', 'sequence', 'video', 'frames', 'performing', 'multi-stage', 'facial', 'search', 'video', 'frame', 'based', 'predetermined', 'feature', 'templates', 'predetermined', 'number', 'stages', 'determine', 'first', 'candidate', 'face', 'region', 'second', 'candidate', 'face', 'region', 'video', 'frame', 'testing', 'first', 'second', 'candidate', 'face', 'regions', 'based', 'skin', 'tone', 'information', 'determine', 'first', 'candidate', 'face', 'region', 'valid', 'face', 'region', 'second', 'candidate', 'face', 'region', 'invalid', 'face', 'region', 'rejecting', 'second', 'candidate', 'face', 'region', 'outputting', 'first', 'candidate', 'face', 'region', 'valid', 'face', 'region', 'processing', 'providing', 'index', 'indicative', 'person', 'present', 'video', 'frame', 'based', 'valid', 'face', 'region', 'method', 'claim', 'wherein', 'sequence', 'video', 'frames', 'comprises', 'sequence', 'surveillance', 'video', 'frames', 'method', 'comprising', 'performing', 'face', 'recognition', 'surveillance', 'video', 'frames', 'based', 'valid', 'face', 'region', 'method', 'claim', 'wherein', 'sequence', 'video', 'frames', 'comprises', 'sequence', 'decoded', 'video', 'frames', 'method', 'comprising', 'adding', 'marker', 'corresponding', 'received', 'video', 'frame', 'perform', 'face', 'recognition', 'received', 'video', 'frame', 'based', 'valid', 'face', 'region', 'method', 'claim', 'wherein', 'sequence', 'video', 'frames', 'received', 'device', 'login', 'attempt', 'method', 'comprising', 'performing', 'face', 'recognition', 'based', 'valid', 'face', 'region', 'allowing', 'access', 'device', 'secured', 'face', 'recognized', 'method', 'claim', 'wherein', 'sequence', 'video', 'frames', 'comprises', 'sequence', 'videoconferencing', 'frames', 'method', 'comprising', 'encoding', 'video', 'frame', 'based', 'least', 'part', 'valid', 'face', 'region', 'generate', 'coded', 'bitstream', 'method', 'claim', 'wherein', 'encoding', 'video', 'frame', 'comprises', 'encoding', 'background', 'region', 'video', 'frame', 'bitstream', 'method', 'claim', 'comprising', 'encoding', 'video', 'frame', 'based', 'least', 'part', 'valid', 'face', 'region', 'generate', 'coded', 'bitstream', 'wherein', 'encoding', 'video', 'frame', 'comprises', 'including', 'metadata', 'corresponding', 'valid', 'face', 'region', 'bitstream', 'method', 'claim', 'comprising', 'decoding', 'coded', 'bitstream', 'generate', 'decoded', 'video', 'frame', 'determine', 'metadata', 'corresponding', 'valid', 'face', 'region', 'bitstream', 'method', 'claim', 'comprising', 'least', 'one', 'replacing', 'valid', 'face', 'region', 'based', 'decoded', 'metadata', 'cropping', 'displaying', 'image', 'data', 'corresponding', 'valid', 'face', 'region', 'based', 'decoded', 'metadata', 'indexing', 'decoded', 'video', 'frame', 'based', 'decoded', 'metadata', 'system', 'performing', 'video', 'coding', 'based', 'face', 'detection', 'comprising', 'memory', 'configured', 'store', 'video', 'frame', 'comprising', 'one', 'plurality', 'video', 'frames', 'video', 'sequence', 'processor', 'coupled', 'memory', 'processor', 'receive', 'video', 'frame', 'determine', 'video', 'frame', 'key', 'frame', 'video', 'sequence', 'perform', 'response', 'video', 'frame', 'key', 'frame', 'video', 'sequence', 'multi-stage', 'facial', 'search', 'video', 'frame', 'based', 'predetermined', 'feature', 'templates', 'predetermined', 'number', 'stages', 'determine', 'first', 'candidate', 'face', 'region', 'second', 'candidate', 'face', 'region', 'video', 'frame', 'test', 'first', 'second', 'candidate', 'face', 'regions', 'based', 'skin', 'tone', 'information', 'determine', 'first', 'candidate', 'face', 'region', 'valid', 'face', 'region', 'second', 'candidate', 'face', 'region', 'invalid', 'face', 'region', 'reject', 'second', 'candidate', 'face', 'region', 'outputting', 'first', 'candidate', 'face', 'region', 'encode', 'video', 'frame', 'based', 'least', 'part', 'first', 'candidate', 'face', 'region', 'valid', 'face', 'region', 'generate', 'coded', 'bitstream', 'system', 'claim', 'wherein', 'skin', 'tone', 'information', 'comprises', 'skin', 'probability', 'map', 'system', 'claim', 'wherein', 'first', 'candidate', 'face', 'region', 'comprises', 'rectangular', 'region', 'processor', 'determine', 'free', 'form', 'shape', 'face', 'region', 'corresponding', 'first', 'candidate', 'face', 'region', 'wherein', 'free', 'form', 'shape', 'face', 'region', 'least', 'one', 'pixel', 'accuracy', 'small', 'block', 'pixels', 'accuracy', 'system', 'claim', 'wherein', 'processor', 'determine', 'free', 'form', 'shape', 'face', 'region', 'comprises', 'processor', 'generate', 'enhanced', 'skip', 'probability', 'map', 'corresponding', 'first', 'candidate', 'face', 'region', 'binarize', 'enhanced', 'skip', 'probability', 'map', 'overlay', 'binarized', 'enhanced', 'skip', 'probability', 'map', 'least', 'portion', 'video', 'frame', 'provide', 'free', 'form', 'shape', 'face', 'region', 'system', 'claim', 'wherein', 'second', 'video', 'frame', 'comprises', 'non-key', 'frame', 'video', 'sequence', 'processor', 'perform', 'face', 'detection', 'second', 'video', 'frame', 'video', 'sequence', 'based', 'free', 'form', 'shape', 'face', 'region', 'system', 'claim', 'wherein', 'processor', 'track', 'second', 'free', 'form', 'shape', 'face', 'region', 'second', 'video', 'frame', 'based', 'free', 'form', 'shape', 'face', 'region', 'video', 'frame', 'system', 'claim', 'wherein', 'encode', 'video', 'frame', 'based', 'least', 'part', 'first', 'candidate', 'face', 'region', 'valid', 'face', 'region', 'comprises', 'processor', 'reduce', 'quantization', 'parameter', 'corresponding', 'first', 'candidate', 'face', 'region', 'adjust', 'lambda', 'value', 'first', 'candidate', 'face', 'region', 'disable', 'skip', 'coding', 'first', 'candidate', 'face', 'region', 'least', 'one', 'non-transitory', 'machine', 'readable', 'medium', 'comprising', 'plurality', 'instructions', 'response', 'executed', 'device', 'cause', 'device', 'perform', 'video', 'coding', 'based', 'face', 'detection', 'receiving', 'video', 'frame', 'comprising', 'one', 'plurality', 'video', 'frames', 'video', 'sequence', 'determining', 'video', 'frame', 'key', 'frame', 'video', 'sequence', 'performing', 'response', 'video', 'frame', 'key', 'frame', 'video', 'sequence', 'multi-stage', 'facial', 'search', 'video', 'frame', 'based', 'predetermined', 'feature', 'templates', 'predetermined', 'number', 'stages', 'determine', 'first', 'candidate', 'face', 'region', 'second', 'candidate', 'face', 'region', 'video', 'frame', 'testing', 'first', 'second', 'candidate', 'face', 'regions', 'based', 'skin', 'tone', 'information', 'determine', 'first', 'candidate', 'face', 'region', 'valid', 'face', 'region', 'second', 'candidate', 'face', 'region', 'invalid', 'face', 'region', 'rejecting', 'second', 'candidate', 'face', 'region', 'outputting', 'first', 'candidate', 'face', 'region', 'encoding', 'video', 'frame', 'based', 'least', 'part', 'first', 'candidate', 'face', 'region', 'valid', 'face', 'region', 'generate', 'coded', 'bitstream', 'non-transitory', 'machine', 'readable', 'medium', 'claim', 'wherein', 'skin', 'tone', 'information', 'comprises', 'skin', 'probability', 'map', 'non-transitory', 'machine', 'readable', 'medium', 'claim', 'wherein', 'first', 'candidate', 'face', 'region', 'comprises', 'rectangular', 'region', 'machine', 'readable', 'medium', 'comprising', 'instructions', 'response', 'executed', 'device', 'cause', 'device', 'perform', 'video', 'coding', 'based', 'face', 'detection', 'determining', 'free', 'form', 'shape', 'face', 'region', 'corresponding', 'first', 'candidate', 'face', 'region', 'wherein', 'free', 'form', 'shape', 'face', 'region', 'least', 'one', 'pixel', 'accuracy', 'small', 'block', 'pixels', 'accuracy', 'non-transitory', 'machine', 'readable', 'medium', 'claim', 'wherein', 'determining', 'free', 'form', 'shape', 'face', 'region', 'comprises', 'generating', 'enhanced', 'skip', 'probability', 'map', 'corresponding', 'first', 'candidate', 'face', 'region', 'binarizing', 'enhanced', 'skip', 'probability', 'map', 'overlaying', 'binarized', 'enhanced', 'skip', 'probability', 'map', 'least', 'portion', 'video', 'frame', 'provide', 'free', 'form', 'shape', 'face', 'region', 'non-transitory', 'machine', 'readable', 'medium', 'claim', 'wherein', 'second', 'video', 'frame', 'comprises', 'non-key', 'frame', 'video', 'sequence', 'machine', 'readable', 'medium', 'comprising', 'instructions', 'response', 'executed', 'device', 'cause', 'device', 'perform', 'video', 'coding', 'based', 'face', 'detection', 'performing', 'face', 'detection', 'second', 'video', 'frame', 'video', 'sequence', 'based', 'free', 'form', 'shape', 'face', 'region', 'non-transitory', 'machine', 'readable', 'medium', 'claim', 'machine', 'readable', 'medium', 'comprising', 'instructions', 'response', 'executed', 'device', 'cause', 'device', 'perform', 'video', 'coding', 'based', 'face', 'detection', 'tracking', 'second', 'free', 'form', 'shape', 'face', 'region', 'second', 'video', 'frame', 'based', 'free', 'form', 'shape', 'face', 'region', 'video', 'frame', 'non-transitory', 'machine', 'readable', 'medium', 'claim', 'wherein', 'encoding', 'video', 'frame', 'based', 'least', 'part', 'first', 'candidate', 'face', 'region', 'valid', 'face', 'region', 'comprises', 'least', 'one', 'reducing', 'quantization', 'parameter', 'corresponding', 'first', 'candidate', 'face', 'region', 'adjusting', 'lambda', 'value', 'first', 'candidate', 'face', 'region', 'disabling', 'skip', 'coding', 'first', 'candidate', 'face', 'region', 'method', 'managing', 'smart', 'database', 'stores', 'facial', 'images', 'face', 'recognition', 'comprising', 'steps', 'managing', 'device', 'performing', 'process', 'counting', 'one', 'specific', 'facial', 'images', 'corresponding', 'least', 'one', 'specific', 'person', 'stored', 'smart', 'database', 'new', 'facial', 'images', 'face', 'recognition', 'continuously', 'stored', 'process', 'determining', 'whether', 'first', 'counted', 'value', 'representing', 'count', 'specific', 'facial', 'images', 'satisfies', 'preset', 'first', 'set', 'value', 'b', 'first', 'counted', 'value', 'determined', 'satisfying', 'first', 'set', 'value', 'managing', 'device', 'performing', 'process', 'inputting', 'specific', 'facial', 'images', 'neural', 'aggregation', 'network', 'thereby', 'allow', 'neural', 'aggregation', 'network', 'generate', 'quality', 'scores', 'specific', 'facial', 'images', 'aggregation', 'specific', 'facial', 'images', 'process', 'sorting', 'quality', 'scores', 'corresponding', 'specific', 'facial', 'images', 'descending', 'order', 'quality', 'scores', 'process', 'counting', 'sorted', 'specific', 'facial', 'images', 'descending', 'order', 'second', 'counted', 'value', 'represents', 'number', 'counted', 'part', 'specific', 'facial', 'images', 'becomes', 'equal', 'preset', 'second', 'set', 'value', 'process', 'deleting', 'uncounted', 'part', 'specific', 'facial', 'images', 'smart', 'database', 'method', 'claim', 'comprising', 'step', 'c', 'managing', 'device', 'performing', 'process', 'generating', 'least', 'one', 'optimal', 'feature', 'weighted', 'summation', 'one', 'features', 'specific', 'facial', 'images', 'using', 'counted', 'part', 'quality', 'scores', 'process', 'setting', 'optimal', 'feature', 'representative', 'face', 'corresponding', 'specific', 'person', 'method', 'claim', 'wherein', 'step', 'b', 'managing', 'device', 'performs', 'process', 'inputting', 'specific', 'facial', 'images', 'cnn', 'neural', 'aggregation', 'network', 'thereby', 'allow', 'cnn', 'generate', 'one', 'features', 'corresponding', 'specific', 'facial', 'images', 'process', 'inputting', 'least', 'one', 'feature', 'vector', 'features', 'embedded', 'aggregation', 'module', 'including', 'least', 'two', 'attention', 'blocks', 'thereby', 'allow', 'aggregation', 'module', 'generate', 'quality', 'scores', 'features', 'method', 'claim', 'wherein', 'step', 'b', 'managing', 'device', 'performs', 'process', 'matching', 'i-', 'one', 'features', 'corresponding', 'specific', 'facial', 'images', 'stored', 'smart', 'database', 'i-', 'quality', 'scores', 'ii', 'specific', 'person', 'process', 'storing', 'matched', 'features', 'matched', 'quality', 'scores', 'smart', 'database', 'method', 'claim', 'comprising', 'step', 'managing', 'device', 'performing', 'one', 'process', 'learning', 'face', 'recognition', 'system', 'using', 'specific', 'facial', 'images', 'corresponding', 'specific', 'person', 'stored', 'smart', 'database', 'ii', 'process', 'transmitting', 'specific', 'facial', 'images', 'corresponding', 'specific', 'person', 'learning', 'device', 'corresponding', 'face', 'recognition', 'system', 'thereby', 'allow', 'learning', 'device', 'learn', 'face', 'recognition', 'system', 'using', 'specific', 'facial', 'images', 'method', 'claim', 'wherein', 'neural', 'aggregation', 'network', 'learned', 'learning', 'device', 'repeating', 'process', 'inputting', 'multiple', 'facial', 'images', 'training', 'corresponding', 'image', 'set', 'single', 'face', 'video', 'single', 'face', 'cnn', 'neural', 'aggregation', 'network', 'thereby', 'allow', 'cnn', 'generate', 'one', 'features', 'training', 'applying', 'least', 'one', 'convolution', 'operation', 'facial', 'images', 'training', 'ii', 'process', 'inputting', 'least', 'one', 'feature', 'vector', 'training', 'features', 'training', 'embedded', 'aggregation', 'module', 'including', 'least', 'two', 'attention', 'blocks', 'neural', 'aggregation', 'network', 'thereby', 'allow', 'aggregation', 'module', 'generate', 'quality', 'scores', 'training', 'features', 'training', 'aggregation', 'features', 'training', 'using', 'one', 'attention', 'parameters', 'learned', 'previous', 'iteration', 'iii', 'process', 'outputting', 'least', 'one', 'optimal', 'feature', 'training', 'weighted', 'summation', 'features', 'training', 'using', 'quality', 'scores', 'training', 'iv', 'process', 'updating', 'attention', 'parameters', 'learned', 'previous', 'iteration', 'least', 'two', 'attention', 'blocks', 'one', 'losses', 'minimized', 'outputted', 'loss', 'layer', 'referring', 'optimal', 'feature', 'training', 'corresponding', 'ground', 'truth', 'managing', 'device', 'managing', 'smart', 'database', 'stores', 'facial', 'images', 'face', 'recognition', 'comprising', 'least', 'one', 'memory', 'stores', 'instructions', 'least', 'one', 'processor', 'configured', 'execute', 'instructions', 'perform', 'support', 'another', 'device', 'perform', 'process', 'counting', 'one', 'specific', 'facial', 'images', 'corresponding', 'least', 'one', 'specific', 'person', 'stored', 'smart', 'database', 'new', 'facial', 'images', 'face', 'recognition', 'continuously', 'stored', 'process', 'determining', 'whether', 'first', 'counted', 'value', 'representing', 'count', 'specific', 'facial', 'images', 'satisfies', 'preset', 'first', 'set', 'value', 'ii', 'first', 'counted', 'value', 'determined', 'satisfying', 'first', 'set', 'value', 'process', 'inputting', 'specific', 'facial', 'images', 'neural', 'aggregation', 'network', 'thereby', 'allow', 'neural', 'aggregation', 'network', 'generate', 'quality', 'scores', 'specific', 'facial', 'images', 'aggregation', 'specific', 'facial', 'images', 'process', 'sorting', 'quality', 'scores', 'corresponding', 'specific', 'facial', 'images', 'descending', 'order', 'quality', 'scores', 'process', 'counting', 'sorted', 'specific', 'facial', 'images', 'descending', 'order', 'second', 'counted', 'value', 'represents', 'number', 'counted', 'part', 'specific', 'facial', 'images', 'becomes', 'equal', 'preset', 'second', 'set', 'value', 'process', 'deleting', 'uncounted', 'part', 'specific', 'facial', 'images', 'smart', 'database', 'managing', 'device', 'claim', 'wherein', 'processor', 'performs', 'iii', 'process', 'generating', 'least', 'one', 'optimal', 'feature', 'weighted', 'summation', 'one', 'features', 'specific', 'facial', 'images', 'using', 'counted', 'part', 'quality', 'scores', 'process', 'setting', 'optimal', 'feature', 'representative', 'face', 'corresponding', 'specific', 'person', 'managing', 'device', 'claim', 'wherein', 'process', 'ii', 'processor', 'performs', 'process', 'inputting', 'specific', 'facial', 'images', 'cnn', 'neural', 'aggregation', 'network', 'thereby', 'allow', 'cnn', 'generate', 'one', 'features', 'corresponding', 'specific', 'facial', 'images', 'process', 'inputting', 'least', 'one', 'feature', 'vector', 'features', 'embedded', 'aggregation', 'module', 'including', 'least', 'two', 'attention', 'blocks', 'thereby', 'allow', 'aggregation', 'module', 'generate', 'quality', 'scores', 'features', 'managing', 'device', 'claim', 'wherein', 'process', 'ii', 'processor', 'performs', 'process', 'matching', 'i-', 'one', 'features', 'corresponding', 'specific', 'facial', 'images', 'stored', 'smart', 'database', 'i-', 'quality', 'scores', 'ii', 'specific', 'person', 'process', 'storing', 'matched', 'features', 'matched', 'quality', 'scores', 'smart', 'database', 'managing', 'device', 'claim', 'wherein', 'processor', 'performs', 'iv', 'one', 'process', 'learning', 'face', 'recognition', 'system', 'using', 'specific', 'facial', 'images', 'corresponding', 'specific', 'person', 'stored', 'smart', 'database', 'ii', 'process', 'transmitting', 'specific', 'facial', 'images', 'corresponding', 'specific', 'person', 'learning', 'device', 'corresponding', 'face', 'recognition', 'system', 'thereby', 'allow', 'learning', 'device', 'learn', 'face', 'recognition', 'system', 'using', 'specific', 'facial', 'images', 'managing', 'device', 'claim', 'wherein', 'neural', 'aggregation', 'network', 'learned', 'learning', 'device', 'repeating', 'process', 'inputting', 'multiple', 'facial', 'images', 'training', 'corresponding', 'image', 'set', 'single', 'face', 'video', 'single', 'face', 'cnn', 'neural', 'aggregation', 'network', 'thereby', 'allow', 'cnn', 'generate', 'one', 'features', 'training', 'applying', 'least', 'one', 'convolution', 'operation', 'facial', 'images', 'training', 'ii', 'process', 'inputting', 'least', 'one', 'feature', 'vector', 'training', 'features', 'training', 'embedded', 'aggregation', 'module', 'including', 'least', 'two', 'attention', 'blocks', 'neural', 'aggregation', 'network', 'thereby', 'allow', 'aggregation', 'module', 'generate', 'quality', 'scores', 'training', 'features', 'training', 'aggregation', 'features', 'training', 'using', 'one', 'attention', 'parameters', 'learned', 'previous', 'iteration', 'iii', 'process', 'outputting', 'least', 'one', 'optimal', 'feature', 'training', 'weighted', 'summation', 'features', 'training', 'using', 'quality', 'scores', 'training', 'iv', 'process', 'updating', 'attention', 'parameters', 'learned', 'previous', 'iteration', 'least', 'two', 'attention', 'blocks', 'one', 'losses', 'minimized', 'outputted', 'loss', 'layer', 'referring', 'optimal', 'feature', 'training', 'corresponding', 'ground', 'truth', 'object', 'data', 'processing', 'system', 'comprising', 'least', 'one', 'processor', 'configured', 'execute', 'least', 'one', 'implementation', 'plurality', 'recognition', 'algorithms', 'stored', 'least', 'one', 'non-transitory', 'computer-readable', 'storage', 'medium', 'recognition', 'algorithm', 'feature', 'density', 'selection', 'criteria', 'data', 'preprocessing', 'code', 'executed', 'least', 'one', 'processor', 'data', 'preprocessing', 'code', 'comprising', 'invariant', 'feature', 'identification', 'algorithm', 'configured', 'obtain', 'digital', 'representation', 'scene', 'scene', 'comprising', 'one', 'textual', 'media', 'generate', 'set', 'invariant', 'features', 'applying', 'invariant', 'feature', 'identification', 'algorithm', 'digital', 'representation', 'cluster', 'set', 'invariant', 'features', 'regions', 'interest', 'digital', 'representation', 'scene', 'region', 'interest', 'region', 'feature', 'density', 'classify', 'region', 'classifier', 'code', 'least', 'one', 'regions', 'interest', 'according', 'object', 'type', 'function', 'attributes', 'derived', 'region', 'feature', 'density', 'digital', 'representation', 'wherein', 'least', 'one', 'classified', 'regions', 'interest', 'corresponds', 'text', 'use', 'classification', 'result', 'corresponding', 'least', 'one', 'regions', 'interest', 'classify', 'another', 'regions', 'interest', 'according', 'object', 'type', 'wherein', 'another', 'regions', 'interest', 'corresponds', 'region', 'interest', 'images', 'system', 'claim', 'wherein', 'preprocessing', 'code', 'based', 'feature', 'density', 'selection', 'criteria', 'determines', 'ocr', 'algorithm', 'applicable', 'text', 'recognition', 'algorithms', 'applicable', 'aspects', 'photographs', 'logos', 'system', 'claim', 'wherein', 'user', 'creates', 'user', 'profile', 'camera-equipped', 'smartphone', 'includes', 'information', 'user', 'visually', 'impaired', 'causes', 'prioritized', 'execution', 'ocr', 'algorithm', 'text', 'reader', 'program', 'begins', 'reading', 'text', 'user', 'quickly', 'possible', 'system', 'claim', 'comprising', 'audio', 'tactile', 'feedback', 'mechanism', 'helps', 'user', 'position', 'smart', 'phone', 'relative', 'text', 'system', 'claim', 'comprising', '``', 'hold', 'still', \"''\", 'audio', 'feedback', 'signal', 'sent', 'user', 'text', 'center', 'captured', 'scene', 'system', 'claim', 'wherein', 'digital', 'representation', 'comprises', 'least', 'one', 'following', 'types', 'digital', 'data', 'image', 'data', 'video', 'data', 'audio', 'data', 'system', 'claim', 'wherein', 'invariant', 'feature', 'identification', 'algorithm', 'comprises', 'least', 'one', 'following', 'feature', 'identification', 'algorithms', 'fast', 'sift', 'freak', 'brisk', 'harris', 'daisy', 'mser', 'system', 'claim', 'wherein', 'invariant', 'feature', 'identification', 'algorithm', 'includes', 'least', 'one', 'following', 'edge', 'detection', 'algorithm', 'corner', 'detection', 'algorithm', 'saliency', 'map', 'algorithm', 'curve', 'detection', 'algorithm', 'texton', 'identification', 'algorithm', 'wavelets', 'algorithm', 'system', 'claim', 'wherein', 'least', 'one', 'region', 'interest', 'represents', 'least', 'one', 'physical', 'object', 'scene', 'system', 'claim', 'wherein', 'least', 'one', 'region', 'interest', 'represents', 'least', 'one', 'textual', 'media', 'scene', 'system', 'claim', 'wherein', 'region', 'interest', 'represents', 'document', 'textual', 'media', 'system', 'claim', 'wherein', 'region', 'interest', 'represents', 'financial', 'document', 'system', 'claim', 'wherein', 'region', 'interest', 'represents', 'structured', 'document', 'system', 'claim', 'wherein', 'least', 'one', 'implementation', 'plurality', 'recognition', 'algorithms', 'includes', 'least', 'one', 'following', 'template', 'driven', 'algorithm', 'face', 'recognition', 'algorithm', 'optical', 'character', 'recognition', 'algorithm', 'speech', 'recognition', 'algorithm', 'object', 'recognition', 'algorithm', 'system', 'claim', 'wherein', 'data', 'preprocessing', 'code', 'configured', 'assign', 'region', 'interest', 'least', 'one', 'recognition', 'algorithm', 'function', 'scene', 'context', 'derived', 'digital', 'representation', 'system', 'claim', 'wherein', 'scene', 'context', 'includes', 'least', 'one', 'following', 'types', 'data', 'location', 'position', 'time', 'user', 'identity', 'news', 'event', 'medical', 'event', 'promotion', 'system', 'claim', 'comprising', 'mobile', 'device', 'comprising', 'least', 'one', 'implementation', 'plurality', 'recognition', 'algorithms', 'data', 'preprocessing', 'code', 'system', 'claim', 'wherein', 'mobile', 'device', 'comprises', 'least', 'one', 'following', 'smart', 'phone', 'tablet', 'wearable', 'glass', 'toy', 'vehicle', 'computer', 'phablet', 'system', 'claim', 'comprising', 'network-accessible', 'server', 'device', 'comprising', 'least', 'one', 'implementation', 'plurality', 'recognition', 'algorithms', 'data', 'preprocessing', 'code', 'system', 'claim', 'wherein', 'object', 'type', 'includes', 'least', 'one', 'following', 'face', 'animal', 'vehicle', 'document', 'plant', 'building', 'appliance', 'clothing', 'body', 'part', 'toy', 'object', 'data', 'processing', 'system', 'comprising', 'least', 'one', 'processor', 'configured', 'execute', 'least', 'one', 'implementation', 'plurality', 'recognition', 'algorithms', 'stored', 'least', 'one', 'non-transitory', 'computer-readable', 'storage', 'medium', 'recognition', 'algorithm', 'feature', 'density', 'selection', 'criteria', 'data', 'preprocessing', 'code', 'executed', 'least', 'one', 'processor', 'data', 'preprocessing', 'code', 'comprising', 'invariant', 'feature', 'identification', 'algorithm', 'configured', 'obtain', 'digital', 'representation', 'scene', 'scene', 'comprising', 'one', 'textual', 'media', 'generate', 'set', 'invariant', 'features', 'applying', 'invariant', 'feature', 'identification', 'algorithm', 'digital', 'representation', 'cluster', 'set', 'invariant', 'features', 'regions', 'interest', 'digital', 'representation', 'scene', 'region', 'interest', 'region', 'feature', 'density', 'classify', 'region', 'classifier', 'code', 'least', 'one', 'regions', 'interest', 'according', 'object', 'type', 'function', 'attributes', 'derived', 'region', 'feature', 'density', 'digital', 'representation', 'wherein', 'least', 'one', 'classified', 'regions', 'interest', 'corresponds', 'text', 'use', 'classification', 'result', 'corresponding', 'least', 'one', 'regions', 'interest', 'classify', 'another', 'regions', 'interest', 'according', 'object', 'type', 'wherein', 'another', 'regions', 'interest', 'corresponds', 'region', 'interest', 'images', 'assign', 'region', 'interest', 'least', 'one', 'recognition', 'algorithm', 'least', 'one', 'implementation', 'plurality', 'diverse', 'recognition', 'algorithms', 'function', 'region', 'feature', 'density', 'region', 'interest', 'feature', 'density', 'selection', 'criteria', 'least', 'one', 'implementation', 'plurality', 'diverse', 'recognition', 'algorithms', 'configure', 'assigned', 'recognition', 'algorithms', 'process', 'respective', 'regions', 'interest', 'wherein', 'preprocessing', 'code', 'based', 'feature', 'density', 'selection', 'criteria', 'determines', 'ocr', 'algorithm', 'applicable', 'text', 'recognition', 'algorithms', 'applicable', 'aspects', 'photographs', 'logos', 'device', 'comprising', 'least', 'one', 'processor', 'configured', 'execute', 'least', 'one', 'implementation', 'plurality', 'recognition', 'algorithms', 'stored', 'least', 'one', 'non-transitory', 'computer-readable', 'storage', 'medium', 'recognition', 'algorithm', 'feature', 'density', 'selection', 'criteria', 'data', 'preprocessing', 'code', 'executed', 'least', 'one', 'processor', 'data', 'preprocessing', 'code', 'comprising', 'invariant', 'feature', 'identification', 'algorithm', 'configured', 'obtain', 'digital', 'representation', 'scene', 'scene', 'comprising', 'one', 'textual', 'media', 'generate', 'set', 'invariant', 'features', 'applying', 'invariant', 'feature', 'identification', 'algorithm', 'digital', 'representation', 'cluster', 'set', 'invariant', 'features', 'regions', 'interest', 'digital', 'representation', 'scene', 'region', 'interest', 'region', 'feature', 'density', 'classify', 'region', 'classifier', 'code', 'least', 'one', 'regions', 'interest', 'according', 'object', 'type', 'function', 'attributes', 'derived', 'region', 'feature', 'density', 'digital', 'representation', 'wherein', 'least', 'one', 'classified', 'regions', 'interest', 'corresponds', 'text', 'use', 'classification', 'result', 'corresponding', 'least', 'one', 'regions', 'interest', 'classify', 'another', 'regions', 'interest', 'according', 'object', 'type', 'wherein', 'another', 'regions', 'interest', 'corresponds', 'region', 'interest', 'images', 'mobile', 'terminal', 'comprising', 'front', 'camera', 'configured', 'obtain', 'two-dimensional', 'face', 'image', 'user', 'glance', 'sensor', 'tilted', 'certain', 'angle', 'disposed', 'adjacent', 'front', 'camera', 'obtain', 'metadata', 'face', 'image', 'controller', 'obtaining', 'distance', 'glance', 'sensor', 'front', 'camera', 'distance', 'enabling', 'area', 'overlap', 'region', 'first', 'region', 'representing', 'range', 'photographable', 'front', 'camera', 'overlaps', 'second', 'region', 'representing', 'range', 'photographable', 'glance', 'sensor', 'maximum', 'mobile', 'terminal', 'claim', 'wherein', 'controller', 'configured', 'obtain', 'distance', 'enabling', 'area', 'overlap', 'region', 'maximum', 'glance', 'sensor', 'front', 'camera', 'varying', 'tilting', 'angle', 'glance', 'sensor', 'mobile', 'terminal', 'claim', 'wherein', 'controller', 'configured', 'set', 'distance', 'enabling', 'area', 'overlap', 'region', 'maximum', 'glance', 'sensor', 'front', 'camera', 'tilting', 'angle', 'glance', 'sensor', 'optimal', 'disposition', 'location', 'glance', 'sensor', 'mobile', 'terminal', 'claim', 'wherein', 'controller', 'configured', 'set', 'disposition', 'location', 'front', 'camera', 'original', 'point', 'calculates', 'coordinates', 'first', 'triangle', 'representing', 'first', 'region', 'based', 'field', 'view', 'front', 'camera', 'maximum', 'photographing', 'distance', 'front', 'camera', 'mobile', 'terminal', 'claim', 'wherein', 'controller', 'configured', 'calculate', 'coordinates', 'second', 'triangle', 'representing', 'second', 'region', 'based', 'field', 'view', 'glance', 'sensor', 'maximum', 'photographing', 'distance', 'glance', 'sensor', 'distance', 'front', 'camera', 'glance', 'sensor', 'tilting', 'angle', 'glance', 'sensor', 'mobile', 'terminal', 'claim', 'wherein', 'glance', 'sensor', 'tilted', 'controller', 'configured', 'calculate', 'coordinates', 'third', 'triangle', 'representing', 'third', 'region', 'photographable', 'glance', 'sensor', 'controller', 'configured', 'rotation-convert', 'coordinates', 'third', 'triangle', 'based', 'tilting', 'angle', 'glance', 'sensor', 'calculate', 'coordinates', 'second', 'triangle', 'mobile', 'terminal', 'claim', 'wherein', 'controller', 'configured', 'calculate', 'coordinates', 'overlap', 'region', 'based', 'coordinates', 'first', 'triangle', 'coordinates', 'second', 'triangle', 'calculates', 'area', 'overlap', 'region', 'based', 'coordinates', 'overlap', 'region', 'mobile', 'terminal', 'claim', 'wherein', 'controller', 'configured', 'generate', 'three-dimensional', 'face', 'information', 'based', 'face', 'image', 'obtained', 'front', 'camera', 'metadata', 'obtained', 'glance', 'sensor', 'mobile', 'terminal', 'claim', 'wherein', 'metadata', 'comprises', 'one', 'angle', 'face', 'user', 'size', 'face', 'location', 'face', 'mobile', 'terminal', 'claim', 'wherein', 'angle', 'face', 'comprises', 'angle', 'face', 'rotated', 'one', 'pitch', 'axis', 'roll', 'axis', 'yaw', 'axis', 'mobile', 'terminal', 'claim', 'comprising', 'memory', 'storing', 'generated', 'face', 'information', 'wherein', 'controller', 'configured', 'performs', 'user', 'authentication', 'process', 'comparing', 'stored', 'face', 'information', 'face', 'information', 'obtained', 'user', 'authentication', 'mobile', 'terminal', 'claim', 'wherein', 'glance', 'sensor', 'controlled', 'permanently', 'activated', 'low', 'power', 'obtain', 'front', 'image', 'metadata', 'front', 'image', 'mobile', 'terminal', 'claim', 'wherein', 'front', 'camera', 'glance', 'sensor', 'disposed', 'line', 'upper', 'end', 'mobile', 'terminal', 'mobile', 'terminal', 'claim', 'wherein', 'glance', 'sensor', 'tilted', 'one', 'direction', 'direction', 'direction', 'left', 'direction', 'right', 'direction', 'mobile', 'terminal', 'claim', 'wherein', 'metadata', 'data', 'changed', 'mobile', 'terminal', 'tilted', 'external', 'physical', 'force', 'method', 'comprising', 'receiving', 'smart', 'television', 'tv', 'indication', 'upcoming', 'media', 'programming', 'wherein', 'upcoming', 'media', 'programming', 'based', 'user', 'profile', 'identifying', 'one', 'devices', 'communication', 'smart', 'tv', 'one', 'devices', 'including', 'least', 'one', 'microphone', 'camera', 'instructing', 'least', 'one', 'identified', 'device', 'detect', 'audio', 'signals', 'using', 'respective', 'microphone', 'detect', 'visual', 'signals', 'using', 'respective', 'camera', 'selecting', 'least', 'one', 'device', 'one', 'devices', 'based', 'detected', 'audio', 'signal', 'detected', 'visual', 'signal', 'providing', 'instructions', 'selected', 'device', 'output', 'notification', 'related', 'upcoming', 'media', 'programming', 'method', 'claim', 'wherein', 'upcoming', 'media', 'programming', 'one', 'live', 'television', 'program', 'recorded', 'television', 'program', 'broadcast', 'television', 'program', 'application-provided', 'program', 'method', 'claim', 'wherein', 'selecting', 'first', 'device', 'based', 'detected', 'audio', 'signal', 'includes', 'recognizing', 'voice', 'method', 'claim', 'comprising', 'determining', 'distance', 'recognized', 'voice', 'wherein', 'selecting', 'first', 'device', 'based', 'determined', 'distance', 'method', 'claim', 'wherein', 'selecting', 'first', 'device', 'based', 'detected', 'visual', 'signals', 'includes', 'recognizing', 'face', 'method', 'claim', 'wherein', 'recognizing', 'face', 'includes', 'face', 'recognition', 'technique', 'method', 'claim', 'comprising', 'presenting', 'smart', 'tv', 'upcoming', 'media', 'programming', 'favorite', 'channel', 'list', 'method', 'claim', 'comprising', 'obtaining', 'media', 'programming', 'viewing', 'data', 'wherein', 'media', 'programming', 'viewing', 'data', 'includes', 'least', 'one', 'historical', 'time', 'historical', 'date', 'one', 'media', 'programs', 'viewed', 'obtaining', 'least', 'one', 'current', 'time', 'current', 'date', 'processing', 'media', 'programming', 'viewing', 'data', 'determine', 'probability', 'one', 'media', 'programs', 'viewed', 'based', 'least', 'one', 'current', 'time', 'current', 'date', 'presenting', 'favorite', 'channel', 'list', 'based', 'determined', 'probability', 'one', 'media', 'programs', 'viewed', 'method', 'claim', 'wherein', 'processing', 'media', 'programming', 'viewing', 'data', 'includes', 'employing', 'neural', 'network', 'model', 'method', 'claim', 'wherein', 'employing', 'neural', 'network', 'model', 'comprises', 'determining', 'duration', 'one', 'media', 'programs', 'viewed', 'least', 'one', 'historical', 'time', 'historical', 'date', 'setting', 'threshold', 'time', 'duration', 'comparing', 'determined', 'duration', 'threshold', 'time', 'duration', 'filtering', 'one', 'media', 'programs', 'viewed', 'threshold', 'time', 'duration', 'smart', 'television', 'tv', 'comprising', 'network', 'interface', 'non-transitory', 'computer-readable', 'medium', 'processor', 'communication', 'network', 'interface', 'non-transitory', 'computer-readable', 'medium', 'capable', 'executing', 'processor-executable', 'program', 'code', 'stored', 'non-transitory', 'computer-readable', 'medium', 'cause', 'smart', 'tv', 'receive', 'indication', 'upcoming', 'media', 'programming', 'wherein', 'upcoming', 'media', 'programming', 'based', 'user', 'profile', 'identify', 'one', 'devices', 'communication', 'smart', 'tv', 'one', 'devices', 'including', 'least', 'one', 'microphone', 'camera', 'instruct', 'least', 'one', 'identified', 'device', 'detect', 'audio', 'signals', 'using', 'respective', 'microphone', 'detect', 'visual', 'signals', 'using', 'respective', 'camera', 'select', 'least', 'one', 'device', 'one', 'devices', 'based', 'detected', 'audio', 'signal', 'detected', 'visual', 'signal', 'provide', 'instructions', 'selected', 'device', 'output', 'notification', 'related', 'upcoming', 'media', 'programming', 'smart', 'tv', 'claim', 'wherein', 'selecting', 'first', 'device', 'based', 'detected', 'audio', 'signal', 'includes', 'recognizing', 'voice', 'smart', 'tv', 'claim', 'wherein', 'processor', 'capable', 'executing', 'processor-executable', 'program', 'code', 'determine', 'distance', 'recognized', 'voice', 'wherein', 'selecting', 'first', 'device', 'based', 'determined', 'distance', 'smart', 'tv', 'claim', 'wherein', 'selecting', 'first', 'device', 'based', 'detected', 'visual', 'signals', 'includes', 'detecting', 'presence', 'user', 'smart', 'tv', 'claim', 'wherein', 'detecting', 'presence', 'user', 'includes', 'employing', 'one', 'camera', 'microphone', 'fingerprint', 'sensor', 'associated', 'least', 'one', 'smart', 'tv', 'mobile', 'device', 'smartphone', 'laptop', 'computer', 'tablet', 'device', 'wearable', 'device', 'internet', 'things', 'iot', 'device', 'internet', 'everything', 'ioe', 'device', 'iot', 'hub', 'ioe', 'hub', 'smart', 'television', 'tv', 'comprising', 'means', 'receiving', 'indication', 'upcoming', 'media', 'programming', 'wherein', 'upcoming', 'media', 'programming', 'based', 'user', 'profile', 'means', 'identifying', 'one', 'devices', 'communication', 'smart', 'tv', 'one', 'devices', 'including', 'least', 'one', 'microphone', 'camera', 'means', 'instructing', 'least', 'one', 'identified', 'device', 'detect', 'audio', 'signals', 'using', 'respective', 'microphone', 'detect', 'visual', 'signals', 'using', 'respective', 'camera', 'means', 'selecting', 'least', 'one', 'device', 'one', 'devices', 'based', 'detected', 'audio', 'signal', 'detected', 'visual', 'signal', 'means', 'providing', 'instructions', 'selected', 'device', 'output', 'notification', 'related', 'upcoming', 'media', 'programming', 'smart', 'tv', 'claim', 'wherein', 'one', 'devices', 'includes', 'least', 'one', 'mobile', 'device', 'smartphone', 'laptop', 'computer', 'tablet', 'device', 'wearable', 'device', 'internet', 'things', 'iot', 'device', 'internet', 'everything', 'ioe', 'device', 'iot', 'hub', 'ioe', 'hub', 'another', 'smart', 'tv', 'smart', 'tv', 'claim', 'wherein', 'upcoming', 'media', 'programming', 'one', 'live', 'television', 'program', 'recorded', 'television', 'program', 'broadcast', 'television', 'program', 'application-provided', 'program', 'smart', 'tv', 'claim', 'wherein', 'notification', 'includes', 'least', 'one', 'push', 'message', 'sms', 'message', 'waysms', 'message', 'audio', 'alert', 'audio', 'message', 'email', 'message', 'smart', 'tv', 'claim', 'comprising', 'presenting', 'upcoming', 'media', 'programming', 'favorite', 'channel', 'list', 'smart', 'tv', 'claim', 'comprising', 'means', 'obtaining', 'media', 'programming', 'viewing', 'data', 'wherein', 'media', 'programming', 'viewing', 'data', 'includes', 'least', 'one', 'historical', 'time', 'historical', 'date', 'one', 'media', 'programs', 'viewed', 'smart', 'tv', 'means', 'obtaining', 'least', 'one', 'current', 'time', 'current', 'date', 'means', 'processing', 'media', 'programming', 'viewing', 'data', 'determine', 'probability', 'one', 'media', 'programs', 'viewed', 'smart', 'tv', 'based', 'least', 'one', 'current', 'time', 'current', 'date', 'means', 'presenting', 'favorite', 'channel', 'list', 'based', 'determined', 'probability', 'one', 'media', 'programs', 'viewed', 'smart', 'tv', 'claim', 'wherein', 'means', 'processing', 'media', 'programming', 'viewing', 'data', 'includes', 'employing', 'neural', 'network', 'model', 'smart', 'tv', 'claim', 'wherein', 'employing', 'neural', 'network', 'model', 'comprises', 'determining', 'duration', 'one', 'media', 'programs', 'viewed', 'smart', 'tv', 'least', 'one', 'historical', 'time', 'historical', 'date', 'setting', 'threshold', 'time', 'duration', 'comparing', 'determined', 'duration', 'threshold', 'time', 'duration', 'filtering', 'one', 'media', 'programs', 'viewed', 'threshold', 'time', 'duration', 'smart', 'tv', 'claim', 'comprising', 'means', 'adjusting', 'least', 'one', 'volume', 'brightness', 'smart', 'tv', 'wherein', 'adjusting', 'based', 'least', 'one', 'historical', 'time', 'historical', 'date', 'smart', 'tv', 'claim', 'comprising', 'means', 'restricting', 'access', 'one', 'media', 'programs', 'non-transitory', 'computer-readable', 'medium', 'comprising', 'processor-executable', 'program', 'code', 'configured', 'cause', 'processor', 'smart', 'television', 'tv', 'receive', 'indication', 'upcoming', 'media', 'programming', 'wherein', 'upcoming', 'media', 'programming', 'based', 'user', 'profile', 'identify', 'one', 'devices', 'communication', 'smart', 'tv', 'one', 'devices', 'including', 'least', 'one', 'microphone', 'camera', 'instruct', 'least', 'one', 'identified', 'device', 'detect', 'audio', 'signals', 'using', 'respective', 'microphone', 'detect', 'visual', 'signals', 'using', 'respective', 'camera', 'select', 'least', 'one', 'device', 'one', 'devices', 'based', 'detected', 'audio', 'signal', 'detected', 'visual', 'signal', 'provide', 'instructions', 'selected', 'device', 'output', 'notification', 'related', 'upcoming', 'media', 'programming', 'non-transitory', 'computer-readable', 'medium', 'claim', 'wherein', 'selecting', 'first', 'device', 'based', 'detected', 'audio', 'signal', 'includes', 'recognizing', 'voice', 'non-transitory', 'computer-readable', 'medium', 'claim', 'wherein', 'processor', 'capable', 'executing', 'processor-executable', 'program', 'code', 'determine', 'distance', 'recognized', 'voice', 'wherein', 'selecting', 'first', 'device', 'based', 'determined', 'distance', 'non-transitory', 'computer-readable', 'medium', 'claim', 'wherein', 'selecting', 'first', 'device', 'based', 'detected', 'visual', 'signals', 'includes', 'recognizing', 'face', 'non-transitory', 'computer-readable', 'medium', 'claim', 'wherein', 'recognizing', 'face', 'includes', 'face', 'recognition', 'technique', 'camera', 'comprising', 'sensor', 'array', 'including', 'plurality', 'sensors', 'infrared', 'ir', 'illuminator', 'configured', 'emit', 'active', 'ir', 'light', 'ir', 'light', 'sub-band', 'plurality', 'spectral', 'illuminators', 'spectral', 'illuminator', 'configured', 'emit', 'active', 'spectral', 'light', 'different', 'spectral', 'light', 'sub-band', 'depth', 'controller', 'machine', 'configured', 'determine', 'depth', 'value', 'plurality', 'sensors', 'based', 'active', 'ir', 'light', 'spectral', 'controller', 'machine', 'configured', 'plurality', 'sensors', 'determine', 'spectral', 'value', 'spectral', 'light', 'sub-band', 'plurality', 'spectral', 'illuminators', 'output', 'machine', 'configured', 'output', 'test', 'depth+multi-spectral', 'image', 'including', 'plurality', 'pixels', 'pixel', 'corresponding', 'one', 'plurality', 'sensors', 'sensor', 'array', 'including', 'least', 'depth', 'value', 'spectral', 'value', 'spectral', 'light', 'sub-band', 'plurality', 'spectral', 'illuminators', 'face', 'recognition', 'machine', 'previously', 'trained', 'set', 'labeled', 'training', 'depth+multi-spectral', 'images', 'structure', 'test', 'depth+multi-spectral', 'image', 'face', 'recognition', 'machine', 'configured', 'output', 'confidence', 'value', 'indicating', 'likelihood', 'test', 'depth+multi-spectral', 'image', 'includes', 'face', 'camera', 'claim', 'wherein', 'spectral', 'value', 'calculated', 'based', 'depth', 'value', 'determined', 'sensor', 'corresponds', 'pixel', 'camera', 'claim', 'wherein', 'face', 'recognition', 'machine', 'configured', 'use', 'convolutional', 'neural', 'network', 'determine', 'confidence', 'value', 'camera', 'claim', 'wherein', 'face', 'recognition', 'machine', 'includes', 'plurality', 'input', 'nodes', 'wherein', 'input', 'node', 'configured', 'receive', 'pixel', 'value', 'array', 'corresponding', 'different', 'pixel', 'plurality', 'pixels', 'test', 'depth+multi-spectral', 'image', 'wherein', 'pixel', 'value', 'array', 'includes', 'depth', 'value', 'plurality', 'multi-spectral', 'values', 'pixel', 'camera', 'claim', 'wherein', 'plurality', 'multi-spectral', 'values', 'pixel', 'include', 'three', 'spectral', 'values', 'camera', 'claim', 'wherein', 'output', 'machine', 'configured', 'output', 'surface', 'normal', 'pixel', 'test', 'depth+multi-spectral', 'image', 'wherein', 'pixel', 'value', 'array', 'includes', 'surface', 'normal', 'camera', 'claim', 'wherein', 'output', 'machine', 'configured', 'output', 'curvature', 'pixel', 'test', 'depth+multi-spectral', 'image', 'wherein', 'pixel', 'value', 'array', 'includes', 'curvature', 'camera', 'claim', 'wherein', 'face', 'recognition', 'machine', 'configured', 'use', 'plurality', 'models', 'determine', 'confidence', 'value', 'wherein', 'plurality', 'models', 'includes', 'plurality', 'channel-specific', 'models', 'wherein', 'channel-specific', 'model', 'configured', 'process', 'different', 'pixel', 'parameter', 'plurality', 'pixels', 'test', 'depth+multi-spectral', 'image', 'wherein', 'channel-specific', 'model', 'includes', 'plurality', 'input', 'nodes', 'wherein', 'channel-specific', 'model', 'input', 'node', 'configured', 'receive', 'pixel', 'parameter', 'value', 'different', 'pixel', 'plurality', 'pixels', 'test', 'depth+multi-spectral', 'image', 'camera', 'claim', 'wherein', 'face', 'recognition', 'machine', 'configured', 'use', 'statistical', 'model', 'determine', 'confidence', 'value', 'camera', 'claim', 'wherein', 'statistical', 'model', 'includes', 'nearest', 'neighbor', 'algorithm', 'camera', 'claim', 'wherein', 'statistical', 'model', 'includes', 'support', 'vector', 'machine', 'camera', 'claim', 'wherein', 'face', 'recognition', 'machine', 'configured', 'output', 'location', 'test', 'depth+multi-spectral', 'image', 'bounding', 'box', 'around', 'recognized', 'face', 'camera', 'claim', 'wherein', 'face', 'recognition', 'machine', 'configured', 'output', 'location', 'test', 'depth+multi-spectral', 'image', 'identified', 'two-dimensional', 'facial', 'feature', 'recognized', 'face', 'camera', 'claim', 'wherein', 'face', 'recognition', 'machine', 'configured', 'output', 'location', 'test', 'depth+multi-spectral', 'image', 'identified', 'three-dimensional', 'facial', 'feature', 'recognized', 'face', 'camera', 'claim', 'wherein', 'face', 'recognition', 'machine', 'configured', 'output', 'location', 'test', 'depth+multi-spectral', 'image', 'identified', 'spectral', 'feature', 'recognized', 'face', 'camera', 'claim', 'wherein', 'face', 'recognition', 'machine', 'configured', 'output', 'pixel', 'test', 'depth+multi-spectral', 'image', 'confidence', 'value', 'indicating', 'likelihood', 'pixel', 'included', 'face', 'camera', 'claim', 'wherein', 'face', 'recognition', 'machine', 'configured', 'output', 'identity', 'face', 'recognized', 'test', 'depth+multi-spectral', 'image', 'camera', 'claim', 'wherein', 'plurality', 'sensors', 'sensor', 'array', 'differential', 'sensors', 'wherein', 'spectral', 'value', 'determined', 'based', 'depth', 'value', 'differential', 'measurement', 'differential', 'sensor', 'camera', 'comprising', 'sensor', 'array', 'including', 'plurality', 'sensors', 'infrared', 'ir', 'illuminator', 'configured', 'emit', 'active', 'ir', 'light', 'ir', 'light', 'sub-band', 'plurality', 'spectral', 'illuminators', 'spectral', 'illuminator', 'configured', 'emit', 'active', 'spectral', 'light', 'different', 'spectral', 'light', 'sub-band', 'depth', 'controller', 'machine', 'configured', 'determine', 'depth', 'value', 'plurality', 'sensors', 'based', 'active', 'ir', 'light', 'spectral', 'controller', 'machine', 'configured', 'plurality', 'sensors', 'determine', 'spectral', 'value', 'spectral', 'light', 'sub-band', 'plurality', 'spectral', 'illuminators', 'wherein', 'spectral', 'value', 'calculated', 'based', 'depth', 'value', 'determined', 'sensor', 'corresponds', 'pixel', 'output', 'machine', 'configured', 'output', 'test', 'depth+multi-spectral', 'image', 'including', 'plurality', 'pixels', 'pixel', 'corresponding', 'one', 'plurality', 'sensors', 'sensor', 'array', 'including', 'least', 'depth', 'value', 'spectral', 'value', 'spectral', 'light', 'sub-band', 'plurality', 'spectral', 'illuminators', 'face', 'recognition', 'machine', 'including', 'convolutional', 'neural', 'network', 'previously', 'trained', 'set', 'labeled', 'training', 'depth+multi-spectral', 'images', 'structure', 'test', 'depth+multi-spectral', 'image', 'face', 'recognition', 'machine', 'configured', 'output', 'confidence', 'value', 'indicating', 'likelihood', 'test', 'depth+multi-spectral', 'image', 'includes', 'face', 'image', 'processing', 'method', 'comprising', 'acquiring', 'photo', 'album', 'obtained', 'face', 'clustering', 'collecting', 'face', 'information', 'respective', 'images', 'photo', 'album', 'acquiring', 'face', 'parameter', 'image', 'according', 'face', 'information', 'selecting', 'cover', 'image', 'according', 'face', 'parameter', 'image', 'taking', 'face-region', 'image', 'cover', 'image', 'setting', 'face-region', 'image', 'cover', 'photo', 'album', 'wherein', 'selecting', 'cover', 'image', 'according', 'face', 'parameter', 'image', 'comprises', 'performing', 'calculation', 'face', 'parameter', 'image', 'preset', 'way', 'obtain', 'cover', 'score', 'image', 'selecting', 'image', 'highest', 'cover', 'score', 'cover', 'image', 'wherein', 'selecting', 'image', 'highest', 'cover', 'score', 'cover', 'image', 'comprises', 'acquiring', 'source', 'image', 'selecting', 'image', 'highest', 'cover', 'score', 'images', 'coming', 'preset', 'source', 'cover', 'image', 'method', 'according', 'claim', 'wherein', 'selecting', 'image', 'highest', 'cover', 'score', 'cover', 'image', 'comprises', 'acquiring', 'number', 'faces', 'contained', 'image', 'determining', 'single-person', 'images', 'according', 'number', 'faces', 'selecting', 'single-person', 'image', 'highest', 'cover', 'score', 'cover', 'image', 'method', 'according', 'claim', 'wherein', 'selecting', 'image', 'highest', 'cover', 'score', 'cover', 'image', 'comprises', 'single-person', 'image', 'photo', 'album', 'determining', 'images', 'including', 'two', 'faces', 'photo', 'album', 'selecting', 'image', 'highest', 'cover', 'score', 'images', 'including', 'two', 'faces', 'cover', 'image', 'method', 'according', 'claim', 'wherein', 'face', 'information', 'comprises', 'face', 'feature', 'points', 'face', 'parameter', 'comprises', 'face', 'turning', 'angle', 'acquiring', 'face', 'parameter', 'image', 'according', 'face', 'information', 'comprises', 'acquiring', 'coordinate', 'values', 'face', 'feature', 'points', 'determining', 'distances', 'angles', 'face', 'feature', 'points', 'determining', 'face', 'turning', 'angle', 'according', 'distances', 'angles', 'method', 'according', 'claim', 'wherein', 'face', 'parameter', 'comprises', 'face', 'ratio', 'acquiring', 'face', 'parameter', 'image', 'according', 'face', 'information', 'comprises', 'determining', 'face', 'region', 'image', 'according', 'face', 'information', 'calculating', 'ratio', 'area', 'face', 'region', 'area', 'image', 'obtain', 'face', 'ratio', 'method', 'according', 'claim', 'wherein', 'calculating', 'face', 'ratio', 'comprises', 'one', 'face', 'image', 'subtracting', 'area', 'occupied', 'faces', 'face', 'corresponding', 'photo', 'album', 'face', 'region', 'obtain', 'remaining', 'area', 'calculating', 'ratio', 'remaining', 'area', 'area', 'image', 'obtain', 'face', 'ratio', 'method', 'according', 'claim', 'wherein', 'collecting', 'face', 'information', 'respective', 'images', 'photo', 'album', 'comprises', 'acquiring', 'image', 'identifications', 'images', 'photo', 'album', 'extracting', 'face', 'information', 'corresponding', 'image', 'identifications', 'face', 'database', 'face', 'database', 'stored', 'face', 'recognition', 'results', 'images', 'face', 'recognition', 'results', 'including', 'face', 'information', 'image', 'processing', 'apparatus', 'comprising', 'processor', 'memory', 'configured', 'store', 'instructions', 'executable', 'processor', 'wherein', 'processor', 'configured', 'run', 'program', 'corresponding', 'instructions', 'reading', 'instructions', 'stored', 'memory', 'perform', 'acquiring', 'photo', 'album', 'obtained', 'face', 'clustering', 'collecting', 'face', 'information', 'image', 'photo', 'album', 'acquiring', 'face', 'parameter', 'image', 'according', 'face', 'information', 'selecting', 'cover', 'image', 'according', 'face', 'parameter', 'image', 'taking', 'face-region', 'image', 'cover', 'image', 'setting', 'face-region', 'image', 'cover', 'photo', 'album', 'wherein', 'processor', 'configured', 'perform', 'calculation', 'face', 'parameter', 'image', 'preset', 'way', 'obtain', 'cover', 'score', 'image', 'select', 'image', 'highest', 'cover', 'score', 'cover', 'image', 'wherein', 'processor', 'configured', 'acquire', 'source', 'image', 'select', 'image', 'highest', 'cover', 'score', 'images', 'coming', 'preset', 'source', 'cover', 'image', 'apparatus', 'according', 'claim', 'wherein', 'processor', 'configured', 'acquire', 'number', 'faces', 'contained', 'image', 'determine', 'single-person', 'images', 'according', 'number', 'faces', 'select', 'single-person', 'image', 'highest', 'cover', 'score', 'cover', 'image', 'apparatus', 'according', 'claim', 'wherein', 'processor', 'configured', 'single-person', 'image', 'photo', 'album', 'determine', 'images', 'including', 'two', 'faces', 'photo', 'album', 'select', 'image', 'highest', 'cover', 'score', 'images', 'including', 'two', 'faces', 'cover', 'image', 'apparatus', 'according', 'claim', 'wherein', 'face', 'information', 'comprises', 'face', 'feature', 'points', 'face', 'parameter', 'comprises', 'face', 'turning', 'angle', 'processor', 'configured', 'acquire', 'coordinate', 'values', 'face', 'feature', 'points', 'determine', 'distances', 'angles', 'face', 'feature', 'points', 'determine', 'face', 'turning', 'angle', 'according', 'distances', 'angles', 'apparatus', 'according', 'claim', 'wherein', 'face', 'parameter', 'comprises', 'face', 'ratio', 'processor', 'configured', 'determine', 'face', 'region', 'image', 'according', 'face', 'information', 'calculate', 'ratio', 'area', 'face', 'region', 'area', 'image', 'obtain', 'face', 'ratio', 'apparatus', 'according', 'claim', 'wherein', 'processor', 'configured', 'one', 'face', 'image', 'subtract', 'area', 'occupied', 'faces', 'face', 'corresponding', 'photo', 'album', 'face', 'region', 'obtain', 'remaining', 'area', 'calculate', 'ratio', 'remaining', 'area', 'area', 'image', 'obtain', 'face', 'ratio', 'apparatus', 'according', 'claim', 'wherein', 'processor', 'configured', 'acquire', 'image', 'identifications', 'images', 'photo', 'album', 'extract', 'face', 'information', 'corresponding', 'image', 'identifications', 'face', 'database', 'face', 'database', 'stored', 'face', 'recognition', 'results', 'images', 'face', 'recognition', 'results', 'including', 'face', 'information', 'electronic', 'device', 'comprising', 'processor', 'memory', 'display', 'screen', 'input', 'device', 'connected', 'via', 'system', 'bus', 'wherein', 'memory', 'stored', 'computer', 'programs', 'executed', 'processor', 'cause', 'processor', 'implement', 'image', 'processing', 'method', 'image', 'processing', 'method', 'comprising', 'acquiring', 'photo', 'album', 'obtained', 'face', 'clustering', 'collecting', 'face', 'information', 'respective', 'images', 'photo', 'album', 'acquiring', 'face', 'parameter', 'image', 'according', 'face', 'information', 'selecting', 'cover', 'image', 'according', 'face', 'parameter', 'image', 'taking', 'face-region', 'image', 'cover', 'image', 'setting', 'face-region', 'image', 'cover', 'photo', 'album', 'wherein', 'selecting', 'cover', 'image', 'according', 'face', 'parameter', 'image', 'comprises', 'performing', 'calculation', 'face', 'parameter', 'image', 'preset', 'way', 'obtain', 'cover', 'score', 'image', 'selecting', 'image', 'highest', 'cover', 'score', 'cover', 'image', 'wherein', 'selecting', 'image', 'highest', 'cover', 'score', 'cover', 'image', 'comprises', 'acquiring', 'source', 'image', 'selecting', 'image', 'highest', 'cover', 'score', 'images', 'coming', 'preset', 'source', 'cover', 'image', 'electronic', 'device', 'according', 'claim', 'wherein', 'electronic', 'device', 'comprises', 'least', 'one', 'mobile', 'phone', 'tablet', 'computer', 'personal', 'digital', 'assistant', 'wearable', 'device', 'computer-implemented', 'method', 'comprising', 'receiving', 'computing', 'device', 'meeting', 'invitation', 'identifying', 'location', 'least', 'one', 'invitee', 'meeting', 'invitation', 'configured', 'provide', 'least', 'one', 'invitee', 'physical', 'access', 'location', 'wherein', 'meeting', 'invitation', 'causes', 'system', 'control', 'pathway', 'allowing', 'physical', 'access', 'location', 'providing', 'based', 'meeting', 'invitation', 'least', 'one', 'invitee', 'physical', 'access', 'location', 'controlling', 'pathway', 'allowing', 'least', 'one', 'invitee', 'physically', 'access', 'location', 'pathway', 'response', 'positioning', 'data', 'indicating', 'least', 'one', 'invitee', 'predetermined', 'location', 'near', 'location', 'wherein', 'positioning', 'data', 'based', 'part', 'face', 'recognition', 'camera', 'system', 'identifying', 'least', 'one', 'invitee', 'receiving', 'positioning', 'data', 'face', 'recognition', 'camera', 'system', 'identifying', 'least', 'one', 'invitee', 'wherein', 'positioning', 'data', 'indicates', 'pattern', 'movement', 'least', 'one', 'invitee', 'determining', 'pattern', 'movement', 'indicates', 'least', 'one', 'invitee', 'exited', 'location', 'revoking', 'physical', 'access', 'location', 'identified', 'meeting', 'invitation', 'controlling', 'pathway', 'restrict', 'least', 'one', 'invitee', 'identified', 'meeting', 'invitation', 'physical', 'access', 'location', 'pathway', 'response', 'determining', 'pattern', 'movement', 'indicates', 'least', 'one', 'invitee', 'exited', 'location', 'computer-implemented', 'method', 'claim', 'wherein', 'determining', 'least', 'one', 'invitee', 'exited', 'location', 'comprises', 'determining', 'least', 'one', 'invitee', 'passed', 'egress', 'associated', 'location', 'predetermined', 'direction', 'computer-implemented', 'method', 'claim', 'wherein', 'determining', 'least', 'one', 'invitee', 'exited', 'location', 'comprises', 'determining', 'least', 'one', 'invitee', 'moved', 'area', 'predetermined', 'direction', 'computer-implemented', 'method', 'claim', 'wherein', 'positioning', 'data', 'indicates', 'second', 'pattern', 'movement', 'least', 'one', 'invitee', 'wherein', 'access', 'secured', 'data', 'associated', 'location', 'provided', 'response', 'detecting', 'second', 'pattern', 'movement', 'computer-implemented', 'method', 'claim', 'comprising', 'collating', 'secured', 'data', 'public', 'data', 'generate', 'resource', 'data', 'communicating', 'resource', 'data', 'client', 'computing', 'device', 'associated', 'least', 'one', 'invitee', 'access', 'location', 'provided', 'computer-implemented', 'method', 'claim', 'wherein', 'positioning', 'data', 'indicates', 'least', 'one', 'invitee', 'predetermined', 'location', 'least', 'one', 'invitee', 'passes', 'predetermined', 'location', 'computer-implemented', 'method', 'claim', 'wherein', 'positioning', 'data', 'indicates', 'least', 'one', 'invitee', 'predetermined', 'location', 'least', 'one', 'invitee', 'passes', 'predetermined', 'location', 'near', 'location', 'predetermined', 'direction', 'system', 'comprising', 'processor', 'memory', 'communication', 'processor', 'memory', 'computer-readable', 'instructions', 'stored', 'thereupon', 'executed', 'processor', 'cause', 'processor', 'receive', 'meeting', 'invitation', 'indicating', 'location', 'identity', 'meeting', 'invitation', 'configured', 'provide', 'least', 'one', 'invitee', 'physical', 'access', 'location', 'wherein', 'meeting', 'invitation', 'causes', 'system', 'control', 'pathway', 'allowing', 'physical', 'access', 'location', 'provide', 'least', 'one', 'invitee', 'associated', 'identity', 'access', 'location', 'controlling', 'pathway', 'allowing', 'least', 'one', 'invitee', 'physically', 'access', 'location', 'pathway', 'response', 'positioning', 'data', 'indicating', 'least', 'one', 'invitee', 'predetermined', 'location', 'near', 'location', 'wherein', 'positioning', 'data', 'based', 'part', 'face', 'recognition', 'camera', 'system', 'identifying', 'least', 'one', 'invitee', 'receive', 'positioning', 'data', 'face', 'recognition', 'camera', 'system', 'identifying', 'least', 'one', 'invitee', 'wherein', 'positioning', 'data', 'indicates', 'pattern', 'movement', 'least', 'one', 'invitee', 'determine', 'pattern', 'movement', 'indicates', 'least', 'one', 'invitee', 'exited', 'location', 'revoke', 'physical', 'access', 'location', 'identified', 'meeting', 'invitation', 'controlling', 'pathway', 'restrict', 'least', 'one', 'invitee', 'identified', 'meeting', 'invitation', 'physical', 'access', 'location', 'pathway', 'response', 'determining', 'pattern', 'movement', 'indicates', 'least', 'one', 'invitee', 'exited', 'location', 'system', 'claim', 'wherein', 'determining', 'least', 'one', 'invitee', 'exited', 'location', 'comprises', 'determining', 'least', 'one', 'invitee', 'passed', 'egress', 'associated', 'location', 'system', 'claim', 'wherein', 'determining', 'least', 'one', 'invitee', 'exited', 'location', 'comprises', 'determining', 'least', 'one', 'invitee', 'moved', 'area', 'predetermined', 'direction', 'system', 'claim', 'wherein', 'positioning', 'data', 'indicates', 'second', 'pattern', 'movement', 'least', 'one', 'invitee', 'wherein', 'access', 'secured', 'data', 'associated', 'location', 'provided', 'response', 'detecting', 'second', 'pattern', 'movement', 'system', 'claim', 'wherein', 'instructions', 'cause', 'processor', 'collate', 'secured', 'data', 'public', 'data', 'generate', 'resource', 'data', 'communicate', 'resource', 'data', 'client', 'computing', 'device', 'associated', 'least', 'one', 'invitee', 'access', 'location', 'provided', 'non-transitory', 'computer-readable', 'storage', 'medium', 'computer-executable', 'instructions', 'stored', 'thereupon', 'executed', 'one', 'processors', 'computing', 'device', 'cause', 'one', 'processors', 'computing', 'device', 'receive', 'meeting', 'invitation', 'indicating', 'location', 'identity', 'meeting', 'invitation', 'configured', 'provide', 'least', 'one', 'invitee', 'physical', 'access', 'location', 'wherein', 'meeting', 'invitation', 'causes', 'system', 'control', 'pathway', 'allowing', 'physical', 'access', 'location', 'provide', 'least', 'one', 'invitee', 'associated', 'identity', 'access', 'location', 'controlling', 'pathway', 'allowing', 'least', 'one', 'invitee', 'physically', 'access', 'location', 'pathway', 'response', 'positioning', 'data', 'indicating', 'least', 'one', 'invitee', 'predetermined', 'location', 'near', 'location', 'wherein', 'positioning', 'data', 'based', 'part', 'face', 'recognition', 'camera', 'system', 'identifying', 'least', 'one', 'invitee', 'receive', 'positioning', 'data', 'face', 'recognition', 'camera', 'system', 'identifying', 'least', 'one', 'invitee', 'wherein', 'positioning', 'data', 'indicates', 'pattern', 'movement', 'least', 'one', 'invitee', 'determine', 'pattern', 'movement', 'indicates', 'least', 'one', 'invitee', 'exited', 'location', 'revoke', 'physical', 'access', 'location', 'identified', 'meeting', 'invitation', 'controlling', 'pathway', 'restrict', 'least', 'one', 'invitee', 'identified', 'meeting', 'invitation', 'physical', 'access', 'location', 'pathway', 'response', 'determining', 'pattern', 'movement', 'indicates', 'least', 'one', 'invitee', 'exited', 'location', 'non-transitory', 'computer-readable', 'storage', 'medium', 'claim', 'wherein', 'determining', 'least', 'one', 'invitee', 'exited', 'location', 'comprises', 'determining', 'least', 'one', 'invitee', 'passed', 'egress', 'associated', 'location', 'non-transitory', 'computer-readable', 'storage', 'medium', 'claim', 'wherein', 'positioning', 'data', 'indicates', 'second', 'pattern', 'movement', 'least', 'one', 'invitee', 'wherein', 'access', 'secured', 'data', 'associated', 'location', 'provided', 'response', 'detecting', 'second', 'pattern', 'movement', 'non-transitory', 'computer-readable', 'storage', 'medium', 'claim', 'wherein', 'instructions', 'cause', 'one', 'processors', 'collate', 'secured', 'data', 'public', 'data', 'generate', 'resource', 'data', 'communicate', 'resource', 'data', 'client', 'computing', 'device', 'associated', 'least', 'one', 'invitee', 'access', 'location', 'provided', 'method', 'comprising', 'receiving', 'piece', 'content', 'salient', 'data', 'piece', 'content', 'based', 'salient', 'data', 'determining', 'first', 'path', 'viewport', 'piece', 'content', 'wherein', 'first', 'path', 'viewport', 'includes', 'different', 'salient', 'events', 'occurring', 'piece', 'content', 'different', 'times', 'playback', 'piece', 'content', 'providing', 'viewport', 'display', 'device', 'wherein', 'movement', 'viewport', 'based', 'first', 'path', 'viewport', 'salient', 'data', 'playback', 'detecting', 'additional', 'salient', 'event', 'piece', 'content', 'included', 'first', 'path', 'viewport', 'providing', 'indication', 'additional', 'salient', 'event', 'viewport', 'playback', 'method', 'claim', 'wherein', 'salient', 'data', 'identifies', 'salient', 'event', 'piece', 'content', 'salient', 'data', 'indicates', 'salient', 'event', 'piece', 'content', 'corresponding', 'point', 'location', 'salient', 'event', 'piece', 'content', 'corresponding', 'time', 'salient', 'event', 'occurs', 'playback', 'method', 'claim', 'wherein', 'salient', 'data', 'indicates', 'salient', 'event', 'piece', 'content', 'corresponding', 'type', 'salient', 'event', 'corresponding', 'strength', 'value', 'salient', 'event', 'method', 'claim', 'wherein', 'first', 'path', 'viewport', 'controls', 'movement', 'viewport', 'put', 'different', 'salient', 'events', 'view', 'viewport', 'different', 'times', 'playback', 'method', 'claim', 'comprising', 'detecting', 'one', 'salient', 'events', 'piece', 'content', 'based', 'least', 'one', 'following', 'visual', 'data', 'piece', 'content', 'audio', 'data', 'piece', 'content', 'content', 'consumption', 'experience', 'data', 'piece', 'content', 'wherein', 'salient', 'data', 'indicative', 'salient', 'event', 'detected', 'method', 'claim', 'comprising', 'detecting', 'one', 'salient', 'events', 'piece', 'content', 'based', 'least', 'one', 'following', 'face', 'recognition', 'facial', 'emotion', 'recognition', 'object', 'recognition', 'motion', 'recognition', 'metadata', 'piece', 'content', 'wherein', 'salient', 'data', 'indicative', 'salient', 'event', 'detected', 'method', 'claim', 'comprising', 'detecting', 'user', 'interaction', 'indication', 'wherein', 'indication', 'comprises', 'interactive', 'hint', 'response', 'detecting', 'user', 'interaction', 'adapting', 'first', 'path', 'viewport', 'second', 'path', 'viewport', 'based', 'user', 'interaction', 'wherein', 'second', 'path', 'viewport', 'includes', 'additional', 'salient', 'event', 'providing', 'updated', 'viewport', 'piece', 'content', 'display', 'device', 'wherein', 'movement', 'updated', 'viewport', 'based', 'second', 'path', 'viewport', 'salient', 'data', 'playback', 'second', 'path', 'viewport', 'controls', 'movement', 'updated', 'viewport', 'put', 'additional', 'salient', 'event', 'view', 'updated', 'viewport', 'method', 'claim', 'comprising', 'changing', 'weight', 'assigned', 'additional', 'salient', 'event', 'one', 'salient', 'events', 'piece', 'content', 'type', 'additional', 'salient', 'event', 'method', 'claim', 'wherein', 'second', 'path', 'viewport', 'includes', 'one', 'salient', 'events', 'piece', 'content', 'type', 'additional', 'salient', 'event', 'system', 'comprising', 'least', 'one', 'processor', 'non-transitory', 'processor-readable', 'memory', 'device', 'storing', 'instructions', 'executed', 'least', 'one', 'processor', 'causes', 'least', 'one', 'processor', 'perform', 'operations', 'including', 'receiving', 'piece', 'content', 'salient', 'data', 'piece', 'content', 'based', 'salient', 'data', 'determining', 'first', 'path', 'viewport', 'piece', 'content', 'wherein', 'first', 'path', 'viewport', 'includes', 'different', 'salient', 'events', 'occurring', 'piece', 'content', 'different', 'times', 'playback', 'piece', 'content', 'providing', 'viewport', 'display', 'device', 'wherein', 'movement', 'viewport', 'based', 'first', 'path', 'viewport', 'salient', 'data', 'playback', 'detecting', 'additional', 'salient', 'event', 'piece', 'content', 'included', 'first', 'path', 'viewport', 'providing', 'indication', 'additional', 'salient', 'event', 'viewport', 'playback', 'system', 'claim', 'wherein', 'salient', 'data', 'identifies', 'salient', 'event', 'piece', 'content', 'salient', 'data', 'indicates', 'salient', 'event', 'piece', 'content', 'corresponding', 'point', 'location', 'salient', 'event', 'piece', 'content', 'corresponding', 'time', 'salient', 'event', 'occurs', 'playback', 'system', 'claim', 'wherein', 'salient', 'data', 'indicates', 'salient', 'event', 'piece', 'content', 'corresponding', 'type', 'salient', 'event', 'corresponding', 'strength', 'value', 'salient', 'event', 'system', 'claim', 'wherein', 'salient', 'data', 'generated', 'offline', 'server', 'system', 'claim', 'operations', 'comprising', 'detecting', 'one', 'salient', 'events', 'piece', 'content', 'based', 'least', 'one', 'following', 'visual', 'data', 'piece', 'content', 'audio', 'data', 'piece', 'content', 'content', 'consumption', 'experience', 'data', 'piece', 'content', 'wherein', 'salient', 'data', 'indicative', 'salient', 'event', 'detected', 'system', 'claim', 'operations', 'comprising', 'detecting', 'one', 'salient', 'events', 'piece', 'content', 'based', 'least', 'one', 'following', 'face', 'recognition', 'facial', 'emotion', 'recognition', 'object', 'recognition', 'motion', 'recognition', 'metadata', 'piece', 'content', 'wherein', 'salient', 'data', 'indicative', 'salient', 'event', 'detected', 'system', 'claim', 'operations', 'comprising', 'detecting', 'user', 'interaction', 'indication', 'wherein', 'indication', 'comprises', 'interactive', 'hint', 'response', 'detecting', 'user', 'interaction', 'adapting', 'first', 'path', 'viewport', 'second', 'path', 'viewport', 'based', 'user', 'interaction', 'wherein', 'second', 'path', 'viewport', 'includes', 'additional', 'salient', 'event', 'providing', 'updated', 'viewport', 'piece', 'content', 'display', 'device', 'wherein', 'movement', 'updated', 'viewport', 'based', 'second', 'path', 'viewport', 'salient', 'data', 'playback', 'second', 'path', 'viewport', 'controls', 'movement', 'updated', 'viewport', 'put', 'additional', 'salient', 'event', 'view', 'updated', 'viewport', 'system', 'claim', 'operations', 'comprising', 'changing', 'weight', 'assigned', 'additional', 'salient', 'event', 'one', 'salient', 'events', 'piece', 'content', 'type', 'additional', 'salient', 'event', 'system', 'claim', 'wherein', 'second', 'path', 'viewport', 'includes', 'one', 'salient', 'events', 'piece', 'content', 'type', 'additional', 'salient', 'event', 'non-transitory', 'computer', 'readable', 'storage', 'medium', 'including', 'instructions', 'perform', 'method', 'comprising', 'receiving', 'piece', 'content', 'salient', 'data', 'piece', 'content', 'based', 'salient', 'data', 'determining', 'first', 'path', 'viewport', 'piece', 'content', 'wherein', 'first', 'path', 'viewport', 'includes', 'different', 'salient', 'events', 'occurring', 'piece', 'content', 'different', 'times', 'playback', 'piece', 'content', 'providing', 'viewport', 'display', 'device', 'wherein', 'movement', 'viewport', 'based', 'first', 'path', 'viewport', 'salient', 'data', 'playback', 'detecting', 'additional', 'salient', 'event', 'piece', 'content', 'included', 'first', 'path', 'viewport', 'providing', 'indication', 'additional', 'salient', 'event', 'viewport', 'playback', 'computer', 'readable', 'storage', 'medium', 'claim', 'method', 'comprising', 'detecting', 'user', 'interaction', 'indication', 'wherein', 'indication', 'comprises', 'interactive', 'hint', 'response', 'detecting', 'user', 'interaction', 'adapting', 'first', 'path', 'viewport', 'second', 'path', 'viewport', 'based', 'user', 'interaction', 'wherein', 'second', 'path', 'viewport', 'includes', 'additional', 'salient', 'event', 'providing', 'updated', 'viewport', 'piece', 'content', 'display', 'device', 'wherein', 'movement', 'updated', 'viewport', 'based', 'second', 'path', 'viewport', 'salient', 'data', 'playback', 'second', 'path', 'viewport', 'controls', 'movement', 'updated', 'viewport', 'put', 'additional', 'salient', 'event', 'view', 'updated', 'viewport', 'mobile', 'device', 'facial', 'recognition', 'mobile', 'device', 'comprising', 'one', 'cameras', 'processor', 'device', 'memory', 'coupled', 'processor', 'device', 'processing', 'system', 'programmed', 'receive', 'plurality', 'images', 'one', 'cameras', 'extract', 'feature', 'extractor', 'utilizing', 'convolutional', 'neural', 'network', 'cnn', 'enlarged', 'intra-class', 'variance', 'long-tail', 'classes', 'feature', 'vectors', 'plurality', 'images', 'generate', 'feature', 'generator', 'discriminative', 'feature', 'vectors', 'feature', 'vectors', 'classify', 'fully', 'connected', 'classifier', 'identity', 'discriminative', 'feature', 'vectors', 'control', 'operation', 'mobile', 'device', 'react', 'accordance', 'identity', 'mobile', 'device', 'recited', 'claim', 'includes', 'communication', 'system', 'mobile', 'device', 'recited', 'claim', 'wherein', 'operation', 'tags', 'video', 'identity', 'uploads', 'video', 'social', 'media', 'mobile', 'device', 'recited', 'claim', 'wherein', 'operation', 'tags', 'video', 'identity', 'sends', 'video', 'user', 'mobile', 'device', 'recited', 'claim', 'wherein', 'mobile', 'device', 'smart', 'phone', 'mobile', 'device', 'recited', 'claim', 'wherein', 'mobile', 'device', 'body', 'cam', 'mobile', 'device', 'recited', 'claim', 'programmed', 'train', 'feature', 'extractor', 'feature', 'generator', 'fully', 'connected', 'classifier', 'alternative', 'bi-stage', 'strategy', 'mobile', 'device', 'recited', 'claim', 'wherein', 'feature', 'extractor', 'shares', 'covariance', 'matrices', 'across', 'classes', 'transfer', 'intra-class', 'variance', 'regular', 'classes', 'long-tail', 'classes', 'mobile', 'device', 'recited', 'claim', 'wherein', 'feature', 'generator', 'optimizes', 'softmax', 'loss', 'joint', 'regularization', 'weights', 'features', 'magnitude', 'inner', 'product', 'weights', 'features', 'mobile', 'device', 'recited', 'claim', 'wherein', 'feature', 'extractor', 'averages', 'feature', 'vector', 'flipped', 'feature', 'vector', 'flipped', 'feature', 'vector', 'generated', 'horizontally', 'flipped', 'frame', 'one', 'plurality', 'images', 'mobile', 'device', 'recited', 'claim', 'wherein', 'plurality', 'images', 'selected', 'group', 'consisting', 'image', 'video', 'frame', 'video', 'mobile', 'device', 'recited', 'claim', 'wherein', 'communication', 'system', 'connects', 'remote', 'server', 'includes', 'facial', 'recognition', 'network', 'mobile', 'device', 'recited', 'claim', 'wherein', 'one', 'stage', 'alternative', 'bi-stage', 'strategy', 'fixes', 'feature', 'extractor', 'applies', 'feature', 'generator', 'generate', 'new', 'transferred', 'features', 'diverse', 'violate', 'decision', 'boundary', 'mobile', 'device', 'recited', 'claim', 'wherein', 'one', 'stage', 'alternative', 'bi-stage', 'strategy', 'fixes', 'fully', 'connected', 'classifier', 'updates', 'feature', 'extractor', 'feature', 'generator', 'computer', 'program', 'product', 'mobile', 'device', 'facial', 'recognition', 'computer', 'program', 'product', 'comprising', 'non-transitory', 'computer', 'readable', 'storage', 'medium', 'program', 'instructions', 'embodied', 'therewith', 'program', 'instructions', 'executable', 'computer', 'cause', 'computer', 'perform', 'method', 'comprising', 'receiving', 'processor', 'device', 'plurality', 'images', 'extracting', 'processor', 'device', 'feature', 'extractor', 'utilizing', 'convolutional', 'neural', 'network', 'cnn', 'enlarged', 'intra-class', 'variance', 'long-tail', 'classes', 'feature', 'vectors', 'plurality', 'images', 'generating', 'processor', 'device', 'feature', 'generator', 'discriminative', 'feature', 'vectors', 'feature', 'vectors', 'classifying', 'processor', 'device', 'utilizing', 'fully', 'connected', 'classifier', 'identity', 'discriminative', 'feature', 'vector', 'controlling', 'operation', 'mobile', 'device', 'react', 'accordance', 'identity', 'computer-implemented', 'method', 'facial', 'recognition', 'mobile', 'device', 'method', 'comprising', 'receiving', 'processor', 'device', 'plurality', 'images', 'extracting', 'processor', 'device', 'feature', 'extractor', 'utilizing', 'convolutional', 'neural', 'network', 'cnn', 'enlarged', 'intra-class', 'variance', 'long-tail', 'classes', 'feature', 'vectors', 'plurality', 'images', 'generating', 'processor', 'device', 'feature', 'generator', 'discriminative', 'feature', 'vectors', 'feature', 'vectors', 'classifying', 'processor', 'device', 'utilizing', 'fully', 'connected', 'classifier', 'identity', 'discriminative', 'feature', 'vector', 'controlling', 'operation', 'mobile', 'device', 'react', 'accordance', 'identity', 'computer-implemented', 'method', 'recited', 'claim', 'wherein', 'controlling', 'includes', 'tagging', 'video', 'identity', 'uploading', 'video', 'social', 'media', 'computer-implemented', 'method', 'recited', 'claim', 'wherein', 'controlling', 'includes', 'tagging', 'video', 'identity', 'sending', 'video', 'user', 'computer-implemented', 'method', 'recited', 'claim', 'wherein', 'extracting', 'includes', 'sharing', 'covariance', 'matrices', 'across', 'classes', 'transfer', 'intra-class', 'variance', 'regular', 'classes', 'long-tail', 'classes', 'computing', 'device', 'comprising', 'non-transitory', 'machine', 'readable', 'medium', 'storing', 'machine', 'trained', 'mt', 'network', 'comprising', 'plurality', 'layers', 'processing', 'nodes', 'processing', 'node', 'configured', 'compute', 'first', 'output', 'value', 'combining', 'set', 'output', 'values', 'set', 'processing', 'nodes', 'use', 'piecewise', 'linear', 'cup', 'function', 'compute', 'second', 'output', 'value', 'first', 'output', 'value', 'processing', 'node', 'wherein', 'piecewise', 'linear', 'cup', 'function', 'prior', 'training', 'mt', 'network', 'comprises', 'least', 'first', 'linear', 'section', 'first', 'slope', 'followed', 'ii', 'second', 'linear', 'section', 'negative', 'second', 'slope', 'followed', 'iii', 'third', 'linear', 'section', 'negative', 'third', 'slope', 'different', 'second', 'slope', 'followed', 'iv', 'fourth', 'linear', 'section', 'positive', 'fourth', 'slope', 'followed', 'v', 'fifth', 'linear', 'section', 'positive', 'fifth', 'slope', 'different', 'fourth', 'slope', 'followed', 'vi', 'sixth', 'linear', 'section', 'sixth', 'slope', 'wherein', 'piecewise', 'linear', 'cup', 'function', 'symmetric', 'vertical', 'axis', 'third', 'fourth', 'linear', 'sections', 'prior', 'training', 'mt', 'network', 'content', 'capturing', 'circuit', 'capturing', 'content', 'processing', 'mt', 'network', 'set', 'processing', 'units', 'executing', 'processing', 'nodes', 'process', 'content', 'captured', 'content', 'capturing', 'circuit', 'wherein', 'training', 'set', 'parameters', 'define', 'piecewise', 'linear', 'cup', 'function', 'node', 'first', 'second', 'pluralities', 'processing', 'nodes', 'processing', 'node', 'first', 'plurality', 'processing', 'nodes', 'configured', 'emulate', 'boolean', 'operator', 'output', 'value', 'processing', 'node', 'range', 'associated', '``', \"''\", 'value', 'set', 'inputs', 'processing', 'node', 'set', 'values', 'range', 'associated', '``', \"''\", 'ii', 'processing', 'node', 'second', 'plurality', 'processing', 'nodes', 'configured', 'emulate', 'boolean', 'xnor', 'operator', 'output', 'value', 'processing', 'node', 'range', 'associated', '``', \"''\", 'set', 'inputs', 'node', 'set', 'values', 'range', 'associated', '``', \"''\", 'b', 'set', 'inputs', 'node', 'set', 'values', 'range', 'associated', '``', \"''\", 'value', 'computing', 'device', 'claim', 'wherein', 'third', 'linear', 'section', 'piecewise', 'linear', 'cup', 'function', 'first', 'processing', 'node', 'mt', 'network', 'different', 'slope', 'third', 'linear', 'section', 'second', 'processing', 'node', 'mt', 'network', 'computing', 'device', 'claim', 'wherein', 'length', 'third', 'section', 'piecewise', 'linear', 'cup', 'function', 'first', 'processing', 'node', 'mt', 'network', 'different', 'length', 'third', 'section', 'piecewise', 'linear', 'cup', 'function', 'second', 'processing', 'node', 'mt', 'network', 'computing', 'device', 'claim', 'wherein', 'sets', 'parameters', 'trained', 'part', 'back', 'propagating', 'module', 'back', 'propagating', 'errors', 'output', 'values', 'later', 'layers', 'processing', 'nodes', 'earlier', 'layers', 'processing', 'nodes', 'adjusting', 'set', 'parameters', 'define', 'piecewise', 'linear', 'cup', 'functions', 'earlier', 'layers', 'processing', 'nodes', 'computing', 'device', 'claim', 'wherein', 'processing', 'node', 'uses', 'linear', 'function', 'defined', 'set', 'parameters', 'compute', 'first', 'output', 'value', 'processing', 'node', 'wherein', 'back', 'propagating', 'module', 'back', 'propagates', 'errors', 'output', 'values', 'later', 'layers', 'processing', 'nodes', 'earlier', 'layers', 'processing', 'nodes', 'adjusting', 'set', 'parameters', 'define', 'linear', 'functions', 'earlier', 'layers', 'processing', 'nodes', 'computing', 'device', 'claim', 'wherein', 'first', 'plurality', 'processing', 'nodes', 'emulate', 'boolean', 'operator', 'second', 'plurality', 'processing', 'nodes', 'emulate', 'boolean', 'xnor', 'operator', 'enable', 'mt', 'network', 'implement', 'mathematical', 'problems', 'computing', 'device', 'claim', 'wherein', 'plurality', 'processing', 'node', 'layers', 'plurality', 'processing', 'nodes', 'receive', 'input', 'values', 'output', 'values', 'plurality', 'processing', 'nodes', 'set', 'prior', 'layers', 'computing', 'device', 'claim', 'wherein', 'processing', 'node', 'uses', 'linear', 'function', 'compute', 'first', 'output', 'value', 'processing', 'node', 'wherein', 'processing', 'node', \"'s\", 'piecewise', 'linear', 'cup', 'function', 'defined', 'along', 'first', 'second', 'axes', 'first', 'axis', 'defining', 'range', 'output', 'values', 'processing', 'node', \"'s\", 'linear', 'function', 'second', 'axis', 'defining', 'range', 'output', 'values', 'produced', 'piecewise', 'linear', 'cup', 'function', 'range', 'output', 'values', 'processing', 'node', \"'s\", 'linear', 'function', 'computing', 'device', 'claim', 'comprising', 'content', 'output', 'circuit', 'presenting', 'output', 'based', 'processing', 'content', 'mt', 'network', 'computing', 'device', 'claim', 'wherein', 'captured', 'content', 'one', 'image', 'audio', 'segment', 'wherein', 'presented', 'output', 'output', 'display', 'display', 'screen', 'computing', 'device', 'audio', 'presentation', 'output', 'speaker', 'computing', 'device', 'computing', 'device', 'claim', 'wherein', 'computing', 'device', 'mobile', 'device', 'computing', 'device', 'claim', 'wherein', 'mt', 'network', 'mt', 'neural', 'network', 'processing', 'nodes', 'mt', 'neurons', 'computing', 'device', 'claim', 'wherein', 'set', 'parameters', 'configured', 'training', 'plurality', 'processing', 'nodes', 'comprise', 'least', 'one', 'negative', 'second', 'third', 'slopes', 'second', 'third', 'linear', 'sections', 'positive', 'fourth', 'fifth', 'slopes', 'fourth', 'fifth', 'linear', 'sections', 'first', 'intercept', 'second', 'linear', 'section', 'second', 'intercept', 'fifth', 'linear', 'section', 'set', 'lengths', 'least', 'second', 'third', 'fourth', 'fifth', 'sections', 'computing', 'device', 'claim', 'wherein', 'trained', 'set', 'parameters', 'define', 'piecewise', 'linear', 'cup', 'function', 'node', 'comprise', 'plurality', 'output', 'values', 'computing', 'device', 'claim', 'wherein', 'first', 'sixth', 'slopes', 'zerowe', 'claim', 'system', 'comprising', 'memory', 'device', 'store', 'input', 'image', 'processor', 'including', 'image', 'input', 'interface', 'receive', 'input', 'image', 'pre-processor', 'model', 'input', 'image', 'yield', 'multi-channel', 'image', 'feature', 'extractor', 'extract', 'set', 'features', 'based', 'multi-channel', 'image', 'feature', 'selector', 'select', 'one', 'features', 'set', 'features', 'multi-channel', 'image', 'wherein', 'one', 'features', 'selected', 'based', 'ability', 'differentiate', 'features', 'feature', 'matcher', 'match', 'one', 'features', 'learned', 'feature', 'set', 'similarity', 'detector', 'determine', 'whether', 'one', 'features', 'meet', 'pre-defined', 'similarity', 'threshold', 'system', 'claim', 'wherein', 'pre-processor', 'activate', 'one', 'channels', 'multi-channel', 'image', 'yield', 'one', 'activated', 'channels', 'system', 'claim', 'wherein', 'one', 'activated', 'channels', 'determined', 'based', 'ability', 'differentiate', 'features', 'system', 'claim', 'wherein', 'pre-processor', 'activate', 'one', 'local', 'patches', 'one', 'activated', 'channels', 'system', 'claim', 'wherein', 'one', 'local', 'patches', 'determined', 'based', 'ability', 'differentiate', 'features', 'system', 'claim', 'wherein', 'feature', 'matcher', 'utilize', 'large-scale', 'data', 'learning', 'process', 'perform', 'feature', 'matching', 'apparatus', 'comprising', 'image', 'input', 'interface', 'receive', 'input', 'image', 'pre-processor', 'model', 'input', 'image', 'yield', 'multi-channel', 'image', 'feature', 'extractor', 'extract', 'set', 'features', 'based', 'multi-channel', 'image', 'feature', 'selector', 'select', 'one', 'features', 'set', 'features', 'multi-channel', 'image', 'wherein', 'one', 'features', 'selected', 'based', 'ability', 'differentiate', 'features', 'feature', 'matcher', 'match', 'one', 'features', 'learned', 'feature', 'set', 'similarity', 'detector', 'determine', 'whether', 'one', 'features', 'meet', 'pre-defined', 'similarity', 'threshold', 'apparatus', 'claim', 'wherein', 'pre-processor', 'activate', 'one', 'channels', 'multi-channel', 'image', 'yield', 'one', 'activated', 'channels', 'apparatus', 'claim', 'wherein', 'one', 'activated', 'channels', 'determined', 'based', 'ability', 'differentiate', 'features', 'apparatus', 'claim', 'wherein', 'pre-processor', 'activate', 'one', 'local', 'patches', 'one', 'activated', 'channels', 'apparatus', 'claim', 'wherein', 'one', 'local', 'patches', 'determined', 'based', 'ability', 'differentiate', 'features', 'apparatus', 'claim', 'wherein', 'feature', 'matcher', 'utilize', 'large-scale', 'data', 'learning', 'process', 'perform', 'feature', 'matching', 'method', 'comprising', 'modeling', 'input', 'image', 'yield', 'multi-channel', 'image', 'extracting', 'set', 'features', 'based', 'multi-channel', 'image', 'selecting', 'one', 'features', 'set', 'features', 'multi-channel', 'image', 'wherein', 'one', 'features', 'selected', 'based', 'ability', 'differentiate', 'features', 'matching', 'one', 'features', 'learned', 'feature', 'set', 'determining', 'whether', 'one', 'features', 'meet', 'pre-defined', 'similarity', 'threshold', 'method', 'claim', 'wherein', 'modeling', 'input', 'image', 'include', 'activating', 'one', 'channels', 'multi-channel', 'image', 'yield', 'one', 'activated', 'channels', 'method', 'claim', 'wherein', 'one', 'activated', 'channels', 'determined', 'based', 'ability', 'differentiate', 'features', 'method', 'claim', 'wherein', 'extracting', 'features', 'input', 'image', 'include', 'activating', 'one', 'local', 'patches', 'one', 'activated', 'channels', 'method', 'claim', 'wherein', 'one', 'local', 'patches', 'determined', 'based', 'ability', 'differentiate', 'features', 'method', 'claim', 'wherein', 'feature', 'matcher', 'utilizes', 'large-scale', 'data', 'learning', 'process', 'perform', 'feature', 'matching', 'least', 'one', 'non-transitory', 'computer', 'readable', 'storage', 'medium', 'comprising', 'set', 'instructions', 'executed', 'computing', 'device', 'cause', 'computing', 'device', 'model', 'input', 'image', 'yield', 'multi-channel', 'image', 'extract', 'set', 'features', 'based', 'multi-channel', 'image', 'select', 'one', 'features', 'set', 'features', 'multi-channel', 'image', 'wherein', 'features', 'selected', 'based', 'ability', 'differentiate', 'features', 'match', 'one', 'features', 'learned', 'feature', 'set', 'determine', 'whether', 'one', 'features', 'meet', 'pre-defined', 'similarity', 'threshold', 'least', 'one', 'non-transitory', 'computer', 'readable', 'storage', 'medium', 'claim', 'wherein', 'instructions', 'executed', 'cause', 'computing', 'device', 'activate', 'one', 'channels', 'multi-channel', 'image', 'yield', 'one', 'activated', 'channels', 'least', 'one', 'non-transitory', 'computer', 'readable', 'storage', 'medium', 'claim', 'wherein', 'instructions', 'executed', 'cause', 'computing', 'device', 'determine', 'one', 'activated', 'channels', 'based', 'ability', 'differentiate', 'features', 'least', 'one', 'non-transitory', 'computer', 'readable', 'storage', 'medium', 'claim', 'wherein', 'extracting', 'features', 'input', 'image', 'include', 'activating', 'one', 'local', 'patches', 'one', 'activated', 'channels', 'least', 'one', 'non-transitory', 'computer', 'readable', 'storage', 'medium', 'claim', 'wherein', 'one', 'local', 'patches', 'determined', 'based', 'ability', 'differentiate', 'features', 'least', 'one', 'non-transitory', 'computer', 'readable', 'storage', 'medium', 'claim', 'wherein', 'feature', 'matcher', 'utilize', 'large-scale', 'data', 'learning', 'process', 'perform', 'feature', 'matching', 'apparatus', 'comprising', 'means', 'modeling', 'input', 'image', 'yield', 'multi-channel', 'image', 'means', 'extracting', 'set', 'features', 'based', 'multi-channel', 'image', 'means', 'selecting', 'one', 'features', 'set', 'features', 'multi-channel', 'image', 'wherein', 'one', 'features', 'selected', 'based', 'ability', 'differentiate', 'features', 'means', 'matching', 'one', 'features', 'learned', 'feature', 'set', 'means', 'determining', 'whether', 'one', 'features', 'meet', 'pre-defined', 'similarity', 'threshold', 'method', 'controlling', 'terminal', 'terminal', 'comprising', 'capturing', 'apparatus', 'least', 'one', 'processor', 'method', 'comprising', 'acquiring', 'capturing', 'apparatus', 'image', 'obtaining', 'least', 'one', 'processor', 'motion', 'parameter', 'terminal', 'motion', 'parameter', 'comprising', 'least', 'one', 'motion', 'frequency', 'motion', 'time', 'two', 'parameters', 'among', 'acceleration', 'angular', 'velocity', 'motion', 'amplitude', 'motion', 'frequency', 'motion', 'time', 'transmitting', 'least', 'one', 'processor', 'parameter', 'threshold', 'obtaining', 'request', 'data', 'management', 'server', 'parameter', 'threshold', 'obtaining', 'request', 'comprising', 'configuration', 'information', 'terminal', 'receiving', 'corresponding', 'preset', 'thresholds', 'correspond', 'configuration', 'information', 'response', 'parameter', 'threshold', 'obtaining', 'request', 'comparing', 'two', 'parameters', 'corresponding', 'preset', 'thresholds', 'controlling', 'least', 'one', 'processor', 'perform', 'image', 'processing', 'acquired', 'image', 'based', 'least', 'one', 'two', 'parameters', 'motion', 'parameter', 'greater', 'corresponding', 'preset', 'threshold', 'based', 'two', 'parameters', 'motion', 'parameter', 'respectively', 'greater', 'corresponding', 'preset', 'thresholds', 'wherein', 'acquiring', 'comprises', 'acquiring', 'image', 'real', 'time', 'obtaining', 'comprises', 'obtaining', 'motion', 'parameter', 'terminal', 'real', 'time', 'method', 'comprising', 'response', 'least', 'one', 'two', 'parameters', 'motion', 'parameter', 'greater', 'corresponding', 'preset', 'threshold', 'obtaining', 'motion', 'parameter', 'terminal', 'response', 'two', 'parameters', 'motion', 'parameter', 'obtained', 'latest', 'time', 'less', 'equal', 'corresponding', 'preset', 'thresholds', 'performing', 'image', 'processing', 'image', 'acquired', 'latest', 'time', 'method', 'according', 'claim', 'wherein', 'acquiring', 'comprises', 'controlling', 'least', 'one', 'processor', 'turn', 'capturing', 'apparatus', 'based', 'face', 'recognition', 'instruction', 'acquiring', 'capturing', 'apparatus', 'face', 'image', 'capturing', 'apparatus', 'turned', 'method', 'according', 'claim', 'wherein', 'controlling', 'perform', 'image', 'processing', 'comprises', 'skipping', 'performing', 'face', 'recognition', 'acquired', 'face', 'image', 'based', 'least', 'one', 'two', 'parameters', 'motion', 'parameter', 'greater', 'corresponding', 'preset', 'threshold', 'based', 'two', 'parameters', 'motion', 'parameter', 'respectively', 'greater', 'corresponding', 'preset', 'thresholds', 'method', 'according', 'claim', 'wherein', 'obtaining', 'comprises', 'least', 'one', 'obtaining', 'acceleration', 'terminal', 'using', 'acceleration', 'sensor', 'obtaining', 'angular', 'velocity', 'terminal', 'using', 'gyro', 'sensor', 'method', 'according', 'claim', 'wherein', 'transmitting', 'comprises', 'transmitting', 'parameter', 'threshold', 'obtaining', 'request', 'data', 'management', 'server', 'according', 'preset', 'time', 'period', 'method', 'according', 'claim', 'comprising', 'generating', 'prompt', 'information', 'based', 'least', 'one', 'two', 'parameters', 'motion', 'parameter', 'greater', 'corresponding', 'preset', 'threshold', 'prompt', 'information', 'used', 'prompting', 'terminal', 'stop', 'moving', 'method', 'according', 'claim', 'wherein', 'motion', 'parameter', 'comprises', 'motion', 'frequency', 'motion', 'time', 'terminal', 'comprising', 'capturing', 'apparatus', 'least', 'one', 'memory', 'configured', 'store', 'program', 'code', 'least', 'one', 'processor', 'configured', 'access', 'least', 'one', 'memory', 'operate', 'according', 'program', 'code', 'program', 'code', 'comprising', 'motion', 'parameter', 'obtaining', 'code', 'configured', 'cause', 'least', 'one', 'processor', 'acquire', 'image', 'using', 'capturing', 'apparatus', 'obtain', 'motion', 'parameter', 'terminal', 'motion', 'parameter', 'comprising', 'least', 'one', 'motion', 'frequency', 'motion', 'time', 'two', 'parameters', 'among', 'acceleration', 'angular', 'velocity', 'motion', 'amplitude', 'motion', 'frequency', 'motion', 'time', 'request', 'transmitting', 'code', 'configured', 'cause', 'least', 'one', 'processor', 'transmit', 'parameter', 'threshold', 'obtaining', 'request', 'data', 'management', 'server', 'parameter', 'threshold', 'obtaining', 'request', 'comprising', 'configuration', 'information', 'terminal', 'parameter', 'threshold', 'receiving', 'code', 'configured', 'cause', 'least', 'one', 'processor', 'receive', 'corresponding', 'preset', 'thresholds', 'correspond', 'configuration', 'information', 'response', 'parameter', 'threshold', 'obtaining', 'request', 'comparing', 'code', 'configured', 'cause', 'least', 'one', 'processor', 'compare', 'two', 'parameters', 'corresponding', 'preset', 'thresholds', 'control', 'code', 'configured', 'cause', 'least', 'one', 'processor', 'perform', 'image', 'processing', 'acquired', 'image', 'based', 'least', 'one', 'two', 'parameters', 'motion', 'parameter', 'greater', 'corresponding', 'preset', 'threshold', 'based', 'two', 'parameters', 'motion', 'parameter', 'respectively', 'greater', 'corresponding', 'preset', 'thresholds', 'wherein', 'motion', 'parameter', 'obtaining', 'code', 'causes', 'least', 'one', 'processor', 'acquire', 'image', 'real', 'time', 'obtain', 'motion', 'parameter', 'terminal', 'real', 'time', 'response', 'least', 'one', 'two', 'parameters', 'motion', 'parameter', 'greater', 'corresponding', 'preset', 'threshold', 'obtain', 'motion', 'parameter', 'terminal', 'wherein', 'control', 'code', 'causes', 'least', 'one', 'processor', 'response', 'two', 'parameters', 'motion', 'parameter', 'obtained', 'latest', 'time', 'less', 'equal', 'corresponding', 'preset', 'thresholds', 'perform', 'image', 'processing', 'image', 'acquired', 'latest', 'time', 'terminal', 'according', 'claim', 'wherein', 'program', 'code', 'comprises', 'face', 'instruction', 'receiving', 'code', 'configured', 'cause', 'least', 'one', 'processor', 'receive', 'face', 'recognition', 'instruction', 'wherein', 'motion', 'parameter', 'obtaining', 'code', 'causes', 'least', 'one', 'processor', 'control', 'according', 'face', 'recognition', 'instruction', 'capturing', 'apparatus', 'turn', 'acquire', 'face', 'image', 'using', 'capturing', 'apparatus', 'capturing', 'apparatus', 'turned', 'wherein', 'control', 'code', 'causes', 'least', 'one', 'processor', 'skip', 'performing', 'face', 'recognition', 'acquired', 'face', 'image', 'based', 'least', 'one', 'two', 'parameters', 'motion', 'parameter', 'greater', 'corresponding', 'preset', 'threshold', 'based', 'two', 'parameters', 'motion', 'parameter', 'respectively', 'greater', 'corresponding', 'preset', 'thresholds', 'terminal', 'according', 'claim', 'wherein', 'request', 'transmitting', 'code', 'causes', 'least', 'one', 'processor', 'transmit', 'parameter', 'threshold', 'obtaining', 'request', 'data', 'management', 'server', 'according', 'preset', 'time', 'period', 'terminal', 'according', 'claim', 'wherein', 'program', 'code', 'comprises', 'prompt', 'information', 'generation', 'code', 'configured', 'cause', 'least', 'one', 'processor', 'generate', 'prompt', 'information', 'based', 'least', 'one', 'two', 'parameters', 'motion', 'parameter', 'greater', 'corresponding', 'preset', 'threshold', 'prompt', 'information', 'used', 'prompting', 'terminal', 'stop', 'moving', 'terminal', 'according', 'claim', 'wherein', 'motion', 'parameter', 'comprises', 'motion', 'frequency', 'motion', 'time', 'non-transitory', 'computer-readable', 'storage', 'medium', 'storing', 'machine', 'instruction', 'executed', 'one', 'processors', 'causes', 'one', 'processors', 'perform', 'obtaining', 'image', 'acquired', 'capturing', 'apparatus', 'obtaining', 'motion', 'parameter', 'terminal', 'terminal', 'comprising', 'capturing', 'apparatus', 'motion', 'parameter', 'comprising', 'least', 'one', 'motion', 'frequency', 'motion', 'time', 'two', 'parameters', 'among', 'acceleration', 'angular', 'velocity', 'motion', 'amplitude', 'motion', 'frequency', 'motion', 'time', 'transmitting', 'parameter', 'threshold', 'obtaining', 'request', 'data', 'management', 'server', 'parameter', 'threshold', 'obtaining', 'request', 'comprising', 'configuration', 'information', 'terminal', 'receiving', 'corresponding', 'preset', 'thresholds', 'correspond', 'configuration', 'information', 'response', 'parameter', 'threshold', 'obtaining', 'request', 'comparing', 'two', 'parameters', 'corresponding', 'preset', 'thresholds', 'controlling', 'perform', 'image', 'processing', 'acquired', 'image', 'based', 'least', 'one', 'two', 'parameters', 'motion', 'parameter', 'greater', 'corresponding', 'preset', 'threshold', 'based', 'two', 'parameters', 'motion', 'parameter', 'respectively', 'greater', 'corresponding', 'preset', 'thresholds', 'wherein', 'acquiring', 'comprises', 'acquiring', 'image', 'real', 'time', 'obtaining', 'comprises', 'obtaining', 'motion', 'parameter', 'terminal', 'real', 'time', 'method', 'comprising', 'response', 'least', 'one', 'two', 'parameters', 'motion', 'parameter', 'greater', 'corresponding', 'preset', 'threshold', 'obtaining', 'motion', 'parameter', 'terminal', 'response', 'two', 'parameters', 'motion', 'parameter', 'obtained', 'latest', 'time', 'less', 'equal', 'corresponding', 'preset', 'thresholds', 'performing', 'image', 'processing', 'image', 'acquired', 'latest', 'time', 'non-transitory', 'computer-readable', 'storage', 'medium', 'according', 'claim', 'wherein', 'acquired', 'image', 'face', 'image', 'image', 'processing', 'comprises', 'performing', 'face', 'recognition', 'non-transitory', 'computer-readable', 'storage', 'medium', 'according', 'claim', 'wherein', 'obtaining', 'motion', 'parameter', 'comprises', 'least', 'one', 'obtaining', 'acceleration', 'terminal', 'using', 'acceleration', 'sensor', 'obtaining', 'angular', 'velocity', 'terminal', 'using', 'gyro', 'sensor', 'non-transitory', 'computer-readable', 'storage', 'medium', 'according', 'claim', 'wherein', 'motion', 'parameter', 'comprises', 'motion', 'frequency', 'motion', 'time', 'method', 'processing', 'drive-through', 'order', 'method', 'comprising', 'receiving', 'customer', 'information', 'detected', 'vision', 'recognition', 'providing', 'product', 'information', 'customer', 'based', 'customer', 'information', 'processing', 'product', 'order', 'customer', 'method', 'according', 'claim', 'wherein', 'receiving', 'customer', 'information', 'comprises', 'least', 'one', 'receiving', 'customer', 'information', 'associated', 'vehicle', 'information', 'detected', 'vehicle', 'recognition', 'receiving', 'customer', 'information', 'associated', 'identification', 'information', 'detected', 'face', 'recognition', 'method', 'according', 'claim', 'comprising', 'determining', 'whether', 'customer', 'pre-order', 'customer', 'based', 'customer', 'information', 'wherein', 'customer', 'determined', 'pre-order', 'customer', 'providing', 'product', 'information', 'based', 'customer', 'information', 'comprises', 'providing', 'pre-order', 'information', 'using', 'least', 'one', 'audio', 'video', 'processing', 'product', 'order', 'customer', 'comprises', 'providing', 'information', 'promptly', 'guiding', 'vehicle', 'pickup', 'stand', 'using', 'least', 'one', 'audio', 'video', 'providing', 'information', 'additional', 'order', 'available', 'method', 'according', 'claim', 'wherein', 'product', 'information', 'based', 'customer', 'information', 'comprises', 'recently', 'ordered', 'product', 'component', 'frequently', 'ordered', 'product', 'component', 'order', 'history', 'customer', 'information', 'method', 'according', 'claim', 'wherein', 'receiving', 'customer', 'information', 'comprises', 'receiving', 'information', 'age', 'gender', 'passenger', 'detected', 'face', 'recognition', 'providing', 'product', 'information', 'customer', 'based', 'customer', 'information', 'comprises', 'providing', 'recommended', 'menu', 'information', 'differentiated', 'according', 'age', 'gender', 'method', 'according', 'claim', 'wherein', 'processing', 'product', 'order', 'customer', 'comprises', 'determining', 'product', 'component', 'past', 'order', 'history', 'component', 'modified', 'product', 'component', 'product', 'order', 'method', 'according', 'claim', 'wherein', 'processing', 'product', 'order', 'customer', 'comprises', 'paying', 'product', 'price', 'according', 'biometrics-based', 'authentication', 'communication', 'system', 'vehicle', 'mobile', 'terminal', 'method', 'according', 'claim', 'wherein', 'processing', 'product', 'order', 'customer', 'comprises', 'issuing', 'payment', 'number', 'divided', 'payment', 'performing', 'divided', 'payments', 'according', 'payment', 'requests', 'plurality', 'mobile', 'terminals', 'payment', 'numbers', 'inputted', 'method', 'according', 'claim', 'wherein', 'processing', 'product', 'order', 'customer', 'comprises', 'accumulating', 'mileage', 'account', 'corresponding', 'mobile', 'terminal', 'undergoing', 'payment', 'method', 'according', 'claim', 'wherein', 'processing', 'product', 'order', 'customer', 'comprises', 'suggesting', 'takeout', 'packaging', 'method', 'according', 'temperature', 'product', 'atmospheric', 'temperature', 'weather', 'vehicle', 'type', 'apparatus', 'configured', 'process', 'drive-through', 'order', 'apparatus', 'comprising', 'transceiver', 'configured', 'receive', 'customer', 'information', 'detected', 'vision', 'recognition', 'digital', 'signage', 'configured', 'provide', 'product', 'information', 'customer', 'based', 'customer', 'information', 'processor', 'configured', 'process', 'product', 'order', 'customer', 'apparatus', 'according', 'claim', 'wherein', 'transceiver', 'receives', 'least', 'one', 'customer', 'information', 'associated', 'vehicle', 'information', 'detected', 'vehicle', 'recognition', 'customer', 'information', 'associated', 'identification', 'information', 'detected', 'face', 'recognition', 'apparatus', 'according', 'claim', 'wherein', 'processor', 'configured', 'determine', 'whether', 'customer', 'pre-order', 'customer', 'based', 'customer', 'information', 'customer', 'determined', 'pre-order', 'customer', 'perform', 'control', 'operation', 'provide', 'pre-order', 'information', 'control', 'digital', 'signage', 'output', 'information', 'promptly', 'guiding', 'vehicle', 'pickup', 'stand', 'provide', 'information', 'additional', 'order', 'available', 'apparatus', 'according', 'claim', 'wherein', 'product', 'information', 'based', 'customer', 'information', 'comprises', 'recently', 'ordered', 'product', 'component', 'frequently', 'ordered', 'product', 'component', 'order', 'history', 'customer', 'information', 'apparatus', 'according', 'claim', 'wherein', 'transceiver', 'configured', 'receive', 'information', 'age', 'gender', 'passenger', 'detected', 'face', 'recognition', 'processor', 'configured', 'control', 'digital', 'signage', 'provide', 'recommended', 'menu', 'information', 'differentiated', 'according', 'age', 'gender', 'apparatus', 'according', 'claim', 'wherein', 'processor', 'configured', 'determine', 'product', 'component', 'past', 'order', 'history', 'component', 'modified', 'product', 'component', 'product', 'order', 'apparatus', 'according', 'claim', 'wherein', 'processor', 'configured', 'pay', 'product', 'price', 'according', 'biometrics-based', 'authentication', 'communication', 'system', 'vehicle', 'mobile', 'terminal', 'apparatus', 'according', 'claim', 'wherein', 'processor', 'configured', 'issue', 'payment', 'number', 'divided', 'payment', 'perform', 'divided', 'payments', 'according', 'requests', 'plurality', 'mobile', 'terminals', 'payment', 'numbers', 'inputted', 'apparatus', 'according', 'claim', 'wherein', 'processor', 'configured', 'accumulate', 'mileage', 'account', 'corresponding', 'mobile', 'terminal', 'undergoing', 'payment', 'apparatus', 'according', 'claim', 'wherein', 'processor', 'configured', 'control', 'digital', 'signage', 'suggest', 'takeout', 'packaging', 'method', 'according', 'temperature', 'product', 'atmospheric', 'temperature', 'weather', 'vehicle', 'type', 'image', 'information', 'processing', 'method', 'performed', 'computing', 'device', 'one', 'processors', 'memory', 'storing', 'plurality', 'programs', 'executed', 'one', 'processors', 'method', 'comprising', 'identifying', 'using', 'face', 'recognition', 'one', 'faces', 'face', 'corresponding', 'respective', 'person', 'captured', 'first', 'image', 'identified', 'face', 'extracting', 'set', 'profile', 'parameters', 'corresponding', 'person', 'first', 'image', 'selecting', 'plurality', 'image', 'tiles', 'first', 'image', 'tile', 'matches', 'face', 'corresponding', 'person', 'first', 'image', 'accordance', 'predefined', 'correspondence', 'set', 'profile', 'parameters', 'corresponding', 'person', 'set', 'pre-stored', 'description', 'parameters', 'first', 'image', 'tile', 'generating', 'second', 'image', 'covering', 'faces', 'respective', 'persons', 'first', 'image', 'corresponding', 'first', 'image', 'tiles', 'sharing', 'first', 'image', 'second', 'image', 'predefined', 'order', 'via', 'group', 'chat', 'session', 'method', 'claim', 'wherein', 'first', 'image', 'second', 'image', 'displayed', 'group', 'chat', 'session', 'one', 'image', 'time', 'one', 'two', 'images', 'replaced', 'two', 'images', 'periodically', 'method', 'claim', 'wherein', 'extracting', 'set', 'profile', 'parameters', 'corresponding', 'person', 'first', 'image', 'includes', 'determining', 'one', 'descriptive', 'labels', 'corresponding', 'identified', 'face', 'corresponding', 'person', 'using', 'first', 'machine', 'learning', 'model', 'wherein', 'first', 'machine', 'learning', 'model', 'trained', 'facial', 'images', 'corresponding', 'descriptive', 'labels', 'method', 'claim', 'wherein', 'extracting', 'set', 'profile', 'parameters', 'corresponding', 'person', 'first', 'image', 'includes', 'determining', 'identity', 'corresponding', 'person', 'based', 'identified', 'face', 'corresponding', 'person', 'locating', 'respective', 'profile', 'information', 'first', 'person', 'based', 'determined', 'identity', 'corresponding', 'person', 'using', 'one', 'characteristics', 'respective', 'profile', 'information', 'first', 'person', 'set', 'profile', 'parameters', 'corresponding', 'identified', 'face', 'corresponding', 'person', 'method', 'claim', 'wherein', 'least', 'first', 'one', 'first', 'image', 'tiles', 'dynamic', 'image', 'tile', 'least', 'second', 'one', 'first', 'image', 'tiles', 'static', 'image', 'tile', 'method', 'claim', 'including', 'receiving', 'plurality', 'user', 'comments', 'different', 'users', 'group', 'chat', 'session', 'user', 'comment', 'including', 'descriptive', 'term', 'respective', 'person', 'identified', 'first', 'image', 'choosing', 'descriptive', 'label', 'respective', 'person', 'according', 'plurality', 'user', 'comments', 'updating', 'second', 'image', 'adding', 'descriptive', 'label', 'adjacent', 'first', 'image', 'tile', 'respective', 'person', 'computing', 'device', 'image', 'information', 'processing', 'comprising', 'one', 'processors', 'memory', 'storing', 'instructions', 'executed', 'one', 'processors', 'cause', 'processors', 'perform', 'plurality', 'operations', 'comprising', 'identifying', 'using', 'face', 'recognition', 'one', 'faces', 'face', 'corresponding', 'respective', 'person', 'captured', 'first', 'image', 'identified', 'face', 'extracting', 'set', 'profile', 'parameters', 'corresponding', 'person', 'first', 'image', 'selecting', 'plurality', 'image', 'tiles', 'first', 'image', 'tile', 'matches', 'face', 'corresponding', 'person', 'first', 'image', 'accordance', 'predefined', 'correspondence', 'set', 'profile', 'parameters', 'corresponding', 'person', 'set', 'pre-stored', 'description', 'parameters', 'first', 'image', 'tile', 'generating', 'second', 'image', 'covering', 'faces', 'respective', 'persons', 'first', 'image', 'corresponding', 'first', 'image', 'tiles', 'sharing', 'first', 'image', 'second', 'image', 'predefined', 'order', 'via', 'group', 'chat', 'session', 'computing', 'device', 'claim', 'wherein', 'first', 'image', 'second', 'image', 'displayed', 'group', 'chat', 'session', 'one', 'image', 'time', 'one', 'two', 'images', 'replaced', 'two', 'images', 'periodically', 'computing', 'device', 'claim', 'wherein', 'extracting', 'set', 'profile', 'parameters', 'corresponding', 'person', 'first', 'image', 'includes', 'determining', 'one', 'descriptive', 'labels', 'corresponding', 'identified', 'face', 'corresponding', 'person', 'using', 'first', 'machine', 'learning', 'model', 'wherein', 'first', 'machine', 'learning', 'model', 'trained', 'facial', 'images', 'corresponding', 'descriptive', 'labels', 'computing', 'device', 'claim', 'wherein', 'extracting', 'set', 'profile', 'parameters', 'corresponding', 'person', 'first', 'image', 'includes', 'determining', 'identity', 'corresponding', 'person', 'based', 'identified', 'face', 'corresponding', 'person', 'locating', 'respective', 'profile', 'information', 'first', 'person', 'based', 'determined', 'identity', 'corresponding', 'person', 'using', 'one', 'characteristics', 'respective', 'profile', 'information', 'first', 'person', 'set', 'profile', 'parameters', 'corresponding', 'identified', 'face', 'corresponding', 'person', 'computing', 'device', 'claim', 'wherein', 'least', 'first', 'one', 'first', 'image', 'tiles', 'dynamic', 'image', 'tile', 'least', 'second', 'one', 'first', 'image', 'tiles', 'static', 'image', 'tile', 'computing', 'device', 'claim', 'wherein', 'plurality', 'operations', 'include', 'receiving', 'plurality', 'user', 'comments', 'different', 'users', 'group', 'chat', 'session', 'user', 'comment', 'including', 'descriptive', 'term', 'respective', 'person', 'identified', 'first', 'image', 'choosing', 'descriptive', 'label', 'respective', 'person', 'according', 'plurality', 'user', 'comments', 'updating', 'second', 'image', 'adding', 'descriptive', 'label', 'adjacent', 'first', 'image', 'tile', 'respective', 'person', 'non-transitory', 'computer-readable', 'storage', 'medium', 'storing', 'instructions', 'executed', 'computing', 'device', 'one', 'processors', 'cause', 'computing', 'device', 'perform', 'plurality', 'operations', 'comprising', 'identifying', 'using', 'face', 'recognition', 'one', 'faces', 'face', 'corresponding', 'respective', 'person', 'captured', 'first', 'image', 'identified', 'face', 'extracting', 'set', 'profile', 'parameters', 'corresponding', 'person', 'first', 'image', 'selecting', 'plurality', 'image', 'tiles', 'first', 'image', 'tile', 'matches', 'face', 'corresponding', 'person', 'first', 'image', 'accordance', 'predefined', 'correspondence', 'set', 'profile', 'parameters', 'corresponding', 'person', 'set', 'pre-stored', 'description', 'parameters', 'first', 'image', 'tile', 'generating', 'second', 'image', 'covering', 'faces', 'respective', 'persons', 'first', 'image', 'corresponding', 'first', 'image', 'tiles', 'sharing', 'first', 'image', 'second', 'image', 'predefined', 'order', 'via', 'group', 'chat', 'session', 'non-transitory', 'computer-readable', 'storage', 'medium', 'claim', 'wherein', 'first', 'image', 'second', 'image', 'displayed', 'group', 'chat', 'session', 'one', 'image', 'time', 'one', 'two', 'images', 'replaced', 'two', 'images', 'periodically', 'non-transitory', 'computer-readable', 'storage', 'medium', 'claim', 'wherein', 'extracting', 'set', 'profile', 'parameters', 'corresponding', 'person', 'first', 'image', 'includes', 'determining', 'one', 'descriptive', 'labels', 'corresponding', 'identified', 'face', 'corresponding', 'person', 'using', 'first', 'machine', 'learning', 'model', 'wherein', 'first', 'machine', 'learning', 'model', 'trained', 'facial', 'images', 'corresponding', 'descriptive', 'labels', 'non-transitory', 'computer-readable', 'storage', 'medium', 'claim', 'wherein', 'extracting', 'set', 'profile', 'parameters', 'corresponding', 'person', 'first', 'image', 'includes', 'determining', 'identity', 'corresponding', 'person', 'based', 'identified', 'face', 'corresponding', 'person', 'locating', 'respective', 'profile', 'information', 'first', 'person', 'based', 'determined', 'identity', 'corresponding', 'person', 'using', 'one', 'characteristics', 'respective', 'profile', 'information', 'first', 'person', 'set', 'profile', 'parameters', 'corresponding', 'identified', 'face', 'corresponding', 'person', 'non-transitory', 'computer-readable', 'storage', 'medium', 'claim', 'wherein', 'least', 'first', 'one', 'first', 'image', 'tiles', 'dynamic', 'image', 'tile', 'least', 'second', 'one', 'first', 'image', 'tiles', 'static', 'image', 'tile', 'non-transitory', 'computer-readable', 'storage', 'medium', 'claim', 'wherein', 'plurality', 'operations', 'include', 'receiving', 'plurality', 'user', 'comments', 'different', 'users', 'group', 'chat', 'session', 'user', 'comment', 'including', 'descriptive', 'term', 'respective', 'person', 'identified', 'first', 'image', 'choosing', 'descriptive', 'label', 'respective', 'person', 'according', 'plurality', 'user', 'comments', 'updating', 'second', 'image', 'adding', 'descriptive', 'label', 'adjacent', 'first', 'image', 'tile', 'respective', 'person', 'method', 'comprising', 'computing', 'system', 'determining', 'performance', 'metric', 'eye', 'tracking', 'system', 'first', 'performance', 'threshold', 'wherein', 'eye', 'tracking', 'system', 'associated', 'head-mounted', 'display', 'worn', 'user', 'based', 'determination', 'performance', 'metric', 'eye', 'tracking', 'system', 'first', 'performance', 'threshold', 'computer', 'system', 'performing', 'receiving', 'one', 'first', 'inputs', 'associated', 'body', 'user', 'estimating', 'region', 'user', 'looking', 'within', 'field', 'view', 'head-mounted', 'display', 'based', 'received', 'one', 'first', 'inputs', 'associated', 'body', 'user', 'determining', 'vergence', 'distance', 'user', 'based', 'least', 'one', 'first', 'inputs', 'associated', 'body', 'user', 'estimated', 'region', 'user', 'looking', 'locations', 'one', 'objects', 'scene', 'displayed', 'head-mounted', 'display', 'adjusting', 'one', 'configurations', 'head-mounted', 'display', 'based', 'determined', 'vergence', 'distance', 'user', 'method', 'claim', 'wherein', 'one', 'configurations', 'head-mounted', 'display', 'comprise', 'one', 'rendering', 'image', 'position', 'display', 'screen', 'position', 'optics', 'block', 'method', 'claim', 'comprising', 'determining', 'performance', 'metric', 'eye', 'tracking', 'system', 'second', 'performance', 'threshold', 'receiving', 'eye', 'tracking', 'data', 'eye', 'tracking', 'system', 'determining', 'vergence', 'distance', 'user', 'based', 'eye', 'tracking', 'data', 'one', 'first', 'inputs', 'associated', 'body', 'user', 'method', 'claim', 'comprising', 'receiving', 'one', 'second', 'inputs', 'associated', 'one', 'displaying', 'elements', 'scene', 'displayed', 'head-mounted', 'display', 'determining', 'vergence', 'distance', 'user', 'based', 'least', 'eye', 'tracking', 'data', 'one', 'first', 'inputs', 'associated', 'body', 'user', 'one', 'second', 'inputs', 'associated', 'one', 'displaying', 'elements', 'scene', 'method', 'claim', 'comprising', 'feeding', 'one', 'first', 'inputs', 'associated', 'body', 'user', 'fusion', 'algorithm', 'wherein', 'fusion', 'algorithm', 'assigns', 'weight', 'score', 'input', 'one', 'first', 'inputs', 'determining', 'vergence', 'distance', 'user', 'using', 'fusion', 'algorithm', 'based', 'one', 'first', 'inputs', 'associated', 'body', 'user', 'determining', 'z-depth', 'display', 'screen', 'confidence', 'score', 'based', 'one', 'first', 'inputs', 'associated', 'body', 'user', 'method', 'claim', 'comprising', 'comparing', 'confidence', 'score', 'confidence', 'level', 'threshold', 'response', 'determination', 'confidence', 'score', 'confidence', 'level', 'threshold', 'feeding', 'one', 'second', 'inputs', 'associated', 'one', 'displaying', 'elements', 'scene', 'fusion', 'algorithm', 'determining', 'z-depth', 'display', 'screen', 'using', 'fusion', 'algorithm', 'based', 'one', 'first', 'inputs', 'associated', 'body', 'user', 'one', 'second', 'inputs', 'associated', 'one', 'displaying', 'elements', 'scene', 'method', 'claim', 'comparing', 'comparing', 'fusion', 'algorithm', 'confidence', 'scores', 'associated', 'plurality', 'combinations', 'inputs', 'determining', 'fusion', 'algorithm', 'z-depth', 'display', 'screen', 'based', 'combination', 'inputs', 'associated', 'highest', 'confidence', 'score', 'method', 'claim', 'wherein', 'z-depth', 'confidence', 'score', 'determined', 'fusion', 'algorithm', 'using', 'piecewise', 'comparison', 'one', 'first', 'inputs', 'one', 'second', 'inputs', 'method', 'claim', 'wherein', 'z-depth', 'confidence', 'score', 'determined', 'based', 'correlation', 'two', 'inputs', 'one', 'first', 'inputs', 'one', 'second', 'inputs', 'method', 'claim', 'wherein', 'fusion', 'algorithm', 'comprises', 'machine', 'learning', 'ml', 'algorithm', 'wherein', 'machine', 'learning', 'ml', 'algorithm', 'determines', 'combination', 'first', 'inputs', 'fed', 'fusion', 'algorithm', 'method', 'claim', 'wherein', 'one', 'first', 'inputs', 'associated', 'body', 'user', 'comprise', 'one', 'hand', 'position', 'hand', 'direction', 'hand', 'movement', 'hand', 'gesture', 'head', 'position', 'head', 'direction', 'head', 'movement', 'head', 'gesture', 'gaze', 'angle', 'rea', 'body', 'gesture', 'body', 'posture', 'body', 'movement', 'behavior', 'user', 'weighted', 'combination', 'one', 'related', 'parameters', 'method', 'claim', 'wherein', 'one', 'first', 'inputs', 'associated', 'body', 'user', 'received', 'one', 'controller', 'sensor', 'camera', 'microphone', 'accelerometer', 'headset', 'worn', 'user', 'mobile', 'device', 'method', 'claim', 'wherein', 'one', 'second', 'inputs', 'associated', 'one', 'displaying', 'elements', 'comprise', 'one', 'z-buffer', 'value', 'associated', 'displaying', 'element', 'displaying', 'element', 'marked', 'developer', 'image', 'analysis', 'result', 'shape', 'displaying', 'element', 'face', 'recognition', 'result', 'object', 'recognition', 'result', 'person', 'identified', 'displaying', 'content', 'object', 'identified', 'displaying', 'content', 'correlation', 'two', 'displaying', 'elements', 'weighted', 'combination', 'one', 'second', 'inputs', 'method', 'claim', 'comprising', 'determining', 'performance', 'metric', 'eye', 'tracking', 'system', 'second', 'performance', 'threshold', 'receiving', 'one', 'second', 'inputs', 'associated', 'one', 'displaying', 'elements', 'scene', 'displayed', 'head-mounted', 'display', 'determining', 'vergence', 'distance', 'user', 'based', 'least', 'one', 'first', 'inputs', 'associated', 'body', 'user', 'one', 'second', 'inputs', 'associated', 'one', 'displaying', 'elements', 'method', 'claim', 'wherein', 'determining', 'performance', 'metric', 'eye', 'tracking', 'system', 'second', 'performance', 'threshold', 'comprises', 'determining', 'eye', 'tracking', 'system', 'exist', 'fails', 'provide', 'eye', 'tracking', 'data', 'method', 'claim', 'wherein', 'performance', 'metric', 'eye', 'tracking', 'system', 'comprises', 'one', 'accuracy', 'parameter', 'eye', 'tracking', 'system', 'precision', 'parameter', 'eye', 'tracking', 'system', 'value', 'parameter', 'eye', 'tracking', 'system', 'detectability', 'pupil', 'metric', 'based', 'one', 'parameters', 'associated', 'user', 'parameter', 'change', 'parameter', 'changing', 'trend', 'data', 'availability', 'weighted', 'combination', 'one', 'performance', 'related', 'parameters', 'method', 'claim', 'wherein', 'one', 'parameters', 'associated', 'user', 'comprise', 'one', 'eye', 'distance', 'user', 'pupil', 'position', 'pupil', 'status', 'correlation', 'two', 'pupils', 'user', 'head', 'size', 'user', 'position', 'headset', 'worn', 'user', 'angle', 'headset', 'worn', 'user', 'direction', 'headset', 'worn', 'user', 'alignment', 'eyes', 'user', 'weighted', 'combination', 'one', 'related', 'parameters', 'associated', 'user', 'method', 'claim', 'wherein', 'first', 'performance', 'threshold', 'comprises', 'one', 'pre-determined', 'value', 'pre-determined', 'range', 'state', 'data', 'changing', 'speed', 'data', 'trend', 'data', 'change', 'one', 'non-transitory', 'computer-readable', 'storage', 'media', 'embodying', 'software', 'operable', 'executed', 'computing', 'system', 'determine', 'performance', 'metric', 'eye', 'tracking', 'system', 'first', 'performance', 'threshold', 'wherein', 'eye', 'tracking', 'system', 'associated', 'head-mounted', 'display', 'worn', 'user', 'based', 'determination', 'performance', 'metric', 'eye', 'tracking', 'system', 'first', 'performance', 'threshold', 'media', 'embodying', 'software', 'operable', 'executed', 'computing', 'system', 'receive', 'one', 'first', 'inputs', 'associated', 'body', 'user', 'estimate', 'region', 'user', 'looking', 'within', 'field', 'view', 'head-mounted', 'display', 'based', 'received', 'one', 'first', 'inputs', 'associated', 'body', 'user', 'determine', 'vergence', 'distance', 'user', 'based', 'least', 'one', 'first', 'inputs', 'associated', 'body', 'user', 'estimated', 'region', 'user', 'looking', 'locations', 'one', 'objects', 'scene', 'displayed', 'head-mounted', 'display', 'adjust', 'one', 'configurations', 'head-mounted', 'display', 'based', 'determined', 'vergence', 'distance', 'user', 'system', 'comprising', 'one', 'non-transitory', 'computer-readable', 'storage', 'media', 'embodying', 'instructions', 'one', 'processors', 'coupled', 'storage', 'media', 'operable', 'execute', 'instructions', 'determine', 'performance', 'metric', 'eye', 'tracking', 'system', 'first', 'performance', 'threshold', 'wherein', 'eye', 'tracking', 'system', 'associated', 'head-mounted', 'display', 'worn', 'user', 'based', 'determination', 'performance', 'metric', 'eye', 'tracking', 'system', 'first', 'performance', 'threshold', 'system', 'configured', 'receive', 'one', 'first', 'inputs', 'associated', 'body', 'user', 'estimate', 'region', 'user', 'looking', 'within', 'field', 'view', 'head-mounted', 'display', 'based', 'received', 'one', 'first', 'inputs', 'associated', 'body', 'user', 'determine', 'vergence', 'distance', 'user', 'based', 'least', 'one', 'first', 'inputs', 'associated', 'body', 'user', 'estimated', 'region', 'user', 'looking', 'locations', 'one', 'objects', 'scene', 'displayed', 'head-mounted', 'display', 'adjust', 'one', 'configurations', 'head-mounted', 'display', 'based', 'determined', 'vergence', 'distance', 'user', 'computer-implemented', 'method', 'image-based', 'self-guided', 'object', 'detection', 'comprising', 'receiving', 'processor', 'device', 'set', 'images', 'images', 'respective', 'grid', 'thereon', 'labeled', 'regarding', 'respective', 'object', 'detected', 'using', 'grid', 'level', 'label', 'data', 'training', 'processor', 'device', 'grid-based', 'object', 'detector', 'using', 'grid', 'level', 'label', 'data', 'determining', 'processor', 'device', 'respective', 'bounding', 'box', 'respective', 'object', 'images', 'applying', 'local', 'segmentation', 'images', 'training', 'processor', 'device', 'region-based', 'convolutional', 'neural', 'network', 'rcnn', 'joint', 'object', 'localization', 'object', 'classification', 'using', 'respective', 'bounding', 'box', 'respective', 'object', 'images', 'input', 'rcnn', 'computer-implemented', 'method', 'claim', 'comprising', 'performing', 'action', 'responsive', 'object', 'localization', 'object', 'classification', 'respective', 'new', 'object', 'new', 'image', 'rcnn', 'applied', 'computer-implemented', 'method', 'claim', 'wherein', 'action', 'comprises', 'autonomously', 'controlling', 'motor', 'vehicle', 'avoid', 'collision', 'new', 'object', 'responsive', 'object', 'localization', 'object', 'classification', 'respective', 'new', 'object', 'computer-implemented', 'method', 'claim', 'wherein', 'local', 'segmentation', 'performed', 'using', 'self-similarity', 'search', 'template', 'matching', 'provide', 'respective', 'bounding', 'box', 'around', 'respective', 'object', 'set', 'images', 'computer-implemented', 'method', 'claim', 'wherein', 'local', 'segmentation', 'applied', 'images', 'segment', 'respective', 'target', 'region', 'therein', 'computer-implemented', 'method', 'claim', 'wherein', 'region-based', 'convolutional', 'neural', 'network', 'rcnn', 'forms', 'model', 'object', 'training', 'stage', 'detect', 'objects', 'new', 'images', 'inference', 'stage', 'computer-implemented', 'method', 'claim', 'wherein', 'method', 'performed', 'system', 'selected', 'group', 'consisting', 'surveillance', 'system', 'face', 'detection', 'system', 'face', 'recognition', 'system', 'cancer', 'detection', 'system', 'object', 'tracking', 'system', 'advanced', 'driver-assistance', 'system', 'computer', 'program', 'product', 'image-based', 'self-guided', 'object', 'detection', 'computer', 'program', 'product', 'comprising', 'non-transitory', 'computer', 'readable', 'storage', 'medium', 'program', 'instructions', 'embodied', 'therewith', 'program', 'instructions', 'executable', 'computer', 'cause', 'computer', 'perform', 'method', 'comprising', 'receiving', 'processor', 'device', 'set', 'images', 'images', 'respective', 'grid', 'thereon', 'labeled', 'regarding', 'respective', 'object', 'detected', 'using', 'grid', 'level', 'label', 'data', 'training', 'processor', 'device', 'grid-based', 'object', 'detector', 'using', 'grid', 'level', 'label', 'data', 'determining', 'processor', 'device', 'respective', 'bounding', 'box', 'respective', 'object', 'images', 'applying', 'local', 'segmentation', 'images', 'training', 'processor', 'device', 'region-based', 'convolutional', 'neural', 'network', 'rcnn', 'joint', 'object', 'localization', 'object', 'classification', 'using', 'respective', 'bounding', 'box', 'respective', 'object', 'images', 'input', 'rcnn', 'computer', 'program', 'product', 'claim', 'wherein', 'method', 'comprises', 'performing', 'action', 'responsive', 'object', 'localization', 'object', 'classification', 'respective', 'new', 'object', 'new', 'image', 'rcnn', 'applied', 'computer', 'program', 'product', 'claim', 'wherein', 'action', 'comprises', 'autonomously', 'controlling', 'motor', 'vehicle', 'avoid', 'collision', 'new', 'object', 'responsive', 'object', 'localization', 'object', 'classification', 'respective', 'new', 'object', 'computer', 'program', 'product', 'claim', 'wherein', 'local', 'segmentation', 'performed', 'using', 'self-similarity', 'search', 'template', 'matching', 'provide', 'respective', 'bounding', 'box', 'around', 'respective', 'object', 'set', 'images', 'computer', 'program', 'product', 'claim', 'wherein', 'local', 'segmentation', 'applied', 'images', 'segment', 'respective', 'target', 'region', 'therein', 'computer', 'program', 'product', 'claim', 'wherein', 'region-based', 'convolutional', 'neural', 'network', 'rcnn', 'forms', 'model', 'object', 'training', 'stage', 'detect', 'objects', 'new', 'images', 'inference', 'stage', 'computer', 'program', 'product', 'claim', 'wherein', 'method', 'performed', 'system', 'selected', 'group', 'consisting', 'surveillance', 'system', 'face', 'detection', 'system', 'face', 'recognition', 'system', 'cancer', 'detection', 'system', 'object', 'tracking', 'system', 'advanced', 'driver-assistance', 'system', 'computer', 'processing', 'system', 'image-based', 'self-guided', 'object', 'detection', 'comprising', 'memory', 'device', 'storing', 'program', 'code', 'processor', 'device', 'running', 'program', 'code', 'receive', 'set', 'images', 'images', 'respective', 'grid', 'thereon', 'labeled', 'regarding', 'respective', 'object', 'detected', 'using', 'grid', 'level', 'label', 'data', 'train', 'grid-based', 'object', 'detector', 'using', 'grid', 'level', 'label', 'data', 'determine', 'respective', 'bounding', 'box', 'respective', 'object', 'images', 'applying', 'local', 'segmentation', 'images', 'train', 'region-based', 'convolutional', 'neural', 'network', 'rcnn', 'joint', 'object', 'localization', 'object', 'classification', 'using', 'respective', 'bounding', 'box', 'respective', 'object', 'images', 'input', 'rcnn', 'computer', 'processing', 'system', 'claim', 'wherein', 'processor', 'device', 'runs', 'program', 'code', 'perform', 'action', 'responsive', 'object', 'localization', 'object', 'classification', 'respective', 'new', 'object', 'new', 'image', 'rcnn', 'applied', 'computer', 'processing', 'system', 'claim', 'wherein', 'action', 'comprises', 'autonomously', 'controlling', 'motor', 'vehicle', 'avoid', 'collision', 'new', 'object', 'responsive', 'object', 'localization', 'object', 'classification', 'respective', 'new', 'object', 'computer', 'processing', 'system', 'claim', 'wherein', 'local', 'segmentation', 'performed', 'using', 'self-similarity', 'search', 'template', 'matching', 'provide', 'respective', 'bounding', 'box', 'around', 'respective', 'object', 'set', 'images', 'computer', 'processing', 'system', 'claim', 'wherein', 'region-based', 'convolutional', 'neural', 'network', 'rcnn', 'forms', 'model', 'object', 'training', 'stage', 'detect', 'objects', 'new', 'images', 'inference', 'stage', 'computer', 'processing', 'system', 'claim', 'wherein', 'computer', 'processing', 'system', 'comprised', 'system', 'selected', 'group', 'consisting', 'surveillance', 'system', 'face', 'detection', 'system', 'face', 'recognition', 'system', 'cancer', 'detection', 'system', 'object', 'tracking', 'system', 'advanced', 'driver-assistance', 'system', 'method', 'scalable', 'parallel', 'cloud-based', 'face', 'recognition', 'utilizing', 'database', 'normalized', 'stored', 'images', 'comprising', 'capturing', 'image', 'using', 'camera', 'detecting', 'face', 'captured', 'image', 'normalizing', 'detected', 'facial', 'image', 'match', 'normalized', 'stored', 'images', 'identifying', 'facial', 'features', 'normalized', 'detected', 'facial', 'image', 'generating', 'plurality', 'facial', 'metrics', 'facial', 'features', 'calculating', 'euclidean', 'distances', 'facial', 'metrics', 'normalized', 'detected', 'facial', 'image', 'corresponding', 'facial', 'metrics', 'stored', 'images', 'comparing', 'euclidean', 'distance', 'predetermined', 'threshold', 'responsive', 'euclidean', 'distance', 'comparison', 'producing', 'reduced', 'candidate', 'list', 'best', 'possible', 'image', 'matches', 'normalized', 'stored', 'images', 'comparing', 'parallel', 'normalized', 'detected', 'facial', 'image', 'normalized', 'stored', 'images', 'reduced', 'candidate', 'list', 'utilizing', 'plurality', 'face', 'recognition', 'algorithms', 'processor', 'parallel', 'processing', 'system', 'uses', 'different', 'face', 'recognition', 'algorithm', 'responsive', 'comparison', 'producing', 'best', 'match', 'results', 'parallel', 'subset', 'reduced', 'candidate', 'list', 'selecting', 'final', 'match', 'best', 'match', 'results', 'using', 'deep', 'learning', 'neural', 'network', 'face', 'recognition', 'algorithm', 'trained', 'outputs', 'individual', 'face', 'recognition', 'algorithms', 'method', 'scalable', 'parallel', 'cloud-based', 'face', 'recognition', 'claim', 'wherein', 'detecting', 'face', 'captured', 'image', 'comprises', 'utilizing', 'opencv', 'detect', 'face', 'captured', 'image', 'extracting', 'location', 'eyes', 'tip', 'nose', 'face', 'determining', 'distance', 'eyes', 'cropping', 'face', 'captured', 'image', 'width', 'height', 'cropped', 'face', 'image', 'function', 'distance', 'eyes', 'rotating', 'face', 'angle', 'rotation', 'function', 'distance', 'eyes', 'method', 'scalable', 'parallel', 'cloud-based', 'face', 'recognition', 'claim', 'wherein', 'width', 'cropped', 'face', 'image', 'times', 'distance', 'eyes', 'height', 'cropped', 'face', 'image', 'times', 'distance', 'eyes', 'angle', 'rotation', 'angle', 'formed', 'straight', 'line', 'joining', 'eyes', 'x-axis', 'face', 'method', 'scalable', 'parallel', 'cloud-based', 'face', 'recognition', 'claim', 'wherein', 'rotating', 'face', 'comprises', 'rotating', 'face', 'provide', 'frontal', 'face', 'pattern', 'method', 'scalable', 'parallel', 'cloud-based', 'face', 'recognition', 'claim', 'comprising', 'step', 'proportionally', 'rescaling', 'cropped', 'rotated', 'image', 'method', 'scalable', 'parallel', 'cloud-based', 'face', 'recognition', 'claim', 'proportional', 'rescaling', 'yields', 'cropped', 'rotated', 'image', 'size', '=', 'pixels', 'method', 'scalable', 'parallel', 'cloud-based', 'face', 'recognition', 'claim', 'wherein', 'facial', 'features', 'identified', 'normalized', 'detected', 'facial', 'image', 'comprise', 'pair', 'eyes', 'tip', 'nose', 'mouth', 'center', 'mouth', 'chin', 'area', 'comprising', 'bottom', 'top', 'left', 'landmark', 'top', 'right', 'landmark', 'method', 'scalable', 'parallel', 'cloud-based', 'face', 'recognition', 'claim', 'wherein', 'generating', 'plurality', 'facial', 'metrics', 'comprises', 'calculating', 'distance', 'pair', 'eyes', 'distance', 'eyes', 'tip', 'nose', 'distance', 'equal', 'width', 'mouth', 'distance', 'tip', 'nose', 'center', 'mouth', 'distance', 'bottom', 'chin', 'center', 'mouth', 'distance', 'top', 'left', 'landmark', 'chin', 'tip', 'nose', 'distance', 'top', 'right', 'landmark', 'chin', 'tip', 'nose', 'method', 'scalable', 'parallel', 'cloud-based', 'face', 'recognition', 'claim', 'wherein', 'performing', 'euclidean', 'distance', 'match', 'comprises', 'partitioning', 'normalized', 'stored', 'images', 'plurality', 'substantially', 'equal', 'subsets', 'performing', 'euclidean', 'distance', 'match', 'facial', 'metrics', 'normalized', 'detected', 'facial', 'image', 'corresponding', 'facial', 'metrics', 'stored', 'images', 'subsets', 'normalized', 'stored', 'images', 'separate', 'processor', 'parallel', 'processing', 'system', 'generate', 'euclidean', 'distance', 'stored', 'image', 'subset', 'comparing', 'euclidean', 'distance', 'predetermined', 'threshold', 'separate', 'processors', 'responsive', 'euclidean', 'distance', 'comparison', 'producing', 'reduced', 'candidate', 'list', 'best', 'possible', 'image', 'matches', 'normalized', 'stored', 'images', 'subset', 'combining', 'reduced', 'candidate', 'lists', 'subset', 'produce', 'single', 'reduced', 'candidate', 'list', 'method', 'scalable', 'parallel', 'cloud-based', 'face', 'recognition', 'claim', 'wherein', 'plurality', 'face', 'recognition', 'algorithms', 'utilized', 'comparing', 'parallel', 'normalized', 'detected', 'facial', 'image', 'normalized', 'stored', 'images', 'reduced', 'candidate', 'list', 'consists', 'face', 'recognition', 'algorithms', 'selected', 'group', 'consisting', 'principle', 'component', 'analysis', 'pca-based', 'algorithms', 'linear', 'discriminant', 'analysis', 'lda', 'algorithms', 'independent', 'component', 'analysis', 'ica', 'algorithms', 'kernel-based', 'algorithms', 'feature-based', 'techniques', 'algorithms', 'based', 'neural', 'networks', 'algorithms', 'based', 'transforms', 'model-based', 'face', 'recognition', 'algorithms', 'method', 'scalable', 'parallel', 'cloud-based', 'face', 'recognition', 'claim', 'wherein', 'pca-based', 'algorithms', 'include', 'eigenfaces', 'face', 'detectionrecognition', 'lda', 'algorithms', 'include', 'fisherfaces', 'method', 'face', 'recognition', 'method', 'scalable', 'parallel', 'cloud-based', 'face', 'recognition', 'claim', 'wherein', 'comparing', 'parallel', 'captured', 'image', 'normalized', 'stored', 'images', 'reduced', 'candidate', 'list', 'comprises', 'partitioning', 'reduced', 'candidate', 'list', 'plurality', 'substantially', 'equal', 'subsets', 'processing', 'subset', 'different', 'processor', 'parallel', 'processing', 'system', 'uses', 'unique', 'face', 'recognition', 'algorithm', 'produce', 'best', 'match', 'results', 'using', 'reduce', 'function', 'mapreduce', 'program', 'combine', 'best', 'match', 'results', 'subsets', 'produce', 'single', 'set', 'best', 'match', 'results', 'method', 'scalable', 'parallel', 'cloud-based', 'face', 'recognition', 'claim', 'wherein', 'partitioning', 'reduced', 'candidate', 'list', 'comprises', 'selecting', 'images', 'comprising', 'subset', 'optimizing', 'variance', 'images', 'according', 'following', 'equation', 'n', 'number', 'rows', 'columns', 'face', 'vector', 'image', 'n', 'number', 'groups', 'σij', 'standard', 'deviation', 'image', 'dimension', 'group', 'j', 'face', 'image', 'vector', 'method', 'scalable', 'parallel', 'cloud-based', 'face', 'recognition', 'claim', 'wherein', 'selecting', 'images', 'comprising', 'subset', 'optimizing', 'variance', 'images', 'according', 'following', 'equation', 'dμi', 'μj', 'euclidean', 'distance', 'mean', 'group', 'mean', 'group', 'j', 'face', 'image', 'vector', 'l', 'number', 'group', 'levels', 'method', 'scalable', 'parallel', 'cloud-based', 'face', 'recognition', 'claim', 'selecting', 'final', 'match', 'best', 'match', 'results', 'utilizing', 'deep', 'learning', 'neural', 'network', 'face', 'recognition', 'algorithm', 'comprises', 'utilizing', 'either', 'adaboost', 'machine-learning', 'algorithm', 'neural', 'networks', 'machine-learning', 'model', 'method', 'scalable', 'parallel', 'cloud-based', 'face', 'recognition', 'claim', 'normalizing', 'detected', 'facial', 'image', 'match', 'normalized', 'stored', 'images', 'includes', 'normalizing', 'detected', 'facial', 'image', 'size', 'orientation', 'illumination', 'normalized', 'stored', 'images', 'non-transitory', 'computer-readable', 'medium', 'containing', 'executable', 'program', 'instructions', 'causing', 'computer', 'perform', 'method', 'face', 'recognition', 'method', 'comprising', 'detecting', 'face', 'image', 'captured', 'camera', 'normalizing', 'detected', 'facial', 'image', 'match', 'normalized', 'stored', 'images', 'identifying', 'facial', 'features', 'normalized', 'detected', 'facial', 'image', 'generating', 'plurality', 'facial', 'metrics', 'facial', 'features', 'calculating', 'euclidean', 'distances', 'facial', 'metrics', 'normalized', 'detected', 'facial', 'image', 'corresponding', 'facial', 'metrics', 'stored', 'images', 'comparing', 'euclidean', 'distance', 'predetermined', 'threshold', 'responsive', 'euclidean', 'distance', 'comparison', 'producing', 'reduced', 'candidate', 'list', 'best', 'possible', 'image', 'matches', 'normalized', 'stored', 'images', 'comparing', 'parallel', 'captured', 'image', 'normalized', 'stored', 'images', 'reduced', 'candidate', 'list', 'utilizing', 'plurality', 'face', 'recognition', 'algorithms', 'processor', 'parallel', 'processing', 'system', 'uses', 'different', 'face', 'recognition', 'algorithm', 'responsive', 'comparison', 'producing', 'best', 'match', 'results', 'parallel', 'subset', 'reduced', 'candidate', 'list', 'selecting', 'final', 'match', 'best', 'match', 'results', 'using', 'deep', 'learning', 'neural', 'network', 'face', 'recognition', 'algorithm', 'trained', 'outputs', 'individual', 'face', 'recognition', 'algorithms', 'non-transitory', 'computer-readable', 'medium', 'containing', 'executable', 'program', 'instructions', 'claim', 'wherein', 'plurality', 'face', 'recognition', 'algorithms', 'utilized', 'comparing', 'parallel', 'normalized', 'detected', 'facial', 'image', 'normalized', 'stored', 'images', 'reduced', 'candidate', 'list', 'consists', 'face', 'recognition', 'algorithms', 'selected', 'group', 'consisting', 'principle', 'component', 'analysis', 'pca-based', 'algorithms', 'linear', 'discriminant', 'analysis', 'lda', 'algorithms', 'independent', 'component', 'analysis', 'ica', 'algorithms', 'kernel-based', 'algorithms', 'feature-based', 'techniques', 'algorithms', 'based', 'neural', 'networks', 'algorithms', 'based', 'transforms', 'model-based', 'face', 'recognition', 'algorithms', 'non-transitory', 'computer-readable', 'medium', 'containing', 'executable', 'program', 'instructions', 'claim', 'wherein', 'pca-based', 'algorithms', 'include', 'eigenfaces', 'face', 'detectionrecognition', 'lda', 'algorithms', 'include', 'fisherfaces', 'method', 'face', 'recognition', 'non-transitory', 'computer-readable', 'medium', 'containing', 'executable', 'program', 'instructions', 'claim', 'selecting', 'final', 'match', 'best', 'match', 'results', 'utilizing', 'deep', 'learning', 'neural', 'network', 'face', 'recognition', 'algorithm', 'comprises', 'utilizing', 'either', 'adaboost', 'machine-learning', 'algorithm', 'neural', 'networks', 'machine-learning', 'model', 'imaging', 'device', 'comprising', 'condensing', 'lens', 'image', 'sensor', 'configured', 'detect', 'light', 'passing', 'condensing', 'lens', 'comprising', 'pixel', 'matrix', 'wherein', 'pixel', 'matrix', 'comprises', 'plurality', 'phase', 'detection', 'pixel', 'pairs', 'plurality', 'regular', 'pixels', 'processor', 'configured', 'turn', 'phase', 'detection', 'pixel', 'pairs', 'autofocusing', 'output', 'autofocused', 'pixel', 'data', 'completing', 'autofocusing', 'divide', 'autofocused', 'pixel', 'data', 'first', 'subframe', 'second', 'subframe', 'calculate', 'image', 'features', 'least', 'one', 'first', 'subframe', 'second', 'subframe', 'wherein', 'image', 'features', 'comprise', 'module', 'widths', 'finder', 'pattern', 'finder', 'pattern', 'predetermined', 'ratio', 'harr-like', 'feature', 'gabor', 'feature', 'determine', 'operating', 'resolution', 'regular', 'pixels', 'according', 'image', 'features', 'calculated', 'least', 'one', 'first', 'subframe', 'second', 'subframe', 'divided', 'autofocused', 'pixel', 'data', 'imaging', 'device', 'claimed', 'claim', 'wherein', 'phase', 'detection', 'pixel', 'pairs', 'comprises', 'first', 'pixel', 'second', 'pixel', 'cover', 'layer', 'covering', 'upon', 'first', 'region', 'first', 'pixel', 'upon', 'second', 'region', 'second', 'pixel', 'wherein', 'first', 'region', 'second', 'region', 'mirror', 'symmetrical', 'microlens', 'aligned', 'least', 'one', 'first', 'pixel', 'second', 'pixel', 'imaging', 'device', 'claimed', 'claim', 'wherein', 'first', 'region', 'second', 'region', '%', '%', 'area', 'single', 'pixel', 'imaging', 'device', 'claimed', 'claim', 'wherein', 'processor', 'configured', 'perform', 'autofocusing', 'using', 'dual', 'pixel', 'autofocus', 'technique', 'according', 'pixel', 'data', 'phase', 'detection', 'pixel', 'pairs', 'completing', 'autofocusing', 'imaging', 'device', 'claimed', 'claim', 'wherein', 'processor', 'configured', 'divide', 'pixel', 'data', 'phase', 'detection', 'pixel', 'pairs', 'third', 'subframe', 'fourth', 'subframe', 'completing', 'autofocusing', 'perform', 'autofocusing', 'according', 'third', 'subframe', 'fourth', 'subframe', 'imaging', 'device', 'claimed', 'claim', 'wherein', 'processor', 'configured', 'calibrate', 'brightness', 'third', 'subframe', 'fourth', 'subframe', 'identical', 'using', 'shading', 'algorithm', 'imaging', 'device', 'claimed', 'claim', 'wherein', 'operating', 'resolution', 'selected', 'first', 'resolution', 'smaller', 'number', 'regular', 'pixels', 'second', 'resolution', 'larger', 'first', 'resolution', 'imaging', 'device', 'claimed', 'claim', 'wherein', 'regular', 'pixels', 'turned', 'autofocusing', 'imaging', 'device', 'claimed', 'claim', 'wherein', 'number', 'phase', 'detection', 'pixel', 'pairs', 'smaller', 'regular', 'pixels', 'imaging', 'device', 'comprising', 'condensing', 'lens', 'image', 'sensor', 'configured', 'detect', 'light', 'passing', 'condensing', 'lens', 'comprising', 'pixel', 'matrix', 'wherein', 'pixel', 'matrix', 'comprises', 'plurality', 'phase', 'detection', 'pixel', 'pairs', 'plurality', 'regular', 'pixels', 'processor', 'configured', 'turn', 'phase', 'detection', 'pixel', 'pairs', 'autofocusing', 'output', 'autofocused', 'pixel', 'data', 'completing', 'autofocusing', 'divide', 'autofocused', 'pixel', 'data', 'first', 'subframe', 'second', 'subframe', 'calculate', 'image', 'features', 'least', 'one', 'first', 'subframe', 'second', 'subframe', 'wherein', 'image', 'features', 'comprise', 'module', 'widths', 'finder', 'pattern', 'finder', 'pattern', 'predetermined', 'ratio', 'harr-like', 'feature', 'gabor', 'feature', 'select', 'image', 'decoding', 'image', 'recognition', 'using', 'pixel', 'data', 'regular', 'pixels', 'according', 'image', 'features', 'calculated', 'least', 'one', 'first', 'subframe', 'second', 'subframe', 'divided', 'autofocused', 'pixel', 'data', 'imaging', 'device', 'claimed', 'claim', 'wherein', 'phase', 'detection', 'pixel', 'pairs', 'comprises', 'first', 'pixel', 'second', 'pixel', 'cover', 'layer', 'covering', 'upon', 'first', 'region', 'first', 'pixel', 'upon', 'second', 'region', 'second', 'pixel', 'wherein', 'first', 'region', 'second', 'region', 'mirror', 'symmetrical', 'microlens', 'aligned', 'least', 'one', 'first', 'pixel', 'second', 'pixel', 'imaging', 'device', 'claimed', 'claim', 'wherein', 'processor', 'configured', 'perform', 'autofocusing', 'using', 'dual', 'pixel', 'autofocus', 'technique', 'according', 'pixel', 'data', 'phase', 'detection', 'pixel', 'pairs', 'completing', 'autofocusing', 'imaging', 'device', 'claimed', 'claim', 'wherein', 'processor', 'configured', 'divide', 'pixel', 'data', 'phase', 'detection', 'pixel', 'pairs', 'third', 'subframe', 'fourth', 'subframe', 'completing', 'autofocusing', 'calibrate', 'brightness', 'third', 'subframe', 'fourth', 'subframe', 'identical', 'using', 'shading', 'algorithm', 'perform', 'autofocusing', 'according', 'third', 'subframe', 'fourth', 'subframe', 'imaging', 'device', 'claimed', 'claim', 'wherein', 'processor', 'configured', 'calculate', 'image', 'features', 'using', 'least', 'one', 'rule', 'based', 'algorithm', 'machine', 'learning', 'algorithm', 'imaging', 'device', 'claimed', 'claim', 'wherein', 'image', 'decoding', 'decoding', 'qr', 'codes', 'image', 'recognition', 'face', 'recognition', 'operating', 'method', 'imaging', 'device', 'imaging', 'device', 'comprising', 'plurality', 'phase', 'detection', 'pixel', 'pairs', 'plurality', 'regular', 'pixels', 'operating', 'method', 'comprising', 'turning', 'phase', 'detection', 'pixel', 'pairs', 'autofocusing', 'outputting', 'autofocused', 'image', 'frame', 'completing', 'autofocusing', 'dividing', 'autofocused', 'image', 'frame', 'acquired', 'phase', 'detection', 'pixel', 'pairs', 'first', 'subframe', 'second', 'subframe', 'calculating', 'image', 'features', 'least', 'one', 'first', 'subframe', 'second', 'subframe', 'wherein', 'image', 'feature', 'comprise', 'module', 'widths', 'finder', 'pattern', 'finder', 'pattern', 'predetermined', 'ratio', 'harr-like', 'feature', 'gabor', 'feature', 'selectively', 'activating', 'least', 'part', 'regular', 'pixels', 'according', 'image', 'features', 'calculated', 'least', 'one', 'first', 'subframe', 'second', 'subframe', 'divided', 'autofocused', 'image', 'frame', 'operating', 'method', 'claimed', 'claim', 'wherein', 'selectively', 'activating', 'comprises', 'activating', 'first', 'part', 'regular', 'pixels', 'perform', 'image', 'decoding', 'according', 'pixel', 'data', 'first', 'part', 'regular', 'pixels', 'activating', 'regular', 'pixels', 'perform', 'image', 'recognition', 'according', 'pixel', 'data', 'regular', 'pixels', 'operating', 'method', 'claimed', 'claim', 'wherein', 'pixel', 'data', 'phase', 'detection', 'pixel', 'pairs', 'captured', 'frame', 'pixel', 'data', 'regular', 'pixels', 'also', 'used', 'performing', 'image', 'decoding', 'image', 'recognition', 'operating', 'method', 'claimed', 'claim', 'wherein', 'image', 'decoding', 'decoding', 'qr', 'codes', 'image', 'recognition', 'face', 'recognition', 'operating', 'method', 'claimed', 'claim', 'wherein', 'phase', 'detection', 'pixel', 'pairs', 'partially', 'covered', 'pixels', 'structure', 'dual', 'pixel', 'apparatus', 'comprising', 'first', 'camera', 'module', 'configured', 'obtain', 'first', 'image', 'object', 'first', 'field', 'view', 'second', 'camera', 'module', 'configured', 'obtain', 'second', 'image', 'object', 'second', 'field', 'view', 'different', 'first', 'field', 'view', 'first', 'depth', 'map', 'generator', 'configured', 'generate', 'first', 'depth', 'map', 'first', 'image', 'based', 'first', 'image', 'second', 'image', 'second', 'depth', 'map', 'generator', 'configured', 'generate', 'second', 'depth', 'map', 'second', 'image', 'based', 'first', 'image', 'second', 'image', 'first', 'depth', 'map', 'apparatus', 'claim', 'wherein', 'first', 'field', 'view', 'narrow', 'angle', 'second', 'field', 'view', 'wider', 'angle', 'apparatus', 'claim', 'wherein', 'second', 'image', 'divided', 'primary', 'region', 'residual', 'region', 'second', 'depth', 'map', 'generator', 'comprises', 'relationship', 'estimating', 'module', 'configured', 'estimate', 'relationship', 'primary', 'region', 'residual', 'region', 'based', 'first', 'image', 'second', 'image', 'depth', 'map', 'estimating', 'module', 'configured', 'estimate', 'depth', 'map', 'residual', 'region', 'based', 'estimated', 'relationship', 'first', 'depth', 'map', 'apparatus', 'claim', 'wherein', 'least', 'one', 'relationship', 'estimating', 'module', 'depth', 'map', 'estimating', 'module', 'performs', 'estimating', 'operation', 'based', 'neural', 'network', 'module', 'apparatus', 'claim', 'comprising', 'depth', 'map', 'fusion', 'unit', 'configured', 'generate', 'third', 'depth', 'map', 'second', 'image', 'performing', 'fusion', 'operation', 'based', 'first', 'depth', 'map', 'second', 'depth', 'map', 'apparatus', 'claim', 'wherein', 'depth', 'map', 'fusion', 'unit', 'comprises', 'tone', 'mapping', 'module', 'configured', 'generate', 'tone-mapped', 'second', 'depth', 'map', 'correspond', 'first', 'depth', 'map', 'performing', 'bias', 'removing', 'operation', 'second', 'depth', 'map', 'fusion', 'module', 'configured', 'generate', 'third', 'depth', 'map', 'fusing', 'tone-mapped', 'second', 'depth', 'map', 'first', 'depth', 'map', 'apparatus', 'claim', 'wherein', 'depth', 'map', 'fusion', 'unit', 'comprises', 'propagating', 'module', 'configured', 'generate', 'propagated', 'first', 'depth', 'map', 'second', 'image', 'iterated', 'propagating', 'first', 'depth', 'map', 'based', 'first', 'depth', 'map', 'second', 'image', 'fusion', 'module', 'generates', 'third', 'depth', 'map', 'fusing', 'tone-mapped', 'second', 'depth', 'map', 'propagated', 'first', 'depth', 'map', 'apparatus', 'claim', 'wherein', 'depth', 'map', 'fusion', 'unit', 'comprises', 'post-processing', 'module', 'configured', 'perform', 'post-processing', 'operation', 'third', 'depth', 'map', 'generated', 'fusion', 'module', 'provide', 'post-processed', 'third', 'depth', 'map', 'apparatus', 'claim', 'wherein', 'post-processing', 'module', 'performs', 'post-processing', 'operation', 'filtering', 'interface', 'generated', 'third', 'depth', 'map', 'accordance', 'fusion', 'fusion', 'module', 'apparatus', 'claim', 'wherein', 'post-processing', 'module', 'removes', 'artifacts', 'generated', 'third', 'depth', 'map', 'accordance', 'fusion', 'fusion', 'module', 'apparatus', 'claim', 'wherein', 'first', 'depth', 'map', 'generator', 'analyses', 'distance', 'relationship', 'first', 'image', 'second', 'image', 'generates', 'first', 'depth', 'map', 'first', 'image', 'based', 'distance', 'relationship', 'method', 'processing', 'image', 'electronic', 'apparatus', 'method', 'comprising', 'obtaining', 'first', 'image', 'object', 'using', 'first', 'camera', 'module', 'obtaining', 'second', 'image', 'object', 'using', 'second', 'camera', 'module', 'generating', 'first', 'depth', 'map', 'first', 'image', 'based', 'first', 'image', 'second', 'image', 'estimating', 'relationship', 'primary', 'region', 'second', 'image', 'residual', 'region', 'second', 'image', 'based', 'first', 'image', 'second', 'image', 'generating', 'second', 'depth', 'map', 'second', 'image', 'based', 'estimated', 'relationship', 'primary', 'region', 'residual', 'region', 'first', 'depth', 'map', 'method', 'claim', 'wherein', 'electronic', 'apparatus', 'comprises', 'first', 'camera', 'module', 'including', 'first', 'lens', 'first', 'field', 'view', 'second', 'camera', 'module', 'including', 'second', 'lens', 'second', 'field', 'view', 'wider', 'first', 'field', 'view', 'method', 'claim', 'wherein', 'generating', 'second', 'depth', 'map', 'comprises', 'estimating', 'depth', 'map', 'residual', 'region', 'based', 'estimated', 'relationship', 'primary', 'region', 'residual', 'region', 'first', 'depth', 'map', 'generating', 'second', 'depth', 'map', 'based', 'depth', 'map', 'residual', 'region', 'first', 'depth', 'map', 'method', 'claim', 'wherein', 'estimating', 'relationship', 'primary', 'region', 'second', 'image', 'performed', 'using', 'neural', 'network', 'model', 'method', 'claim', 'comprising', 'performing', 'pre-processing', 'operation', 'second', 'depth', 'map', 'generating', 'third', 'depth', 'map', 'residual', 'image', 'fusing', 'second', 'depth', 'map', 'pre-processing', 'operation', 'performed', 'first', 'depth', 'map', 'method', 'claim', 'wherein', 'performing', 'pre-processing', 'operation', 'comprises', 'performing', 'tone', 'mapping', 'operation', 'depth', 'map', 'primary', 'region', 'depth', 'map', 'residual', 'region', 'based', 'second', 'depth', 'map', 'operating', 'method', 'electronic', 'apparatus', 'electronic', 'apparatus', 'including', 'first', 'camera', 'module', 'providing', 'first', 'image', 'object', 'using', 'first', 'field', 'view', 'second', 'camera', 'module', 'providing', 'second', 'image', 'object', 'using', 'second', 'field', 'view', 'wider', 'first', 'field', 'view', 'processor', 'generating', 'depth', 'map', 'second', 'image', 'based', 'primary', 'region', 'second', 'image', 'residual', 'region', 'second', 'image', 'operating', 'method', 'comprising', 'generating', 'first', 'depth', 'map', 'primary', 'region', 'estimating', 'relationship', 'first', 'image', 'second', 'image', 'estimating', 'relationship', 'primary', 'region', 'residual', 'region', 'based', 'first', 'image', 'second', 'image', 'generating', 'second', 'depth', 'map', 'second', 'image', 'estimating', 'depth', 'map', 'second', 'region', 'based', 'estimated', 'relationship', 'primary', 'region', 'residual', 'region', 'generating', 'depth', 'map', 'second', 'image', 'fusing', 'first', 'depth', 'map', 'second', 'depth', 'map', 'operation', 'method', 'claim', 'comprising', 'executing', 'application', 'applies', 'image', 'effect', 'second', 'image', 'based', 'depth', 'map', 'residual', 'image', 'operation', 'method', 'claim', 'wherein', 'application', 'applies', 'least', 'one', 'image', 'effect', 'auto-focusing', 'out-focusing', 'forebackground', 'separation', 'face', 'recognition', 'object', 'detection', 'within', 'frame', 'augmented', 'reality', 'second', 'image', 'based', 'depth', 'map', 'second', 'image', 'payment', 'method', 'based', 'face', 'recognition', 'comprising', 'acquiring', 'first', 'face', 'image', 'information', 'target', 'user', 'extracting', 'first', 'characteristic', 'information', 'first', 'face', 'image', 'information', 'wherein', 'first', 'characteristic', 'information', 'includes', 'head', 'posture', 'information', 'target', 'user', 'gaze', 'information', 'target', 'user', 'determining', 'whether', 'target', 'user', 'willingness', 'pay', 'according', 'head', 'posture', 'information', 'target', 'user', 'gaze', 'information', 'target', 'user', 'including', 'determining', 'whether', 'angle', 'rotation', 'preset', 'direction', 'less', 'angle', 'threshold', 'wherein', 'head', 'posture', 'information', 'includes', 'angle', 'rotation', 'preset', 'direction', 'determining', 'whether', 'probability', 'value', 'user', 'gazes', 'payment', 'screen', 'greater', 'probability', 'threshold', 'wherein', 'gaze', 'information', 'includes', 'probability', 'value', 'user', 'gazes', 'payment', 'screen', 'response', 'determining', 'angle', 'rotation', 'preset', 'direction', 'less', 'angle', 'threshold', 'probability', 'value', 'user', 'gazes', 'payment', 'screen', 'greater', 'probability', 'threshold', 'determining', 'target', 'user', 'willingness', 'pay', 'response', 'determining', 'target', 'user', 'willingness', 'pay', 'completing', 'payment', 'operation', 'based', 'face', 'recognition', 'method', 'claimed', 'claim', 'wherein', 'completing', 'payment', 'operation', 'based', 'face', 'recognition', 'comprises', 'triggering', 'performing', 'payment', 'initiating', 'operation', 'acquire', 'second', 'face', 'image', 'information', 'based', 'face', 'recognition', 'determining', 'whether', 'second', 'characteristic', 'information', 'extracted', 'second', 'face', 'image', 'information', 'indicates', 'user', 'willingness', 'pay', 'response', 'determining', 'second', 'characteristic', 'information', 'indicates', 'user', 'willingness', 'pay', 'triggering', 'performing', 'payment', 'confirmation', 'operation', 'complete', 'payment', 'operation', 'based', 'payment', 'account', 'information', 'corresponding', 'target', 'user', 'method', 'claimed', 'claim', 'wherein', 'determining', 'whether', 'second', 'characteristic', 'information', 'extracted', 'second', 'face', 'image', 'information', 'indicates', 'user', 'willingness', 'pay', 'comprises', 'determining', 'whether', 'current', 'user', 'corresponding', 'second', 'face', 'image', 'information', 'consistent', 'target', 'user', 'response', 'determining', 'current', 'user', 'consistent', 'target', 'user', 'determining', 'whether', 'target', 'user', 'willingness', 'pay', 'according', 'second', 'characteristic', 'information', 'extracted', 'second', 'face', 'image', 'information', 'method', 'claimed', 'claim', 'wherein', 'extracting', 'first', 'characteristic', 'information', 'first', 'face', 'image', 'information', 'comprises', 'determining', 'head', 'posture', 'information', 'target', 'user', 'using', 'head', 'posture', 'recognition', 'model', 'based', 'first', 'face', 'image', 'information', 'determining', 'gaze', 'information', 'target', 'user', 'using', 'gaze', 'information', 'recognition', 'model', 'based', 'characteristics', 'eye', 'region', 'first', 'face', 'image', 'information', 'method', 'claimed', 'claim', 'wherein', 'head', 'posture', 'recognition', 'model', 'obtained', 'training', 'acquiring', 'first', 'sample', 'data', 'set', 'wherein', 'first', 'sample', 'data', 'set', 'includes', 'plurality', 'pieces', 'first', 'sample', 'data', 'plurality', 'pieces', 'first', 'sample', 'data', 'includes', 'correspondence', 'sample', 'face', 'image', 'head', 'posture', 'information', 'determining', 'mean', 'image', 'data', 'variance', 'image', 'data', 'plurality', 'sample', 'face', 'images', 'plurality', 'pieces', 'first', 'sample', 'data', 'preprocessing', 'sample', 'face', 'image', 'contained', 'plurality', 'pieces', 'first', 'sample', 'data', 'based', 'mean', 'image', 'data', 'variance', 'image', 'data', 'obtain', 'preprocessed', 'sample', 'face', 'image', 'setting', 'preprocessed', 'sample', 'face', 'image', 'corresponding', 'head', 'posture', 'information', 'first', 'model', 'training', 'sample', 'performing', 'training', 'using', 'machine', 'learning', 'method', 'based', 'plurality', 'first', 'model', 'training', 'samples', 'obtain', 'head', 'posture', 'recognition', 'model', 'method', 'claimed', 'claim', 'wherein', 'gaze', 'information', 'recognition', 'model', 'obtained', 'training', 'acquiring', 'second', 'sample', 'data', 'set', 'wherein', 'second', 'sample', 'data', 'set', 'includes', 'plurality', 'pieces', 'second', 'sample', 'data', 'plurality', 'pieces', 'second', 'sample', 'data', 'includes', 'correspondence', 'sample', 'eye', 'image', 'gaze', 'information', 'determining', 'mean', 'image', 'data', 'variance', 'image', 'data', 'plurality', 'sample', 'eye', 'images', 'plurality', 'pieces', 'second', 'sample', 'data', 'preprocessing', 'sample', 'eye', 'image', 'contained', 'plurality', 'pieces', 'second', 'sample', 'data', 'based', 'mean', 'image', 'data', 'variance', 'image', 'data', 'obtain', 'preprocessed', 'sample', 'eye', 'image', 'setting', 'preprocessed', 'sample', 'eye', 'image', 'corresponding', 'gaze', 'information', 'second', 'model', 'training', 'sample', 'performing', 'training', 'using', 'machine', 'learning', 'method', 'based', 'plurality', 'second', 'model', 'training', 'samples', 'obtain', 'gaze', 'information', 'recognition', 'model', 'method', 'claimed', 'claim', 'wherein', 'angle', 'rotation', 'preset', 'direction', 'comprises', 'pitch', 'angle', 'yaw', 'angle', 'roll', 'angle', 'wherein', 'pitch', 'angle', 'refers', 'angle', 'rotation', 'around', 'x-axis', 'yaw', 'angle', 'refers', 'angle', 'rotation', 'around', 'y-axis', 'roll', 'angle', 'refers', 'angle', 'rotation', 'around', 'z-axis', 'payment', 'device', 'based', 'face', 'recognition', 'comprising', 'processor', 'non-transitory', 'computer-readable', 'storage', 'medium', 'storing', 'instructions', 'executable', 'processor', 'cause', 'device', 'perform', 'operations', 'comprising', 'acquiring', 'first', 'face', 'image', 'information', 'target', 'user', 'extracting', 'first', 'characteristic', 'information', 'first', 'face', 'image', 'information', 'wherein', 'first', 'characteristic', 'information', 'includes', 'head', 'posture', 'information', 'target', 'user', 'gaze', 'information', 'target', 'user', 'determining', 'whether', 'target', 'user', 'willingness', 'pay', 'according', 'head', 'posture', 'information', 'target', 'user', 'gaze', 'information', 'target', 'user', 'including', 'determining', 'whether', 'angle', 'rotation', 'preset', 'direction', 'less', 'angle', 'threshold', 'wherein', 'head', 'posture', 'information', 'includes', 'angle', 'rotation', 'preset', 'direction', 'determining', 'whether', 'probability', 'value', 'user', 'gazes', 'payment', 'screen', 'greater', 'probability', 'threshold', 'wherein', 'gaze', 'information', 'includes', 'probability', 'value', 'user', 'gazes', 'payment', 'screen', 'response', 'determining', 'angle', 'rotation', 'preset', 'direction', 'less', 'angle', 'threshold', 'probability', 'value', 'user', 'gazes', 'payment', 'screen', 'greater', 'probability', 'threshold', 'determining', 'target', 'user', 'willingness', 'pay', 'response', 'determining', 'target', 'user', 'willingness', 'pay', 'completing', 'payment', 'operation', 'based', 'face', 'recognition', 'device', 'claimed', 'claim', 'wherein', 'completing', 'payment', 'operation', 'based', 'face', 'recognition', 'comprises', 'triggering', 'performing', 'payment', 'initiating', 'operation', 'acquire', 'second', 'face', 'image', 'information', 'based', 'face', 'recognition', 'determining', 'whether', 'second', 'characteristic', 'information', 'extracted', 'second', 'face', 'image', 'information', 'indicates', 'user', 'willingness', 'pay', 'response', 'determining', 'second', 'characteristic', 'information', 'indicates', 'user', 'willingness', 'pay', 'triggering', 'performing', 'payment', 'confirmation', 'operation', 'complete', 'payment', 'operation', 'based', 'payment', 'account', 'information', 'corresponding', 'target', 'user', 'device', 'claimed', 'claim', 'wherein', 'determining', 'whether', 'second', 'characteristic', 'information', 'extracted', 'second', 'face', 'image', 'information', 'indicates', 'user', 'willingness', 'pay', 'comprises', 'determining', 'whether', 'current', 'user', 'corresponding', 'second', 'face', 'image', 'information', 'consistent', 'target', 'user', 'response', 'determining', 'current', 'user', 'consistent', 'target', 'user', 'determining', 'whether', 'target', 'user', 'willingness', 'pay', 'according', 'second', 'characteristic', 'information', 'extracted', 'second', 'face', 'image', 'information', 'device', 'claimed', 'claim', 'wherein', 'extracting', 'first', 'characteristic', 'information', 'first', 'face', 'image', 'information', 'comprises', 'determining', 'head', 'posture', 'information', 'target', 'user', 'using', 'head', 'posture', 'recognition', 'model', 'based', 'first', 'face', 'image', 'information', 'determining', 'gaze', 'information', 'target', 'user', 'using', 'gaze', 'information', 'recognition', 'model', 'based', 'characteristics', 'eye', 'region', 'first', 'face', 'image', 'information', 'device', 'claimed', 'claim', 'wherein', 'head', 'posture', 'recognition', 'model', 'obtained', 'training', 'acquiring', 'first', 'sample', 'data', 'set', 'wherein', 'first', 'sample', 'data', 'set', 'includes', 'plurality', 'pieces', 'first', 'sample', 'data', 'plurality', 'pieces', 'first', 'sample', 'data', 'includes', 'correspondence', 'sample', 'face', 'image', 'head', 'posture', 'information', 'determining', 'mean', 'image', 'data', 'variance', 'image', 'data', 'plurality', 'sample', 'face', 'images', 'plurality', 'pieces', 'first', 'sample', 'data', 'preprocessing', 'sample', 'face', 'image', 'contained', 'plurality', 'pieces', 'first', 'sample', 'data', 'based', 'mean', 'image', 'data', 'variance', 'image', 'data', 'obtain', 'preprocessed', 'sample', 'face', 'image', 'setting', 'preprocessed', 'sample', 'face', 'image', 'corresponding', 'head', 'posture', 'information', 'first', 'model', 'training', 'sample', 'performing', 'training', 'using', 'machine', 'learning', 'method', 'based', 'plurality', 'first', 'model', 'training', 'samples', 'obtain', 'head', 'posture', 'recognition', 'model', 'device', 'claimed', 'claim', 'wherein', 'gaze', 'information', 'recognition', 'model', 'obtained', 'training', 'acquiring', 'second', 'sample', 'data', 'set', 'wherein', 'second', 'sample', 'data', 'set', 'includes', 'plurality', 'pieces', 'second', 'sample', 'data', 'plurality', 'pieces', 'second', 'sample', 'data', 'includes', 'correspondence', 'sample', 'eye', 'image', 'gaze', 'information', 'determining', 'mean', 'image', 'data', 'variance', 'image', 'data', 'plurality', 'sample', 'eye', 'images', 'plurality', 'pieces', 'second', 'sample', 'data', 'preprocessing', 'sample', 'eye', 'image', 'contained', 'plurality', 'pieces', 'second', 'sample', 'data', 'based', 'mean', 'image', 'data', 'variance', 'image', 'data', 'obtain', 'preprocessed', 'sample', 'eye', 'image', 'setting', 'preprocessed', 'sample', 'eye', 'image', 'corresponding', 'gaze', 'information', 'second', 'model', 'training', 'sample', 'performing', 'training', 'using', 'machine', 'learning', 'method', 'plurality', 'second', 'model', 'training', 'samples', 'obtain', 'gaze', 'information', 'recognition', 'model', 'device', 'claimed', 'claim', 'wherein', 'angle', 'rotation', 'preset', 'direction', 'comprises', 'pitch', 'angle', 'yaw', 'angle', 'roll', 'angle', 'wherein', 'pitch', 'angle', 'refers', 'angle', 'rotation', 'around', 'x-axis', 'yaw', 'angle', 'refers', 'angle', 'rotation', 'around', 'y-axis', 'roll', 'angle', 'refers', 'angle', 'rotation', 'around', 'z-axis', 'non-transitory', 'computer-readable', 'storage', 'medium', 'payment', 'based', 'face', 'recognition', 'configured', 'instructions', 'executable', 'one', 'processors', 'cause', 'one', 'processors', 'perform', 'operations', 'comprising', 'acquiring', 'first', 'face', 'image', 'information', 'target', 'user', 'extracting', 'first', 'characteristic', 'information', 'first', 'face', 'image', 'information', 'wherein', 'first', 'characteristic', 'information', 'includes', 'head', 'posture', 'information', 'target', 'user', 'gaze', 'information', 'target', 'user', 'determining', 'whether', 'target', 'user', 'willingness', 'pay', 'according', 'head', 'posture', 'information', 'target', 'user', 'gaze', 'information', 'target', 'user', 'including', 'determining', 'whether', 'angle', 'rotation', 'preset', 'direction', 'less', 'angle', 'threshold', 'wherein', 'head', 'posture', 'information', 'includes', 'angle', 'rotation', 'preset', 'direction', 'determining', 'whether', 'probability', 'value', 'user', 'gazes', 'payment', 'screen', 'greater', 'probability', 'threshold', 'wherein', 'gaze', 'information', 'includes', 'probability', 'value', 'user', 'gazes', 'payment', 'screen', 'response', 'determining', 'angle', 'rotation', 'preset', 'direction', 'less', 'angle', 'threshold', 'probability', 'value', 'user', 'gazes', 'payment', 'screen', 'greater', 'probability', 'threshold', 'determining', 'target', 'user', 'willingness', 'pay', 'response', 'determining', 'target', 'user', 'willingness', 'pay', 'completing', 'payment', 'operation', 'based', 'face', 'recognition', 'storage', 'medium', 'claimed', 'claim', 'wherein', 'completing', 'payment', 'operation', 'based', 'face', 'recognition', 'comprises', 'triggering', 'performing', 'payment', 'initiating', 'operation', 'acquire', 'second', 'face', 'image', 'information', 'based', 'face', 'recognition', 'determining', 'whether', 'second', 'characteristic', 'information', 'extracted', 'second', 'face', 'image', 'information', 'indicates', 'user', 'willingness', 'pay', 'response', 'determining', 'second', 'characteristic', 'information', 'indicates', 'user', 'willingness', 'pay', 'triggering', 'performing', 'payment', 'confirmation', 'operation', 'complete', 'payment', 'operation', 'based', 'payment', 'account', 'information', 'corresponding', 'target', 'user', 'storage', 'medium', 'claimed', 'claim', 'wherein', 'determining', 'whether', 'second', 'characteristic', 'information', 'extracted', 'second', 'face', 'image', 'information', 'indicates', 'user', 'willingness', 'pay', 'comprises', 'determining', 'whether', 'current', 'user', 'corresponding', 'second', 'face', 'image', 'information', 'consistent', 'target', 'user', 'response', 'determining', 'current', 'user', 'consistent', 'target', 'user', 'determining', 'whether', 'target', 'user', 'willingness', 'pay', 'according', 'second', 'characteristic', 'information', 'extracted', 'second', 'face', 'image', 'information', 'storage', 'medium', 'claimed', 'claim', 'wherein', 'extracting', 'first', 'characteristic', 'information', 'first', 'face', 'image', 'information', 'comprises', 'determining', 'head', 'posture', 'information', 'target', 'user', 'using', 'head', 'posture', 'recognition', 'model', 'based', 'first', 'face', 'image', 'information', 'determining', 'gaze', 'information', 'target', 'user', 'using', 'gaze', 'information', 'recognition', 'model', 'based', 'characteristics', 'eye', 'region', 'first', 'face', 'image', 'information', 'storage', 'medium', 'claimed', 'claim', 'wherein', 'head', 'posture', 'recognition', 'model', 'obtained', 'training', 'acquiring', 'first', 'sample', 'data', 'set', 'wherein', 'first', 'sample', 'data', 'set', 'includes', 'plurality', 'pieces', 'first', 'sample', 'data', 'plurality', 'pieces', 'first', 'sample', 'data', 'includes', 'correspondence', 'sample', 'face', 'image', 'head', 'posture', 'information', 'determining', 'mean', 'image', 'data', 'variance', 'image', 'data', 'plurality', 'sample', 'face', 'images', 'plurality', 'pieces', 'first', 'sample', 'data', 'preprocessing', 'sample', 'face', 'image', 'contained', 'plurality', 'pieces', 'first', 'sample', 'data', 'based', 'mean', 'image', 'data', 'variance', 'image', 'data', 'obtain', 'preprocessed', 'sample', 'face', 'image', 'setting', 'preprocessed', 'sample', 'face', 'image', 'corresponding', 'head', 'posture', 'information', 'first', 'model', 'training', 'sample', 'performing', 'training', 'using', 'machine', 'learning', 'method', 'based', 'plurality', 'first', 'model', 'training', 'samples', 'obtain', 'head', 'posture', 'recognition', 'model', 'wherein', 'gaze', 'information', 'recognition', 'model', 'obtained', 'training', 'acquiring', 'second', 'sample', 'data', 'set', 'wherein', 'second', 'sample', 'data', 'set', 'includes', 'plurality', 'pieces', 'second', 'sample', 'data', 'plurality', 'pieces', 'second', 'sample', 'data', 'includes', 'correspondence', 'sample', 'eye', 'image', 'gaze', 'information', 'determining', 'mean', 'image', 'data', 'variance', 'image', 'data', 'plurality', 'sample', 'eye', 'images', 'plurality', 'pieces', 'second', 'sample', 'data', 'preprocessing', 'sample', 'eye', 'image', 'contained', 'plurality', 'pieces', 'second', 'sample', 'data', 'based', 'mean', 'image', 'data', 'variance', 'image', 'data', 'obtain', 'preprocessed', 'sample', 'eye', 'image', 'setting', 'preprocessed', 'sample', 'eye', 'image', 'corresponding', 'gaze', 'information', 'second', 'model', 'training', 'sample', 'performing', 'training', 'using', 'machine', 'learning', 'method', 'based', 'plurality', 'second', 'model', 'training', 'samples', 'obtain', 'gaze', 'information', 'recognition', 'model', 'storage', 'medium', 'claimed', 'claim', 'wherein', 'angle', 'rotation', 'preset', 'direction', 'comprises', 'pitch', 'angle', 'yaw', 'angle', 'roll', 'angle', 'wherein', 'pitch', 'angle', 'refers', 'angle', 'rotation', 'around', 'x-axis', 'yaw', 'angle', 'refers', 'angle', 'rotation', 'around', 'y-axis', 'roll', 'angle', 'refers', 'angle', 'rotation', 'around', 'z-axis', 'method', 'comprising', 'detecting', 'motion', 'detection', 'module', 'motion', 'subject', 'within', 'predetermined', 'area', 'view', 'assigning', 'unique', 'session', 'identification', 'number', 'subject', 'detected', 'within', 'predetermined', 'area', 'view', 'detecting', 'facial', 'area', 'subject', 'detected', 'within', 'predetermined', 'area', 'view', 'generating', 'image', 'facial', 'area', 'subject', 'assessing', 'quality', 'image', 'facial', 'area', 'subject', 'determining', 'identity', 'subject', 'based', 'image', 'facial', 'area', 'subject', 'identifying', 'intent', 'subject', 'authorizing', 'access', 'point', 'entry', 'based', 'determined', 'identity', 'subject', 'based', 'intent', 'subject', 'method', 'claim', 'comprising', 'determining', 'one', 'additional', 'subjects', 'within', 'predetermined', 'area', 'view', 'assigning', 'unique', 'session', 'identification', 'number', 'one', 'additional', 'subjects', 'detected', 'within', 'predetermined', 'area', 'view', 'method', 'claim', 'wherein', 'assessing', 'quality', 'image', 'facial', 'area', 'subject', 'comprises', 'assessing', 'whether', 'quality', 'image', 'facial', 'area', 'object', 'equates', 'predetermined', 'metric', 'quality', 'upon', 'determining', 'quality', 'image', 'facial', 'area', 'object', 'inferior', 'predetermined', 'metric', 'quality', 'discarding', 'image', 'facial', 'area', 'subject', 'generating', 'second', 'image', 'facial', 'area', 'subject', 'method', 'claim', 'comprising', 'detecting', 'whether', 'facial', 'area', 'subject', 'photographic', 'image', 'upon', 'detecting', 'facial', 'area', 'subject', 'photographic', 'image', 'generating', 'warning', 'restrict', 'access', 'point', 'entry', 'method', 'claim', 'comprising', 'conducing', 'incremental', 'training', 'image', 'facial', 'area', 'subject', 'method', 'claim', 'wherein', 'conducing', 'incremental', 'training', 'image', 'facial', 'area', 'subject', 'comprises', 'capturing', 'first', 'image', 'facial', 'area', 'facial', 'landmarks', 'converting', 'first', 'image', 'facial', 'area', 'first', 'numeric', 'vector', 'capturing', 'second', 'image', 'facial', 'area', 'facial', 'landmarks', 'converting', 'second', 'image', 'facial', 'area', 'second', 'numeric', 'vector', 'calculating', 'weighted', 'mean', 'first', 'numeric', 'vector', 'second', 'numeric', 'vector', 'wherein', 'weighted', 'mean', 'represents', 'change', 'facial', 'area', 'storing', 'weighted', 'mean', 'database', 'method', 'claim', 'wherein', 'determining', 'identity', 'subject', 'based', 'image', 'facial', 'area', 'subject', 'comprises', 'comparing', 'image', 'facial', 'area', 'subject', 'plurality', 'images', 'stored', 'database', 'authenticating', 'subject', 'method', 'claim', 'wherein', 'identifying', 'intent', 'subject', 'comprises', 'upon', 'detecting', 'facial', 'area', 'bounding', 'box', 'commencing', 'authentication', 'subject', 'calculating', 'directional', 'vector', 'face', 'subject', 'determine', 'intent', 'subject', 'gain', 'access', 'point', 'entry', 'based', 'directional', 'vector', 'face', 'subject', 'granting', 'access', 'point', 'entry', 'based', 'authentication', 'subject', 'based', 'determining', 'intent', 'subject', 'non-transitory', 'computer', 'readable', 'medium', 'program', 'instructions', 'stored', 'thereon', 'response', 'execution', 'computing', 'device', 'cause', 'computing', 'device', 'perform', 'operations', 'comprising', 'detecting', 'motion', 'subject', 'within', 'predetermined', 'area', 'view', 'assigning', 'unique', 'session', 'identification', 'number', 'subject', 'detected', 'within', 'predetermined', 'area', 'view', 'detecting', 'facial', 'area', 'subject', 'detected', 'within', 'predetermined', 'area', 'view', 'generating', 'image', 'facial', 'area', 'subject', 'assessing', 'quality', 'image', 'facial', 'area', 'subject', 'determining', 'identity', 'subject', 'based', 'image', 'facial', 'area', 'subject', 'identifying', 'intent', 'subject', 'authorizing', 'access', 'point', 'entry', 'based', 'determined', 'identity', 'subject', 'based', 'intent', 'subject', 'non-transitory', 'computer', 'readable', 'medium', 'claim', 'comprising', 'determining', 'one', 'additional', 'subjects', 'within', 'predetermined', 'area', 'view', 'assigning', 'unique', 'session', 'identification', 'number', 'one', 'additional', 'subjects', 'detected', 'within', 'predetermined', 'area', 'view', 'non-transitory', 'computer', 'readable', 'medium', 'claim', 'wherein', 'assessing', 'quality', 'image', 'facial', 'area', 'subject', 'comprises', 'assessing', 'whether', 'quality', 'image', 'facial', 'area', 'object', 'equates', 'predetermined', 'metric', 'quality', 'upon', 'determining', 'quality', 'image', 'facial', 'area', 'object', 'inferior', 'predetermined', 'metric', 'quality', 'discarding', 'image', 'facial', 'area', 'subject', 'generating', 'second', 'image', 'facial', 'area', 'subject', 'non-transitory', 'computer', 'readable', 'medium', 'claim', 'comprising', 'detecting', 'whether', 'facial', 'area', 'subject', 'photographic', 'image', 'upon', 'detecting', 'facial', 'area', 'subject', 'photographic', 'image', 'generating', 'warning', 'restrict', 'access', 'access', 'point', 'non-transitory', 'computer', 'readable', 'medium', 'claim', 'comprising', 'conducing', 'incremental', 'training', 'image', 'facial', 'area', 'subject', 'non-transitory', 'computer', 'readable', 'medium', 'claim', 'wherein', 'conducing', 'incremental', 'training', 'image', 'facial', 'area', 'subject', 'comprises', 'capturing', 'first', 'image', 'facial', 'area', 'facial', 'landmarks', 'converting', 'first', 'image', 'facial', 'area', 'first', 'numeric', 'vector', 'capturing', 'second', 'image', 'facial', 'area', 'facial', 'landmarks', 'converting', 'second', 'image', 'facial', 'area', 'second', 'numeric', 'vector', 'calculating', 'weighted', 'mean', 'first', 'numeric', 'vector', 'second', 'numeric', 'vector', 'wherein', 'weighted', 'mean', 'represents', 'change', 'facial', 'area', 'storing', 'weighted', 'mean', 'database', 'apparatus', 'face', 'recognition', 'comprising', 'processor', 'memory', 'store', 'computer', 'program', 'instructions', 'computer', 'program', 'instructions', 'executed', 'processor', 'cause', 'processor', 'perform', 'operations', 'comprising', 'detecting', 'motion', 'subject', 'within', 'predetermined', 'area', 'view', 'assigning', 'unique', 'session', 'identification', 'number', 'subject', 'detected', 'within', 'predetermined', 'area', 'view', 'detecting', 'facial', 'area', 'subject', 'detected', 'within', 'predetermined', 'area', 'view', 'generating', 'image', 'facial', 'area', 'subject', 'assessing', 'quality', 'image', 'facial', 'area', 'subject', 'determining', 'identity', 'subject', 'based', 'image', 'facial', 'area', 'subject', 'identifying', 'intent', 'subject', 'authorizing', 'access', 'point', 'entry', 'based', 'determined', 'identity', 'subject', 'based', 'intent', 'subject', 'apparatus', 'claim', 'comprising', 'determining', 'one', 'additional', 'subjects', 'within', 'predetermined', 'area', 'view', 'assigning', 'unique', 'session', 'identification', 'number', 'one', 'additional', 'subjects', 'detected', 'within', 'predetermined', 'area', 'view', 'apparatus', 'claim', 'wherein', 'assessing', 'quality', 'image', 'facial', 'area', 'subject', 'comprises', 'assessing', 'whether', 'quality', 'image', 'facial', 'area', 'object', 'equates', 'predetermined', 'metric', 'quality', 'upon', 'determining', 'quality', 'image', 'facial', 'area', 'object', 'inferior', 'predetermined', 'metric', 'quality', 'discarding', 'image', 'facial', 'area', 'subject', 'generating', 'second', 'image', 'facial', 'area', 'subject', 'apparatus', 'claim', 'comprising', 'detecting', 'whether', 'facial', 'area', 'subject', 'photographic', 'image', 'upon', 'detecting', 'facial', 'area', 'subject', 'photographic', 'image', 'generating', 'warning', 'restrict', 'access', 'access', 'point', 'apparatus', 'claim', 'comprising', 'conducing', 'incremental', 'training', 'image', 'facial', 'area', 'subject', 'apparatus', 'claim', 'wherein', 'conducing', 'incremental', 'training', 'image', 'facial', 'area', 'subject', 'comprises', 'capturing', 'first', 'image', 'facial', 'area', 'facial', 'landmarks', 'converting', 'first', 'image', 'facial', 'area', 'first', 'numeric', 'vector', 'capturing', 'second', 'image', 'facial', 'area', 'facial', 'landmarks', 'converting', 'second', 'image', 'facial', 'area', 'second', 'numeric', 'vector', 'calculating', 'weighted', 'mean', 'first', 'numeric', 'vector', 'second', 'numeric', 'vector', 'wherein', 'weighted', 'mean', 'represents', 'change', 'facial', 'area', 'storing', 'weighted', 'mean', 'database', 'robot', 'comprising', 'body', 'configured', 'rotate', 'tilt', 'camera', 'coupled', 'body', 'configured', 'rotate', 'tilt', 'according', 'rotate', 'tilt', 'body', 'wherein', 'camera', 'configured', 'acquire', 'video', 'space', 'face', 'recognition', 'unit', 'configured', 'recognize', 'respective', 'faces', 'one', 'persons', 'video', 'tracking', 'unit', 'configured', 'track', 'motion', 'recognized', 'faces', 'one', 'persons', 'controller', 'configured', 'calculate', 'respective', 'size', 'faces', 'one', 'persons', 'select', 'first', 'person', 'among', 'one', 'persons', 'based', 'calculated', 'sizes', 'faces', 'control', 'least', 'one', 'direction', 'rotation', 'camera', 'angle', 'tilt', 'camera', 'focal', 'distance', 'camera', 'based', 'tracked', 'motion', 'recognized', 'face', 'first', 'person', 'robot', 'claim', 'wherein', 'controller', 'configured', 'control', 'direction', 'rotation', 'camera', 'angle', 'tilt', 'camera', 'achieve', 'particular', 'orientation', 'camera', 'relative', 'face', 'first', 'person', 'control', 'focal', 'distance', 'camera', 'comparing', 'respective', 'sizes', 'face', 'first', 'person', 'motion', 'first', 'person', 'robot', 'claim', 'wherein', 'particular', 'orientation', 'occurs', 'camera', 'faces', 'general', 'direction', 'face', 'first', 'person', 'robot', 'claim', 'wherein', 'controller', 'configured', 'normalize', 'sizes', 'faces', 'one', 'persons', 'based', 'interocular', 'distance', 'select', 'first', 'person', 'based', 'normalized', 'sizes', 'faces', 'one', 'persons', 'robot', 'claim', 'wherein', 'controller', 'configured', 'select', 'person', 'largest', 'face', 'size', 'among', 'one', 'persons', 'first', 'person', 'robot', 'claim', 'comprising', 'microphone', 'configured', 'receive', 'spoken', 'audio', 'present', 'space', 'wherein', 'controller', 'configured', 'select', 'first', 'person', 'based', 'received', 'spoken', 'audio', 'robot', 'claim', 'wherein', 'controller', 'configured', 'control', 'gain', 'microphone', 'comparing', 'respective', 'sizes', 'face', 'first', 'person', 'motion', 'first', 'person', 'robot', 'claim', 'wherein', 'controller', 'configured', 'calculate', 'position', 'spoken', 'audio', 'provided', 'select', 'first', 'person', 'based', 'whether', 'one', 'persons', 'position', 'voice', 'signal', 'provided', 'robot', 'claim', 'wherein', 'controller', 'configured', 'select', 'second', 'person', 'first', 'person', 'among', 'one', 'persons', 'second', 'person', 'located', 'position', 'spoken', 'audio', 'provided', 'robot', 'claim', 'wherein', 'controller', 'configured', 'select', 'second', 'person', 'largest', 'face', 'size', 'first', 'person', 'among', 'one', 'persons', 'none', 'one', 'persons', 'located', 'position', 'spoken', 'audio', 'provided', 'robot', 'claim', 'wherein', 'controller', 'configured', 'select', 'second', 'person', 'largest', 'face', 'size', 'first', 'person', 'among', 'one', 'persons', 'plurality', 'persons', 'among', 'one', 'persons', 'located', 'position', 'spoken', 'audio', 'provided', 'robot', 'claim', 'comprising', 'speaker', 'wherein', 'controller', 'configured', 'control', 'volume', 'speaker', 'comparing', 'respective', 'sizes', 'face', 'first', 'person', 'motion', 'first', 'person', 'robot', 'claim', 'wherein', 'body', 'configured', 'rotate', 'lateral', 'direction', 'tilt', 'vertical', 'direction', 'electronic', 'device', 'comprising', 'camera', 'coupled', 'body', 'configured', 'rotate', 'tilt', 'wherein', 'camera', 'configured', 'acquire', 'video', 'space', 'within', 'one', 'persons', 'positioned', 'processor', 'configured', 'recognize', 'respective', 'faces', 'one', 'persons', 'video', 'track', 'motion', 'recognized', 'faces', 'one', 'persons', 'calculate', 'respective', 'size', 'faces', 'one', 'persons', 'select', 'first', 'person', 'among', 'one', 'persons', 'based', 'calculated', 'sizes', 'faces', 'control', 'least', 'one', 'direction', 'rotation', 'camera', 'angle', 'tilt', 'camera', 'focal', 'distance', 'camera', 'based', 'tracked', 'motion', 'recognized', 'face', 'first', 'person', 'method', 'comprising', 'acquiring', 'camera', 'video', 'space', 'within', 'one', 'persons', 'positioned', 'recognizing', 'respective', 'faces', 'one', 'persons', 'video', 'tracking', 'motion', 'recognized', 'faces', 'one', 'persons', 'calculating', 'respective', 'size', 'faces', 'one', 'persons', 'selecting', 'first', 'person', 'among', 'one', 'persons', 'based', 'calculated', 'sizes', 'faces', 'controlling', 'least', 'one', 'direction', 'rotation', 'camera', 'angle', 'tilt', 'camera', 'focal', 'distance', 'camera', 'based', 'tracked', 'motion', 'recognized', 'face', 'first', 'person', 'method', 'inferring', 'topics', 'multimodal', 'file', 'method', 'comprising', 'receiving', 'multimodal', 'file', 'extracting', 'set', 'entities', 'multimodal', 'file', 'linking', 'set', 'entities', 'produce', 'set', 'linked', 'entities', 'obtaining', 'reference', 'information', 'set', 'entities', 'based', 'least', 'reference', 'information', 'generating', 'graph', 'set', 'linked', 'entities', 'graph', 'comprising', 'nodes', 'edges', 'based', 'least', 'nodes', 'edges', 'graph', 'determining', 'clusters', 'graph', 'based', 'least', 'clusters', 'graph', 'identifying', 'topic', 'candidates', 'extracting', 'features', 'clusters', 'graph', 'based', 'least', 'extracted', 'features', 'selecting', 'least', 'one', 'topicid', 'among', 'topic', 'candidates', 'represent', 'least', 'one', 'cluster', 'indexing', 'multimodal', 'file', 'least', 'one', 'topicid', 'method', 'claim', 'wherein', 'multimodal', 'file', 'comprises', 'video', 'portion', 'audio', 'portion', 'wherein', 'extracting', 'set', 'entities', 'multimodal', 'file', 'comprises', 'detecting', 'objects', 'video', 'portion', 'multimodal', 'file', 'detecting', 'text', 'audio', 'portion', 'multimodal', 'file', 'method', 'claim', 'wherein', 'detecting', 'objects', 'comprises', 'performing', 'face', 'recognition', 'method', 'claim', 'wherein', 'detecting', 'text', 'comprises', 'performing', 'speech', 'text', 'process', 'method', 'claim', 'comprising', 'identifying', 'language', 'used', 'audio', 'portion', 'multimodal', 'file', 'wherein', 'performing', 'speech', 'text', 'process', 'comprises', 'performing', 'speech', 'text', 'process', 'identified', 'language', 'method', 'claim', 'comprising', 'translating', 'detected', 'text', 'method', 'claim', 'comprising', 'determining', 'significant', 'clusters', 'insignificant', 'clusters', 'determined', 'clusters', 'wherein', 'extracting', 'features', 'clusters', 'graph', 'comprises', 'extracting', 'features', 'significant', 'clusters', 'graph', 'method', 'claim', 'wherein', 'extracting', 'features', 'clusters', 'graph', 'comprises', 'least', 'one', 'process', 'selected', 'list', 'consisting', 'determining', 'graph', 'diameter', 'determining', 'jaccard', 'coefficient', 'method', 'claim', 'wherein', 'selecting', 'least', 'one', 'topicid', 'represent', 'least', 'one', 'cluster', 'comprises', 'based', 'least', 'extracted', 'features', 'mapping', 'topic', 'candidates', 'probability', 'interval', 'based', 'least', 'mapping', 'ranking', 'topic', 'candidates', 'within', 'least', 'one', 'cluster', 'selecting', 'least', 'one', 'topicid', 'based', 'least', 'ranking', 'method', 'claim', 'comprising', 'translating', 'least', 'one', 'topicid', 'wherein', 'indexing', 'multimodal', 'file', 'least', 'one', 'topicid', 'comprises', 'indexing', 'multimodal', 'file', 'least', 'one', 'translated', 'topicid', 'system', 'inferring', 'topics', 'multimodal', 'file', 'system', 'comprising', 'entity', 'extraction', 'component', 'comprising', 'object', 'detection', 'component', 'speech', 'text', 'component', 'operative', 'extract', 'set', 'entities', 'multimodal', 'file', 'comprising', 'video', 'portion', 'audio', 'portion', 'entity', 'linking', 'component', 'operative', 'link', 'extracted', 'set', 'entities', 'produce', 'set', 'linked', 'entities', 'information', 'retrieval', 'component', 'operative', 'obtain', 'reference', 'information', 'extracted', 'set', 'entities', 'graphing', 'analysis', 'component', 'operative', 'generate', 'graph', 'set', 'linked', 'entities', 'graph', 'comprising', 'nodes', 'edges', 'based', 'least', 'nodes', 'edges', 'graph', 'determine', 'clusters', 'graph', 'based', 'least', 'clusters', 'graph', 'identify', 'topic', 'candidates', 'extract', 'features', 'clusters', 'graph', 'topicid', 'selection', 'component', 'operative', 'rank', 'topic', 'candidates', 'within', 'least', 'one', 'cluster', 'based', 'least', 'ranking', 'select', 'least', 'one', 'topicid', 'among', 'topic', 'candidates', 'represent', 'least', 'one', 'cluster', 'video', 'indexer', 'operative', 'index', 'multimodal', 'file', 'least', 'one', 'topicid', 'system', 'claim', 'wherein', 'object', 'detection', 'component', 'operative', 'perform', 'face', 'recognition', 'system', 'claim', 'wherein', 'speech', 'text', 'component', 'operative', 'extract', 'entity', 'information', 'least', 'two', 'different', 'languages', 'one', 'computer', 'storage', 'devices', 'computer-executable', 'instructions', 'stored', 'thereon', 'inferring', 'topics', 'multimodal', 'file', 'execution', 'computer', 'cause', 'computer', 'perform', 'operations', 'comprising', 'receiving', 'multimodal', 'file', 'comprising', 'video', 'portion', 'audio', 'portion', 'extracting', 'set', 'entities', 'multimodal', 'file', 'wherein', 'extracting', 'set', 'entities', 'multimodal', 'file', 'comprises', 'detecting', 'objects', 'video', 'portion', 'multimodal', 'file', 'face', 'recognition', 'detecting', 'text', 'audio', 'portion', 'multimodal', 'file', 'speech', 'text', 'process', 'disambiguating', 'among', 'set', 'detected', 'entity', 'names', 'linking', 'set', 'entities', 'produce', 'set', 'linked', 'entities', 'obtaining', 'reference', 'information', 'set', 'entities', 'based', 'least', 'reference', 'information', 'generating', 'graph', 'set', 'linked', 'entities', 'graph', 'comprising', 'nodes', 'edges', 'based', 'least', 'nodes', 'edges', 'graph', 'determining', 'clusters', 'graph', 'determining', 'significant', 'clusters', 'insignificant', 'clusters', 'determined', 'clusters', 'based', 'least', 'significant', 'clusters', 'graph', 'identifying', 'topic', 'candidates', 'extracting', 'features', 'significant', 'clusters', 'graph', 'based', 'least', 'extracted', 'features', 'mapping', 'topic', 'candidates', 'probability', 'interval', 'based', 'least', 'mapping', 'ranking', 'topic', 'candidates', 'within', 'least', 'one', 'significant', 'cluster', 'based', 'ranking', 'selecting', 'least', 'one', 'topicid', 'among', 'topic', 'candidates', 'represent', 'least', 'one', 'significant', 'cluster', 'indexing', 'multimodal', 'file', 'least', 'one', 'topicid', 'one', 'computer', 'storage', 'devices', 'claim', 'wherein', 'operations', 'comprise', 'identifying', 'language', 'used', 'audio', 'portion', 'multimodal', 'file', 'detecting', 'text', 'audio', 'portion', 'multimodal', 'file', 'speech', 'text', 'process', 'comprises', 'performing', 'speech', 'text', 'process', 'identified', 'language权利要求', '、', '一种人脸识别方法其特征在于包括', '通过第一摄像头获取第一人脸图像', '提取所述第一人脸图像的第一人脸特征', '将所述第一人脸特征与预先存储的第二人脸特征进行对比获得参考相似度所述第', '二人脸特征经第二摄像头获取的第二人脸图像的特征提取而得所述第二摄像头与所述第', '一摄像头属于不同类型的摄像头', '根据所述参考相似度确定所述第一人脸特征与所述第二人脸特征是否对应相同人。', '、', '根据权利要求', '所述的方法其特征在于', '所述第一摄像头为热成像摄像头所述第二摄像头为可见光摄像头', '或者所述第一摄像头为可见光摄像头所述第一摄像头为热成像摄像头。', '、', '根据权利要求', '或', '所述的方法其特征在于所述根据所述参考相似度确定所', '述第一人脸特征与所述第二人脸特征是否对应相同人包括', '根据所述参考相似度、', '参考误报率以及相似度阈值确定所述第一人脸特征与所述第二', '人脸特征是否对应相同人其中不同的误报率对应不同的相似度阈值。', '、', '根据权利要求', '或', '所述的方法其特征在于所述根据所述参考相似度确定所', '述第一人脸特征与所述第二人脸特征是否对应相同人包括', '根据所述参考相似度以及阈值信息确定归一化后的参考相似度', '根据所述归一化后的参考相似度确定所述第一人脸特征与所述第二人脸特征是否对', '应相同人。', '、', '根据权利要求', '-任一项所述的方法其特征在于所述提取所述第一人脸图像的', '第_人脸特征包括', '将所述第一人脸图像输入预先训练完成的神经网络通过所述神经网络输出所述第一', '人脸图像的第一人脸特征其中所述神经网络基于第一类型图像样本和第二类型图像样', '本训练得到所述第一类型图像样本和所述第二类型图像样本由不同类型的摄像头拍摄得', '到且所述第一类型图像样本和所述第二类型图像样本中包括人脸。', '、', '根据权利要求', '所述的方法其特征在于所述神经网络基于所述第一类型图像', '样本、', '所述第二类型图像样本和混合类型图像样本训练得到所述混合类型图像样本由所', '述第一类型图像样本和所述第二类型图像样本配对而得。', '、', '根据权利要求', '-任一项所述的方法其特征在于所述第一摄像头包括车载摄像', '头所述通过第一摄像头获取第一人脸图像包括', '通过所述车载摄像头获取所述第一人脸图像所述第一人脸图像包括车辆的用车人的', '人脸图像。', '、', '根据权利要求', '所述的方法其特征在于所述用车人包括驾驶所述车辆的人、', '乘坐所述车辆的人、', '对所述车辆进行修理的人、', '给所述车辆加油的人以及控制所述车辆的', '人中的一项或多项。', '、', '根据权利要求', '所述的方法其特征在于所述用车人包括驾驶所述车辆的人', '所述通过所述车载摄像头获取所述第一人脸图像包括', '在接收到触发指令的情况下通过所述车载摄像头获取所述第一人脸图像', '或者在所述车辆运行时通过所述车载摄像头获取所述第一人脸图像', '或者在所述车辆的运行速度达到参考速度的情况下通过所述车载摄像头获取所述', '第一人脸图像。', '、', '根据权利要求', '-任一项所述的方法其特征在于所述第二人脸图像为对所述', '用车人进行人脸注册的图像所述将所述第一人脸特征与预先存储的第二人脸特征进行对', '比之前所述方法还包括', '通过所述第二摄像头获取所述第二人脸图像', '提取所述第二人脸图像的第二人脸特征', '保存所述第二人脸图像的第二人脸特征。', '、', '一种神经网络训练方法其特征在于包括', '获取第一类型图像样本和第二类型图像样本所述第一类型图像样本和所述第二类型', '图像样本由不同类型的摄像头拍摄得到且所述第一类型图像样本和所述第二类型图像样', '本中包括人脸', '根据所述第一类型图像样本和所述第二类型图像样本训练神经网络。', '、', '根据权利要求', '所述的方法其特征在于所述根据所述第一类型图像样本和所', '述第二类型图像样本训练神经网络包括', '将所述第一类型图像样本和所述第二类型图像样本配对得到所述第一类型图像样本', '和所述第二类型图像样本的混合类型图像样本', '根据所述第一类型图像样本、', '所述第二类型图像样本和所述混合类型图像样本训练', '所述神经网络。', '、', '根据权利要求', '所述的方法其特征在于所述根据所述第一类型图像样本、', '所述第二类型图像样本和所述混合类型图像样本训练所述神经网络包括', '通过所述神经网络获取所述第一类型图像样本的人脸预测结果、', '所述第二类型图像样', '本的人脸预测结果和所述混合类型图像样本的人脸预测结果', '根据所述第一类型图像样本的人脸预测结果和人脸标注结果的差异、', '所述第二类型图', '像样本的人脸预测结果和人脸标注结果之间的差异、', '以及所述混合类型图像样本的人脸预', '测结果和人脸标注结果的差异训练所述神经网络。', '、', '根据权利要求', '所述的方法其特征在于所述神经网络中包括第一分类器、', '第二分类器和混合分类器所述通过所述神经网络获取所述第一类型图像样本的人脸预测', '结果、', '所述第二类型图像样本的人脸预测结果和所述混合类型图像样本的人脸预测结果', '包括', '将所述第一类型图像样本的人脸特征输入至所述第一分类器中得到所述第一类型图', '像样本的人脸预测结果', '将所述第二类型图像样本的人脸特征输入至所述第二分类器中得到所述第二类型图', '像样本的人脸预测结果', '将所述混合类型图像样本的人脸特征输入至所述混合分类器中得到所述混合类型图', '像样本的人脸预测结果。', '、', '根据权利要求', '所述的方法其特征在于所述方法还包括', '在训练完成的所述神经网络中去除所述第一分类器、', '所述第二分类器和所述混合分类', '器得到用于进行人脸识别的神经网络。', '、', '一种人脸识别装置其特征在于包括', '第一获取单元用于通过第一摄像头获取第一人脸图像', '第一提取单元用于提取所述第一人脸图像的第一人脸特征', '对比单元用于将所述第一人脸特征与预先存储的第二人脸特征进行对比获得参考', '相似度所述第二人脸特征经第二摄像头获取的第二人脸图像的特征提取而得所述第二', '摄像头与所述第一摄像头属于不同类型的摄像头', '确定单元用于根据所述参考相似度确定所述第一人脸特征与所述第二人脸特征是否', '对应相同人。', '、', '根据权利要求', '所述的装置其特征在于', '所述第一摄像头为热成像摄像头所述第二摄像头为可见光摄像头', '或者所述第一摄像头为可见光摄像头所述第一摄像头为热成像摄像头。', '、', '根据权利要求', '或', '所述的装置其特征在于', '所述确定单元具体用于根据所述参考相似度、', '参考误报率以及相似度阈值确定所述', '第一人脸特征与所述第二人脸特征是否对应相同人其中不同的误报率对应不同的相似', '度阈值。', '、', '根据权利要求', '或', '所述的装置其特征在于', '所述确定单元具体用于根据所述参考相似度以及阈值信息确定归一化后的参考相似', '度以及根据所述归一化后的参考相似度确定所述第一人脸特征与所述第二人脸特征是否', '对应相同人。', '、', '根据权利要求', '-任_项所述的装置其特征在于', '所述第一提取单元具体用于将所述第一人脸图像输入预先训练完成的神经网络通', '过所述神经网络输出所述第一人脸图像的第一人脸特征其中所述神经网络基于第一类', '型图像样本和第二类型图像样本训练得到所述第一类型图像样本和所述第二类型图像样', '本由不同类型的摄像头拍摄得到且所述第一类型图像样本和所述第二类型图像样本中包', '括人脸。', '、', '根据权利要求', '所述的装置其特征在于所述神经网络基于所述第一类型图', '像样本、', '所述第二类型图像样本和混合类型图像样本训练得到所述混合类型图像样本由', '所述第一类型图像样本和所述第二类型图像样本配对而得。', '、', '根据权利要求', '-任一项所述的装置其特征在于所述第一摄像头包括车载', '摄像头', '所述第一获取单元具体用于通过所述车载摄像头获取所述第一人脸图像所述第一', '人脸图像包括车辆的用车人的人脸图像。', '、', '根据权利要求', '所述的装置其特征在于所述用车人包括驾驶所述车辆的人、', '乘坐所述车辆的人、', '对所述车辆进行修理的人、', '给所述车辆加油的人以及控制所述车辆的', '人中的一项或多项。', '、', '根据权利要求', '所述的装置其特征在于所述用车人包括驾驶所述车辆的人', '所述第一获取单元具体用于在接收到触发指令的情况下通过所述车载摄像头获取所述', '第一人脸图像', '或者所述第一获取单元具体用于在所述车辆运行时通过所述车载摄像头获取所', '述第', '_人脸图像', '或者所述第一获取单元具体用于在所述车辆的运行速度达到参考速度的情况下', '通过所述车载摄像头获取所述第一人脸图像。', '、', '根据权利要求', '-任一项所述的装置其特征在于所述第二人脸图像为对所', '述用车人进行人脸注册的图像所述装置还包括', '第二获取单元用于通过所述第二摄像头获取所述第二人脸图像', '第二提取单元用于提取所述第二人脸图像的第二人脸特征', '保存单元用于保存所述第二人脸图像的第二人脸特征。', '、', '一种神经网络训练装置其特征在于包括', '获取单元用于获取第一类型图像样本和第二类型图像样本所述第一类型图像样本', '和所述第二类型图像样本由不同类型的摄像头拍摄得到且所述第一类型图像样本和所述', '第二类型图像样本中包括人脸', '训练单元用于根据所述第一类型图像样本和所述第二类型图像样本训练神经网络。', '、', '根据权利要求', '所述的装置其特征在于所述训练单元包括', '配对子单元用于将所述第一类型图像样本和所述第二类型图像样本配对得到所述', '第一类型图像样本和所述第二类型图像样本的混合类型图像样本', '训练子单元用于根据所述第一类型图像样本、', '所述第二类型图像样本和所述混合类', '型图像样本训练所述神经网络。', '、', '根据权利要求', '所述的装置其特征在于', '所述训练子单元具体用于通过所述神经网络获取所述第一类型图像样本的人脸预测', '结果、', '所述第二类型图像样本的人脸预测结果和所述混合类型图像样本的人脸预测结果', '以及根据所述第一类型图像样本的人脸预测结果和人脸标注结果的差异、', '所述第二类型图', '像样本的人脸预测结果和人脸标注结果之间的差异、', '以及所述混合类型图像样本的人脸预', '测结果和人脸标注结果的差异训练所述神经网络。', '、', '根据权利要求', '所述的装置其特征在于所述神经网络中包括第一分类器、', '第二分类器和混合分类器', '所述训练子单元具体用于将所述第一类型图像样本的人脸特征输入至所述第一分类', '器中得到所述第一类型图像样本的人脸预测结果以及将所述第二类型图像样本的人脸', '特征输入至所述第二分类器中得到所述第二类型图像样本的人脸预测结果以及将所述', '混合类型图像样本的人脸特征输入至所述混合分类器中得到所述混合类型图像样本的人', '脸预测结果。', '、', '根据权利要求', '所述的装置其特征在于所述装置还包括', '神经网络应用单元用于在训练完成的所述神经网络中去除所述第一分类器、', '所述第', '二分类器和所述混合分类器得到用于进行人脸识别的神经网络。', '、', '一种电子设备其特征在于包括处理器和存储器所述处理器和所述存储器耦', '合其中所述存储器用于存储程序指令所述程序指令被所述处理器执行时使所述处', '理器执行权利要求', '-任一项所述的方法和或使所述处理器执行权利要求', '-任一', '项所述的方法。', '、', '一种计算机可读存储介质其特征在于所述计算机可读存储介质中存储有计算', '机程序所述计算机程序包括程序指令所述程序指令当被处理器执行时使所述处理器', '执行权利要求', '-任一项所述的方法和或使所述处理器执行权利要求', '-任一项所', '述的方法。', 'system', 'alerting', 'vision', 'impairment', 'said', 'system', 'comprising', 'processing', 'unit', 'configured', 'operable', 'receiving', 'scene', 'data', 'indicative', 'scene', 'least', 'one', 'consumer', 'environment', 'identifying', 'scene', 'data', 'certain', 'consumer', 'identifying', 'event', 'indicative', 'behavioral', 'compensation', 'vision', 'impairment', 'upon', 'identification', 'event', 'sending', 'notification', 'relating', 'vision', 'impairment', 'system', 'claim', 'comprising', 'least', 'one', 'sensing', 'unit', 'configured', 'operable', 'detecting', 'scene', 'data', 'system', 'claim', 'wherein', 'said', 'least', 'one', 'sensing', 'unit', 'comprises', 'least', 'one', 'least', 'one', 'imaging', 'unit', 'configured', 'operable', 'capturing', 'least', 'one', 'image', 'least', 'portion', 'consumer', \"'s\", 'body', 'least', 'one', 'motion', 'detector', 'configured', 'operable', 'detecting', 'consumer', 'data', 'indicative', 'motion', 'consumer', 'least', 'one', 'eye', 'tracker', 'configured', 'operable', 'tracking', 'eye', 'motion', 'consumer', 'system', 'claim', 'wherein', 'least', 'one', 'imaging', 'unit', 'comprises', 'plurality', 'cameras', 'placed', 'different', 'heights', 'system', 'one', 'claims', 'wherein', 'said', 'sensing', 'unit', 'accommodated', 'optical', 'digital', 'eyewear', 'frame', 'display', 'system', 'one', 'claims', 'wherein', 'said', 'processing', 'unit', 'configured', 'operable', 'identifying', 'consumer', \"'s\", 'condition', 'said', 'consumer', \"'s\", 'condition', 'comprising', 'consumer', 'data', 'indicative', 'consumer', \"'s\", 'position', 'location', 'relative', 'least', 'one', 'object', 'consumer', \"'s\", 'environment', 'said', 'consumer', 'data', 'comprises', 'least', 'one', 'consumer', \"'s\", 'face', 'eyewear', 'posture', 'position', 'sound', 'motion', 'system', 'one', 'claims', 'wherein', 'said', 'event', 'comprises', 'least', 'one', 'position', 'orientation', 'head', 'increase', 'decrease', 'viewing', 'distance', 'consumer', 'viewed', 'object', 'changing', 'position', 'eyeglasses', 'worn', 'consumer', 'system', 'one', 'claims', 'wherein', 'said', 'event', 'identified', 'identifying', 'images', 'image', 'feature', 'indicative', 'behavioral', 'compensation', 'performing', 'bruckner', 'test', 'performing', 'hirschberg', 'test', 'measuring', 'blink', 'count', 'frequency', 'system', 'claim', 'wherein', 'image', 'feature', 'indicative', 'behavioral', 'compensation', 'comprises', 'squinting', 'head', 'orientation', 'certain', 'distances', 'object', 'consumer', \"'s\", 'eyes', 'certain', 'position', 'eyeglasses', 'consumer', \"'s\", 'face', 'strabismus', 'cataracts', 'reflections', 'eye', 'system', 'one', 'claims', 'wherein', 'notification', 'includes', 'least', 'one', 'data', 'indicative', 'identified', 'event', 'data', 'indicative', 'identified', 'consumer', 'ophthalmologic', 'recommendations', 'based', 'identified', 'event', 'lack', 'events', 'appointment', 'vision', 'test', 'system', 'one', 'claims', 'wherein', 'said', 'processing', 'unit', 'comprises', 'memory', 'storing', 'least', 'one', 'reference', 'data', 'indicative', 'behavioral', 'compensation', 'vision', 'impairment', 'data', 'indicative', 'notification', 'data', 'indicative', 'follow-up', 'notification', 'system', 'claim', 'wherein', 'said', 'processing', 'unit', 'configured', 'least', 'one', 'identifying', 'event', 'upon', 'comparison', 'detected', 'data', 'reference', 'data', 'determining', 'probability', 'vision', 'impairment', 'consumer', 'based', 'comparison', 'system', 'one', 'claims', 'wherein', 'said', 'processing', 'unit', 'comprises', 'communication', 'interface', 'configured', 'sending', 'notification', 'least', 'one', 'identified', 'consumer', 'third', 'party', 'system', 'one', 'claims', 'wherein', 'said', 'processing', 'unit', 'configured', 'providing', 'frame', 'recommendation', 'system', 'one', 'claims', 'wherein', 'said', 'memory', 'configured', 'storing', 'database', 'including', 'multiplicity', 'data', 'sets', 'related', 'plurality', 'spectacle', 'frame', 'models', 'sizes', 'system', 'according', 'claim', 'wherein', 'said', 'processing', 'unit', 'configured', 'operable', 'correlate', 'frames', 'parameters', 'ophthalmic', 'prescriptions', 'system', 'according', 'claims', 'wherein', 'said', 'processing', 'unit', 'configured', 'operable', 'correlate', 'frames', 'parameters', 'facial', 'features', 'system', 'according', 'claims', 'wherein', 'said', 'processing', 'unit', 'configured', 'operable', 'correlate', 'frames', 'parameters', 'eyewear', 'preferences', 'system', 'according', 'claims', 'comprising', 'server', 'least', 'one', 'computer', 'entity', 'linked', 'server', 'via', 'network', 'wherein', 'said', 'network', 'configured', 'receive', 'respond', 'requests', 'sent', 'across', 'network', 'transmitting', 'one', 'modules', 'computer', 'executable', 'program', 'instructions', 'displayable', 'data', 'network', 'connected', 'user', 'computer', 'platform', 'response', 'request', 'wherein', 'said', 'modules', 'include', 'modules', 'configured', 'receive', 'transmit', 'image', 'information', 'transmitting', 'frame', 'recommendation', 'optical', 'lens', 'option', 'recommendation', 'based', 'received', 'image', 'information', 'display', 'network', 'connected', 'user', 'computer', 'platform', 'computer', 'program', 'instructions', 'stored', 'local', 'storage', 'executed', 'processing', 'unit', 'cause', 'processing', 'unit', 'receive', 'data', 'indicative', 'scene', 'least', 'one', 'consumer', 'environment', 'identify', 'data', 'certain', 'consumer', 'identify', 'event', 'indicative', 'behavioral', 'compensation', 'vision', 'impairment', 'upon', 'identification', 'event', 'send', 'notification', 'relating', 'vision', 'impairment', 'computer', 'program', 'product', 'stored', 'tangible', 'computer', 'readable', 'medium', 'comprising', 'library', 'software', 'modules', 'cause', 'computer', 'executing', 'prompt', 'information', 'pertinent', 'least', 'one', 'eyeglasses', 'recommendation', 'optical', 'lens', 'option', 'recommendation', 'store', 'said', 'information', 'display', 'eyewear', 'recommendations', 'computer', 'program', 'product', 'claim', 'wherein', 'said', 'library', 'comprises', 'module', 'frame', 'selection', 'point', 'sales', 'advertising', 'computer', 'platform', 'facilitating', 'eye', 'glasses', 'marketing', 'selection', 'comprising', 'camera', 'processor', 'configured', 'execute', 'computer', 'program', 'instructions', 'cause', 'processor', 'take', 'image', 'consumer', 'identify', 'image', 'certain', 'consumer', 'identify', 'event', 'indicative', 'behavioral', 'compensation', 'vision', 'impairment', 'upon', 'identification', 'event', 'sending', 'notification', 'relating', 'vision', 'impairment', 'local', 'storage', 'processor', 'executable', 'instructions', 'carrying', 'storage', 'information', 'method', 'alerting', 'vision', 'impairment', 'said', 'method', 'comprising', 'identifying', 'certain', 'individual', 'scene', 'data', 'indicative', 'scene', 'least', 'one', 'consumer', 'environment', 'identifying', 'event', 'indicative', 'behavioral', 'compensation', 'vision', 'impairment', 'upon', 'identification', 'event', 'sending', 'notification', 'vision', 'impairment', 'method', 'claim', 'comprising', 'detecting', 'data', 'indicative', 'scene', 'least', 'one', 'consumer', 'retail', 'environment', 'method', 'claim', 'wherein', 'detecting', 'data', 'indicative', 'least', 'one', 'consumer', 'comprises', 'least', 'one', 'capturing', 'least', 'one', 'image', 'least', 'one', 'consumer', 'detecting', 'data', 'indicative', 'motion', 'consumer', 'tracking', 'eye', 'motion', 'consumer', 'method', 'claim', 'wherein', 'capturing', 'least', 'one', 'image', 'least', 'one', 'consumer', 'comprises', 'continuously', 'recording', 'scene', 'method', 'one', 'claims', 'comprising', 'identifying', 'data', 'consumer', \"'\", 'condition', 'including', 'data', 'indicative', 'consumer', \"'s\", 'position', 'location', 'relative', 'consumer', \"'s\", 'environment', 'said', 'data', 'comprising', 'least', 'one', 'consumer', \"'s\", 'face', 'posture', 'position', 'sound', 'motion', 'method', 'one', 'claims', 'wherein', 'said', 'event', 'comprises', 'least', 'one', 'position', 'orientation', 'head', 'increase', 'decrease', 'viewing', 'distance', 'consumer', 'viewed', 'object', 'changing', 'position', 'eyeglasses', 'worn', 'consumer', 'method', 'one', 'claims', 'wherein', 'identifying', 'event', 'comprises', 'identifying', 'images', 'image', 'feature', 'indicative', 'behavioral', 'compensation', 'performing', 'bruckner', 'test', 'performing', 'hirschberg', 'test', 'measuring', 'blink', 'countfrequency', 'method', 'claim', 'wherein', 'image', 'feature', 'indicative', 'behavioral', 'compensation', 'comprises', 'squinting', 'head', 'orientation', 'certain', 'distances', 'object', 'consumer', \"'s\", 'eyes', 'certain', 'position', 'eyeglasses', 'consumer', \"'s\", 'face', 'strabismus', 'cataracts', 'reflections', 'eye', 'method', 'one', 'claims', 'wherein', 'identifying', 'least', 'one', 'image', 'consumer', 'retail', 'environment', 'comprising', 'least', 'one', 'receiving', 'data', 'characterizing', 'retail', 'environment', 'performing', 'face', 'recognition', 'method', 'one', 'claims', 'wherein', 'sending', 'notification', 'comprising', 'sending', 'notification', 'least', 'one', 'identified', 'consumer', 'third', 'party', 'method', 'one', 'claims', 'wherein', 'notification', 'includes', 'least', 'one', 'data', 'indicative', 'identified', 'event', 'data', 'indicative', 'identified', 'consumer', 'ophthalmologic', 'recommendations', 'based', 'identified', 'event', 'lack', 'events', 'appointment', 'vision', 'test', 'method', 'one', 'claims', 'comprising', 'storing', 'least', 'one', 'reference', 'data', 'indicative', 'behavioral', 'compensation', 'vision', 'impairment', 'data', 'indicative', 'notification', 'data', 'indicative', 'follow-up', 'notification', 'method', 'claim', 'comprising', 'identifying', 'event', 'upon', 'comparison', 'detected', 'data', 'reference', 'data', 'determining', 'probability', 'vision', 'impairment', 'consumer', 'based', 'comparison', 'computer', 'program', 'intended', 'stored', 'memory', 'processor', 'unit', 'computer', 'system', 'removable', 'memory', 'medium', 'adapted', 'cooperate', 'reader', 'processor', 'unit', 'comprising', 'instructions', 'implementing', 'method', 'according', 'claims']\n"
     ]
    }
   ],
   "source": [
    "# we prepare a empty list, which will contain the words after the stopwords removal\n",
    "tokenized_vector_a = []\n",
    "\n",
    "# we iterate into the list of tokens obtained through the tokenization\n",
    "for token in tokenized_text_a:\n",
    "    # if a token is not a stopword, we insert it in the list\n",
    "    if token not in stopwords_en:\n",
    "        tokenized_vector_a.append(token)\n",
    "\n",
    "# the output is a list of all the tokens of the original text excluding the stopwords\n",
    "print(tokenized_vector_a)\n",
    "\n",
    "# we prepare a empty list, which will contain the words after the stopwords removal\n",
    "tokenized_vector_c = []\n",
    "\n",
    "# we iterate into the list of tokens obtained through the tokenization\n",
    "for token in tokenized_text_c:\n",
    "    # if a token is not a stopword, we insert it in the list\n",
    "    if token not in stopwords_en:\n",
    "        tokenized_vector_c.append(token)\n",
    "\n",
    "# the output is a list of all the tokens of the original text excluding the stopwords\n",
    "print(tokenized_vector_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d538983",
   "metadata": {},
   "source": [
    "### POS Analysis\n",
    "We now do the POS analysis: we use the pos tagging to assign each word to its pos tag, then we clean and simplify the pos text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ce410d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('electronic', 'JJ'), ('apparatus', 'NN'), ('including', 'VBG'), ('image', 'NN'), ('capturing', 'NN'), ('device', 'NN'), ('storage', 'NN'), ('device', 'NN'), ('processor', 'NN'), ('operation', 'NN'), ('method', 'NN'), ('thereof', 'NN'), ('provided', 'VBD'), ('image', 'NN'), ('capturing', 'VBG'), ('device', 'NN'), ('captures', 'NNS'), ('image', 'NN'), ('user', 'JJ'), ('storage', 'NN'), ('device', 'NN'), ('records', 'NNS'), ('plurality', 'NN'), ('modules', 'VBZ'), ('processor', 'NN'), ('coupled', 'VBN'), ('image', 'NN'), ('capturing', 'VBG'), ('device', 'JJ'), ('storage', 'NN'), ('device', 'NN'), ('configured', 'VBD'), ('configure', 'JJ'), ('image', 'NN'), ('capturing', 'VBG'), ('device', 'JJ'), ('capture', 'NN'), ('head', 'NN'), ('image', 'NN'), ('user', 'NN'), ('perform', 'VB'), ('face', 'NN'), ('recognition', 'NN'), ('operation', 'NN'), ('obtain', 'VB'), ('face', 'JJ'), ('region', 'NN'), ('detect', 'JJ'), ('plurality', 'NN'), ('facial', 'JJ'), ('landmarks', 'NNS'), ('within', 'IN'), ('face', 'NN'), ('region', 'NN'), ('estimate', 'NN'), ('head', 'NN'), ('posture', 'NN'), ('angle', 'VBZ'), ('user', 'RP'), ('according', 'VBG'), ('facial', 'JJ'), ('landmarks', 'NN'), ('calculate', 'NN'), ('gaze', 'NN'), ('position', 'NN'), ('user', 'NN'), ('gazes', 'VBZ'), ('screen', 'JJ'), ('according', 'VBG'), ('head', 'NN'), ('posture', 'NN'), ('angle', 'VBP'), ('plurality', 'NN'), ('rotation', 'NN'), ('reference', 'NN'), ('angle', 'NN'), ('plurality', 'NN'), ('predetermined', 'VBN'), ('calibration', 'NN'), ('positions', 'NNS'), ('configure', 'VBP'), ('screen', 'JJ'), ('display', 'NN'), ('corresponding', 'VBG'), ('visual', 'JJ'), ('effect', 'NN'), ('according', 'VBG'), ('gaze', 'NN'), ('positionthe', 'NN'), ('present', 'JJ'), ('disclosure', 'NN'), ('provides', 'VBZ'), ('computation', 'NN'), ('method', 'NN'), ('product', 'NN'), ('thereof', 'NN'), ('computation', 'NN'), ('method', 'NN'), ('adopts', 'NNS'), ('fusion', 'VBP'), ('method', 'JJ'), ('perform', 'NN'), ('machine', 'NN'), ('learning', 'VBG'), ('computations', 'NNS'), ('technical', 'JJ'), ('effects', 'NNS'), ('present', 'JJ'), ('disclosure', 'NN'), ('include', 'VBP'), ('fewer', 'JJR'), ('computations', 'NNS'), ('less', 'RBR'), ('power', 'NN'), ('consumptiona', 'NN'), ('method', 'NN'), ('detecting', 'VBG'), ('body', 'NN'), ('information', 'NN'), ('passengers', 'NNS'), ('vehicle', 'NN'), ('based', 'VBN'), ('humans', 'NNS'), (\"'\", 'POS'), ('status', 'NN'), ('recognition', 'NN'), ('provided', 'VBD'), ('method', 'NN'), ('includes', 'VBZ'), ('steps', 'NNS'), ('passenger', 'NN'), ('body', 'NN'), ('information-detecting', 'JJ'), ('device', 'NN'), ('inputting', 'VBG'), ('interior', 'JJ'), ('image', 'NN'), ('vehicle', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('network', 'NN'), ('detect', 'JJ'), ('faces', 'VBZ'), ('passengers', 'NNS'), ('output', 'NN'), ('passenger', 'NN'), ('feature', 'NN'), ('information', 'NN'), ('inputting', 'VBG'), ('interior', 'JJ'), ('image', 'NN'), ('body', 'NN'), ('recognition', 'NN'), ('network', 'NN'), ('detect', 'JJ'), ('bodies', 'NNS'), ('output', 'NN'), ('body-part', 'JJ'), ('length', 'NN'), ('information', 'NN'), ('b', 'NN'), ('retrieving', 'VBG'), ('specific', 'JJ'), ('height', 'JJ'), ('mapping', 'NN'), ('information', 'NN'), ('referring', 'VBG'), ('height', 'NN'), ('mapping', 'VBG'), ('table', 'JJ'), ('ratios', 'NNS'), ('segment', 'NN'), ('body', 'NN'), ('portions', 'NNS'), ('human', 'JJ'), ('groups', 'NNS'), ('heights', 'NNS'), ('per', 'IN'), ('human', 'JJ'), ('groups', 'NNS'), ('acquiring', 'VBG'), ('specific', 'JJ'), ('height', 'NN'), ('specific', 'JJ'), ('passenger', 'NN'), ('retrieving', 'VBG'), ('specific', 'JJ'), ('weight', 'NN'), ('mapping', 'VBG'), ('information', 'NN'), ('weight', 'NN'), ('mapping', 'NN'), ('table', 'JJ'), ('correlations', 'NNS'), ('heights', 'NNS'), ('weights', 'NNS'), ('per', 'IN'), ('human', 'JJ'), ('groups', 'NNS'), ('acquiring', 'VBG'), ('weight', 'NN'), ('specific', 'JJ'), ('passenger', 'NN'), ('referring', 'VBG'), ('specific', 'JJ'), ('heighttechniques', 'NNS'), ('related', 'VBN'), ('improved', 'JJ'), ('video', 'NN'), ('coding', 'VBG'), ('based', 'VBN'), ('face', 'NN'), ('detection', 'NN'), ('region', 'NN'), ('extraction', 'NN'), ('tracking', 'VBG'), ('discussed', 'VBN'), ('techniques', 'NNS'), ('may', 'MD'), ('include', 'VB'), ('performing', 'VBG'), ('facial', 'JJ'), ('search', 'NN'), ('video', 'NN'), ('frame', 'NN'), ('determine', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('regions', 'NNS'), ('video', 'VBP'), ('frame', 'JJ'), ('testing', 'VBG'), ('candidate', 'NN'), ('face', 'NN'), ('regions', 'NNS'), ('based', 'VBN'), ('skin', 'JJ'), ('tone', 'NN'), ('information', 'NN'), ('determine', 'NN'), ('valid', 'NN'), ('invalid', 'JJ'), ('face', 'NN'), ('regions', 'NNS'), ('rejecting', 'VBG'), ('invalid', 'JJ'), ('face', 'NN'), ('regions', 'NNS'), ('encoding', 'VBG'), ('video', 'NN'), ('frame', 'NN'), ('based', 'VBN'), ('valid', 'JJ'), ('face', 'NN'), ('regions', 'NNS'), ('generate', 'VBP'), ('coded', 'VBN'), ('bitstreama', 'NN'), ('method', 'NN'), ('managing', 'VBG'), ('smart', 'JJ'), ('database', 'NN'), ('stores', 'NNS'), ('facial', 'JJ'), ('images', 'NNS'), ('face', 'VBP'), ('recognition', 'NN'), ('provided', 'VBN'), ('method', 'NN'), ('includes', 'VBZ'), ('steps', 'NNS'), ('managing', 'VBG'), ('device', 'NN'), ('counting', 'VBG'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('corresponding', 'VBG'), ('specific', 'JJ'), ('person', 'NN'), ('smart', 'JJ'), ('database', 'NN'), ('new', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('continuously', 'RB'), ('stored', 'VBD'), ('determining', 'VBG'), ('whether', 'IN'), ('first', 'JJ'), ('counted', 'VBN'), ('value', 'NN'), ('representing', 'VBG'), ('count', 'NN'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('satisfies', 'NNS'), ('first', 'RB'), ('set', 'VBN'), ('value', 'NN'), ('b', 'NN'), ('first', 'RB'), ('counted', 'VBD'), ('value', 'NN'), ('satisfies', 'NNS'), ('first', 'RB'), ('set', 'VBN'), ('value', 'NN'), ('inputting', 'VBG'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('neural', 'JJ'), ('aggregation', 'NN'), ('network', 'NN'), ('generate', 'VBP'), ('quality', 'NN'), ('scores', 'NNS'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('aggregation', 'VBP'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('second', 'VBP'), ('counted', 'VBN'), ('value', 'NN'), ('representing', 'VBG'), ('count', 'NN'), ('specific', 'JJ'), ('quality', 'NN'), ('scores', 'NNS'), ('among', 'IN'), ('quality', 'NN'), ('scores', 'NNS'), ('highest', 'JJS'), ('counting', 'VBG'), ('thereof', 'JJ'), ('satisfies', 'NNS'), ('second', 'VBP'), ('set', 'VBN'), ('value', 'NN'), ('deleting', 'VBG'), ('part', 'NN'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('corresponding', 'VBG'), ('uncounted', 'JJ'), ('quality', 'NN'), ('scores', 'NNS'), ('smart', 'VBP'), ('databasea', 'NN'), ('system', 'NN'), ('capable', 'JJ'), ('determining', 'VBG'), ('recognition', 'NN'), ('algorithms', 'NNS'), ('applied', 'VBD'), ('regions', 'NNS'), ('interest', 'NN'), ('within', 'IN'), ('digital', 'JJ'), ('representations', 'NNS'), ('presented', 'VBD'), ('preprocessing', 'VBG'), ('module', 'NN'), ('utilizes', 'IN'), ('one', 'CD'), ('feature', 'NN'), ('identification', 'NN'), ('algorithms', 'FW'), ('determine', 'NN'), ('regions', 'NNS'), ('interest', 'NN'), ('based', 'VBN'), ('feature', 'NN'), ('density', 'NN'), ('preprocessing', 'VBG'), ('modules', 'NNS'), ('leverages', 'VBZ'), ('feature', 'VBP'), ('density', 'NN'), ('signature', 'NN'), ('region', 'NN'), ('determine', 'NN'), ('plurality', 'NN'), ('diverse', 'JJ'), ('recognition', 'NN'), ('modules', 'NNS'), ('operate', 'VBP'), ('region', 'NN'), ('interest', 'NN'), ('specific', 'JJ'), ('embodiment', 'NN'), ('focuses', 'NNS'), ('structured', 'VBD'), ('documents', 'NNS'), ('also', 'RB'), ('presented', 'VBD'), ('disclosed', 'JJ'), ('approach', 'NN'), ('enhanced', 'VBD'), ('addition', 'NN'), ('object', 'NN'), ('classifier', 'NN'), ('classifies', 'NNS'), ('types', 'VBZ'), ('objects', 'NNS'), ('found', 'VBN'), ('regions', 'NNS'), ('interestdisclosed', 'VBN'), ('mobile', 'JJ'), ('terminal', 'NN'), ('mobile', 'JJ'), ('terminal', 'NN'), ('may', 'MD'), ('include', 'VB'), ('front', 'JJ'), ('camera', 'NN'), ('obtaining', 'VBG'), ('face', 'NN'), ('image', 'NN'), ('user', 'JJ'), ('glance', 'NN'), ('sensor', 'NN'), ('tilted', 'VBD'), ('certain', 'JJ'), ('angle', 'NN'), ('disposed', 'VBD'), ('adjacent', 'JJ'), ('front', 'JJ'), ('camera', 'NN'), ('obtain', 'VB'), ('metadata', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('controller', 'NN'), ('obtaining', 'VBG'), ('distance', 'NN'), ('glance', 'NN'), ('sensor', 'NN'), ('front', 'NN'), ('camera', 'NN'), ('distance', 'NN'), ('enabling', 'VBG'), ('area', 'NN'), ('overlap', 'IN'), ('region', 'NN'), ('first', 'JJ'), ('region', 'NN'), ('representing', 'VBG'), ('range', 'NN'), ('photographable', 'JJ'), ('front', 'NN'), ('camera', 'NN'), ('overlaps', 'VBZ'), ('second', 'JJ'), ('region', 'NN'), ('representing', 'VBG'), ('range', 'NN'), ('photographable', 'JJ'), ('glance', 'NN'), ('sensor', 'NN'), ('maximumthis', 'NN'), ('disclosure', 'NN'), ('provides', 'VBZ'), ('systems', 'NNS'), ('methods', 'NNS'), ('apparatus', 'RB'), ('including', 'VBG'), ('computer', 'NN'), ('programs', 'NNS'), ('encoded', 'VBD'), ('computer', 'NN'), ('storage', 'NN'), ('media', 'NNS'), ('intelligent', 'JJ'), ('routing', 'VBG'), ('notifications', 'NNS'), ('related', 'JJ'), ('media', 'NNS'), ('programming', 'VBG'), ('one', 'CD'), ('aspect', 'JJ'), ('smart', 'JJ'), ('television', 'NN'), ('tv', 'NN'), ('implemented', 'VBD'), ('track', 'RP'), ('user', 'NN'), (\"'s\", 'POS'), ('tv', 'NN'), ('watching', 'VBG'), ('behavior', 'JJ'), ('anticipate', 'NN'), ('programming', 'NN'), ('based', 'VBN'), ('behavior', 'JJ'), ('aspects', 'NNS'), ('smart', 'JJ'), ('tv', 'NN'), ('implemented', 'VBN'), ('detect', 'JJ'), ('user', 'NN'), (\"'s\", 'POS'), ('presence', 'NN'), ('based', 'VBN'), ('detection', 'NN'), ('automatically', 'RB'), ('change', 'JJ'), ('tv', 'NN'), ('channel', 'NN'), ('media', 'NNS'), ('programming', 'VBG'), ('analyzed', 'VBN'), ('desirable', 'JJ'), ('user', 'JJ'), ('aspects', 'NNS'), ('smart', 'JJ'), ('tv', 'NN'), ('implemented', 'VBD'), ('transmit', 'NN'), ('notification', 'NN'), ('instructions', 'NNS'), ('electronic', 'JJ'), ('devices', 'NNS'), ('within', 'IN'), ('network', 'NN'), ('attempt', 'NN'), ('alert', 'IN'), ('user', 'NN'), ('upcoming', 'JJ'), ('media', 'NNS'), ('programming', 'VBG'), ('additionally', 'RB'), ('smart', 'JJ'), ('tv', 'NN'), ('implemented', 'VBD'), ('transmit', 'NN'), ('detection', 'NN'), ('instructions', 'NNS'), ('electronic', 'JJ'), ('devices', 'NNS'), ('within', 'IN'), ('network', 'NN'), ('whereby', 'WRB'), ('electronic', 'JJ'), ('devices', 'NNS'), ('attempt', 'VBP'), ('detect', 'JJ'), ('user', 'NN'), (\"'s\", 'POS'), ('presence', 'NN'), ('voice', 'NN'), ('facial', 'JJ'), ('recognitiona', 'NN'), ('camera', 'NN'), ('configured', 'VBD'), ('output', 'NN'), ('test', 'NN'), ('depth+multi-spectral', 'JJ'), ('image', 'NN'), ('including', 'VBG'), ('plurality', 'NN'), ('pixels', 'NNS'), ('pixel', 'VBP'), ('corresponds', 'VBZ'), ('one', 'CD'), ('plurality', 'NN'), ('sensors', 'NNS'), ('sensor', 'VBP'), ('array', 'JJ'), ('camera', 'NN'), ('includes', 'VBZ'), ('least', 'JJS'), ('depth', 'JJ'), ('value', 'NN'), ('spectral', 'JJ'), ('value', 'NN'), ('spectral', 'JJ'), ('light', 'JJ'), ('sub-band', 'JJ'), ('plurality', 'NN'), ('spectral', 'JJ'), ('illuminators', 'NNS'), ('camera', 'VBP'), ('face', 'NN'), ('recognition', 'NN'), ('machine', 'NN'), ('previously', 'RB'), ('trained', 'VBN'), ('set', 'VBN'), ('labeled', 'JJ'), ('training', 'NN'), ('depth+multi-spectral', 'JJ'), ('images', 'NNS'), ('structure', 'NN'), ('test', 'NN'), ('depth+multi-spectral', 'JJ'), ('image', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('machine', 'NN'), ('configured', 'VBD'), ('output', 'NN'), ('confidence', 'NN'), ('value', 'NN'), ('indicating', 'VBG'), ('likelihood', 'JJ'), ('test', 'NN'), ('depth+multi-spectral', 'JJ'), ('image', 'NN'), ('includes', 'VBZ'), ('faceembodiments', 'NNS'), ('present', 'JJ'), ('disclosure', 'NN'), ('relate', 'NN'), ('image', 'NN'), ('processing', 'NN'), ('method', 'NN'), ('apparatus', 'NN'), ('electronic', 'JJ'), ('device', 'NN'), ('method', 'NN'), ('includes', 'VBZ'), ('acquiring', 'VBG'), ('photo', 'NN'), ('album', 'NN'), ('obtained', 'VBD'), ('face', 'NN'), ('clustering', 'VBG'), ('collecting', 'VBG'), ('face', 'NN'), ('information', 'NN'), ('respective', 'JJ'), ('images', 'NNS'), ('photo', 'VBP'), ('album', 'IN'), ('acquiring', 'VBG'), ('face', 'NN'), ('parameter', 'NN'), ('image', 'NN'), ('according', 'VBG'), ('face', 'NN'), ('information', 'NN'), ('selecting', 'VBG'), ('cover', 'NN'), ('image', 'NN'), ('according', 'VBG'), ('face', 'NN'), ('parameter', 'NN'), ('image', 'NN'), ('taking', 'VBG'), ('face-region', 'JJ'), ('image', 'NN'), ('cover', 'NN'), ('image', 'NN'), ('setting', 'VBG'), ('face-region', 'JJ'), ('image', 'NN'), ('cover', 'NN'), ('photo', 'NN'), ('albumtechniques', 'NNS'), ('described', 'VBD'), ('herein', 'JJ'), ('provide', 'IN'), ('location-based', 'JJ'), ('access', 'NN'), ('control', 'NN'), ('secured', 'VBD'), ('resources', 'NNS'), ('generally', 'RB'), ('described', 'VBN'), ('configurations', 'NNS'), ('disclosed', 'VBD'), ('herein', 'RBR'), ('enable', 'JJ'), ('system', 'NN'), ('dynamically', 'RB'), ('modify', 'JJ'), ('access', 'NN'), ('secured', 'VBD'), ('resources', 'NNS'), ('based', 'VBN'), ('one', 'CD'), ('location-related', 'JJ'), ('actions', 'NNS'), ('example', 'NN'), ('techniques', 'NNS'), ('disclosed', 'VBN'), ('herein', 'RB'), ('enable', 'JJ'), ('computing', 'VBG'), ('system', 'NN'), ('control', 'NN'), ('access', 'NN'), ('resources', 'NNS'), ('computing', 'VBG'), ('devices', 'NNS'), ('display', 'NN'), ('devices', 'NNS'), ('secured', 'VBD'), ('locations', 'NNS'), ('secured', 'VBN'), ('data', 'NNS'), ('configurations', 'NNS'), ('techniques', 'NNS'), ('disclosed', 'VBD'), ('herein', 'RBR'), ('enable', 'JJ'), ('controlled', 'JJ'), ('access', 'NN'), ('secured', 'VBD'), ('resources', 'NNS'), ('based', 'VBN'), ('least', 'JJS'), ('part', 'NN'), ('invitation', 'NN'), ('associated', 'VBN'), ('location', 'NN'), ('positioning', 'VBG'), ('data', 'NNS'), ('indicating', 'VBG'), ('location', 'NN'), ('userone', 'JJ'), ('embodiment', 'NN'), ('provides', 'VBZ'), ('method', 'JJ'), ('comprising', 'VBG'), ('receiving', 'VBG'), ('piece', 'NN'), ('content', 'NN'), ('salient', 'NN'), ('moments', 'NNS'), ('data', 'NNS'), ('piece', 'NN'), ('content', 'NN'), ('method', 'NN'), ('comprises', 'NNS'), ('based', 'VBN'), ('salient', 'JJ'), ('moments', 'NNS'), ('data', 'NNS'), ('determining', 'VBG'), ('first', 'JJ'), ('path', 'NN'), ('viewport', 'NN'), ('piece', 'NN'), ('content', 'NN'), ('method', 'NN'), ('comprises', 'VBZ'), ('displaying', 'VBG'), ('viewport', 'NN'), ('display', 'NN'), ('device', 'NN'), ('movement', 'NN'), ('viewport', 'NN'), ('based', 'VBN'), ('first', 'JJ'), ('path', 'NN'), ('playback', 'NN'), ('piece', 'NN'), ('content', 'NN'), ('method', 'NN'), ('comprises', 'VBZ'), ('generating', 'VBG'), ('augmentation', 'NN'), ('salient', 'JJ'), ('moment', 'NN'), ('occurring', 'VBG'), ('piece', 'NN'), ('content', 'NN'), ('presenting', 'VBG'), ('augmentation', 'NN'), ('viewport', 'NN'), ('portion', 'NN'), ('playback', 'NN'), ('augmentation', 'NN'), ('comprises', 'VBZ'), ('interactive', 'JJ'), ('hint', 'NN'), ('guiding', 'VBG'), ('viewport', 'NN'), ('salient', 'NN'), ('momenta', 'VBD'), ('computer-implemented', 'JJ'), ('method', 'NN'), ('system', 'NN'), ('computer', 'NN'), ('program', 'NN'), ('product', 'NN'), ('provided', 'VBD'), ('facial', 'JJ'), ('recognition', 'NN'), ('method', 'NN'), ('includes', 'VBZ'), ('receiving', 'VBG'), ('processor', 'NN'), ('device', 'NN'), ('plurality', 'NN'), ('images', 'NNS'), ('method', 'VBP'), ('also', 'RB'), ('includes', 'VBZ'), ('extracting', 'VBG'), ('processor', 'NN'), ('device', 'NN'), ('feature', 'NN'), ('extractor', 'NN'), ('utilizing', 'JJ'), ('convolutional', 'JJ'), ('neural', 'JJ'), ('network', 'NN'), ('cnn', 'NNS'), ('enlarged', 'VBD'), ('intra-class', 'JJ'), ('variance', 'NN'), ('long-tail', 'JJ'), ('classes', 'NNS'), ('feature', 'VBP'), ('vectors', 'NNS'), ('plurality', 'NN'), ('images', 'NNS'), ('method', 'VBP'), ('additionally', 'RB'), ('includes', 'VBZ'), ('generating', 'VBG'), ('processor', 'NN'), ('device', 'NN'), ('feature', 'NN'), ('generator', 'NN'), ('discriminative', 'JJ'), ('feature', 'NN'), ('vectors', 'NNS'), ('feature', 'VBP'), ('vectors', 'NNS'), ('method', 'VBP'), ('includes', 'VBZ'), ('classifying', 'VBG'), ('processor', 'NN'), ('device', 'NN'), ('utilizing', 'VBG'), ('fully', 'RB'), ('connected', 'VBN'), ('classifier', 'JJR'), ('identity', 'NN'), ('discriminative', 'JJ'), ('feature', 'NN'), ('vector', 'NN'), ('method', 'NN'), ('also', 'RB'), ('includes', 'VBZ'), ('control', 'NN'), ('operation', 'NN'), ('processor-based', 'JJ'), ('machine', 'NN'), ('react', 'NN'), ('accordance', 'NN'), ('identitysome', 'JJ'), ('embodiments', 'NNS'), ('invention', 'NN'), ('provide', 'VBP'), ('efficient', 'JJ'), ('expressive', 'JJ'), ('machine-trained', 'JJ'), ('networks', 'NNS'), ('performing', 'VBG'), ('machine', 'NN'), ('learning', 'VBG'), ('machine-trained', 'JJ'), ('mt', 'NN'), ('networks', 'NNS'), ('embodiments', 'NNS'), ('use', 'VBP'), ('novel', 'JJ'), ('processing', 'NN'), ('nodes', 'NNS'), ('novel', 'JJ'), ('activation', 'NN'), ('functions', 'NNS'), ('allow', 'VBP'), ('mt', 'NN'), ('network', 'NN'), ('efficiently', 'RB'), ('define', 'VBZ'), ('fewer', 'JJR'), ('processing', 'NN'), ('node', 'NN'), ('layers', 'NNS'), ('complex', 'JJ'), ('mathematical', 'JJ'), ('expression', 'NN'), ('solves', 'VBZ'), ('particular', 'JJ'), ('problem', 'NN'), ('eg', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('speech', 'NN'), ('recognition', 'NN'), ('etc', 'FW'), ('embodiments', 'NNS'), ('activation', 'NN'), ('function', 'NN'), ('eg', 'FW'), ('cup', 'NN'), ('function', 'NN'), ('used', 'VBN'), ('numerous', 'JJ'), ('processing', 'VBG'), ('nodes', 'NNS'), ('mt', 'JJ'), ('network', 'NN'), ('machine', 'NN'), ('learning', 'VBG'), ('activation', 'NN'), ('function', 'NN'), ('configured', 'VBD'), ('differently', 'RB'), ('different', 'JJ'), ('processing', 'VBG'), ('nodes', 'NNS'), ('different', 'JJ'), ('nodes', 'NNS'), ('emulate', 'VBP'), ('implement', 'JJ'), ('two', 'CD'), ('different', 'JJ'), ('functions', 'NNS'), ('eg', 'VBP'), ('two', 'CD'), ('boolean', 'JJ'), ('logical', 'JJ'), ('operators', 'NNS'), ('xor', 'VBP'), ('activation', 'NN'), ('function', 'NN'), ('embodiments', 'NNS'), ('periodic', 'JJ'), ('function', 'NN'), ('configured', 'VBD'), ('implement', 'JJ'), ('different', 'JJ'), ('functions', 'NNS'), ('eg', 'VBP'), ('different', 'JJ'), ('sinusoidal', 'JJ'), ('functionsmethods', 'NNS'), ('systems', 'NNS'), ('may', 'MD'), ('provide', 'VB'), ('facial', 'JJ'), ('recognition', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('input', 'NN'), ('image', 'NN'), ('utilizing', 'JJ'), ('hierarchical', 'JJ'), ('feature', 'NN'), ('learning', 'VBG'), ('pair-wise', 'JJ'), ('classification', 'NN'), ('receptive', 'JJ'), ('field', 'NN'), ('theory', 'NN'), ('may', 'MD'), ('used', 'VBN'), ('input', 'VB'), ('image', 'NN'), ('generate', 'JJ'), ('pre-processed', 'JJ'), ('multi-channel', 'JJ'), ('image', 'NN'), ('channels', 'NNS'), ('pre-processed', 'JJ'), ('image', 'NN'), ('may', 'MD'), ('activated', 'VB'), ('based', 'VBN'), ('amount', 'NN'), ('feature', 'NN'), ('rich', 'JJ'), ('details', 'NNS'), ('within', 'IN'), ('channels', 'NNS'), ('similarly', 'RB'), ('local', 'JJ'), ('patches', 'NNS'), ('may', 'MD'), ('activated', 'VB'), ('based', 'VBN'), ('discriminant', 'JJ'), ('features', 'NNS'), ('within', 'IN'), ('local', 'JJ'), ('patches', 'NNS'), ('features', 'NNS'), ('may', 'MD'), ('extracted', 'VB'), ('local', 'JJ'), ('patches', 'NNS'), ('discriminant', 'JJ'), ('features', 'NNS'), ('may', 'MD'), ('selected', 'VBN'), ('order', 'NN'), ('perform', 'NN'), ('feature', 'NN'), ('matching', 'VBG'), ('pair', 'NN'), ('sets', 'NNS'), ('system', 'NN'), ('may', 'MD'), ('utilize', 'VB'), ('patch', 'NN'), ('feature', 'NN'), ('pooling', 'VBG'), ('pair-wise', 'JJ'), ('matching', 'JJ'), ('large-scale', 'JJ'), ('training', 'NN'), ('order', 'NN'), ('quickly', 'RB'), ('accurately', 'RB'), ('perform', 'JJ'), ('facial', 'JJ'), ('recognition', 'NN'), ('low', 'JJ'), ('cost', 'NN'), ('system', 'NN'), ('memory', 'NN'), ('computationa', 'NN'), ('method', 'NN'), ('controlling', 'VBG'), ('terminal', 'NN'), ('provided', 'VBD'), ('terminal', 'JJ'), ('includes', 'VBZ'), ('capturing', 'VBG'), ('apparatus', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('processor', 'NN'), ('image', 'NN'), ('acquired', 'VBD'), ('capturing', 'VBG'), ('apparatus', 'NN'), ('motion', 'NN'), ('parameter', 'NN'), ('terminal', 'NN'), ('obtained', 'VBN'), ('image', 'NN'), ('processing', 'NN'), ('acquired', 'VBD'), ('image', 'NN'), ('controlled', 'VBN'), ('performed', 'VBD'), ('based', 'VBN'), ('motion', 'NN'), ('parameter', 'NN'), ('equal', 'JJ'), ('less', 'RBR'), ('preset', 'JJ'), ('parameter', 'NN'), ('threshold', 'NN'), ('skipped', 'VBD'), ('based', 'VBN'), ('motion', 'NN'), ('parameter', 'NN'), ('greater', 'JJR'), ('preset', 'NN'), ('parameter', 'NN'), ('thresholda', 'VBD'), ('drive-through', 'JJ'), ('order', 'NN'), ('processing', 'NN'), ('method', 'NN'), ('apparatus', 'NN'), ('disclosed', 'VBD'), ('drive-through', 'JJ'), ('order', 'NN'), ('processing', 'NN'), ('method', 'NN'), ('includes', 'VBZ'), ('receiving', 'VBG'), ('customer', 'NN'), ('information', 'NN'), ('detected', 'VBN'), ('vision', 'NN'), ('recognition', 'NN'), ('providing', 'VBG'), ('product', 'NN'), ('information', 'NN'), ('based', 'VBN'), ('customer', 'NN'), ('information', 'NN'), ('processing', 'VBG'), ('product', 'NN'), ('order', 'NN'), ('customer', 'NN'), ('according', 'VBG'), ('present', 'JJ'), ('disclosure', 'NN'), ('possible', 'JJ'), ('rapidly', 'RB'), ('process', 'JJ'), ('order', 'NN'), ('using', 'VBG'), ('customer', 'NN'), ('information', 'NN'), ('based', 'VBN'), ('customer', 'NN'), ('recognition', 'NN'), ('using', 'VBG'), ('artificial', 'JJ'), ('intelligence', 'NN'), ('ai', 'JJ'), ('model', 'NN'), ('machine', 'NN'), ('learning', 'VBG'), ('g', 'JJ'), ('networkan', 'JJ'), ('image', 'NN'), ('processing', 'NN'), ('method', 'NN'), ('performed', 'VBD'), ('computing', 'VBG'), ('device', 'NN'), ('includes', 'VBZ'), ('identifying', 'VBG'), ('using', 'VBG'), ('face', 'NN'), ('recognition', 'NN'), ('one', 'CD'), ('faces', 'VBZ'), ('face', 'NN'), ('corresponding', 'VBG'), ('respective', 'JJ'), ('person', 'NN'), ('captured', 'VBD'), ('first', 'JJ'), ('image', 'NN'), ('identified', 'VBN'), ('face', 'NN'), ('extracting', 'VBG'), ('set', 'VBN'), ('profile', 'JJ'), ('parameters', 'NNS'), ('corresponding', 'VBG'), ('person', 'NN'), ('first', 'JJ'), ('image', 'NN'), ('selecting', 'VBG'), ('plurality', 'NN'), ('image', 'NN'), ('tiles', 'NNS'), ('first', 'RB'), ('image', 'NN'), ('tile', 'NN'), ('matches', 'NNS'), ('face', 'VBP'), ('corresponding', 'VBG'), ('person', 'NN'), ('first', 'JJ'), ('image', 'NN'), ('accordance', 'NN'), ('predefined', 'VBD'), ('correspondence', 'NN'), ('set', 'VBN'), ('profile', 'JJ'), ('parameters', 'NNS'), ('corresponding', 'VBG'), ('person', 'NN'), ('set', 'VBN'), ('pre-stored', 'JJ'), ('description', 'NN'), ('parameters', 'NNS'), ('first', 'JJ'), ('image', 'NN'), ('tile', 'NN'), ('generating', 'VBG'), ('second', 'JJ'), ('image', 'NN'), ('covering', 'VBG'), ('faces', 'VBZ'), ('respective', 'JJ'), ('persons', 'NNS'), ('first', 'JJ'), ('image', 'NN'), ('corresponding', 'VBG'), ('first', 'JJ'), ('image', 'NN'), ('tiles', 'NNS'), ('sharing', 'VBG'), ('first', 'JJ'), ('image', 'NN'), ('second', 'JJ'), ('image', 'NN'), ('predefined', 'VBD'), ('order', 'NN'), ('via', 'IN'), ('group', 'NN'), ('chat', 'WP'), ('sessionin', 'VBZ'), ('one', 'CD'), ('embodiment', 'NN'), ('artificial', 'JJ'), ('reality', 'NN'), ('system', 'NN'), ('determines', 'VBZ'), ('performance', 'NN'), ('metric', 'JJ'), ('eye', 'NN'), ('tracking', 'VBG'), ('system', 'NN'), ('first', 'JJ'), ('performance', 'NN'), ('threshold', 'NN'), ('eye', 'NN'), ('tracking', 'VBG'), ('system', 'NN'), ('associated', 'VBN'), ('head-mounted', 'JJ'), ('display', 'NN'), ('worn', 'VBN'), ('user', 'JJ'), ('artificial', 'JJ'), ('reality', 'NN'), ('system', 'NN'), ('receives', 'VBZ'), ('first', 'RB'), ('inputs', 'NNS'), ('associated', 'VBN'), ('body', 'NN'), ('user', 'JJ'), ('determines', 'NNS'), ('region', 'NN'), ('user', 'IN'), ('looking', 'VBG'), ('within', 'IN'), ('field', 'NN'), ('view', 'NN'), ('head-mounted', 'JJ'), ('display', 'NN'), ('based', 'VBN'), ('received', 'VBD'), ('first', 'RB'), ('inputs', 'JJ'), ('system', 'NN'), ('determines', 'VBZ'), ('vergence', 'NN'), ('distance', 'NN'), ('user', 'NN'), ('based', 'VBN'), ('least', 'JJS'), ('first', 'JJ'), ('inputs', 'NNS'), ('associated', 'VBN'), ('body', 'NN'), ('user', 'JJ'), ('region', 'NN'), ('user', 'IN'), ('looking', 'VBG'), ('locations', 'NNS'), ('one', 'CD'), ('objects', 'VBZ'), ('scene', 'NN'), ('displayed', 'VBD'), ('head-mounted', 'JJ'), ('display', 'NN'), ('system', 'NN'), ('adjusts', 'VBZ'), ('one', 'CD'), ('configurations', 'NNS'), ('head-mounted', 'JJ'), ('display', 'NN'), ('based', 'VBN'), ('determined', 'JJ'), ('vergence', 'NN'), ('distance', 'NN'), ('usera', 'JJ'), ('computer-implemented', 'JJ'), ('method', 'NN'), ('provided', 'VBD'), ('image-based', 'JJ'), ('self-guided', 'JJ'), ('object', 'JJ'), ('detection', 'NN'), ('method', 'NN'), ('includes', 'VBZ'), ('receiving', 'VBG'), ('processor', 'NN'), ('device', 'NN'), ('set', 'VBN'), ('images', 'NNS'), ('images', 'NNS'), ('respective', 'VBP'), ('grid', 'JJ'), ('thereon', 'NN'), ('labeled', 'VBD'), ('regarding', 'VBG'), ('respective', 'JJ'), ('object', 'NN'), ('detected', 'VBD'), ('using', 'VBG'), ('grid', 'JJ'), ('level', 'NN'), ('label', 'NN'), ('data', 'NNS'), ('method', 'NN'), ('includes', 'VBZ'), ('training', 'VBG'), ('processor', 'JJ'), ('device', 'NN'), ('grid-based', 'JJ'), ('object', 'NN'), ('detector', 'NN'), ('using', 'VBG'), ('grid', 'JJ'), ('level', 'NN'), ('label', 'NN'), ('data', 'NNS'), ('method', 'NN'), ('also', 'RB'), ('includes', 'VBZ'), ('determining', 'VBG'), ('processor', 'NN'), ('device', 'NN'), ('respective', 'NN'), ('bounding', 'VBG'), ('box', 'NN'), ('respective', 'JJ'), ('object', 'JJ'), ('images', 'NNS'), ('applying', 'VBG'), ('local', 'JJ'), ('segmentation', 'NN'), ('images', 'NNS'), ('method', 'VBP'), ('additionally', 'RB'), ('includes', 'VBZ'), ('training', 'NN'), ('processor', 'NN'), ('device', 'NN'), ('region-based', 'JJ'), ('convolutional', 'JJ'), ('neural', 'JJ'), ('network', 'NN'), ('rcnn', 'NN'), ('joint', 'NN'), ('object', 'JJ'), ('localization', 'NN'), ('object', 'NN'), ('classification', 'NN'), ('using', 'VBG'), ('respective', 'JJ'), ('bounding', 'NN'), ('box', 'NN'), ('respective', 'JJ'), ('object', 'JJ'), ('images', 'NNS'), ('input', 'VBP'), ('rcnna', 'JJ'), ('system', 'NN'), ('method', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('comprising', 'VBG'), ('multiple', 'JJ'), ('phases', 'NNS'), ('implemented', 'VBN'), ('parallel', 'JJ'), ('architecture', 'NN'), ('first', 'JJ'), ('phase', 'NN'), ('normalization', 'NN'), ('phase', 'NN'), ('whereby', 'NN'), ('captured', 'VBD'), ('image', 'NN'), ('normalized', 'VBN'), ('size', 'NN'), ('orientation', 'NN'), ('illumination', 'NN'), ('stored', 'VBD'), ('images', 'NNS'), ('preexisting', 'VBG'), ('database', 'JJ'), ('second', 'JJ'), ('phase', 'NN'), ('feature', 'NN'), ('extractiondistance', 'NN'), ('matrix', 'NN'), ('phase', 'NN'), ('distance', 'NN'), ('matrix', 'NN'), ('generated', 'VBD'), ('captured', 'JJ'), ('image', 'NN'), ('coarse', 'NN'), ('recognition', 'NN'), ('phase', 'NN'), ('generated', 'VBD'), ('distance', 'NN'), ('matrix', 'NNS'), ('compared', 'VBN'), ('distance', 'NN'), ('matrices', 'NNS'), ('database', 'VBP'), ('using', 'VBG'), ('euclidean', 'JJ'), ('distance', 'NN'), ('matches', 'NNS'), ('create', 'VBP'), ('candidate', 'NN'), ('lists', 'NNS'), ('detailed', 'VBD'), ('recognition', 'NN'), ('phase', 'NN'), ('multiple', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('algorithms', 'RB'), ('applied', 'JJ'), ('candidate', 'NN'), ('lists', 'NNS'), ('produce', 'VBP'), ('final', 'JJ'), ('result', 'NN'), ('distance', 'NN'), ('matrices', 'NNS'), ('normalized', 'JJ'), ('database', 'NN'), ('may', 'MD'), ('broken', 'VB'), ('parallel', 'JJ'), ('lists', 'NNS'), ('parallelization', 'VBP'), ('feature', 'NN'), ('extractiondistance', 'NN'), ('matrix', 'NN'), ('phase', 'NN'), ('candidate', 'NN'), ('lists', 'NNS'), ('may', 'MD'), ('also', 'RB'), ('grouped', 'VB'), ('according', 'VBG'), ('dissimilarity', 'NN'), ('algorithm', 'NN'), ('parallel', 'NN'), ('processing', 'NN'), ('detailed', 'JJ'), ('recognition', 'NN'), ('phasean', 'JJ'), ('imaging', 'NN'), ('device', 'NN'), ('including', 'VBG'), ('pixel', 'JJ'), ('matrix', 'NN'), ('processor', 'NN'), ('provided', 'VBD'), ('pixel', 'JJ'), ('matrix', 'NN'), ('includes', 'VBZ'), ('plurality', 'NN'), ('phase', 'NN'), ('detection', 'NN'), ('pixels', 'NNS'), ('plurality', 'NN'), ('regular', 'JJ'), ('pixels', 'NNS'), ('processor', 'NN'), ('performs', 'NNS'), ('autofocusing', 'VBG'), ('according', 'VBG'), ('pixel', 'NN'), ('data', 'NNS'), ('phase', 'NN'), ('detection', 'NN'), ('pixels', 'NNS'), ('determines', 'VBZ'), ('operating', 'VBG'), ('resolution', 'NN'), ('regular', 'JJ'), ('pixels', 'NNS'), ('according', 'VBG'), ('autofocused', 'JJ'), ('pixel', 'NN'), ('data', 'NNS'), ('phase', 'NN'), ('detection', 'NN'), ('pixels', 'NNS'), ('wherein', 'VBP'), ('phase', 'JJ'), ('detection', 'NN'), ('pixels', 'NNS'), ('always-on', 'JJ'), ('pixels', 'NNS'), ('regular', 'JJ'), ('pixels', 'NNS'), ('selectively', 'RB'), ('turned', 'VBD'), ('autofocusing', 'VBG'), ('accomplishedan', 'NN'), ('apparatus', 'NN'), ('includes', 'VBZ'), ('first', 'JJ'), ('camera', 'NN'), ('module', 'NN'), ('providing', 'VBG'), ('first', 'JJ'), ('image', 'NN'), ('object', 'VBP'), ('first', 'JJ'), ('field', 'NN'), ('view', 'NN'), ('second', 'JJ'), ('camera', 'NN'), ('module', 'NN'), ('providing', 'VBG'), ('second', 'JJ'), ('image', 'NN'), ('object', 'JJ'), ('second', 'JJ'), ('field', 'NN'), ('view', 'NN'), ('different', 'JJ'), ('first', 'JJ'), ('field', 'NN'), ('view', 'NN'), ('first', 'RB'), ('depth', 'VBZ'), ('map', 'NN'), ('generator', 'NN'), ('generates', 'NNS'), ('first', 'RB'), ('depth', 'VB'), ('map', 'NN'), ('first', 'RB'), ('image', 'NN'), ('based', 'VBN'), ('first', 'JJ'), ('image', 'NN'), ('second', 'JJ'), ('image', 'NN'), ('second', 'JJ'), ('depth', 'NN'), ('map', 'NN'), ('generator', 'NN'), ('generates', 'VBZ'), ('second', 'JJ'), ('depth', 'NN'), ('map', 'NN'), ('second', 'JJ'), ('image', 'NN'), ('based', 'VBN'), ('first', 'JJ'), ('image', 'NN'), ('second', 'JJ'), ('image', 'NN'), ('first', 'RB'), ('depth', 'JJ'), ('mapmethods', 'NNS'), ('systems', 'NNS'), ('apparatus', 'RB'), ('including', 'VBG'), ('computer', 'NN'), ('programs', 'NNS'), ('encoded', 'VBD'), ('computer', 'NN'), ('storage', 'NN'), ('media', 'NNS'), ('payment', 'NN'), ('based', 'VBN'), ('face', 'NN'), ('recognition', 'NN'), ('provided', 'VBD'), ('one', 'CD'), ('methods', 'NNS'), ('includes', 'VBZ'), ('acquiring', 'VBG'), ('first', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('information', 'NN'), ('target', 'NN'), ('user', 'NN'), ('extracting', 'VBG'), ('first', 'JJ'), ('characteristic', 'JJ'), ('information', 'NN'), ('first', 'RB'), ('face', 'NN'), ('image', 'NN'), ('information', 'NN'), ('wherein', 'IN'), ('first', 'JJ'), ('characteristic', 'JJ'), ('information', 'NN'), ('includes', 'VBZ'), ('head', 'NN'), ('posture', 'NN'), ('information', 'NN'), ('target', 'NN'), ('user', 'NN'), ('gaze', 'NN'), ('information', 'NN'), ('target', 'NN'), ('user', 'NN'), ('determining', 'VBG'), ('whether', 'IN'), ('target', 'NN'), ('user', 'JJ'), ('willingness', 'NN'), ('pay', 'NN'), ('according', 'VBG'), ('head', 'NN'), ('posture', 'NN'), ('information', 'NN'), ('target', 'NN'), ('user', 'NN'), ('gaze', 'NN'), ('information', 'NN'), ('target', 'NN'), ('user', 'NN'), ('including', 'VBG'), ('determining', 'VBG'), ('whether', 'IN'), ('angle', 'JJ'), ('rotation', 'NN'), ('preset', 'VBN'), ('direction', 'NN'), ('less', 'RBR'), ('angle', 'JJ'), ('threshold', 'NN'), ('whether', 'IN'), ('probability', 'NN'), ('value', 'NN'), ('user', 'NN'), ('gazes', 'JJ'), ('payment', 'NN'), ('screen', 'NN'), ('greater', 'JJR'), ('probability', 'NN'), ('threshold', 'JJ'), ('response', 'NN'), ('determining', 'VBG'), ('target', 'NN'), ('user', 'JJ'), ('willingness', 'NN'), ('pay', 'NN'), ('completing', 'VBG'), ('payment', 'NN'), ('operation', 'NN'), ('based', 'VBN'), ('face', 'NN'), ('recognitiona', 'NN'), ('novel', 'JJ'), ('method', 'NN'), ('apparatus', 'NN'), ('face', 'NN'), ('authentication', 'NN'), ('disclosed', 'VBD'), ('disclosed', 'VBN'), ('method', 'NN'), ('comprises', 'VBZ'), ('detecting', 'VBG'), ('motion', 'NN'), ('subject', 'NN'), ('within', 'IN'), ('predetermined', 'JJ'), ('area', 'NN'), ('view', 'NN'), ('assigning', 'VBG'), ('unique', 'JJ'), ('session', 'NN'), ('identification', 'NN'), ('number', 'NN'), ('subject', 'JJ'), ('detected', 'VBD'), ('within', 'IN'), ('predetermined', 'JJ'), ('area', 'NN'), ('view', 'NN'), ('detecting', 'VBG'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'NN'), ('detected', 'VBD'), ('within', 'IN'), ('predetermined', 'JJ'), ('area', 'NN'), ('view', 'NN'), ('generating', 'VBG'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'NN'), ('assessing', 'VBG'), ('quality', 'NN'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'JJ'), ('conducing', 'VBG'), ('incremental', 'JJ'), ('training', 'NN'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'JJ'), ('determining', 'VBG'), ('identity', 'NN'), ('subject', 'NN'), ('based', 'VBN'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'JJ'), ('identifying', 'VBG'), ('intent', 'NN'), ('subject', 'JJ'), ('authorizing', 'VBG'), ('access', 'NN'), ('point', 'NN'), ('entry', 'NN'), ('based', 'VBN'), ('determined', 'VBN'), ('identity', 'NN'), ('subject', 'NN'), ('based', 'VBN'), ('intent', 'NN'), ('subjectdisclosed', 'VBN'), ('herein', 'NN'), ('robot', 'VBZ'), ('electronic', 'JJ'), ('device', 'NN'), ('acquiring', 'VBG'), ('video', 'JJ'), ('method', 'NN'), ('acquiring', 'VBG'), ('video', 'NN'), ('using', 'VBG'), ('robot', 'JJ'), ('robot', 'NN'), ('includes', 'VBZ'), ('camera', 'NN'), ('configured', 'VBD'), ('rotate', 'JJ'), ('lateral', 'JJ'), ('direction', 'NN'), ('tilt', 'VBD'), ('vertical', 'JJ'), ('direction', 'NN'), ('controls', 'NNS'), ('least', 'VBP'), ('one', 'CD'), ('direction', 'NN'), ('rotation', 'NN'), ('camera', 'NN'), ('angle', 'NN'), ('tilt', 'NN'), ('camera', 'NN'), ('focal', 'JJ'), ('distance', 'NN'), ('camera', 'NN'), ('recognizing', 'VBG'), ('tracking', 'VBG'), ('users', 'NNS'), ('video', 'RB'), ('acquired', 'VBD'), ('camerasystems', 'NNS'), ('methods', 'NNS'), ('disclosed', 'VBD'), ('inferring', 'VBG'), ('topics', 'NNS'), ('file', 'NN'), ('containing', 'VBG'), ('audio', 'JJ'), ('video', 'NN'), ('example', 'NN'), ('multimodal', 'JJ'), ('multimedia', 'NN'), ('file', 'NN'), ('order', 'NN'), ('facilitate', 'NN'), ('video', 'NN'), ('indexing', 'VBG'), ('set', 'VBN'), ('entities', 'NNS'), ('extracted', 'VBD'), ('file', 'NN'), ('linked', 'VBN'), ('produce', 'VBP'), ('graph', 'JJ'), ('reference', 'NN'), ('information', 'NN'), ('also', 'RB'), ('obtained', 'VBD'), ('set', 'JJ'), ('entities', 'NNS'), ('entities', 'NNS'), ('may', 'MD'), ('drawn', 'VB'), ('example', 'NN'), ('wikipedia', 'NN'), ('categories', 'NNS'), ('large', 'JJ'), ('ontological', 'JJ'), ('data', 'NNS'), ('sources', 'NNS'), ('analysis', 'NN'), ('graph', 'NN'), ('using', 'VBG'), ('unsupervised', 'JJ'), ('learning', 'VBG'), ('permits', 'NNS'), ('determining', 'VBG'), ('clusters', 'NNS'), ('graph', 'VBP'), ('extracting', 'VBG'), ('features', 'NNS'), ('clusters', 'NNS'), ('possibly', 'RB'), ('using', 'VBG'), ('supervised', 'VBN'), ('learning', 'VBG'), ('provides', 'VBZ'), ('selection', 'NN'), ('topic', 'NN'), ('identifiers', 'NNS'), ('topic', 'VBP'), ('identifiers', 'NNS'), ('used', 'VBD'), ('indexing', 'VBG'), ('filea', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('method', 'FW'), ('neural', 'JJ'), ('network', 'NN'), ('training', 'VBG'), ('method', 'NN'), ('apparatus', 'NN'), ('electronic', 'JJ'), ('device', 'NN'), ('method', 'NN'), ('comprises', 'VBZ'), ('obtaining', 'VBG'), ('first', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('means', 'VBZ'), ('first', 'JJ'), ('camera', 'NN'), ('extracting', 'VBG'), ('first', 'JJ'), ('face', 'NN'), ('feature', 'NN'), ('first', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('comparing', 'VBG'), ('first', 'JJ'), ('face', 'NN'), ('feature', 'NN'), ('pre-stored', 'JJ'), ('second', 'JJ'), ('face', 'NN'), ('feature', 'NN'), ('obtain', 'VB'), ('reference', 'NN'), ('similarity', 'NN'), ('second', 'JJ'), ('face', 'NN'), ('feature', 'NN'), ('obtained', 'VBN'), ('extracting', 'JJ'), ('feature', 'JJ'), ('second', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('obtained', 'VBN'), ('second', 'JJ'), ('camera', 'NN'), ('second', 'JJ'), ('camera', 'NN'), ('first', 'RB'), ('camera', 'VB'), ('different', 'JJ'), ('types', 'NNS'), ('cameras', 'NNS'), ('determining', 'VBG'), ('according', 'VBG'), ('reference', 'NN'), ('similarity', 'NN'), ('whether', 'IN'), ('first', 'JJ'), ('face', 'NN'), ('feature', 'NN'), ('second', 'JJ'), ('face', 'NN'), ('feature', 'NN'), ('correspond', 'NN'), ('person', 'NN'), ('present', 'JJ'), ('invention', 'NN'), ('discloses', 'VBZ'), ('technique', 'JJ'), ('alerting', 'VBG'), ('vision', 'NN'), ('impairment', 'NN'), ('system', 'NN'), ('comprises', 'VBZ'), ('processing', 'VBG'), ('unit', 'NN'), ('configured', 'VBD'), ('operable', 'JJ'), ('receiving', 'VBG'), ('scene', 'NN'), ('data', 'NNS'), ('indicative', 'JJ'), ('scene', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('consumer', 'NN'), ('environment', 'NN'), ('identifying', 'VBG'), ('scene', 'NN'), ('data', 'NNS'), ('certain', 'JJ'), ('consumer', 'NN'), ('identifying', 'VBG'), ('event', 'NN'), ('indicative', 'JJ'), ('behavioral', 'JJ'), ('compensation', 'NN'), ('vision', 'NN'), ('impairment', 'NN'), ('upon', 'IN'), ('identification', 'NN'), ('event', 'NN'), ('sending', 'VBG'), ('notification', 'NN'), ('relating', 'VBG'), ('vision', 'NN'), ('impairment', 'NN')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('electronic', 'JJ'), ('device', 'NN'), ('configured', 'VBD'), ('make', 'VBP'), ('screen', 'JJ'), ('display', 'NN'), ('plurality', 'NN'), ('image', 'NN'), ('frames', 'NNS'), ('comprising', 'VBG'), ('image', 'NN'), ('capturing', 'VBG'), ('device', 'JJ'), ('storage', 'NN'), ('device', 'NN'), ('storing', 'VBG'), ('plurality', 'NN'), ('modules', 'NNS'), ('processor', 'VBP'), ('coupled', 'VBN'), ('image', 'NN'), ('capturing', 'VBG'), ('device', 'JJ'), ('storage', 'NN'), ('device', 'NN'), ('configured', 'VBD'), ('execute', 'JJ'), ('modules', 'NNS'), ('storage', 'NN'), ('device', 'NN'), ('configure', 'NN'), ('screen', 'NN'), ('display', 'NN'), ('plurality', 'NN'), ('marker', 'NN'), ('objects', 'VBZ'), ('plurality', 'NN'), ('predetermined', 'VBN'), ('calibration', 'NN'), ('positions', 'NNS'), ('configure', 'VBP'), ('image', 'NN'), ('capturing', 'NN'), ('device', 'NN'), ('capture', 'NN'), ('plurality', 'NN'), ('first', 'RB'), ('head', 'JJ'), ('images', 'NNS'), ('user', 'VBP'), ('looking', 'VBG'), ('predetermined', 'VBN'), ('calibration', 'NN'), ('positions', 'NNS'), ('perform', 'VBP'), ('plurality', 'NN'), ('first', 'RB'), ('face', 'NN'), ('recognition', 'NN'), ('operations', 'NNS'), ('first', 'RB'), ('head', 'VBP'), ('images', 'NNS'), ('obtain', 'VB'), ('plurality', 'NN'), ('first', 'RB'), ('face', 'NN'), ('regions', 'NNS'), ('corresponding', 'VBG'), ('predetermined', 'JJ'), ('calibration', 'NN'), ('positions', 'NNS'), ('detect', 'VBP'), ('plurality', 'NN'), ('first', 'RB'), ('facial', 'JJ'), ('landmarks', 'NNS'), ('corresponding', 'VBG'), ('first', 'JJ'), ('face', 'NN'), ('regions', 'NNS'), ('calculate', 'VBP'), ('plurality', 'NN'), ('rotation', 'NN'), ('reference', 'NN'), ('angles', 'NNS'), ('user', 'RBR'), ('looking', 'VBG'), ('predetermined', 'JJ'), ('calibration', 'NN'), ('positions', 'NNS'), ('according', 'VBG'), ('first', 'JJ'), ('facial', 'JJ'), ('landmarks', 'NN'), ('configure', 'NN'), ('image', 'NN'), ('capturing', 'VBG'), ('device', 'JJ'), ('capture', 'NN'), ('second', 'JJ'), ('head', 'NN'), ('image', 'NN'), ('user', 'JJ'), ('perform', 'JJ'), ('second', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('operation', 'NN'), ('second', 'JJ'), ('head', 'NN'), ('image', 'NN'), ('obtain', 'VB'), ('second', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('detect', 'JJ'), ('plurality', 'NN'), ('second', 'JJ'), ('facial', 'JJ'), ('landmarks', 'NNS'), ('within', 'IN'), ('second', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('estimate', 'NN'), ('head', 'NN'), ('posture', 'NN'), ('angle', 'VBZ'), ('user', 'RP'), ('according', 'VBG'), ('second', 'JJ'), ('facial', 'JJ'), ('landmarks', 'NNS'), ('calculate', 'VBP'), ('gaze', 'JJ'), ('position', 'NN'), ('user', 'NN'), ('screen', 'NN'), ('according', 'VBG'), ('head', 'NN'), ('posture', 'NN'), ('angle', 'JJ'), ('rotation', 'NN'), ('reference', 'NN'), ('angles', 'NNS'), ('predetermined', 'VBN'), ('calibration', 'NN'), ('positions', 'NNS'), ('configure', 'VBP'), ('screen', 'JJ'), ('display', 'NN'), ('corresponding', 'VBG'), ('visual', 'JJ'), ('effect', 'NN'), ('according', 'VBG'), ('gaze', 'JJ'), ('position', 'NN'), ('electronic', 'JJ'), ('device', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('gaze', 'JJ'), ('position', 'NN'), ('comprises', 'NNS'), ('first', 'JJ'), ('coordinate', 'NN'), ('value', 'NN'), ('first', 'RB'), ('axial', 'JJ'), ('direction', 'NN'), ('second', 'JJ'), ('coordinate', 'NN'), ('value', 'NN'), ('second', 'JJ'), ('axial', 'JJ'), ('direction', 'NN'), ('electronic', 'JJ'), ('device', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('head', 'NN'), ('posture', 'NN'), ('angles', 'VBZ'), ('comprise', 'RB'), ('head', 'JJ'), ('pitch', 'NN'), ('angle', 'NN'), ('head', 'NN'), ('yaw', 'NN'), ('angle', 'JJ'), ('rotation', 'NN'), ('reference', 'NN'), ('angles', 'NNS'), ('comprise', 'VBP'), ('first', 'JJ'), ('pitch', 'NN'), ('angle', 'NN'), ('second', 'JJ'), ('pitch', 'NN'), ('angle', 'NN'), ('first', 'RB'), ('yaw', 'RB'), ('angle', 'JJ'), ('second', 'JJ'), ('yaw', 'NN'), ('angle', 'NN'), ('corresponding', 'VBG'), ('predetermined', 'JJ'), ('calibration', 'NN'), ('positions', 'NNS'), ('electronic', 'JJ'), ('device', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('processor', 'NN'), ('performs', 'NNS'), ('interpolation', 'NN'), ('operation', 'NN'), ('extrapolation', 'NN'), ('operation', 'NN'), ('according', 'VBG'), ('first', 'JJ'), ('yaw', 'NN'), ('angle', 'JJ'), ('second', 'JJ'), ('yaw', 'NN'), ('angle', 'NN'), ('first', 'JJ'), ('position', 'NN'), ('corresponding', 'VBG'), ('first', 'JJ'), ('yaw', 'JJ'), ('angle', 'NN'), ('among', 'IN'), ('predetermined', 'JJ'), ('calibration', 'NN'), ('positions', 'NNS'), ('second', 'JJ'), ('position', 'NN'), ('corresponding', 'VBG'), ('second', 'JJ'), ('yaw', 'JJ'), ('angle', 'NN'), ('among', 'IN'), ('predetermined', 'JJ'), ('calibration', 'NN'), ('positions', 'NNS'), ('head', 'VBP'), ('yaw', 'RB'), ('angle', 'JJ'), ('thereby', 'RB'), ('obtaining', 'VBG'), ('first', 'JJ'), ('coordinate', 'NN'), ('value', 'NN'), ('gaze', 'JJ'), ('position', 'NN'), ('processor', 'NN'), ('performs', 'NNS'), ('interpolation', 'NN'), ('operation', 'NN'), ('extrapolation', 'NN'), ('operation', 'NN'), ('according', 'VBG'), ('first', 'JJ'), ('pitch', 'NN'), ('angle', 'NN'), ('second', 'JJ'), ('pitch', 'NN'), ('angle', 'NN'), ('third', 'JJ'), ('position', 'NN'), ('corresponding', 'VBG'), ('first', 'JJ'), ('pitch', 'NN'), ('angle', 'NN'), ('among', 'IN'), ('predetermined', 'JJ'), ('calibration', 'NN'), ('positions', 'NNS'), ('fourth', 'JJ'), ('position', 'NN'), ('corresponding', 'VBG'), ('second', 'JJ'), ('pitch', 'NN'), ('angle', 'NN'), ('among', 'IN'), ('predetermined', 'JJ'), ('calibration', 'NN'), ('positions', 'NNS'), ('head', 'VBP'), ('pitch', 'NN'), ('angle', 'NN'), ('thereby', 'RB'), ('obtaining', 'VBG'), ('second', 'JJ'), ('coordinate', 'NN'), ('value', 'NN'), ('gaze', 'JJ'), ('position', 'NN'), ('electronic', 'JJ'), ('device', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('processor', 'NN'), ('calculates', 'NNS'), ('plurality', 'NN'), ('first', 'RB'), ('viewing', 'VBG'), ('distances', 'NNS'), ('user', 'RB'), ('screen', 'VBP'), ('according', 'VBG'), ('first', 'RB'), ('facial', 'JJ'), ('landmarks', 'NNS'), ('processor', 'VBP'), ('estimates', 'NNS'), ('second', 'JJ'), ('viewing', 'VBG'), ('distance', 'NN'), ('user', 'NN'), ('screen', 'NN'), ('according', 'VBG'), ('second', 'JJ'), ('facial', 'JJ'), ('landmarks', 'NNS'), ('processor', 'VBP'), ('adjusts', 'NNS'), ('rotation', 'NN'), ('reference', 'NN'), ('angles', 'NNS'), ('gaze', 'VBP'), ('position', 'NN'), ('according', 'VBG'), ('second', 'JJ'), ('viewing', 'NN'), ('distance', 'NN'), ('first', 'RB'), ('viewing', 'VBG'), ('distances', 'NNS'), ('electronic', 'JJ'), ('device', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('processor', 'NN'), ('maps', 'NNS'), ('plurality', 'NN'), ('two-dimensional', 'JJ'), ('position', 'NN'), ('coordinates', 'NNS'), ('second', 'JJ'), ('facial', 'JJ'), ('landmarks', 'NNS'), ('plane', 'NN'), ('coordinate', 'NN'), ('system', 'NN'), ('plurality', 'NN'), ('three-dimensional', 'JJ'), ('position', 'NN'), ('coordinates', 'VBZ'), ('three-dimensional', 'JJ'), ('coordinate', 'NN'), ('system', 'NN'), ('processor', 'NN'), ('estimates', 'NNS'), ('head', 'VBP'), ('posture', 'NN'), ('angle', 'NN'), ('according', 'VBG'), ('three-dimensional', 'JJ'), ('position', 'NN'), ('coordinates', 'NNS'), ('second', 'JJ'), ('facial', 'JJ'), ('landmarks', 'NNS'), ('electronic', 'JJ'), ('device', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('second', 'JJ'), ('head', 'NN'), ('image', 'NN'), ('comprises', 'VBZ'), ('wearable', 'JJ'), ('device', 'NN'), ('second', 'JJ'), ('facial', 'JJ'), ('landmarks', 'NNS'), ('comprise', 'VBP'), ('plurality', 'NN'), ('third', 'JJ'), ('facial', 'JJ'), ('landmarks', 'NNS'), ('user', 'RB'), ('covered', 'VBD'), ('wearable', 'JJ'), ('device', 'NN'), ('electronic', 'JJ'), ('device', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('second', 'JJ'), ('head', 'NN'), ('image', 'NN'), ('comprises', 'VBZ'), ('wearable', 'JJ'), ('device', 'NN'), ('second', 'JJ'), ('facial', 'JJ'), ('landmarks', 'NNS'), ('comprise', 'VBP'), ('one', 'CD'), ('simulated', 'VBN'), ('landmarks', 'NN'), ('marked', 'VBD'), ('wearable', 'JJ'), ('device', 'NN'), ('operating', 'VBG'), ('method', 'NN'), ('adapted', 'VBD'), ('electronic', 'JJ'), ('device', 'NN'), ('comprising', 'VBG'), ('image', 'NN'), ('capturing', 'VBG'), ('device', 'NN'), ('making', 'VBG'), ('screen', 'JJ'), ('display', 'NN'), ('plurality', 'NN'), ('image', 'NN'), ('frames', 'NNS'), ('method', 'VBP'), ('comprising', 'VBG'), ('configuring', 'VBG'), ('screen', 'JJ'), ('display', 'NN'), ('plurality', 'NN'), ('marker', 'NN'), ('objects', 'VBZ'), ('plurality', 'NN'), ('predetermined', 'VBN'), ('calibration', 'NN'), ('positions', 'NNS'), ('configuring', 'VBG'), ('image', 'NN'), ('capturing', 'VBG'), ('device', 'JJ'), ('capture', 'NN'), ('plurality', 'NN'), ('first', 'RB'), ('head', 'JJ'), ('images', 'NNS'), ('user', 'VBP'), ('looking', 'VBG'), ('predetermined', 'VBN'), ('calibration', 'NN'), ('positions', 'NNS'), ('performing', 'VBG'), ('plurality', 'NN'), ('first', 'RB'), ('face', 'NN'), ('recognition', 'NN'), ('operations', 'NNS'), ('first', 'RB'), ('head', 'VBP'), ('images', 'NNS'), ('obtain', 'VB'), ('plurality', 'NN'), ('first', 'RB'), ('face', 'NN'), ('regions', 'NNS'), ('corresponding', 'VBG'), ('predetermined', 'JJ'), ('calibration', 'NN'), ('positions', 'NNS'), ('detecting', 'VBG'), ('plurality', 'NN'), ('first', 'RB'), ('facial', 'JJ'), ('landmarks', 'NNS'), ('corresponding', 'VBG'), ('first', 'JJ'), ('face', 'NN'), ('regions', 'NNS'), ('calculating', 'VBG'), ('plurality', 'NN'), ('rotation', 'NN'), ('reference', 'NN'), ('angles', 'NNS'), ('user', 'RBR'), ('looking', 'VBG'), ('predetermined', 'JJ'), ('calibration', 'NN'), ('positions', 'NNS'), ('according', 'VBG'), ('first', 'JJ'), ('facial', 'JJ'), ('landmarks', 'NNS'), ('configuring', 'VBG'), ('image', 'NN'), ('capturing', 'VBG'), ('device', 'JJ'), ('capture', 'NN'), ('second', 'JJ'), ('head', 'NN'), ('image', 'NN'), ('user', 'JJ'), ('performing', 'VBG'), ('second', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('operation', 'NN'), ('second', 'JJ'), ('head', 'NN'), ('image', 'NN'), ('obtain', 'VB'), ('second', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('detecting', 'VBG'), ('plurality', 'NN'), ('second', 'JJ'), ('facial', 'JJ'), ('landmarks', 'NNS'), ('within', 'IN'), ('second', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('estimating', 'VBG'), ('head', 'NN'), ('posture', 'NN'), ('angle', 'VBZ'), ('user', 'RP'), ('according', 'VBG'), ('second', 'JJ'), ('facial', 'JJ'), ('landmarks', 'NNS'), ('calculating', 'VBG'), ('gaze', 'JJ'), ('position', 'NN'), ('user', 'NN'), ('screen', 'NN'), ('according', 'VBG'), ('head', 'NN'), ('posture', 'NN'), ('angle', 'JJ'), ('rotation', 'NN'), ('reference', 'NN'), ('angles', 'NNS'), ('predetermined', 'VBN'), ('calibration', 'NN'), ('positions', 'NNS'), ('configuring', 'VBG'), ('screen', 'NN'), ('display', 'NN'), ('corresponding', 'VBG'), ('visual', 'JJ'), ('effect', 'NN'), ('according', 'VBG'), ('gaze', 'JJ'), ('position', 'NN'), ('operation', 'NN'), ('method', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('gaze', 'JJ'), ('position', 'NN'), ('comprises', 'NNS'), ('first', 'JJ'), ('coordinate', 'NN'), ('value', 'NN'), ('first', 'RB'), ('axial', 'JJ'), ('direction', 'NN'), ('second', 'JJ'), ('coordinate', 'NN'), ('value', 'NN'), ('second', 'JJ'), ('axial', 'JJ'), ('direction', 'NN'), ('operation', 'NN'), ('method', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('head', 'NN'), ('posture', 'NN'), ('angles', 'VBZ'), ('comprise', 'RB'), ('head', 'JJ'), ('pitch', 'NN'), ('angle', 'NN'), ('head', 'NN'), ('yaw', 'NN'), ('angle', 'JJ'), ('rotation', 'NN'), ('reference', 'NN'), ('angles', 'NNS'), ('comprise', 'VBP'), ('first', 'JJ'), ('pitch', 'NN'), ('angle', 'NN'), ('second', 'JJ'), ('pitch', 'NN'), ('angle', 'NN'), ('first', 'RB'), ('yaw', 'RB'), ('angle', 'JJ'), ('second', 'JJ'), ('yaw', 'NN'), ('angle', 'NN'), ('corresponding', 'VBG'), ('predetermined', 'JJ'), ('calibration', 'NN'), ('positions', 'NNS'), ('operation', 'NN'), ('method', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'JJ'), ('step', 'NN'), ('calculating', 'VBG'), ('gaze', 'JJ'), ('position', 'NN'), ('user', 'NN'), ('screen', 'NN'), ('according', 'VBG'), ('head', 'NN'), ('posture', 'NN'), ('angle', 'JJ'), ('rotation', 'NN'), ('reference', 'NN'), ('angles', 'NNS'), ('predetermined', 'VBN'), ('calibration', 'NN'), ('positions', 'NNS'), ('comprises', 'VBZ'), ('performing', 'VBG'), ('interpolation', 'NN'), ('operation', 'NN'), ('extrapolation', 'NN'), ('operation', 'NN'), ('according', 'VBG'), ('first', 'JJ'), ('yaw', 'NN'), ('angle', 'JJ'), ('second', 'JJ'), ('yaw', 'NN'), ('angle', 'NN'), ('first', 'JJ'), ('position', 'NN'), ('corresponding', 'VBG'), ('first', 'JJ'), ('yaw', 'JJ'), ('angle', 'NN'), ('among', 'IN'), ('predetermined', 'JJ'), ('calibration', 'NN'), ('positions', 'NNS'), ('second', 'JJ'), ('position', 'NN'), ('corresponding', 'VBG'), ('second', 'JJ'), ('yaw', 'JJ'), ('angle', 'NN'), ('among', 'IN'), ('predetermined', 'JJ'), ('calibration', 'NN'), ('positions', 'NNS'), ('head', 'VBP'), ('yaw', 'RB'), ('angle', 'JJ'), ('thereby', 'RB'), ('obtaining', 'VBG'), ('first', 'JJ'), ('coordinate', 'NN'), ('value', 'NN'), ('gaze', 'JJ'), ('position', 'NN'), ('performing', 'VBG'), ('interpolation', 'NN'), ('operation', 'NN'), ('extrapolation', 'NN'), ('operation', 'NN'), ('according', 'VBG'), ('first', 'JJ'), ('pitch', 'NN'), ('angle', 'NN'), ('second', 'JJ'), ('pitch', 'NN'), ('angle', 'NN'), ('third', 'JJ'), ('position', 'NN'), ('corresponding', 'VBG'), ('first', 'JJ'), ('pitch', 'NN'), ('angle', 'NN'), ('among', 'IN'), ('predetermined', 'JJ'), ('calibration', 'NN'), ('positions', 'NNS'), ('fourth', 'JJ'), ('position', 'NN'), ('corresponding', 'VBG'), ('second', 'JJ'), ('pitch', 'NN'), ('angle', 'NN'), ('among', 'IN'), ('predetermined', 'JJ'), ('calibration', 'NN'), ('positions', 'NNS'), ('head', 'VBP'), ('pitch', 'NN'), ('angle', 'NN'), ('thereby', 'RB'), ('obtaining', 'VBG'), ('second', 'JJ'), ('coordinate', 'NN'), ('value', 'NN'), ('gaze', 'JJ'), ('position', 'NN'), ('operation', 'NN'), ('method', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('method', 'NN'), ('comprises', 'VBZ'), ('calculating', 'VBG'), ('plurality', 'NN'), ('first', 'RB'), ('viewing', 'VBG'), ('distances', 'NNS'), ('user', 'RB'), ('screen', 'VBP'), ('according', 'VBG'), ('first', 'RB'), ('facial', 'JJ'), ('landmarks', 'NNS'), ('estimating', 'VBG'), ('second', 'JJ'), ('viewing', 'VBG'), ('distance', 'NN'), ('user', 'NN'), ('screen', 'NN'), ('according', 'VBG'), ('second', 'JJ'), ('facial', 'JJ'), ('landmarks', 'NNS'), ('adjusting', 'VBG'), ('rotation', 'NN'), ('reference', 'NN'), ('angles', 'NNS'), ('gaze', 'VBP'), ('position', 'NN'), ('according', 'VBG'), ('second', 'JJ'), ('viewing', 'NN'), ('distance', 'NN'), ('first', 'RB'), ('viewing', 'VBG'), ('distances', 'NNS'), ('operation', 'NN'), ('method', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('method', 'NN'), ('comprises', 'VBZ'), ('mapping', 'VBG'), ('plurality', 'NN'), ('two-dimensional', 'JJ'), ('position', 'NN'), ('coordinates', 'NNS'), ('second', 'JJ'), ('facial', 'JJ'), ('landmarks', 'NNS'), ('plane', 'NN'), ('coordinate', 'NN'), ('system', 'NN'), ('plurality', 'NN'), ('three-dimensional', 'JJ'), ('position', 'NN'), ('coordinates', 'VBZ'), ('three-dimensional', 'JJ'), ('coordinate', 'NN'), ('system', 'NN'), ('estimating', 'VBG'), ('head', 'NN'), ('posture', 'NN'), ('angle', 'IN'), ('according', 'VBG'), ('three-dimensional', 'JJ'), ('position', 'NN'), ('coordinates', 'NNS'), ('second', 'JJ'), ('facial', 'JJ'), ('landmarks', 'NNS'), ('operation', 'NN'), ('method', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('second', 'JJ'), ('head', 'NN'), ('image', 'NN'), ('comprises', 'VBZ'), ('wearable', 'JJ'), ('device', 'NN'), ('second', 'JJ'), ('facial', 'JJ'), ('landmarks', 'NNS'), ('comprise', 'VBP'), ('plurality', 'NN'), ('third', 'JJ'), ('facial', 'JJ'), ('landmarks', 'NNS'), ('user', 'RB'), ('covered', 'VBD'), ('wearable', 'JJ'), ('device', 'NN'), ('operation', 'NN'), ('method', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('second', 'JJ'), ('head', 'NN'), ('image', 'NN'), ('comprises', 'VBZ'), ('wearable', 'JJ'), ('device', 'NN'), ('second', 'JJ'), ('facial', 'JJ'), ('landmarks', 'NNS'), ('comprise', 'VBP'), ('one', 'CD'), ('simulated', 'VBN'), ('landmarks', 'NN'), ('marked', 'VBD'), ('wearable', 'JJ'), ('device', 'NN'), ('computation', 'NN'), ('method', 'NN'), ('applied', 'VBD'), ('computing', 'VBG'), ('system', 'NN'), ('wherein', 'VBD'), ('computing', 'VBG'), ('system', 'NN'), ('comprises', 'VBZ'), ('control', 'VB'), ('unit', 'NN'), ('computation', 'NN'), ('group', 'NN'), ('general', 'JJ'), ('storage', 'NN'), ('unit', 'NN'), ('wherein', 'VBZ'), ('control', 'JJ'), ('unit', 'NN'), ('comprises', 'VBZ'), ('first', 'JJ'), ('memory', 'NN'), ('decoding', 'VBG'), ('logic', 'JJ'), ('controller', 'NN'), ('wherein', 'NN'), ('computation', 'NN'), ('group', 'NN'), ('comprises', 'VBZ'), ('group', 'NN'), ('controller', 'NN'), ('plurality', 'NN'), ('computing', 'VBG'), ('units', 'NNS'), ('general', 'JJ'), ('storage', 'NN'), ('unit', 'NN'), ('configured', 'VBD'), ('store', 'NN'), ('data', 'NNS'), ('computation', 'NN'), ('method', 'NN'), ('comprises', 'VBZ'), ('receiving', 'VBG'), ('controller', 'NN'), ('first', 'RB'), ('level', 'JJ'), ('instruction', 'NN'), ('sequence', 'NN'), ('partitioning', 'VBG'), ('decoding', 'VBG'), ('logic', 'JJ'), ('first', 'JJ'), ('level', 'NN'), ('instruction', 'NN'), ('sequence', 'NN'), ('plurality', 'NN'), ('second', 'JJ'), ('level', 'NN'), ('instruction', 'NN'), ('sequences', 'NNS'), ('creating', 'VBG'), ('controller', 'NN'), ('threads', 'NNS'), ('plurality', 'JJ'), ('second', 'JJ'), ('level', 'NN'), ('instruction', 'NN'), ('sequences', 'NNS'), ('allocating', 'VBG'), ('controller', 'NN'), ('independent', 'JJ'), ('register', 'NN'), ('well', 'RB'), ('configuring', 'VBG'), ('independent', 'JJ'), ('addressing', 'VBG'), ('function', 'NN'), ('thread', 'NN'), ('threads', 'NNS'), ('wherein', 'VBP'), ('integer', 'JJ'), ('greater', 'JJR'), ('equal', 'JJ'), ('obtaining', 'VBG'), ('group', 'NN'), ('controller', 'NN'), ('plurality', 'NN'), ('computation', 'NN'), ('types', 'NNS'), ('plurality', 'JJ'), ('second', 'JJ'), ('level', 'NN'), ('instruction', 'NN'), ('sequences', 'NNS'), ('obtaining', 'VBG'), ('corresponding', 'VBG'), ('fusion', 'NN'), ('computation', 'NN'), ('manner', 'NN'), ('computation', 'NN'), ('types', 'NNS'), ('according', 'VBG'), ('plurality', 'NN'), ('computation', 'NN'), ('types', 'NNS'), ('adopting', 'VBG'), ('plurality', 'NN'), ('computing', 'VBG'), ('units', 'NNS'), ('fusion', 'NN'), ('computation', 'NN'), ('manner', 'NN'), ('call', 'NN'), ('threads', 'NNS'), ('performing', 'VBG'), ('computations', 'NNS'), ('plurality', 'NN'), ('second', 'JJ'), ('level', 'NN'), ('instruction', 'NN'), ('sequences', 'NNS'), ('obtain', 'VB'), ('final', 'JJ'), ('result', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('obtaining', 'VBG'), ('group', 'NN'), ('controller', 'NN'), ('plurality', 'NN'), ('computation', 'NN'), ('types', 'NNS'), ('plurality', 'JJ'), ('second', 'JJ'), ('level', 'NN'), ('instruction', 'NN'), ('sequences', 'NNS'), ('obtaining', 'VBG'), ('corresponding', 'VBG'), ('fusion', 'NN'), ('computation', 'NN'), ('manner', 'NN'), ('computation', 'NN'), ('types', 'NNS'), ('according', 'VBG'), ('plurality', 'NN'), ('computation', 'NN'), ('types', 'NNS'), ('adopting', 'VBG'), ('plurality', 'NN'), ('computing', 'VBG'), ('units', 'NNS'), ('fusion', 'NN'), ('computation', 'NN'), ('manner', 'NN'), ('call', 'NN'), ('threads', 'NNS'), ('performing', 'VBG'), ('computations', 'NNS'), ('plurality', 'NN'), ('second', 'JJ'), ('instruction', 'NN'), ('sequences', 'NNS'), ('obtain', 'VB'), ('final', 'JJ'), ('result', 'NN'), ('computation', 'NN'), ('types', 'NNS'), ('represent', 'JJ'), ('computation', 'NN'), ('operations', 'NNS'), ('type', 'VBP'), ('group', 'NN'), ('controller', 'NN'), ('calls', 'VBZ'), ('combined', 'VBN'), ('computation', 'NN'), ('manner', 'NN'), ('single', 'JJ'), ('instruction', 'NN'), ('multiple', 'NN'), ('data', 'NNS'), ('type', 'NN'), ('combination', 'NN'), ('single', 'JJ'), ('instruction', 'NN'), ('multiple', 'JJ'), ('threads', 'NNS'), ('uses', 'VBZ'), ('threads', 'NNS'), ('perform', 'NN'), ('combined', 'VBN'), ('computation', 'NN'), ('manner', 'NN'), ('obtain', 'VB'), ('final', 'JJ'), ('result', 'NN'), ('includes', 'VBZ'), ('partitioning', 'VBG'), ('decoding', 'VBG'), ('logic', 'JJ'), ('threads', 'NNS'), ('n', 'RB'), ('wraps', 'VBP'), ('allocating', 'VBG'), ('plurality', 'NN'), ('computing', 'VBG'), ('units', 'NNS'), ('converting', 'VBG'), ('group', 'NN'), ('controller', 'NN'), ('plurality', 'NN'), ('second', 'JJ'), ('instruction', 'NN'), ('sequences', 'NNS'), ('plurality', 'JJ'), ('second', 'JJ'), ('control', 'NN'), ('signals', 'NNS'), ('sending', 'VBG'), ('second', 'JJ'), ('control', 'NN'), ('signals', 'NNS'), ('plurality', 'NN'), ('computing', 'VBG'), ('units', 'NNS'), ('calling', 'VBG'), ('plurality', 'NN'), ('computing', 'VBG'), ('units', 'NNS'), ('wraps', 'NNS'), ('allocated', 'VBD'), ('computing', 'VBG'), ('units', 'NNS'), ('second', 'JJ'), ('control', 'NN'), ('signals', 'NNS'), ('fetch', 'VBP'), ('corresponding', 'VBG'), ('data', 'NNS'), ('according', 'VBG'), ('independent', 'JJ'), ('addressing', 'VBG'), ('function', 'NN'), ('performing', 'VBG'), ('plurality', 'NN'), ('computing', 'VBG'), ('units', 'NNS'), ('computations', 'NNS'), ('data', 'NNS'), ('obtain', 'VB'), ('plurality', 'NN'), ('intermediate', 'JJ'), ('results', 'NNS'), ('splicing', 'VBG'), ('plurality', 'NN'), ('intermediate', 'JJ'), ('results', 'NNS'), ('obtain', 'VB'), ('final', 'JJ'), ('result', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('obtaining', 'VBG'), ('group', 'NN'), ('controller', 'NN'), ('plurality', 'NN'), ('computation', 'NN'), ('types', 'NNS'), ('plurality', 'JJ'), ('second', 'JJ'), ('level', 'NN'), ('instruction', 'NN'), ('sequences', 'NNS'), ('obtaining', 'VBG'), ('corresponding', 'VBG'), ('fusion', 'NN'), ('computation', 'NN'), ('manner', 'NN'), ('computation', 'NN'), ('types', 'NNS'), ('according', 'VBG'), ('plurality', 'NN'), ('computation', 'NN'), ('types', 'NNS'), ('adopting', 'VBG'), ('plurality', 'NN'), ('computing', 'VBG'), ('units', 'NNS'), ('fusion', 'NN'), ('computation', 'NN'), ('manner', 'NN'), ('call', 'NN'), ('threads', 'NNS'), ('performing', 'VBG'), ('computations', 'NNS'), ('plurality', 'NN'), ('second', 'JJ'), ('instruction', 'NN'), ('sequences', 'NNS'), ('obtain', 'VB'), ('final', 'JJ'), ('result', 'NN'), ('computation', 'NN'), ('types', 'NNS'), ('represent', 'JJ'), ('computation', 'NN'), ('operations', 'NNS'), ('different', 'JJ'), ('types', 'NNS'), ('group', 'NN'), ('controller', 'NN'), ('calls', 'VBZ'), ('simultaneous', 'JJ'), ('multi-threading', 'JJ'), ('threads', 'NNS'), ('perform', 'VB'), ('computations', 'NNS'), ('obtain', 'VB'), ('final', 'JJ'), ('result', 'NN'), ('includes', 'VBZ'), ('partitioning', 'VBG'), ('decoding', 'VBG'), ('logic', 'JJ'), ('threads', 'NNS'), ('n', 'RB'), ('wraps', 'VBP'), ('converting', 'VBG'), ('plurality', 'NN'), ('second', 'JJ'), ('instruction', 'NN'), ('sequences', 'NNS'), ('plurality', 'JJ'), ('second', 'JJ'), ('control', 'NN'), ('signals', 'NNS'), ('obtaining', 'VBG'), ('group', 'NN'), ('controller', 'NN'), ('computation', 'NN'), ('types', 'NNS'), ('supported', 'VBD'), ('plurality', 'NN'), ('computing', 'VBG'), ('units', 'NNS'), ('allocating', 'VBG'), ('controller', 'NN'), ('n', 'NN'), ('wraps', 'NNS'), ('plurality', 'JJ'), ('second', 'JJ'), ('control', 'NN'), ('signals', 'NNS'), ('corresponding', 'VBG'), ('computing', 'VBG'), ('units', 'NNS'), ('support', 'NN'), ('computation', 'NN'), ('types', 'NNS'), ('wraps', 'VBP'), ('second', 'JJ'), ('control', 'NN'), ('signals', 'NNS'), ('calling', 'VBG'), ('plurality', 'NN'), ('computing', 'VBG'), ('units', 'NNS'), ('wraps', 'NNS'), ('allocated', 'VBD'), ('computing', 'VBG'), ('units', 'NNS'), ('second', 'JJ'), ('control', 'NN'), ('signals', 'NNS'), ('fetching', 'VBG'), ('plurality', 'NN'), ('computing', 'VBG'), ('units', 'NNS'), ('corresponding', 'VBG'), ('data', 'NNS'), ('performing', 'VBG'), ('plurality', 'NN'), ('computing', 'VBG'), ('units', 'NNS'), ('computations', 'NNS'), ('data', 'NNS'), ('obtain', 'VB'), ('plurality', 'NN'), ('intermediate', 'JJ'), ('results', 'NNS'), ('splicing', 'VBG'), ('intermediate', 'JJ'), ('results', 'NNS'), ('obtain', 'VB'), ('final', 'JJ'), ('result', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('wrap', 'NN'), ('plurality', 'NN'), ('wraps', 'NNS'), ('blocked', 'VBD'), ('adding', 'VBG'), ('wrap', 'NN'), ('waiting', 'VBG'), ('queue', 'NN'), ('data', 'NNS'), ('wrap', 'NN'), ('already', 'RB'), ('fetched', 'VBD'), ('adding', 'VBG'), ('wrap', 'NN'), ('preparation', 'NN'), ('queue', 'NN'), ('wherein', 'WRB'), ('preparation', 'NN'), ('queue', 'NN'), ('queue', 'NN'), ('wrap', 'NN'), ('scheduled', 'VBN'), ('executing', 'VBG'), ('located', 'VBN'), ('computing', 'VBG'), ('resource', 'NN'), ('idle', 'JJ'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'VBP'), ('first', 'JJ'), ('level', 'NN'), ('instruction', 'NN'), ('sequence', 'NN'), ('includes', 'VBZ'), ('long', 'JJ'), ('instruction', 'NN'), ('second', 'JJ'), ('level', 'NN'), ('instruction', 'NN'), ('sequence', 'NN'), ('includes', 'VBZ'), ('instruction', 'NN'), ('sequence', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('computing', 'VBG'), ('system', 'NN'), ('includes', 'VBZ'), ('tree', 'JJ'), ('module', 'NN'), ('wherein', 'VBD'), ('tree', 'JJ'), ('module', 'NN'), ('includes', 'VBZ'), ('root', 'JJ'), ('port', 'NN'), ('plurality', 'NN'), ('branch', 'NN'), ('ports', 'NNS'), ('wherein', 'VBP'), ('root', 'JJ'), ('port', 'NN'), ('tree', 'NN'), ('module', 'NN'), ('connected', 'VBN'), ('group', 'NN'), ('controller', 'NN'), ('plurality', 'NN'), ('branch', 'NN'), ('ports', 'NNS'), ('tree', 'VBP'), ('module', 'NN'), ('connected', 'VBN'), ('computing', 'VBG'), ('unit', 'NN'), ('plurality', 'NN'), ('computing', 'VBG'), ('units', 'NNS'), ('respectively', 'RB'), ('tree', 'VBP'), ('module', 'NN'), ('configured', 'VBN'), ('forward', 'RB'), ('data', 'NN'), ('blocks', 'NNS'), ('wraps', 'VBP'), ('instruction', 'NN'), ('sequences', 'NNS'), ('group', 'NN'), ('controller', 'NN'), ('plurality', 'NN'), ('computing', 'VBG'), ('units', 'NNS'), ('method', 'FW'), ('claim', 'NN'), ('wherein', 'VBP'), ('tree', 'JJ'), ('module', 'NN'), ('n-ary', 'JJ'), ('tree', 'NN'), ('wherein', 'NN'), ('n', 'RB'), ('integer', 'RB'), ('greater', 'JJR'), ('equal', 'JJ'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('computing', 'VBG'), ('system', 'NN'), ('includes', 'VBZ'), ('branch', 'NN'), ('processing', 'VBG'), ('circuit', 'NN'), ('wherein', 'NN'), ('branch', 'NN'), ('processing', 'VBG'), ('circuit', 'NN'), ('connected', 'VBN'), ('group', 'NN'), ('controller', 'NN'), ('plurality', 'NN'), ('computing', 'VBG'), ('units', 'NNS'), ('branch', 'NN'), ('processing', 'VBG'), ('circuit', 'NN'), ('configured', 'VBD'), ('forward', 'RB'), ('data', 'NNS'), ('wraps', 'NNS'), ('instruction', 'NN'), ('sequences', 'NNS'), ('group', 'NN'), ('controller', 'NN'), ('plurality', 'NN'), ('computing', 'VBG'), ('units', 'NNS'), ('computing', 'VBG'), ('system', 'NN'), ('comprising', 'VBG'), ('control', 'NN'), ('unit', 'NN'), ('computation', 'NN'), ('group', 'NN'), ('general', 'JJ'), ('storage', 'NN'), ('unit', 'NN'), ('wherein', 'VBZ'), ('control', 'JJ'), ('unit', 'NN'), ('includes', 'VBZ'), ('first', 'JJ'), ('memory', 'NN'), ('decoding', 'VBG'), ('logic', 'JJ'), ('controller', 'NN'), ('computation', 'NN'), ('group', 'NN'), ('includes', 'VBZ'), ('group', 'NN'), ('controller', 'NN'), ('plurality', 'NN'), ('computing', 'VBG'), ('units', 'NNS'), ('general', 'JJ'), ('storage', 'NN'), ('unit', 'NN'), ('configured', 'VBD'), ('store', 'NN'), ('data', 'NNS'), ('controller', 'NN'), ('configured', 'VBD'), ('receive', 'JJ'), ('first', 'JJ'), ('level', 'NN'), ('instruction', 'NN'), ('sequence', 'NN'), ('control', 'NN'), ('first', 'JJ'), ('memory', 'NN'), ('decoding', 'VBG'), ('logic', 'JJ'), ('decoding', 'VBG'), ('logic', 'NN'), ('configured', 'VBD'), ('partition', 'NN'), ('first', 'RB'), ('level', 'JJ'), ('instruction', 'NN'), ('sequence', 'NN'), ('plurality', 'NN'), ('second', 'JJ'), ('level', 'NN'), ('instruction', 'NN'), ('sequences', 'NNS'), ('controller', 'VBP'), ('configured', 'JJ'), ('create', 'NN'), ('threads', 'NNS'), ('plurality', 'JJ'), ('second', 'JJ'), ('level', 'NN'), ('instruction', 'NN'), ('sequences', 'NNS'), ('allocate', 'VBP'), ('independent', 'JJ'), ('register', 'NN'), ('configure', 'NN'), ('independent', 'JJ'), ('addressing', 'VBG'), ('function', 'NN'), ('thread', 'NN'), ('threads', 'NNS'), ('integer', 'VBP'), ('greater', 'JJR'), ('equal', 'JJ'), ('controller', 'NN'), ('configured', 'VBD'), ('convert', 'JJ'), ('plurality', 'NN'), ('second', 'JJ'), ('instruction', 'NN'), ('sequences', 'NNS'), ('plurality', 'NN'), ('control', 'NN'), ('signals', 'NNS'), ('sending', 'VBG'), ('group', 'NN'), ('controller', 'NN'), ('group', 'NN'), ('controller', 'NN'), ('configured', 'VBD'), ('receive', 'JJ'), ('plurality', 'NN'), ('control', 'NN'), ('signals', 'NNS'), ('obtain', 'VB'), ('plurality', 'JJ'), ('computational', 'JJ'), ('types', 'NNS'), ('plurality', 'NN'), ('control', 'NN'), ('signals', 'NNS'), ('divide', 'VBP'), ('threads', 'NNS'), ('n', 'RB'), ('wraps', 'VBP'), ('allocate', 'JJ'), ('n', 'NN'), ('wraps', 'NNS'), ('plurality', 'NN'), ('control', 'NN'), ('signals', 'NNS'), ('plurality', 'NN'), ('computing', 'VBG'), ('units', 'NNS'), ('according', 'VBG'), ('plurality', 'NN'), ('computational', 'JJ'), ('types', 'NNS'), ('plurality', 'NN'), ('computing', 'VBG'), ('units', 'NNS'), ('configured', 'VBN'), ('fetch', 'RB'), ('data', 'NNS'), ('general', 'JJ'), ('storage', 'NN'), ('unit', 'NN'), ('allocated', 'VBD'), ('wraps', 'NNS'), ('control', 'NN'), ('signals', 'NNS'), ('perform', 'VBP'), ('computations', 'NNS'), ('obtain', 'VB'), ('intermediate', 'JJ'), ('result', 'NN'), ('group', 'NN'), ('controller', 'NN'), ('configured', 'VBD'), ('splice', 'JJ'), ('intermediate', 'JJ'), ('results', 'NNS'), ('obtain', 'VB'), ('final', 'JJ'), ('computation', 'NN'), ('result', 'NN'), ('computing', 'VBG'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'VBP'), ('plurality', 'NN'), ('computing', 'VBG'), ('units', 'NNS'), ('includes', 'VBZ'), ('addition', 'NN'), ('computing', 'VBG'), ('unit', 'NN'), ('multiplication', 'NN'), ('computing', 'VBG'), ('unit', 'NN'), ('activation', 'NN'), ('computing', 'VBG'), ('unit', 'NN'), ('dedicated', 'VBN'), ('computing', 'VBG'), ('unit', 'NN'), ('computing', 'VBG'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'RB'), ('dedicated', 'VBD'), ('computing', 'VBG'), ('unit', 'NN'), ('includes', 'VBZ'), ('face', 'NN'), ('recognition', 'NN'), ('computing', 'VBG'), ('unit', 'NN'), ('graphics', 'NNS'), ('computing', 'VBG'), ('unit', 'NN'), ('fingerprint', 'NN'), ('computing', 'VBG'), ('unit', 'NN'), ('neural', 'JJ'), ('network', 'NN'), ('computing', 'VBG'), ('unit', 'NN'), ('computing', 'VBG'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('group', 'NN'), ('controller', 'NN'), ('configured', 'VBD'), ('computation', 'NN'), ('types', 'NNS'), ('plurality', 'NN'), ('control', 'NN'), ('signals', 'NNS'), ('graphics', 'NNS'), ('computations', 'NNS'), ('fingerprint', 'VBP'), ('identification', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('neural', 'JJ'), ('network', 'NN'), ('operations', 'NNS'), ('allocate', 'VBP'), ('plurality', 'NN'), ('control', 'NN'), ('signals', 'NNS'), ('face', 'VBP'), ('recognition', 'NN'), ('computing', 'VBG'), ('unit', 'NN'), ('graphics', 'NNS'), ('computing', 'VBG'), ('unit', 'NN'), ('fingerprint', 'NN'), ('computing', 'VBG'), ('unit', 'NN'), ('neural', 'JJ'), ('network', 'NN'), ('computing', 'VBG'), ('unit', 'NN'), ('respectively', 'RB'), ('computing', 'VBG'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'VBP'), ('first', 'JJ'), ('level', 'NN'), ('instruction', 'NN'), ('sequence', 'NN'), ('includes', 'VBZ'), ('long', 'JJ'), ('instruction', 'NN'), ('second', 'JJ'), ('level', 'NN'), ('instruction', 'NN'), ('sequence', 'NN'), ('includes', 'VBZ'), ('instruction', 'NN'), ('sequence', 'NN'), ('computing', 'VBG'), ('system', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('tree', 'JJ'), ('module', 'NN'), ('wherein', 'VBD'), ('tree', 'JJ'), ('module', 'NN'), ('includes', 'VBZ'), ('root', 'JJ'), ('port', 'NN'), ('plurality', 'NN'), ('branch', 'NN'), ('ports', 'NNS'), ('wherein', 'VBP'), ('root', 'JJ'), ('port', 'NN'), ('tree', 'NN'), ('module', 'NN'), ('connected', 'VBN'), ('group', 'NN'), ('controller', 'NN'), ('plurality', 'NN'), ('branch', 'NN'), ('ports', 'NNS'), ('tree', 'VBP'), ('module', 'NN'), ('connected', 'VBN'), ('computing', 'VBG'), ('unit', 'NN'), ('plurality', 'NN'), ('computing', 'VBG'), ('units', 'NNS'), ('respectively', 'RB'), ('tree', 'VBP'), ('module', 'NN'), ('configured', 'VBN'), ('forward', 'RB'), ('data', 'NN'), ('blocks', 'NNS'), ('wraps', 'VBP'), ('instruction', 'NN'), ('sequences', 'NNS'), ('group', 'NN'), ('controller', 'NN'), ('plurality', 'NN'), ('computing', 'VBG'), ('units', 'NNS'), ('computing', 'VBG'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'VBP'), ('tree', 'JJ'), ('module', 'NN'), ('n-ary', 'JJ'), ('tree', 'NN'), ('wherein', 'NN'), ('n', 'RB'), ('integer', 'RB'), ('greater', 'JJR'), ('equal', 'JJ'), ('computing', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('computing', 'VBG'), ('system', 'NN'), ('includes', 'VBZ'), ('branch', 'NN'), ('processing', 'NN'), ('circuit', 'NN'), ('branch', 'NN'), ('processing', 'VBG'), ('circuit', 'NN'), ('connected', 'VBN'), ('group', 'NN'), ('controller', 'NN'), ('plurality', 'NN'), ('computing', 'VBG'), ('units', 'NNS'), ('branch', 'NN'), ('processing', 'VBG'), ('circuit', 'NN'), ('configured', 'VBD'), ('forward', 'RB'), ('data', 'NNS'), ('wraps', 'NNS'), ('instruction', 'NN'), ('sequences', 'NNS'), ('group', 'NN'), ('controller', 'NN'), ('plurality', 'NN'), ('computing', 'VBG'), ('units', 'NNS'), ('computer', 'NN'), ('program', 'NN'), ('product', 'NN'), ('comprising', 'VBG'), ('non-instant', 'JJ'), ('computer', 'NN'), ('readable', 'JJ'), ('storage', 'NN'), ('medium', 'NN'), ('wherein', 'VBP'), ('computer', 'NN'), ('program', 'NN'), ('stored', 'VBD'), ('non-instant', 'JJ'), ('computer', 'NN'), ('readable', 'JJ'), ('storage', 'NN'), ('medium', 'NN'), ('computer', 'NN'), ('program', 'NN'), ('capable', 'JJ'), ('causing', 'VBG'), ('computer', 'NN'), ('perform', 'NN'), ('method', 'NN'), ('claims', 'VBZ'), ('-', ':'), ('operations', 'NNS'), ('method', 'VBP'), ('detecting', 'VBG'), ('body', 'NN'), ('information', 'NN'), ('one', 'CD'), ('passengers', 'NN'), ('vehicle', 'NN'), ('based', 'VBN'), ('humans', 'NNS'), (\"'\", 'POS'), ('status', 'NN'), ('recognition', 'NN'), ('comprising', 'VBG'), ('steps', 'NNS'), ('least', 'JJS'), ('one', 'CD'), ('interior', 'JJ'), ('image', 'NN'), ('interior', 'JJ'), ('vehicle', 'NN'), ('acquired', 'VBD'), ('passenger', 'JJR'), ('body', 'NN'), ('information-detecting', 'JJ'), ('device', 'NN'), ('performing', 'VBG'), ('process', 'NN'), ('inputting', 'VBG'), ('interior', 'JJ'), ('image', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('network', 'NN'), ('thereby', 'RB'), ('allow', 'VB'), ('face', 'NN'), ('recognition', 'NN'), ('network', 'NN'), ('detect', 'JJ'), ('faces', 'VBZ'), ('passengers', 'NNS'), ('interior', 'JJ'), ('image', 'NN'), ('thus', 'RB'), ('output', 'NN'), ('multiple', 'JJ'), ('pieces', 'NNS'), ('passenger', 'NN'), ('feature', 'NN'), ('information', 'NN'), ('corresponding', 'VBG'), ('detected', 'VBD'), ('faces', 'VBZ'), ('ii', 'JJ'), ('process', 'NN'), ('inputting', 'VBG'), ('interior', 'JJ'), ('image', 'NN'), ('body', 'NN'), ('recognition', 'NN'), ('network', 'NN'), ('thereby', 'RB'), ('allow', 'VB'), ('body', 'NN'), ('recognition', 'NN'), ('network', 'NN'), ('detect', 'JJ'), ('bodies', 'NNS'), ('passengers', 'NNS'), ('interior', 'JJ'), ('image', 'NN'), ('thus', 'RB'), ('output', 'NN'), ('body-part', 'JJ'), ('length', 'NN'), ('information', 'NN'), ('detected', 'VBD'), ('bodies', 'NNS'), ('b', 'IN'), ('passenger', 'NN'), ('body', 'NN'), ('information-detecting', 'JJ'), ('device', 'NN'), ('performing', 'VBG'), ('process', 'NN'), ('retrieving', 'VBG'), ('specific', 'JJ'), ('height', 'JJ'), ('mapping', 'NN'), ('information', 'NN'), ('corresponding', 'VBG'), ('specific', 'JJ'), ('passenger', 'NN'), ('feature', 'NN'), ('information', 'NN'), ('specific', 'JJ'), ('passenger', 'NN'), ('height', 'VBD'), ('mapping', 'VBG'), ('table', 'NN'), ('stores', 'NNS'), ('height', 'VBD'), ('mapping', 'VBG'), ('information', 'NN'), ('representing', 'VBG'), ('respective', 'JJ'), ('one', 'CD'), ('predetermined', 'VBD'), ('ratios', 'NNS'), ('one', 'CD'), ('segment', 'NN'), ('body', 'NN'), ('portions', 'NNS'), ('human', 'JJ'), ('groups', 'NNS'), ('heights', 'NNS'), ('per', 'IN'), ('human', 'JJ'), ('groups', 'NNS'), ('process', 'NN'), ('acquiring', 'VBG'), ('specific', 'JJ'), ('height', 'NN'), ('specific', 'JJ'), ('passenger', 'NN'), ('specific', 'JJ'), ('height', 'VBD'), ('mapping', 'VBG'), ('information', 'NN'), ('referring', 'VBG'), ('specific', 'JJ'), ('body-part', 'JJ'), ('length', 'NN'), ('information', 'NN'), ('specific', 'JJ'), ('passenger', 'NN'), ('process', 'NN'), ('retrieving', 'VBG'), ('specific', 'JJ'), ('weight', 'NN'), ('mapping', 'VBG'), ('information', 'NN'), ('corresponding', 'VBG'), ('specific', 'JJ'), ('passenger', 'NN'), ('feature', 'NN'), ('information', 'NN'), ('weight', 'VBD'), ('mapping', 'VBG'), ('table', 'NN'), ('stores', 'NNS'), ('multiple', 'JJ'), ('pieces', 'NNS'), ('weight', 'VBD'), ('mapping', 'VBG'), ('information', 'NN'), ('representing', 'VBG'), ('predetermined', 'VBN'), ('correlations', 'NNS'), ('heights', 'NNS'), ('weights', 'NNS'), ('per', 'IN'), ('human', 'JJ'), ('groups', 'NNS'), ('process', 'NN'), ('acquiring', 'VBG'), ('weight', 'NN'), ('specific', 'JJ'), ('passenger', 'NN'), ('specific', 'JJ'), ('weight', 'VBD'), ('mapping', 'VBG'), ('information', 'NN'), ('referring', 'VBG'), ('specific', 'JJ'), ('height', 'NN'), ('specific', 'JJ'), ('passenger', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'JJ'), ('step', 'NN'), ('passenger', 'NN'), ('body', 'NN'), ('information-detecting', 'JJ'), ('device', 'NN'), ('performs', 'NNS'), ('process', 'NN'), ('inputting', 'VBG'), ('interior', 'JJ'), ('image', 'NN'), ('body', 'NN'), ('recognition', 'NN'), ('network', 'NN'), ('thereby', 'RB'), ('allow', 'VB'), ('body', 'NN'), ('recognition', 'NN'), ('network', 'NN'), ('output', 'NN'), ('one', 'CD'), ('feature', 'NN'), ('tensors', 'VBZ'), ('one', 'CD'), ('channels', 'NNS'), ('corresponding', 'VBG'), ('interior', 'JJ'), ('image', 'NN'), ('via', 'IN'), ('feature', 'NN'), ('extraction', 'NN'), ('network', 'NN'), ('ii', 'JJ'), ('generate', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('keypoint', 'NN'), ('heatmap', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('part', 'NN'), ('affinity', 'NN'), ('field', 'NN'), ('one', 'CD'), ('channels', 'NNS'), ('corresponding', 'VBG'), ('feature', 'NN'), ('tensors', 'NNS'), ('via', 'IN'), ('keypoint', 'NN'), ('heatmap', 'NN'), ('&', 'CC'), ('part', 'NN'), ('affinity', 'NN'), ('field', 'NN'), ('extractor', 'NN'), ('iii', 'JJ'), ('extract', 'JJ'), ('keypoints', 'NNS'), ('keypoint', 'VB'), ('heatmap', 'NN'), ('via', 'IN'), ('keypoint', 'NN'), ('detector', 'NN'), ('group', 'NN'), ('extracted', 'VBD'), ('keypoints', 'NNS'), ('referring', 'VBG'), ('part', 'NN'), ('affinity', 'NN'), ('field', 'NN'), ('thus', 'RB'), ('generate', 'VB'), ('body', 'NN'), ('parts', 'NNS'), ('per', 'IN'), ('passengers', 'NNS'), ('result', 'VBP'), ('allow', 'IN'), ('body', 'NN'), ('recognition', 'NN'), ('network', 'NN'), ('output', 'NN'), ('multiple', 'JJ'), ('pieces', 'NNS'), ('body-part', 'JJ'), ('length', 'NN'), ('information', 'NN'), ('passengers', 'NNS'), ('referring', 'VBG'), ('body', 'NN'), ('parts', 'NNS'), ('per', 'IN'), ('passengers', 'NNS'), ('method', 'VBP'), ('claim', 'NN'), ('wherein', 'NN'), ('feature', 'NN'), ('extraction', 'NN'), ('network', 'NN'), ('includes', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('convolutional', 'JJ'), ('layer', 'NN'), ('applies', 'NNS'), ('least', 'VBP'), ('one', 'CD'), ('convolution', 'NN'), ('operation', 'NN'), ('interior', 'JJ'), ('image', 'NN'), ('thereby', 'NN'), ('output', 'NN'), ('feature', 'NN'), ('tensors', 'NNS'), ('method', 'VBP'), ('claim', 'NN'), ('wherein', 'NN'), ('keypoint', 'NN'), ('heatmap', 'NN'), ('&', 'CC'), ('part', 'NN'), ('affinity', 'NN'), ('field', 'NN'), ('extractor', 'NN'), ('includes', 'VBZ'), ('one', 'CD'), ('fully', 'RB'), ('convolutional', 'JJ'), ('network', 'NN'), ('×', 'NNP'), ('convolutional', 'NN'), ('layer', 'NN'), ('applies', 'VBZ'), ('fully-convolution', 'NN'), ('operation', 'NN'), ('×', 'NNP'), ('convolution', 'NN'), ('operation', 'NN'), ('feature', 'NN'), ('tensors', 'NNS'), ('thereby', 'RB'), ('generate', 'VBP'), ('keypoint', 'NN'), ('heatmap', 'NN'), ('part', 'NN'), ('affinity', 'NN'), ('field', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'VBD'), ('keypoint', 'JJ'), ('detector', 'NN'), ('connects', 'NNS'), ('referring', 'VBG'), ('part', 'NN'), ('affinity', 'NN'), ('field', 'NN'), ('pairs', 'VBZ'), ('respectively', 'RB'), ('highest', 'JJS'), ('mutual', 'JJ'), ('connection', 'NN'), ('probabilities', 'NNS'), ('connected', 'VBN'), ('among', 'IN'), ('extracted', 'JJ'), ('keypoints', 'NNS'), ('thereby', 'RB'), ('group', 'NN'), ('extracted', 'VBD'), ('keypoints', 'NNS'), ('method', 'JJ'), ('claim', 'NN'), ('wherein', 'NN'), ('feature', 'NN'), ('extraction', 'NN'), ('network', 'NN'), ('keypoint', 'NN'), ('heatmap', 'NN'), ('&', 'CC'), ('part', 'NN'), ('affinity', 'NN'), ('field', 'NN'), ('extractor', 'NN'), ('learned', 'VBD'), ('learning', 'JJ'), ('device', 'NN'), ('performing', 'VBG'), ('process', 'NN'), ('inputting', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('training', 'NN'), ('image', 'NN'), ('including', 'VBG'), ('one', 'CD'), ('objects', 'VBZ'), ('training', 'VBG'), ('feature', 'NN'), ('extraction', 'NN'), ('network', 'NN'), ('thereby', 'RB'), ('allow', 'JJ'), ('feature', 'NN'), ('extraction', 'NN'), ('network', 'NN'), ('generate', 'VBP'), ('one', 'CD'), ('feature', 'NN'), ('tensors', 'NNS'), ('training', 'VBG'), ('one', 'CD'), ('channels', 'NNS'), ('applying', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('convolutional', 'JJ'), ('operation', 'NN'), ('training', 'NN'), ('image', 'NN'), ('ii', 'JJ'), ('process', 'NN'), ('inputting', 'VBG'), ('feature', 'NN'), ('tensors', 'NNS'), ('training', 'VBG'), ('keypoint', 'NN'), ('heatmap', 'NN'), ('&', 'CC'), ('part', 'NN'), ('affinity', 'NN'), ('field', 'NN'), ('extractor', 'NN'), ('thereby', 'RB'), ('allow', 'JJ'), ('keypoint', 'NN'), ('heatmap', 'NN'), ('&', 'CC'), ('part', 'NN'), ('affinity', 'NN'), ('field', 'NN'), ('extractor', 'NN'), ('generate', 'VBP'), ('one', 'CD'), ('keypoint', 'NN'), ('heatmaps', 'VBZ'), ('training', 'VBG'), ('one', 'CD'), ('part', 'NN'), ('affinity', 'NN'), ('fields', 'NNS'), ('training', 'VBG'), ('one', 'CD'), ('channels', 'JJ'), ('feature', 'NN'), ('tensors', 'NNS'), ('training', 'VBG'), ('iii', 'JJ'), ('process', 'NN'), ('inputting', 'VBG'), ('keypoint', 'NN'), ('heatmaps', 'NNS'), ('training', 'VBG'), ('part', 'NN'), ('affinity', 'NN'), ('fields', 'NNS'), ('training', 'VBG'), ('keypoint', 'NN'), ('detector', 'NN'), ('thereby', 'RB'), ('allow', 'JJ'), ('keypoint', 'NN'), ('detector', 'NN'), ('extract', 'JJ'), ('keypoints', 'NNS'), ('training', 'VBG'), ('keypoint', 'NN'), ('heatmaps', 'NNS'), ('training', 'VBG'), ('process', 'NN'), ('grouping', 'NN'), ('extracted', 'VBD'), ('keypoints', 'NNS'), ('training', 'VBG'), ('referring', 'VBG'), ('part', 'NN'), ('affinity', 'NN'), ('fields', 'NNS'), ('training', 'VBG'), ('thereby', 'RB'), ('detect', 'JJ'), ('keypoints', 'NNS'), ('per', 'IN'), ('objects', 'NNS'), ('training', 'VBG'), ('iv', 'JJ'), ('process', 'NN'), ('allowing', 'VBG'), ('loss', 'NN'), ('layer', 'NN'), ('calculate', 'VBP'), ('one', 'CD'), ('losses', 'NNS'), ('referring', 'VBG'), ('keypoints', 'NNS'), ('per', 'IN'), ('objects', 'NNS'), ('training', 'VBG'), ('corresponding', 'VBG'), ('ground', 'NN'), ('truths', 'NNS'), ('thereby', 'RB'), ('adjust', 'VBP'), ('one', 'CD'), ('parameters', 'NNS'), ('feature', 'VBP'), ('extraction', 'NN'), ('network', 'NN'), ('keypoint', 'NN'), ('heatmap', 'NN'), ('&', 'CC'), ('part', 'NN'), ('affinity', 'NN'), ('field', 'NN'), ('extractor', 'NN'), ('losses', 'NNS'), ('minimized', 'VBN'), ('backpropagation', 'NN'), ('using', 'VBG'), ('losses', 'NNS'), ('method', 'JJ'), ('claim', 'NN'), ('wherein', 'JJ'), ('step', 'NN'), ('passenger', 'NN'), ('body', 'NN'), ('information-detecting', 'JJ'), ('device', 'NN'), ('performs', 'NNS'), ('process', 'NN'), ('inputting', 'VBG'), ('interior', 'JJ'), ('image', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('network', 'NN'), ('thereby', 'RB'), ('allow', 'VB'), ('face', 'NN'), ('recognition', 'NN'), ('network', 'NN'), ('detect', 'JJ'), ('faces', 'VBZ'), ('passengers', 'NNS'), ('located', 'VBN'), ('interior', 'JJ'), ('image', 'NN'), ('via', 'IN'), ('face', 'NN'), ('detector', 'NN'), ('output', 'NN'), ('multiple', 'JJ'), ('pieces', 'NNS'), ('passenger', 'NN'), ('feature', 'NN'), ('information', 'NN'), ('facial', 'JJ'), ('images', 'NNS'), ('via', 'IN'), ('facial', 'JJ'), ('feature', 'NN'), ('classifier', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'JJ'), ('step', 'NN'), ('passenger', 'NN'), ('body', 'NN'), ('information-detecting', 'JJ'), ('device', 'NN'), ('performs', 'NNS'), ('process', 'NN'), ('inputting', 'VBG'), ('interior', 'JJ'), ('image', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('network', 'NN'), ('thereby', 'RB'), ('allow', 'VB'), ('face', 'NN'), ('recognition', 'NN'), ('network', 'NN'), ('apply', 'RB'), ('least', 'JJS'), ('one', 'CD'), ('convolution', 'NN'), ('operation', 'NN'), ('interior', 'JJ'), ('image', 'NN'), ('thus', 'RB'), ('output', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('feature', 'NN'), ('map', 'NN'), ('corresponding', 'VBG'), ('interior', 'JJ'), ('image', 'NN'), ('via', 'IN'), ('least', 'JJS'), ('one', 'CD'), ('convolutional', 'JJ'), ('layer', 'NN'), ('ii', 'NN'), ('output', 'NN'), ('one', 'CD'), ('proposal', 'NN'), ('boxes', 'VBZ'), ('passengers', 'NNS'), ('estimated', 'VBN'), ('located', 'JJ'), ('feature', 'NN'), ('map', 'NN'), ('via', 'IN'), ('region', 'NN'), ('proposal', 'NN'), ('network', 'NN'), ('iii', 'VBP'), ('apply', 'VB'), ('pooling', 'VBG'), ('operation', 'NN'), ('one', 'CD'), ('regions', 'NNS'), ('corresponding', 'VBG'), ('proposal', 'NN'), ('boxes', 'NNS'), ('feature', 'VBP'), ('map', 'JJ'), ('thus', 'RB'), ('output', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('feature', 'NN'), ('vector', 'NN'), ('via', 'IN'), ('pooling', 'VBG'), ('layer', 'NN'), ('iv', 'JJ'), ('apply', 'RB'), ('fully-connected', 'JJ'), ('operation', 'NN'), ('feature', 'NN'), ('vector', 'NN'), ('thus', 'RB'), ('output', 'NN'), ('multiple', 'JJ'), ('pieces', 'NNS'), ('passenger', 'NN'), ('feature', 'NN'), ('information', 'NN'), ('corresponding', 'VBG'), ('faces', 'VBZ'), ('passengers', 'NNS'), ('corresponding', 'VBG'), ('proposal', 'NN'), ('boxes', 'NNS'), ('via', 'IN'), ('fully', 'RB'), ('connected', 'VBN'), ('layer', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('multiple', 'JJ'), ('pieces', 'NNS'), ('passenger', 'NN'), ('feature', 'NN'), ('information', 'NN'), ('include', 'VBP'), ('ages', 'VBZ'), ('genders', 'NNS'), ('races', 'NNS'), ('corresponding', 'VBG'), ('passengers', 'NNS'), ('passenger', 'NN'), ('body', 'NN'), ('information-detecting', 'JJ'), ('device', 'NN'), ('detecting', 'VBG'), ('body', 'NN'), ('information', 'NN'), ('one', 'CD'), ('passengers', 'NN'), ('vehicle', 'NN'), ('based', 'VBN'), ('humans', 'NNS'), (\"'\", 'POS'), ('status', 'NN'), ('recognition', 'NN'), ('comprising', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('memory', 'NN'), ('stores', 'NNS'), ('instructions', 'NNS'), ('least', 'VBP'), ('one', 'CD'), ('processor', 'NN'), ('configured', 'VBD'), ('execute', 'JJ'), ('instructions', 'NNS'), ('perform', 'VB'), ('support', 'NN'), ('another', 'DT'), ('device', 'NN'), ('perform', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('interior', 'JJ'), ('image', 'NN'), ('interior', 'JJ'), ('vehicle', 'NN'), ('acquired', 'VBD'), ('process', 'NN'), ('inputting', 'VBG'), ('interior', 'JJ'), ('image', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('network', 'NN'), ('thereby', 'RB'), ('allow', 'VB'), ('face', 'NN'), ('recognition', 'NN'), ('network', 'NN'), ('detect', 'JJ'), ('faces', 'VBZ'), ('passengers', 'NNS'), ('interior', 'JJ'), ('image', 'NN'), ('thus', 'RB'), ('output', 'NN'), ('multiple', 'JJ'), ('pieces', 'NNS'), ('passenger', 'NN'), ('feature', 'NN'), ('information', 'NN'), ('corresponding', 'VBG'), ('detected', 'VBD'), ('faces', 'VBZ'), ('ii', 'JJ'), ('process', 'NN'), ('inputting', 'VBG'), ('interior', 'JJ'), ('image', 'NN'), ('body', 'NN'), ('recognition', 'NN'), ('network', 'NN'), ('thereby', 'RB'), ('allow', 'VB'), ('body', 'NN'), ('recognition', 'NN'), ('network', 'NN'), ('detect', 'JJ'), ('bodies', 'NNS'), ('passengers', 'NNS'), ('interior', 'JJ'), ('image', 'NN'), ('thus', 'RB'), ('output', 'NN'), ('body-part', 'JJ'), ('length', 'NN'), ('information', 'NN'), ('detected', 'VBD'), ('bodies', 'NNS'), ('ii', 'JJ'), ('process', 'NN'), ('retrieving', 'VBG'), ('specific', 'JJ'), ('height', 'JJ'), ('mapping', 'NN'), ('information', 'NN'), ('corresponding', 'VBG'), ('specific', 'JJ'), ('passenger', 'NN'), ('feature', 'NN'), ('information', 'NN'), ('specific', 'JJ'), ('passenger', 'NN'), ('height', 'VBD'), ('mapping', 'VBG'), ('table', 'NN'), ('stores', 'NNS'), ('height', 'VBD'), ('mapping', 'VBG'), ('information', 'NN'), ('representing', 'VBG'), ('respective', 'JJ'), ('one', 'CD'), ('predetermined', 'VBD'), ('ratios', 'NNS'), ('one', 'CD'), ('segment', 'NN'), ('body', 'NN'), ('portions', 'NNS'), ('human', 'JJ'), ('groups', 'NNS'), ('heights', 'NNS'), ('per', 'IN'), ('human', 'JJ'), ('groups', 'NNS'), ('process', 'NN'), ('acquiring', 'VBG'), ('specific', 'JJ'), ('height', 'NN'), ('specific', 'JJ'), ('passenger', 'NN'), ('specific', 'JJ'), ('height', 'VBD'), ('mapping', 'VBG'), ('information', 'NN'), ('referring', 'VBG'), ('specific', 'JJ'), ('body-part', 'JJ'), ('length', 'NN'), ('information', 'NN'), ('specific', 'JJ'), ('passenger', 'NN'), ('process', 'NN'), ('retrieving', 'VBG'), ('specific', 'JJ'), ('weight', 'NN'), ('mapping', 'VBG'), ('information', 'NN'), ('corresponding', 'VBG'), ('specific', 'JJ'), ('passenger', 'NN'), ('feature', 'NN'), ('information', 'NN'), ('weight', 'VBD'), ('mapping', 'VBG'), ('table', 'NN'), ('stores', 'NNS'), ('multiple', 'JJ'), ('pieces', 'NNS'), ('weight', 'VBD'), ('mapping', 'VBG'), ('information', 'NN'), ('representing', 'VBG'), ('predetermined', 'VBN'), ('correlations', 'NNS'), ('heights', 'NNS'), ('weights', 'NNS'), ('per', 'IN'), ('human', 'JJ'), ('groups', 'NNS'), ('process', 'NN'), ('acquiring', 'VBG'), ('weight', 'NN'), ('specific', 'JJ'), ('passenger', 'NN'), ('specific', 'JJ'), ('weight', 'VBD'), ('mapping', 'VBG'), ('information', 'NN'), ('referring', 'VBG'), ('specific', 'JJ'), ('height', 'NN'), ('specific', 'JJ'), ('passenger', 'NN'), ('passenger', 'NN'), ('body', 'NN'), ('information-detecting', 'JJ'), ('device', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('process', 'NN'), ('processor', 'NN'), ('performs', 'NNS'), ('process', 'NN'), ('inputting', 'VBG'), ('interior', 'JJ'), ('image', 'NN'), ('body', 'NN'), ('recognition', 'NN'), ('network', 'NN'), ('thereby', 'RB'), ('allow', 'VB'), ('body', 'NN'), ('recognition', 'NN'), ('network', 'NN'), ('output', 'NN'), ('one', 'CD'), ('feature', 'NN'), ('tensors', 'VBZ'), ('one', 'CD'), ('channels', 'NNS'), ('corresponding', 'VBG'), ('interior', 'JJ'), ('image', 'NN'), ('via', 'IN'), ('feature', 'NN'), ('extraction', 'NN'), ('network', 'NN'), ('ii', 'JJ'), ('generate', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('keypoint', 'NN'), ('heatmap', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('part', 'NN'), ('affinity', 'NN'), ('field', 'NN'), ('one', 'CD'), ('channels', 'NNS'), ('corresponding', 'VBG'), ('feature', 'NN'), ('tensors', 'NNS'), ('via', 'IN'), ('keypoint', 'NN'), ('heatmap', 'NN'), ('&', 'CC'), ('part', 'NN'), ('affinity', 'NN'), ('field', 'NN'), ('extractor', 'NN'), ('iii', 'JJ'), ('extract', 'JJ'), ('keypoints', 'NNS'), ('keypoint', 'VB'), ('heatmap', 'NN'), ('via', 'IN'), ('keypoint', 'NN'), ('detector', 'NN'), ('group', 'NN'), ('extracted', 'VBD'), ('keypoints', 'NNS'), ('referring', 'VBG'), ('part', 'NN'), ('affinity', 'NN'), ('field', 'NN'), ('thus', 'RB'), ('generate', 'VB'), ('body', 'NN'), ('parts', 'NNS'), ('per', 'IN'), ('passengers', 'NNS'), ('result', 'VBP'), ('allow', 'IN'), ('body', 'NN'), ('recognition', 'NN'), ('network', 'NN'), ('output', 'NN'), ('multiple', 'JJ'), ('pieces', 'NNS'), ('body-part', 'JJ'), ('length', 'NN'), ('information', 'NN'), ('passengers', 'NNS'), ('referring', 'VBG'), ('body', 'NN'), ('parts', 'NNS'), ('per', 'IN'), ('passengers', 'NNS'), ('passenger', 'VBP'), ('body', 'NN'), ('information-detecting', 'JJ'), ('device', 'NN'), ('claim', 'NN'), ('wherein', 'VBD'), ('keypoint', 'NNP'), ('heatmap', 'NN'), ('&', 'CC'), ('part', 'NN'), ('affinity', 'NN'), ('field', 'NN'), ('extractor', 'NN'), ('includes', 'VBZ'), ('one', 'CD'), ('fully', 'RB'), ('convolutional', 'JJ'), ('network', 'NN'), ('×', 'NNP'), ('convolutional', 'NN'), ('layer', 'NN'), ('applies', 'VBZ'), ('fully-convolution', 'NN'), ('operation', 'NN'), ('×', 'NNP'), ('convolution', 'NN'), ('operation', 'NN'), ('feature', 'NN'), ('tensors', 'NNS'), ('thereby', 'RB'), ('generate', 'VBP'), ('keypoint', 'NN'), ('heatmap', 'NN'), ('part', 'NN'), ('affinity', 'NN'), ('field', 'NN'), ('passenger', 'NN'), ('body', 'NN'), ('information-detecting', 'JJ'), ('device', 'NN'), ('claim', 'NN'), ('wherein', 'VBD'), ('keypoint', 'JJ'), ('detector', 'NN'), ('connects', 'NNS'), ('referring', 'VBG'), ('part', 'NN'), ('affinity', 'NN'), ('field', 'NN'), ('pairs', 'VBZ'), ('respectively', 'RB'), ('highest', 'JJS'), ('mutual', 'JJ'), ('connection', 'NN'), ('probabilities', 'NNS'), ('connected', 'VBN'), ('among', 'IN'), ('extracted', 'JJ'), ('keypoints', 'NNS'), ('thereby', 'RB'), ('group', 'NN'), ('extracted', 'VBD'), ('keypoints', 'NNS'), ('passenger', 'NN'), ('body', 'NN'), ('information-detecting', 'JJ'), ('device', 'NN'), ('claim', 'NN'), ('wherein', 'JJ'), ('feature', 'NN'), ('extraction', 'NN'), ('network', 'NN'), ('keypoint', 'NN'), ('heatmap', 'NN'), ('&', 'CC'), ('part', 'NN'), ('affinity', 'NN'), ('field', 'NN'), ('extractor', 'NN'), ('learned', 'VBD'), ('learning', 'JJ'), ('device', 'NN'), ('performing', 'VBG'), ('process', 'NN'), ('inputting', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('training', 'NN'), ('image', 'NN'), ('including', 'VBG'), ('one', 'CD'), ('objects', 'VBZ'), ('training', 'VBG'), ('feature', 'NN'), ('extraction', 'NN'), ('network', 'NN'), ('thereby', 'RB'), ('allow', 'JJ'), ('feature', 'NN'), ('extraction', 'NN'), ('network', 'NN'), ('generate', 'VBP'), ('one', 'CD'), ('feature', 'NN'), ('tensors', 'NNS'), ('training', 'VBG'), ('one', 'CD'), ('channels', 'NNS'), ('applying', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('convolutional', 'JJ'), ('operation', 'NN'), ('training', 'NN'), ('image', 'NN'), ('ii', 'JJ'), ('process', 'NN'), ('inputting', 'VBG'), ('feature', 'NN'), ('tensors', 'NNS'), ('training', 'VBG'), ('keypoint', 'NN'), ('heatmap', 'NN'), ('&', 'CC'), ('part', 'NN'), ('affinity', 'NN'), ('field', 'NN'), ('extractor', 'NN'), ('thereby', 'RB'), ('allow', 'JJ'), ('keypoint', 'NN'), ('heatmap', 'NN'), ('&', 'CC'), ('part', 'NN'), ('affinity', 'NN'), ('field', 'NN'), ('extractor', 'NN'), ('generate', 'VBP'), ('one', 'CD'), ('keypoint', 'NN'), ('heatmaps', 'VBZ'), ('training', 'VBG'), ('one', 'CD'), ('part', 'NN'), ('affinity', 'NN'), ('fields', 'NNS'), ('training', 'VBG'), ('one', 'CD'), ('channels', 'JJ'), ('feature', 'NN'), ('tensors', 'NNS'), ('training', 'VBG'), ('iii', 'JJ'), ('process', 'NN'), ('inputting', 'VBG'), ('keypoint', 'NN'), ('heatmaps', 'NNS'), ('training', 'VBG'), ('part', 'NN'), ('affinity', 'NN'), ('fields', 'NNS'), ('training', 'VBG'), ('keypoint', 'NN'), ('detector', 'NN'), ('thereby', 'RB'), ('allow', 'JJ'), ('keypoint', 'NN'), ('detector', 'NN'), ('extract', 'JJ'), ('keypoints', 'NNS'), ('training', 'VBG'), ('keypoint', 'NN'), ('heatmaps', 'NNS'), ('training', 'VBG'), ('process', 'NN'), ('grouping', 'NN'), ('extracted', 'VBD'), ('keypoints', 'NNS'), ('training', 'VBG'), ('referring', 'VBG'), ('part', 'NN'), ('affinity', 'NN'), ('fields', 'NNS'), ('training', 'VBG'), ('thereby', 'RB'), ('detect', 'JJ'), ('keypoints', 'NNS'), ('per', 'IN'), ('objects', 'NNS'), ('training', 'VBG'), ('iv', 'JJ'), ('process', 'NN'), ('allowing', 'VBG'), ('loss', 'NN'), ('layer', 'NN'), ('calculate', 'VBP'), ('one', 'CD'), ('losses', 'NNS'), ('referring', 'VBG'), ('keypoints', 'NNS'), ('per', 'IN'), ('objects', 'NNS'), ('training', 'VBG'), ('corresponding', 'VBG'), ('ground', 'NN'), ('truths', 'NNS'), ('thereby', 'RB'), ('adjust', 'VBP'), ('one', 'CD'), ('parameters', 'NNS'), ('feature', 'VBP'), ('extraction', 'NN'), ('network', 'NN'), ('keypoint', 'NN'), ('heatmap', 'NN'), ('&', 'CC'), ('part', 'NN'), ('affinity', 'NN'), ('field', 'NN'), ('extractor', 'NN'), ('losses', 'NNS'), ('minimized', 'VBN'), ('backpropagation', 'NN'), ('using', 'VBG'), ('losses', 'NNS'), ('passenger', 'NN'), ('body', 'NN'), ('information-detecting', 'JJ'), ('device', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('process', 'NN'), ('processor', 'NN'), ('performs', 'NNS'), ('process', 'NN'), ('inputting', 'VBG'), ('interior', 'JJ'), ('image', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('network', 'NN'), ('thereby', 'RB'), ('allow', 'VB'), ('face', 'NN'), ('recognition', 'NN'), ('network', 'NN'), ('apply', 'RB'), ('least', 'JJS'), ('one', 'CD'), ('convolution', 'NN'), ('operation', 'NN'), ('interior', 'JJ'), ('image', 'NN'), ('thus', 'RB'), ('output', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('feature', 'NN'), ('map', 'NN'), ('corresponding', 'VBG'), ('interior', 'JJ'), ('image', 'NN'), ('via', 'IN'), ('least', 'JJS'), ('one', 'CD'), ('convolutional', 'JJ'), ('layer', 'NN'), ('ii', 'NN'), ('output', 'NN'), ('one', 'CD'), ('proposal', 'NN'), ('boxes', 'VBZ'), ('passengers', 'NNS'), ('estimated', 'VBN'), ('located', 'JJ'), ('feature', 'NN'), ('map', 'NN'), ('via', 'IN'), ('region', 'NN'), ('proposal', 'NN'), ('network', 'NN'), ('iii', 'VBP'), ('apply', 'VB'), ('pooling', 'VBG'), ('operation', 'NN'), ('one', 'CD'), ('regions', 'NNS'), ('corresponding', 'VBG'), ('proposal', 'NN'), ('boxes', 'NNS'), ('feature', 'VBP'), ('map', 'JJ'), ('thus', 'RB'), ('output', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('feature', 'NN'), ('vector', 'NN'), ('via', 'IN'), ('pooling', 'VBG'), ('layer', 'NN'), ('iv', 'JJ'), ('apply', 'RB'), ('fully-connected', 'JJ'), ('operation', 'NN'), ('feature', 'NN'), ('vector', 'NN'), ('thus', 'RB'), ('output', 'NN'), ('multiple', 'JJ'), ('pieces', 'NNS'), ('passenger', 'NN'), ('feature', 'NN'), ('information', 'NN'), ('corresponding', 'VBG'), ('faces', 'VBZ'), ('passengers', 'NNS'), ('corresponding', 'VBG'), ('proposal', 'NN'), ('boxes', 'NNS'), ('via', 'IN'), ('fully', 'RB'), ('connected', 'VBN'), ('layer', 'NN'), ('computer', 'NN'), ('implemented', 'VBD'), ('method', 'JJ'), ('performing', 'VBG'), ('video', 'NN'), ('coding', 'VBG'), ('based', 'VBN'), ('face', 'NN'), ('detection', 'NN'), ('comprising', 'VBG'), ('receiving', 'VBG'), ('video', 'NN'), ('frame', 'NN'), ('comprising', 'VBG'), ('one', 'CD'), ('plurality', 'NN'), ('video', 'NN'), ('frames', 'NNS'), ('video', 'VBP'), ('sequence', 'NN'), ('determining', 'VBG'), ('video', 'NN'), ('frame', 'NN'), ('key', 'JJ'), ('frame', 'NN'), ('video', 'NN'), ('sequence', 'NN'), ('performing', 'VBG'), ('response', 'NN'), ('video', 'NN'), ('frame', 'NN'), ('key', 'JJ'), ('frame', 'NN'), ('video', 'JJ'), ('sequence', 'NN'), ('multi-stage', 'NN'), ('facial', 'JJ'), ('search', 'NN'), ('video', 'NN'), ('frame', 'NN'), ('based', 'VBN'), ('predetermined', 'JJ'), ('feature', 'NN'), ('templates', 'NNS'), ('predetermined', 'VBD'), ('number', 'NN'), ('stages', 'NNS'), ('determine', 'VBP'), ('first', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('second', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('video', 'NN'), ('frame', 'NN'), ('testing', 'VBG'), ('first', 'JJ'), ('second', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('regions', 'NNS'), ('based', 'VBN'), ('skin', 'JJ'), ('tone', 'NN'), ('information', 'NN'), ('determine', 'NN'), ('first', 'RB'), ('candidate', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('valid', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('second', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('invalid', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('rejecting', 'VBG'), ('second', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('outputting', 'VBG'), ('first', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('encoding', 'VBG'), ('video', 'NN'), ('frame', 'NN'), ('based', 'VBN'), ('least', 'JJS'), ('part', 'NN'), ('first', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('valid', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('generate', 'NN'), ('coded', 'VBD'), ('bitstream', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('skin', 'VBD'), ('tone', 'NN'), ('information', 'NN'), ('comprises', 'VBZ'), ('skin', 'JJ'), ('probability', 'NN'), ('map', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('said', 'VBD'), ('testing', 'VBG'), ('first', 'JJ'), ('second', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('regions', 'NNS'), ('based', 'VBN'), ('skin', 'JJ'), ('tone', 'NN'), ('information', 'NN'), ('performed', 'VBN'), ('response', 'NN'), ('video', 'NN'), ('frame', 'NN'), ('key', 'JJ'), ('frame', 'NN'), ('video', 'NN'), ('sequence', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('first', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('comprises', 'VBZ'), ('rectangular', 'JJ'), ('region', 'NN'), ('method', 'NN'), ('comprising', 'VBG'), ('determining', 'VBG'), ('free', 'JJ'), ('form', 'NN'), ('shape', 'NN'), ('face', 'NN'), ('region', 'NN'), ('corresponding', 'VBG'), ('first', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('wherein', 'VBD'), ('free', 'JJ'), ('form', 'NN'), ('shape', 'NN'), ('face', 'NN'), ('region', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('pixel', 'NN'), ('accuracy', 'NN'), ('small', 'JJ'), ('block', 'NN'), ('pixels', 'NNS'), ('accuracy', 'VBP'), ('method', 'JJ'), ('claim', 'NN'), ('wherein', 'IN'), ('determining', 'VBG'), ('free', 'JJ'), ('form', 'NN'), ('shape', 'NN'), ('face', 'NN'), ('region', 'NN'), ('comprises', 'VBZ'), ('generating', 'VBG'), ('enhanced', 'VBN'), ('skip', 'JJ'), ('probability', 'NN'), ('map', 'NN'), ('corresponding', 'VBG'), ('first', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('binarizing', 'VBG'), ('enhanced', 'VBD'), ('skip', 'JJ'), ('probability', 'NN'), ('map', 'NN'), ('overlaying', 'VBG'), ('binarized', 'VBN'), ('enhanced', 'JJ'), ('skip', 'NN'), ('probability', 'NN'), ('map', 'NN'), ('least', 'JJS'), ('portion', 'NN'), ('video', 'NN'), ('frame', 'NN'), ('provide', 'VBP'), ('free', 'JJ'), ('form', 'NN'), ('shape', 'NN'), ('face', 'NN'), ('region', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('second', 'JJ'), ('video', 'NN'), ('frame', 'NN'), ('comprises', 'VBZ'), ('non-key', 'JJ'), ('frame', 'NN'), ('video', 'NN'), ('sequence', 'NN'), ('method', 'NN'), ('comprising', 'VBG'), ('performing', 'VBG'), ('face', 'NN'), ('detection', 'NN'), ('second', 'JJ'), ('video', 'NN'), ('frame', 'NN'), ('video', 'NN'), ('sequence', 'NN'), ('based', 'VBN'), ('free', 'JJ'), ('form', 'NN'), ('shape', 'NN'), ('face', 'NN'), ('region', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('tracking', 'VBG'), ('second', 'JJ'), ('free', 'JJ'), ('form', 'NN'), ('shape', 'NN'), ('face', 'NN'), ('region', 'NN'), ('second', 'JJ'), ('video', 'NN'), ('frame', 'NN'), ('based', 'VBN'), ('free', 'JJ'), ('form', 'NN'), ('shape', 'NN'), ('face', 'NN'), ('region', 'NN'), ('video', 'NN'), ('frame', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('tracking', 'VBG'), ('second', 'JJ'), ('free', 'JJ'), ('form', 'NN'), ('shape', 'NN'), ('face', 'NN'), ('region', 'NN'), ('comprises', 'VBZ'), ('determining', 'VBG'), ('location', 'NN'), ('second', 'JJ'), ('valid', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('second', 'JJ'), ('video', 'NN'), ('frame', 'NN'), ('based', 'VBN'), ('displacement', 'JJ'), ('offset', 'NN'), ('respect', 'NN'), ('first', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('determining', 'VBG'), ('displacement', 'NN'), ('offset', 'NN'), ('based', 'VBN'), ('offset', 'VBN'), ('centroid', 'JJ'), ('bounding', 'VBG'), ('box', 'NN'), ('around', 'IN'), ('skin', 'NN'), ('enhanced', 'VBN'), ('region', 'NN'), ('corresponding', 'VBG'), ('first', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('second', 'JJ'), ('centroid', 'JJ'), ('second', 'JJ'), ('bounding', 'NN'), ('box', 'NN'), ('around', 'IN'), ('second', 'JJ'), ('skin', 'NN'), ('enhanced', 'VBD'), ('region', 'NN'), ('second', 'JJ'), ('video', 'NN'), ('frame', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('encoding', 'VBG'), ('video', 'NN'), ('frame', 'NN'), ('based', 'VBN'), ('least', 'JJS'), ('part', 'NN'), ('first', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('valid', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('comprises', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('reducing', 'VBG'), ('quantization', 'NN'), ('parameter', 'NN'), ('corresponding', 'VBG'), ('first', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('adjusting', 'VBG'), ('lambda', 'NN'), ('value', 'NN'), ('first', 'RB'), ('candidate', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('disabling', 'VBG'), ('skip', 'NN'), ('coding', 'VBG'), ('first', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('bitstream', 'NN'), ('comprises', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('hadvanced', 'VBD'), ('video', 'NN'), ('coding', 'VBG'), ('avc', 'JJ'), ('compliant', 'JJ'), ('bitstream', 'NN'), ('hhigh', 'NN'), ('efficiency', 'NN'), ('video', 'NN'), ('coding', 'VBG'), ('hevc', 'NN'), ('compliant', 'JJ'), ('bitstream', 'NN'), ('vp', 'NN'), ('compliant', 'JJ'), ('bitstream', 'NN'), ('vp', 'NN'), ('compliant', 'JJ'), ('bitstream', 'NN'), ('alliance', 'NN'), ('open', 'JJ'), ('media', 'NNS'), ('aom', 'VBP'), ('av', 'JJ'), ('compliant', 'NN'), ('bitstream', 'NN'), ('computer', 'NN'), ('implemented', 'VBD'), ('method', 'NN'), ('performing', 'VBG'), ('face', 'NN'), ('detection', 'NN'), ('comprising', 'VBG'), ('receiving', 'VBG'), ('video', 'NN'), ('frame', 'NN'), ('sequence', 'NN'), ('video', 'NN'), ('frames', 'NNS'), ('performing', 'VBG'), ('multi-stage', 'JJ'), ('facial', 'JJ'), ('search', 'NN'), ('video', 'NN'), ('frame', 'NN'), ('based', 'VBN'), ('predetermined', 'JJ'), ('feature', 'NN'), ('templates', 'NNS'), ('predetermined', 'VBD'), ('number', 'NN'), ('stages', 'NNS'), ('determine', 'VBP'), ('first', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('second', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('video', 'NN'), ('frame', 'NN'), ('testing', 'VBG'), ('first', 'JJ'), ('second', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('regions', 'NNS'), ('based', 'VBN'), ('skin', 'JJ'), ('tone', 'NN'), ('information', 'NN'), ('determine', 'NN'), ('first', 'RB'), ('candidate', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('valid', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('second', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('invalid', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('rejecting', 'VBG'), ('second', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('outputting', 'VBG'), ('first', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('valid', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('processing', 'VBG'), ('providing', 'VBG'), ('index', 'NN'), ('indicative', 'JJ'), ('person', 'NN'), ('present', 'JJ'), ('video', 'NN'), ('frame', 'NN'), ('based', 'VBN'), ('valid', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('sequence', 'NN'), ('video', 'NN'), ('frames', 'VBZ'), ('comprises', 'NNS'), ('sequence', 'NN'), ('surveillance', 'NN'), ('video', 'NN'), ('frames', 'NNS'), ('method', 'VBP'), ('comprising', 'VBG'), ('performing', 'VBG'), ('face', 'NN'), ('recognition', 'NN'), ('surveillance', 'NN'), ('video', 'NN'), ('frames', 'NNS'), ('based', 'VBN'), ('valid', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('sequence', 'NN'), ('video', 'NN'), ('frames', 'VBZ'), ('comprises', 'NNS'), ('sequence', 'NN'), ('decoded', 'VBD'), ('video', 'NN'), ('frames', 'NNS'), ('method', 'VBP'), ('comprising', 'VBG'), ('adding', 'VBG'), ('marker', 'NN'), ('corresponding', 'VBG'), ('received', 'VBD'), ('video', 'JJ'), ('frame', 'NN'), ('perform', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('received', 'VBD'), ('video', 'NN'), ('frame', 'NN'), ('based', 'VBN'), ('valid', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('sequence', 'NN'), ('video', 'NN'), ('frames', 'NNS'), ('received', 'VBD'), ('device', 'NN'), ('login', 'NN'), ('attempt', 'NN'), ('method', 'NN'), ('comprising', 'VBG'), ('performing', 'VBG'), ('face', 'NN'), ('recognition', 'NN'), ('based', 'VBN'), ('valid', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('allowing', 'VBG'), ('access', 'NN'), ('device', 'NN'), ('secured', 'VBD'), ('face', 'NN'), ('recognized', 'VBN'), ('method', 'JJ'), ('claim', 'NN'), ('wherein', 'NN'), ('sequence', 'NN'), ('video', 'NN'), ('frames', 'VBZ'), ('comprises', 'NNS'), ('sequence', 'NN'), ('videoconferencing', 'VBG'), ('frames', 'NNS'), ('method', 'RB'), ('comprising', 'VBG'), ('encoding', 'VBG'), ('video', 'NN'), ('frame', 'NN'), ('based', 'VBN'), ('least', 'JJS'), ('part', 'NN'), ('valid', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('generate', 'NN'), ('coded', 'VBD'), ('bitstream', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('encoding', 'VBG'), ('video', 'NN'), ('frame', 'NN'), ('comprises', 'VBZ'), ('encoding', 'VBG'), ('background', 'RP'), ('region', 'NN'), ('video', 'NN'), ('frame', 'NN'), ('bitstream', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('encoding', 'VBG'), ('video', 'NN'), ('frame', 'NN'), ('based', 'VBN'), ('least', 'JJS'), ('part', 'NN'), ('valid', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('generate', 'NN'), ('coded', 'VBD'), ('bitstream', 'NN'), ('wherein', 'NN'), ('encoding', 'VBG'), ('video', 'NN'), ('frame', 'NN'), ('comprises', 'VBZ'), ('including', 'VBG'), ('metadata', 'NNS'), ('corresponding', 'VBG'), ('valid', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('bitstream', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('decoding', 'VBG'), ('coded', 'VBN'), ('bitstream', 'NN'), ('generate', 'NN'), ('decoded', 'VBD'), ('video', 'NN'), ('frame', 'NN'), ('determine', 'NN'), ('metadata', 'NN'), ('corresponding', 'VBG'), ('valid', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('bitstream', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('replacing', 'VBG'), ('valid', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('based', 'VBN'), ('decoded', 'VBN'), ('metadata', 'NNS'), ('cropping', 'VBG'), ('displaying', 'VBG'), ('image', 'NN'), ('data', 'NNS'), ('corresponding', 'VBG'), ('valid', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('based', 'VBN'), ('decoded', 'VBN'), ('metadata', 'NNS'), ('indexing', 'VBG'), ('decoded', 'VBD'), ('video', 'NN'), ('frame', 'NN'), ('based', 'VBN'), ('decoded', 'VBN'), ('metadata', 'NN'), ('system', 'NN'), ('performing', 'VBG'), ('video', 'NN'), ('coding', 'VBG'), ('based', 'VBN'), ('face', 'NN'), ('detection', 'NN'), ('comprising', 'VBG'), ('memory', 'NN'), ('configured', 'VBD'), ('store', 'NN'), ('video', 'NN'), ('frame', 'NN'), ('comprising', 'VBG'), ('one', 'CD'), ('plurality', 'NN'), ('video', 'NN'), ('frames', 'NNS'), ('video', 'VBP'), ('sequence', 'NN'), ('processor', 'NN'), ('coupled', 'VBD'), ('memory', 'NN'), ('processor', 'NN'), ('receive', 'VBP'), ('video', 'NN'), ('frame', 'NN'), ('determine', 'JJ'), ('video', 'NN'), ('frame', 'NN'), ('key', 'JJ'), ('frame', 'NN'), ('video', 'NN'), ('sequence', 'NN'), ('perform', 'NN'), ('response', 'NN'), ('video', 'NN'), ('frame', 'NN'), ('key', 'JJ'), ('frame', 'NN'), ('video', 'JJ'), ('sequence', 'NN'), ('multi-stage', 'NN'), ('facial', 'JJ'), ('search', 'NN'), ('video', 'NN'), ('frame', 'NN'), ('based', 'VBN'), ('predetermined', 'JJ'), ('feature', 'NN'), ('templates', 'NNS'), ('predetermined', 'VBD'), ('number', 'NN'), ('stages', 'NNS'), ('determine', 'VBP'), ('first', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('second', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('video', 'NN'), ('frame', 'NN'), ('test', 'NN'), ('first', 'RB'), ('second', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('regions', 'NNS'), ('based', 'VBN'), ('skin', 'JJ'), ('tone', 'NN'), ('information', 'NN'), ('determine', 'NN'), ('first', 'RB'), ('candidate', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('valid', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('second', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('invalid', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('reject', 'JJ'), ('second', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('outputting', 'VBG'), ('first', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('encode', 'FW'), ('video', 'NN'), ('frame', 'NN'), ('based', 'VBN'), ('least', 'JJS'), ('part', 'NN'), ('first', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('valid', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('generate', 'NN'), ('coded', 'VBD'), ('bitstream', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('skin', 'VBD'), ('tone', 'NN'), ('information', 'NN'), ('comprises', 'VBZ'), ('skin', 'JJ'), ('probability', 'NN'), ('map', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('first', 'RB'), ('candidate', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('comprises', 'VBZ'), ('rectangular', 'JJ'), ('region', 'NN'), ('processor', 'NN'), ('determine', 'VBP'), ('free', 'JJ'), ('form', 'NN'), ('shape', 'NN'), ('face', 'NN'), ('region', 'NN'), ('corresponding', 'VBG'), ('first', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('wherein', 'VBD'), ('free', 'JJ'), ('form', 'NN'), ('shape', 'NN'), ('face', 'NN'), ('region', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('pixel', 'NN'), ('accuracy', 'NN'), ('small', 'JJ'), ('block', 'NN'), ('pixels', 'NNS'), ('accuracy', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('processor', 'NN'), ('determine', 'VBP'), ('free', 'JJ'), ('form', 'NN'), ('shape', 'NN'), ('face', 'NN'), ('region', 'NN'), ('comprises', 'VBZ'), ('processor', 'NN'), ('generate', 'NN'), ('enhanced', 'VBD'), ('skip', 'JJ'), ('probability', 'NN'), ('map', 'NN'), ('corresponding', 'VBG'), ('first', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('binarize', 'NN'), ('enhanced', 'VBD'), ('skip', 'JJ'), ('probability', 'NN'), ('map', 'NN'), ('overlay', 'NN'), ('binarized', 'VBD'), ('enhanced', 'JJ'), ('skip', 'JJ'), ('probability', 'NN'), ('map', 'NN'), ('least', 'JJS'), ('portion', 'NN'), ('video', 'NN'), ('frame', 'NN'), ('provide', 'VBP'), ('free', 'JJ'), ('form', 'NN'), ('shape', 'NN'), ('face', 'NN'), ('region', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('second', 'JJ'), ('video', 'NN'), ('frame', 'NN'), ('comprises', 'VBZ'), ('non-key', 'JJ'), ('frame', 'NN'), ('video', 'NN'), ('sequence', 'NN'), ('processor', 'NN'), ('perform', 'NN'), ('face', 'NN'), ('detection', 'NN'), ('second', 'JJ'), ('video', 'NN'), ('frame', 'NN'), ('video', 'NN'), ('sequence', 'NN'), ('based', 'VBN'), ('free', 'JJ'), ('form', 'NN'), ('shape', 'NN'), ('face', 'NN'), ('region', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('processor', 'NN'), ('track', 'NN'), ('second', 'JJ'), ('free', 'JJ'), ('form', 'NN'), ('shape', 'NN'), ('face', 'NN'), ('region', 'NN'), ('second', 'JJ'), ('video', 'NN'), ('frame', 'NN'), ('based', 'VBN'), ('free', 'JJ'), ('form', 'NN'), ('shape', 'NN'), ('face', 'NN'), ('region', 'NN'), ('video', 'NN'), ('frame', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('encode', 'VBD'), ('video', 'NN'), ('frame', 'NN'), ('based', 'VBN'), ('least', 'JJS'), ('part', 'NN'), ('first', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('valid', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('comprises', 'VBZ'), ('processor', 'NN'), ('reduce', 'VB'), ('quantization', 'NN'), ('parameter', 'NN'), ('corresponding', 'VBG'), ('first', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('adjust', 'VBP'), ('lambda', 'NN'), ('value', 'NN'), ('first', 'RB'), ('candidate', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('disable', 'JJ'), ('skip', 'NN'), ('coding', 'VBG'), ('first', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('non-transitory', 'JJ'), ('machine', 'NN'), ('readable', 'JJ'), ('medium', 'NN'), ('comprising', 'VBG'), ('plurality', 'NN'), ('instructions', 'NNS'), ('response', 'NN'), ('executed', 'VBD'), ('device', 'NN'), ('cause', 'NN'), ('device', 'NN'), ('perform', 'NN'), ('video', 'NN'), ('coding', 'VBG'), ('based', 'VBN'), ('face', 'NN'), ('detection', 'NN'), ('receiving', 'VBG'), ('video', 'NN'), ('frame', 'NN'), ('comprising', 'VBG'), ('one', 'CD'), ('plurality', 'NN'), ('video', 'NN'), ('frames', 'NNS'), ('video', 'VBP'), ('sequence', 'NN'), ('determining', 'VBG'), ('video', 'NN'), ('frame', 'NN'), ('key', 'JJ'), ('frame', 'NN'), ('video', 'NN'), ('sequence', 'NN'), ('performing', 'VBG'), ('response', 'NN'), ('video', 'NN'), ('frame', 'NN'), ('key', 'JJ'), ('frame', 'NN'), ('video', 'JJ'), ('sequence', 'NN'), ('multi-stage', 'NN'), ('facial', 'JJ'), ('search', 'NN'), ('video', 'NN'), ('frame', 'NN'), ('based', 'VBN'), ('predetermined', 'JJ'), ('feature', 'NN'), ('templates', 'NNS'), ('predetermined', 'VBD'), ('number', 'NN'), ('stages', 'NNS'), ('determine', 'VBP'), ('first', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('second', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('video', 'NN'), ('frame', 'NN'), ('testing', 'VBG'), ('first', 'JJ'), ('second', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('regions', 'NNS'), ('based', 'VBN'), ('skin', 'JJ'), ('tone', 'NN'), ('information', 'NN'), ('determine', 'NN'), ('first', 'RB'), ('candidate', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('valid', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('second', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('invalid', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('rejecting', 'VBG'), ('second', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('outputting', 'VBG'), ('first', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('encoding', 'VBG'), ('video', 'NN'), ('frame', 'NN'), ('based', 'VBN'), ('least', 'JJS'), ('part', 'NN'), ('first', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('valid', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('generate', 'NN'), ('coded', 'VBD'), ('bitstream', 'JJ'), ('non-transitory', 'JJ'), ('machine', 'NN'), ('readable', 'JJ'), ('medium', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('skin', 'VBD'), ('tone', 'NN'), ('information', 'NN'), ('comprises', 'VBZ'), ('skin', 'JJ'), ('probability', 'NN'), ('map', 'VBP'), ('non-transitory', 'JJ'), ('machine', 'NN'), ('readable', 'JJ'), ('medium', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('first', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('comprises', 'VBZ'), ('rectangular', 'JJ'), ('region', 'NN'), ('machine', 'NN'), ('readable', 'JJ'), ('medium', 'NN'), ('comprising', 'VBG'), ('instructions', 'NNS'), ('response', 'NN'), ('executed', 'VBD'), ('device', 'NN'), ('cause', 'NN'), ('device', 'NN'), ('perform', 'NN'), ('video', 'NN'), ('coding', 'VBG'), ('based', 'VBN'), ('face', 'NN'), ('detection', 'NN'), ('determining', 'VBG'), ('free', 'JJ'), ('form', 'NN'), ('shape', 'NN'), ('face', 'NN'), ('region', 'NN'), ('corresponding', 'VBG'), ('first', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('wherein', 'VBD'), ('free', 'JJ'), ('form', 'NN'), ('shape', 'NN'), ('face', 'NN'), ('region', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('pixel', 'NN'), ('accuracy', 'NN'), ('small', 'JJ'), ('block', 'NN'), ('pixels', 'NNS'), ('accuracy', 'IN'), ('non-transitory', 'JJ'), ('machine', 'NN'), ('readable', 'JJ'), ('medium', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('determining', 'VBG'), ('free', 'JJ'), ('form', 'NN'), ('shape', 'NN'), ('face', 'NN'), ('region', 'NN'), ('comprises', 'VBZ'), ('generating', 'VBG'), ('enhanced', 'VBN'), ('skip', 'JJ'), ('probability', 'NN'), ('map', 'NN'), ('corresponding', 'VBG'), ('first', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('binarizing', 'VBG'), ('enhanced', 'VBD'), ('skip', 'JJ'), ('probability', 'NN'), ('map', 'NN'), ('overlaying', 'VBG'), ('binarized', 'VBN'), ('enhanced', 'JJ'), ('skip', 'NN'), ('probability', 'NN'), ('map', 'NN'), ('least', 'JJS'), ('portion', 'NN'), ('video', 'NN'), ('frame', 'NN'), ('provide', 'VBP'), ('free', 'JJ'), ('form', 'NN'), ('shape', 'NN'), ('face', 'NN'), ('region', 'NN'), ('non-transitory', 'JJ'), ('machine', 'NN'), ('readable', 'JJ'), ('medium', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('second', 'JJ'), ('video', 'NN'), ('frame', 'NN'), ('comprises', 'VBZ'), ('non-key', 'JJ'), ('frame', 'NN'), ('video', 'NN'), ('sequence', 'NN'), ('machine', 'NN'), ('readable', 'JJ'), ('medium', 'NN'), ('comprising', 'VBG'), ('instructions', 'NNS'), ('response', 'NN'), ('executed', 'VBD'), ('device', 'NN'), ('cause', 'NN'), ('device', 'NN'), ('perform', 'NN'), ('video', 'NN'), ('coding', 'VBG'), ('based', 'VBN'), ('face', 'NN'), ('detection', 'NN'), ('performing', 'VBG'), ('face', 'NN'), ('detection', 'NN'), ('second', 'JJ'), ('video', 'NN'), ('frame', 'NN'), ('video', 'NN'), ('sequence', 'NN'), ('based', 'VBN'), ('free', 'JJ'), ('form', 'NN'), ('shape', 'NN'), ('face', 'NN'), ('region', 'NN'), ('non-transitory', 'JJ'), ('machine', 'NN'), ('readable', 'JJ'), ('medium', 'NN'), ('claim', 'NN'), ('machine', 'NN'), ('readable', 'JJ'), ('medium', 'NN'), ('comprising', 'VBG'), ('instructions', 'NNS'), ('response', 'NN'), ('executed', 'VBD'), ('device', 'NN'), ('cause', 'NN'), ('device', 'NN'), ('perform', 'NN'), ('video', 'NN'), ('coding', 'VBG'), ('based', 'VBN'), ('face', 'NN'), ('detection', 'NN'), ('tracking', 'VBG'), ('second', 'JJ'), ('free', 'JJ'), ('form', 'NN'), ('shape', 'NN'), ('face', 'NN'), ('region', 'NN'), ('second', 'JJ'), ('video', 'NN'), ('frame', 'NN'), ('based', 'VBN'), ('free', 'JJ'), ('form', 'NN'), ('shape', 'NN'), ('face', 'NN'), ('region', 'NN'), ('video', 'NN'), ('frame', 'NN'), ('non-transitory', 'JJ'), ('machine', 'NN'), ('readable', 'JJ'), ('medium', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('encoding', 'VBG'), ('video', 'NN'), ('frame', 'NN'), ('based', 'VBN'), ('least', 'JJS'), ('part', 'NN'), ('first', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('valid', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('comprises', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('reducing', 'VBG'), ('quantization', 'NN'), ('parameter', 'NN'), ('corresponding', 'VBG'), ('first', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('adjusting', 'VBG'), ('lambda', 'NN'), ('value', 'NN'), ('first', 'RB'), ('candidate', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('disabling', 'VBG'), ('skip', 'NN'), ('coding', 'VBG'), ('first', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('method', 'NN'), ('managing', 'VBG'), ('smart', 'JJ'), ('database', 'NN'), ('stores', 'NNS'), ('facial', 'JJ'), ('images', 'NNS'), ('face', 'VBP'), ('recognition', 'NN'), ('comprising', 'VBG'), ('steps', 'NNS'), ('managing', 'VBG'), ('device', 'NN'), ('performing', 'VBG'), ('process', 'NN'), ('counting', 'VBG'), ('one', 'CD'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('corresponding', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('specific', 'JJ'), ('person', 'NN'), ('stored', 'VBD'), ('smart', 'JJ'), ('database', 'NN'), ('new', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('face', 'VBP'), ('recognition', 'NN'), ('continuously', 'RB'), ('stored', 'VBD'), ('process', 'NN'), ('determining', 'VBG'), ('whether', 'IN'), ('first', 'JJ'), ('counted', 'VBN'), ('value', 'NN'), ('representing', 'VBG'), ('count', 'NN'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('satisfies', 'NNS'), ('preset', 'VBP'), ('first', 'RB'), ('set', 'VBN'), ('value', 'NN'), ('b', 'NN'), ('first', 'RB'), ('counted', 'VBD'), ('value', 'NN'), ('determined', 'VBD'), ('satisfying', 'VBG'), ('first', 'RB'), ('set', 'VBN'), ('value', 'NN'), ('managing', 'VBG'), ('device', 'NN'), ('performing', 'VBG'), ('process', 'NN'), ('inputting', 'VBG'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('neural', 'JJ'), ('aggregation', 'NN'), ('network', 'NN'), ('thereby', 'RB'), ('allow', 'VB'), ('neural', 'JJ'), ('aggregation', 'NN'), ('network', 'NN'), ('generate', 'VBP'), ('quality', 'NN'), ('scores', 'NNS'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('aggregation', 'VBP'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('process', 'NN'), ('sorting', 'VBG'), ('quality', 'NN'), ('scores', 'NNS'), ('corresponding', 'VBG'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('descending', 'VBG'), ('order', 'NN'), ('quality', 'NN'), ('scores', 'VBZ'), ('process', 'NN'), ('counting', 'NN'), ('sorted', 'VBN'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('descending', 'VBG'), ('order', 'NN'), ('second', 'JJ'), ('counted', 'VBN'), ('value', 'NN'), ('represents', 'VBZ'), ('number', 'NN'), ('counted', 'VBN'), ('part', 'NN'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('becomes', 'VBZ'), ('equal', 'JJ'), ('preset', 'JJ'), ('second', 'NN'), ('set', 'VBN'), ('value', 'NN'), ('process', 'NN'), ('deleting', 'VBG'), ('uncounted', 'JJ'), ('part', 'NN'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('smart', 'JJ'), ('database', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('step', 'NN'), ('c', 'RB'), ('managing', 'VBG'), ('device', 'NN'), ('performing', 'VBG'), ('process', 'NN'), ('generating', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('optimal', 'JJ'), ('feature', 'NN'), ('weighted', 'VBD'), ('summation', 'NN'), ('one', 'CD'), ('features', 'VBZ'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('using', 'VBG'), ('counted', 'JJ'), ('part', 'NN'), ('quality', 'NN'), ('scores', 'VBZ'), ('process', 'JJ'), ('setting', 'VBG'), ('optimal', 'JJ'), ('feature', 'NN'), ('representative', 'JJ'), ('face', 'NN'), ('corresponding', 'VBG'), ('specific', 'JJ'), ('person', 'NN'), ('method', 'JJ'), ('claim', 'NN'), ('wherein', 'JJ'), ('step', 'NN'), ('b', 'NN'), ('managing', 'VBG'), ('device', 'NN'), ('performs', 'NNS'), ('process', 'NN'), ('inputting', 'VBG'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('cnn', 'VBP'), ('neural', 'JJ'), ('aggregation', 'NN'), ('network', 'NN'), ('thereby', 'RB'), ('allow', 'VB'), ('cnn', 'NN'), ('generate', 'NN'), ('one', 'CD'), ('features', 'VBZ'), ('corresponding', 'VBG'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('process', 'NN'), ('inputting', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('feature', 'NN'), ('vector', 'NN'), ('features', 'NNS'), ('embedded', 'VBD'), ('aggregation', 'NN'), ('module', 'NN'), ('including', 'VBG'), ('least', 'JJS'), ('two', 'CD'), ('attention', 'NN'), ('blocks', 'NNS'), ('thereby', 'RB'), ('allow', 'VB'), ('aggregation', 'NN'), ('module', 'NN'), ('generate', 'VBP'), ('quality', 'NN'), ('scores', 'NNS'), ('features', 'VBZ'), ('method', 'JJ'), ('claim', 'NN'), ('wherein', 'JJ'), ('step', 'NN'), ('b', 'NN'), ('managing', 'VBG'), ('device', 'NN'), ('performs', 'NNS'), ('process', 'NN'), ('matching', 'VBG'), ('i-', 'JJ'), ('one', 'CD'), ('features', 'VBZ'), ('corresponding', 'VBG'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('stored', 'VBN'), ('smart', 'JJ'), ('database', 'NN'), ('i-', 'JJ'), ('quality', 'NN'), ('scores', 'NNS'), ('ii', 'VBP'), ('specific', 'JJ'), ('person', 'NN'), ('process', 'NN'), ('storing', 'VBG'), ('matched', 'VBN'), ('features', 'NNS'), ('matched', 'VBN'), ('quality', 'NN'), ('scores', 'NNS'), ('smart', 'VBP'), ('database', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('step', 'NN'), ('managing', 'VBG'), ('device', 'NN'), ('performing', 'VBG'), ('one', 'CD'), ('process', 'NN'), ('learning', 'VBG'), ('face', 'NN'), ('recognition', 'NN'), ('system', 'NN'), ('using', 'VBG'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('corresponding', 'VBG'), ('specific', 'JJ'), ('person', 'NN'), ('stored', 'VBD'), ('smart', 'JJ'), ('database', 'NN'), ('ii', 'NN'), ('process', 'NN'), ('transmitting', 'VBG'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('corresponding', 'VBG'), ('specific', 'JJ'), ('person', 'NN'), ('learning', 'JJ'), ('device', 'NN'), ('corresponding', 'VBG'), ('face', 'NN'), ('recognition', 'NN'), ('system', 'NN'), ('thereby', 'RB'), ('allow', 'VB'), ('learning', 'VBG'), ('device', 'NN'), ('learn', 'FW'), ('face', 'NN'), ('recognition', 'NN'), ('system', 'NN'), ('using', 'VBG'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('method', 'VBP'), ('claim', 'NN'), ('wherein', 'JJ'), ('neural', 'JJ'), ('aggregation', 'NN'), ('network', 'NN'), ('learned', 'VBD'), ('learning', 'JJ'), ('device', 'NN'), ('repeating', 'VBG'), ('process', 'NN'), ('inputting', 'VBG'), ('multiple', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('training', 'VBG'), ('corresponding', 'JJ'), ('image', 'NN'), ('set', 'VBN'), ('single', 'JJ'), ('face', 'NN'), ('video', 'NN'), ('single', 'JJ'), ('face', 'NN'), ('cnn', 'JJ'), ('neural', 'JJ'), ('aggregation', 'NN'), ('network', 'NN'), ('thereby', 'RB'), ('allow', 'VB'), ('cnn', 'NN'), ('generate', 'NN'), ('one', 'CD'), ('features', 'VBZ'), ('training', 'VBG'), ('applying', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('convolution', 'NN'), ('operation', 'NN'), ('facial', 'JJ'), ('images', 'NNS'), ('training', 'VBG'), ('ii', 'JJ'), ('process', 'NN'), ('inputting', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('feature', 'NN'), ('vector', 'NN'), ('training', 'NN'), ('features', 'NNS'), ('training', 'VBG'), ('embedded', 'JJ'), ('aggregation', 'NN'), ('module', 'NN'), ('including', 'VBG'), ('least', 'JJS'), ('two', 'CD'), ('attention', 'NN'), ('blocks', 'NNS'), ('neural', 'JJ'), ('aggregation', 'NN'), ('network', 'NN'), ('thereby', 'RB'), ('allow', 'JJ'), ('aggregation', 'NN'), ('module', 'NN'), ('generate', 'VBP'), ('quality', 'NN'), ('scores', 'NNS'), ('training', 'VBG'), ('features', 'NNS'), ('training', 'VBG'), ('aggregation', 'NN'), ('features', 'NNS'), ('training', 'VBG'), ('using', 'VBG'), ('one', 'CD'), ('attention', 'NN'), ('parameters', 'NNS'), ('learned', 'VBD'), ('previous', 'JJ'), ('iteration', 'NN'), ('iii', 'NN'), ('process', 'NN'), ('outputting', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('optimal', 'JJ'), ('feature', 'NN'), ('training', 'NN'), ('weighted', 'JJ'), ('summation', 'NN'), ('features', 'NNS'), ('training', 'VBG'), ('using', 'VBG'), ('quality', 'NN'), ('scores', 'NNS'), ('training', 'VBG'), ('iv', 'JJ'), ('process', 'NN'), ('updating', 'VBG'), ('attention', 'NN'), ('parameters', 'NNS'), ('learned', 'VBD'), ('previous', 'JJ'), ('iteration', 'NN'), ('least', 'JJS'), ('two', 'CD'), ('attention', 'NN'), ('blocks', 'NNS'), ('one', 'CD'), ('losses', 'NNS'), ('minimized', 'VBN'), ('outputted', 'JJ'), ('loss', 'NN'), ('layer', 'NN'), ('referring', 'VBG'), ('optimal', 'JJ'), ('feature', 'NN'), ('training', 'VBG'), ('corresponding', 'VBG'), ('ground', 'NN'), ('truth', 'NN'), ('managing', 'VBG'), ('device', 'NN'), ('managing', 'VBG'), ('smart', 'JJ'), ('database', 'NN'), ('stores', 'NNS'), ('facial', 'JJ'), ('images', 'NNS'), ('face', 'VBP'), ('recognition', 'NN'), ('comprising', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('memory', 'NN'), ('stores', 'NNS'), ('instructions', 'NNS'), ('least', 'VBP'), ('one', 'CD'), ('processor', 'NN'), ('configured', 'VBD'), ('execute', 'JJ'), ('instructions', 'NNS'), ('perform', 'VB'), ('support', 'NN'), ('another', 'DT'), ('device', 'NN'), ('perform', 'NN'), ('process', 'NN'), ('counting', 'VBG'), ('one', 'CD'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('corresponding', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('specific', 'JJ'), ('person', 'NN'), ('stored', 'VBD'), ('smart', 'JJ'), ('database', 'NN'), ('new', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('face', 'VBP'), ('recognition', 'NN'), ('continuously', 'RB'), ('stored', 'VBD'), ('process', 'NN'), ('determining', 'VBG'), ('whether', 'IN'), ('first', 'JJ'), ('counted', 'VBN'), ('value', 'NN'), ('representing', 'VBG'), ('count', 'NN'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('satisfies', 'NNS'), ('preset', 'VBP'), ('first', 'RB'), ('set', 'VBN'), ('value', 'NN'), ('ii', 'NN'), ('first', 'RB'), ('counted', 'VBD'), ('value', 'NN'), ('determined', 'VBD'), ('satisfying', 'VBG'), ('first', 'RB'), ('set', 'VBN'), ('value', 'NN'), ('process', 'NN'), ('inputting', 'VBG'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('neural', 'JJ'), ('aggregation', 'NN'), ('network', 'NN'), ('thereby', 'RB'), ('allow', 'VB'), ('neural', 'JJ'), ('aggregation', 'NN'), ('network', 'NN'), ('generate', 'VBP'), ('quality', 'NN'), ('scores', 'NNS'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('aggregation', 'VBP'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('process', 'NN'), ('sorting', 'VBG'), ('quality', 'NN'), ('scores', 'NNS'), ('corresponding', 'VBG'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('descending', 'VBG'), ('order', 'NN'), ('quality', 'NN'), ('scores', 'VBZ'), ('process', 'NN'), ('counting', 'NN'), ('sorted', 'VBN'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('descending', 'VBG'), ('order', 'NN'), ('second', 'JJ'), ('counted', 'VBN'), ('value', 'NN'), ('represents', 'VBZ'), ('number', 'NN'), ('counted', 'VBN'), ('part', 'NN'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('becomes', 'VBZ'), ('equal', 'JJ'), ('preset', 'JJ'), ('second', 'NN'), ('set', 'VBN'), ('value', 'NN'), ('process', 'NN'), ('deleting', 'VBG'), ('uncounted', 'JJ'), ('part', 'NN'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('smart', 'VBP'), ('database', 'NN'), ('managing', 'VBG'), ('device', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('processor', 'NN'), ('performs', 'NNS'), ('iii', 'VBP'), ('process', 'NN'), ('generating', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('optimal', 'JJ'), ('feature', 'NN'), ('weighted', 'VBD'), ('summation', 'NN'), ('one', 'CD'), ('features', 'VBZ'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('using', 'VBG'), ('counted', 'JJ'), ('part', 'NN'), ('quality', 'NN'), ('scores', 'VBZ'), ('process', 'JJ'), ('setting', 'VBG'), ('optimal', 'JJ'), ('feature', 'NN'), ('representative', 'JJ'), ('face', 'NN'), ('corresponding', 'VBG'), ('specific', 'JJ'), ('person', 'NN'), ('managing', 'VBG'), ('device', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('process', 'NN'), ('ii', 'NN'), ('processor', 'NN'), ('performs', 'NNS'), ('process', 'NN'), ('inputting', 'VBG'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('cnn', 'VBP'), ('neural', 'JJ'), ('aggregation', 'NN'), ('network', 'NN'), ('thereby', 'RB'), ('allow', 'VB'), ('cnn', 'NN'), ('generate', 'NN'), ('one', 'CD'), ('features', 'VBZ'), ('corresponding', 'VBG'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('process', 'NN'), ('inputting', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('feature', 'NN'), ('vector', 'NN'), ('features', 'NNS'), ('embedded', 'VBD'), ('aggregation', 'NN'), ('module', 'NN'), ('including', 'VBG'), ('least', 'JJS'), ('two', 'CD'), ('attention', 'NN'), ('blocks', 'NNS'), ('thereby', 'RB'), ('allow', 'VB'), ('aggregation', 'NN'), ('module', 'NN'), ('generate', 'VBP'), ('quality', 'NN'), ('scores', 'NNS'), ('features', 'VBZ'), ('managing', 'VBG'), ('device', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('process', 'NN'), ('ii', 'NN'), ('processor', 'NN'), ('performs', 'NNS'), ('process', 'NN'), ('matching', 'VBG'), ('i-', 'JJ'), ('one', 'CD'), ('features', 'VBZ'), ('corresponding', 'VBG'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('stored', 'VBN'), ('smart', 'JJ'), ('database', 'NN'), ('i-', 'JJ'), ('quality', 'NN'), ('scores', 'NNS'), ('ii', 'VBP'), ('specific', 'JJ'), ('person', 'NN'), ('process', 'NN'), ('storing', 'VBG'), ('matched', 'VBN'), ('features', 'NNS'), ('matched', 'VBN'), ('quality', 'NN'), ('scores', 'NNS'), ('smart', 'VBP'), ('database', 'NN'), ('managing', 'VBG'), ('device', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('processor', 'NN'), ('performs', 'NNS'), ('iv', 'VBP'), ('one', 'CD'), ('process', 'NN'), ('learning', 'VBG'), ('face', 'NN'), ('recognition', 'NN'), ('system', 'NN'), ('using', 'VBG'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('corresponding', 'VBG'), ('specific', 'JJ'), ('person', 'NN'), ('stored', 'VBD'), ('smart', 'JJ'), ('database', 'NN'), ('ii', 'NN'), ('process', 'NN'), ('transmitting', 'VBG'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('corresponding', 'VBG'), ('specific', 'JJ'), ('person', 'NN'), ('learning', 'JJ'), ('device', 'NN'), ('corresponding', 'VBG'), ('face', 'NN'), ('recognition', 'NN'), ('system', 'NN'), ('thereby', 'RB'), ('allow', 'VB'), ('learning', 'VBG'), ('device', 'NN'), ('learn', 'FW'), ('face', 'NN'), ('recognition', 'NN'), ('system', 'NN'), ('using', 'VBG'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('managing', 'VBG'), ('device', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('neural', 'JJ'), ('aggregation', 'NN'), ('network', 'NN'), ('learned', 'VBD'), ('learning', 'JJ'), ('device', 'NN'), ('repeating', 'VBG'), ('process', 'NN'), ('inputting', 'VBG'), ('multiple', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('training', 'VBG'), ('corresponding', 'JJ'), ('image', 'NN'), ('set', 'VBN'), ('single', 'JJ'), ('face', 'NN'), ('video', 'NN'), ('single', 'JJ'), ('face', 'NN'), ('cnn', 'JJ'), ('neural', 'JJ'), ('aggregation', 'NN'), ('network', 'NN'), ('thereby', 'RB'), ('allow', 'VB'), ('cnn', 'NN'), ('generate', 'NN'), ('one', 'CD'), ('features', 'VBZ'), ('training', 'VBG'), ('applying', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('convolution', 'NN'), ('operation', 'NN'), ('facial', 'JJ'), ('images', 'NNS'), ('training', 'VBG'), ('ii', 'JJ'), ('process', 'NN'), ('inputting', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('feature', 'NN'), ('vector', 'NN'), ('training', 'NN'), ('features', 'NNS'), ('training', 'VBG'), ('embedded', 'JJ'), ('aggregation', 'NN'), ('module', 'NN'), ('including', 'VBG'), ('least', 'JJS'), ('two', 'CD'), ('attention', 'NN'), ('blocks', 'NNS'), ('neural', 'JJ'), ('aggregation', 'NN'), ('network', 'NN'), ('thereby', 'RB'), ('allow', 'JJ'), ('aggregation', 'NN'), ('module', 'NN'), ('generate', 'VBP'), ('quality', 'NN'), ('scores', 'NNS'), ('training', 'VBG'), ('features', 'NNS'), ('training', 'VBG'), ('aggregation', 'NN'), ('features', 'NNS'), ('training', 'VBG'), ('using', 'VBG'), ('one', 'CD'), ('attention', 'NN'), ('parameters', 'NNS'), ('learned', 'VBD'), ('previous', 'JJ'), ('iteration', 'NN'), ('iii', 'NN'), ('process', 'NN'), ('outputting', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('optimal', 'JJ'), ('feature', 'NN'), ('training', 'NN'), ('weighted', 'JJ'), ('summation', 'NN'), ('features', 'NNS'), ('training', 'VBG'), ('using', 'VBG'), ('quality', 'NN'), ('scores', 'NNS'), ('training', 'VBG'), ('iv', 'JJ'), ('process', 'NN'), ('updating', 'VBG'), ('attention', 'NN'), ('parameters', 'NNS'), ('learned', 'VBD'), ('previous', 'JJ'), ('iteration', 'NN'), ('least', 'JJS'), ('two', 'CD'), ('attention', 'NN'), ('blocks', 'NNS'), ('one', 'CD'), ('losses', 'NNS'), ('minimized', 'VBN'), ('outputted', 'JJ'), ('loss', 'NN'), ('layer', 'NN'), ('referring', 'VBG'), ('optimal', 'JJ'), ('feature', 'NN'), ('training', 'VBG'), ('corresponding', 'VBG'), ('ground', 'NN'), ('truth', 'NN'), ('object', 'IN'), ('data', 'NNS'), ('processing', 'VBG'), ('system', 'NN'), ('comprising', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('processor', 'NN'), ('configured', 'VBD'), ('execute', 'CC'), ('least', 'JJS'), ('one', 'CD'), ('implementation', 'NN'), ('plurality', 'NN'), ('recognition', 'NN'), ('algorithms', 'RB'), ('stored', 'VBD'), ('least', 'JJS'), ('one', 'CD'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('storage', 'NN'), ('medium', 'NN'), ('recognition', 'NN'), ('algorithm', 'IN'), ('feature', 'NN'), ('density', 'NN'), ('selection', 'NN'), ('criteria', 'NNS'), ('data', 'NNS'), ('preprocessing', 'VBG'), ('code', 'NN'), ('executed', 'VBD'), ('least', 'JJS'), ('one', 'CD'), ('processor', 'NN'), ('data', 'NNS'), ('preprocessing', 'VBG'), ('code', 'NN'), ('comprising', 'VBG'), ('invariant', 'JJ'), ('feature', 'NN'), ('identification', 'NN'), ('algorithm', 'RB'), ('configured', 'VBD'), ('obtain', 'VB'), ('digital', 'JJ'), ('representation', 'NN'), ('scene', 'NN'), ('scene', 'NN'), ('comprising', 'VBG'), ('one', 'CD'), ('textual', 'JJ'), ('media', 'NNS'), ('generate', 'NN'), ('set', 'VBN'), ('invariant', 'JJ'), ('features', 'NNS'), ('applying', 'VBG'), ('invariant', 'JJ'), ('feature', 'NN'), ('identification', 'NN'), ('algorithm', 'IN'), ('digital', 'JJ'), ('representation', 'NN'), ('cluster', 'NN'), ('set', 'VBN'), ('invariant', 'JJ'), ('features', 'NNS'), ('regions', 'NNS'), ('interest', 'NN'), ('digital', 'JJ'), ('representation', 'NN'), ('scene', 'NN'), ('region', 'NN'), ('interest', 'NN'), ('region', 'NN'), ('feature', 'NN'), ('density', 'NN'), ('classify', 'VB'), ('region', 'NN'), ('classifier', 'JJR'), ('code', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('regions', 'NNS'), ('interest', 'NN'), ('according', 'VBG'), ('object', 'JJ'), ('type', 'NN'), ('function', 'NN'), ('attributes', 'VBZ'), ('derived', 'JJ'), ('region', 'NN'), ('feature', 'NN'), ('density', 'NN'), ('digital', 'JJ'), ('representation', 'NN'), ('wherein', 'VBD'), ('least', 'JJS'), ('one', 'CD'), ('classified', 'JJ'), ('regions', 'NNS'), ('interest', 'NN'), ('corresponds', 'NNS'), ('text', 'JJ'), ('use', 'NN'), ('classification', 'NN'), ('result', 'NN'), ('corresponding', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('regions', 'NNS'), ('interest', 'NN'), ('classify', 'NN'), ('another', 'DT'), ('regions', 'NNS'), ('interest', 'NN'), ('according', 'VBG'), ('object', 'JJ'), ('type', 'NN'), ('wherein', 'NN'), ('another', 'DT'), ('regions', 'NNS'), ('interest', 'NN'), ('corresponds', 'VBZ'), ('region', 'NN'), ('interest', 'NN'), ('images', 'NNS'), ('system', 'NN'), ('claim', 'VBP'), ('wherein', 'IN'), ('preprocessing', 'VBG'), ('code', 'NN'), ('based', 'VBN'), ('feature', 'NN'), ('density', 'NN'), ('selection', 'NN'), ('criteria', 'NNS'), ('determines', 'VBZ'), ('ocr', 'JJ'), ('algorithm', 'NN'), ('applicable', 'JJ'), ('text', 'JJ'), ('recognition', 'NN'), ('algorithms', 'NN'), ('applicable', 'JJ'), ('aspects', 'NNS'), ('photographs', 'VBP'), ('logos', 'JJ'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('user', 'JJ'), ('creates', 'NNS'), ('user', 'VBP'), ('profile', 'IN'), ('camera-equipped', 'JJ'), ('smartphone', 'NN'), ('includes', 'VBZ'), ('information', 'NN'), ('user', 'NN'), ('visually', 'RB'), ('impaired', 'JJ'), ('causes', 'NNS'), ('prioritized', 'JJ'), ('execution', 'NN'), ('ocr', 'IN'), ('algorithm', 'JJ'), ('text', 'JJ'), ('reader', 'NN'), ('program', 'NN'), ('begins', 'VBZ'), ('reading', 'VBG'), ('text', 'IN'), ('user', 'JJ'), ('quickly', 'RB'), ('possible', 'JJ'), ('system', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('audio', 'JJ'), ('tactile', 'NN'), ('feedback', 'NN'), ('mechanism', 'NN'), ('helps', 'VBZ'), ('user', 'JJ'), ('position', 'NN'), ('smart', 'NN'), ('phone', 'NN'), ('relative', 'JJ'), ('text', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('``', '``'), ('hold', 'VB'), ('still', 'RB'), (\"''\", \"''\"), ('audio', 'JJ'), ('feedback', 'NN'), ('signal', 'JJ'), ('sent', 'VBD'), ('user', 'JJ'), ('text', 'NN'), ('center', 'NN'), ('captured', 'VBN'), ('scene', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('digital', 'JJ'), ('representation', 'NN'), ('comprises', 'NNS'), ('least', 'VBP'), ('one', 'CD'), ('following', 'VBG'), ('types', 'NNS'), ('digital', 'JJ'), ('data', 'NNS'), ('image', 'NN'), ('data', 'NNS'), ('video', 'NN'), ('data', 'NNS'), ('audio', 'RB'), ('data', 'NNS'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('invariant', 'JJ'), ('feature', 'NN'), ('identification', 'NN'), ('algorithm', 'NN'), ('comprises', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('following', 'VBG'), ('feature', 'NN'), ('identification', 'NN'), ('algorithms', 'IN'), ('fast', 'JJ'), ('sift', 'NN'), ('freak', 'NN'), ('brisk', 'JJ'), ('harris', 'NN'), ('daisy', 'NN'), ('mser', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('invariant', 'JJ'), ('feature', 'NN'), ('identification', 'NN'), ('algorithm', 'NN'), ('includes', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('following', 'VBG'), ('edge', 'NN'), ('detection', 'NN'), ('algorithm', 'NN'), ('corner', 'NN'), ('detection', 'NN'), ('algorithm', 'JJ'), ('saliency', 'NN'), ('map', 'NN'), ('algorithm', 'NN'), ('curve', 'NN'), ('detection', 'NN'), ('algorithm', 'IN'), ('texton', 'NN'), ('identification', 'NN'), ('algorithm', 'IN'), ('wavelets', 'NNS'), ('algorithm', 'JJ'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('least', 'JJS'), ('one', 'CD'), ('region', 'NN'), ('interest', 'NN'), ('represents', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('physical', 'JJ'), ('object', 'NN'), ('scene', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('least', 'JJS'), ('one', 'CD'), ('region', 'NN'), ('interest', 'NN'), ('represents', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('textual', 'JJ'), ('media', 'NNS'), ('scene', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'JJ'), ('region', 'NN'), ('interest', 'NN'), ('represents', 'VBZ'), ('document', 'JJ'), ('textual', 'JJ'), ('media', 'NNS'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'JJ'), ('region', 'NN'), ('interest', 'NN'), ('represents', 'VBZ'), ('financial', 'JJ'), ('document', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'JJ'), ('region', 'NN'), ('interest', 'NN'), ('represents', 'VBZ'), ('structured', 'VBN'), ('document', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('least', 'JJS'), ('one', 'CD'), ('implementation', 'NN'), ('plurality', 'NN'), ('recognition', 'NN'), ('algorithms', 'VBZ'), ('includes', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('following', 'VBG'), ('template', 'NN'), ('driven', 'VBN'), ('algorithm', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('algorithm', 'RB'), ('optical', 'JJ'), ('character', 'NN'), ('recognition', 'NN'), ('algorithm', 'IN'), ('speech', 'NN'), ('recognition', 'NN'), ('algorithm', 'IN'), ('object', 'JJ'), ('recognition', 'NN'), ('algorithm', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('data', 'NNS'), ('preprocessing', 'VBG'), ('code', 'NN'), ('configured', 'VBD'), ('assign', 'JJ'), ('region', 'NN'), ('interest', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('recognition', 'NN'), ('algorithm', 'NN'), ('function', 'NN'), ('scene', 'NN'), ('context', 'NN'), ('derived', 'VBD'), ('digital', 'JJ'), ('representation', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'WRB'), ('scene', 'NN'), ('context', 'NN'), ('includes', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('following', 'VBG'), ('types', 'NNS'), ('data', 'NNS'), ('location', 'NN'), ('position', 'NN'), ('time', 'NN'), ('user', 'JJ'), ('identity', 'NN'), ('news', 'NN'), ('event', 'NN'), ('medical', 'JJ'), ('event', 'NN'), ('promotion', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('mobile', 'JJ'), ('device', 'NN'), ('comprising', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('implementation', 'NN'), ('plurality', 'NN'), ('recognition', 'NN'), ('algorithms', 'IN'), ('data', 'NNS'), ('preprocessing', 'VBG'), ('code', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'VBP'), ('mobile', 'JJ'), ('device', 'NN'), ('comprises', 'NNS'), ('least', 'VBP'), ('one', 'CD'), ('following', 'VBG'), ('smart', 'JJ'), ('phone', 'NN'), ('tablet', 'NN'), ('wearable', 'JJ'), ('glass', 'NN'), ('toy', 'NN'), ('vehicle', 'NN'), ('computer', 'NN'), ('phablet', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('network-accessible', 'JJ'), ('server', 'NN'), ('device', 'NN'), ('comprising', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('implementation', 'NN'), ('plurality', 'NN'), ('recognition', 'NN'), ('algorithms', 'IN'), ('data', 'NNS'), ('preprocessing', 'VBG'), ('code', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('object', 'VBP'), ('type', 'NN'), ('includes', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('following', 'VBG'), ('face', 'NN'), ('animal', 'JJ'), ('vehicle', 'NN'), ('document', 'NN'), ('plant', 'NN'), ('building', 'NN'), ('appliance', 'NN'), ('clothing', 'NN'), ('body', 'NN'), ('part', 'NN'), ('toy', 'NN'), ('object', 'VBP'), ('data', 'NNS'), ('processing', 'NN'), ('system', 'NN'), ('comprising', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('processor', 'NN'), ('configured', 'VBD'), ('execute', 'CC'), ('least', 'JJS'), ('one', 'CD'), ('implementation', 'NN'), ('plurality', 'NN'), ('recognition', 'NN'), ('algorithms', 'RB'), ('stored', 'VBD'), ('least', 'JJS'), ('one', 'CD'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('storage', 'NN'), ('medium', 'NN'), ('recognition', 'NN'), ('algorithm', 'IN'), ('feature', 'NN'), ('density', 'NN'), ('selection', 'NN'), ('criteria', 'NNS'), ('data', 'NNS'), ('preprocessing', 'VBG'), ('code', 'NN'), ('executed', 'VBD'), ('least', 'JJS'), ('one', 'CD'), ('processor', 'NN'), ('data', 'NNS'), ('preprocessing', 'VBG'), ('code', 'NN'), ('comprising', 'VBG'), ('invariant', 'JJ'), ('feature', 'NN'), ('identification', 'NN'), ('algorithm', 'RB'), ('configured', 'VBD'), ('obtain', 'VB'), ('digital', 'JJ'), ('representation', 'NN'), ('scene', 'NN'), ('scene', 'NN'), ('comprising', 'VBG'), ('one', 'CD'), ('textual', 'JJ'), ('media', 'NNS'), ('generate', 'NN'), ('set', 'VBN'), ('invariant', 'JJ'), ('features', 'NNS'), ('applying', 'VBG'), ('invariant', 'JJ'), ('feature', 'NN'), ('identification', 'NN'), ('algorithm', 'IN'), ('digital', 'JJ'), ('representation', 'NN'), ('cluster', 'NN'), ('set', 'VBN'), ('invariant', 'JJ'), ('features', 'NNS'), ('regions', 'NNS'), ('interest', 'NN'), ('digital', 'JJ'), ('representation', 'NN'), ('scene', 'NN'), ('region', 'NN'), ('interest', 'NN'), ('region', 'NN'), ('feature', 'NN'), ('density', 'NN'), ('classify', 'VB'), ('region', 'NN'), ('classifier', 'JJR'), ('code', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('regions', 'NNS'), ('interest', 'NN'), ('according', 'VBG'), ('object', 'JJ'), ('type', 'NN'), ('function', 'NN'), ('attributes', 'VBZ'), ('derived', 'JJ'), ('region', 'NN'), ('feature', 'NN'), ('density', 'NN'), ('digital', 'JJ'), ('representation', 'NN'), ('wherein', 'VBD'), ('least', 'JJS'), ('one', 'CD'), ('classified', 'JJ'), ('regions', 'NNS'), ('interest', 'NN'), ('corresponds', 'NNS'), ('text', 'JJ'), ('use', 'NN'), ('classification', 'NN'), ('result', 'NN'), ('corresponding', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('regions', 'NNS'), ('interest', 'NN'), ('classify', 'NN'), ('another', 'DT'), ('regions', 'NNS'), ('interest', 'NN'), ('according', 'VBG'), ('object', 'JJ'), ('type', 'NN'), ('wherein', 'NN'), ('another', 'DT'), ('regions', 'NNS'), ('interest', 'NN'), ('corresponds', 'VBZ'), ('region', 'NN'), ('interest', 'NN'), ('images', 'NNS'), ('assign', 'JJ'), ('region', 'NN'), ('interest', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('recognition', 'NN'), ('algorithm', 'IN'), ('least', 'JJS'), ('one', 'CD'), ('implementation', 'NN'), ('plurality', 'NN'), ('diverse', 'JJ'), ('recognition', 'NN'), ('algorithms', 'NN'), ('function', 'NN'), ('region', 'NN'), ('feature', 'NN'), ('density', 'NN'), ('region', 'NN'), ('interest', 'NN'), ('feature', 'NN'), ('density', 'NN'), ('selection', 'NN'), ('criteria', 'NNS'), ('least', 'VBP'), ('one', 'CD'), ('implementation', 'NN'), ('plurality', 'NN'), ('diverse', 'JJ'), ('recognition', 'NN'), ('algorithms', 'IN'), ('configure', 'NN'), ('assigned', 'VBN'), ('recognition', 'NN'), ('algorithms', 'NN'), ('process', 'NN'), ('respective', 'JJ'), ('regions', 'NNS'), ('interest', 'NN'), ('wherein', 'NN'), ('preprocessing', 'VBG'), ('code', 'NN'), ('based', 'VBN'), ('feature', 'NN'), ('density', 'NN'), ('selection', 'NN'), ('criteria', 'NNS'), ('determines', 'VBZ'), ('ocr', 'JJ'), ('algorithm', 'NN'), ('applicable', 'JJ'), ('text', 'JJ'), ('recognition', 'NN'), ('algorithms', 'NN'), ('applicable', 'JJ'), ('aspects', 'NNS'), ('photographs', 'VBP'), ('logos', 'JJ'), ('device', 'NN'), ('comprising', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('processor', 'NN'), ('configured', 'VBD'), ('execute', 'CC'), ('least', 'JJS'), ('one', 'CD'), ('implementation', 'NN'), ('plurality', 'NN'), ('recognition', 'NN'), ('algorithms', 'RB'), ('stored', 'VBD'), ('least', 'JJS'), ('one', 'CD'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('storage', 'NN'), ('medium', 'NN'), ('recognition', 'NN'), ('algorithm', 'IN'), ('feature', 'NN'), ('density', 'NN'), ('selection', 'NN'), ('criteria', 'NNS'), ('data', 'NNS'), ('preprocessing', 'VBG'), ('code', 'NN'), ('executed', 'VBD'), ('least', 'JJS'), ('one', 'CD'), ('processor', 'NN'), ('data', 'NNS'), ('preprocessing', 'VBG'), ('code', 'NN'), ('comprising', 'VBG'), ('invariant', 'JJ'), ('feature', 'NN'), ('identification', 'NN'), ('algorithm', 'RB'), ('configured', 'VBD'), ('obtain', 'VB'), ('digital', 'JJ'), ('representation', 'NN'), ('scene', 'NN'), ('scene', 'NN'), ('comprising', 'VBG'), ('one', 'CD'), ('textual', 'JJ'), ('media', 'NNS'), ('generate', 'NN'), ('set', 'VBN'), ('invariant', 'JJ'), ('features', 'NNS'), ('applying', 'VBG'), ('invariant', 'JJ'), ('feature', 'NN'), ('identification', 'NN'), ('algorithm', 'IN'), ('digital', 'JJ'), ('representation', 'NN'), ('cluster', 'NN'), ('set', 'VBN'), ('invariant', 'JJ'), ('features', 'NNS'), ('regions', 'NNS'), ('interest', 'NN'), ('digital', 'JJ'), ('representation', 'NN'), ('scene', 'NN'), ('region', 'NN'), ('interest', 'NN'), ('region', 'NN'), ('feature', 'NN'), ('density', 'NN'), ('classify', 'VB'), ('region', 'NN'), ('classifier', 'JJR'), ('code', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('regions', 'NNS'), ('interest', 'NN'), ('according', 'VBG'), ('object', 'JJ'), ('type', 'NN'), ('function', 'NN'), ('attributes', 'VBZ'), ('derived', 'JJ'), ('region', 'NN'), ('feature', 'NN'), ('density', 'NN'), ('digital', 'JJ'), ('representation', 'NN'), ('wherein', 'VBD'), ('least', 'JJS'), ('one', 'CD'), ('classified', 'JJ'), ('regions', 'NNS'), ('interest', 'NN'), ('corresponds', 'NNS'), ('text', 'JJ'), ('use', 'NN'), ('classification', 'NN'), ('result', 'NN'), ('corresponding', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('regions', 'NNS'), ('interest', 'NN'), ('classify', 'NN'), ('another', 'DT'), ('regions', 'NNS'), ('interest', 'NN'), ('according', 'VBG'), ('object', 'JJ'), ('type', 'NN'), ('wherein', 'NN'), ('another', 'DT'), ('regions', 'NNS'), ('interest', 'NN'), ('corresponds', 'VBZ'), ('region', 'NN'), ('interest', 'NN'), ('images', 'NNS'), ('mobile', 'VBP'), ('terminal', 'JJ'), ('comprising', 'NN'), ('front', 'JJ'), ('camera', 'NN'), ('configured', 'VBD'), ('obtain', 'VB'), ('two-dimensional', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('user', 'JJ'), ('glance', 'NN'), ('sensor', 'NN'), ('tilted', 'VBD'), ('certain', 'JJ'), ('angle', 'NN'), ('disposed', 'VBD'), ('adjacent', 'JJ'), ('front', 'JJ'), ('camera', 'NN'), ('obtain', 'VB'), ('metadata', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('controller', 'NN'), ('obtaining', 'VBG'), ('distance', 'NN'), ('glance', 'NN'), ('sensor', 'NN'), ('front', 'NN'), ('camera', 'NN'), ('distance', 'NN'), ('enabling', 'VBG'), ('area', 'NN'), ('overlap', 'IN'), ('region', 'NN'), ('first', 'JJ'), ('region', 'NN'), ('representing', 'VBG'), ('range', 'NN'), ('photographable', 'JJ'), ('front', 'NN'), ('camera', 'NN'), ('overlaps', 'VBZ'), ('second', 'JJ'), ('region', 'NN'), ('representing', 'VBG'), ('range', 'NN'), ('photographable', 'JJ'), ('glance', 'NN'), ('sensor', 'NN'), ('maximum', 'NN'), ('mobile', 'JJ'), ('terminal', 'JJ'), ('claim', 'NN'), ('wherein', 'NN'), ('controller', 'NN'), ('configured', 'VBD'), ('obtain', 'VB'), ('distance', 'NN'), ('enabling', 'VBG'), ('area', 'NN'), ('overlap', 'JJ'), ('region', 'NN'), ('maximum', 'JJ'), ('glance', 'NN'), ('sensor', 'NN'), ('front', 'NN'), ('camera', 'NN'), ('varying', 'VBG'), ('tilting', 'VBG'), ('angle', 'JJ'), ('glance', 'NN'), ('sensor', 'NN'), ('mobile', 'JJ'), ('terminal', 'JJ'), ('claim', 'NN'), ('wherein', 'NN'), ('controller', 'NN'), ('configured', 'VBD'), ('set', 'VBN'), ('distance', 'NN'), ('enabling', 'VBG'), ('area', 'NN'), ('overlap', 'JJ'), ('region', 'NN'), ('maximum', 'JJ'), ('glance', 'NN'), ('sensor', 'NN'), ('front', 'NN'), ('camera', 'NN'), ('tilting', 'VBG'), ('angle', 'JJ'), ('glance', 'NN'), ('sensor', 'NN'), ('optimal', 'JJ'), ('disposition', 'NN'), ('location', 'NN'), ('glance', 'NN'), ('sensor', 'NN'), ('mobile', 'JJ'), ('terminal', 'JJ'), ('claim', 'NN'), ('wherein', 'NN'), ('controller', 'NN'), ('configured', 'VBD'), ('set', 'VBN'), ('disposition', 'NN'), ('location', 'NN'), ('front', 'NN'), ('camera', 'NN'), ('original', 'JJ'), ('point', 'NN'), ('calculates', 'NNS'), ('coordinates', 'NNS'), ('first', 'RB'), ('triangle', 'VBP'), ('representing', 'VBG'), ('first', 'JJ'), ('region', 'NN'), ('based', 'VBN'), ('field', 'NN'), ('view', 'NN'), ('front', 'JJ'), ('camera', 'NN'), ('maximum', 'JJ'), ('photographing', 'VBG'), ('distance', 'NN'), ('front', 'NN'), ('camera', 'NN'), ('mobile', 'JJ'), ('terminal', 'JJ'), ('claim', 'NN'), ('wherein', 'NN'), ('controller', 'NN'), ('configured', 'VBD'), ('calculate', 'JJ'), ('coordinates', 'NNS'), ('second', 'JJ'), ('triangle', 'JJ'), ('representing', 'VBG'), ('second', 'JJ'), ('region', 'NN'), ('based', 'VBN'), ('field', 'NN'), ('view', 'NN'), ('glance', 'NN'), ('sensor', 'NN'), ('maximum', 'NN'), ('photographing', 'VBG'), ('distance', 'NN'), ('glance', 'NN'), ('sensor', 'NN'), ('distance', 'NN'), ('front', 'JJ'), ('camera', 'NN'), ('glance', 'NN'), ('sensor', 'NN'), ('tilting', 'VBG'), ('angle', 'JJ'), ('glance', 'NN'), ('sensor', 'NN'), ('mobile', 'JJ'), ('terminal', 'JJ'), ('claim', 'NN'), ('wherein', 'NN'), ('glance', 'NN'), ('sensor', 'NN'), ('tilted', 'VBD'), ('controller', 'NN'), ('configured', 'JJ'), ('calculate', 'NN'), ('coordinates', 'NNS'), ('third', 'JJ'), ('triangle', 'JJ'), ('representing', 'VBG'), ('third', 'JJ'), ('region', 'NN'), ('photographable', 'JJ'), ('glance', 'NN'), ('sensor', 'NN'), ('controller', 'NN'), ('configured', 'VBD'), ('rotation-convert', 'JJ'), ('coordinates', 'NNS'), ('third', 'JJ'), ('triangle', 'NNS'), ('based', 'VBN'), ('tilting', 'VBG'), ('angle', 'JJ'), ('glance', 'NN'), ('sensor', 'NN'), ('calculate', 'NN'), ('coordinates', 'NNS'), ('second', 'JJ'), ('triangle', 'VBP'), ('mobile', 'JJ'), ('terminal', 'JJ'), ('claim', 'NN'), ('wherein', 'NN'), ('controller', 'NN'), ('configured', 'VBD'), ('calculate', 'NN'), ('coordinates', 'NNS'), ('overlap', 'VBP'), ('region', 'NN'), ('based', 'VBN'), ('coordinates', 'NNS'), ('first', 'JJ'), ('triangle', 'JJ'), ('coordinates', 'NNS'), ('second', 'JJ'), ('triangle', 'NN'), ('calculates', 'NNS'), ('area', 'NN'), ('overlap', 'VBP'), ('region', 'NN'), ('based', 'VBN'), ('coordinates', 'NNS'), ('overlap', 'JJ'), ('region', 'NN'), ('mobile', 'JJ'), ('terminal', 'JJ'), ('claim', 'NN'), ('wherein', 'NN'), ('controller', 'NN'), ('configured', 'VBD'), ('generate', 'JJ'), ('three-dimensional', 'JJ'), ('face', 'NN'), ('information', 'NN'), ('based', 'VBN'), ('face', 'NN'), ('image', 'NN'), ('obtained', 'VBD'), ('front', 'JJ'), ('camera', 'NN'), ('metadata', 'NN'), ('obtained', 'VBD'), ('glance', 'NN'), ('sensor', 'NN'), ('mobile', 'JJ'), ('terminal', 'JJ'), ('claim', 'NN'), ('wherein', 'NN'), ('metadata', 'NN'), ('comprises', 'VBZ'), ('one', 'CD'), ('angle', 'NN'), ('face', 'NN'), ('user', 'NN'), ('size', 'NN'), ('face', 'NN'), ('location', 'NN'), ('face', 'NN'), ('mobile', 'JJ'), ('terminal', 'JJ'), ('claim', 'NN'), ('wherein', 'NN'), ('angle', 'VBD'), ('face', 'NN'), ('comprises', 'NNS'), ('angle', 'VBP'), ('face', 'NN'), ('rotated', 'VBD'), ('one', 'CD'), ('pitch', 'NN'), ('axis', 'NN'), ('roll', 'NN'), ('axis', 'NN'), ('yaw', 'NN'), ('axis', 'VBP'), ('mobile', 'JJ'), ('terminal', 'JJ'), ('claim', 'NN'), ('comprising', 'VBG'), ('memory', 'NN'), ('storing', 'VBG'), ('generated', 'VBD'), ('face', 'NN'), ('information', 'NN'), ('wherein', 'WRB'), ('controller', 'NN'), ('configured', 'VBD'), ('performs', 'NNS'), ('user', 'JJ'), ('authentication', 'NN'), ('process', 'NN'), ('comparing', 'VBG'), ('stored', 'VBD'), ('face', 'NN'), ('information', 'NN'), ('face', 'NN'), ('information', 'NN'), ('obtained', 'VBN'), ('user', 'JJ'), ('authentication', 'NN'), ('mobile', 'JJ'), ('terminal', 'JJ'), ('claim', 'NN'), ('wherein', 'NN'), ('glance', 'NN'), ('sensor', 'NN'), ('controlled', 'VBD'), ('permanently', 'RB'), ('activated', 'VBN'), ('low', 'JJ'), ('power', 'NN'), ('obtain', 'VB'), ('front', 'JJ'), ('image', 'NN'), ('metadata', 'NN'), ('front', 'JJ'), ('image', 'NN'), ('mobile', 'JJ'), ('terminal', 'JJ'), ('claim', 'NN'), ('wherein', 'NN'), ('front', 'JJ'), ('camera', 'NN'), ('glance', 'NN'), ('sensor', 'NN'), ('disposed', 'VBD'), ('line', 'NN'), ('upper', 'JJ'), ('end', 'NN'), ('mobile', 'JJ'), ('terminal', 'NN'), ('mobile', 'JJ'), ('terminal', 'JJ'), ('claim', 'NN'), ('wherein', 'NN'), ('glance', 'NN'), ('sensor', 'NN'), ('tilted', 'VBD'), ('one', 'CD'), ('direction', 'NN'), ('direction', 'NN'), ('direction', 'NN'), ('left', 'VBD'), ('direction', 'NN'), ('right', 'JJ'), ('direction', 'NN'), ('mobile', 'JJ'), ('terminal', 'JJ'), ('claim', 'NN'), ('wherein', 'NN'), ('metadata', 'NN'), ('data', 'NNS'), ('changed', 'VBD'), ('mobile', 'JJ'), ('terminal', 'NN'), ('tilted', 'VBD'), ('external', 'JJ'), ('physical', 'JJ'), ('force', 'NN'), ('method', 'NN'), ('comprising', 'VBG'), ('receiving', 'VBG'), ('smart', 'JJ'), ('television', 'NN'), ('tv', 'NN'), ('indication', 'NN'), ('upcoming', 'VBG'), ('media', 'NNS'), ('programming', 'VBG'), ('wherein', 'NN'), ('upcoming', 'JJ'), ('media', 'NNS'), ('programming', 'VBG'), ('based', 'VBN'), ('user', 'NN'), ('profile', 'NN'), ('identifying', 'VBG'), ('one', 'CD'), ('devices', 'NNS'), ('communication', 'NN'), ('smart', 'JJ'), ('tv', 'NN'), ('one', 'CD'), ('devices', 'NNS'), ('including', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('microphone', 'NN'), ('camera', 'NN'), ('instructing', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('identified', 'JJ'), ('device', 'NN'), ('detect', 'NN'), ('audio', 'NN'), ('signals', 'NNS'), ('using', 'VBG'), ('respective', 'JJ'), ('microphone', 'NN'), ('detect', 'JJ'), ('visual', 'JJ'), ('signals', 'NNS'), ('using', 'VBG'), ('respective', 'JJ'), ('camera', 'NN'), ('selecting', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('device', 'NN'), ('one', 'CD'), ('devices', 'NNS'), ('based', 'VBN'), ('detected', 'JJ'), ('audio', 'JJ'), ('signal', 'NN'), ('detected', 'VBD'), ('visual', 'JJ'), ('signal', 'NN'), ('providing', 'VBG'), ('instructions', 'NNS'), ('selected', 'VBN'), ('device', 'NN'), ('output', 'NN'), ('notification', 'NN'), ('related', 'VBN'), ('upcoming', 'JJ'), ('media', 'NNS'), ('programming', 'VBG'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('upcoming', 'VBG'), ('media', 'NNS'), ('programming', 'VBG'), ('one', 'CD'), ('live', 'JJ'), ('television', 'NN'), ('program', 'NN'), ('recorded', 'VBN'), ('television', 'NN'), ('program', 'NN'), ('broadcast', 'NN'), ('television', 'NN'), ('program', 'NN'), ('application-provided', 'JJ'), ('program', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('selecting', 'VBG'), ('first', 'JJ'), ('device', 'NN'), ('based', 'VBN'), ('detected', 'JJ'), ('audio', 'JJ'), ('signal', 'NN'), ('includes', 'VBZ'), ('recognizing', 'VBG'), ('voice', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('determining', 'VBG'), ('distance', 'NN'), ('recognized', 'VBN'), ('voice', 'NN'), ('wherein', 'NN'), ('selecting', 'VBG'), ('first', 'JJ'), ('device', 'NN'), ('based', 'VBN'), ('determined', 'JJ'), ('distance', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('selecting', 'VBG'), ('first', 'JJ'), ('device', 'NN'), ('based', 'VBN'), ('detected', 'VBN'), ('visual', 'JJ'), ('signals', 'NNS'), ('includes', 'VBZ'), ('recognizing', 'VBG'), ('face', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('recognizing', 'VBG'), ('face', 'NN'), ('includes', 'VBZ'), ('face', 'JJ'), ('recognition', 'NN'), ('technique', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('presenting', 'VBG'), ('smart', 'JJ'), ('tv', 'NN'), ('upcoming', 'VBG'), ('media', 'NNS'), ('programming', 'VBG'), ('favorite', 'JJ'), ('channel', 'NNS'), ('list', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('obtaining', 'VBG'), ('media', 'NNS'), ('programming', 'VBG'), ('viewing', 'VBG'), ('data', 'NNS'), ('wherein', 'RB'), ('media', 'NNS'), ('programming', 'VBG'), ('viewing', 'VBG'), ('data', 'NNS'), ('includes', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('historical', 'JJ'), ('time', 'NN'), ('historical', 'JJ'), ('date', 'NN'), ('one', 'CD'), ('media', 'NNS'), ('programs', 'NNS'), ('viewed', 'VBD'), ('obtaining', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('current', 'JJ'), ('time', 'NN'), ('current', 'JJ'), ('date', 'NN'), ('processing', 'NN'), ('media', 'NNS'), ('programming', 'VBG'), ('viewing', 'VBG'), ('data', 'NNS'), ('determine', 'NN'), ('probability', 'NN'), ('one', 'CD'), ('media', 'NNS'), ('programs', 'NNS'), ('viewed', 'VBD'), ('based', 'VBN'), ('least', 'JJS'), ('one', 'CD'), ('current', 'JJ'), ('time', 'NN'), ('current', 'JJ'), ('date', 'NN'), ('presenting', 'NN'), ('favorite', 'JJ'), ('channel', 'NNS'), ('list', 'NN'), ('based', 'VBN'), ('determined', 'JJ'), ('probability', 'NN'), ('one', 'CD'), ('media', 'NNS'), ('programs', 'NNS'), ('viewed', 'VBD'), ('method', 'JJ'), ('claim', 'NN'), ('wherein', 'NN'), ('processing', 'VBG'), ('media', 'NNS'), ('programming', 'VBG'), ('viewing', 'VBG'), ('data', 'NNS'), ('includes', 'VBZ'), ('employing', 'VBG'), ('neural', 'JJ'), ('network', 'NN'), ('model', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('employing', 'VBG'), ('neural', 'JJ'), ('network', 'NN'), ('model', 'NN'), ('comprises', 'VBZ'), ('determining', 'VBG'), ('duration', 'NN'), ('one', 'CD'), ('media', 'NNS'), ('programs', 'NNS'), ('viewed', 'VBD'), ('least', 'JJS'), ('one', 'CD'), ('historical', 'JJ'), ('time', 'NN'), ('historical', 'JJ'), ('date', 'NN'), ('setting', 'VBG'), ('threshold', 'JJ'), ('time', 'NN'), ('duration', 'NN'), ('comparing', 'VBG'), ('determined', 'VBN'), ('duration', 'NN'), ('threshold', 'JJ'), ('time', 'NN'), ('duration', 'NN'), ('filtering', 'VBG'), ('one', 'CD'), ('media', 'NNS'), ('programs', 'NNS'), ('viewed', 'VBD'), ('threshold', 'JJ'), ('time', 'NN'), ('duration', 'NN'), ('smart', 'JJ'), ('television', 'NN'), ('tv', 'NN'), ('comprising', 'VBG'), ('network', 'NN'), ('interface', 'JJ'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('medium', 'NN'), ('processor', 'NN'), ('communication', 'NN'), ('network', 'NN'), ('interface', 'JJ'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('medium', 'NN'), ('capable', 'JJ'), ('executing', 'VBG'), ('processor-executable', 'JJ'), ('program', 'NN'), ('code', 'NN'), ('stored', 'VBD'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('medium', 'NN'), ('cause', 'NN'), ('smart', 'JJ'), ('tv', 'NN'), ('receive', 'NN'), ('indication', 'NN'), ('upcoming', 'VBG'), ('media', 'NNS'), ('programming', 'VBG'), ('wherein', 'NN'), ('upcoming', 'JJ'), ('media', 'NNS'), ('programming', 'VBG'), ('based', 'VBN'), ('user', 'NN'), ('profile', 'NN'), ('identify', 'VB'), ('one', 'CD'), ('devices', 'NNS'), ('communication', 'NN'), ('smart', 'JJ'), ('tv', 'NN'), ('one', 'CD'), ('devices', 'NNS'), ('including', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('microphone', 'NN'), ('camera', 'NN'), ('instruct', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('identified', 'JJ'), ('device', 'NN'), ('detect', 'NN'), ('audio', 'NN'), ('signals', 'NNS'), ('using', 'VBG'), ('respective', 'JJ'), ('microphone', 'NN'), ('detect', 'JJ'), ('visual', 'JJ'), ('signals', 'NNS'), ('using', 'VBG'), ('respective', 'JJ'), ('camera', 'NN'), ('select', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('device', 'NN'), ('one', 'CD'), ('devices', 'NNS'), ('based', 'VBN'), ('detected', 'JJ'), ('audio', 'JJ'), ('signal', 'NN'), ('detected', 'VBD'), ('visual', 'JJ'), ('signal', 'NN'), ('provide', 'NN'), ('instructions', 'NNS'), ('selected', 'VBN'), ('device', 'NN'), ('output', 'NN'), ('notification', 'NN'), ('related', 'VBN'), ('upcoming', 'JJ'), ('media', 'NNS'), ('programming', 'VBG'), ('smart', 'JJ'), ('tv', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('selecting', 'VBG'), ('first', 'JJ'), ('device', 'NN'), ('based', 'VBN'), ('detected', 'JJ'), ('audio', 'JJ'), ('signal', 'NN'), ('includes', 'VBZ'), ('recognizing', 'VBG'), ('voice', 'NN'), ('smart', 'JJ'), ('tv', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('processor', 'NN'), ('capable', 'JJ'), ('executing', 'VBG'), ('processor-executable', 'JJ'), ('program', 'NN'), ('code', 'NN'), ('determine', 'NN'), ('distance', 'NN'), ('recognized', 'VBN'), ('voice', 'NN'), ('wherein', 'NN'), ('selecting', 'VBG'), ('first', 'JJ'), ('device', 'NN'), ('based', 'VBN'), ('determined', 'JJ'), ('distance', 'NN'), ('smart', 'JJ'), ('tv', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('selecting', 'VBG'), ('first', 'JJ'), ('device', 'NN'), ('based', 'VBN'), ('detected', 'VBN'), ('visual', 'JJ'), ('signals', 'NNS'), ('includes', 'VBZ'), ('detecting', 'VBG'), ('presence', 'NN'), ('user', 'JJ'), ('smart', 'JJ'), ('tv', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('detecting', 'VBG'), ('presence', 'NN'), ('user', 'NN'), ('includes', 'VBZ'), ('employing', 'VBG'), ('one', 'CD'), ('camera', 'NN'), ('microphone', 'NN'), ('fingerprint', 'NN'), ('sensor', 'NN'), ('associated', 'VBN'), ('least', 'JJS'), ('one', 'CD'), ('smart', 'JJ'), ('tv', 'NN'), ('mobile', 'NN'), ('device', 'NN'), ('smartphone', 'NN'), ('laptop', 'JJ'), ('computer', 'NN'), ('tablet', 'NN'), ('device', 'NN'), ('wearable', 'JJ'), ('device', 'NN'), ('internet', 'NN'), ('things', 'NNS'), ('iot', 'JJ'), ('device', 'JJ'), ('internet', 'NN'), ('everything', 'NN'), ('ioe', 'NN'), ('device', 'NN'), ('iot', 'NN'), ('hub', 'NN'), ('ioe', 'NN'), ('hub', 'NN'), ('smart', 'JJ'), ('television', 'NN'), ('tv', 'NN'), ('comprising', 'NN'), ('means', 'VBZ'), ('receiving', 'VBG'), ('indication', 'NN'), ('upcoming', 'VBG'), ('media', 'NNS'), ('programming', 'VBG'), ('wherein', 'NN'), ('upcoming', 'JJ'), ('media', 'NNS'), ('programming', 'VBG'), ('based', 'VBN'), ('user', 'NN'), ('profile', 'NN'), ('means', 'VBZ'), ('identifying', 'VBG'), ('one', 'CD'), ('devices', 'NNS'), ('communication', 'NN'), ('smart', 'JJ'), ('tv', 'NN'), ('one', 'CD'), ('devices', 'NNS'), ('including', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('microphone', 'NN'), ('camera', 'NN'), ('means', 'VBZ'), ('instructing', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('identified', 'JJ'), ('device', 'NN'), ('detect', 'NN'), ('audio', 'NN'), ('signals', 'NNS'), ('using', 'VBG'), ('respective', 'JJ'), ('microphone', 'NN'), ('detect', 'JJ'), ('visual', 'JJ'), ('signals', 'NNS'), ('using', 'VBG'), ('respective', 'JJ'), ('camera', 'NN'), ('means', 'VBZ'), ('selecting', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('device', 'NN'), ('one', 'CD'), ('devices', 'NNS'), ('based', 'VBN'), ('detected', 'JJ'), ('audio', 'JJ'), ('signal', 'NN'), ('detected', 'VBD'), ('visual', 'JJ'), ('signal', 'NN'), ('means', 'NNS'), ('providing', 'VBG'), ('instructions', 'NNS'), ('selected', 'VBN'), ('device', 'NN'), ('output', 'NN'), ('notification', 'NN'), ('related', 'VBN'), ('upcoming', 'JJ'), ('media', 'NNS'), ('programming', 'VBG'), ('smart', 'JJ'), ('tv', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('one', 'CD'), ('devices', 'NNS'), ('includes', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('mobile', 'JJ'), ('device', 'NN'), ('smartphone', 'NN'), ('laptop', 'JJ'), ('computer', 'NN'), ('tablet', 'NN'), ('device', 'NN'), ('wearable', 'JJ'), ('device', 'NN'), ('internet', 'NN'), ('things', 'NNS'), ('iot', 'JJ'), ('device', 'JJ'), ('internet', 'NN'), ('everything', 'NN'), ('ioe', 'NN'), ('device', 'NN'), ('iot', 'NN'), ('hub', 'NN'), ('ioe', 'NN'), ('hub', 'NN'), ('another', 'DT'), ('smart', 'JJ'), ('tv', 'NN'), ('smart', 'JJ'), ('tv', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('upcoming', 'VBG'), ('media', 'NNS'), ('programming', 'VBG'), ('one', 'CD'), ('live', 'JJ'), ('television', 'NN'), ('program', 'NN'), ('recorded', 'VBN'), ('television', 'NN'), ('program', 'NN'), ('broadcast', 'NN'), ('television', 'NN'), ('program', 'NN'), ('application-provided', 'JJ'), ('program', 'NN'), ('smart', 'JJ'), ('tv', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('notification', 'NN'), ('includes', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('push', 'NN'), ('message', 'NN'), ('sms', 'JJ'), ('message', 'NN'), ('waysms', 'JJ'), ('message', 'NN'), ('audio', 'NN'), ('alert', 'NN'), ('audio', 'JJ'), ('message', 'NN'), ('email', 'JJ'), ('message', 'NN'), ('smart', 'JJ'), ('tv', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('presenting', 'VBG'), ('upcoming', 'JJ'), ('media', 'NNS'), ('programming', 'VBG'), ('favorite', 'JJ'), ('channel', 'NNS'), ('list', 'NN'), ('smart', 'JJ'), ('tv', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('means', 'NNS'), ('obtaining', 'VBG'), ('media', 'NNS'), ('programming', 'VBG'), ('viewing', 'VBG'), ('data', 'NNS'), ('wherein', 'RB'), ('media', 'NNS'), ('programming', 'VBG'), ('viewing', 'VBG'), ('data', 'NNS'), ('includes', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('historical', 'JJ'), ('time', 'NN'), ('historical', 'JJ'), ('date', 'NN'), ('one', 'CD'), ('media', 'NNS'), ('programs', 'NNS'), ('viewed', 'VBD'), ('smart', 'JJ'), ('tv', 'NN'), ('means', 'NNS'), ('obtaining', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('current', 'JJ'), ('time', 'NN'), ('current', 'JJ'), ('date', 'NN'), ('means', 'VBZ'), ('processing', 'VBG'), ('media', 'NNS'), ('programming', 'VBG'), ('viewing', 'VBG'), ('data', 'NNS'), ('determine', 'NN'), ('probability', 'NN'), ('one', 'CD'), ('media', 'NNS'), ('programs', 'NNS'), ('viewed', 'VBD'), ('smart', 'JJ'), ('tv', 'NN'), ('based', 'VBN'), ('least', 'JJS'), ('one', 'CD'), ('current', 'JJ'), ('time', 'NN'), ('current', 'JJ'), ('date', 'NN'), ('means', 'NNS'), ('presenting', 'VBG'), ('favorite', 'JJ'), ('channel', 'NNS'), ('list', 'NN'), ('based', 'VBN'), ('determined', 'JJ'), ('probability', 'NN'), ('one', 'CD'), ('media', 'NNS'), ('programs', 'NNS'), ('viewed', 'VBD'), ('smart', 'JJ'), ('tv', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('means', 'VBZ'), ('processing', 'VBG'), ('media', 'NNS'), ('programming', 'VBG'), ('viewing', 'VBG'), ('data', 'NNS'), ('includes', 'VBZ'), ('employing', 'VBG'), ('neural', 'JJ'), ('network', 'NN'), ('model', 'NN'), ('smart', 'JJ'), ('tv', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('employing', 'VBG'), ('neural', 'JJ'), ('network', 'NN'), ('model', 'NN'), ('comprises', 'VBZ'), ('determining', 'VBG'), ('duration', 'NN'), ('one', 'CD'), ('media', 'NNS'), ('programs', 'NNS'), ('viewed', 'VBD'), ('smart', 'JJ'), ('tv', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('historical', 'JJ'), ('time', 'NN'), ('historical', 'JJ'), ('date', 'NN'), ('setting', 'VBG'), ('threshold', 'JJ'), ('time', 'NN'), ('duration', 'NN'), ('comparing', 'VBG'), ('determined', 'VBN'), ('duration', 'NN'), ('threshold', 'JJ'), ('time', 'NN'), ('duration', 'NN'), ('filtering', 'VBG'), ('one', 'CD'), ('media', 'NNS'), ('programs', 'NNS'), ('viewed', 'VBD'), ('threshold', 'JJ'), ('time', 'NN'), ('duration', 'NN'), ('smart', 'JJ'), ('tv', 'NN'), ('claim', 'NN'), ('comprising', 'NN'), ('means', 'VBZ'), ('adjusting', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('volume', 'NN'), ('brightness', 'NN'), ('smart', 'JJ'), ('tv', 'NN'), ('wherein', 'NN'), ('adjusting', 'VBG'), ('based', 'VBN'), ('least', 'JJS'), ('one', 'CD'), ('historical', 'JJ'), ('time', 'NN'), ('historical', 'JJ'), ('date', 'NN'), ('smart', 'JJ'), ('tv', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('means', 'NNS'), ('restricting', 'VBG'), ('access', 'NN'), ('one', 'CD'), ('media', 'NNS'), ('programs', 'NNS'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('medium', 'NN'), ('comprising', 'VBG'), ('processor-executable', 'JJ'), ('program', 'NN'), ('code', 'NN'), ('configured', 'VBD'), ('cause', 'NN'), ('processor', 'NN'), ('smart', 'JJ'), ('television', 'NN'), ('tv', 'NN'), ('receive', 'VBP'), ('indication', 'NN'), ('upcoming', 'JJ'), ('media', 'NNS'), ('programming', 'VBG'), ('wherein', 'NN'), ('upcoming', 'JJ'), ('media', 'NNS'), ('programming', 'VBG'), ('based', 'VBN'), ('user', 'NN'), ('profile', 'NN'), ('identify', 'VB'), ('one', 'CD'), ('devices', 'NNS'), ('communication', 'NN'), ('smart', 'JJ'), ('tv', 'NN'), ('one', 'CD'), ('devices', 'NNS'), ('including', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('microphone', 'NN'), ('camera', 'NN'), ('instruct', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('identified', 'JJ'), ('device', 'NN'), ('detect', 'NN'), ('audio', 'NN'), ('signals', 'NNS'), ('using', 'VBG'), ('respective', 'JJ'), ('microphone', 'NN'), ('detect', 'JJ'), ('visual', 'JJ'), ('signals', 'NNS'), ('using', 'VBG'), ('respective', 'JJ'), ('camera', 'NN'), ('select', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('device', 'NN'), ('one', 'CD'), ('devices', 'NNS'), ('based', 'VBN'), ('detected', 'JJ'), ('audio', 'JJ'), ('signal', 'NN'), ('detected', 'VBD'), ('visual', 'JJ'), ('signal', 'NN'), ('provide', 'NN'), ('instructions', 'NNS'), ('selected', 'VBN'), ('device', 'NN'), ('output', 'NN'), ('notification', 'NN'), ('related', 'VBN'), ('upcoming', 'JJ'), ('media', 'NNS'), ('programming', 'VBG'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('medium', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('selecting', 'VBG'), ('first', 'JJ'), ('device', 'NN'), ('based', 'VBN'), ('detected', 'JJ'), ('audio', 'JJ'), ('signal', 'NN'), ('includes', 'VBZ'), ('recognizing', 'VBG'), ('voice', 'NN'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('medium', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('processor', 'NN'), ('capable', 'JJ'), ('executing', 'VBG'), ('processor-executable', 'JJ'), ('program', 'NN'), ('code', 'NN'), ('determine', 'NN'), ('distance', 'NN'), ('recognized', 'VBN'), ('voice', 'NN'), ('wherein', 'NN'), ('selecting', 'VBG'), ('first', 'JJ'), ('device', 'NN'), ('based', 'VBN'), ('determined', 'JJ'), ('distance', 'NN'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('medium', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('selecting', 'VBG'), ('first', 'JJ'), ('device', 'NN'), ('based', 'VBN'), ('detected', 'VBN'), ('visual', 'JJ'), ('signals', 'NNS'), ('includes', 'VBZ'), ('recognizing', 'VBG'), ('face', 'NN'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('medium', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('recognizing', 'VBG'), ('face', 'NN'), ('includes', 'VBZ'), ('face', 'JJ'), ('recognition', 'NN'), ('technique', 'NN'), ('camera', 'NN'), ('comprising', 'VBG'), ('sensor', 'JJ'), ('array', 'NN'), ('including', 'VBG'), ('plurality', 'NN'), ('sensors', 'NNS'), ('infrared', 'VBD'), ('ir', 'JJ'), ('illuminator', 'NN'), ('configured', 'VBD'), ('emit', 'RB'), ('active', 'JJ'), ('ir', 'NN'), ('light', 'JJ'), ('ir', 'JJ'), ('light', 'JJ'), ('sub-band', 'JJ'), ('plurality', 'NN'), ('spectral', 'JJ'), ('illuminators', 'NNS'), ('spectral', 'JJ'), ('illuminator', 'NN'), ('configured', 'VBD'), ('emit', 'RB'), ('active', 'JJ'), ('spectral', 'JJ'), ('light', 'NN'), ('different', 'JJ'), ('spectral', 'JJ'), ('light', 'NN'), ('sub-band', 'NN'), ('depth', 'NN'), ('controller', 'NN'), ('machine', 'NN'), ('configured', 'VBN'), ('determine', 'JJ'), ('depth', 'NN'), ('value', 'NN'), ('plurality', 'NN'), ('sensors', 'NNS'), ('based', 'VBN'), ('active', 'JJ'), ('ir', 'NN'), ('light', 'JJ'), ('spectral', 'JJ'), ('controller', 'NN'), ('machine', 'NN'), ('configured', 'VBN'), ('plurality', 'NN'), ('sensors', 'NNS'), ('determine', 'VBP'), ('spectral', 'JJ'), ('value', 'NN'), ('spectral', 'JJ'), ('light', 'JJ'), ('sub-band', 'JJ'), ('plurality', 'NN'), ('spectral', 'JJ'), ('illuminators', 'NNS'), ('output', 'NN'), ('machine', 'NN'), ('configured', 'VBN'), ('output', 'NN'), ('test', 'NN'), ('depth+multi-spectral', 'JJ'), ('image', 'NN'), ('including', 'VBG'), ('plurality', 'NN'), ('pixels', 'NNS'), ('pixel', 'VBP'), ('corresponding', 'VBG'), ('one', 'CD'), ('plurality', 'NN'), ('sensors', 'NNS'), ('sensor', 'VBP'), ('array', 'JJ'), ('including', 'VBG'), ('least', 'JJS'), ('depth', 'JJ'), ('value', 'NN'), ('spectral', 'JJ'), ('value', 'NN'), ('spectral', 'JJ'), ('light', 'JJ'), ('sub-band', 'JJ'), ('plurality', 'NN'), ('spectral', 'JJ'), ('illuminators', 'NNS'), ('face', 'VBP'), ('recognition', 'NN'), ('machine', 'NN'), ('previously', 'RB'), ('trained', 'VBN'), ('set', 'VBN'), ('labeled', 'JJ'), ('training', 'NN'), ('depth+multi-spectral', 'JJ'), ('images', 'NNS'), ('structure', 'NN'), ('test', 'NN'), ('depth+multi-spectral', 'JJ'), ('image', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('machine', 'NN'), ('configured', 'VBD'), ('output', 'NN'), ('confidence', 'NN'), ('value', 'NN'), ('indicating', 'VBG'), ('likelihood', 'JJ'), ('test', 'NN'), ('depth+multi-spectral', 'JJ'), ('image', 'NN'), ('includes', 'VBZ'), ('face', 'VBP'), ('camera', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('spectral', 'JJ'), ('value', 'NN'), ('calculated', 'VBD'), ('based', 'VBN'), ('depth', 'NN'), ('value', 'NN'), ('determined', 'VBD'), ('sensor', 'JJ'), ('corresponds', 'NNS'), ('pixel', 'JJ'), ('camera', 'NN'), ('claim', 'NN'), ('wherein', 'VBD'), ('face', 'NN'), ('recognition', 'NN'), ('machine', 'NN'), ('configured', 'VBN'), ('use', 'IN'), ('convolutional', 'JJ'), ('neural', 'JJ'), ('network', 'NN'), ('determine', 'NN'), ('confidence', 'NN'), ('value', 'NN'), ('camera', 'NN'), ('claim', 'NN'), ('wherein', 'VBD'), ('face', 'NN'), ('recognition', 'NN'), ('machine', 'NN'), ('includes', 'VBZ'), ('plurality', 'NN'), ('input', 'NN'), ('nodes', 'NNS'), ('wherein', 'VBP'), ('input', 'JJ'), ('node', 'RB'), ('configured', 'VBD'), ('receive', 'JJ'), ('pixel', 'NN'), ('value', 'NN'), ('array', 'NN'), ('corresponding', 'VBG'), ('different', 'JJ'), ('pixel', 'NN'), ('plurality', 'NN'), ('pixels', 'NNS'), ('test', 'VBP'), ('depth+multi-spectral', 'JJ'), ('image', 'NN'), ('wherein', 'NN'), ('pixel', 'VBZ'), ('value', 'NN'), ('array', 'NN'), ('includes', 'VBZ'), ('depth', 'IN'), ('value', 'NN'), ('plurality', 'NN'), ('multi-spectral', 'JJ'), ('values', 'NNS'), ('pixel', 'VBP'), ('camera', 'NN'), ('claim', 'NN'), ('wherein', 'JJ'), ('plurality', 'NN'), ('multi-spectral', 'JJ'), ('values', 'NNS'), ('pixel', 'VBP'), ('include', 'VBP'), ('three', 'CD'), ('spectral', 'JJ'), ('values', 'NNS'), ('camera', 'VBP'), ('claim', 'NN'), ('wherein', 'NN'), ('output', 'NN'), ('machine', 'NN'), ('configured', 'VBN'), ('output', 'NN'), ('surface', 'NN'), ('normal', 'JJ'), ('pixel', 'JJ'), ('test', 'NN'), ('depth+multi-spectral', 'JJ'), ('image', 'NN'), ('wherein', 'NN'), ('pixel', 'VBZ'), ('value', 'NN'), ('array', 'NN'), ('includes', 'VBZ'), ('surface', 'NN'), ('normal', 'JJ'), ('camera', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('output', 'NN'), ('machine', 'NN'), ('configured', 'VBN'), ('output', 'NN'), ('curvature', 'NN'), ('pixel', 'JJ'), ('test', 'NN'), ('depth+multi-spectral', 'JJ'), ('image', 'NN'), ('wherein', 'NN'), ('pixel', 'VBZ'), ('value', 'NN'), ('array', 'NN'), ('includes', 'VBZ'), ('curvature', 'NN'), ('camera', 'NN'), ('claim', 'NN'), ('wherein', 'VBD'), ('face', 'NN'), ('recognition', 'NN'), ('machine', 'NN'), ('configured', 'VBN'), ('use', 'NN'), ('plurality', 'NN'), ('models', 'NNS'), ('determine', 'VBP'), ('confidence', 'NN'), ('value', 'NN'), ('wherein', 'VBP'), ('plurality', 'NN'), ('models', 'NNS'), ('includes', 'VBZ'), ('plurality', 'NN'), ('channel-specific', 'JJ'), ('models', 'NNS'), ('wherein', 'IN'), ('channel-specific', 'JJ'), ('model', 'NN'), ('configured', 'VBD'), ('process', 'JJ'), ('different', 'JJ'), ('pixel', 'NN'), ('parameter', 'NN'), ('plurality', 'NN'), ('pixels', 'NNS'), ('test', 'VBP'), ('depth+multi-spectral', 'JJ'), ('image', 'NN'), ('wherein', 'VBD'), ('channel-specific', 'JJ'), ('model', 'NN'), ('includes', 'VBZ'), ('plurality', 'NN'), ('input', 'NN'), ('nodes', 'NNS'), ('wherein', 'VBP'), ('channel-specific', 'JJ'), ('model', 'NN'), ('input', 'NN'), ('node', 'RB'), ('configured', 'VBD'), ('receive', 'JJ'), ('pixel', 'NN'), ('parameter', 'NN'), ('value', 'NN'), ('different', 'JJ'), ('pixel', 'NN'), ('plurality', 'NN'), ('pixels', 'NNS'), ('test', 'VBP'), ('depth+multi-spectral', 'JJ'), ('image', 'NN'), ('camera', 'NN'), ('claim', 'NN'), ('wherein', 'VBD'), ('face', 'NN'), ('recognition', 'NN'), ('machine', 'NN'), ('configured', 'VBN'), ('use', 'RB'), ('statistical', 'JJ'), ('model', 'NN'), ('determine', 'NN'), ('confidence', 'NN'), ('value', 'NN'), ('camera', 'NN'), ('claim', 'NN'), ('wherein', 'VBD'), ('statistical', 'JJ'), ('model', 'NN'), ('includes', 'VBZ'), ('nearest', 'JJS'), ('neighbor', 'NN'), ('algorithm', 'NN'), ('camera', 'NN'), ('claim', 'NN'), ('wherein', 'VBD'), ('statistical', 'JJ'), ('model', 'NN'), ('includes', 'VBZ'), ('support', 'NN'), ('vector', 'NN'), ('machine', 'NN'), ('camera', 'NN'), ('claim', 'NN'), ('wherein', 'VBD'), ('face', 'NN'), ('recognition', 'NN'), ('machine', 'NN'), ('configured', 'VBD'), ('output', 'NN'), ('location', 'NN'), ('test', 'NN'), ('depth+multi-spectral', 'JJ'), ('image', 'NN'), ('bounding', 'VBG'), ('box', 'NN'), ('around', 'IN'), ('recognized', 'VBN'), ('face', 'NN'), ('camera', 'NN'), ('claim', 'NN'), ('wherein', 'VBD'), ('face', 'NN'), ('recognition', 'NN'), ('machine', 'NN'), ('configured', 'VBD'), ('output', 'NN'), ('location', 'NN'), ('test', 'NN'), ('depth+multi-spectral', 'JJ'), ('image', 'NN'), ('identified', 'VBD'), ('two-dimensional', 'JJ'), ('facial', 'JJ'), ('feature', 'NN'), ('recognized', 'VBN'), ('face', 'NN'), ('camera', 'NN'), ('claim', 'NN'), ('wherein', 'VBD'), ('face', 'NN'), ('recognition', 'NN'), ('machine', 'NN'), ('configured', 'VBD'), ('output', 'NN'), ('location', 'NN'), ('test', 'NN'), ('depth+multi-spectral', 'JJ'), ('image', 'NN'), ('identified', 'VBD'), ('three-dimensional', 'JJ'), ('facial', 'JJ'), ('feature', 'NN'), ('recognized', 'VBN'), ('face', 'NN'), ('camera', 'NN'), ('claim', 'NN'), ('wherein', 'VBD'), ('face', 'NN'), ('recognition', 'NN'), ('machine', 'NN'), ('configured', 'VBD'), ('output', 'NN'), ('location', 'NN'), ('test', 'NN'), ('depth+multi-spectral', 'JJ'), ('image', 'NN'), ('identified', 'VBN'), ('spectral', 'JJ'), ('feature', 'NN'), ('recognized', 'VBN'), ('face', 'NN'), ('camera', 'NN'), ('claim', 'NN'), ('wherein', 'VBD'), ('face', 'NN'), ('recognition', 'NN'), ('machine', 'NN'), ('configured', 'VBD'), ('output', 'NN'), ('pixel', 'JJ'), ('test', 'NN'), ('depth+multi-spectral', 'JJ'), ('image', 'NN'), ('confidence', 'NN'), ('value', 'NN'), ('indicating', 'VBG'), ('likelihood', 'NN'), ('pixel', 'NN'), ('included', 'VBD'), ('face', 'NN'), ('camera', 'NN'), ('claim', 'NN'), ('wherein', 'VBD'), ('face', 'NN'), ('recognition', 'NN'), ('machine', 'NN'), ('configured', 'VBD'), ('output', 'NN'), ('identity', 'NN'), ('face', 'NN'), ('recognized', 'VBN'), ('test', 'IN'), ('depth+multi-spectral', 'JJ'), ('image', 'NN'), ('camera', 'NN'), ('claim', 'NN'), ('wherein', 'VBP'), ('plurality', 'NN'), ('sensors', 'NNS'), ('sensor', 'VBP'), ('array', 'JJ'), ('differential', 'JJ'), ('sensors', 'NNS'), ('wherein', 'VBP'), ('spectral', 'JJ'), ('value', 'NN'), ('determined', 'VBD'), ('based', 'VBN'), ('depth', 'NN'), ('value', 'NN'), ('differential', 'JJ'), ('measurement', 'JJ'), ('differential', 'NN'), ('sensor', 'NN'), ('camera', 'NN'), ('comprising', 'VBG'), ('sensor', 'JJ'), ('array', 'NN'), ('including', 'VBG'), ('plurality', 'NN'), ('sensors', 'NNS'), ('infrared', 'VBD'), ('ir', 'JJ'), ('illuminator', 'NN'), ('configured', 'VBD'), ('emit', 'RB'), ('active', 'JJ'), ('ir', 'NN'), ('light', 'JJ'), ('ir', 'JJ'), ('light', 'JJ'), ('sub-band', 'JJ'), ('plurality', 'NN'), ('spectral', 'JJ'), ('illuminators', 'NNS'), ('spectral', 'JJ'), ('illuminator', 'NN'), ('configured', 'VBD'), ('emit', 'RB'), ('active', 'JJ'), ('spectral', 'JJ'), ('light', 'NN'), ('different', 'JJ'), ('spectral', 'JJ'), ('light', 'NN'), ('sub-band', 'NN'), ('depth', 'NN'), ('controller', 'NN'), ('machine', 'NN'), ('configured', 'VBN'), ('determine', 'JJ'), ('depth', 'NN'), ('value', 'NN'), ('plurality', 'NN'), ('sensors', 'NNS'), ('based', 'VBN'), ('active', 'JJ'), ('ir', 'NN'), ('light', 'JJ'), ('spectral', 'JJ'), ('controller', 'NN'), ('machine', 'NN'), ('configured', 'VBN'), ('plurality', 'NN'), ('sensors', 'NNS'), ('determine', 'VBP'), ('spectral', 'JJ'), ('value', 'NN'), ('spectral', 'JJ'), ('light', 'JJ'), ('sub-band', 'JJ'), ('plurality', 'NN'), ('spectral', 'JJ'), ('illuminators', 'NNS'), ('wherein', 'VBP'), ('spectral', 'JJ'), ('value', 'NN'), ('calculated', 'VBD'), ('based', 'VBN'), ('depth', 'NN'), ('value', 'NN'), ('determined', 'VBD'), ('sensor', 'JJ'), ('corresponds', 'NNS'), ('pixel', 'JJ'), ('output', 'NN'), ('machine', 'NN'), ('configured', 'VBN'), ('output', 'NN'), ('test', 'NN'), ('depth+multi-spectral', 'JJ'), ('image', 'NN'), ('including', 'VBG'), ('plurality', 'NN'), ('pixels', 'NNS'), ('pixel', 'VBP'), ('corresponding', 'VBG'), ('one', 'CD'), ('plurality', 'NN'), ('sensors', 'NNS'), ('sensor', 'VBP'), ('array', 'JJ'), ('including', 'VBG'), ('least', 'JJS'), ('depth', 'JJ'), ('value', 'NN'), ('spectral', 'JJ'), ('value', 'NN'), ('spectral', 'JJ'), ('light', 'JJ'), ('sub-band', 'JJ'), ('plurality', 'NN'), ('spectral', 'JJ'), ('illuminators', 'NNS'), ('face', 'VBP'), ('recognition', 'NN'), ('machine', 'NN'), ('including', 'VBG'), ('convolutional', 'JJ'), ('neural', 'JJ'), ('network', 'NN'), ('previously', 'RB'), ('trained', 'VBN'), ('set', 'VBN'), ('labeled', 'JJ'), ('training', 'NN'), ('depth+multi-spectral', 'JJ'), ('images', 'NNS'), ('structure', 'NN'), ('test', 'NN'), ('depth+multi-spectral', 'JJ'), ('image', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('machine', 'NN'), ('configured', 'VBD'), ('output', 'NN'), ('confidence', 'NN'), ('value', 'NN'), ('indicating', 'VBG'), ('likelihood', 'JJ'), ('test', 'NN'), ('depth+multi-spectral', 'JJ'), ('image', 'NN'), ('includes', 'VBZ'), ('face', 'VBP'), ('image', 'NN'), ('processing', 'NN'), ('method', 'NN'), ('comprising', 'VBG'), ('acquiring', 'VBG'), ('photo', 'NN'), ('album', 'NN'), ('obtained', 'VBD'), ('face', 'NN'), ('clustering', 'VBG'), ('collecting', 'VBG'), ('face', 'NN'), ('information', 'NN'), ('respective', 'JJ'), ('images', 'NNS'), ('photo', 'VBP'), ('album', 'IN'), ('acquiring', 'VBG'), ('face', 'NN'), ('parameter', 'NN'), ('image', 'NN'), ('according', 'VBG'), ('face', 'NN'), ('information', 'NN'), ('selecting', 'VBG'), ('cover', 'NN'), ('image', 'NN'), ('according', 'VBG'), ('face', 'NN'), ('parameter', 'NN'), ('image', 'NN'), ('taking', 'VBG'), ('face-region', 'JJ'), ('image', 'NN'), ('cover', 'NN'), ('image', 'NN'), ('setting', 'VBG'), ('face-region', 'JJ'), ('image', 'NN'), ('cover', 'NN'), ('photo', 'NN'), ('album', 'JJ'), ('wherein', 'NN'), ('selecting', 'VBG'), ('cover', 'NN'), ('image', 'NN'), ('according', 'VBG'), ('face', 'NN'), ('parameter', 'NN'), ('image', 'NN'), ('comprises', 'VBZ'), ('performing', 'VBG'), ('calculation', 'NN'), ('face', 'NN'), ('parameter', 'NN'), ('image', 'NN'), ('preset', 'VB'), ('way', 'NN'), ('obtain', 'VB'), ('cover', 'NN'), ('score', 'NN'), ('image', 'NN'), ('selecting', 'VBG'), ('image', 'NN'), ('highest', 'JJS'), ('cover', 'NN'), ('score', 'NN'), ('cover', 'JJ'), ('image', 'NN'), ('wherein', 'VBD'), ('selecting', 'VBG'), ('image', 'NN'), ('highest', 'JJS'), ('cover', 'NN'), ('score', 'NN'), ('cover', 'JJ'), ('image', 'NN'), ('comprises', 'VBZ'), ('acquiring', 'VBG'), ('source', 'NN'), ('image', 'NN'), ('selecting', 'VBG'), ('image', 'NN'), ('highest', 'JJS'), ('cover', 'NN'), ('score', 'NN'), ('images', 'NNS'), ('coming', 'VBG'), ('preset', 'NN'), ('source', 'NN'), ('cover', 'NN'), ('image', 'NN'), ('method', 'JJ'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('selecting', 'VBG'), ('image', 'NN'), ('highest', 'JJS'), ('cover', 'NN'), ('score', 'NN'), ('cover', 'JJ'), ('image', 'NN'), ('comprises', 'VBZ'), ('acquiring', 'VBG'), ('number', 'NN'), ('faces', 'VBZ'), ('contained', 'VBN'), ('image', 'NN'), ('determining', 'VBG'), ('single-person', 'JJ'), ('images', 'NNS'), ('according', 'VBG'), ('number', 'NN'), ('faces', 'VBZ'), ('selecting', 'VBG'), ('single-person', 'JJ'), ('image', 'NN'), ('highest', 'JJS'), ('cover', 'NN'), ('score', 'NN'), ('cover', 'JJ'), ('image', 'NN'), ('method', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('selecting', 'VBG'), ('image', 'NN'), ('highest', 'JJS'), ('cover', 'NN'), ('score', 'NN'), ('cover', 'JJ'), ('image', 'NN'), ('comprises', 'VBZ'), ('single-person', 'JJ'), ('image', 'NN'), ('photo', 'NN'), ('album', 'IN'), ('determining', 'VBG'), ('images', 'NNS'), ('including', 'VBG'), ('two', 'CD'), ('faces', 'VBZ'), ('photo', 'NN'), ('album', 'NN'), ('selecting', 'VBG'), ('image', 'NN'), ('highest', 'JJS'), ('cover', 'NN'), ('score', 'NN'), ('images', 'NNS'), ('including', 'VBG'), ('two', 'CD'), ('faces', 'VBZ'), ('cover', 'RB'), ('image', 'NN'), ('method', 'JJ'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('face', 'NN'), ('information', 'NN'), ('comprises', 'VBZ'), ('face', 'NN'), ('feature', 'NN'), ('points', 'NNS'), ('face', 'VBP'), ('parameter', 'NN'), ('comprises', 'NNS'), ('face', 'VBP'), ('turning', 'VBG'), ('angle', 'RP'), ('acquiring', 'VBG'), ('face', 'NN'), ('parameter', 'NN'), ('image', 'NN'), ('according', 'VBG'), ('face', 'NN'), ('information', 'NN'), ('comprises', 'VBZ'), ('acquiring', 'VBG'), ('coordinate', 'NN'), ('values', 'NNS'), ('face', 'VBP'), ('feature', 'NN'), ('points', 'NNS'), ('determining', 'VBG'), ('distances', 'NNS'), ('angles', 'NNS'), ('face', 'VBP'), ('feature', 'NN'), ('points', 'NNS'), ('determining', 'VBG'), ('face', 'NN'), ('turning', 'VBG'), ('angle', 'RP'), ('according', 'VBG'), ('distances', 'NNS'), ('angles', 'NNS'), ('method', 'VBP'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('face', 'NN'), ('parameter', 'NN'), ('comprises', 'VBZ'), ('face', 'VBP'), ('ratio', 'NN'), ('acquiring', 'VBG'), ('face', 'NN'), ('parameter', 'NN'), ('image', 'NN'), ('according', 'VBG'), ('face', 'NN'), ('information', 'NN'), ('comprises', 'VBZ'), ('determining', 'VBG'), ('face', 'NN'), ('region', 'NN'), ('image', 'NN'), ('according', 'VBG'), ('face', 'NN'), ('information', 'NN'), ('calculating', 'VBG'), ('ratio', 'NN'), ('area', 'NN'), ('face', 'NN'), ('region', 'NN'), ('area', 'NN'), ('image', 'NN'), ('obtain', 'VB'), ('face', 'NN'), ('ratio', 'NN'), ('method', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('calculating', 'VBG'), ('face', 'NN'), ('ratio', 'NN'), ('comprises', 'VBZ'), ('one', 'CD'), ('face', 'NN'), ('image', 'NN'), ('subtracting', 'VBG'), ('area', 'NN'), ('occupied', 'VBD'), ('faces', 'VBZ'), ('face', 'NN'), ('corresponding', 'VBG'), ('photo', 'NN'), ('album', 'NN'), ('face', 'NN'), ('region', 'NN'), ('obtain', 'VB'), ('remaining', 'VBG'), ('area', 'NN'), ('calculating', 'VBG'), ('ratio', 'NN'), ('remaining', 'VBG'), ('area', 'NN'), ('area', 'NN'), ('image', 'NN'), ('obtain', 'VB'), ('face', 'NN'), ('ratio', 'NN'), ('method', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('collecting', 'VBG'), ('face', 'NN'), ('information', 'NN'), ('respective', 'JJ'), ('images', 'NNS'), ('photo', 'VBP'), ('album', 'JJ'), ('comprises', 'NNS'), ('acquiring', 'VBG'), ('image', 'NN'), ('identifications', 'NNS'), ('images', 'VBZ'), ('photo', 'NN'), ('album', 'NN'), ('extracting', 'VBG'), ('face', 'NN'), ('information', 'NN'), ('corresponding', 'VBG'), ('image', 'NN'), ('identifications', 'NNS'), ('face', 'VBP'), ('database', 'JJ'), ('face', 'NN'), ('database', 'NN'), ('stored', 'VBD'), ('face', 'NN'), ('recognition', 'NN'), ('results', 'NNS'), ('images', 'NNS'), ('face', 'VBP'), ('recognition', 'NN'), ('results', 'NNS'), ('including', 'VBG'), ('face', 'NN'), ('information', 'NN'), ('image', 'NN'), ('processing', 'NN'), ('apparatus', 'NN'), ('comprising', 'VBG'), ('processor', 'JJ'), ('memory', 'NN'), ('configured', 'VBD'), ('store', 'NN'), ('instructions', 'NNS'), ('executable', 'JJ'), ('processor', 'NN'), ('wherein', 'NN'), ('processor', 'NN'), ('configured', 'VBD'), ('run', 'VBN'), ('program', 'NN'), ('corresponding', 'NN'), ('instructions', 'NNS'), ('reading', 'VBG'), ('instructions', 'NNS'), ('stored', 'VBD'), ('memory', 'NN'), ('perform', 'NN'), ('acquiring', 'VBG'), ('photo', 'NN'), ('album', 'NN'), ('obtained', 'VBD'), ('face', 'NN'), ('clustering', 'VBG'), ('collecting', 'VBG'), ('face', 'NN'), ('information', 'NN'), ('image', 'NN'), ('photo', 'NN'), ('album', 'IN'), ('acquiring', 'VBG'), ('face', 'NN'), ('parameter', 'NN'), ('image', 'NN'), ('according', 'VBG'), ('face', 'NN'), ('information', 'NN'), ('selecting', 'VBG'), ('cover', 'NN'), ('image', 'NN'), ('according', 'VBG'), ('face', 'NN'), ('parameter', 'NN'), ('image', 'NN'), ('taking', 'VBG'), ('face-region', 'JJ'), ('image', 'NN'), ('cover', 'NN'), ('image', 'NN'), ('setting', 'VBG'), ('face-region', 'JJ'), ('image', 'NN'), ('cover', 'NN'), ('photo', 'NN'), ('album', 'JJ'), ('wherein', 'NN'), ('processor', 'NN'), ('configured', 'VBD'), ('perform', 'JJ'), ('calculation', 'NN'), ('face', 'NN'), ('parameter', 'NN'), ('image', 'NN'), ('preset', 'VB'), ('way', 'NN'), ('obtain', 'VB'), ('cover', 'NN'), ('score', 'NN'), ('image', 'NN'), ('select', 'JJ'), ('image', 'NN'), ('highest', 'JJS'), ('cover', 'NN'), ('score', 'NN'), ('cover', 'JJ'), ('image', 'NN'), ('wherein', 'NN'), ('processor', 'NN'), ('configured', 'VBD'), ('acquire', 'VB'), ('source', 'NN'), ('image', 'NN'), ('select', 'JJ'), ('image', 'NN'), ('highest', 'JJS'), ('cover', 'NN'), ('score', 'NN'), ('images', 'NNS'), ('coming', 'VBG'), ('preset', 'NN'), ('source', 'NN'), ('cover', 'NN'), ('image', 'NN'), ('apparatus', 'JJ'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('processor', 'NN'), ('configured', 'VBD'), ('acquire', 'VB'), ('number', 'NN'), ('faces', 'VBZ'), ('contained', 'VBN'), ('image', 'NN'), ('determine', 'JJ'), ('single-person', 'JJ'), ('images', 'NNS'), ('according', 'VBG'), ('number', 'NN'), ('faces', 'VBZ'), ('select', 'JJ'), ('single-person', 'JJ'), ('image', 'NN'), ('highest', 'JJS'), ('cover', 'NN'), ('score', 'NN'), ('cover', 'JJ'), ('image', 'NN'), ('apparatus', 'JJ'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('processor', 'NN'), ('configured', 'VBD'), ('single-person', 'JJ'), ('image', 'NN'), ('photo', 'NN'), ('album', 'JJ'), ('determine', 'NN'), ('images', 'NNS'), ('including', 'VBG'), ('two', 'CD'), ('faces', 'VBZ'), ('photo', 'NN'), ('album', 'NN'), ('select', 'JJ'), ('image', 'NN'), ('highest', 'JJS'), ('cover', 'NN'), ('score', 'NN'), ('images', 'NNS'), ('including', 'VBG'), ('two', 'CD'), ('faces', 'VBZ'), ('cover', 'RB'), ('image', 'NN'), ('apparatus', 'JJ'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('face', 'NN'), ('information', 'NN'), ('comprises', 'VBZ'), ('face', 'NN'), ('feature', 'NN'), ('points', 'NNS'), ('face', 'VBP'), ('parameter', 'NN'), ('comprises', 'NNS'), ('face', 'VBP'), ('turning', 'VBG'), ('angle', 'NN'), ('processor', 'NN'), ('configured', 'VBD'), ('acquire', 'VB'), ('coordinate', 'NN'), ('values', 'NNS'), ('face', 'VBP'), ('feature', 'NN'), ('points', 'NNS'), ('determine', 'JJ'), ('distances', 'NNS'), ('angles', 'NNS'), ('face', 'VBP'), ('feature', 'NN'), ('points', 'NNS'), ('determine', 'JJ'), ('face', 'NN'), ('turning', 'VBG'), ('angle', 'RP'), ('according', 'VBG'), ('distances', 'NNS'), ('angles', 'NNS'), ('apparatus', 'VBP'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('face', 'NN'), ('parameter', 'NN'), ('comprises', 'VBZ'), ('face', 'VBP'), ('ratio', 'NN'), ('processor', 'NN'), ('configured', 'VBD'), ('determine', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('image', 'NN'), ('according', 'VBG'), ('face', 'NN'), ('information', 'NN'), ('calculate', 'NN'), ('ratio', 'NN'), ('area', 'NN'), ('face', 'NN'), ('region', 'NN'), ('area', 'NN'), ('image', 'NN'), ('obtain', 'VB'), ('face', 'NN'), ('ratio', 'NN'), ('apparatus', 'IN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('processor', 'NN'), ('configured', 'VBD'), ('one', 'CD'), ('face', 'NN'), ('image', 'NN'), ('subtract', 'JJ'), ('area', 'NN'), ('occupied', 'VBD'), ('faces', 'VBZ'), ('face', 'NN'), ('corresponding', 'VBG'), ('photo', 'NN'), ('album', 'NN'), ('face', 'NN'), ('region', 'NN'), ('obtain', 'VB'), ('remaining', 'VBG'), ('area', 'NN'), ('calculate', 'NN'), ('ratio', 'NN'), ('remaining', 'VBG'), ('area', 'NN'), ('area', 'NN'), ('image', 'NN'), ('obtain', 'VB'), ('face', 'NN'), ('ratio', 'NN'), ('apparatus', 'IN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('processor', 'NN'), ('configured', 'VBD'), ('acquire', 'VB'), ('image', 'NN'), ('identifications', 'NNS'), ('images', 'VBZ'), ('photo', 'NN'), ('album', 'NN'), ('extract', 'JJ'), ('face', 'NN'), ('information', 'NN'), ('corresponding', 'VBG'), ('image', 'NN'), ('identifications', 'NNS'), ('face', 'VBP'), ('database', 'JJ'), ('face', 'NN'), ('database', 'NN'), ('stored', 'VBD'), ('face', 'NN'), ('recognition', 'NN'), ('results', 'NNS'), ('images', 'NNS'), ('face', 'VBP'), ('recognition', 'NN'), ('results', 'NNS'), ('including', 'VBG'), ('face', 'NN'), ('information', 'NN'), ('electronic', 'JJ'), ('device', 'NN'), ('comprising', 'VBG'), ('processor', 'JJ'), ('memory', 'NN'), ('display', 'NN'), ('screen', 'NN'), ('input', 'NN'), ('device', 'NN'), ('connected', 'VBN'), ('via', 'IN'), ('system', 'NN'), ('bus', 'JJ'), ('wherein', 'JJ'), ('memory', 'NN'), ('stored', 'VBN'), ('computer', 'NN'), ('programs', 'NNS'), ('executed', 'VBD'), ('processor', 'NN'), ('cause', 'NN'), ('processor', 'NN'), ('implement', 'JJ'), ('image', 'NN'), ('processing', 'NN'), ('method', 'JJ'), ('image', 'NN'), ('processing', 'NN'), ('method', 'NN'), ('comprising', 'VBG'), ('acquiring', 'VBG'), ('photo', 'NN'), ('album', 'NN'), ('obtained', 'VBD'), ('face', 'NN'), ('clustering', 'VBG'), ('collecting', 'VBG'), ('face', 'NN'), ('information', 'NN'), ('respective', 'JJ'), ('images', 'NNS'), ('photo', 'VBP'), ('album', 'IN'), ('acquiring', 'VBG'), ('face', 'NN'), ('parameter', 'NN'), ('image', 'NN'), ('according', 'VBG'), ('face', 'NN'), ('information', 'NN'), ('selecting', 'VBG'), ('cover', 'NN'), ('image', 'NN'), ('according', 'VBG'), ('face', 'NN'), ('parameter', 'NN'), ('image', 'NN'), ('taking', 'VBG'), ('face-region', 'JJ'), ('image', 'NN'), ('cover', 'NN'), ('image', 'NN'), ('setting', 'VBG'), ('face-region', 'JJ'), ('image', 'NN'), ('cover', 'NN'), ('photo', 'NN'), ('album', 'JJ'), ('wherein', 'NN'), ('selecting', 'VBG'), ('cover', 'NN'), ('image', 'NN'), ('according', 'VBG'), ('face', 'NN'), ('parameter', 'NN'), ('image', 'NN'), ('comprises', 'VBZ'), ('performing', 'VBG'), ('calculation', 'NN'), ('face', 'NN'), ('parameter', 'NN'), ('image', 'NN'), ('preset', 'VB'), ('way', 'NN'), ('obtain', 'VB'), ('cover', 'NN'), ('score', 'NN'), ('image', 'NN'), ('selecting', 'VBG'), ('image', 'NN'), ('highest', 'JJS'), ('cover', 'NN'), ('score', 'NN'), ('cover', 'JJ'), ('image', 'NN'), ('wherein', 'VBD'), ('selecting', 'VBG'), ('image', 'NN'), ('highest', 'JJS'), ('cover', 'NN'), ('score', 'NN'), ('cover', 'JJ'), ('image', 'NN'), ('comprises', 'VBZ'), ('acquiring', 'VBG'), ('source', 'NN'), ('image', 'NN'), ('selecting', 'VBG'), ('image', 'NN'), ('highest', 'JJS'), ('cover', 'NN'), ('score', 'NN'), ('images', 'NNS'), ('coming', 'VBG'), ('preset', 'NN'), ('source', 'NN'), ('cover', 'NN'), ('image', 'NN'), ('electronic', 'JJ'), ('device', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('electronic', 'JJ'), ('device', 'NN'), ('comprises', 'NNS'), ('least', 'VBP'), ('one', 'CD'), ('mobile', 'JJ'), ('phone', 'NN'), ('tablet', 'NN'), ('computer', 'NN'), ('personal', 'JJ'), ('digital', 'NN'), ('assistant', 'NN'), ('wearable', 'JJ'), ('device', 'NN'), ('computer-implemented', 'JJ'), ('method', 'NN'), ('comprising', 'VBG'), ('receiving', 'VBG'), ('computing', 'VBG'), ('device', 'NN'), ('meeting', 'NN'), ('invitation', 'NN'), ('identifying', 'VBG'), ('location', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('meeting', 'NN'), ('invitation', 'NN'), ('configured', 'VBD'), ('provide', 'IN'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('physical', 'JJ'), ('access', 'NN'), ('location', 'NN'), ('wherein', 'NN'), ('meeting', 'NN'), ('invitation', 'NN'), ('causes', 'VBZ'), ('system', 'NN'), ('control', 'NN'), ('pathway', 'RB'), ('allowing', 'VBG'), ('physical', 'JJ'), ('access', 'NN'), ('location', 'NN'), ('providing', 'VBG'), ('based', 'VBN'), ('meeting', 'VBG'), ('invitation', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('physical', 'JJ'), ('access', 'NN'), ('location', 'NN'), ('controlling', 'VBG'), ('pathway', 'RB'), ('allowing', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('physically', 'RB'), ('access', 'NN'), ('location', 'NN'), ('pathway', 'NN'), ('response', 'NN'), ('positioning', 'VBG'), ('data', 'NNS'), ('indicating', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('predetermined', 'VBN'), ('location', 'NN'), ('near', 'IN'), ('location', 'NN'), ('wherein', 'NN'), ('positioning', 'VBG'), ('data', 'NNS'), ('based', 'VBN'), ('part', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('camera', 'NN'), ('system', 'NN'), ('identifying', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('receiving', 'VBG'), ('positioning', 'VBG'), ('data', 'NNS'), ('face', 'NN'), ('recognition', 'NN'), ('camera', 'NN'), ('system', 'NN'), ('identifying', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('wherein', 'NN'), ('positioning', 'VBG'), ('data', 'NNS'), ('indicates', 'VBZ'), ('pattern', 'JJ'), ('movement', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('determining', 'VBG'), ('pattern', 'JJ'), ('movement', 'NN'), ('indicates', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('exited', 'VBN'), ('location', 'NN'), ('revoking', 'VBG'), ('physical', 'JJ'), ('access', 'NN'), ('location', 'NN'), ('identified', 'VBD'), ('meeting', 'VBG'), ('invitation', 'NN'), ('controlling', 'VBG'), ('pathway', 'RB'), ('restrict', 'VB'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('identified', 'VBD'), ('meeting', 'VBG'), ('invitation', 'NN'), ('physical', 'JJ'), ('access', 'NN'), ('location', 'NN'), ('pathway', 'NN'), ('response', 'NN'), ('determining', 'VBG'), ('pattern', 'JJ'), ('movement', 'NN'), ('indicates', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('exited', 'VBN'), ('location', 'NN'), ('computer-implemented', 'JJ'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('determining', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('exited', 'VBN'), ('location', 'NN'), ('comprises', 'VBZ'), ('determining', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('passed', 'VBD'), ('egress', 'RB'), ('associated', 'VBN'), ('location', 'NN'), ('predetermined', 'VBN'), ('direction', 'NN'), ('computer-implemented', 'JJ'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('determining', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('exited', 'VBN'), ('location', 'NN'), ('comprises', 'VBZ'), ('determining', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('moved', 'VBD'), ('area', 'NN'), ('predetermined', 'VBN'), ('direction', 'NN'), ('computer-implemented', 'JJ'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('positioning', 'VBG'), ('data', 'NNS'), ('indicates', 'VBZ'), ('second', 'JJ'), ('pattern', 'JJ'), ('movement', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('wherein', 'NN'), ('access', 'NN'), ('secured', 'VBN'), ('data', 'NNS'), ('associated', 'VBN'), ('location', 'NN'), ('provided', 'VBN'), ('response', 'NN'), ('detecting', 'VBG'), ('second', 'JJ'), ('pattern', 'JJ'), ('movement', 'NN'), ('computer-implemented', 'JJ'), ('method', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('collating', 'VBG'), ('secured', 'VBN'), ('data', 'NNS'), ('public', 'JJ'), ('data', 'NNS'), ('generate', 'VBP'), ('resource', 'NN'), ('data', 'NNS'), ('communicating', 'VBG'), ('resource', 'NN'), ('data', 'NNS'), ('client', 'NN'), ('computing', 'VBG'), ('device', 'NN'), ('associated', 'VBN'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('access', 'NN'), ('location', 'NN'), ('provided', 'VBD'), ('computer-implemented', 'JJ'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('positioning', 'VBG'), ('data', 'NNS'), ('indicates', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('predetermined', 'VBN'), ('location', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('passes', 'NNS'), ('predetermined', 'VBD'), ('location', 'NN'), ('computer-implemented', 'JJ'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('positioning', 'VBG'), ('data', 'NNS'), ('indicates', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('predetermined', 'VBN'), ('location', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('passes', 'NNS'), ('predetermined', 'VBD'), ('location', 'NN'), ('near', 'IN'), ('location', 'NN'), ('predetermined', 'VBN'), ('direction', 'NN'), ('system', 'NN'), ('comprising', 'VBG'), ('processor', 'JJ'), ('memory', 'NN'), ('communication', 'NN'), ('processor', 'NN'), ('memory', 'NN'), ('computer-readable', 'JJ'), ('instructions', 'NNS'), ('stored', 'VBD'), ('thereupon', 'RB'), ('executed', 'VBN'), ('processor', 'NN'), ('cause', 'NN'), ('processor', 'NN'), ('receive', 'VBP'), ('meeting', 'NN'), ('invitation', 'NN'), ('indicating', 'VBG'), ('location', 'NN'), ('identity', 'NN'), ('meeting', 'NN'), ('invitation', 'NN'), ('configured', 'VBD'), ('provide', 'IN'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('physical', 'JJ'), ('access', 'NN'), ('location', 'NN'), ('wherein', 'NN'), ('meeting', 'NN'), ('invitation', 'NN'), ('causes', 'VBZ'), ('system', 'NN'), ('control', 'NN'), ('pathway', 'RB'), ('allowing', 'VBG'), ('physical', 'JJ'), ('access', 'NN'), ('location', 'NN'), ('provide', 'IN'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('associated', 'VBN'), ('identity', 'NN'), ('access', 'NN'), ('location', 'NN'), ('controlling', 'VBG'), ('pathway', 'RB'), ('allowing', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('physically', 'RB'), ('access', 'NN'), ('location', 'NN'), ('pathway', 'NN'), ('response', 'NN'), ('positioning', 'VBG'), ('data', 'NNS'), ('indicating', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('predetermined', 'VBN'), ('location', 'NN'), ('near', 'IN'), ('location', 'NN'), ('wherein', 'NN'), ('positioning', 'VBG'), ('data', 'NNS'), ('based', 'VBN'), ('part', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('camera', 'NN'), ('system', 'NN'), ('identifying', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('receive', 'VBP'), ('positioning', 'VBG'), ('data', 'NNS'), ('face', 'NN'), ('recognition', 'NN'), ('camera', 'NN'), ('system', 'NN'), ('identifying', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('wherein', 'NN'), ('positioning', 'VBG'), ('data', 'NNS'), ('indicates', 'VBZ'), ('pattern', 'JJ'), ('movement', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('determine', 'NN'), ('pattern', 'JJ'), ('movement', 'NN'), ('indicates', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('exited', 'VBN'), ('location', 'NN'), ('revoke', 'VBD'), ('physical', 'JJ'), ('access', 'NN'), ('location', 'NN'), ('identified', 'VBD'), ('meeting', 'VBG'), ('invitation', 'NN'), ('controlling', 'VBG'), ('pathway', 'RB'), ('restrict', 'VB'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('identified', 'VBD'), ('meeting', 'VBG'), ('invitation', 'NN'), ('physical', 'JJ'), ('access', 'NN'), ('location', 'NN'), ('pathway', 'NN'), ('response', 'NN'), ('determining', 'VBG'), ('pattern', 'JJ'), ('movement', 'NN'), ('indicates', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('exited', 'VBN'), ('location', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('determining', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('exited', 'VBN'), ('location', 'NN'), ('comprises', 'VBZ'), ('determining', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('passed', 'VBD'), ('egress', 'RB'), ('associated', 'VBN'), ('location', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('determining', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('exited', 'VBN'), ('location', 'NN'), ('comprises', 'VBZ'), ('determining', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('moved', 'VBD'), ('area', 'NN'), ('predetermined', 'VBN'), ('direction', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('positioning', 'VBG'), ('data', 'NNS'), ('indicates', 'VBZ'), ('second', 'JJ'), ('pattern', 'JJ'), ('movement', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('wherein', 'NN'), ('access', 'NN'), ('secured', 'VBN'), ('data', 'NNS'), ('associated', 'VBN'), ('location', 'NN'), ('provided', 'VBN'), ('response', 'NN'), ('detecting', 'VBG'), ('second', 'JJ'), ('pattern', 'JJ'), ('movement', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('instructions', 'NNS'), ('cause', 'VBP'), ('processor', 'NN'), ('collate', 'NN'), ('secured', 'VBN'), ('data', 'NNS'), ('public', 'JJ'), ('data', 'NNS'), ('generate', 'VBP'), ('resource', 'NN'), ('data', 'NNS'), ('communicate', 'VBP'), ('resource', 'NN'), ('data', 'NNS'), ('client', 'NN'), ('computing', 'VBG'), ('device', 'NN'), ('associated', 'VBN'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('access', 'NN'), ('location', 'NN'), ('provided', 'VBD'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('storage', 'NN'), ('medium', 'NN'), ('computer-executable', 'JJ'), ('instructions', 'NNS'), ('stored', 'VBD'), ('thereupon', 'RB'), ('executed', 'VBN'), ('one', 'CD'), ('processors', 'NNS'), ('computing', 'VBG'), ('device', 'NN'), ('cause', 'NN'), ('one', 'CD'), ('processors', 'NNS'), ('computing', 'VBG'), ('device', 'NN'), ('receive', 'VBP'), ('meeting', 'NN'), ('invitation', 'NN'), ('indicating', 'VBG'), ('location', 'NN'), ('identity', 'NN'), ('meeting', 'NN'), ('invitation', 'NN'), ('configured', 'VBD'), ('provide', 'IN'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('physical', 'JJ'), ('access', 'NN'), ('location', 'NN'), ('wherein', 'NN'), ('meeting', 'NN'), ('invitation', 'NN'), ('causes', 'VBZ'), ('system', 'NN'), ('control', 'NN'), ('pathway', 'RB'), ('allowing', 'VBG'), ('physical', 'JJ'), ('access', 'NN'), ('location', 'NN'), ('provide', 'IN'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('associated', 'VBN'), ('identity', 'NN'), ('access', 'NN'), ('location', 'NN'), ('controlling', 'VBG'), ('pathway', 'RB'), ('allowing', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('physically', 'RB'), ('access', 'NN'), ('location', 'NN'), ('pathway', 'NN'), ('response', 'NN'), ('positioning', 'VBG'), ('data', 'NNS'), ('indicating', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('predetermined', 'VBN'), ('location', 'NN'), ('near', 'IN'), ('location', 'NN'), ('wherein', 'NN'), ('positioning', 'VBG'), ('data', 'NNS'), ('based', 'VBN'), ('part', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('camera', 'NN'), ('system', 'NN'), ('identifying', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('receive', 'VBP'), ('positioning', 'VBG'), ('data', 'NNS'), ('face', 'NN'), ('recognition', 'NN'), ('camera', 'NN'), ('system', 'NN'), ('identifying', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('wherein', 'NN'), ('positioning', 'VBG'), ('data', 'NNS'), ('indicates', 'VBZ'), ('pattern', 'JJ'), ('movement', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('determine', 'NN'), ('pattern', 'JJ'), ('movement', 'NN'), ('indicates', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('exited', 'VBN'), ('location', 'NN'), ('revoke', 'VBD'), ('physical', 'JJ'), ('access', 'NN'), ('location', 'NN'), ('identified', 'VBD'), ('meeting', 'VBG'), ('invitation', 'NN'), ('controlling', 'VBG'), ('pathway', 'RB'), ('restrict', 'VB'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('identified', 'VBD'), ('meeting', 'VBG'), ('invitation', 'NN'), ('physical', 'JJ'), ('access', 'NN'), ('location', 'NN'), ('pathway', 'NN'), ('response', 'NN'), ('determining', 'VBG'), ('pattern', 'JJ'), ('movement', 'NN'), ('indicates', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('exited', 'VBN'), ('location', 'NN'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('storage', 'NN'), ('medium', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('determining', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('exited', 'VBN'), ('location', 'NN'), ('comprises', 'VBZ'), ('determining', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('passed', 'VBD'), ('egress', 'RB'), ('associated', 'VBN'), ('location', 'NN'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('storage', 'NN'), ('medium', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('positioning', 'VBG'), ('data', 'NNS'), ('indicates', 'VBZ'), ('second', 'JJ'), ('pattern', 'JJ'), ('movement', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('wherein', 'NN'), ('access', 'NN'), ('secured', 'VBN'), ('data', 'NNS'), ('associated', 'VBN'), ('location', 'NN'), ('provided', 'VBN'), ('response', 'NN'), ('detecting', 'VBG'), ('second', 'JJ'), ('pattern', 'JJ'), ('movement', 'NN'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('storage', 'NN'), ('medium', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('instructions', 'NNS'), ('cause', 'VBP'), ('one', 'CD'), ('processors', 'NNS'), ('collate', 'VBP'), ('secured', 'VBN'), ('data', 'NNS'), ('public', 'JJ'), ('data', 'NNS'), ('generate', 'VBP'), ('resource', 'NN'), ('data', 'NNS'), ('communicate', 'VBP'), ('resource', 'NN'), ('data', 'NNS'), ('client', 'NN'), ('computing', 'VBG'), ('device', 'NN'), ('associated', 'VBN'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('access', 'NN'), ('location', 'NN'), ('provided', 'VBD'), ('method', 'NN'), ('comprising', 'VBG'), ('receiving', 'VBG'), ('piece', 'NN'), ('content', 'JJ'), ('salient', 'NN'), ('data', 'NNS'), ('piece', 'NN'), ('content', 'NN'), ('based', 'VBN'), ('salient', 'JJ'), ('data', 'NNS'), ('determining', 'VBG'), ('first', 'JJ'), ('path', 'NN'), ('viewport', 'NN'), ('piece', 'NN'), ('content', 'NN'), ('wherein', 'NN'), ('first', 'JJ'), ('path', 'NN'), ('viewport', 'NN'), ('includes', 'VBZ'), ('different', 'JJ'), ('salient', 'JJ'), ('events', 'NNS'), ('occurring', 'VBG'), ('piece', 'NN'), ('content', 'NN'), ('different', 'JJ'), ('times', 'NNS'), ('playback', 'VBP'), ('piece', 'NN'), ('content', 'NN'), ('providing', 'VBG'), ('viewport', 'NN'), ('display', 'NN'), ('device', 'NN'), ('wherein', 'VBD'), ('movement', 'NN'), ('viewport', 'NN'), ('based', 'VBN'), ('first', 'JJ'), ('path', 'NN'), ('viewport', 'NN'), ('salient', 'NN'), ('data', 'NNS'), ('playback', 'NN'), ('detecting', 'VBG'), ('additional', 'JJ'), ('salient', 'NN'), ('event', 'NN'), ('piece', 'NN'), ('content', 'NN'), ('included', 'VBD'), ('first', 'JJ'), ('path', 'NN'), ('viewport', 'NN'), ('providing', 'VBG'), ('indication', 'JJ'), ('additional', 'JJ'), ('salient', 'NN'), ('event', 'NN'), ('viewport', 'NN'), ('playback', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'VBP'), ('salient', 'NN'), ('data', 'NNS'), ('identifies', 'NNS'), ('salient', 'JJ'), ('event', 'NN'), ('piece', 'NN'), ('content', 'JJ'), ('salient', 'NN'), ('data', 'NNS'), ('indicates', 'VBZ'), ('salient', 'JJ'), ('event', 'NN'), ('piece', 'NN'), ('content', 'NN'), ('corresponding', 'VBG'), ('point', 'NN'), ('location', 'NN'), ('salient', 'JJ'), ('event', 'NN'), ('piece', 'NN'), ('content', 'NN'), ('corresponding', 'VBG'), ('time', 'NN'), ('salient', 'JJ'), ('event', 'NN'), ('occurs', 'VBZ'), ('playback', 'JJ'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'VBP'), ('salient', 'NN'), ('data', 'NNS'), ('indicates', 'VBZ'), ('salient', 'JJ'), ('event', 'NN'), ('piece', 'NN'), ('content', 'NN'), ('corresponding', 'VBG'), ('type', 'JJ'), ('salient', 'JJ'), ('event', 'NN'), ('corresponding', 'VBG'), ('strength', 'NN'), ('value', 'NN'), ('salient', 'JJ'), ('event', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('first', 'JJ'), ('path', 'NN'), ('viewport', 'NN'), ('controls', 'NNS'), ('movement', 'NN'), ('viewport', 'NN'), ('put', 'VBD'), ('different', 'JJ'), ('salient', 'JJ'), ('events', 'NNS'), ('view', 'VBP'), ('viewport', 'RB'), ('different', 'JJ'), ('times', 'NNS'), ('playback', 'VBP'), ('method', 'JJ'), ('claim', 'NN'), ('comprising', 'VBG'), ('detecting', 'VBG'), ('one', 'CD'), ('salient', 'NN'), ('events', 'NNS'), ('piece', 'VBP'), ('content', 'NN'), ('based', 'VBN'), ('least', 'JJS'), ('one', 'CD'), ('following', 'VBG'), ('visual', 'JJ'), ('data', 'NNS'), ('piece', 'NN'), ('content', 'NN'), ('audio', 'NN'), ('data', 'NNS'), ('piece', 'NN'), ('content', 'NN'), ('content', 'JJ'), ('consumption', 'NN'), ('experience', 'NN'), ('data', 'NNS'), ('piece', 'NN'), ('content', 'NN'), ('wherein', 'WRB'), ('salient', 'NN'), ('data', 'NNS'), ('indicative', 'JJ'), ('salient', 'JJ'), ('event', 'NN'), ('detected', 'VBD'), ('method', 'JJ'), ('claim', 'NN'), ('comprising', 'VBG'), ('detecting', 'VBG'), ('one', 'CD'), ('salient', 'NN'), ('events', 'NNS'), ('piece', 'VBP'), ('content', 'NN'), ('based', 'VBN'), ('least', 'JJS'), ('one', 'CD'), ('following', 'VBG'), ('face', 'NN'), ('recognition', 'NN'), ('facial', 'JJ'), ('emotion', 'NN'), ('recognition', 'NN'), ('object', 'JJ'), ('recognition', 'NN'), ('motion', 'NN'), ('recognition', 'NN'), ('metadata', 'NNS'), ('piece', 'NN'), ('content', 'NN'), ('wherein', 'WRB'), ('salient', 'NN'), ('data', 'NNS'), ('indicative', 'JJ'), ('salient', 'JJ'), ('event', 'NN'), ('detected', 'VBD'), ('method', 'JJ'), ('claim', 'NN'), ('comprising', 'VBG'), ('detecting', 'VBG'), ('user', 'JJ'), ('interaction', 'NN'), ('indication', 'NN'), ('wherein', 'WRB'), ('indication', 'NN'), ('comprises', 'VBZ'), ('interactive', 'JJ'), ('hint', 'NN'), ('response', 'NN'), ('detecting', 'VBG'), ('user', 'JJ'), ('interaction', 'NN'), ('adapting', 'VBG'), ('first', 'JJ'), ('path', 'NN'), ('viewport', 'NN'), ('second', 'JJ'), ('path', 'NN'), ('viewport', 'NN'), ('based', 'VBN'), ('user', 'JJ'), ('interaction', 'NN'), ('wherein', 'IN'), ('second', 'JJ'), ('path', 'NN'), ('viewport', 'NN'), ('includes', 'VBZ'), ('additional', 'JJ'), ('salient', 'NN'), ('event', 'NN'), ('providing', 'VBG'), ('updated', 'JJ'), ('viewport', 'NN'), ('piece', 'NN'), ('content', 'NN'), ('display', 'NN'), ('device', 'NN'), ('wherein', 'VBD'), ('movement', 'NN'), ('updated', 'VBN'), ('viewport', 'NN'), ('based', 'VBN'), ('second', 'JJ'), ('path', 'NN'), ('viewport', 'NN'), ('salient', 'NN'), ('data', 'NNS'), ('playback', 'VBP'), ('second', 'JJ'), ('path', 'NN'), ('viewport', 'NN'), ('controls', 'NNS'), ('movement', 'NN'), ('updated', 'VBN'), ('viewport', 'NN'), ('put', 'VBD'), ('additional', 'JJ'), ('salient', 'NN'), ('event', 'NN'), ('view', 'NN'), ('updated', 'VBD'), ('viewport', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('changing', 'VBG'), ('weight', 'NN'), ('assigned', 'VBD'), ('additional', 'JJ'), ('salient', 'NN'), ('event', 'NN'), ('one', 'CD'), ('salient', 'NN'), ('events', 'NNS'), ('piece', 'VBP'), ('content', 'JJ'), ('type', 'JJ'), ('additional', 'JJ'), ('salient', 'NN'), ('event', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('second', 'JJ'), ('path', 'NN'), ('viewport', 'NN'), ('includes', 'VBZ'), ('one', 'CD'), ('salient', 'NN'), ('events', 'NNS'), ('piece', 'VBP'), ('content', 'JJ'), ('type', 'JJ'), ('additional', 'JJ'), ('salient', 'NN'), ('event', 'NN'), ('system', 'NN'), ('comprising', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('processor', 'NN'), ('non-transitory', 'JJ'), ('processor-readable', 'JJ'), ('memory', 'NN'), ('device', 'NN'), ('storing', 'VBG'), ('instructions', 'NNS'), ('executed', 'VBD'), ('least', 'JJS'), ('one', 'CD'), ('processor', 'NN'), ('causes', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('processor', 'NN'), ('perform', 'NN'), ('operations', 'NNS'), ('including', 'VBG'), ('receiving', 'VBG'), ('piece', 'NN'), ('content', 'JJ'), ('salient', 'NN'), ('data', 'NNS'), ('piece', 'NN'), ('content', 'NN'), ('based', 'VBN'), ('salient', 'JJ'), ('data', 'NNS'), ('determining', 'VBG'), ('first', 'JJ'), ('path', 'NN'), ('viewport', 'NN'), ('piece', 'NN'), ('content', 'NN'), ('wherein', 'NN'), ('first', 'JJ'), ('path', 'NN'), ('viewport', 'NN'), ('includes', 'VBZ'), ('different', 'JJ'), ('salient', 'JJ'), ('events', 'NNS'), ('occurring', 'VBG'), ('piece', 'NN'), ('content', 'NN'), ('different', 'JJ'), ('times', 'NNS'), ('playback', 'VBP'), ('piece', 'NN'), ('content', 'NN'), ('providing', 'VBG'), ('viewport', 'NN'), ('display', 'NN'), ('device', 'NN'), ('wherein', 'VBD'), ('movement', 'NN'), ('viewport', 'NN'), ('based', 'VBN'), ('first', 'JJ'), ('path', 'NN'), ('viewport', 'NN'), ('salient', 'NN'), ('data', 'NNS'), ('playback', 'NN'), ('detecting', 'VBG'), ('additional', 'JJ'), ('salient', 'NN'), ('event', 'NN'), ('piece', 'NN'), ('content', 'NN'), ('included', 'VBD'), ('first', 'JJ'), ('path', 'NN'), ('viewport', 'NN'), ('providing', 'VBG'), ('indication', 'JJ'), ('additional', 'JJ'), ('salient', 'NN'), ('event', 'NN'), ('viewport', 'NN'), ('playback', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'VBP'), ('salient', 'NN'), ('data', 'NNS'), ('identifies', 'NNS'), ('salient', 'JJ'), ('event', 'NN'), ('piece', 'NN'), ('content', 'JJ'), ('salient', 'NN'), ('data', 'NNS'), ('indicates', 'VBZ'), ('salient', 'JJ'), ('event', 'NN'), ('piece', 'NN'), ('content', 'NN'), ('corresponding', 'VBG'), ('point', 'NN'), ('location', 'NN'), ('salient', 'JJ'), ('event', 'NN'), ('piece', 'NN'), ('content', 'NN'), ('corresponding', 'VBG'), ('time', 'NN'), ('salient', 'JJ'), ('event', 'NN'), ('occurs', 'VBZ'), ('playback', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'VBP'), ('salient', 'NN'), ('data', 'NNS'), ('indicates', 'VBZ'), ('salient', 'JJ'), ('event', 'NN'), ('piece', 'NN'), ('content', 'NN'), ('corresponding', 'VBG'), ('type', 'JJ'), ('salient', 'JJ'), ('event', 'NN'), ('corresponding', 'VBG'), ('strength', 'NN'), ('value', 'NN'), ('salient', 'NN'), ('event', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'VBP'), ('salient', 'NN'), ('data', 'NNS'), ('generated', 'VBD'), ('offline', 'JJ'), ('server', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('operations', 'NNS'), ('comprising', 'VBG'), ('detecting', 'VBG'), ('one', 'CD'), ('salient', 'NN'), ('events', 'NNS'), ('piece', 'VBP'), ('content', 'NN'), ('based', 'VBN'), ('least', 'JJS'), ('one', 'CD'), ('following', 'VBG'), ('visual', 'JJ'), ('data', 'NNS'), ('piece', 'NN'), ('content', 'NN'), ('audio', 'NN'), ('data', 'NNS'), ('piece', 'NN'), ('content', 'NN'), ('content', 'JJ'), ('consumption', 'NN'), ('experience', 'NN'), ('data', 'NNS'), ('piece', 'NN'), ('content', 'NN'), ('wherein', 'WRB'), ('salient', 'NN'), ('data', 'NNS'), ('indicative', 'JJ'), ('salient', 'JJ'), ('event', 'NN'), ('detected', 'VBD'), ('system', 'NN'), ('claim', 'NN'), ('operations', 'NNS'), ('comprising', 'VBG'), ('detecting', 'VBG'), ('one', 'CD'), ('salient', 'NN'), ('events', 'NNS'), ('piece', 'VBP'), ('content', 'NN'), ('based', 'VBN'), ('least', 'JJS'), ('one', 'CD'), ('following', 'VBG'), ('face', 'NN'), ('recognition', 'NN'), ('facial', 'JJ'), ('emotion', 'NN'), ('recognition', 'NN'), ('object', 'JJ'), ('recognition', 'NN'), ('motion', 'NN'), ('recognition', 'NN'), ('metadata', 'NNS'), ('piece', 'NN'), ('content', 'NN'), ('wherein', 'WRB'), ('salient', 'NN'), ('data', 'NNS'), ('indicative', 'JJ'), ('salient', 'JJ'), ('event', 'NN'), ('detected', 'VBD'), ('system', 'NN'), ('claim', 'NN'), ('operations', 'NNS'), ('comprising', 'VBG'), ('detecting', 'VBG'), ('user', 'JJ'), ('interaction', 'NN'), ('indication', 'NN'), ('wherein', 'WRB'), ('indication', 'NN'), ('comprises', 'VBZ'), ('interactive', 'JJ'), ('hint', 'NN'), ('response', 'NN'), ('detecting', 'VBG'), ('user', 'JJ'), ('interaction', 'NN'), ('adapting', 'VBG'), ('first', 'JJ'), ('path', 'NN'), ('viewport', 'NN'), ('second', 'JJ'), ('path', 'NN'), ('viewport', 'NN'), ('based', 'VBN'), ('user', 'JJ'), ('interaction', 'NN'), ('wherein', 'IN'), ('second', 'JJ'), ('path', 'NN'), ('viewport', 'NN'), ('includes', 'VBZ'), ('additional', 'JJ'), ('salient', 'NN'), ('event', 'NN'), ('providing', 'VBG'), ('updated', 'JJ'), ('viewport', 'NN'), ('piece', 'NN'), ('content', 'NN'), ('display', 'NN'), ('device', 'NN'), ('wherein', 'VBD'), ('movement', 'NN'), ('updated', 'VBN'), ('viewport', 'NN'), ('based', 'VBN'), ('second', 'JJ'), ('path', 'NN'), ('viewport', 'NN'), ('salient', 'NN'), ('data', 'NNS'), ('playback', 'VBP'), ('second', 'JJ'), ('path', 'NN'), ('viewport', 'NN'), ('controls', 'NNS'), ('movement', 'NN'), ('updated', 'VBN'), ('viewport', 'NN'), ('put', 'VBD'), ('additional', 'JJ'), ('salient', 'NN'), ('event', 'NN'), ('view', 'NN'), ('updated', 'VBN'), ('viewport', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('operations', 'NNS'), ('comprising', 'VBG'), ('changing', 'VBG'), ('weight', 'NN'), ('assigned', 'VBD'), ('additional', 'JJ'), ('salient', 'NN'), ('event', 'NN'), ('one', 'CD'), ('salient', 'NN'), ('events', 'NNS'), ('piece', 'VBP'), ('content', 'JJ'), ('type', 'JJ'), ('additional', 'JJ'), ('salient', 'NN'), ('event', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('second', 'JJ'), ('path', 'NN'), ('viewport', 'NN'), ('includes', 'VBZ'), ('one', 'CD'), ('salient', 'NN'), ('events', 'NNS'), ('piece', 'VBP'), ('content', 'JJ'), ('type', 'JJ'), ('additional', 'JJ'), ('salient', 'NN'), ('event', 'NN'), ('non-transitory', 'JJ'), ('computer', 'NN'), ('readable', 'JJ'), ('storage', 'NN'), ('medium', 'NN'), ('including', 'VBG'), ('instructions', 'NNS'), ('perform', 'VBP'), ('method', 'NN'), ('comprising', 'VBG'), ('receiving', 'VBG'), ('piece', 'NN'), ('content', 'JJ'), ('salient', 'NN'), ('data', 'NNS'), ('piece', 'NN'), ('content', 'NN'), ('based', 'VBN'), ('salient', 'JJ'), ('data', 'NNS'), ('determining', 'VBG'), ('first', 'JJ'), ('path', 'NN'), ('viewport', 'NN'), ('piece', 'NN'), ('content', 'NN'), ('wherein', 'NN'), ('first', 'JJ'), ('path', 'NN'), ('viewport', 'NN'), ('includes', 'VBZ'), ('different', 'JJ'), ('salient', 'JJ'), ('events', 'NNS'), ('occurring', 'VBG'), ('piece', 'NN'), ('content', 'NN'), ('different', 'JJ'), ('times', 'NNS'), ('playback', 'VBP'), ('piece', 'NN'), ('content', 'NN'), ('providing', 'VBG'), ('viewport', 'NN'), ('display', 'NN'), ('device', 'NN'), ('wherein', 'VBD'), ('movement', 'NN'), ('viewport', 'NN'), ('based', 'VBN'), ('first', 'JJ'), ('path', 'NN'), ('viewport', 'NN'), ('salient', 'NN'), ('data', 'NNS'), ('playback', 'NN'), ('detecting', 'VBG'), ('additional', 'JJ'), ('salient', 'NN'), ('event', 'NN'), ('piece', 'NN'), ('content', 'NN'), ('included', 'VBD'), ('first', 'JJ'), ('path', 'NN'), ('viewport', 'NN'), ('providing', 'VBG'), ('indication', 'JJ'), ('additional', 'JJ'), ('salient', 'NN'), ('event', 'NN'), ('viewport', 'NN'), ('playback', 'NN'), ('computer', 'NN'), ('readable', 'JJ'), ('storage', 'NN'), ('medium', 'NN'), ('claim', 'NN'), ('method', 'NN'), ('comprising', 'VBG'), ('detecting', 'VBG'), ('user', 'JJ'), ('interaction', 'NN'), ('indication', 'NN'), ('wherein', 'WRB'), ('indication', 'NN'), ('comprises', 'VBZ'), ('interactive', 'JJ'), ('hint', 'NN'), ('response', 'NN'), ('detecting', 'VBG'), ('user', 'JJ'), ('interaction', 'NN'), ('adapting', 'VBG'), ('first', 'JJ'), ('path', 'NN'), ('viewport', 'NN'), ('second', 'JJ'), ('path', 'NN'), ('viewport', 'NN'), ('based', 'VBN'), ('user', 'JJ'), ('interaction', 'NN'), ('wherein', 'IN'), ('second', 'JJ'), ('path', 'NN'), ('viewport', 'NN'), ('includes', 'VBZ'), ('additional', 'JJ'), ('salient', 'NN'), ('event', 'NN'), ('providing', 'VBG'), ('updated', 'JJ'), ('viewport', 'NN'), ('piece', 'NN'), ('content', 'NN'), ('display', 'NN'), ('device', 'NN'), ('wherein', 'VBD'), ('movement', 'NN'), ('updated', 'VBN'), ('viewport', 'NN'), ('based', 'VBN'), ('second', 'JJ'), ('path', 'NN'), ('viewport', 'NN'), ('salient', 'NN'), ('data', 'NNS'), ('playback', 'VBP'), ('second', 'JJ'), ('path', 'NN'), ('viewport', 'NN'), ('controls', 'NNS'), ('movement', 'NN'), ('updated', 'VBN'), ('viewport', 'NN'), ('put', 'VBD'), ('additional', 'JJ'), ('salient', 'NN'), ('event', 'NN'), ('view', 'NN'), ('updated', 'VBD'), ('viewport', 'NN'), ('mobile', 'NN'), ('device', 'NN'), ('facial', 'JJ'), ('recognition', 'NN'), ('mobile', 'JJ'), ('device', 'NN'), ('comprising', 'VBG'), ('one', 'CD'), ('cameras', 'NN'), ('processor', 'NN'), ('device', 'NN'), ('memory', 'NN'), ('coupled', 'VBN'), ('processor', 'NN'), ('device', 'NN'), ('processing', 'NN'), ('system', 'NN'), ('programmed', 'VBD'), ('receive', 'JJ'), ('plurality', 'NN'), ('images', 'VBZ'), ('one', 'CD'), ('cameras', 'NN'), ('extract', 'JJ'), ('feature', 'NN'), ('extractor', 'NN'), ('utilizing', 'JJ'), ('convolutional', 'JJ'), ('neural', 'JJ'), ('network', 'NN'), ('cnn', 'NNS'), ('enlarged', 'VBD'), ('intra-class', 'JJ'), ('variance', 'NN'), ('long-tail', 'JJ'), ('classes', 'NNS'), ('feature', 'VBP'), ('vectors', 'NNS'), ('plurality', 'NN'), ('images', 'NNS'), ('generate', 'VBP'), ('feature', 'NN'), ('generator', 'NN'), ('discriminative', 'JJ'), ('feature', 'NN'), ('vectors', 'NNS'), ('feature', 'VBP'), ('vectors', 'NNS'), ('classify', 'VBP'), ('fully', 'RB'), ('connected', 'VBN'), ('classifier', 'JJR'), ('identity', 'NN'), ('discriminative', 'JJ'), ('feature', 'NN'), ('vectors', 'NNS'), ('control', 'VBP'), ('operation', 'NN'), ('mobile', 'JJ'), ('device', 'NN'), ('react', 'NN'), ('accordance', 'NN'), ('identity', 'NN'), ('mobile', 'JJ'), ('device', 'NN'), ('recited', 'VBD'), ('claim', 'NN'), ('includes', 'VBZ'), ('communication', 'NN'), ('system', 'NN'), ('mobile', 'JJ'), ('device', 'NN'), ('recited', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('operation', 'NN'), ('tags', 'NNS'), ('video', 'VBP'), ('identity', 'NN'), ('uploads', 'NNS'), ('video', 'VBP'), ('social', 'JJ'), ('media', 'NNS'), ('mobile', 'JJ'), ('device', 'NN'), ('recited', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('operation', 'NN'), ('tags', 'NNS'), ('video', 'VBP'), ('identity', 'NN'), ('sends', 'NNS'), ('video', 'VBP'), ('user', 'RB'), ('mobile', 'JJ'), ('device', 'NN'), ('recited', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('mobile', 'JJ'), ('device', 'NN'), ('smart', 'VBD'), ('phone', 'NN'), ('mobile', 'JJ'), ('device', 'NN'), ('recited', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('mobile', 'JJ'), ('device', 'NN'), ('body', 'NN'), ('cam', 'VBP'), ('mobile', 'JJ'), ('device', 'NN'), ('recited', 'VBD'), ('claim', 'NN'), ('programmed', 'VBD'), ('train', 'JJ'), ('feature', 'NN'), ('extractor', 'NN'), ('feature', 'NN'), ('generator', 'NN'), ('fully', 'RB'), ('connected', 'VBN'), ('classifier', 'JJ'), ('alternative', 'JJ'), ('bi-stage', 'NN'), ('strategy', 'NN'), ('mobile', 'JJ'), ('device', 'NN'), ('recited', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('feature', 'NN'), ('extractor', 'NN'), ('shares', 'NNS'), ('covariance', 'NN'), ('matrices', 'NNS'), ('across', 'IN'), ('classes', 'NNS'), ('transfer', 'VBP'), ('intra-class', 'JJ'), ('variance', 'NN'), ('regular', 'JJ'), ('classes', 'NNS'), ('long-tail', 'JJ'), ('classes', 'NNS'), ('mobile', 'JJ'), ('device', 'NN'), ('recited', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('feature', 'NN'), ('generator', 'NN'), ('optimizes', 'VBZ'), ('softmax', 'JJ'), ('loss', 'NN'), ('joint', 'NN'), ('regularization', 'NN'), ('weights', 'NNS'), ('features', 'NNS'), ('magnitude', 'VBP'), ('inner', 'JJ'), ('product', 'NN'), ('weights', 'NNS'), ('features', 'NNS'), ('mobile', 'JJ'), ('device', 'NN'), ('recited', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('feature', 'NN'), ('extractor', 'NN'), ('averages', 'NNS'), ('feature', 'VBP'), ('vector', 'NN'), ('flipped', 'VBD'), ('feature', 'NN'), ('vector', 'NN'), ('flipped', 'VBD'), ('feature', 'NN'), ('vector', 'NN'), ('generated', 'VBD'), ('horizontally', 'RB'), ('flipped', 'VBN'), ('frame', 'VB'), ('one', 'CD'), ('plurality', 'NN'), ('images', 'VBZ'), ('mobile', 'JJ'), ('device', 'NN'), ('recited', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('plurality', 'NN'), ('images', 'NNS'), ('selected', 'VBN'), ('group', 'NN'), ('consisting', 'VBG'), ('image', 'NN'), ('video', 'NN'), ('frame', 'NN'), ('video', 'NN'), ('mobile', 'JJ'), ('device', 'NN'), ('recited', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('communication', 'NN'), ('system', 'NN'), ('connects', 'VBZ'), ('remote', 'JJ'), ('server', 'NN'), ('includes', 'VBZ'), ('facial', 'JJ'), ('recognition', 'NN'), ('network', 'NN'), ('mobile', 'JJ'), ('device', 'NN'), ('recited', 'VBD'), ('claim', 'NN'), ('wherein', 'IN'), ('one', 'CD'), ('stage', 'NN'), ('alternative', 'JJ'), ('bi-stage', 'NN'), ('strategy', 'NN'), ('fixes', 'NNS'), ('feature', 'VBP'), ('extractor', 'NN'), ('applies', 'NNS'), ('feature', 'VBP'), ('generator', 'NN'), ('generate', 'VBP'), ('new', 'JJ'), ('transferred', 'VBN'), ('features', 'NNS'), ('diverse', 'JJ'), ('violate', 'JJ'), ('decision', 'NN'), ('boundary', 'NN'), ('mobile', 'JJ'), ('device', 'NN'), ('recited', 'VBD'), ('claim', 'NN'), ('wherein', 'IN'), ('one', 'CD'), ('stage', 'NN'), ('alternative', 'JJ'), ('bi-stage', 'NN'), ('strategy', 'NN'), ('fixes', 'NNS'), ('fully', 'RB'), ('connected', 'VBN'), ('classifier', 'JJR'), ('updates', 'JJ'), ('feature', 'NN'), ('extractor', 'NN'), ('feature', 'NN'), ('generator', 'NN'), ('computer', 'NN'), ('program', 'NN'), ('product', 'NN'), ('mobile', 'JJ'), ('device', 'NN'), ('facial', 'JJ'), ('recognition', 'NN'), ('computer', 'NN'), ('program', 'NN'), ('product', 'NN'), ('comprising', 'VBG'), ('non-transitory', 'JJ'), ('computer', 'NN'), ('readable', 'JJ'), ('storage', 'NN'), ('medium', 'NN'), ('program', 'NN'), ('instructions', 'NNS'), ('embodied', 'VBD'), ('therewith', 'JJ'), ('program', 'NN'), ('instructions', 'NNS'), ('executable', 'JJ'), ('computer', 'NN'), ('cause', 'NN'), ('computer', 'NN'), ('perform', 'NN'), ('method', 'NN'), ('comprising', 'VBG'), ('receiving', 'VBG'), ('processor', 'NN'), ('device', 'NN'), ('plurality', 'NN'), ('images', 'VBZ'), ('extracting', 'VBG'), ('processor', 'NN'), ('device', 'NN'), ('feature', 'NN'), ('extractor', 'NN'), ('utilizing', 'JJ'), ('convolutional', 'JJ'), ('neural', 'JJ'), ('network', 'NN'), ('cnn', 'NNS'), ('enlarged', 'VBD'), ('intra-class', 'JJ'), ('variance', 'NN'), ('long-tail', 'JJ'), ('classes', 'NNS'), ('feature', 'VBP'), ('vectors', 'NNS'), ('plurality', 'NN'), ('images', 'NNS'), ('generating', 'VBG'), ('processor', 'NN'), ('device', 'NN'), ('feature', 'NN'), ('generator', 'NN'), ('discriminative', 'JJ'), ('feature', 'NN'), ('vectors', 'NNS'), ('feature', 'VBP'), ('vectors', 'NNS'), ('classifying', 'VBG'), ('processor', 'NN'), ('device', 'NN'), ('utilizing', 'VBG'), ('fully', 'RB'), ('connected', 'VBN'), ('classifier', 'JJR'), ('identity', 'NN'), ('discriminative', 'JJ'), ('feature', 'NN'), ('vector', 'NN'), ('controlling', 'VBG'), ('operation', 'NN'), ('mobile', 'JJ'), ('device', 'NN'), ('react', 'NN'), ('accordance', 'NN'), ('identity', 'NN'), ('computer-implemented', 'JJ'), ('method', 'NN'), ('facial', 'JJ'), ('recognition', 'NN'), ('mobile', 'JJ'), ('device', 'NN'), ('method', 'NN'), ('comprising', 'VBG'), ('receiving', 'VBG'), ('processor', 'NN'), ('device', 'NN'), ('plurality', 'NN'), ('images', 'VBZ'), ('extracting', 'VBG'), ('processor', 'NN'), ('device', 'NN'), ('feature', 'NN'), ('extractor', 'NN'), ('utilizing', 'JJ'), ('convolutional', 'JJ'), ('neural', 'JJ'), ('network', 'NN'), ('cnn', 'NNS'), ('enlarged', 'VBD'), ('intra-class', 'JJ'), ('variance', 'NN'), ('long-tail', 'JJ'), ('classes', 'NNS'), ('feature', 'VBP'), ('vectors', 'NNS'), ('plurality', 'NN'), ('images', 'NNS'), ('generating', 'VBG'), ('processor', 'NN'), ('device', 'NN'), ('feature', 'NN'), ('generator', 'NN'), ('discriminative', 'JJ'), ('feature', 'NN'), ('vectors', 'NNS'), ('feature', 'VBP'), ('vectors', 'NNS'), ('classifying', 'VBG'), ('processor', 'NN'), ('device', 'NN'), ('utilizing', 'VBG'), ('fully', 'RB'), ('connected', 'VBN'), ('classifier', 'JJR'), ('identity', 'NN'), ('discriminative', 'JJ'), ('feature', 'NN'), ('vector', 'NN'), ('controlling', 'VBG'), ('operation', 'NN'), ('mobile', 'JJ'), ('device', 'NN'), ('react', 'NN'), ('accordance', 'NN'), ('identity', 'NN'), ('computer-implemented', 'JJ'), ('method', 'NN'), ('recited', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('controlling', 'VBG'), ('includes', 'VBZ'), ('tagging', 'VBG'), ('video', 'NN'), ('identity', 'NN'), ('uploading', 'VBG'), ('video', 'JJ'), ('social', 'JJ'), ('media', 'NNS'), ('computer-implemented', 'JJ'), ('method', 'NN'), ('recited', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('controlling', 'VBG'), ('includes', 'VBZ'), ('tagging', 'VBG'), ('video', 'NN'), ('identity', 'NN'), ('sending', 'VBG'), ('video', 'JJ'), ('user', 'JJ'), ('computer-implemented', 'JJ'), ('method', 'NN'), ('recited', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('extracting', 'VBG'), ('includes', 'VBZ'), ('sharing', 'VBG'), ('covariance', 'NN'), ('matrices', 'NNS'), ('across', 'IN'), ('classes', 'NNS'), ('transfer', 'VBP'), ('intra-class', 'JJ'), ('variance', 'NN'), ('regular', 'JJ'), ('classes', 'NNS'), ('long-tail', 'JJ'), ('classes', 'NNS'), ('computing', 'VBG'), ('device', 'NN'), ('comprising', 'VBG'), ('non-transitory', 'JJ'), ('machine', 'NN'), ('readable', 'JJ'), ('medium', 'NN'), ('storing', 'VBG'), ('machine', 'NN'), ('trained', 'VBN'), ('mt', 'JJ'), ('network', 'NN'), ('comprising', 'VBG'), ('plurality', 'NN'), ('layers', 'NNS'), ('processing', 'VBG'), ('nodes', 'NNS'), ('processing', 'VBG'), ('node', 'RB'), ('configured', 'VBN'), ('compute', 'NN'), ('first', 'RB'), ('output', 'NN'), ('value', 'NN'), ('combining', 'VBG'), ('set', 'VBN'), ('output', 'NN'), ('values', 'NNS'), ('set', 'VBD'), ('processing', 'VBG'), ('nodes', 'NNS'), ('use', 'VBP'), ('piecewise', 'JJ'), ('linear', 'JJ'), ('cup', 'NN'), ('function', 'NN'), ('compute', 'JJ'), ('second', 'JJ'), ('output', 'NN'), ('value', 'NN'), ('first', 'RB'), ('output', 'NN'), ('value', 'NN'), ('processing', 'VBG'), ('node', 'JJ'), ('wherein', 'NN'), ('piecewise', 'NN'), ('linear', 'JJ'), ('cup', 'NN'), ('function', 'NN'), ('prior', 'RB'), ('training', 'VBG'), ('mt', 'NN'), ('network', 'NN'), ('comprises', 'NNS'), ('least', 'VBP'), ('first', 'JJ'), ('linear', 'JJ'), ('section', 'NN'), ('first', 'RB'), ('slope', 'NN'), ('followed', 'VBD'), ('ii', 'JJ'), ('second', 'JJ'), ('linear', 'JJ'), ('section', 'NN'), ('negative', 'JJ'), ('second', 'JJ'), ('slope', 'NN'), ('followed', 'VBD'), ('iii', 'JJ'), ('third', 'JJ'), ('linear', 'JJ'), ('section', 'NN'), ('negative', 'JJ'), ('third', 'JJ'), ('slope', 'NN'), ('different', 'JJ'), ('second', 'JJ'), ('slope', 'NN'), ('followed', 'VBD'), ('iv', 'JJ'), ('fourth', 'JJ'), ('linear', 'JJ'), ('section', 'NN'), ('positive', 'JJ'), ('fourth', 'JJ'), ('slope', 'NN'), ('followed', 'VBD'), ('v', 'JJ'), ('fifth', 'JJ'), ('linear', 'JJ'), ('section', 'NN'), ('positive', 'JJ'), ('fifth', 'JJ'), ('slope', 'NN'), ('different', 'JJ'), ('fourth', 'JJ'), ('slope', 'NN'), ('followed', 'VBD'), ('vi', 'JJ'), ('sixth', 'JJ'), ('linear', 'JJ'), ('section', 'NN'), ('sixth', 'VBD'), ('slope', 'NN'), ('wherein', 'NN'), ('piecewise', 'NN'), ('linear', 'JJ'), ('cup', 'NN'), ('function', 'NN'), ('symmetric', 'JJ'), ('vertical', 'JJ'), ('axis', 'NN'), ('third', 'JJ'), ('fourth', 'JJ'), ('linear', 'JJ'), ('sections', 'NNS'), ('prior', 'RB'), ('training', 'VBG'), ('mt', 'NN'), ('network', 'NN'), ('content', 'JJ'), ('capturing', 'NN'), ('circuit', 'NN'), ('capturing', 'VBG'), ('content', 'JJ'), ('processing', 'NN'), ('mt', 'NN'), ('network', 'NN'), ('set', 'VBN'), ('processing', 'VBG'), ('units', 'NNS'), ('executing', 'VBG'), ('processing', 'VBG'), ('nodes', 'NNS'), ('process', 'NN'), ('content', 'NN'), ('captured', 'VBD'), ('content', 'JJ'), ('capturing', 'VBG'), ('circuit', 'NN'), ('wherein', 'NN'), ('training', 'NN'), ('set', 'VBN'), ('parameters', 'NNS'), ('define', 'VBP'), ('piecewise', 'NN'), ('linear', 'JJ'), ('cup', 'NN'), ('function', 'NN'), ('node', 'IN'), ('first', 'JJ'), ('second', 'JJ'), ('pluralities', 'NNS'), ('processing', 'VBG'), ('nodes', 'NNS'), ('processing', 'VBG'), ('node', 'NN'), ('first', 'JJ'), ('plurality', 'NN'), ('processing', 'NN'), ('nodes', 'NNS'), ('configured', 'VBD'), ('emulate', 'JJ'), ('boolean', 'NN'), ('operator', 'NN'), ('output', 'NN'), ('value', 'NN'), ('processing', 'NN'), ('node', 'JJ'), ('range', 'NN'), ('associated', 'VBN'), ('``', '``'), (\"''\", \"''\"), ('value', 'NN'), ('set', 'VBN'), ('inputs', 'NNS'), ('processing', 'VBG'), ('node', 'NN'), ('set', 'VBN'), ('values', 'NNS'), ('range', 'VBP'), ('associated', 'VBN'), ('``', '``'), (\"''\", \"''\"), ('ii', 'NN'), ('processing', 'NN'), ('node', 'JJ'), ('second', 'JJ'), ('plurality', 'NN'), ('processing', 'NN'), ('nodes', 'NNS'), ('configured', 'VBD'), ('emulate', 'JJ'), ('boolean', 'JJ'), ('xnor', 'NN'), ('operator', 'NN'), ('output', 'NN'), ('value', 'NN'), ('processing', 'NN'), ('node', 'JJ'), ('range', 'NN'), ('associated', 'VBN'), ('``', '``'), (\"''\", \"''\"), ('set', 'NN'), ('inputs', 'NNS'), ('node', 'JJ'), ('set', 'NN'), ('values', 'NNS'), ('range', 'VBP'), ('associated', 'VBN'), ('``', '``'), (\"''\", \"''\"), ('b', 'NN'), ('set', 'VBN'), ('inputs', 'NNS'), ('node', 'JJ'), ('set', 'NN'), ('values', 'NNS'), ('range', 'VBP'), ('associated', 'VBN'), ('``', '``'), (\"''\", \"''\"), ('value', 'NN'), ('computing', 'VBG'), ('device', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('third', 'JJ'), ('linear', 'JJ'), ('section', 'NN'), ('piecewise', 'NN'), ('linear', 'JJ'), ('cup', 'NN'), ('function', 'NN'), ('first', 'RB'), ('processing', 'VBG'), ('node', 'NN'), ('mt', 'NN'), ('network', 'NN'), ('different', 'JJ'), ('slope', 'NN'), ('third', 'JJ'), ('linear', 'JJ'), ('section', 'NN'), ('second', 'JJ'), ('processing', 'NN'), ('node', 'NN'), ('mt', 'NN'), ('network', 'NN'), ('computing', 'VBG'), ('device', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('length', 'VBZ'), ('third', 'JJ'), ('section', 'NN'), ('piecewise', 'NN'), ('linear', 'JJ'), ('cup', 'NN'), ('function', 'NN'), ('first', 'RB'), ('processing', 'VBG'), ('node', 'NN'), ('mt', 'NN'), ('network', 'NN'), ('different', 'JJ'), ('length', 'NN'), ('third', 'JJ'), ('section', 'NN'), ('piecewise', 'NN'), ('linear', 'JJ'), ('cup', 'NN'), ('function', 'NN'), ('second', 'JJ'), ('processing', 'NN'), ('node', 'NN'), ('mt', 'NN'), ('network', 'NN'), ('computing', 'VBG'), ('device', 'NN'), ('claim', 'NN'), ('wherein', 'JJ'), ('sets', 'VBZ'), ('parameters', 'NNS'), ('trained', 'VBD'), ('part', 'NN'), ('back', 'RB'), ('propagating', 'VBG'), ('module', 'NN'), ('back', 'RB'), ('propagating', 'JJ'), ('errors', 'NNS'), ('output', 'NN'), ('values', 'NNS'), ('later', 'RBR'), ('layers', 'NNS'), ('processing', 'VBG'), ('nodes', 'NNS'), ('earlier', 'RBR'), ('layers', 'NNS'), ('processing', 'VBG'), ('nodes', 'NNS'), ('adjusting', 'VBG'), ('set', 'NN'), ('parameters', 'NNS'), ('define', 'VBP'), ('piecewise', 'NN'), ('linear', 'JJ'), ('cup', 'NN'), ('functions', 'NNS'), ('earlier', 'RBR'), ('layers', 'NNS'), ('processing', 'VBG'), ('nodes', 'NNS'), ('computing', 'VBG'), ('device', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('processing', 'NN'), ('node', 'JJ'), ('uses', 'NNS'), ('linear', 'JJ'), ('function', 'NN'), ('defined', 'VBD'), ('set', 'VBN'), ('parameters', 'NNS'), ('compute', 'VBP'), ('first', 'JJ'), ('output', 'NN'), ('value', 'NN'), ('processing', 'VBG'), ('node', 'CC'), ('wherein', 'JJ'), ('back', 'RB'), ('propagating', 'VBG'), ('module', 'NN'), ('back', 'RB'), ('propagates', 'VBZ'), ('errors', 'NNS'), ('output', 'NN'), ('values', 'NNS'), ('later', 'RBR'), ('layers', 'NNS'), ('processing', 'VBG'), ('nodes', 'NNS'), ('earlier', 'RBR'), ('layers', 'NNS'), ('processing', 'VBG'), ('nodes', 'NNS'), ('adjusting', 'VBG'), ('set', 'NN'), ('parameters', 'NNS'), ('define', 'VBP'), ('linear', 'JJ'), ('functions', 'NNS'), ('earlier', 'RBR'), ('layers', 'NNS'), ('processing', 'VBG'), ('nodes', 'NNS'), ('computing', 'VBG'), ('device', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('first', 'JJ'), ('plurality', 'NN'), ('processing', 'NN'), ('nodes', 'NNS'), ('emulate', 'VBP'), ('boolean', 'JJ'), ('operator', 'NN'), ('second', 'JJ'), ('plurality', 'NN'), ('processing', 'NN'), ('nodes', 'NNS'), ('emulate', 'VBP'), ('boolean', 'JJ'), ('xnor', 'NNP'), ('operator', 'NN'), ('enable', 'JJ'), ('mt', 'NN'), ('network', 'NN'), ('implement', 'JJ'), ('mathematical', 'JJ'), ('problems', 'NNS'), ('computing', 'VBG'), ('device', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('plurality', 'NN'), ('processing', 'NN'), ('node', 'NN'), ('layers', 'NNS'), ('plurality', 'NN'), ('processing', 'NN'), ('nodes', 'NNS'), ('receive', 'VBP'), ('input', 'NN'), ('values', 'NNS'), ('output', 'NN'), ('values', 'NNS'), ('plurality', 'NN'), ('processing', 'NN'), ('nodes', 'NNS'), ('set', 'VBD'), ('prior', 'JJ'), ('layers', 'NNS'), ('computing', 'VBG'), ('device', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('processing', 'NN'), ('node', 'JJ'), ('uses', 'NNS'), ('linear', 'JJ'), ('function', 'NN'), ('compute', 'NN'), ('first', 'RB'), ('output', 'NN'), ('value', 'NN'), ('processing', 'VBG'), ('node', 'JJ'), ('wherein', 'NN'), ('processing', 'VBG'), ('node', 'NN'), (\"'s\", 'POS'), ('piecewise', 'NN'), ('linear', 'JJ'), ('cup', 'NN'), ('function', 'NN'), ('defined', 'VBD'), ('along', 'IN'), ('first', 'JJ'), ('second', 'JJ'), ('axes', 'NNS'), ('first', 'RB'), ('axis', 'VBP'), ('defining', 'VBG'), ('range', 'NN'), ('output', 'NN'), ('values', 'NNS'), ('processing', 'VBG'), ('node', 'NN'), (\"'s\", 'POS'), ('linear', 'JJ'), ('function', 'NN'), ('second', 'JJ'), ('axis', 'NN'), ('defining', 'VBG'), ('range', 'NN'), ('output', 'NN'), ('values', 'NNS'), ('produced', 'VBD'), ('piecewise', 'JJ'), ('linear', 'JJ'), ('cup', 'NN'), ('function', 'NN'), ('range', 'NN'), ('output', 'NN'), ('values', 'NNS'), ('processing', 'VBG'), ('node', 'NN'), (\"'s\", 'POS'), ('linear', 'JJ'), ('function', 'NN'), ('computing', 'VBG'), ('device', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('content', 'JJ'), ('output', 'NN'), ('circuit', 'NN'), ('presenting', 'VBG'), ('output', 'NN'), ('based', 'VBN'), ('processing', 'NN'), ('content', 'NN'), ('mt', 'NN'), ('network', 'NN'), ('computing', 'VBG'), ('device', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('captured', 'VBD'), ('content', 'JJ'), ('one', 'CD'), ('image', 'NN'), ('audio', 'NN'), ('segment', 'NN'), ('wherein', 'NN'), ('presented', 'VBD'), ('output', 'NN'), ('output', 'NN'), ('display', 'VBP'), ('display', 'NN'), ('screen', 'NN'), ('computing', 'VBG'), ('device', 'NN'), ('audio', 'NN'), ('presentation', 'NN'), ('output', 'NN'), ('speaker', 'NN'), ('computing', 'VBG'), ('device', 'NN'), ('computing', 'VBG'), ('device', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('computing', 'VBG'), ('device', 'NN'), ('mobile', 'JJ'), ('device', 'NN'), ('computing', 'VBG'), ('device', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('mt', 'NN'), ('network', 'NN'), ('mt', 'NN'), ('neural', 'JJ'), ('network', 'NN'), ('processing', 'VBG'), ('nodes', 'NNS'), ('mt', 'JJ'), ('neurons', 'NNS'), ('computing', 'VBG'), ('device', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('set', 'VBN'), ('parameters', 'NNS'), ('configured', 'VBD'), ('training', 'VBG'), ('plurality', 'NN'), ('processing', 'NN'), ('nodes', 'NNS'), ('comprise', 'VBP'), ('least', 'JJS'), ('one', 'CD'), ('negative', 'JJ'), ('second', 'JJ'), ('third', 'JJ'), ('slopes', 'NNS'), ('second', 'JJ'), ('third', 'JJ'), ('linear', 'JJ'), ('sections', 'NNS'), ('positive', 'JJ'), ('fourth', 'JJ'), ('fifth', 'JJ'), ('slopes', 'NNS'), ('fourth', 'JJ'), ('fifth', 'JJ'), ('linear', 'NN'), ('sections', 'NNS'), ('first', 'RB'), ('intercept', 'JJ'), ('second', 'JJ'), ('linear', 'JJ'), ('section', 'NN'), ('second', 'JJ'), ('intercept', 'NN'), ('fifth', 'JJ'), ('linear', 'JJ'), ('section', 'NN'), ('set', 'VBN'), ('lengths', 'NNS'), ('least', 'JJS'), ('second', 'JJ'), ('third', 'JJ'), ('fourth', 'JJ'), ('fifth', 'JJ'), ('sections', 'NNS'), ('computing', 'VBG'), ('device', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('trained', 'VBD'), ('set', 'VBN'), ('parameters', 'NNS'), ('define', 'VBP'), ('piecewise', 'NN'), ('linear', 'JJ'), ('cup', 'NN'), ('function', 'NN'), ('node', 'NN'), ('comprise', 'NN'), ('plurality', 'NN'), ('output', 'NN'), ('values', 'NNS'), ('computing', 'VBG'), ('device', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('first', 'JJ'), ('sixth', 'JJ'), ('slopes', 'NNS'), ('zerowe', 'VBP'), ('claim', 'NN'), ('system', 'NN'), ('comprising', 'VBG'), ('memory', 'NN'), ('device', 'NN'), ('store', 'NN'), ('input', 'NN'), ('image', 'NN'), ('processor', 'NN'), ('including', 'VBG'), ('image', 'NN'), ('input', 'NN'), ('interface', 'VBP'), ('receive', 'JJ'), ('input', 'NN'), ('image', 'NN'), ('pre-processor', 'JJ'), ('model', 'NN'), ('input', 'NN'), ('image', 'NN'), ('yield', 'NN'), ('multi-channel', 'JJ'), ('image', 'NN'), ('feature', 'NN'), ('extractor', 'NN'), ('extract', 'NN'), ('set', 'VBN'), ('features', 'NNS'), ('based', 'VBN'), ('multi-channel', 'JJ'), ('image', 'NN'), ('feature', 'NN'), ('selector', 'NN'), ('select', 'VBP'), ('one', 'CD'), ('features', 'VBZ'), ('set', 'VBN'), ('features', 'NNS'), ('multi-channel', 'JJ'), ('image', 'NN'), ('wherein', 'VBD'), ('one', 'CD'), ('features', 'NNS'), ('selected', 'VBN'), ('based', 'VBN'), ('ability', 'NN'), ('differentiate', 'NN'), ('features', 'NNS'), ('feature', 'VBP'), ('matcher', 'JJR'), ('match', 'NN'), ('one', 'CD'), ('features', 'NNS'), ('learned', 'VBD'), ('feature', 'NN'), ('set', 'VBN'), ('similarity', 'NN'), ('detector', 'NN'), ('determine', 'NN'), ('whether', 'IN'), ('one', 'CD'), ('features', 'VBZ'), ('meet', 'RBS'), ('pre-defined', 'JJ'), ('similarity', 'NN'), ('threshold', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('pre-processor', 'JJ'), ('activate', 'NN'), ('one', 'CD'), ('channels', 'VBZ'), ('multi-channel', 'NN'), ('image', 'NN'), ('yield', 'NN'), ('one', 'CD'), ('activated', 'VBN'), ('channels', 'NNS'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'VBP'), ('one', 'CD'), ('activated', 'VBN'), ('channels', 'NNS'), ('determined', 'VBN'), ('based', 'VBN'), ('ability', 'NN'), ('differentiate', 'NN'), ('features', 'NNS'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('pre-processor', 'JJ'), ('activate', 'NN'), ('one', 'CD'), ('local', 'JJ'), ('patches', 'VBZ'), ('one', 'CD'), ('activated', 'VBN'), ('channels', 'NNS'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'VBP'), ('one', 'CD'), ('local', 'JJ'), ('patches', 'NNS'), ('determined', 'VBD'), ('based', 'VBN'), ('ability', 'NN'), ('differentiate', 'NN'), ('features', 'NNS'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'JJ'), ('feature', 'NN'), ('matcher', 'NN'), ('utilize', 'JJ'), ('large-scale', 'JJ'), ('data', 'NNS'), ('learning', 'VBG'), ('process', 'NN'), ('perform', 'NN'), ('feature', 'NN'), ('matching', 'VBG'), ('apparatus', 'NN'), ('comprising', 'VBG'), ('image', 'NN'), ('input', 'NN'), ('interface', 'VBP'), ('receive', 'JJ'), ('input', 'NN'), ('image', 'NN'), ('pre-processor', 'JJ'), ('model', 'NN'), ('input', 'NN'), ('image', 'NN'), ('yield', 'NN'), ('multi-channel', 'JJ'), ('image', 'NN'), ('feature', 'NN'), ('extractor', 'NN'), ('extract', 'NN'), ('set', 'VBN'), ('features', 'NNS'), ('based', 'VBN'), ('multi-channel', 'JJ'), ('image', 'NN'), ('feature', 'NN'), ('selector', 'NN'), ('select', 'VBP'), ('one', 'CD'), ('features', 'VBZ'), ('set', 'VBN'), ('features', 'NNS'), ('multi-channel', 'JJ'), ('image', 'NN'), ('wherein', 'VBD'), ('one', 'CD'), ('features', 'NNS'), ('selected', 'VBN'), ('based', 'VBN'), ('ability', 'NN'), ('differentiate', 'NN'), ('features', 'NNS'), ('feature', 'VBP'), ('matcher', 'JJR'), ('match', 'NN'), ('one', 'CD'), ('features', 'NNS'), ('learned', 'VBD'), ('feature', 'NN'), ('set', 'VBN'), ('similarity', 'NN'), ('detector', 'NN'), ('determine', 'NN'), ('whether', 'IN'), ('one', 'CD'), ('features', 'VBZ'), ('meet', 'RBS'), ('pre-defined', 'JJ'), ('similarity', 'NN'), ('threshold', 'NN'), ('apparatus', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('pre-processor', 'JJ'), ('activate', 'NN'), ('one', 'CD'), ('channels', 'VBZ'), ('multi-channel', 'NN'), ('image', 'NN'), ('yield', 'NN'), ('one', 'CD'), ('activated', 'VBN'), ('channels', 'NNS'), ('apparatus', 'VBP'), ('claim', 'NN'), ('wherein', 'VBP'), ('one', 'CD'), ('activated', 'VBN'), ('channels', 'NNS'), ('determined', 'VBN'), ('based', 'VBN'), ('ability', 'NN'), ('differentiate', 'NN'), ('features', 'NNS'), ('apparatus', 'VBP'), ('claim', 'NN'), ('wherein', 'IN'), ('pre-processor', 'JJ'), ('activate', 'NN'), ('one', 'CD'), ('local', 'JJ'), ('patches', 'VBZ'), ('one', 'CD'), ('activated', 'JJ'), ('channels', 'NNS'), ('apparatus', 'VBP'), ('claim', 'NN'), ('wherein', 'VBP'), ('one', 'CD'), ('local', 'JJ'), ('patches', 'NNS'), ('determined', 'VBD'), ('based', 'VBN'), ('ability', 'NN'), ('differentiate', 'NN'), ('features', 'NNS'), ('apparatus', 'VBP'), ('claim', 'NN'), ('wherein', 'NN'), ('feature', 'NN'), ('matcher', 'NN'), ('utilize', 'JJ'), ('large-scale', 'JJ'), ('data', 'NNS'), ('learning', 'VBG'), ('process', 'NN'), ('perform', 'NN'), ('feature', 'NN'), ('matching', 'VBG'), ('method', 'NN'), ('comprising', 'VBG'), ('modeling', 'VBG'), ('input', 'NN'), ('image', 'NN'), ('yield', 'NN'), ('multi-channel', 'JJ'), ('image', 'NN'), ('extracting', 'VBG'), ('set', 'VBN'), ('features', 'NNS'), ('based', 'VBN'), ('multi-channel', 'JJ'), ('image', 'NN'), ('selecting', 'VBG'), ('one', 'CD'), ('features', 'VBZ'), ('set', 'VBN'), ('features', 'NNS'), ('multi-channel', 'JJ'), ('image', 'NN'), ('wherein', 'VBD'), ('one', 'CD'), ('features', 'NNS'), ('selected', 'VBN'), ('based', 'VBN'), ('ability', 'NN'), ('differentiate', 'NN'), ('features', 'NNS'), ('matching', 'VBG'), ('one', 'CD'), ('features', 'NNS'), ('learned', 'VBD'), ('feature', 'NN'), ('set', 'VBN'), ('determining', 'VBG'), ('whether', 'IN'), ('one', 'CD'), ('features', 'VBZ'), ('meet', 'RBS'), ('pre-defined', 'JJ'), ('similarity', 'NN'), ('threshold', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('modeling', 'VBG'), ('input', 'JJ'), ('image', 'NN'), ('include', 'VBP'), ('activating', 'VBG'), ('one', 'CD'), ('channels', 'JJ'), ('multi-channel', 'JJ'), ('image', 'NN'), ('yield', 'NN'), ('one', 'CD'), ('activated', 'VBN'), ('channels', 'NNS'), ('method', 'VBP'), ('claim', 'NN'), ('wherein', 'VBP'), ('one', 'CD'), ('activated', 'VBN'), ('channels', 'NNS'), ('determined', 'VBN'), ('based', 'VBN'), ('ability', 'NN'), ('differentiate', 'NN'), ('features', 'NNS'), ('method', 'VBP'), ('claim', 'NN'), ('wherein', 'NN'), ('extracting', 'VBG'), ('features', 'NNS'), ('input', 'JJ'), ('image', 'NN'), ('include', 'VBP'), ('activating', 'VBG'), ('one', 'CD'), ('local', 'JJ'), ('patches', 'VBZ'), ('one', 'CD'), ('activated', 'JJ'), ('channels', 'NNS'), ('method', 'VBP'), ('claim', 'NN'), ('wherein', 'VBP'), ('one', 'CD'), ('local', 'JJ'), ('patches', 'NNS'), ('determined', 'VBD'), ('based', 'VBN'), ('ability', 'NN'), ('differentiate', 'NN'), ('features', 'NNS'), ('method', 'VBP'), ('claim', 'NN'), ('wherein', 'NN'), ('feature', 'NN'), ('matcher', 'NN'), ('utilizes', 'JJ'), ('large-scale', 'JJ'), ('data', 'NNS'), ('learning', 'VBG'), ('process', 'NN'), ('perform', 'NN'), ('feature', 'NN'), ('matching', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('non-transitory', 'JJ'), ('computer', 'NN'), ('readable', 'JJ'), ('storage', 'NN'), ('medium', 'NN'), ('comprising', 'VBG'), ('set', 'VBN'), ('instructions', 'NNS'), ('executed', 'VBD'), ('computing', 'VBG'), ('device', 'NN'), ('cause', 'NN'), ('computing', 'VBG'), ('device', 'NN'), ('model', 'NN'), ('input', 'NN'), ('image', 'NN'), ('yield', 'NN'), ('multi-channel', 'JJ'), ('image', 'NN'), ('extract', 'NN'), ('set', 'VBN'), ('features', 'NNS'), ('based', 'VBN'), ('multi-channel', 'JJ'), ('image', 'NN'), ('select', 'VBP'), ('one', 'CD'), ('features', 'VBZ'), ('set', 'VBN'), ('features', 'NNS'), ('multi-channel', 'JJ'), ('image', 'NN'), ('wherein', 'NN'), ('features', 'VBZ'), ('selected', 'VBN'), ('based', 'VBN'), ('ability', 'NN'), ('differentiate', 'NN'), ('features', 'NNS'), ('match', 'VBP'), ('one', 'CD'), ('features', 'NNS'), ('learned', 'VBD'), ('feature', 'NN'), ('set', 'VBN'), ('determine', 'NN'), ('whether', 'IN'), ('one', 'CD'), ('features', 'VBZ'), ('meet', 'RBS'), ('pre-defined', 'JJ'), ('similarity', 'NN'), ('threshold', 'VBD'), ('least', 'JJS'), ('one', 'CD'), ('non-transitory', 'JJ'), ('computer', 'NN'), ('readable', 'JJ'), ('storage', 'NN'), ('medium', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('instructions', 'NNS'), ('executed', 'VBD'), ('cause', 'NN'), ('computing', 'VBG'), ('device', 'NN'), ('activate', 'VBP'), ('one', 'CD'), ('channels', 'NNS'), ('multi-channel', 'JJ'), ('image', 'NN'), ('yield', 'NN'), ('one', 'CD'), ('activated', 'VBN'), ('channels', 'NNS'), ('least', 'JJS'), ('one', 'CD'), ('non-transitory', 'JJ'), ('computer', 'NN'), ('readable', 'JJ'), ('storage', 'NN'), ('medium', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('instructions', 'NNS'), ('executed', 'VBD'), ('cause', 'NN'), ('computing', 'VBG'), ('device', 'NN'), ('determine', 'NN'), ('one', 'CD'), ('activated', 'VBN'), ('channels', 'NNS'), ('based', 'VBN'), ('ability', 'NN'), ('differentiate', 'NN'), ('features', 'NNS'), ('least', 'VBP'), ('one', 'CD'), ('non-transitory', 'JJ'), ('computer', 'NN'), ('readable', 'JJ'), ('storage', 'NN'), ('medium', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('extracting', 'VBG'), ('features', 'NNS'), ('input', 'JJ'), ('image', 'NN'), ('include', 'VBP'), ('activating', 'VBG'), ('one', 'CD'), ('local', 'JJ'), ('patches', 'VBZ'), ('one', 'CD'), ('activated', 'JJ'), ('channels', 'NNS'), ('least', 'JJS'), ('one', 'CD'), ('non-transitory', 'JJ'), ('computer', 'NN'), ('readable', 'JJ'), ('storage', 'NN'), ('medium', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('one', 'CD'), ('local', 'JJ'), ('patches', 'NNS'), ('determined', 'VBD'), ('based', 'VBN'), ('ability', 'NN'), ('differentiate', 'NN'), ('features', 'NNS'), ('least', 'VBP'), ('one', 'CD'), ('non-transitory', 'JJ'), ('computer', 'NN'), ('readable', 'JJ'), ('storage', 'NN'), ('medium', 'NN'), ('claim', 'NN'), ('wherein', 'JJ'), ('feature', 'NN'), ('matcher', 'NN'), ('utilize', 'JJ'), ('large-scale', 'JJ'), ('data', 'NNS'), ('learning', 'VBG'), ('process', 'NN'), ('perform', 'NN'), ('feature', 'NN'), ('matching', 'VBG'), ('apparatus', 'NN'), ('comprising', 'VBG'), ('means', 'NNS'), ('modeling', 'VBG'), ('input', 'NN'), ('image', 'NN'), ('yield', 'NN'), ('multi-channel', 'JJ'), ('image', 'NN'), ('means', 'VBZ'), ('extracting', 'VBG'), ('set', 'VBN'), ('features', 'NNS'), ('based', 'VBN'), ('multi-channel', 'JJ'), ('image', 'NN'), ('means', 'VBZ'), ('selecting', 'VBG'), ('one', 'CD'), ('features', 'VBZ'), ('set', 'VBN'), ('features', 'NNS'), ('multi-channel', 'JJ'), ('image', 'NN'), ('wherein', 'VBD'), ('one', 'CD'), ('features', 'NNS'), ('selected', 'VBN'), ('based', 'VBN'), ('ability', 'NN'), ('differentiate', 'NN'), ('features', 'NNS'), ('means', 'VBZ'), ('matching', 'VBG'), ('one', 'CD'), ('features', 'NNS'), ('learned', 'VBD'), ('feature', 'NN'), ('set', 'VBN'), ('means', 'VBZ'), ('determining', 'VBG'), ('whether', 'IN'), ('one', 'CD'), ('features', 'VBZ'), ('meet', 'RBS'), ('pre-defined', 'JJ'), ('similarity', 'NN'), ('threshold', 'NN'), ('method', 'NN'), ('controlling', 'VBG'), ('terminal', 'JJ'), ('terminal', 'JJ'), ('comprising', 'VBG'), ('capturing', 'VBG'), ('apparatus', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('processor', 'NN'), ('method', 'NN'), ('comprising', 'VBG'), ('acquiring', 'VBG'), ('capturing', 'VBG'), ('apparatus', 'JJ'), ('image', 'NN'), ('obtaining', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('processor', 'NN'), ('motion', 'NN'), ('parameter', 'NN'), ('terminal', 'JJ'), ('motion', 'NN'), ('parameter', 'NN'), ('comprising', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('motion', 'NN'), ('frequency', 'NN'), ('motion', 'NN'), ('time', 'NN'), ('two', 'CD'), ('parameters', 'NNS'), ('among', 'IN'), ('acceleration', 'NN'), ('angular', 'JJ'), ('velocity', 'NN'), ('motion', 'NN'), ('amplitude', 'NN'), ('motion', 'NN'), ('frequency', 'NN'), ('motion', 'NN'), ('time', 'NN'), ('transmitting', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('processor', 'NN'), ('parameter', 'NN'), ('threshold', 'VBD'), ('obtaining', 'VBG'), ('request', 'NN'), ('data', 'NNS'), ('management', 'NN'), ('server', 'RB'), ('parameter', 'RB'), ('threshold', 'JJ'), ('obtaining', 'VBG'), ('request', 'NN'), ('comprising', 'VBG'), ('configuration', 'NN'), ('information', 'NN'), ('terminal', 'NN'), ('receiving', 'NN'), ('corresponding', 'VBG'), ('preset', 'NN'), ('thresholds', 'NNS'), ('correspond', 'NN'), ('configuration', 'NN'), ('information', 'NN'), ('response', 'NN'), ('parameter', 'NN'), ('threshold', 'VBD'), ('obtaining', 'VBG'), ('request', 'NN'), ('comparing', 'VBG'), ('two', 'CD'), ('parameters', 'NNS'), ('corresponding', 'VBG'), ('preset', 'NN'), ('thresholds', 'NNS'), ('controlling', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('processor', 'NN'), ('perform', 'NN'), ('image', 'NN'), ('processing', 'NN'), ('acquired', 'VBD'), ('image', 'NN'), ('based', 'VBN'), ('least', 'JJS'), ('one', 'CD'), ('two', 'CD'), ('parameters', 'NNS'), ('motion', 'VBP'), ('parameter', 'RB'), ('greater', 'JJR'), ('corresponding', 'VBG'), ('preset', 'NN'), ('threshold', 'NN'), ('based', 'VBN'), ('two', 'CD'), ('parameters', 'NNS'), ('motion', 'VBP'), ('parameter', 'NN'), ('respectively', 'RB'), ('greater', 'JJR'), ('corresponding', 'VBG'), ('preset', 'NN'), ('thresholds', 'NNS'), ('wherein', 'VBP'), ('acquiring', 'VBG'), ('comprises', 'NNS'), ('acquiring', 'VBG'), ('image', 'NN'), ('real', 'JJ'), ('time', 'NN'), ('obtaining', 'VBG'), ('comprises', 'NNS'), ('obtaining', 'VBG'), ('motion', 'NN'), ('parameter', 'NN'), ('terminal', 'JJ'), ('real', 'JJ'), ('time', 'NN'), ('method', 'NN'), ('comprising', 'VBG'), ('response', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('two', 'CD'), ('parameters', 'NNS'), ('motion', 'VBP'), ('parameter', 'RB'), ('greater', 'JJR'), ('corresponding', 'VBG'), ('preset', 'NN'), ('threshold', 'VBD'), ('obtaining', 'VBG'), ('motion', 'NN'), ('parameter', 'FW'), ('terminal', 'JJ'), ('response', 'NN'), ('two', 'CD'), ('parameters', 'NNS'), ('motion', 'VBP'), ('parameter', 'NN'), ('obtained', 'VBN'), ('latest', 'JJS'), ('time', 'NN'), ('less', 'CC'), ('equal', 'JJ'), ('corresponding', 'NN'), ('preset', 'NN'), ('thresholds', 'NNS'), ('performing', 'VBG'), ('image', 'NN'), ('processing', 'NN'), ('image', 'NN'), ('acquired', 'VBD'), ('latest', 'JJS'), ('time', 'NN'), ('method', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('acquiring', 'VBG'), ('comprises', 'NNS'), ('controlling', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('processor', 'NN'), ('turn', 'NN'), ('capturing', 'VBG'), ('apparatus', 'NNS'), ('based', 'VBN'), ('face', 'NN'), ('recognition', 'NN'), ('instruction', 'NN'), ('acquiring', 'VBG'), ('capturing', 'VBG'), ('apparatus', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('capturing', 'VBG'), ('apparatus', 'NNS'), ('turned', 'VBD'), ('method', 'JJ'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('controlling', 'VBG'), ('perform', 'JJ'), ('image', 'NN'), ('processing', 'NN'), ('comprises', 'VBZ'), ('skipping', 'VBG'), ('performing', 'VBG'), ('face', 'NN'), ('recognition', 'NN'), ('acquired', 'VBD'), ('face', 'NN'), ('image', 'NN'), ('based', 'VBN'), ('least', 'JJS'), ('one', 'CD'), ('two', 'CD'), ('parameters', 'NNS'), ('motion', 'VBP'), ('parameter', 'RB'), ('greater', 'JJR'), ('corresponding', 'VBG'), ('preset', 'NN'), ('threshold', 'NN'), ('based', 'VBN'), ('two', 'CD'), ('parameters', 'NNS'), ('motion', 'VBP'), ('parameter', 'NN'), ('respectively', 'RB'), ('greater', 'JJR'), ('corresponding', 'VBG'), ('preset', 'NN'), ('thresholds', 'NNS'), ('method', 'VBP'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('obtaining', 'VBG'), ('comprises', 'NNS'), ('least', 'JJS'), ('one', 'CD'), ('obtaining', 'VBG'), ('acceleration', 'NN'), ('terminal', 'NN'), ('using', 'VBG'), ('acceleration', 'NN'), ('sensor', 'NN'), ('obtaining', 'VBG'), ('angular', 'JJ'), ('velocity', 'NN'), ('terminal', 'NN'), ('using', 'VBG'), ('gyro', 'JJ'), ('sensor', 'NN'), ('method', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('transmitting', 'VBG'), ('comprises', 'NNS'), ('transmitting', 'VBG'), ('parameter', 'NN'), ('threshold', 'VBD'), ('obtaining', 'VBG'), ('request', 'NN'), ('data', 'NNS'), ('management', 'NN'), ('server', 'NN'), ('according', 'VBG'), ('preset', 'JJ'), ('time', 'NN'), ('period', 'NN'), ('method', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('comprising', 'VBG'), ('generating', 'VBG'), ('prompt', 'JJ'), ('information', 'NN'), ('based', 'VBN'), ('least', 'JJS'), ('one', 'CD'), ('two', 'CD'), ('parameters', 'NNS'), ('motion', 'VBP'), ('parameter', 'RB'), ('greater', 'JJR'), ('corresponding', 'VBG'), ('preset', 'NN'), ('threshold', 'VBD'), ('prompt', 'JJ'), ('information', 'NN'), ('used', 'VBN'), ('prompting', 'VBG'), ('terminal', 'JJ'), ('stop', 'NN'), ('moving', 'VBG'), ('method', 'JJ'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('motion', 'NN'), ('parameter', 'NN'), ('comprises', 'VBZ'), ('motion', 'NN'), ('frequency', 'NN'), ('motion', 'NN'), ('time', 'NN'), ('terminal', 'JJ'), ('comprising', 'VBG'), ('capturing', 'VBG'), ('apparatus', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('memory', 'NN'), ('configured', 'VBD'), ('store', 'NN'), ('program', 'NN'), ('code', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('processor', 'NN'), ('configured', 'VBD'), ('access', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('memory', 'NN'), ('operate', 'NN'), ('according', 'VBG'), ('program', 'NN'), ('code', 'NN'), ('program', 'NN'), ('code', 'NN'), ('comprising', 'VBG'), ('motion', 'NN'), ('parameter', 'NN'), ('obtaining', 'VBG'), ('code', 'NN'), ('configured', 'VBN'), ('cause', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('processor', 'NN'), ('acquire', 'VB'), ('image', 'NN'), ('using', 'VBG'), ('capturing', 'VBG'), ('apparatus', 'NN'), ('obtain', 'VB'), ('motion', 'NN'), ('parameter', 'NN'), ('terminal', 'JJ'), ('motion', 'NN'), ('parameter', 'NN'), ('comprising', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('motion', 'NN'), ('frequency', 'NN'), ('motion', 'NN'), ('time', 'NN'), ('two', 'CD'), ('parameters', 'NNS'), ('among', 'IN'), ('acceleration', 'NN'), ('angular', 'JJ'), ('velocity', 'NN'), ('motion', 'NN'), ('amplitude', 'NN'), ('motion', 'NN'), ('frequency', 'NN'), ('motion', 'NN'), ('time', 'NN'), ('request', 'NN'), ('transmitting', 'VBG'), ('code', 'NN'), ('configured', 'VBN'), ('cause', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('processor', 'NN'), ('transmit', 'NN'), ('parameter', 'NN'), ('threshold', 'VBD'), ('obtaining', 'VBG'), ('request', 'NN'), ('data', 'NNS'), ('management', 'NN'), ('server', 'RB'), ('parameter', 'RB'), ('threshold', 'JJ'), ('obtaining', 'VBG'), ('request', 'NN'), ('comprising', 'VBG'), ('configuration', 'NN'), ('information', 'NN'), ('terminal', 'NN'), ('parameter', 'NN'), ('threshold', 'VBD'), ('receiving', 'VBG'), ('code', 'NN'), ('configured', 'VBN'), ('cause', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('processor', 'NN'), ('receive', 'NN'), ('corresponding', 'VBG'), ('preset', 'NN'), ('thresholds', 'NNS'), ('correspond', 'NN'), ('configuration', 'NN'), ('information', 'NN'), ('response', 'NN'), ('parameter', 'NN'), ('threshold', 'VBD'), ('obtaining', 'VBG'), ('request', 'NN'), ('comparing', 'VBG'), ('code', 'NN'), ('configured', 'VBN'), ('cause', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('processor', 'NN'), ('compare', 'NN'), ('two', 'CD'), ('parameters', 'NNS'), ('corresponding', 'VBG'), ('preset', 'NN'), ('thresholds', 'NNS'), ('control', 'NN'), ('code', 'NN'), ('configured', 'VBN'), ('cause', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('processor', 'NN'), ('perform', 'NN'), ('image', 'NN'), ('processing', 'NN'), ('acquired', 'VBD'), ('image', 'NN'), ('based', 'VBN'), ('least', 'JJS'), ('one', 'CD'), ('two', 'CD'), ('parameters', 'NNS'), ('motion', 'VBP'), ('parameter', 'RB'), ('greater', 'JJR'), ('corresponding', 'VBG'), ('preset', 'NN'), ('threshold', 'NN'), ('based', 'VBN'), ('two', 'CD'), ('parameters', 'NNS'), ('motion', 'VBP'), ('parameter', 'NN'), ('respectively', 'RB'), ('greater', 'JJR'), ('corresponding', 'VBG'), ('preset', 'NN'), ('thresholds', 'NNS'), ('wherein', 'VBP'), ('motion', 'NN'), ('parameter', 'NN'), ('obtaining', 'VBG'), ('code', 'NN'), ('causes', 'NNS'), ('least', 'VBP'), ('one', 'CD'), ('processor', 'NN'), ('acquire', 'VB'), ('image', 'NN'), ('real', 'JJ'), ('time', 'NN'), ('obtain', 'VB'), ('motion', 'NN'), ('parameter', 'IN'), ('terminal', 'JJ'), ('real', 'JJ'), ('time', 'NN'), ('response', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('two', 'CD'), ('parameters', 'NNS'), ('motion', 'VBP'), ('parameter', 'RB'), ('greater', 'JJR'), ('corresponding', 'VBG'), ('preset', 'VBN'), ('threshold', 'JJ'), ('obtain', 'VB'), ('motion', 'NN'), ('parameter', 'NN'), ('terminal', 'JJ'), ('wherein', 'NN'), ('control', 'NN'), ('code', 'NN'), ('causes', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('processor', 'NN'), ('response', 'NN'), ('two', 'CD'), ('parameters', 'NNS'), ('motion', 'VBP'), ('parameter', 'NN'), ('obtained', 'VBN'), ('latest', 'JJS'), ('time', 'NN'), ('less', 'CC'), ('equal', 'JJ'), ('corresponding', 'NN'), ('preset', 'NN'), ('thresholds', 'NNS'), ('perform', 'VBP'), ('image', 'NN'), ('processing', 'NN'), ('image', 'NN'), ('acquired', 'VBD'), ('latest', 'JJS'), ('time', 'NN'), ('terminal', 'JJ'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('program', 'NN'), ('code', 'NN'), ('comprises', 'VBZ'), ('face', 'VBP'), ('instruction', 'NN'), ('receiving', 'VBG'), ('code', 'NN'), ('configured', 'VBN'), ('cause', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('processor', 'NN'), ('receive', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('instruction', 'NN'), ('wherein', 'WRB'), ('motion', 'NN'), ('parameter', 'NN'), ('obtaining', 'VBG'), ('code', 'NN'), ('causes', 'NNS'), ('least', 'VBP'), ('one', 'CD'), ('processor', 'NN'), ('control', 'NN'), ('according', 'VBG'), ('face', 'NN'), ('recognition', 'NN'), ('instruction', 'NN'), ('capturing', 'VBG'), ('apparatus', 'NN'), ('turn', 'NN'), ('acquire', 'VB'), ('face', 'NN'), ('image', 'NN'), ('using', 'VBG'), ('capturing', 'VBG'), ('apparatus', 'NN'), ('capturing', 'VBG'), ('apparatus', 'NN'), ('turned', 'VBD'), ('wherein', 'JJ'), ('control', 'NN'), ('code', 'NN'), ('causes', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('processor', 'NN'), ('skip', 'NN'), ('performing', 'VBG'), ('face', 'NN'), ('recognition', 'NN'), ('acquired', 'VBD'), ('face', 'NN'), ('image', 'NN'), ('based', 'VBN'), ('least', 'JJS'), ('one', 'CD'), ('two', 'CD'), ('parameters', 'NNS'), ('motion', 'VBP'), ('parameter', 'RB'), ('greater', 'JJR'), ('corresponding', 'VBG'), ('preset', 'NN'), ('threshold', 'NN'), ('based', 'VBN'), ('two', 'CD'), ('parameters', 'NNS'), ('motion', 'VBP'), ('parameter', 'NN'), ('respectively', 'RB'), ('greater', 'JJR'), ('corresponding', 'VBG'), ('preset', 'NN'), ('thresholds', 'NNS'), ('terminal', 'JJ'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('request', 'NN'), ('transmitting', 'VBG'), ('code', 'NN'), ('causes', 'NNS'), ('least', 'VBP'), ('one', 'CD'), ('processor', 'NN'), ('transmit', 'NN'), ('parameter', 'NN'), ('threshold', 'VBD'), ('obtaining', 'VBG'), ('request', 'NN'), ('data', 'NNS'), ('management', 'NN'), ('server', 'NN'), ('according', 'VBG'), ('preset', 'JJ'), ('time', 'NN'), ('period', 'NN'), ('terminal', 'JJ'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('program', 'NN'), ('code', 'NN'), ('comprises', 'VBZ'), ('prompt', 'JJ'), ('information', 'NN'), ('generation', 'NN'), ('code', 'NN'), ('configured', 'VBN'), ('cause', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('processor', 'NN'), ('generate', 'NN'), ('prompt', 'NN'), ('information', 'NN'), ('based', 'VBN'), ('least', 'JJS'), ('one', 'CD'), ('two', 'CD'), ('parameters', 'NNS'), ('motion', 'VBP'), ('parameter', 'RB'), ('greater', 'JJR'), ('corresponding', 'VBG'), ('preset', 'NN'), ('threshold', 'VBD'), ('prompt', 'JJ'), ('information', 'NN'), ('used', 'VBN'), ('prompting', 'VBG'), ('terminal', 'JJ'), ('stop', 'NN'), ('moving', 'VBG'), ('terminal', 'JJ'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('motion', 'NN'), ('parameter', 'NN'), ('comprises', 'VBZ'), ('motion', 'NN'), ('frequency', 'NN'), ('motion', 'NN'), ('time', 'NN'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('storage', 'NN'), ('medium', 'NN'), ('storing', 'VBG'), ('machine', 'NN'), ('instruction', 'NN'), ('executed', 'VBD'), ('one', 'CD'), ('processors', 'NNS'), ('causes', 'VBZ'), ('one', 'CD'), ('processors', 'NNS'), ('perform', 'VBP'), ('obtaining', 'VBG'), ('image', 'NN'), ('acquired', 'VBD'), ('capturing', 'VBG'), ('apparatus', 'NN'), ('obtaining', 'VBG'), ('motion', 'NN'), ('parameter', 'NN'), ('terminal', 'JJ'), ('terminal', 'NN'), ('comprising', 'VBG'), ('capturing', 'VBG'), ('apparatus', 'JJ'), ('motion', 'NN'), ('parameter', 'NN'), ('comprising', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('motion', 'NN'), ('frequency', 'NN'), ('motion', 'NN'), ('time', 'NN'), ('two', 'CD'), ('parameters', 'NNS'), ('among', 'IN'), ('acceleration', 'NN'), ('angular', 'JJ'), ('velocity', 'NN'), ('motion', 'NN'), ('amplitude', 'NN'), ('motion', 'NN'), ('frequency', 'NN'), ('motion', 'NN'), ('time', 'NN'), ('transmitting', 'VBG'), ('parameter', 'NN'), ('threshold', 'VBD'), ('obtaining', 'VBG'), ('request', 'NN'), ('data', 'NNS'), ('management', 'NN'), ('server', 'RB'), ('parameter', 'RB'), ('threshold', 'JJ'), ('obtaining', 'VBG'), ('request', 'NN'), ('comprising', 'VBG'), ('configuration', 'NN'), ('information', 'NN'), ('terminal', 'NN'), ('receiving', 'NN'), ('corresponding', 'VBG'), ('preset', 'NN'), ('thresholds', 'NNS'), ('correspond', 'NN'), ('configuration', 'NN'), ('information', 'NN'), ('response', 'NN'), ('parameter', 'NN'), ('threshold', 'VBD'), ('obtaining', 'VBG'), ('request', 'NN'), ('comparing', 'VBG'), ('two', 'CD'), ('parameters', 'NNS'), ('corresponding', 'VBG'), ('preset', 'NN'), ('thresholds', 'NNS'), ('controlling', 'VBG'), ('perform', 'JJ'), ('image', 'NN'), ('processing', 'NN'), ('acquired', 'VBD'), ('image', 'NN'), ('based', 'VBN'), ('least', 'JJS'), ('one', 'CD'), ('two', 'CD'), ('parameters', 'NNS'), ('motion', 'VBP'), ('parameter', 'RB'), ('greater', 'JJR'), ('corresponding', 'VBG'), ('preset', 'NN'), ('threshold', 'NN'), ('based', 'VBN'), ('two', 'CD'), ('parameters', 'NNS'), ('motion', 'VBP'), ('parameter', 'NN'), ('respectively', 'RB'), ('greater', 'JJR'), ('corresponding', 'VBG'), ('preset', 'NN'), ('thresholds', 'NNS'), ('wherein', 'VBP'), ('acquiring', 'VBG'), ('comprises', 'NNS'), ('acquiring', 'VBG'), ('image', 'NN'), ('real', 'JJ'), ('time', 'NN'), ('obtaining', 'VBG'), ('comprises', 'NNS'), ('obtaining', 'VBG'), ('motion', 'NN'), ('parameter', 'NN'), ('terminal', 'JJ'), ('real', 'JJ'), ('time', 'NN'), ('method', 'NN'), ('comprising', 'VBG'), ('response', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('two', 'CD'), ('parameters', 'NNS'), ('motion', 'VBP'), ('parameter', 'RB'), ('greater', 'JJR'), ('corresponding', 'VBG'), ('preset', 'NN'), ('threshold', 'VBD'), ('obtaining', 'VBG'), ('motion', 'NN'), ('parameter', 'FW'), ('terminal', 'JJ'), ('response', 'NN'), ('two', 'CD'), ('parameters', 'NNS'), ('motion', 'VBP'), ('parameter', 'NN'), ('obtained', 'VBN'), ('latest', 'JJS'), ('time', 'NN'), ('less', 'CC'), ('equal', 'JJ'), ('corresponding', 'NN'), ('preset', 'NN'), ('thresholds', 'NNS'), ('performing', 'VBG'), ('image', 'NN'), ('processing', 'NN'), ('image', 'NN'), ('acquired', 'VBD'), ('latest', 'JJS'), ('time', 'NN'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('storage', 'NN'), ('medium', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('acquired', 'VBD'), ('image', 'NN'), ('face', 'NN'), ('image', 'NN'), ('image', 'NN'), ('processing', 'NN'), ('comprises', 'VBZ'), ('performing', 'VBG'), ('face', 'NN'), ('recognition', 'NN'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('storage', 'NN'), ('medium', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('obtaining', 'VBG'), ('motion', 'NN'), ('parameter', 'NN'), ('comprises', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('obtaining', 'VBG'), ('acceleration', 'NN'), ('terminal', 'NN'), ('using', 'VBG'), ('acceleration', 'NN'), ('sensor', 'NN'), ('obtaining', 'VBG'), ('angular', 'JJ'), ('velocity', 'NN'), ('terminal', 'NN'), ('using', 'VBG'), ('gyro', 'JJ'), ('sensor', 'JJ'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('storage', 'NN'), ('medium', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('motion', 'NN'), ('parameter', 'NN'), ('comprises', 'VBZ'), ('motion', 'NN'), ('frequency', 'NN'), ('motion', 'NN'), ('time', 'NN'), ('method', 'NN'), ('processing', 'VBG'), ('drive-through', 'JJ'), ('order', 'NN'), ('method', 'NN'), ('comprising', 'VBG'), ('receiving', 'VBG'), ('customer', 'NN'), ('information', 'NN'), ('detected', 'VBN'), ('vision', 'NN'), ('recognition', 'NN'), ('providing', 'VBG'), ('product', 'NN'), ('information', 'NN'), ('customer', 'NN'), ('based', 'VBN'), ('customer', 'NN'), ('information', 'NN'), ('processing', 'VBG'), ('product', 'NN'), ('order', 'NN'), ('customer', 'NN'), ('method', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('receiving', 'VBG'), ('customer', 'NN'), ('information', 'NN'), ('comprises', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('receiving', 'VBG'), ('customer', 'NN'), ('information', 'NN'), ('associated', 'VBN'), ('vehicle', 'NN'), ('information', 'NN'), ('detected', 'VBD'), ('vehicle', 'NN'), ('recognition', 'NN'), ('receiving', 'VBG'), ('customer', 'NN'), ('information', 'NN'), ('associated', 'VBN'), ('identification', 'NN'), ('information', 'NN'), ('detected', 'VBD'), ('face', 'NN'), ('recognition', 'NN'), ('method', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('comprising', 'VBG'), ('determining', 'VBG'), ('whether', 'IN'), ('customer', 'NN'), ('pre-order', 'NN'), ('customer', 'NN'), ('based', 'VBN'), ('customer', 'NN'), ('information', 'NN'), ('wherein', 'NN'), ('customer', 'NN'), ('determined', 'VBD'), ('pre-order', 'JJ'), ('customer', 'NN'), ('providing', 'VBG'), ('product', 'NN'), ('information', 'NN'), ('based', 'VBN'), ('customer', 'NN'), ('information', 'NN'), ('comprises', 'VBZ'), ('providing', 'VBG'), ('pre-order', 'JJ'), ('information', 'NN'), ('using', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('audio', 'JJ'), ('video', 'NN'), ('processing', 'VBG'), ('product', 'NN'), ('order', 'NN'), ('customer', 'NN'), ('comprises', 'VBZ'), ('providing', 'VBG'), ('information', 'NN'), ('promptly', 'RB'), ('guiding', 'VBG'), ('vehicle', 'NN'), ('pickup', 'NN'), ('stand', 'VBP'), ('using', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('audio', 'NN'), ('video', 'NN'), ('providing', 'VBG'), ('information', 'NN'), ('additional', 'JJ'), ('order', 'NN'), ('available', 'JJ'), ('method', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('product', 'NN'), ('information', 'NN'), ('based', 'VBN'), ('customer', 'NN'), ('information', 'NN'), ('comprises', 'VBZ'), ('recently', 'RB'), ('ordered', 'VBN'), ('product', 'NN'), ('component', 'NN'), ('frequently', 'RB'), ('ordered', 'VBD'), ('product', 'NN'), ('component', 'NN'), ('order', 'NN'), ('history', 'NN'), ('customer', 'NN'), ('information', 'NN'), ('method', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('receiving', 'VBG'), ('customer', 'NN'), ('information', 'NN'), ('comprises', 'VBZ'), ('receiving', 'VBG'), ('information', 'NN'), ('age', 'NN'), ('gender', 'NN'), ('passenger', 'NN'), ('detected', 'VBD'), ('face', 'NN'), ('recognition', 'NN'), ('providing', 'VBG'), ('product', 'NN'), ('information', 'NN'), ('customer', 'NN'), ('based', 'VBN'), ('customer', 'NN'), ('information', 'NN'), ('comprises', 'VBZ'), ('providing', 'VBG'), ('recommended', 'VBD'), ('menu', 'JJ'), ('information', 'NN'), ('differentiated', 'VBD'), ('according', 'VBG'), ('age', 'NN'), ('gender', 'NN'), ('method', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('processing', 'VBG'), ('product', 'NN'), ('order', 'NN'), ('customer', 'NN'), ('comprises', 'VBZ'), ('determining', 'VBG'), ('product', 'NN'), ('component', 'NN'), ('past', 'JJ'), ('order', 'NN'), ('history', 'NN'), ('component', 'NN'), ('modified', 'VBD'), ('product', 'NN'), ('component', 'NN'), ('product', 'NN'), ('order', 'NN'), ('method', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('processing', 'VBG'), ('product', 'NN'), ('order', 'NN'), ('customer', 'NN'), ('comprises', 'VBZ'), ('paying', 'VBG'), ('product', 'NN'), ('price', 'NN'), ('according', 'VBG'), ('biometrics-based', 'JJ'), ('authentication', 'NN'), ('communication', 'NN'), ('system', 'NN'), ('vehicle', 'NN'), ('mobile', 'JJ'), ('terminal', 'NN'), ('method', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('processing', 'VBG'), ('product', 'NN'), ('order', 'NN'), ('customer', 'NN'), ('comprises', 'VBZ'), ('issuing', 'VBG'), ('payment', 'NN'), ('number', 'NN'), ('divided', 'VBN'), ('payment', 'NN'), ('performing', 'VBG'), ('divided', 'VBD'), ('payments', 'NNS'), ('according', 'VBG'), ('payment', 'NN'), ('requests', 'NNS'), ('plurality', 'VBP'), ('mobile', 'JJ'), ('terminals', 'NNS'), ('payment', 'NN'), ('numbers', 'NNS'), ('inputted', 'VBD'), ('method', 'JJ'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('processing', 'VBG'), ('product', 'NN'), ('order', 'NN'), ('customer', 'NN'), ('comprises', 'VBZ'), ('accumulating', 'VBG'), ('mileage', 'NN'), ('account', 'NN'), ('corresponding', 'VBG'), ('mobile', 'JJ'), ('terminal', 'JJ'), ('undergoing', 'JJ'), ('payment', 'NN'), ('method', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('processing', 'VBG'), ('product', 'NN'), ('order', 'NN'), ('customer', 'NN'), ('comprises', 'VBZ'), ('suggesting', 'VBG'), ('takeout', 'RP'), ('packaging', 'VBG'), ('method', 'NN'), ('according', 'VBG'), ('temperature', 'NN'), ('product', 'NN'), ('atmospheric', 'JJ'), ('temperature', 'NN'), ('weather', 'NN'), ('vehicle', 'NN'), ('type', 'NN'), ('apparatus', 'NN'), ('configured', 'VBD'), ('process', 'JJ'), ('drive-through', 'JJ'), ('order', 'NN'), ('apparatus', 'NN'), ('comprising', 'VBG'), ('transceiver', 'RB'), ('configured', 'VBN'), ('receive', 'JJ'), ('customer', 'NN'), ('information', 'NN'), ('detected', 'VBN'), ('vision', 'NN'), ('recognition', 'NN'), ('digital', 'JJ'), ('signage', 'NN'), ('configured', 'VBD'), ('provide', 'JJ'), ('product', 'NN'), ('information', 'NN'), ('customer', 'NN'), ('based', 'VBN'), ('customer', 'NN'), ('information', 'NN'), ('processor', 'NN'), ('configured', 'VBD'), ('process', 'JJ'), ('product', 'NN'), ('order', 'NN'), ('customer', 'NN'), ('apparatus', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('transceiver', 'WDT'), ('receives', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('customer', 'NN'), ('information', 'NN'), ('associated', 'VBN'), ('vehicle', 'NN'), ('information', 'NN'), ('detected', 'VBD'), ('vehicle', 'NN'), ('recognition', 'NN'), ('customer', 'NN'), ('information', 'NN'), ('associated', 'VBN'), ('identification', 'NN'), ('information', 'NN'), ('detected', 'VBD'), ('face', 'NN'), ('recognition', 'NN'), ('apparatus', 'IN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('processor', 'NN'), ('configured', 'VBD'), ('determine', 'NN'), ('whether', 'IN'), ('customer', 'NN'), ('pre-order', 'NN'), ('customer', 'NN'), ('based', 'VBN'), ('customer', 'NN'), ('information', 'NN'), ('customer', 'NN'), ('determined', 'VBD'), ('pre-order', 'JJ'), ('customer', 'NN'), ('perform', 'NN'), ('control', 'NN'), ('operation', 'NN'), ('provide', 'IN'), ('pre-order', 'JJ'), ('information', 'NN'), ('control', 'NN'), ('digital', 'JJ'), ('signage', 'NN'), ('output', 'NN'), ('information', 'NN'), ('promptly', 'RB'), ('guiding', 'VBG'), ('vehicle', 'NN'), ('pickup', 'NN'), ('stand', 'VB'), ('provide', 'JJ'), ('information', 'NN'), ('additional', 'JJ'), ('order', 'NN'), ('available', 'JJ'), ('apparatus', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('product', 'NN'), ('information', 'NN'), ('based', 'VBN'), ('customer', 'NN'), ('information', 'NN'), ('comprises', 'VBZ'), ('recently', 'RB'), ('ordered', 'VBN'), ('product', 'NN'), ('component', 'NN'), ('frequently', 'RB'), ('ordered', 'VBD'), ('product', 'NN'), ('component', 'NN'), ('order', 'NN'), ('history', 'NN'), ('customer', 'NN'), ('information', 'NN'), ('apparatus', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('transceiver', 'RB'), ('configured', 'VBD'), ('receive', 'JJ'), ('information', 'NN'), ('age', 'NN'), ('gender', 'NN'), ('passenger', 'NN'), ('detected', 'VBD'), ('face', 'NN'), ('recognition', 'NN'), ('processor', 'NN'), ('configured', 'VBD'), ('control', 'NN'), ('digital', 'JJ'), ('signage', 'NN'), ('provide', 'NN'), ('recommended', 'VBD'), ('menu', 'JJ'), ('information', 'NN'), ('differentiated', 'VBD'), ('according', 'VBG'), ('age', 'NN'), ('gender', 'NN'), ('apparatus', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('processor', 'NN'), ('configured', 'VBD'), ('determine', 'JJ'), ('product', 'NN'), ('component', 'NN'), ('past', 'JJ'), ('order', 'NN'), ('history', 'NN'), ('component', 'NN'), ('modified', 'VBD'), ('product', 'NN'), ('component', 'NN'), ('product', 'NN'), ('order', 'NN'), ('apparatus', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('processor', 'NN'), ('configured', 'VBD'), ('pay', 'JJ'), ('product', 'NN'), ('price', 'NN'), ('according', 'VBG'), ('biometrics-based', 'JJ'), ('authentication', 'NN'), ('communication', 'NN'), ('system', 'NN'), ('vehicle', 'NN'), ('mobile', 'JJ'), ('terminal', 'NN'), ('apparatus', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('processor', 'NN'), ('configured', 'VBD'), ('issue', 'NN'), ('payment', 'NN'), ('number', 'NN'), ('divided', 'VBN'), ('payment', 'NN'), ('perform', 'NN'), ('divided', 'VBD'), ('payments', 'NNS'), ('according', 'VBG'), ('requests', 'NNS'), ('plurality', 'NN'), ('mobile', 'NN'), ('terminals', 'NNS'), ('payment', 'NN'), ('numbers', 'NNS'), ('inputted', 'VBD'), ('apparatus', 'JJ'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('processor', 'NN'), ('configured', 'VBD'), ('accumulate', 'JJ'), ('mileage', 'NN'), ('account', 'NN'), ('corresponding', 'VBG'), ('mobile', 'JJ'), ('terminal', 'JJ'), ('undergoing', 'JJ'), ('payment', 'NN'), ('apparatus', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('processor', 'NN'), ('configured', 'VBD'), ('control', 'NN'), ('digital', 'JJ'), ('signage', 'NN'), ('suggest', 'VBP'), ('takeout', 'IN'), ('packaging', 'NN'), ('method', 'NN'), ('according', 'VBG'), ('temperature', 'NN'), ('product', 'NN'), ('atmospheric', 'JJ'), ('temperature', 'NN'), ('weather', 'NN'), ('vehicle', 'NN'), ('type', 'JJ'), ('image', 'NN'), ('information', 'NN'), ('processing', 'VBG'), ('method', 'NN'), ('performed', 'VBD'), ('computing', 'VBG'), ('device', 'NN'), ('one', 'CD'), ('processors', 'NNS'), ('memory', 'NN'), ('storing', 'VBG'), ('plurality', 'NN'), ('programs', 'NNS'), ('executed', 'VBD'), ('one', 'CD'), ('processors', 'NNS'), ('method', 'VBP'), ('comprising', 'VBG'), ('identifying', 'VBG'), ('using', 'VBG'), ('face', 'NN'), ('recognition', 'NN'), ('one', 'CD'), ('faces', 'VBZ'), ('face', 'NN'), ('corresponding', 'VBG'), ('respective', 'JJ'), ('person', 'NN'), ('captured', 'VBD'), ('first', 'JJ'), ('image', 'NN'), ('identified', 'VBN'), ('face', 'NN'), ('extracting', 'VBG'), ('set', 'VBN'), ('profile', 'JJ'), ('parameters', 'NNS'), ('corresponding', 'VBG'), ('person', 'NN'), ('first', 'JJ'), ('image', 'NN'), ('selecting', 'VBG'), ('plurality', 'NN'), ('image', 'NN'), ('tiles', 'NNS'), ('first', 'RB'), ('image', 'NN'), ('tile', 'NN'), ('matches', 'NNS'), ('face', 'VBP'), ('corresponding', 'VBG'), ('person', 'NN'), ('first', 'JJ'), ('image', 'NN'), ('accordance', 'NN'), ('predefined', 'VBD'), ('correspondence', 'NN'), ('set', 'VBN'), ('profile', 'JJ'), ('parameters', 'NNS'), ('corresponding', 'VBG'), ('person', 'NN'), ('set', 'VBN'), ('pre-stored', 'JJ'), ('description', 'NN'), ('parameters', 'NNS'), ('first', 'JJ'), ('image', 'NN'), ('tile', 'NN'), ('generating', 'VBG'), ('second', 'JJ'), ('image', 'NN'), ('covering', 'VBG'), ('faces', 'VBZ'), ('respective', 'JJ'), ('persons', 'NNS'), ('first', 'JJ'), ('image', 'NN'), ('corresponding', 'VBG'), ('first', 'JJ'), ('image', 'NN'), ('tiles', 'NNS'), ('sharing', 'VBG'), ('first', 'JJ'), ('image', 'NN'), ('second', 'JJ'), ('image', 'NN'), ('predefined', 'VBD'), ('order', 'NN'), ('via', 'IN'), ('group', 'NN'), ('chat', 'WP'), ('session', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('first', 'RB'), ('image', 'NN'), ('second', 'JJ'), ('image', 'NN'), ('displayed', 'VBD'), ('group', 'NN'), ('chat', 'WP'), ('session', 'NN'), ('one', 'CD'), ('image', 'NN'), ('time', 'NN'), ('one', 'CD'), ('two', 'CD'), ('images', 'NNS'), ('replaced', 'VBD'), ('two', 'CD'), ('images', 'NNS'), ('periodically', 'RB'), ('method', 'VBP'), ('claim', 'NN'), ('wherein', 'NN'), ('extracting', 'VBG'), ('set', 'VBN'), ('profile', 'JJ'), ('parameters', 'NNS'), ('corresponding', 'VBG'), ('person', 'NN'), ('first', 'JJ'), ('image', 'NN'), ('includes', 'VBZ'), ('determining', 'VBG'), ('one', 'CD'), ('descriptive', 'JJ'), ('labels', 'NNS'), ('corresponding', 'VBG'), ('identified', 'JJ'), ('face', 'NN'), ('corresponding', 'VBG'), ('person', 'NN'), ('using', 'VBG'), ('first', 'JJ'), ('machine', 'NN'), ('learning', 'VBG'), ('model', 'NN'), ('wherein', 'NN'), ('first', 'JJ'), ('machine', 'NN'), ('learning', 'VBG'), ('model', 'NN'), ('trained', 'VBD'), ('facial', 'JJ'), ('images', 'NNS'), ('corresponding', 'VBG'), ('descriptive', 'JJ'), ('labels', 'NNS'), ('method', 'VBP'), ('claim', 'NN'), ('wherein', 'NN'), ('extracting', 'VBG'), ('set', 'VBN'), ('profile', 'JJ'), ('parameters', 'NNS'), ('corresponding', 'VBG'), ('person', 'NN'), ('first', 'JJ'), ('image', 'NN'), ('includes', 'VBZ'), ('determining', 'VBG'), ('identity', 'NN'), ('corresponding', 'VBG'), ('person', 'NN'), ('based', 'VBN'), ('identified', 'JJ'), ('face', 'NN'), ('corresponding', 'VBG'), ('person', 'NN'), ('locating', 'VBG'), ('respective', 'JJ'), ('profile', 'NN'), ('information', 'NN'), ('first', 'RB'), ('person', 'NN'), ('based', 'VBN'), ('determined', 'VBN'), ('identity', 'NN'), ('corresponding', 'VBG'), ('person', 'NN'), ('using', 'VBG'), ('one', 'CD'), ('characteristics', 'NNS'), ('respective', 'JJ'), ('profile', 'JJ'), ('information', 'NN'), ('first', 'RB'), ('person', 'NN'), ('set', 'VBN'), ('profile', 'NN'), ('parameters', 'NNS'), ('corresponding', 'VBG'), ('identified', 'JJ'), ('face', 'NN'), ('corresponding', 'VBG'), ('person', 'NN'), ('method', 'JJ'), ('claim', 'NN'), ('wherein', 'NN'), ('least', 'VBD'), ('first', 'JJ'), ('one', 'CD'), ('first', 'JJ'), ('image', 'NN'), ('tiles', 'NNS'), ('dynamic', 'JJ'), ('image', 'NN'), ('tile', 'NN'), ('least', 'JJS'), ('second', 'JJ'), ('one', 'CD'), ('first', 'JJ'), ('image', 'NN'), ('tiles', 'NNS'), ('static', 'JJ'), ('image', 'NN'), ('tile', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('including', 'VBG'), ('receiving', 'VBG'), ('plurality', 'NN'), ('user', 'JJ'), ('comments', 'NNS'), ('different', 'JJ'), ('users', 'NNS'), ('group', 'NN'), ('chat', 'VBZ'), ('session', 'NN'), ('user', 'JJ'), ('comment', 'NN'), ('including', 'VBG'), ('descriptive', 'JJ'), ('term', 'NN'), ('respective', 'JJ'), ('person', 'NN'), ('identified', 'VBD'), ('first', 'JJ'), ('image', 'NN'), ('choosing', 'VBG'), ('descriptive', 'JJ'), ('label', 'NN'), ('respective', 'JJ'), ('person', 'NN'), ('according', 'VBG'), ('plurality', 'NN'), ('user', 'NN'), ('comments', 'NNS'), ('updating', 'VBG'), ('second', 'JJ'), ('image', 'NN'), ('adding', 'VBG'), ('descriptive', 'JJ'), ('label', 'NN'), ('adjacent', 'NN'), ('first', 'RB'), ('image', 'NN'), ('tile', 'NN'), ('respective', 'JJ'), ('person', 'NN'), ('computing', 'VBG'), ('device', 'NN'), ('image', 'NN'), ('information', 'NN'), ('processing', 'VBG'), ('comprising', 'VBG'), ('one', 'CD'), ('processors', 'NNS'), ('memory', 'NN'), ('storing', 'VBG'), ('instructions', 'NNS'), ('executed', 'VBD'), ('one', 'CD'), ('processors', 'NNS'), ('cause', 'VBP'), ('processors', 'NNS'), ('perform', 'VBP'), ('plurality', 'NN'), ('operations', 'NNS'), ('comprising', 'VBG'), ('identifying', 'VBG'), ('using', 'VBG'), ('face', 'NN'), ('recognition', 'NN'), ('one', 'CD'), ('faces', 'VBZ'), ('face', 'NN'), ('corresponding', 'VBG'), ('respective', 'JJ'), ('person', 'NN'), ('captured', 'VBD'), ('first', 'JJ'), ('image', 'NN'), ('identified', 'VBN'), ('face', 'NN'), ('extracting', 'VBG'), ('set', 'VBN'), ('profile', 'JJ'), ('parameters', 'NNS'), ('corresponding', 'VBG'), ('person', 'NN'), ('first', 'JJ'), ('image', 'NN'), ('selecting', 'VBG'), ('plurality', 'NN'), ('image', 'NN'), ('tiles', 'NNS'), ('first', 'RB'), ('image', 'NN'), ('tile', 'NN'), ('matches', 'NNS'), ('face', 'VBP'), ('corresponding', 'VBG'), ('person', 'NN'), ('first', 'JJ'), ('image', 'NN'), ('accordance', 'NN'), ('predefined', 'VBD'), ('correspondence', 'NN'), ('set', 'VBN'), ('profile', 'JJ'), ('parameters', 'NNS'), ('corresponding', 'VBG'), ('person', 'NN'), ('set', 'VBN'), ('pre-stored', 'JJ'), ('description', 'NN'), ('parameters', 'NNS'), ('first', 'JJ'), ('image', 'NN'), ('tile', 'NN'), ('generating', 'VBG'), ('second', 'JJ'), ('image', 'NN'), ('covering', 'VBG'), ('faces', 'VBZ'), ('respective', 'JJ'), ('persons', 'NNS'), ('first', 'JJ'), ('image', 'NN'), ('corresponding', 'VBG'), ('first', 'JJ'), ('image', 'NN'), ('tiles', 'NNS'), ('sharing', 'VBG'), ('first', 'JJ'), ('image', 'NN'), ('second', 'JJ'), ('image', 'NN'), ('predefined', 'VBD'), ('order', 'NN'), ('via', 'IN'), ('group', 'NN'), ('chat', 'WP'), ('session', 'NN'), ('computing', 'VBG'), ('device', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('first', 'RB'), ('image', 'NN'), ('second', 'JJ'), ('image', 'NN'), ('displayed', 'VBD'), ('group', 'NN'), ('chat', 'WP'), ('session', 'NN'), ('one', 'CD'), ('image', 'NN'), ('time', 'NN'), ('one', 'CD'), ('two', 'CD'), ('images', 'NNS'), ('replaced', 'VBD'), ('two', 'CD'), ('images', 'NNS'), ('periodically', 'RB'), ('computing', 'VBG'), ('device', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('extracting', 'VBG'), ('set', 'VBN'), ('profile', 'JJ'), ('parameters', 'NNS'), ('corresponding', 'VBG'), ('person', 'NN'), ('first', 'JJ'), ('image', 'NN'), ('includes', 'VBZ'), ('determining', 'VBG'), ('one', 'CD'), ('descriptive', 'JJ'), ('labels', 'NNS'), ('corresponding', 'VBG'), ('identified', 'JJ'), ('face', 'NN'), ('corresponding', 'VBG'), ('person', 'NN'), ('using', 'VBG'), ('first', 'JJ'), ('machine', 'NN'), ('learning', 'VBG'), ('model', 'NN'), ('wherein', 'NN'), ('first', 'JJ'), ('machine', 'NN'), ('learning', 'VBG'), ('model', 'NN'), ('trained', 'VBD'), ('facial', 'JJ'), ('images', 'NNS'), ('corresponding', 'VBG'), ('descriptive', 'JJ'), ('labels', 'NNS'), ('computing', 'VBG'), ('device', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('extracting', 'VBG'), ('set', 'VBN'), ('profile', 'JJ'), ('parameters', 'NNS'), ('corresponding', 'VBG'), ('person', 'NN'), ('first', 'JJ'), ('image', 'NN'), ('includes', 'VBZ'), ('determining', 'VBG'), ('identity', 'NN'), ('corresponding', 'VBG'), ('person', 'NN'), ('based', 'VBN'), ('identified', 'JJ'), ('face', 'NN'), ('corresponding', 'VBG'), ('person', 'NN'), ('locating', 'VBG'), ('respective', 'JJ'), ('profile', 'NN'), ('information', 'NN'), ('first', 'RB'), ('person', 'NN'), ('based', 'VBN'), ('determined', 'VBN'), ('identity', 'NN'), ('corresponding', 'VBG'), ('person', 'NN'), ('using', 'VBG'), ('one', 'CD'), ('characteristics', 'NNS'), ('respective', 'JJ'), ('profile', 'JJ'), ('information', 'NN'), ('first', 'RB'), ('person', 'NN'), ('set', 'VBN'), ('profile', 'NN'), ('parameters', 'NNS'), ('corresponding', 'VBG'), ('identified', 'JJ'), ('face', 'NN'), ('corresponding', 'VBG'), ('person', 'NN'), ('computing', 'VBG'), ('device', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('least', 'JJS'), ('first', 'JJ'), ('one', 'CD'), ('first', 'JJ'), ('image', 'NN'), ('tiles', 'NNS'), ('dynamic', 'JJ'), ('image', 'NN'), ('tile', 'NN'), ('least', 'JJS'), ('second', 'JJ'), ('one', 'CD'), ('first', 'JJ'), ('image', 'NN'), ('tiles', 'NNS'), ('static', 'JJ'), ('image', 'NN'), ('tile', 'NN'), ('computing', 'VBG'), ('device', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('plurality', 'NN'), ('operations', 'NNS'), ('include', 'VBP'), ('receiving', 'VBG'), ('plurality', 'NN'), ('user', 'JJ'), ('comments', 'NNS'), ('different', 'JJ'), ('users', 'NNS'), ('group', 'NN'), ('chat', 'VBZ'), ('session', 'NN'), ('user', 'JJ'), ('comment', 'NN'), ('including', 'VBG'), ('descriptive', 'JJ'), ('term', 'NN'), ('respective', 'JJ'), ('person', 'NN'), ('identified', 'VBD'), ('first', 'JJ'), ('image', 'NN'), ('choosing', 'VBG'), ('descriptive', 'JJ'), ('label', 'NN'), ('respective', 'JJ'), ('person', 'NN'), ('according', 'VBG'), ('plurality', 'NN'), ('user', 'NN'), ('comments', 'NNS'), ('updating', 'VBG'), ('second', 'JJ'), ('image', 'NN'), ('adding', 'VBG'), ('descriptive', 'JJ'), ('label', 'NN'), ('adjacent', 'NN'), ('first', 'RB'), ('image', 'NN'), ('tile', 'NN'), ('respective', 'JJ'), ('person', 'NN'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('storage', 'NN'), ('medium', 'NN'), ('storing', 'VBG'), ('instructions', 'NNS'), ('executed', 'VBD'), ('computing', 'VBG'), ('device', 'NN'), ('one', 'CD'), ('processors', 'NNS'), ('cause', 'VBP'), ('computing', 'VBG'), ('device', 'NN'), ('perform', 'NN'), ('plurality', 'NN'), ('operations', 'NNS'), ('comprising', 'VBG'), ('identifying', 'VBG'), ('using', 'VBG'), ('face', 'NN'), ('recognition', 'NN'), ('one', 'CD'), ('faces', 'VBZ'), ('face', 'NN'), ('corresponding', 'VBG'), ('respective', 'JJ'), ('person', 'NN'), ('captured', 'VBD'), ('first', 'JJ'), ('image', 'NN'), ('identified', 'VBN'), ('face', 'NN'), ('extracting', 'VBG'), ('set', 'VBN'), ('profile', 'JJ'), ('parameters', 'NNS'), ('corresponding', 'VBG'), ('person', 'NN'), ('first', 'JJ'), ('image', 'NN'), ('selecting', 'VBG'), ('plurality', 'NN'), ('image', 'NN'), ('tiles', 'NNS'), ('first', 'RB'), ('image', 'NN'), ('tile', 'NN'), ('matches', 'NNS'), ('face', 'VBP'), ('corresponding', 'VBG'), ('person', 'NN'), ('first', 'JJ'), ('image', 'NN'), ('accordance', 'NN'), ('predefined', 'VBD'), ('correspondence', 'NN'), ('set', 'VBN'), ('profile', 'JJ'), ('parameters', 'NNS'), ('corresponding', 'VBG'), ('person', 'NN'), ('set', 'VBN'), ('pre-stored', 'JJ'), ('description', 'NN'), ('parameters', 'NNS'), ('first', 'JJ'), ('image', 'NN'), ('tile', 'NN'), ('generating', 'VBG'), ('second', 'JJ'), ('image', 'NN'), ('covering', 'VBG'), ('faces', 'VBZ'), ('respective', 'JJ'), ('persons', 'NNS'), ('first', 'JJ'), ('image', 'NN'), ('corresponding', 'VBG'), ('first', 'JJ'), ('image', 'NN'), ('tiles', 'NNS'), ('sharing', 'VBG'), ('first', 'JJ'), ('image', 'NN'), ('second', 'JJ'), ('image', 'NN'), ('predefined', 'VBD'), ('order', 'NN'), ('via', 'IN'), ('group', 'NN'), ('chat', 'DT'), ('session', 'NN'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('storage', 'NN'), ('medium', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('first', 'RB'), ('image', 'NN'), ('second', 'JJ'), ('image', 'NN'), ('displayed', 'VBD'), ('group', 'NN'), ('chat', 'WP'), ('session', 'NN'), ('one', 'CD'), ('image', 'NN'), ('time', 'NN'), ('one', 'CD'), ('two', 'CD'), ('images', 'NNS'), ('replaced', 'VBD'), ('two', 'CD'), ('images', 'NNS'), ('periodically', 'RB'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('storage', 'NN'), ('medium', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('extracting', 'VBG'), ('set', 'VBN'), ('profile', 'JJ'), ('parameters', 'NNS'), ('corresponding', 'VBG'), ('person', 'NN'), ('first', 'JJ'), ('image', 'NN'), ('includes', 'VBZ'), ('determining', 'VBG'), ('one', 'CD'), ('descriptive', 'JJ'), ('labels', 'NNS'), ('corresponding', 'VBG'), ('identified', 'JJ'), ('face', 'NN'), ('corresponding', 'VBG'), ('person', 'NN'), ('using', 'VBG'), ('first', 'JJ'), ('machine', 'NN'), ('learning', 'VBG'), ('model', 'NN'), ('wherein', 'NN'), ('first', 'JJ'), ('machine', 'NN'), ('learning', 'VBG'), ('model', 'NN'), ('trained', 'VBD'), ('facial', 'JJ'), ('images', 'NNS'), ('corresponding', 'VBG'), ('descriptive', 'JJ'), ('labels', 'NNS'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('storage', 'NN'), ('medium', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('extracting', 'VBG'), ('set', 'VBN'), ('profile', 'JJ'), ('parameters', 'NNS'), ('corresponding', 'VBG'), ('person', 'NN'), ('first', 'JJ'), ('image', 'NN'), ('includes', 'VBZ'), ('determining', 'VBG'), ('identity', 'NN'), ('corresponding', 'VBG'), ('person', 'NN'), ('based', 'VBN'), ('identified', 'JJ'), ('face', 'NN'), ('corresponding', 'VBG'), ('person', 'NN'), ('locating', 'VBG'), ('respective', 'JJ'), ('profile', 'NN'), ('information', 'NN'), ('first', 'RB'), ('person', 'NN'), ('based', 'VBN'), ('determined', 'VBN'), ('identity', 'NN'), ('corresponding', 'VBG'), ('person', 'NN'), ('using', 'VBG'), ('one', 'CD'), ('characteristics', 'NNS'), ('respective', 'JJ'), ('profile', 'JJ'), ('information', 'NN'), ('first', 'RB'), ('person', 'NN'), ('set', 'VBN'), ('profile', 'NN'), ('parameters', 'NNS'), ('corresponding', 'VBG'), ('identified', 'JJ'), ('face', 'NN'), ('corresponding', 'VBG'), ('person', 'NN'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('storage', 'NN'), ('medium', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('least', 'JJS'), ('first', 'JJ'), ('one', 'CD'), ('first', 'JJ'), ('image', 'NN'), ('tiles', 'NNS'), ('dynamic', 'JJ'), ('image', 'NN'), ('tile', 'NN'), ('least', 'JJS'), ('second', 'JJ'), ('one', 'CD'), ('first', 'JJ'), ('image', 'NN'), ('tiles', 'NNS'), ('static', 'JJ'), ('image', 'NN'), ('tile', 'JJ'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('storage', 'NN'), ('medium', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('plurality', 'NN'), ('operations', 'NNS'), ('include', 'VBP'), ('receiving', 'VBG'), ('plurality', 'NN'), ('user', 'JJ'), ('comments', 'NNS'), ('different', 'JJ'), ('users', 'NNS'), ('group', 'NN'), ('chat', 'VBZ'), ('session', 'NN'), ('user', 'JJ'), ('comment', 'NN'), ('including', 'VBG'), ('descriptive', 'JJ'), ('term', 'NN'), ('respective', 'JJ'), ('person', 'NN'), ('identified', 'VBD'), ('first', 'JJ'), ('image', 'NN'), ('choosing', 'VBG'), ('descriptive', 'JJ'), ('label', 'NN'), ('respective', 'JJ'), ('person', 'NN'), ('according', 'VBG'), ('plurality', 'NN'), ('user', 'NN'), ('comments', 'NNS'), ('updating', 'VBG'), ('second', 'JJ'), ('image', 'NN'), ('adding', 'VBG'), ('descriptive', 'JJ'), ('label', 'NN'), ('adjacent', 'NN'), ('first', 'RB'), ('image', 'NN'), ('tile', 'NN'), ('respective', 'JJ'), ('person', 'NN'), ('method', 'NN'), ('comprising', 'VBG'), ('computing', 'VBG'), ('system', 'NN'), ('determining', 'VBG'), ('performance', 'NN'), ('metric', 'JJ'), ('eye', 'NN'), ('tracking', 'VBG'), ('system', 'NN'), ('first', 'JJ'), ('performance', 'NN'), ('threshold', 'NN'), ('wherein', 'NN'), ('eye', 'NN'), ('tracking', 'VBG'), ('system', 'NN'), ('associated', 'VBN'), ('head-mounted', 'JJ'), ('display', 'NN'), ('worn', 'VBN'), ('user', 'RB'), ('based', 'VBN'), ('determination', 'NN'), ('performance', 'NN'), ('metric', 'JJ'), ('eye', 'NN'), ('tracking', 'VBG'), ('system', 'NN'), ('first', 'JJ'), ('performance', 'NN'), ('threshold', 'VBN'), ('computer', 'NN'), ('system', 'NN'), ('performing', 'VBG'), ('receiving', 'VBG'), ('one', 'CD'), ('first', 'JJ'), ('inputs', 'NNS'), ('associated', 'VBN'), ('body', 'NN'), ('user', 'RBR'), ('estimating', 'VBG'), ('region', 'NN'), ('user', 'NN'), ('looking', 'VBG'), ('within', 'IN'), ('field', 'NN'), ('view', 'NN'), ('head-mounted', 'JJ'), ('display', 'NN'), ('based', 'VBN'), ('received', 'VBD'), ('one', 'CD'), ('first', 'JJ'), ('inputs', 'NNS'), ('associated', 'VBN'), ('body', 'NN'), ('user', 'RBR'), ('determining', 'VBG'), ('vergence', 'NN'), ('distance', 'NN'), ('user', 'NN'), ('based', 'VBN'), ('least', 'JJS'), ('one', 'CD'), ('first', 'JJ'), ('inputs', 'NNS'), ('associated', 'VBN'), ('body', 'NN'), ('user', 'RBR'), ('estimated', 'VBN'), ('region', 'NN'), ('user', 'RBR'), ('looking', 'VBG'), ('locations', 'NNS'), ('one', 'CD'), ('objects', 'VBZ'), ('scene', 'NN'), ('displayed', 'VBD'), ('head-mounted', 'JJ'), ('display', 'NN'), ('adjusting', 'VBG'), ('one', 'CD'), ('configurations', 'NNS'), ('head-mounted', 'JJ'), ('display', 'NN'), ('based', 'VBN'), ('determined', 'JJ'), ('vergence', 'NN'), ('distance', 'NN'), ('user', 'JJ'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('one', 'CD'), ('configurations', 'NNS'), ('head-mounted', 'JJ'), ('display', 'NN'), ('comprise', 'NN'), ('one', 'CD'), ('rendering', 'NN'), ('image', 'NN'), ('position', 'NN'), ('display', 'NN'), ('screen', 'JJ'), ('position', 'NN'), ('optics', 'NNS'), ('block', 'VBP'), ('method', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('determining', 'VBG'), ('performance', 'NN'), ('metric', 'JJ'), ('eye', 'NN'), ('tracking', 'VBG'), ('system', 'NN'), ('second', 'JJ'), ('performance', 'NN'), ('threshold', 'VBD'), ('receiving', 'VBG'), ('eye', 'NN'), ('tracking', 'VBG'), ('data', 'NNS'), ('eye', 'NN'), ('tracking', 'VBG'), ('system', 'NN'), ('determining', 'VBG'), ('vergence', 'NN'), ('distance', 'NN'), ('user', 'NN'), ('based', 'VBN'), ('eye', 'NN'), ('tracking', 'VBG'), ('data', 'NNS'), ('one', 'CD'), ('first', 'JJ'), ('inputs', 'NNS'), ('associated', 'VBN'), ('body', 'NN'), ('user', 'JJ'), ('method', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('receiving', 'VBG'), ('one', 'CD'), ('second', 'JJ'), ('inputs', 'NNS'), ('associated', 'VBD'), ('one', 'CD'), ('displaying', 'NN'), ('elements', 'NNS'), ('scene', 'VBP'), ('displayed', 'VBN'), ('head-mounted', 'JJ'), ('display', 'NN'), ('determining', 'VBG'), ('vergence', 'NN'), ('distance', 'NN'), ('user', 'NN'), ('based', 'VBN'), ('least', 'JJS'), ('eye', 'NN'), ('tracking', 'VBG'), ('data', 'NNS'), ('one', 'CD'), ('first', 'JJ'), ('inputs', 'NNS'), ('associated', 'VBN'), ('body', 'NN'), ('user', 'JJ'), ('one', 'CD'), ('second', 'NN'), ('inputs', 'NNS'), ('associated', 'VBD'), ('one', 'CD'), ('displaying', 'NN'), ('elements', 'NNS'), ('scene', 'VBP'), ('method', 'JJ'), ('claim', 'NN'), ('comprising', 'VBG'), ('feeding', 'VBG'), ('one', 'CD'), ('first', 'JJ'), ('inputs', 'NNS'), ('associated', 'VBN'), ('body', 'NN'), ('user', 'JJ'), ('fusion', 'NN'), ('algorithm', 'NN'), ('wherein', 'WRB'), ('fusion', 'NN'), ('algorithm', 'NN'), ('assigns', 'NNS'), ('weight', 'VBD'), ('score', 'RB'), ('input', 'JJ'), ('one', 'CD'), ('first', 'JJ'), ('inputs', 'VBZ'), ('determining', 'VBG'), ('vergence', 'NN'), ('distance', 'NN'), ('user', 'NN'), ('using', 'VBG'), ('fusion', 'NN'), ('algorithm', 'NNS'), ('based', 'VBN'), ('one', 'CD'), ('first', 'JJ'), ('inputs', 'NNS'), ('associated', 'VBN'), ('body', 'NN'), ('user', 'JJ'), ('determining', 'VBG'), ('z-depth', 'JJ'), ('display', 'NN'), ('screen', 'NN'), ('confidence', 'NN'), ('score', 'NN'), ('based', 'VBN'), ('one', 'CD'), ('first', 'JJ'), ('inputs', 'NNS'), ('associated', 'VBN'), ('body', 'NN'), ('user', 'JJ'), ('method', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('comparing', 'VBG'), ('confidence', 'NN'), ('score', 'NN'), ('confidence', 'NN'), ('level', 'NN'), ('threshold', 'JJ'), ('response', 'NN'), ('determination', 'NN'), ('confidence', 'NN'), ('score', 'NN'), ('confidence', 'NN'), ('level', 'NN'), ('threshold', 'VBD'), ('feeding', 'VBG'), ('one', 'CD'), ('second', 'JJ'), ('inputs', 'NNS'), ('associated', 'VBD'), ('one', 'CD'), ('displaying', 'NN'), ('elements', 'NNS'), ('scene', 'JJ'), ('fusion', 'NN'), ('algorithm', 'IN'), ('determining', 'VBG'), ('z-depth', 'JJ'), ('display', 'NN'), ('screen', 'NN'), ('using', 'VBG'), ('fusion', 'NN'), ('algorithm', 'NNS'), ('based', 'VBN'), ('one', 'CD'), ('first', 'JJ'), ('inputs', 'NNS'), ('associated', 'VBN'), ('body', 'NN'), ('user', 'JJ'), ('one', 'CD'), ('second', 'NN'), ('inputs', 'NNS'), ('associated', 'VBD'), ('one', 'CD'), ('displaying', 'NN'), ('elements', 'NNS'), ('scene', 'VBP'), ('method', 'JJ'), ('claim', 'NN'), ('comparing', 'VBG'), ('comparing', 'VBG'), ('fusion', 'NN'), ('algorithm', 'NN'), ('confidence', 'NN'), ('scores', 'NNS'), ('associated', 'VBN'), ('plurality', 'NN'), ('combinations', 'NNS'), ('inputs', 'VBP'), ('determining', 'VBG'), ('fusion', 'NN'), ('algorithm', 'IN'), ('z-depth', 'JJ'), ('display', 'NN'), ('screen', 'NN'), ('based', 'VBN'), ('combination', 'NN'), ('inputs', 'NNS'), ('associated', 'VBN'), ('highest', 'JJS'), ('confidence', 'NN'), ('score', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('z-depth', 'JJ'), ('confidence', 'NN'), ('score', 'NN'), ('determined', 'VBD'), ('fusion', 'NN'), ('algorithm', 'IN'), ('using', 'VBG'), ('piecewise', 'NN'), ('comparison', 'NN'), ('one', 'CD'), ('first', 'JJ'), ('inputs', 'VBZ'), ('one', 'CD'), ('second', 'NN'), ('inputs', 'VBZ'), ('method', 'JJ'), ('claim', 'NN'), ('wherein', 'IN'), ('z-depth', 'JJ'), ('confidence', 'NN'), ('score', 'NN'), ('determined', 'VBD'), ('based', 'VBN'), ('correlation', 'NN'), ('two', 'CD'), ('inputs', 'NNS'), ('one', 'CD'), ('first', 'JJ'), ('inputs', 'VBZ'), ('one', 'CD'), ('second', 'NN'), ('inputs', 'VBZ'), ('method', 'JJ'), ('claim', 'NN'), ('wherein', 'NN'), ('fusion', 'NN'), ('algorithm', 'NN'), ('comprises', 'VBZ'), ('machine', 'NN'), ('learning', 'VBG'), ('ml', 'JJ'), ('algorithm', 'JJ'), ('wherein', 'NN'), ('machine', 'NN'), ('learning', 'VBG'), ('ml', 'JJ'), ('algorithm', 'JJ'), ('determines', 'NNS'), ('combination', 'NN'), ('first', 'RB'), ('inputs', 'VBZ'), ('fed', 'JJ'), ('fusion', 'NN'), ('algorithm', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('one', 'CD'), ('first', 'JJ'), ('inputs', 'NNS'), ('associated', 'VBN'), ('body', 'NN'), ('user', 'JJ'), ('comprise', 'NN'), ('one', 'CD'), ('hand', 'NN'), ('position', 'NN'), ('hand', 'NN'), ('direction', 'NN'), ('hand', 'NN'), ('movement', 'NN'), ('hand', 'NN'), ('gesture', 'NN'), ('head', 'NN'), ('position', 'NN'), ('head', 'NN'), ('direction', 'NN'), ('head', 'NN'), ('movement', 'NN'), ('head', 'NN'), ('gesture', 'NN'), ('gaze', 'NN'), ('angle', 'VBP'), ('rea', 'NN'), ('body', 'NN'), ('gesture', 'NN'), ('body', 'NN'), ('posture', 'NN'), ('body', 'NN'), ('movement', 'NN'), ('behavior', 'IN'), ('user', 'NN'), ('weighted', 'VBN'), ('combination', 'NN'), ('one', 'CD'), ('related', 'JJ'), ('parameters', 'NNS'), ('method', 'VBP'), ('claim', 'NN'), ('wherein', 'NN'), ('one', 'CD'), ('first', 'JJ'), ('inputs', 'NNS'), ('associated', 'VBN'), ('body', 'NN'), ('user', 'NN'), ('received', 'VBD'), ('one', 'CD'), ('controller', 'NN'), ('sensor', 'NN'), ('camera', 'NN'), ('microphone', 'NN'), ('accelerometer', 'NN'), ('headset', 'VBN'), ('worn', 'JJ'), ('user', 'NN'), ('mobile', 'JJ'), ('device', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'VBP'), ('one', 'CD'), ('second', 'JJ'), ('inputs', 'NNS'), ('associated', 'VBD'), ('one', 'CD'), ('displaying', 'NN'), ('elements', 'NNS'), ('comprise', 'VBP'), ('one', 'CD'), ('z-buffer', 'NN'), ('value', 'NN'), ('associated', 'VBN'), ('displaying', 'VBG'), ('element', 'NN'), ('displaying', 'VBG'), ('element', 'NN'), ('marked', 'VBD'), ('developer', 'JJ'), ('image', 'NN'), ('analysis', 'NN'), ('result', 'NN'), ('shape', 'NN'), ('displaying', 'VBG'), ('element', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('result', 'NN'), ('object', 'JJ'), ('recognition', 'NN'), ('result', 'NN'), ('person', 'NN'), ('identified', 'VBD'), ('displaying', 'VBG'), ('content', 'NN'), ('object', 'NN'), ('identified', 'VBD'), ('displaying', 'VBG'), ('content', 'JJ'), ('correlation', 'NN'), ('two', 'CD'), ('displaying', 'VBG'), ('elements', 'NNS'), ('weighted', 'VBN'), ('combination', 'NN'), ('one', 'CD'), ('second', 'NN'), ('inputs', 'VBZ'), ('method', 'JJ'), ('claim', 'NN'), ('comprising', 'VBG'), ('determining', 'VBG'), ('performance', 'NN'), ('metric', 'JJ'), ('eye', 'NN'), ('tracking', 'VBG'), ('system', 'NN'), ('second', 'JJ'), ('performance', 'NN'), ('threshold', 'VBD'), ('receiving', 'VBG'), ('one', 'CD'), ('second', 'JJ'), ('inputs', 'NNS'), ('associated', 'VBD'), ('one', 'CD'), ('displaying', 'NN'), ('elements', 'NNS'), ('scene', 'VBP'), ('displayed', 'VBN'), ('head-mounted', 'JJ'), ('display', 'NN'), ('determining', 'VBG'), ('vergence', 'NN'), ('distance', 'NN'), ('user', 'NN'), ('based', 'VBN'), ('least', 'JJS'), ('one', 'CD'), ('first', 'JJ'), ('inputs', 'NNS'), ('associated', 'VBN'), ('body', 'NN'), ('user', 'JJ'), ('one', 'CD'), ('second', 'NN'), ('inputs', 'NNS'), ('associated', 'VBD'), ('one', 'CD'), ('displaying', 'NN'), ('elements', 'NNS'), ('method', 'VBP'), ('claim', 'NN'), ('wherein', 'NN'), ('determining', 'VBG'), ('performance', 'NN'), ('metric', 'JJ'), ('eye', 'NN'), ('tracking', 'VBG'), ('system', 'NN'), ('second', 'JJ'), ('performance', 'NN'), ('threshold', 'NN'), ('comprises', 'VBZ'), ('determining', 'VBG'), ('eye', 'NN'), ('tracking', 'VBG'), ('system', 'NN'), ('exist', 'VBP'), ('fails', 'NNS'), ('provide', 'VBP'), ('eye', 'NN'), ('tracking', 'VBG'), ('data', 'NNS'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('performance', 'NN'), ('metric', 'JJ'), ('eye', 'NN'), ('tracking', 'VBG'), ('system', 'NN'), ('comprises', 'VBZ'), ('one', 'CD'), ('accuracy', 'NN'), ('parameter', 'NN'), ('eye', 'NN'), ('tracking', 'VBG'), ('system', 'NN'), ('precision', 'NN'), ('parameter', 'NN'), ('eye', 'NN'), ('tracking', 'VBG'), ('system', 'NN'), ('value', 'NN'), ('parameter', 'NN'), ('eye', 'NN'), ('tracking', 'VBG'), ('system', 'NN'), ('detectability', 'NN'), ('pupil', 'VBP'), ('metric', 'JJ'), ('based', 'VBN'), ('one', 'CD'), ('parameters', 'NNS'), ('associated', 'VBN'), ('user', 'JJ'), ('parameter', 'NN'), ('change', 'NN'), ('parameter', 'NN'), ('changing', 'VBG'), ('trend', 'NN'), ('data', 'NNS'), ('availability', 'NN'), ('weighted', 'VBD'), ('combination', 'NN'), ('one', 'CD'), ('performance', 'NN'), ('related', 'JJ'), ('parameters', 'NNS'), ('method', 'VBP'), ('claim', 'NN'), ('wherein', 'VBP'), ('one', 'CD'), ('parameters', 'NNS'), ('associated', 'VBN'), ('user', 'RB'), ('comprise', 'VB'), ('one', 'CD'), ('eye', 'NN'), ('distance', 'NN'), ('user', 'NN'), ('pupil', 'NN'), ('position', 'NN'), ('pupil', 'NN'), ('status', 'NN'), ('correlation', 'NN'), ('two', 'CD'), ('pupils', 'NNS'), ('user', 'JJ'), ('head', 'NN'), ('size', 'NN'), ('user', 'JJ'), ('position', 'NN'), ('headset', 'NN'), ('worn', 'JJ'), ('user', 'NN'), ('angle', 'NN'), ('headset', 'NN'), ('worn', 'WRB'), ('user', 'JJ'), ('direction', 'NN'), ('headset', 'NN'), ('worn', 'WRB'), ('user', 'NN'), ('alignment', 'JJ'), ('eyes', 'NNS'), ('user', 'RB'), ('weighted', 'VBD'), ('combination', 'NN'), ('one', 'CD'), ('related', 'JJ'), ('parameters', 'NNS'), ('associated', 'VBN'), ('user', 'JJ'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('first', 'JJ'), ('performance', 'NN'), ('threshold', 'NN'), ('comprises', 'VBZ'), ('one', 'CD'), ('pre-determined', 'JJ'), ('value', 'NN'), ('pre-determined', 'JJ'), ('range', 'NN'), ('state', 'NN'), ('data', 'NNS'), ('changing', 'VBG'), ('speed', 'NN'), ('data', 'NNS'), ('trend', 'NN'), ('data', 'NNS'), ('change', 'VBP'), ('one', 'CD'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('storage', 'NN'), ('media', 'NNS'), ('embodying', 'VBG'), ('software', 'NN'), ('operable', 'JJ'), ('executed', 'VBN'), ('computing', 'NN'), ('system', 'NN'), ('determine', 'JJ'), ('performance', 'NN'), ('metric', 'JJ'), ('eye', 'NN'), ('tracking', 'VBG'), ('system', 'NN'), ('first', 'JJ'), ('performance', 'NN'), ('threshold', 'NN'), ('wherein', 'NN'), ('eye', 'NN'), ('tracking', 'VBG'), ('system', 'NN'), ('associated', 'VBN'), ('head-mounted', 'JJ'), ('display', 'NN'), ('worn', 'VBN'), ('user', 'RB'), ('based', 'VBN'), ('determination', 'NN'), ('performance', 'NN'), ('metric', 'JJ'), ('eye', 'NN'), ('tracking', 'VBG'), ('system', 'NN'), ('first', 'JJ'), ('performance', 'NN'), ('threshold', 'JJ'), ('media', 'NNS'), ('embodying', 'VBG'), ('software', 'NN'), ('operable', 'JJ'), ('executed', 'VBN'), ('computing', 'VBG'), ('system', 'NN'), ('receive', 'VBP'), ('one', 'CD'), ('first', 'JJ'), ('inputs', 'NNS'), ('associated', 'VBN'), ('body', 'NN'), ('user', 'JJ'), ('estimate', 'NN'), ('region', 'NN'), ('user', 'IN'), ('looking', 'VBG'), ('within', 'IN'), ('field', 'NN'), ('view', 'NN'), ('head-mounted', 'JJ'), ('display', 'NN'), ('based', 'VBN'), ('received', 'VBD'), ('one', 'CD'), ('first', 'JJ'), ('inputs', 'NNS'), ('associated', 'VBN'), ('body', 'NN'), ('user', 'JJ'), ('determine', 'JJ'), ('vergence', 'NN'), ('distance', 'NN'), ('user', 'NN'), ('based', 'VBN'), ('least', 'JJS'), ('one', 'CD'), ('first', 'JJ'), ('inputs', 'NNS'), ('associated', 'VBN'), ('body', 'NN'), ('user', 'RBR'), ('estimated', 'VBN'), ('region', 'NN'), ('user', 'RBR'), ('looking', 'VBG'), ('locations', 'NNS'), ('one', 'CD'), ('objects', 'VBZ'), ('scene', 'NN'), ('displayed', 'VBD'), ('head-mounted', 'JJ'), ('display', 'NN'), ('adjust', 'VBP'), ('one', 'CD'), ('configurations', 'NNS'), ('head-mounted', 'JJ'), ('display', 'NN'), ('based', 'VBN'), ('determined', 'JJ'), ('vergence', 'NN'), ('distance', 'NN'), ('user', 'NN'), ('system', 'NN'), ('comprising', 'VBG'), ('one', 'CD'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('storage', 'NN'), ('media', 'NNS'), ('embodying', 'VBG'), ('instructions', 'NNS'), ('one', 'CD'), ('processors', 'NNS'), ('coupled', 'VBD'), ('storage', 'NN'), ('media', 'NNS'), ('operable', 'JJ'), ('execute', 'JJ'), ('instructions', 'NNS'), ('determine', 'VBP'), ('performance', 'NN'), ('metric', 'JJ'), ('eye', 'NN'), ('tracking', 'VBG'), ('system', 'NN'), ('first', 'JJ'), ('performance', 'NN'), ('threshold', 'NN'), ('wherein', 'NN'), ('eye', 'NN'), ('tracking', 'VBG'), ('system', 'NN'), ('associated', 'VBN'), ('head-mounted', 'JJ'), ('display', 'NN'), ('worn', 'VBN'), ('user', 'RB'), ('based', 'VBN'), ('determination', 'NN'), ('performance', 'NN'), ('metric', 'JJ'), ('eye', 'NN'), ('tracking', 'VBG'), ('system', 'NN'), ('first', 'JJ'), ('performance', 'NN'), ('threshold', 'NN'), ('system', 'NN'), ('configured', 'VBD'), ('receive', 'JJ'), ('one', 'CD'), ('first', 'JJ'), ('inputs', 'NNS'), ('associated', 'VBN'), ('body', 'NN'), ('user', 'JJ'), ('estimate', 'NN'), ('region', 'NN'), ('user', 'IN'), ('looking', 'VBG'), ('within', 'IN'), ('field', 'NN'), ('view', 'NN'), ('head-mounted', 'JJ'), ('display', 'NN'), ('based', 'VBN'), ('received', 'VBD'), ('one', 'CD'), ('first', 'JJ'), ('inputs', 'NNS'), ('associated', 'VBN'), ('body', 'NN'), ('user', 'JJ'), ('determine', 'JJ'), ('vergence', 'NN'), ('distance', 'NN'), ('user', 'NN'), ('based', 'VBN'), ('least', 'JJS'), ('one', 'CD'), ('first', 'JJ'), ('inputs', 'NNS'), ('associated', 'VBN'), ('body', 'NN'), ('user', 'RBR'), ('estimated', 'VBN'), ('region', 'NN'), ('user', 'RBR'), ('looking', 'VBG'), ('locations', 'NNS'), ('one', 'CD'), ('objects', 'VBZ'), ('scene', 'NN'), ('displayed', 'VBD'), ('head-mounted', 'JJ'), ('display', 'NN'), ('adjust', 'VBP'), ('one', 'CD'), ('configurations', 'NNS'), ('head-mounted', 'JJ'), ('display', 'NN'), ('based', 'VBN'), ('determined', 'JJ'), ('vergence', 'NN'), ('distance', 'NN'), ('user', 'JJ'), ('computer-implemented', 'JJ'), ('method', 'NN'), ('image-based', 'JJ'), ('self-guided', 'JJ'), ('object', 'JJ'), ('detection', 'NN'), ('comprising', 'VBG'), ('receiving', 'VBG'), ('processor', 'NN'), ('device', 'NN'), ('set', 'VBN'), ('images', 'NNS'), ('images', 'NNS'), ('respective', 'VBP'), ('grid', 'JJ'), ('thereon', 'NN'), ('labeled', 'VBD'), ('regarding', 'VBG'), ('respective', 'JJ'), ('object', 'NN'), ('detected', 'VBD'), ('using', 'VBG'), ('grid', 'JJ'), ('level', 'NN'), ('label', 'NN'), ('data', 'NNS'), ('training', 'NN'), ('processor', 'NN'), ('device', 'NN'), ('grid-based', 'JJ'), ('object', 'NN'), ('detector', 'NN'), ('using', 'VBG'), ('grid', 'JJ'), ('level', 'NN'), ('label', 'NN'), ('data', 'NNS'), ('determining', 'VBG'), ('processor', 'NN'), ('device', 'NN'), ('respective', 'NN'), ('bounding', 'VBG'), ('box', 'NN'), ('respective', 'JJ'), ('object', 'JJ'), ('images', 'NNS'), ('applying', 'VBG'), ('local', 'JJ'), ('segmentation', 'NN'), ('images', 'NNS'), ('training', 'VBG'), ('processor', 'JJ'), ('device', 'NN'), ('region-based', 'JJ'), ('convolutional', 'JJ'), ('neural', 'JJ'), ('network', 'NN'), ('rcnn', 'NN'), ('joint', 'NN'), ('object', 'JJ'), ('localization', 'NN'), ('object', 'NN'), ('classification', 'NN'), ('using', 'VBG'), ('respective', 'JJ'), ('bounding', 'NN'), ('box', 'NN'), ('respective', 'JJ'), ('object', 'JJ'), ('images', 'NNS'), ('input', 'VBP'), ('rcnn', 'JJ'), ('computer-implemented', 'JJ'), ('method', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('performing', 'VBG'), ('action', 'NN'), ('responsive', 'JJ'), ('object', 'NN'), ('localization', 'NN'), ('object', 'JJ'), ('classification', 'NN'), ('respective', 'JJ'), ('new', 'JJ'), ('object', 'JJ'), ('new', 'JJ'), ('image', 'NN'), ('rcnn', 'NN'), ('applied', 'VBD'), ('computer-implemented', 'JJ'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'WRB'), ('action', 'NN'), ('comprises', 'VBZ'), ('autonomously', 'RB'), ('controlling', 'VBG'), ('motor', 'NN'), ('vehicle', 'NN'), ('avoid', 'VBP'), ('collision', 'NN'), ('new', 'JJ'), ('object', 'JJ'), ('responsive', 'JJ'), ('object', 'NN'), ('localization', 'NN'), ('object', 'JJ'), ('classification', 'NN'), ('respective', 'JJ'), ('new', 'JJ'), ('object', 'JJ'), ('computer-implemented', 'JJ'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'VBD'), ('local', 'JJ'), ('segmentation', 'NN'), ('performed', 'VBD'), ('using', 'VBG'), ('self-similarity', 'JJ'), ('search', 'NN'), ('template', 'NN'), ('matching', 'VBG'), ('provide', 'RB'), ('respective', 'JJ'), ('bounding', 'VBG'), ('box', 'NN'), ('around', 'IN'), ('respective', 'JJ'), ('object', 'NN'), ('set', 'VBN'), ('images', 'NNS'), ('computer-implemented', 'JJ'), ('method', 'JJ'), ('claim', 'NN'), ('wherein', 'VBD'), ('local', 'JJ'), ('segmentation', 'NN'), ('applied', 'VBD'), ('images', 'NNS'), ('segment', 'NN'), ('respective', 'JJ'), ('target', 'NN'), ('region', 'NN'), ('therein', 'IN'), ('computer-implemented', 'JJ'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('region-based', 'JJ'), ('convolutional', 'JJ'), ('neural', 'JJ'), ('network', 'NN'), ('rcnn', 'NN'), ('forms', 'NNS'), ('model', 'VBP'), ('object', 'JJ'), ('training', 'NN'), ('stage', 'NN'), ('detect', 'JJ'), ('objects', 'VBZ'), ('new', 'JJ'), ('images', 'NNS'), ('inference', 'NN'), ('stage', 'NN'), ('computer-implemented', 'JJ'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('method', 'NN'), ('performed', 'VBD'), ('system', 'NN'), ('selected', 'VBN'), ('group', 'NN'), ('consisting', 'VBG'), ('surveillance', 'NN'), ('system', 'NN'), ('face', 'NN'), ('detection', 'NN'), ('system', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('system', 'NN'), ('cancer', 'NN'), ('detection', 'NN'), ('system', 'NN'), ('object', 'VBP'), ('tracking', 'VBG'), ('system', 'NN'), ('advanced', 'VBD'), ('driver-assistance', 'NN'), ('system', 'NN'), ('computer', 'NN'), ('program', 'NN'), ('product', 'NN'), ('image-based', 'JJ'), ('self-guided', 'JJ'), ('object', 'NN'), ('detection', 'NN'), ('computer', 'NN'), ('program', 'NN'), ('product', 'NN'), ('comprising', 'VBG'), ('non-transitory', 'JJ'), ('computer', 'NN'), ('readable', 'JJ'), ('storage', 'NN'), ('medium', 'NN'), ('program', 'NN'), ('instructions', 'NNS'), ('embodied', 'VBD'), ('therewith', 'JJ'), ('program', 'NN'), ('instructions', 'NNS'), ('executable', 'JJ'), ('computer', 'NN'), ('cause', 'NN'), ('computer', 'NN'), ('perform', 'NN'), ('method', 'NN'), ('comprising', 'VBG'), ('receiving', 'VBG'), ('processor', 'NN'), ('device', 'NN'), ('set', 'VBN'), ('images', 'NNS'), ('images', 'NNS'), ('respective', 'VBP'), ('grid', 'JJ'), ('thereon', 'NN'), ('labeled', 'VBD'), ('regarding', 'VBG'), ('respective', 'JJ'), ('object', 'NN'), ('detected', 'VBD'), ('using', 'VBG'), ('grid', 'JJ'), ('level', 'NN'), ('label', 'NN'), ('data', 'NNS'), ('training', 'NN'), ('processor', 'NN'), ('device', 'NN'), ('grid-based', 'JJ'), ('object', 'NN'), ('detector', 'NN'), ('using', 'VBG'), ('grid', 'JJ'), ('level', 'NN'), ('label', 'NN'), ('data', 'NNS'), ('determining', 'VBG'), ('processor', 'NN'), ('device', 'NN'), ('respective', 'NN'), ('bounding', 'VBG'), ('box', 'NN'), ('respective', 'JJ'), ('object', 'JJ'), ('images', 'NNS'), ('applying', 'VBG'), ('local', 'JJ'), ('segmentation', 'NN'), ('images', 'NNS'), ('training', 'VBG'), ('processor', 'JJ'), ('device', 'NN'), ('region-based', 'JJ'), ('convolutional', 'JJ'), ('neural', 'JJ'), ('network', 'NN'), ('rcnn', 'NN'), ('joint', 'NN'), ('object', 'JJ'), ('localization', 'NN'), ('object', 'NN'), ('classification', 'NN'), ('using', 'VBG'), ('respective', 'JJ'), ('bounding', 'NN'), ('box', 'NN'), ('respective', 'JJ'), ('object', 'JJ'), ('images', 'NNS'), ('input', 'VBP'), ('rcnn', 'JJ'), ('computer', 'NN'), ('program', 'NN'), ('product', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('method', 'NN'), ('comprises', 'VBZ'), ('performing', 'VBG'), ('action', 'NN'), ('responsive', 'JJ'), ('object', 'NN'), ('localization', 'NN'), ('object', 'JJ'), ('classification', 'NN'), ('respective', 'JJ'), ('new', 'JJ'), ('object', 'JJ'), ('new', 'JJ'), ('image', 'NN'), ('rcnn', 'NN'), ('applied', 'VBN'), ('computer', 'NN'), ('program', 'NN'), ('product', 'NN'), ('claim', 'NN'), ('wherein', 'JJ'), ('action', 'NN'), ('comprises', 'VBZ'), ('autonomously', 'RB'), ('controlling', 'VBG'), ('motor', 'NN'), ('vehicle', 'NN'), ('avoid', 'VBP'), ('collision', 'NN'), ('new', 'JJ'), ('object', 'JJ'), ('responsive', 'JJ'), ('object', 'NN'), ('localization', 'NN'), ('object', 'JJ'), ('classification', 'NN'), ('respective', 'JJ'), ('new', 'JJ'), ('object', 'JJ'), ('computer', 'NN'), ('program', 'NN'), ('product', 'NN'), ('claim', 'NN'), ('wherein', 'JJ'), ('local', 'JJ'), ('segmentation', 'NN'), ('performed', 'VBD'), ('using', 'VBG'), ('self-similarity', 'JJ'), ('search', 'NN'), ('template', 'NN'), ('matching', 'VBG'), ('provide', 'RB'), ('respective', 'JJ'), ('bounding', 'VBG'), ('box', 'NN'), ('around', 'IN'), ('respective', 'JJ'), ('object', 'NN'), ('set', 'VBN'), ('images', 'NNS'), ('computer', 'NN'), ('program', 'NN'), ('product', 'NN'), ('claim', 'NN'), ('wherein', 'JJ'), ('local', 'JJ'), ('segmentation', 'NN'), ('applied', 'VBD'), ('images', 'NNS'), ('segment', 'NN'), ('respective', 'JJ'), ('target', 'NN'), ('region', 'NN'), ('therein', 'JJ'), ('computer', 'NN'), ('program', 'NN'), ('product', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('region-based', 'JJ'), ('convolutional', 'JJ'), ('neural', 'JJ'), ('network', 'NN'), ('rcnn', 'NN'), ('forms', 'NNS'), ('model', 'VBP'), ('object', 'JJ'), ('training', 'NN'), ('stage', 'NN'), ('detect', 'JJ'), ('objects', 'VBZ'), ('new', 'JJ'), ('images', 'NNS'), ('inference', 'NN'), ('stage', 'NN'), ('computer', 'NN'), ('program', 'NN'), ('product', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('method', 'NN'), ('performed', 'VBD'), ('system', 'NN'), ('selected', 'VBN'), ('group', 'NN'), ('consisting', 'VBG'), ('surveillance', 'NN'), ('system', 'NN'), ('face', 'NN'), ('detection', 'NN'), ('system', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('system', 'NN'), ('cancer', 'NN'), ('detection', 'NN'), ('system', 'NN'), ('object', 'VBP'), ('tracking', 'VBG'), ('system', 'NN'), ('advanced', 'VBD'), ('driver-assistance', 'NN'), ('system', 'NN'), ('computer', 'NN'), ('processing', 'VBG'), ('system', 'NN'), ('image-based', 'JJ'), ('self-guided', 'JJ'), ('object', 'JJ'), ('detection', 'NN'), ('comprising', 'VBG'), ('memory', 'NN'), ('device', 'NN'), ('storing', 'VBG'), ('program', 'NN'), ('code', 'NN'), ('processor', 'NN'), ('device', 'NN'), ('running', 'VBG'), ('program', 'NN'), ('code', 'NN'), ('receive', 'VBP'), ('set', 'VBN'), ('images', 'NNS'), ('images', 'NNS'), ('respective', 'VBP'), ('grid', 'JJ'), ('thereon', 'NN'), ('labeled', 'VBD'), ('regarding', 'VBG'), ('respective', 'JJ'), ('object', 'NN'), ('detected', 'VBD'), ('using', 'VBG'), ('grid', 'JJ'), ('level', 'NN'), ('label', 'NN'), ('data', 'NNS'), ('train', 'VBP'), ('grid-based', 'JJ'), ('object', 'NN'), ('detector', 'NN'), ('using', 'VBG'), ('grid', 'JJ'), ('level', 'NN'), ('label', 'NN'), ('data', 'NNS'), ('determine', 'VBP'), ('respective', 'JJ'), ('bounding', 'NN'), ('box', 'NN'), ('respective', 'JJ'), ('object', 'JJ'), ('images', 'NNS'), ('applying', 'VBG'), ('local', 'JJ'), ('segmentation', 'NN'), ('images', 'NNS'), ('train', 'VBP'), ('region-based', 'JJ'), ('convolutional', 'JJ'), ('neural', 'JJ'), ('network', 'NN'), ('rcnn', 'NN'), ('joint', 'NN'), ('object', 'JJ'), ('localization', 'NN'), ('object', 'NN'), ('classification', 'NN'), ('using', 'VBG'), ('respective', 'JJ'), ('bounding', 'NN'), ('box', 'NN'), ('respective', 'JJ'), ('object', 'JJ'), ('images', 'NNS'), ('input', 'VBP'), ('rcnn', 'RB'), ('computer', 'NN'), ('processing', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('processor', 'NN'), ('device', 'NN'), ('runs', 'VBZ'), ('program', 'NN'), ('code', 'NN'), ('perform', 'VB'), ('action', 'NN'), ('responsive', 'JJ'), ('object', 'NN'), ('localization', 'NN'), ('object', 'JJ'), ('classification', 'NN'), ('respective', 'JJ'), ('new', 'JJ'), ('object', 'JJ'), ('new', 'JJ'), ('image', 'NN'), ('rcnn', 'NN'), ('applied', 'VBD'), ('computer', 'NN'), ('processing', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'WRB'), ('action', 'NN'), ('comprises', 'VBZ'), ('autonomously', 'RB'), ('controlling', 'VBG'), ('motor', 'NN'), ('vehicle', 'NN'), ('avoid', 'VBP'), ('collision', 'NN'), ('new', 'JJ'), ('object', 'JJ'), ('responsive', 'JJ'), ('object', 'NN'), ('localization', 'NN'), ('object', 'JJ'), ('classification', 'NN'), ('respective', 'JJ'), ('new', 'JJ'), ('object', 'JJ'), ('computer', 'NN'), ('processing', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'RB'), ('local', 'JJ'), ('segmentation', 'NN'), ('performed', 'VBD'), ('using', 'VBG'), ('self-similarity', 'JJ'), ('search', 'NN'), ('template', 'NN'), ('matching', 'VBG'), ('provide', 'RB'), ('respective', 'JJ'), ('bounding', 'VBG'), ('box', 'NN'), ('around', 'IN'), ('respective', 'JJ'), ('object', 'NN'), ('set', 'VBN'), ('images', 'NNS'), ('computer', 'NN'), ('processing', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('region-based', 'JJ'), ('convolutional', 'JJ'), ('neural', 'JJ'), ('network', 'NN'), ('rcnn', 'NN'), ('forms', 'NNS'), ('model', 'VBP'), ('object', 'JJ'), ('training', 'NN'), ('stage', 'NN'), ('detect', 'JJ'), ('objects', 'VBZ'), ('new', 'JJ'), ('images', 'NNS'), ('inference', 'NN'), ('stage', 'NN'), ('computer', 'NN'), ('processing', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'VBP'), ('computer', 'NN'), ('processing', 'NN'), ('system', 'NN'), ('comprised', 'VBD'), ('system', 'NN'), ('selected', 'VBN'), ('group', 'NN'), ('consisting', 'VBG'), ('surveillance', 'NN'), ('system', 'NN'), ('face', 'NN'), ('detection', 'NN'), ('system', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('system', 'NN'), ('cancer', 'NN'), ('detection', 'NN'), ('system', 'NN'), ('object', 'VBP'), ('tracking', 'VBG'), ('system', 'NN'), ('advanced', 'VBD'), ('driver-assistance', 'NN'), ('system', 'NN'), ('method', 'RBR'), ('scalable', 'JJ'), ('parallel', 'JJ'), ('cloud-based', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('utilizing', 'VBG'), ('database', 'NN'), ('normalized', 'VBN'), ('stored', 'JJ'), ('images', 'NNS'), ('comprising', 'VBG'), ('capturing', 'VBG'), ('image', 'NN'), ('using', 'VBG'), ('camera', 'NN'), ('detecting', 'VBG'), ('face', 'NN'), ('captured', 'VBN'), ('image', 'NN'), ('normalizing', 'VBG'), ('detected', 'VBN'), ('facial', 'JJ'), ('image', 'NN'), ('match', 'NN'), ('normalized', 'VBN'), ('stored', 'JJ'), ('images', 'NNS'), ('identifying', 'VBG'), ('facial', 'JJ'), ('features', 'NNS'), ('normalized', 'VBN'), ('detected', 'JJ'), ('facial', 'JJ'), ('image', 'NN'), ('generating', 'VBG'), ('plurality', 'NN'), ('facial', 'JJ'), ('metrics', 'NNS'), ('facial', 'JJ'), ('features', 'NNS'), ('calculating', 'VBG'), ('euclidean', 'JJ'), ('distances', 'NNS'), ('facial', 'JJ'), ('metrics', 'NNS'), ('normalized', 'VBN'), ('detected', 'JJ'), ('facial', 'JJ'), ('image', 'NN'), ('corresponding', 'VBG'), ('facial', 'JJ'), ('metrics', 'NNS'), ('stored', 'VBD'), ('images', 'NNS'), ('comparing', 'VBG'), ('euclidean', 'JJ'), ('distance', 'NN'), ('predetermined', 'VBD'), ('threshold', 'JJ'), ('responsive', 'JJ'), ('euclidean', 'JJ'), ('distance', 'NN'), ('comparison', 'NN'), ('producing', 'VBG'), ('reduced', 'JJ'), ('candidate', 'JJ'), ('list', 'NN'), ('best', 'JJS'), ('possible', 'JJ'), ('image', 'NN'), ('matches', 'NNS'), ('normalized', 'VBN'), ('stored', 'JJ'), ('images', 'NNS'), ('comparing', 'VBG'), ('parallel', 'JJ'), ('normalized', 'VBN'), ('detected', 'JJ'), ('facial', 'JJ'), ('image', 'NN'), ('normalized', 'VBN'), ('stored', 'JJ'), ('images', 'NNS'), ('reduced', 'VBN'), ('candidate', 'JJ'), ('list', 'NN'), ('utilizing', 'VBG'), ('plurality', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('algorithms', 'NN'), ('processor', 'NN'), ('parallel', 'RB'), ('processing', 'VBG'), ('system', 'NN'), ('uses', 'VBZ'), ('different', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('algorithm', 'IN'), ('responsive', 'JJ'), ('comparison', 'NN'), ('producing', 'VBG'), ('best', 'JJS'), ('match', 'NN'), ('results', 'NNS'), ('parallel', 'JJ'), ('subset', 'NN'), ('reduced', 'VBN'), ('candidate', 'JJ'), ('list', 'NN'), ('selecting', 'VBG'), ('final', 'JJ'), ('match', 'NN'), ('best', 'JJS'), ('match', 'NN'), ('results', 'NNS'), ('using', 'VBG'), ('deep', 'JJ'), ('learning', 'VBG'), ('neural', 'JJ'), ('network', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('algorithm', 'NN'), ('trained', 'VBD'), ('outputs', 'NNS'), ('individual', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('algorithms', 'IN'), ('method', 'NN'), ('scalable', 'JJ'), ('parallel', 'JJ'), ('cloud-based', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('detecting', 'VBG'), ('face', 'NN'), ('captured', 'VBN'), ('image', 'NN'), ('comprises', 'VBZ'), ('utilizing', 'VBG'), ('opencv', 'RP'), ('detect', 'JJ'), ('face', 'NN'), ('captured', 'VBD'), ('image', 'NN'), ('extracting', 'VBG'), ('location', 'JJ'), ('eyes', 'NNS'), ('tip', 'VBP'), ('nose', 'JJ'), ('face', 'NN'), ('determining', 'VBG'), ('distance', 'NN'), ('eyes', 'NNS'), ('cropping', 'VBG'), ('face', 'NN'), ('captured', 'VBN'), ('image', 'NN'), ('width', 'NN'), ('height', 'VBD'), ('cropped', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('function', 'NN'), ('distance', 'NN'), ('eyes', 'NNS'), ('rotating', 'VBG'), ('face', 'NN'), ('angle', 'NN'), ('rotation', 'NN'), ('function', 'NN'), ('distance', 'NN'), ('eyes', 'NNS'), ('method', 'RBR'), ('scalable', 'JJ'), ('parallel', 'JJ'), ('cloud-based', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('width', 'NN'), ('cropped', 'VBD'), ('face', 'NN'), ('image', 'NN'), ('times', 'NNS'), ('distance', 'VB'), ('eyes', 'NNS'), ('height', 'MD'), ('cropped', 'VB'), ('face', 'NN'), ('image', 'NN'), ('times', 'NNS'), ('distance', 'VB'), ('eyes', 'NNS'), ('angle', 'JJ'), ('rotation', 'NN'), ('angle', 'NN'), ('formed', 'VBD'), ('straight', 'JJ'), ('line', 'NN'), ('joining', 'VBG'), ('eyes', 'NNS'), ('x-axis', 'JJ'), ('face', 'NN'), ('method', 'NN'), ('scalable', 'JJ'), ('parallel', 'JJ'), ('cloud-based', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('rotating', 'VBG'), ('face', 'NN'), ('comprises', 'NNS'), ('rotating', 'VBG'), ('face', 'NN'), ('provide', 'VBP'), ('frontal', 'JJ'), ('face', 'NN'), ('pattern', 'NN'), ('method', 'NN'), ('scalable', 'JJ'), ('parallel', 'JJ'), ('cloud-based', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('step', 'NN'), ('proportionally', 'RB'), ('rescaling', 'VBG'), ('cropped', 'VBN'), ('rotated', 'VBN'), ('image', 'NN'), ('method', 'NN'), ('scalable', 'JJ'), ('parallel', 'JJ'), ('cloud-based', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('claim', 'NN'), ('proportional', 'JJ'), ('rescaling', 'NN'), ('yields', 'NNS'), ('cropped', 'VBD'), ('rotated', 'VBN'), ('image', 'NN'), ('size', 'NN'), ('=', 'NNP'), ('pixels', 'NNS'), ('method', 'RBR'), ('scalable', 'JJ'), ('parallel', 'JJ'), ('cloud-based', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('claim', 'NN'), ('wherein', 'VBP'), ('facial', 'JJ'), ('features', 'NNS'), ('identified', 'VBN'), ('normalized', 'JJ'), ('detected', 'VBN'), ('facial', 'JJ'), ('image', 'NN'), ('comprise', 'NN'), ('pair', 'JJ'), ('eyes', 'NNS'), ('tip', 'VBP'), ('nose', 'JJ'), ('mouth', 'NN'), ('center', 'NN'), ('mouth', 'NN'), ('chin', 'JJ'), ('area', 'NN'), ('comprising', 'VBG'), ('bottom', 'JJ'), ('top', 'JJ'), ('left', 'VBN'), ('landmark', 'NN'), ('top', 'JJ'), ('right', 'NN'), ('landmark', 'NN'), ('method', 'NN'), ('scalable', 'JJ'), ('parallel', 'JJ'), ('cloud-based', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('generating', 'VBG'), ('plurality', 'NN'), ('facial', 'JJ'), ('metrics', 'NNS'), ('comprises', 'NNS'), ('calculating', 'VBG'), ('distance', 'NN'), ('pair', 'NN'), ('eyes', 'NNS'), ('distance', 'VB'), ('eyes', 'NNS'), ('tip', 'VBP'), ('nose', 'JJ'), ('distance', 'NN'), ('equal', 'JJ'), ('width', 'NN'), ('mouth', 'NN'), ('distance', 'NN'), ('tip', 'NN'), ('nose', 'RB'), ('center', 'JJ'), ('mouth', 'NN'), ('distance', 'NN'), ('bottom', 'NN'), ('chin', 'NN'), ('center', 'NN'), ('mouth', 'NN'), ('distance', 'NN'), ('top', 'NN'), ('left', 'VBD'), ('landmark', 'NN'), ('chin', 'NN'), ('tip', 'NN'), ('nose', 'JJ'), ('distance', 'NN'), ('top', 'JJ'), ('right', 'NN'), ('landmark', 'NN'), ('chin', 'JJ'), ('tip', 'NN'), ('nose', 'JJ'), ('method', 'NN'), ('scalable', 'JJ'), ('parallel', 'JJ'), ('cloud-based', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('performing', 'VBG'), ('euclidean', 'JJ'), ('distance', 'NN'), ('match', 'NN'), ('comprises', 'VBZ'), ('partitioning', 'VBG'), ('normalized', 'VBN'), ('stored', 'JJ'), ('images', 'NNS'), ('plurality', 'VBP'), ('substantially', 'RB'), ('equal', 'JJ'), ('subsets', 'NNS'), ('performing', 'VBG'), ('euclidean', 'JJ'), ('distance', 'NN'), ('match', 'NN'), ('facial', 'JJ'), ('metrics', 'NNS'), ('normalized', 'VBN'), ('detected', 'JJ'), ('facial', 'JJ'), ('image', 'NN'), ('corresponding', 'VBG'), ('facial', 'JJ'), ('metrics', 'NNS'), ('stored', 'VBD'), ('images', 'NNS'), ('subsets', 'NNS'), ('normalized', 'VBN'), ('stored', 'JJ'), ('images', 'NNS'), ('separate', 'VBP'), ('processor', 'NN'), ('parallel', 'NN'), ('processing', 'NN'), ('system', 'NN'), ('generate', 'JJ'), ('euclidean', 'JJ'), ('distance', 'NN'), ('stored', 'VBN'), ('image', 'NN'), ('subset', 'NN'), ('comparing', 'VBG'), ('euclidean', 'JJ'), ('distance', 'NN'), ('predetermined', 'VBD'), ('threshold', 'JJ'), ('separate', 'JJ'), ('processors', 'NNS'), ('responsive', 'JJ'), ('euclidean', 'JJ'), ('distance', 'NN'), ('comparison', 'NN'), ('producing', 'VBG'), ('reduced', 'JJ'), ('candidate', 'JJ'), ('list', 'NN'), ('best', 'JJS'), ('possible', 'JJ'), ('image', 'NN'), ('matches', 'NNS'), ('normalized', 'VBN'), ('stored', 'JJ'), ('images', 'NNS'), ('subset', 'VBP'), ('combining', 'VBG'), ('reduced', 'VBN'), ('candidate', 'NN'), ('lists', 'NNS'), ('subset', 'VBP'), ('produce', 'VBP'), ('single', 'JJ'), ('reduced', 'VBN'), ('candidate', 'JJ'), ('list', 'NN'), ('method', 'NN'), ('scalable', 'JJ'), ('parallel', 'JJ'), ('cloud-based', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('plurality', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('algorithms', 'IN'), ('utilized', 'JJ'), ('comparing', 'VBG'), ('parallel', 'JJ'), ('normalized', 'VBN'), ('detected', 'JJ'), ('facial', 'JJ'), ('image', 'NN'), ('normalized', 'VBN'), ('stored', 'JJ'), ('images', 'NNS'), ('reduced', 'VBN'), ('candidate', 'JJ'), ('list', 'NN'), ('consists', 'VBZ'), ('face', 'VBP'), ('recognition', 'NN'), ('algorithms', 'RB'), ('selected', 'VBN'), ('group', 'NN'), ('consisting', 'VBG'), ('principle', 'JJ'), ('component', 'JJ'), ('analysis', 'NN'), ('pca-based', 'JJ'), ('algorithms', 'NN'), ('linear', 'JJ'), ('discriminant', 'JJ'), ('analysis', 'NN'), ('lda', 'NN'), ('algorithms', 'JJ'), ('independent', 'JJ'), ('component', 'NN'), ('analysis', 'NN'), ('ica', 'NN'), ('algorithms', 'IN'), ('kernel-based', 'JJ'), ('algorithms', 'JJ'), ('feature-based', 'JJ'), ('techniques', 'NNS'), ('algorithms', 'VBP'), ('based', 'VBN'), ('neural', 'JJ'), ('networks', 'NNS'), ('algorithms', 'VBP'), ('based', 'VBN'), ('transforms', 'NNS'), ('model-based', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('algorithms', 'IN'), ('method', 'NN'), ('scalable', 'JJ'), ('parallel', 'JJ'), ('cloud-based', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('pca-based', 'JJ'), ('algorithms', 'NNS'), ('include', 'VBP'), ('eigenfaces', 'NNS'), ('face', 'VBP'), ('detectionrecognition', 'NN'), ('lda', 'NN'), ('algorithms', 'NN'), ('include', 'VBP'), ('fisherfaces', 'NNS'), ('method', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('method', 'NN'), ('scalable', 'JJ'), ('parallel', 'JJ'), ('cloud-based', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('comparing', 'VBG'), ('parallel', 'NN'), ('captured', 'VBN'), ('image', 'NN'), ('normalized', 'VBN'), ('stored', 'JJ'), ('images', 'NNS'), ('reduced', 'VBN'), ('candidate', 'JJ'), ('list', 'NN'), ('comprises', 'NNS'), ('partitioning', 'VBG'), ('reduced', 'JJ'), ('candidate', 'NN'), ('list', 'NN'), ('plurality', 'NN'), ('substantially', 'RB'), ('equal', 'JJ'), ('subsets', 'NNS'), ('processing', 'VBG'), ('subset', 'JJ'), ('different', 'JJ'), ('processor', 'NN'), ('parallel', 'NN'), ('processing', 'NN'), ('system', 'NN'), ('uses', 'VBZ'), ('unique', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('algorithm', 'IN'), ('produce', 'NN'), ('best', 'JJS'), ('match', 'NN'), ('results', 'NNS'), ('using', 'VBG'), ('reduce', 'VB'), ('function', 'NN'), ('mapreduce', 'NN'), ('program', 'NN'), ('combine', 'NN'), ('best', 'RBS'), ('match', 'NN'), ('results', 'NNS'), ('subsets', 'NNS'), ('produce', 'VBP'), ('single', 'JJ'), ('set', 'NN'), ('best', 'JJS'), ('match', 'NN'), ('results', 'NNS'), ('method', 'RBR'), ('scalable', 'JJ'), ('parallel', 'JJ'), ('cloud-based', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('partitioning', 'VBG'), ('reduced', 'VBN'), ('candidate', 'JJ'), ('list', 'NN'), ('comprises', 'NNS'), ('selecting', 'VBG'), ('images', 'NNS'), ('comprising', 'VBG'), ('subset', 'NN'), ('optimizing', 'VBG'), ('variance', 'NN'), ('images', 'NNS'), ('according', 'VBG'), ('following', 'VBG'), ('equation', 'NN'), ('n', 'IN'), ('number', 'NN'), ('rows', 'NNS'), ('columns', 'VBP'), ('face', 'NN'), ('vector', 'NN'), ('image', 'NN'), ('n', 'JJ'), ('number', 'NN'), ('groups', 'NNS'), ('σij', 'VBP'), ('standard', 'JJ'), ('deviation', 'NN'), ('image', 'NN'), ('dimension', 'NN'), ('group', 'NN'), ('j', 'NN'), ('face', 'NN'), ('image', 'NN'), ('vector', 'NN'), ('method', 'NN'), ('scalable', 'JJ'), ('parallel', 'JJ'), ('cloud-based', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('selecting', 'VBG'), ('images', 'NNS'), ('comprising', 'VBG'), ('subset', 'NN'), ('optimizing', 'VBG'), ('variance', 'NN'), ('images', 'NNS'), ('according', 'VBG'), ('following', 'VBG'), ('equation', 'NN'), ('dμi', 'FW'), ('μj', 'JJ'), ('euclidean', 'JJ'), ('distance', 'NN'), ('mean', 'NN'), ('group', 'NN'), ('mean', 'VBD'), ('group', 'NN'), ('j', 'NN'), ('face', 'NN'), ('image', 'NN'), ('vector', 'NN'), ('l', 'JJ'), ('number', 'NN'), ('group', 'NN'), ('levels', 'NNS'), ('method', 'VBP'), ('scalable', 'JJ'), ('parallel', 'JJ'), ('cloud-based', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('claim', 'NN'), ('selecting', 'VBG'), ('final', 'JJ'), ('match', 'NN'), ('best', 'JJS'), ('match', 'NN'), ('results', 'NNS'), ('utilizing', 'JJ'), ('deep', 'JJ'), ('learning', 'NN'), ('neural', 'JJ'), ('network', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('algorithm', 'NN'), ('comprises', 'VBZ'), ('utilizing', 'VBG'), ('either', 'DT'), ('adaboost', 'JJ'), ('machine-learning', 'JJ'), ('algorithm', 'JJ'), ('neural', 'JJ'), ('networks', 'NNS'), ('machine-learning', 'JJ'), ('model', 'NN'), ('method', 'NN'), ('scalable', 'JJ'), ('parallel', 'JJ'), ('cloud-based', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('claim', 'NN'), ('normalizing', 'VBG'), ('detected', 'VBN'), ('facial', 'JJ'), ('image', 'NN'), ('match', 'NN'), ('normalized', 'VBN'), ('stored', 'JJ'), ('images', 'NNS'), ('includes', 'VBZ'), ('normalizing', 'VBG'), ('detected', 'VBN'), ('facial', 'JJ'), ('image', 'NN'), ('size', 'NN'), ('orientation', 'NN'), ('illumination', 'NN'), ('normalized', 'VBN'), ('stored', 'JJ'), ('images', 'NNS'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('medium', 'NN'), ('containing', 'VBG'), ('executable', 'JJ'), ('program', 'NN'), ('instructions', 'NNS'), ('causing', 'VBG'), ('computer', 'NN'), ('perform', 'NN'), ('method', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('method', 'NN'), ('comprising', 'VBG'), ('detecting', 'VBG'), ('face', 'NN'), ('image', 'NN'), ('captured', 'VBD'), ('camera', 'NN'), ('normalizing', 'NN'), ('detected', 'VBN'), ('facial', 'JJ'), ('image', 'NN'), ('match', 'NN'), ('normalized', 'VBN'), ('stored', 'JJ'), ('images', 'NNS'), ('identifying', 'VBG'), ('facial', 'JJ'), ('features', 'NNS'), ('normalized', 'VBN'), ('detected', 'JJ'), ('facial', 'JJ'), ('image', 'NN'), ('generating', 'VBG'), ('plurality', 'NN'), ('facial', 'JJ'), ('metrics', 'NNS'), ('facial', 'JJ'), ('features', 'NNS'), ('calculating', 'VBG'), ('euclidean', 'JJ'), ('distances', 'NNS'), ('facial', 'JJ'), ('metrics', 'NNS'), ('normalized', 'VBN'), ('detected', 'JJ'), ('facial', 'JJ'), ('image', 'NN'), ('corresponding', 'VBG'), ('facial', 'JJ'), ('metrics', 'NNS'), ('stored', 'VBD'), ('images', 'NNS'), ('comparing', 'VBG'), ('euclidean', 'JJ'), ('distance', 'NN'), ('predetermined', 'VBD'), ('threshold', 'JJ'), ('responsive', 'JJ'), ('euclidean', 'JJ'), ('distance', 'NN'), ('comparison', 'NN'), ('producing', 'VBG'), ('reduced', 'JJ'), ('candidate', 'JJ'), ('list', 'NN'), ('best', 'JJS'), ('possible', 'JJ'), ('image', 'NN'), ('matches', 'NNS'), ('normalized', 'VBN'), ('stored', 'JJ'), ('images', 'NNS'), ('comparing', 'VBG'), ('parallel', 'RB'), ('captured', 'VBN'), ('image', 'NN'), ('normalized', 'VBN'), ('stored', 'JJ'), ('images', 'NNS'), ('reduced', 'VBN'), ('candidate', 'JJ'), ('list', 'NN'), ('utilizing', 'VBG'), ('plurality', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('algorithms', 'NN'), ('processor', 'NN'), ('parallel', 'RB'), ('processing', 'VBG'), ('system', 'NN'), ('uses', 'VBZ'), ('different', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('algorithm', 'IN'), ('responsive', 'JJ'), ('comparison', 'NN'), ('producing', 'VBG'), ('best', 'JJS'), ('match', 'NN'), ('results', 'NNS'), ('parallel', 'JJ'), ('subset', 'NN'), ('reduced', 'VBN'), ('candidate', 'JJ'), ('list', 'NN'), ('selecting', 'VBG'), ('final', 'JJ'), ('match', 'NN'), ('best', 'JJS'), ('match', 'NN'), ('results', 'NNS'), ('using', 'VBG'), ('deep', 'JJ'), ('learning', 'VBG'), ('neural', 'JJ'), ('network', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('algorithm', 'NN'), ('trained', 'VBD'), ('outputs', 'NNS'), ('individual', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('algorithms', 'IN'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('medium', 'NN'), ('containing', 'VBG'), ('executable', 'JJ'), ('program', 'NN'), ('instructions', 'NNS'), ('claim', 'VBP'), ('wherein', 'JJ'), ('plurality', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('algorithms', 'IN'), ('utilized', 'JJ'), ('comparing', 'VBG'), ('parallel', 'JJ'), ('normalized', 'VBN'), ('detected', 'JJ'), ('facial', 'JJ'), ('image', 'NN'), ('normalized', 'VBN'), ('stored', 'JJ'), ('images', 'NNS'), ('reduced', 'VBN'), ('candidate', 'JJ'), ('list', 'NN'), ('consists', 'VBZ'), ('face', 'VBP'), ('recognition', 'NN'), ('algorithms', 'RB'), ('selected', 'VBN'), ('group', 'NN'), ('consisting', 'VBG'), ('principle', 'JJ'), ('component', 'JJ'), ('analysis', 'NN'), ('pca-based', 'JJ'), ('algorithms', 'NN'), ('linear', 'JJ'), ('discriminant', 'JJ'), ('analysis', 'NN'), ('lda', 'NN'), ('algorithms', 'JJ'), ('independent', 'JJ'), ('component', 'NN'), ('analysis', 'NN'), ('ica', 'NN'), ('algorithms', 'IN'), ('kernel-based', 'JJ'), ('algorithms', 'JJ'), ('feature-based', 'JJ'), ('techniques', 'NNS'), ('algorithms', 'VBP'), ('based', 'VBN'), ('neural', 'JJ'), ('networks', 'NNS'), ('algorithms', 'VBP'), ('based', 'VBN'), ('transforms', 'NNS'), ('model-based', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('algorithms', 'IN'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('medium', 'NN'), ('containing', 'VBG'), ('executable', 'JJ'), ('program', 'NN'), ('instructions', 'NNS'), ('claim', 'VBP'), ('wherein', 'IN'), ('pca-based', 'JJ'), ('algorithms', 'NNS'), ('include', 'VBP'), ('eigenfaces', 'NNS'), ('face', 'VBP'), ('detectionrecognition', 'NN'), ('lda', 'NN'), ('algorithms', 'NN'), ('include', 'VBP'), ('fisherfaces', 'NNS'), ('method', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('medium', 'NN'), ('containing', 'VBG'), ('executable', 'JJ'), ('program', 'NN'), ('instructions', 'NNS'), ('claim', 'VBP'), ('selecting', 'VBG'), ('final', 'JJ'), ('match', 'NN'), ('best', 'JJS'), ('match', 'NN'), ('results', 'NNS'), ('utilizing', 'JJ'), ('deep', 'JJ'), ('learning', 'NN'), ('neural', 'JJ'), ('network', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('algorithm', 'NN'), ('comprises', 'VBZ'), ('utilizing', 'VBG'), ('either', 'DT'), ('adaboost', 'JJ'), ('machine-learning', 'JJ'), ('algorithm', 'JJ'), ('neural', 'JJ'), ('networks', 'NNS'), ('machine-learning', 'JJ'), ('model', 'NN'), ('imaging', 'VBG'), ('device', 'NN'), ('comprising', 'VBG'), ('condensing', 'VBG'), ('lens', 'JJ'), ('image', 'NN'), ('sensor', 'NN'), ('configured', 'VBD'), ('detect', 'JJ'), ('light', 'JJ'), ('passing', 'VBG'), ('condensing', 'VBG'), ('lens', 'NNS'), ('comprising', 'VBG'), ('pixel', 'NN'), ('matrix', 'NN'), ('wherein', 'NN'), ('pixel', 'NN'), ('matrix', 'NN'), ('comprises', 'VBZ'), ('plurality', 'NN'), ('phase', 'NN'), ('detection', 'NN'), ('pixel', 'NN'), ('pairs', 'NNS'), ('plurality', 'NN'), ('regular', 'JJ'), ('pixels', 'NNS'), ('processor', 'NN'), ('configured', 'VBD'), ('turn', 'JJ'), ('phase', 'JJ'), ('detection', 'NN'), ('pixel', 'NN'), ('pairs', 'NNS'), ('autofocusing', 'VBG'), ('output', 'NN'), ('autofocused', 'VBD'), ('pixel', 'JJ'), ('data', 'NNS'), ('completing', 'VBG'), ('autofocusing', 'VBG'), ('divide', 'NN'), ('autofocused', 'VBD'), ('pixel', 'NN'), ('data', 'NNS'), ('first', 'RB'), ('subframe', 'JJ'), ('second', 'JJ'), ('subframe', 'NN'), ('calculate', 'NN'), ('image', 'NN'), ('features', 'NNS'), ('least', 'VBP'), ('one', 'CD'), ('first', 'JJ'), ('subframe', 'JJ'), ('second', 'JJ'), ('subframe', 'NN'), ('wherein', 'NN'), ('image', 'NN'), ('features', 'NNS'), ('comprise', 'VBP'), ('module', 'JJ'), ('widths', 'NNS'), ('finder', 'VBP'), ('pattern', 'JJ'), ('finder', 'NN'), ('pattern', 'NN'), ('predetermined', 'VBN'), ('ratio', 'JJ'), ('harr-like', 'JJ'), ('feature', 'NN'), ('gabor', 'NN'), ('feature', 'NN'), ('determine', 'NN'), ('operating', 'VBG'), ('resolution', 'NN'), ('regular', 'JJ'), ('pixels', 'NNS'), ('according', 'VBG'), ('image', 'NN'), ('features', 'NNS'), ('calculated', 'VBD'), ('least', 'JJS'), ('one', 'CD'), ('first', 'JJ'), ('subframe', 'JJ'), ('second', 'JJ'), ('subframe', 'NN'), ('divided', 'VBD'), ('autofocused', 'JJ'), ('pixel', 'NN'), ('data', 'NNS'), ('imaging', 'VBG'), ('device', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('phase', 'NN'), ('detection', 'NN'), ('pixel', 'NN'), ('pairs', 'NN'), ('comprises', 'VBZ'), ('first', 'JJ'), ('pixel', 'JJ'), ('second', 'JJ'), ('pixel', 'NN'), ('cover', 'NN'), ('layer', 'NN'), ('covering', 'VBG'), ('upon', 'IN'), ('first', 'JJ'), ('region', 'NN'), ('first', 'RB'), ('pixel', 'VBZ'), ('upon', 'IN'), ('second', 'JJ'), ('region', 'NN'), ('second', 'JJ'), ('pixel', 'NN'), ('wherein', 'NN'), ('first', 'JJ'), ('region', 'NN'), ('second', 'JJ'), ('region', 'NN'), ('mirror', 'NN'), ('symmetrical', 'JJ'), ('microlens', 'NNS'), ('aligned', 'VBN'), ('least', 'JJS'), ('one', 'CD'), ('first', 'JJ'), ('pixel', 'JJ'), ('second', 'JJ'), ('pixel', 'NN'), ('imaging', 'VBG'), ('device', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('first', 'JJ'), ('region', 'NN'), ('second', 'JJ'), ('region', 'NN'), ('%', 'NN'), ('%', 'NN'), ('area', 'NN'), ('single', 'JJ'), ('pixel', 'NN'), ('imaging', 'VBG'), ('device', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('processor', 'NN'), ('configured', 'VBD'), ('perform', 'NN'), ('autofocusing', 'VBG'), ('using', 'VBG'), ('dual', 'JJ'), ('pixel', 'NN'), ('autofocus', 'NN'), ('technique', 'NN'), ('according', 'VBG'), ('pixel', 'NN'), ('data', 'NNS'), ('phase', 'NN'), ('detection', 'NN'), ('pixel', 'NN'), ('pairs', 'NNS'), ('completing', 'VBG'), ('autofocusing', 'VBG'), ('imaging', 'JJ'), ('device', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('processor', 'NN'), ('configured', 'VBD'), ('divide', 'JJ'), ('pixel', 'NN'), ('data', 'NNS'), ('phase', 'NN'), ('detection', 'NN'), ('pixel', 'NN'), ('pairs', 'NNS'), ('third', 'JJ'), ('subframe', 'JJ'), ('fourth', 'JJ'), ('subframe', 'NN'), ('completing', 'VBG'), ('autofocusing', 'VBG'), ('perform', 'NN'), ('autofocusing', 'VBG'), ('according', 'VBG'), ('third', 'JJ'), ('subframe', 'JJ'), ('fourth', 'JJ'), ('subframe', 'NN'), ('imaging', 'VBG'), ('device', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('processor', 'NN'), ('configured', 'VBD'), ('calibrate', 'JJ'), ('brightness', 'JJ'), ('third', 'JJ'), ('subframe', 'NN'), ('fourth', 'JJ'), ('subframe', 'JJ'), ('identical', 'JJ'), ('using', 'VBG'), ('shading', 'VBG'), ('algorithm', 'JJ'), ('imaging', 'VBG'), ('device', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('operating', 'VBG'), ('resolution', 'NN'), ('selected', 'VBN'), ('first', 'JJ'), ('resolution', 'NN'), ('smaller', 'JJR'), ('number', 'NN'), ('regular', 'JJ'), ('pixels', 'NNS'), ('second', 'JJ'), ('resolution', 'NN'), ('larger', 'JJR'), ('first', 'JJ'), ('resolution', 'NN'), ('imaging', 'VBG'), ('device', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('regular', 'JJ'), ('pixels', 'NNS'), ('turned', 'VBD'), ('autofocusing', 'VBG'), ('imaging', 'VBG'), ('device', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('number', 'NN'), ('phase', 'NN'), ('detection', 'NN'), ('pixel', 'NN'), ('pairs', 'VBZ'), ('smaller', 'JJR'), ('regular', 'JJ'), ('pixels', 'NNS'), ('imaging', 'VBG'), ('device', 'NN'), ('comprising', 'VBG'), ('condensing', 'VBG'), ('lens', 'JJ'), ('image', 'NN'), ('sensor', 'NN'), ('configured', 'VBD'), ('detect', 'JJ'), ('light', 'JJ'), ('passing', 'VBG'), ('condensing', 'VBG'), ('lens', 'NNS'), ('comprising', 'VBG'), ('pixel', 'NN'), ('matrix', 'NN'), ('wherein', 'NN'), ('pixel', 'NN'), ('matrix', 'NN'), ('comprises', 'VBZ'), ('plurality', 'NN'), ('phase', 'NN'), ('detection', 'NN'), ('pixel', 'NN'), ('pairs', 'NNS'), ('plurality', 'NN'), ('regular', 'JJ'), ('pixels', 'NNS'), ('processor', 'NN'), ('configured', 'VBD'), ('turn', 'JJ'), ('phase', 'JJ'), ('detection', 'NN'), ('pixel', 'NN'), ('pairs', 'NNS'), ('autofocusing', 'VBG'), ('output', 'NN'), ('autofocused', 'VBD'), ('pixel', 'JJ'), ('data', 'NNS'), ('completing', 'VBG'), ('autofocusing', 'VBG'), ('divide', 'NN'), ('autofocused', 'VBD'), ('pixel', 'NN'), ('data', 'NNS'), ('first', 'RB'), ('subframe', 'JJ'), ('second', 'JJ'), ('subframe', 'NN'), ('calculate', 'NN'), ('image', 'NN'), ('features', 'NNS'), ('least', 'VBP'), ('one', 'CD'), ('first', 'JJ'), ('subframe', 'JJ'), ('second', 'JJ'), ('subframe', 'NN'), ('wherein', 'NN'), ('image', 'NN'), ('features', 'NNS'), ('comprise', 'VBP'), ('module', 'JJ'), ('widths', 'NNS'), ('finder', 'VBP'), ('pattern', 'JJ'), ('finder', 'NN'), ('pattern', 'NN'), ('predetermined', 'VBN'), ('ratio', 'JJ'), ('harr-like', 'JJ'), ('feature', 'NN'), ('gabor', 'NN'), ('feature', 'NN'), ('select', 'JJ'), ('image', 'NN'), ('decoding', 'VBG'), ('image', 'NN'), ('recognition', 'NN'), ('using', 'VBG'), ('pixel', 'JJ'), ('data', 'NNS'), ('regular', 'JJ'), ('pixels', 'NNS'), ('according', 'VBG'), ('image', 'NN'), ('features', 'NNS'), ('calculated', 'VBD'), ('least', 'JJS'), ('one', 'CD'), ('first', 'JJ'), ('subframe', 'JJ'), ('second', 'JJ'), ('subframe', 'NN'), ('divided', 'VBD'), ('autofocused', 'JJ'), ('pixel', 'NN'), ('data', 'NNS'), ('imaging', 'VBG'), ('device', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('phase', 'NN'), ('detection', 'NN'), ('pixel', 'NN'), ('pairs', 'NN'), ('comprises', 'VBZ'), ('first', 'JJ'), ('pixel', 'JJ'), ('second', 'JJ'), ('pixel', 'NN'), ('cover', 'NN'), ('layer', 'NN'), ('covering', 'VBG'), ('upon', 'IN'), ('first', 'JJ'), ('region', 'NN'), ('first', 'RB'), ('pixel', 'VBZ'), ('upon', 'IN'), ('second', 'JJ'), ('region', 'NN'), ('second', 'JJ'), ('pixel', 'NN'), ('wherein', 'NN'), ('first', 'JJ'), ('region', 'NN'), ('second', 'JJ'), ('region', 'NN'), ('mirror', 'NN'), ('symmetrical', 'JJ'), ('microlens', 'NNS'), ('aligned', 'VBN'), ('least', 'JJS'), ('one', 'CD'), ('first', 'JJ'), ('pixel', 'JJ'), ('second', 'JJ'), ('pixel', 'NN'), ('imaging', 'VBG'), ('device', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('processor', 'NN'), ('configured', 'VBD'), ('perform', 'NN'), ('autofocusing', 'VBG'), ('using', 'VBG'), ('dual', 'JJ'), ('pixel', 'NN'), ('autofocus', 'NN'), ('technique', 'NN'), ('according', 'VBG'), ('pixel', 'NN'), ('data', 'NNS'), ('phase', 'NN'), ('detection', 'NN'), ('pixel', 'NN'), ('pairs', 'NNS'), ('completing', 'VBG'), ('autofocusing', 'VBG'), ('imaging', 'JJ'), ('device', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('processor', 'NN'), ('configured', 'VBD'), ('divide', 'JJ'), ('pixel', 'NN'), ('data', 'NNS'), ('phase', 'NN'), ('detection', 'NN'), ('pixel', 'NN'), ('pairs', 'NNS'), ('third', 'JJ'), ('subframe', 'JJ'), ('fourth', 'JJ'), ('subframe', 'NN'), ('completing', 'VBG'), ('autofocusing', 'VBG'), ('calibrate', 'JJ'), ('brightness', 'JJ'), ('third', 'JJ'), ('subframe', 'NN'), ('fourth', 'JJ'), ('subframe', 'JJ'), ('identical', 'JJ'), ('using', 'VBG'), ('shading', 'VBG'), ('algorithm', 'JJ'), ('perform', 'NN'), ('autofocusing', 'VBG'), ('according', 'VBG'), ('third', 'JJ'), ('subframe', 'JJ'), ('fourth', 'JJ'), ('subframe', 'NN'), ('imaging', 'VBG'), ('device', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('processor', 'NN'), ('configured', 'VBD'), ('calculate', 'JJ'), ('image', 'NN'), ('features', 'NNS'), ('using', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('rule', 'NN'), ('based', 'VBN'), ('algorithm', 'RB'), ('machine', 'NN'), ('learning', 'VBG'), ('algorithm', 'JJ'), ('imaging', 'VBG'), ('device', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('image', 'NN'), ('decoding', 'VBG'), ('decoding', 'VBG'), ('qr', 'NN'), ('codes', 'NNS'), ('image', 'NN'), ('recognition', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('operating', 'VBG'), ('method', 'NN'), ('imaging', 'VBG'), ('device', 'NN'), ('imaging', 'VBG'), ('device', 'NN'), ('comprising', 'VBG'), ('plurality', 'NN'), ('phase', 'NN'), ('detection', 'NN'), ('pixel', 'NN'), ('pairs', 'NNS'), ('plurality', 'NN'), ('regular', 'JJ'), ('pixels', 'NNS'), ('operating', 'VBG'), ('method', 'NN'), ('comprising', 'VBG'), ('turning', 'VBG'), ('phase', 'NN'), ('detection', 'NN'), ('pixel', 'NN'), ('pairs', 'NNS'), ('autofocusing', 'VBG'), ('outputting', 'VBG'), ('autofocused', 'VBN'), ('image', 'NN'), ('frame', 'NN'), ('completing', 'VBG'), ('autofocusing', 'VBG'), ('dividing', 'VBG'), ('autofocused', 'VBN'), ('image', 'NN'), ('frame', 'NN'), ('acquired', 'VBD'), ('phase', 'JJ'), ('detection', 'NN'), ('pixel', 'NN'), ('pairs', 'NNS'), ('first', 'RB'), ('subframe', 'JJ'), ('second', 'JJ'), ('subframe', 'NN'), ('calculating', 'VBG'), ('image', 'NN'), ('features', 'NNS'), ('least', 'VBP'), ('one', 'CD'), ('first', 'JJ'), ('subframe', 'JJ'), ('second', 'JJ'), ('subframe', 'NN'), ('wherein', 'JJ'), ('image', 'NN'), ('feature', 'NN'), ('comprise', 'NN'), ('module', 'NN'), ('widths', 'NNS'), ('finder', 'VBP'), ('pattern', 'JJ'), ('finder', 'NN'), ('pattern', 'NN'), ('predetermined', 'VBN'), ('ratio', 'JJ'), ('harr-like', 'JJ'), ('feature', 'NN'), ('gabor', 'NN'), ('feature', 'NN'), ('selectively', 'RB'), ('activating', 'VBG'), ('least', 'JJS'), ('part', 'NN'), ('regular', 'JJ'), ('pixels', 'NNS'), ('according', 'VBG'), ('image', 'NN'), ('features', 'NNS'), ('calculated', 'VBD'), ('least', 'JJS'), ('one', 'CD'), ('first', 'JJ'), ('subframe', 'JJ'), ('second', 'JJ'), ('subframe', 'NN'), ('divided', 'VBD'), ('autofocused', 'JJ'), ('image', 'NN'), ('frame', 'NN'), ('operating', 'VBG'), ('method', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('selectively', 'RB'), ('activating', 'VBG'), ('comprises', 'NNS'), ('activating', 'VBG'), ('first', 'JJ'), ('part', 'NN'), ('regular', 'JJ'), ('pixels', 'NNS'), ('perform', 'VBP'), ('image', 'NN'), ('decoding', 'VBG'), ('according', 'VBG'), ('pixel', 'NN'), ('data', 'NNS'), ('first', 'JJ'), ('part', 'NN'), ('regular', 'JJ'), ('pixels', 'NNS'), ('activating', 'VBG'), ('regular', 'JJ'), ('pixels', 'NNS'), ('perform', 'VBP'), ('image', 'NN'), ('recognition', 'NN'), ('according', 'VBG'), ('pixel', 'NN'), ('data', 'NNS'), ('regular', 'JJ'), ('pixels', 'NNS'), ('operating', 'VBG'), ('method', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('pixel', 'NN'), ('data', 'NNS'), ('phase', 'NN'), ('detection', 'NN'), ('pixel', 'NN'), ('pairs', 'NNS'), ('captured', 'VBD'), ('frame', 'JJ'), ('pixel', 'NN'), ('data', 'NNS'), ('regular', 'JJ'), ('pixels', 'NNS'), ('also', 'RB'), ('used', 'VBD'), ('performing', 'VBG'), ('image', 'NN'), ('decoding', 'VBG'), ('image', 'NN'), ('recognition', 'NN'), ('operating', 'VBG'), ('method', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('image', 'NN'), ('decoding', 'VBG'), ('decoding', 'VBG'), ('qr', 'NN'), ('codes', 'NNS'), ('image', 'NN'), ('recognition', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('operating', 'VBG'), ('method', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('phase', 'NN'), ('detection', 'NN'), ('pixel', 'NN'), ('pairs', 'NNS'), ('partially', 'RB'), ('covered', 'VBD'), ('pixels', 'NNS'), ('structure', 'NN'), ('dual', 'JJ'), ('pixel', 'NN'), ('apparatus', 'NN'), ('comprising', 'VBG'), ('first', 'JJ'), ('camera', 'NN'), ('module', 'NN'), ('configured', 'VBD'), ('obtain', 'VB'), ('first', 'JJ'), ('image', 'NN'), ('object', 'VBP'), ('first', 'JJ'), ('field', 'NN'), ('view', 'NN'), ('second', 'JJ'), ('camera', 'NN'), ('module', 'NN'), ('configured', 'VBD'), ('obtain', 'VB'), ('second', 'JJ'), ('image', 'NN'), ('object', 'JJ'), ('second', 'JJ'), ('field', 'NN'), ('view', 'NN'), ('different', 'JJ'), ('first', 'JJ'), ('field', 'NN'), ('view', 'NN'), ('first', 'RB'), ('depth', 'VBZ'), ('map', 'NN'), ('generator', 'NN'), ('configured', 'VBD'), ('generate', 'NN'), ('first', 'RB'), ('depth', 'VBZ'), ('map', 'NN'), ('first', 'RB'), ('image', 'NN'), ('based', 'VBN'), ('first', 'JJ'), ('image', 'NN'), ('second', 'JJ'), ('image', 'NN'), ('second', 'JJ'), ('depth', 'NN'), ('map', 'NN'), ('generator', 'NN'), ('configured', 'VBD'), ('generate', 'JJ'), ('second', 'JJ'), ('depth', 'NN'), ('map', 'NN'), ('second', 'JJ'), ('image', 'NN'), ('based', 'VBN'), ('first', 'JJ'), ('image', 'NN'), ('second', 'JJ'), ('image', 'NN'), ('first', 'RB'), ('depth', 'VBZ'), ('map', 'JJ'), ('apparatus', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('first', 'JJ'), ('field', 'NN'), ('view', 'NN'), ('narrow', 'JJ'), ('angle', 'JJ'), ('second', 'JJ'), ('field', 'NN'), ('view', 'NN'), ('wider', 'VBP'), ('angle', 'NN'), ('apparatus', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('second', 'JJ'), ('image', 'NN'), ('divided', 'VBD'), ('primary', 'JJ'), ('region', 'NN'), ('residual', 'JJ'), ('region', 'NN'), ('second', 'JJ'), ('depth', 'NN'), ('map', 'NN'), ('generator', 'NN'), ('comprises', 'VBZ'), ('relationship', 'NN'), ('estimating', 'VBG'), ('module', 'NN'), ('configured', 'VBD'), ('estimate', 'NN'), ('relationship', 'NN'), ('primary', 'JJ'), ('region', 'NN'), ('residual', 'JJ'), ('region', 'NN'), ('based', 'VBN'), ('first', 'JJ'), ('image', 'NN'), ('second', 'JJ'), ('image', 'NN'), ('depth', 'NN'), ('map', 'NN'), ('estimating', 'VBG'), ('module', 'NN'), ('configured', 'VBD'), ('estimate', 'NN'), ('depth', 'NN'), ('map', 'VBP'), ('residual', 'JJ'), ('region', 'NN'), ('based', 'VBN'), ('estimated', 'VBN'), ('relationship', 'NN'), ('first', 'JJ'), ('depth', 'NN'), ('map', 'NN'), ('apparatus', 'NN'), ('claim', 'NN'), ('wherein', 'VBD'), ('least', 'JJS'), ('one', 'CD'), ('relationship', 'NN'), ('estimating', 'VBG'), ('module', 'NN'), ('depth', 'NN'), ('map', 'NN'), ('estimating', 'VBG'), ('module', 'NN'), ('performs', 'NNS'), ('estimating', 'VBG'), ('operation', 'NN'), ('based', 'VBN'), ('neural', 'JJ'), ('network', 'NN'), ('module', 'NN'), ('apparatus', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('depth', 'NN'), ('map', 'FW'), ('fusion', 'NN'), ('unit', 'NN'), ('configured', 'VBD'), ('generate', 'JJ'), ('third', 'JJ'), ('depth', 'NN'), ('map', 'NN'), ('second', 'JJ'), ('image', 'NN'), ('performing', 'VBG'), ('fusion', 'NN'), ('operation', 'NN'), ('based', 'VBN'), ('first', 'RB'), ('depth', 'JJ'), ('map', 'JJ'), ('second', 'JJ'), ('depth', 'NN'), ('map', 'NN'), ('apparatus', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('depth', 'NN'), ('map', 'JJ'), ('fusion', 'NN'), ('unit', 'NN'), ('comprises', 'VBZ'), ('tone', 'CD'), ('mapping', 'NN'), ('module', 'NN'), ('configured', 'VBD'), ('generate', 'JJ'), ('tone-mapped', 'JJ'), ('second', 'JJ'), ('depth', 'NN'), ('map', 'NN'), ('correspond', 'NN'), ('first', 'RB'), ('depth', 'VBZ'), ('map', 'NN'), ('performing', 'VBG'), ('bias', 'JJ'), ('removing', 'VBG'), ('operation', 'NN'), ('second', 'JJ'), ('depth', 'NN'), ('map', 'NN'), ('fusion', 'NN'), ('module', 'NN'), ('configured', 'VBD'), ('generate', 'JJ'), ('third', 'JJ'), ('depth', 'NN'), ('map', 'NN'), ('fusing', 'VBG'), ('tone-mapped', 'JJ'), ('second', 'JJ'), ('depth', 'NN'), ('map', 'NN'), ('first', 'RB'), ('depth', 'VBZ'), ('map', 'JJ'), ('apparatus', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('depth', 'NN'), ('map', 'JJ'), ('fusion', 'NN'), ('unit', 'NN'), ('comprises', 'VBZ'), ('propagating', 'VBG'), ('module', 'NN'), ('configured', 'VBD'), ('generate', 'NN'), ('propagated', 'VBN'), ('first', 'JJ'), ('depth', 'NN'), ('map', 'NN'), ('second', 'JJ'), ('image', 'NN'), ('iterated', 'VBD'), ('propagating', 'VBG'), ('first', 'JJ'), ('depth', 'NN'), ('map', 'NN'), ('based', 'VBN'), ('first', 'RB'), ('depth', 'JJ'), ('map', 'NN'), ('second', 'JJ'), ('image', 'NN'), ('fusion', 'NN'), ('module', 'NN'), ('generates', 'VBZ'), ('third', 'JJ'), ('depth', 'NN'), ('map', 'NN'), ('fusing', 'VBG'), ('tone-mapped', 'JJ'), ('second', 'JJ'), ('depth', 'NN'), ('map', 'NN'), ('propagated', 'VBD'), ('first', 'JJ'), ('depth', 'NN'), ('map', 'NN'), ('apparatus', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('depth', 'NN'), ('map', 'JJ'), ('fusion', 'NN'), ('unit', 'NN'), ('comprises', 'VBZ'), ('post-processing', 'JJ'), ('module', 'NN'), ('configured', 'VBD'), ('perform', 'JJ'), ('post-processing', 'JJ'), ('operation', 'NN'), ('third', 'JJ'), ('depth', 'NN'), ('map', 'NN'), ('generated', 'VBD'), ('fusion', 'NN'), ('module', 'NN'), ('provide', 'IN'), ('post-processed', 'JJ'), ('third', 'JJ'), ('depth', 'NN'), ('map', 'NN'), ('apparatus', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('post-processing', 'JJ'), ('module', 'NN'), ('performs', 'NNS'), ('post-processing', 'JJ'), ('operation', 'NN'), ('filtering', 'VBG'), ('interface', 'NN'), ('generated', 'VBD'), ('third', 'JJ'), ('depth', 'JJ'), ('map', 'NN'), ('accordance', 'NN'), ('fusion', 'NN'), ('fusion', 'NN'), ('module', 'NN'), ('apparatus', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('post-processing', 'JJ'), ('module', 'NN'), ('removes', 'VBZ'), ('artifacts', 'NNS'), ('generated', 'VBD'), ('third', 'JJ'), ('depth', 'JJ'), ('map', 'NN'), ('accordance', 'NN'), ('fusion', 'NN'), ('fusion', 'NN'), ('module', 'NN'), ('apparatus', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('first', 'JJ'), ('depth', 'NN'), ('map', 'NN'), ('generator', 'NN'), ('analyses', 'VBZ'), ('distance', 'NN'), ('relationship', 'NN'), ('first', 'JJ'), ('image', 'NN'), ('second', 'JJ'), ('image', 'NN'), ('generates', 'NNS'), ('first', 'RB'), ('depth', 'VB'), ('map', 'NN'), ('first', 'RB'), ('image', 'NN'), ('based', 'VBN'), ('distance', 'NN'), ('relationship', 'NN'), ('method', 'NN'), ('processing', 'NN'), ('image', 'NN'), ('electronic', 'JJ'), ('apparatus', 'NN'), ('method', 'NN'), ('comprising', 'VBG'), ('obtaining', 'VBG'), ('first', 'JJ'), ('image', 'NN'), ('object', 'NN'), ('using', 'VBG'), ('first', 'JJ'), ('camera', 'NN'), ('module', 'NN'), ('obtaining', 'VBG'), ('second', 'JJ'), ('image', 'NN'), ('object', 'NN'), ('using', 'VBG'), ('second', 'JJ'), ('camera', 'NN'), ('module', 'NN'), ('generating', 'VBG'), ('first', 'JJ'), ('depth', 'NN'), ('map', 'NN'), ('first', 'RB'), ('image', 'NN'), ('based', 'VBN'), ('first', 'JJ'), ('image', 'NN'), ('second', 'JJ'), ('image', 'NN'), ('estimating', 'VBG'), ('relationship', 'NN'), ('primary', 'JJ'), ('region', 'NN'), ('second', 'JJ'), ('image', 'NN'), ('residual', 'JJ'), ('region', 'NN'), ('second', 'JJ'), ('image', 'NN'), ('based', 'VBN'), ('first', 'JJ'), ('image', 'NN'), ('second', 'JJ'), ('image', 'NN'), ('generating', 'VBG'), ('second', 'JJ'), ('depth', 'NN'), ('map', 'NN'), ('second', 'JJ'), ('image', 'NN'), ('based', 'VBN'), ('estimated', 'VBN'), ('relationship', 'NN'), ('primary', 'JJ'), ('region', 'NN'), ('residual', 'JJ'), ('region', 'NN'), ('first', 'RB'), ('depth', 'VBZ'), ('map', 'JJ'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'VBZ'), ('electronic', 'JJ'), ('apparatus', 'NN'), ('comprises', 'NNS'), ('first', 'RB'), ('camera', 'VBP'), ('module', 'NN'), ('including', 'VBG'), ('first', 'JJ'), ('lens', 'NNS'), ('first', 'JJ'), ('field', 'NN'), ('view', 'NN'), ('second', 'JJ'), ('camera', 'NN'), ('module', 'NN'), ('including', 'VBG'), ('second', 'JJ'), ('lens', 'JJ'), ('second', 'JJ'), ('field', 'NN'), ('view', 'NN'), ('wider', 'VBP'), ('first', 'JJ'), ('field', 'NN'), ('view', 'NN'), ('method', 'VBP'), ('claim', 'NN'), ('wherein', 'NN'), ('generating', 'VBG'), ('second', 'JJ'), ('depth', 'NN'), ('map', 'NN'), ('comprises', 'VBZ'), ('estimating', 'VBG'), ('depth', 'NN'), ('map', 'FW'), ('residual', 'JJ'), ('region', 'NN'), ('based', 'VBN'), ('estimated', 'VBN'), ('relationship', 'NN'), ('primary', 'JJ'), ('region', 'NN'), ('residual', 'JJ'), ('region', 'NN'), ('first', 'RB'), ('depth', 'VBZ'), ('map', 'JJ'), ('generating', 'VBG'), ('second', 'JJ'), ('depth', 'NN'), ('map', 'NNS'), ('based', 'VBN'), ('depth', 'JJ'), ('map', 'JJ'), ('residual', 'JJ'), ('region', 'NN'), ('first', 'RB'), ('depth', 'VBZ'), ('map', 'JJ'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('estimating', 'VBG'), ('relationship', 'NN'), ('primary', 'JJ'), ('region', 'NN'), ('second', 'JJ'), ('image', 'NN'), ('performed', 'VBD'), ('using', 'VBG'), ('neural', 'JJ'), ('network', 'NN'), ('model', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('performing', 'VBG'), ('pre-processing', 'JJ'), ('operation', 'NN'), ('second', 'JJ'), ('depth', 'NN'), ('map', 'NN'), ('generating', 'VBG'), ('third', 'JJ'), ('depth', 'NN'), ('map', 'NN'), ('residual', 'JJ'), ('image', 'NN'), ('fusing', 'VBG'), ('second', 'JJ'), ('depth', 'JJ'), ('map', 'NN'), ('pre-processing', 'JJ'), ('operation', 'NN'), ('performed', 'VBD'), ('first', 'JJ'), ('depth', 'NN'), ('map', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('performing', 'VBG'), ('pre-processing', 'JJ'), ('operation', 'NN'), ('comprises', 'NNS'), ('performing', 'VBG'), ('tone', 'NN'), ('mapping', 'NN'), ('operation', 'NN'), ('depth', 'NN'), ('map', 'NN'), ('primary', 'JJ'), ('region', 'NN'), ('depth', 'NN'), ('map', 'VBP'), ('residual', 'JJ'), ('region', 'NN'), ('based', 'VBN'), ('second', 'JJ'), ('depth', 'NN'), ('map', 'NN'), ('operating', 'VBG'), ('method', 'NN'), ('electronic', 'JJ'), ('apparatus', 'NN'), ('electronic', 'JJ'), ('apparatus', 'NN'), ('including', 'VBG'), ('first', 'JJ'), ('camera', 'NN'), ('module', 'NN'), ('providing', 'VBG'), ('first', 'JJ'), ('image', 'NN'), ('object', 'NN'), ('using', 'VBG'), ('first', 'JJ'), ('field', 'NN'), ('view', 'NN'), ('second', 'JJ'), ('camera', 'NN'), ('module', 'NN'), ('providing', 'VBG'), ('second', 'JJ'), ('image', 'NN'), ('object', 'NN'), ('using', 'VBG'), ('second', 'JJ'), ('field', 'NN'), ('view', 'NN'), ('wider', 'VBP'), ('first', 'JJ'), ('field', 'NN'), ('view', 'NN'), ('processor', 'NN'), ('generating', 'VBG'), ('depth', 'JJ'), ('map', 'JJ'), ('second', 'JJ'), ('image', 'NN'), ('based', 'VBN'), ('primary', 'JJ'), ('region', 'NN'), ('second', 'JJ'), ('image', 'NN'), ('residual', 'JJ'), ('region', 'NN'), ('second', 'JJ'), ('image', 'NN'), ('operating', 'VBG'), ('method', 'NN'), ('comprising', 'VBG'), ('generating', 'VBG'), ('first', 'JJ'), ('depth', 'NN'), ('map', 'NN'), ('primary', 'JJ'), ('region', 'NN'), ('estimating', 'VBG'), ('relationship', 'NN'), ('first', 'JJ'), ('image', 'NN'), ('second', 'JJ'), ('image', 'NN'), ('estimating', 'VBG'), ('relationship', 'NN'), ('primary', 'JJ'), ('region', 'NN'), ('residual', 'JJ'), ('region', 'NN'), ('based', 'VBN'), ('first', 'JJ'), ('image', 'NN'), ('second', 'JJ'), ('image', 'NN'), ('generating', 'VBG'), ('second', 'JJ'), ('depth', 'NN'), ('map', 'NN'), ('second', 'JJ'), ('image', 'NN'), ('estimating', 'VBG'), ('depth', 'JJ'), ('map', 'JJ'), ('second', 'JJ'), ('region', 'NN'), ('based', 'VBN'), ('estimated', 'VBN'), ('relationship', 'NN'), ('primary', 'JJ'), ('region', 'NN'), ('residual', 'JJ'), ('region', 'NN'), ('generating', 'VBG'), ('depth', 'JJ'), ('map', 'JJ'), ('second', 'JJ'), ('image', 'NN'), ('fusing', 'VBG'), ('first', 'JJ'), ('depth', 'NN'), ('map', 'NN'), ('second', 'JJ'), ('depth', 'NN'), ('map', 'NN'), ('operation', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('executing', 'VBG'), ('application', 'NN'), ('applies', 'NNS'), ('image', 'NN'), ('effect', 'NN'), ('second', 'JJ'), ('image', 'NN'), ('based', 'VBN'), ('depth', 'JJ'), ('map', 'NN'), ('residual', 'JJ'), ('image', 'NN'), ('operation', 'NN'), ('method', 'FW'), ('claim', 'NN'), ('wherein', 'WRB'), ('application', 'NN'), ('applies', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('image', 'NN'), ('effect', 'NN'), ('auto-focusing', 'JJ'), ('out-focusing', 'JJ'), ('forebackground', 'NN'), ('separation', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('object', 'JJ'), ('detection', 'NN'), ('within', 'IN'), ('frame', 'NN'), ('augmented', 'JJ'), ('reality', 'NN'), ('second', 'JJ'), ('image', 'NN'), ('based', 'VBN'), ('depth', 'JJ'), ('map', 'JJ'), ('second', 'JJ'), ('image', 'NN'), ('payment', 'NN'), ('method', 'NN'), ('based', 'VBN'), ('face', 'NN'), ('recognition', 'NN'), ('comprising', 'VBG'), ('acquiring', 'VBG'), ('first', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('information', 'NN'), ('target', 'NN'), ('user', 'NN'), ('extracting', 'VBG'), ('first', 'JJ'), ('characteristic', 'JJ'), ('information', 'NN'), ('first', 'RB'), ('face', 'NN'), ('image', 'NN'), ('information', 'NN'), ('wherein', 'IN'), ('first', 'JJ'), ('characteristic', 'JJ'), ('information', 'NN'), ('includes', 'VBZ'), ('head', 'NN'), ('posture', 'NN'), ('information', 'NN'), ('target', 'NN'), ('user', 'NN'), ('gaze', 'NN'), ('information', 'NN'), ('target', 'NN'), ('user', 'NN'), ('determining', 'VBG'), ('whether', 'IN'), ('target', 'NN'), ('user', 'JJ'), ('willingness', 'NN'), ('pay', 'NN'), ('according', 'VBG'), ('head', 'NN'), ('posture', 'NN'), ('information', 'NN'), ('target', 'NN'), ('user', 'NN'), ('gaze', 'NN'), ('information', 'NN'), ('target', 'NN'), ('user', 'NN'), ('including', 'VBG'), ('determining', 'VBG'), ('whether', 'IN'), ('angle', 'JJ'), ('rotation', 'NN'), ('preset', 'VBN'), ('direction', 'NN'), ('less', 'RBR'), ('angle', 'JJ'), ('threshold', 'NN'), ('wherein', 'NN'), ('head', 'NN'), ('posture', 'NN'), ('information', 'NN'), ('includes', 'VBZ'), ('angle', 'JJ'), ('rotation', 'NN'), ('preset', 'VBN'), ('direction', 'NN'), ('determining', 'VBG'), ('whether', 'IN'), ('probability', 'NN'), ('value', 'NN'), ('user', 'NN'), ('gazes', 'JJ'), ('payment', 'NN'), ('screen', 'NN'), ('greater', 'JJR'), ('probability', 'NN'), ('threshold', 'NN'), ('wherein', 'NN'), ('gaze', 'JJ'), ('information', 'NN'), ('includes', 'VBZ'), ('probability', 'NN'), ('value', 'NN'), ('user', 'NN'), ('gazes', 'JJ'), ('payment', 'NN'), ('screen', 'NN'), ('response', 'NN'), ('determining', 'VBG'), ('angle', 'JJ'), ('rotation', 'NN'), ('preset', 'VBN'), ('direction', 'NN'), ('less', 'RBR'), ('angle', 'JJ'), ('threshold', 'NN'), ('probability', 'NN'), ('value', 'NN'), ('user', 'NN'), ('gazes', 'JJ'), ('payment', 'NN'), ('screen', 'NN'), ('greater', 'JJR'), ('probability', 'NN'), ('threshold', 'VBD'), ('determining', 'VBG'), ('target', 'NN'), ('user', 'JJ'), ('willingness', 'NN'), ('pay', 'NN'), ('response', 'NN'), ('determining', 'VBG'), ('target', 'NN'), ('user', 'JJ'), ('willingness', 'NN'), ('pay', 'NN'), ('completing', 'VBG'), ('payment', 'NN'), ('operation', 'NN'), ('based', 'VBN'), ('face', 'NN'), ('recognition', 'NN'), ('method', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('completing', 'VBG'), ('payment', 'NN'), ('operation', 'NN'), ('based', 'VBN'), ('face', 'NN'), ('recognition', 'NN'), ('comprises', 'VBZ'), ('triggering', 'VBG'), ('performing', 'VBG'), ('payment', 'NN'), ('initiating', 'NN'), ('operation', 'NN'), ('acquire', 'VB'), ('second', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('information', 'NN'), ('based', 'VBN'), ('face', 'NN'), ('recognition', 'NN'), ('determining', 'VBG'), ('whether', 'IN'), ('second', 'JJ'), ('characteristic', 'JJ'), ('information', 'NN'), ('extracted', 'VBD'), ('second', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('information', 'NN'), ('indicates', 'VBZ'), ('user', 'JJ'), ('willingness', 'NN'), ('pay', 'NN'), ('response', 'NN'), ('determining', 'VBG'), ('second', 'JJ'), ('characteristic', 'JJ'), ('information', 'NN'), ('indicates', 'VBZ'), ('user', 'JJ'), ('willingness', 'NN'), ('pay', 'NN'), ('triggering', 'VBG'), ('performing', 'VBG'), ('payment', 'NN'), ('confirmation', 'NN'), ('operation', 'NN'), ('complete', 'JJ'), ('payment', 'NN'), ('operation', 'NN'), ('based', 'VBN'), ('payment', 'NN'), ('account', 'NN'), ('information', 'NN'), ('corresponding', 'VBG'), ('target', 'NN'), ('user', 'JJ'), ('method', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('determining', 'VBG'), ('whether', 'IN'), ('second', 'JJ'), ('characteristic', 'JJ'), ('information', 'NN'), ('extracted', 'VBD'), ('second', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('information', 'NN'), ('indicates', 'VBZ'), ('user', 'JJ'), ('willingness', 'NN'), ('pay', 'NN'), ('comprises', 'VBZ'), ('determining', 'VBG'), ('whether', 'IN'), ('current', 'JJ'), ('user', 'NN'), ('corresponding', 'VBG'), ('second', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('information', 'NN'), ('consistent', 'JJ'), ('target', 'NN'), ('user', 'JJ'), ('response', 'NN'), ('determining', 'VBG'), ('current', 'JJ'), ('user', 'JJ'), ('consistent', 'NN'), ('target', 'NN'), ('user', 'IN'), ('determining', 'VBG'), ('whether', 'IN'), ('target', 'NN'), ('user', 'JJ'), ('willingness', 'NN'), ('pay', 'NN'), ('according', 'VBG'), ('second', 'JJ'), ('characteristic', 'JJ'), ('information', 'NN'), ('extracted', 'VBD'), ('second', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('information', 'NN'), ('method', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('extracting', 'VBG'), ('first', 'JJ'), ('characteristic', 'JJ'), ('information', 'NN'), ('first', 'RB'), ('face', 'NN'), ('image', 'NN'), ('information', 'NN'), ('comprises', 'VBZ'), ('determining', 'VBG'), ('head', 'NN'), ('posture', 'NN'), ('information', 'NN'), ('target', 'NN'), ('user', 'NN'), ('using', 'VBG'), ('head', 'NN'), ('posture', 'NN'), ('recognition', 'NN'), ('model', 'NN'), ('based', 'VBN'), ('first', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('information', 'NN'), ('determining', 'VBG'), ('gaze', 'NN'), ('information', 'NN'), ('target', 'NN'), ('user', 'NN'), ('using', 'VBG'), ('gaze', 'JJ'), ('information', 'NN'), ('recognition', 'NN'), ('model', 'NN'), ('based', 'VBN'), ('characteristics', 'NNS'), ('eye', 'NN'), ('region', 'NN'), ('first', 'RB'), ('face', 'JJ'), ('image', 'NN'), ('information', 'NN'), ('method', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('head', 'NN'), ('posture', 'NN'), ('recognition', 'NN'), ('model', 'NN'), ('obtained', 'VBD'), ('training', 'VBG'), ('acquiring', 'VBG'), ('first', 'JJ'), ('sample', 'NN'), ('data', 'NNS'), ('set', 'VBD'), ('wherein', 'NN'), ('first', 'JJ'), ('sample', 'NN'), ('data', 'NNS'), ('set', 'VBD'), ('includes', 'VBZ'), ('plurality', 'NN'), ('pieces', 'NNS'), ('first', 'RB'), ('sample', 'JJ'), ('data', 'NNS'), ('plurality', 'NN'), ('pieces', 'NNS'), ('first', 'RB'), ('sample', 'JJ'), ('data', 'NNS'), ('includes', 'VBZ'), ('correspondence', 'NN'), ('sample', 'NN'), ('face', 'NN'), ('image', 'NN'), ('head', 'NN'), ('posture', 'NN'), ('information', 'NN'), ('determining', 'VBG'), ('mean', 'JJ'), ('image', 'NN'), ('data', 'NNS'), ('variance', 'NN'), ('image', 'NN'), ('data', 'NNS'), ('plurality', 'NN'), ('sample', 'NN'), ('face', 'NN'), ('images', 'VBZ'), ('plurality', 'NN'), ('pieces', 'NNS'), ('first', 'RB'), ('sample', 'JJ'), ('data', 'NNS'), ('preprocessing', 'VBG'), ('sample', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('contained', 'VBD'), ('plurality', 'NN'), ('pieces', 'NNS'), ('first', 'RB'), ('sample', 'VB'), ('data', 'NNS'), ('based', 'VBN'), ('mean', 'JJ'), ('image', 'NN'), ('data', 'NNS'), ('variance', 'NN'), ('image', 'NN'), ('data', 'NNS'), ('obtain', 'VB'), ('preprocessed', 'JJ'), ('sample', 'NN'), ('face', 'NN'), ('image', 'NN'), ('setting', 'VBG'), ('preprocessed', 'JJ'), ('sample', 'NN'), ('face', 'NN'), ('image', 'NN'), ('corresponding', 'VBG'), ('head', 'JJ'), ('posture', 'NN'), ('information', 'NN'), ('first', 'RB'), ('model', 'VBZ'), ('training', 'VBG'), ('sample', 'JJ'), ('performing', 'VBG'), ('training', 'NN'), ('using', 'VBG'), ('machine', 'NN'), ('learning', 'VBG'), ('method', 'NNS'), ('based', 'VBN'), ('plurality', 'NN'), ('first', 'JJ'), ('model', 'NN'), ('training', 'NN'), ('samples', 'NNS'), ('obtain', 'VB'), ('head', 'JJ'), ('posture', 'NN'), ('recognition', 'NN'), ('model', 'NN'), ('method', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('gaze', 'NN'), ('information', 'NN'), ('recognition', 'NN'), ('model', 'NN'), ('obtained', 'VBD'), ('training', 'VBG'), ('acquiring', 'VBG'), ('second', 'JJ'), ('sample', 'NN'), ('data', 'NNS'), ('set', 'VBD'), ('wherein', 'JJ'), ('second', 'JJ'), ('sample', 'NN'), ('data', 'NNS'), ('set', 'VBD'), ('includes', 'VBZ'), ('plurality', 'NN'), ('pieces', 'NNS'), ('second', 'JJ'), ('sample', 'NN'), ('data', 'NNS'), ('plurality', 'NN'), ('pieces', 'NNS'), ('second', 'JJ'), ('sample', 'JJ'), ('data', 'NNS'), ('includes', 'VBZ'), ('correspondence', 'NN'), ('sample', 'NN'), ('eye', 'NN'), ('image', 'NN'), ('gaze', 'JJ'), ('information', 'NN'), ('determining', 'VBG'), ('mean', 'JJ'), ('image', 'NN'), ('data', 'NNS'), ('variance', 'NN'), ('image', 'NN'), ('data', 'NNS'), ('plurality', 'NN'), ('sample', 'NN'), ('eye', 'NN'), ('images', 'VBZ'), ('plurality', 'NN'), ('pieces', 'NNS'), ('second', 'JJ'), ('sample', 'NN'), ('data', 'NNS'), ('preprocessing', 'VBG'), ('sample', 'NN'), ('eye', 'NN'), ('image', 'NN'), ('contained', 'VBD'), ('plurality', 'NN'), ('pieces', 'NNS'), ('second', 'JJ'), ('sample', 'NN'), ('data', 'NNS'), ('based', 'VBN'), ('mean', 'JJ'), ('image', 'NN'), ('data', 'NNS'), ('variance', 'NN'), ('image', 'NN'), ('data', 'NNS'), ('obtain', 'VB'), ('preprocessed', 'JJ'), ('sample', 'NN'), ('eye', 'NN'), ('image', 'NN'), ('setting', 'VBG'), ('preprocessed', 'JJ'), ('sample', 'NN'), ('eye', 'NN'), ('image', 'NN'), ('corresponding', 'VBG'), ('gaze', 'JJ'), ('information', 'NN'), ('second', 'JJ'), ('model', 'NN'), ('training', 'VBG'), ('sample', 'JJ'), ('performing', 'VBG'), ('training', 'NN'), ('using', 'VBG'), ('machine', 'NN'), ('learning', 'VBG'), ('method', 'NNS'), ('based', 'VBN'), ('plurality', 'NN'), ('second', 'JJ'), ('model', 'NN'), ('training', 'NN'), ('samples', 'NNS'), ('obtain', 'VB'), ('gaze', 'JJ'), ('information', 'NN'), ('recognition', 'NN'), ('model', 'NN'), ('method', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('angle', 'VBZ'), ('rotation', 'NN'), ('preset', 'VBN'), ('direction', 'NN'), ('comprises', 'VBZ'), ('pitch', 'VBP'), ('angle', 'NN'), ('yaw', 'NN'), ('angle', 'NN'), ('roll', 'NN'), ('angle', 'NN'), ('wherein', 'NN'), ('pitch', 'NN'), ('angle', 'NN'), ('refers', 'NNS'), ('angle', 'VBP'), ('rotation', 'NN'), ('around', 'IN'), ('x-axis', 'JJ'), ('yaw', 'NN'), ('angle', 'NN'), ('refers', 'NNS'), ('angle', 'VBP'), ('rotation', 'NN'), ('around', 'IN'), ('y-axis', 'JJ'), ('roll', 'NN'), ('angle', 'NN'), ('refers', 'NNS'), ('angle', 'VBP'), ('rotation', 'NN'), ('around', 'IN'), ('z-axis', 'JJ'), ('payment', 'NN'), ('device', 'NN'), ('based', 'VBN'), ('face', 'NN'), ('recognition', 'NN'), ('comprising', 'VBG'), ('processor', 'JJ'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('storage', 'NN'), ('medium', 'NN'), ('storing', 'VBG'), ('instructions', 'NNS'), ('executable', 'JJ'), ('processor', 'NN'), ('cause', 'NN'), ('device', 'NN'), ('perform', 'NN'), ('operations', 'NNS'), ('comprising', 'VBG'), ('acquiring', 'VBG'), ('first', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('information', 'NN'), ('target', 'NN'), ('user', 'NN'), ('extracting', 'VBG'), ('first', 'JJ'), ('characteristic', 'JJ'), ('information', 'NN'), ('first', 'RB'), ('face', 'NN'), ('image', 'NN'), ('information', 'NN'), ('wherein', 'IN'), ('first', 'JJ'), ('characteristic', 'JJ'), ('information', 'NN'), ('includes', 'VBZ'), ('head', 'NN'), ('posture', 'NN'), ('information', 'NN'), ('target', 'NN'), ('user', 'NN'), ('gaze', 'NN'), ('information', 'NN'), ('target', 'NN'), ('user', 'NN'), ('determining', 'VBG'), ('whether', 'IN'), ('target', 'NN'), ('user', 'JJ'), ('willingness', 'NN'), ('pay', 'NN'), ('according', 'VBG'), ('head', 'NN'), ('posture', 'NN'), ('information', 'NN'), ('target', 'NN'), ('user', 'NN'), ('gaze', 'NN'), ('information', 'NN'), ('target', 'NN'), ('user', 'NN'), ('including', 'VBG'), ('determining', 'VBG'), ('whether', 'IN'), ('angle', 'JJ'), ('rotation', 'NN'), ('preset', 'VBN'), ('direction', 'NN'), ('less', 'RBR'), ('angle', 'JJ'), ('threshold', 'NN'), ('wherein', 'NN'), ('head', 'NN'), ('posture', 'NN'), ('information', 'NN'), ('includes', 'VBZ'), ('angle', 'JJ'), ('rotation', 'NN'), ('preset', 'VBN'), ('direction', 'NN'), ('determining', 'VBG'), ('whether', 'IN'), ('probability', 'NN'), ('value', 'NN'), ('user', 'NN'), ('gazes', 'JJ'), ('payment', 'NN'), ('screen', 'NN'), ('greater', 'JJR'), ('probability', 'NN'), ('threshold', 'NN'), ('wherein', 'NN'), ('gaze', 'JJ'), ('information', 'NN'), ('includes', 'VBZ'), ('probability', 'NN'), ('value', 'NN'), ('user', 'NN'), ('gazes', 'JJ'), ('payment', 'NN'), ('screen', 'NN'), ('response', 'NN'), ('determining', 'VBG'), ('angle', 'JJ'), ('rotation', 'NN'), ('preset', 'VBN'), ('direction', 'NN'), ('less', 'RBR'), ('angle', 'JJ'), ('threshold', 'NN'), ('probability', 'NN'), ('value', 'NN'), ('user', 'NN'), ('gazes', 'JJ'), ('payment', 'NN'), ('screen', 'NN'), ('greater', 'JJR'), ('probability', 'NN'), ('threshold', 'VBD'), ('determining', 'VBG'), ('target', 'NN'), ('user', 'JJ'), ('willingness', 'NN'), ('pay', 'NN'), ('response', 'NN'), ('determining', 'VBG'), ('target', 'NN'), ('user', 'JJ'), ('willingness', 'NN'), ('pay', 'NN'), ('completing', 'VBG'), ('payment', 'NN'), ('operation', 'NN'), ('based', 'VBN'), ('face', 'NN'), ('recognition', 'NN'), ('device', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('completing', 'VBG'), ('payment', 'NN'), ('operation', 'NN'), ('based', 'VBN'), ('face', 'NN'), ('recognition', 'NN'), ('comprises', 'VBZ'), ('triggering', 'VBG'), ('performing', 'VBG'), ('payment', 'NN'), ('initiating', 'NN'), ('operation', 'NN'), ('acquire', 'VB'), ('second', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('information', 'NN'), ('based', 'VBN'), ('face', 'NN'), ('recognition', 'NN'), ('determining', 'VBG'), ('whether', 'IN'), ('second', 'JJ'), ('characteristic', 'JJ'), ('information', 'NN'), ('extracted', 'VBD'), ('second', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('information', 'NN'), ('indicates', 'VBZ'), ('user', 'JJ'), ('willingness', 'NN'), ('pay', 'NN'), ('response', 'NN'), ('determining', 'VBG'), ('second', 'JJ'), ('characteristic', 'JJ'), ('information', 'NN'), ('indicates', 'VBZ'), ('user', 'JJ'), ('willingness', 'NN'), ('pay', 'NN'), ('triggering', 'VBG'), ('performing', 'VBG'), ('payment', 'NN'), ('confirmation', 'NN'), ('operation', 'NN'), ('complete', 'JJ'), ('payment', 'NN'), ('operation', 'NN'), ('based', 'VBN'), ('payment', 'NN'), ('account', 'NN'), ('information', 'NN'), ('corresponding', 'VBG'), ('target', 'NN'), ('user', 'JJ'), ('device', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('determining', 'VBG'), ('whether', 'IN'), ('second', 'JJ'), ('characteristic', 'JJ'), ('information', 'NN'), ('extracted', 'VBD'), ('second', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('information', 'NN'), ('indicates', 'VBZ'), ('user', 'JJ'), ('willingness', 'NN'), ('pay', 'NN'), ('comprises', 'VBZ'), ('determining', 'VBG'), ('whether', 'IN'), ('current', 'JJ'), ('user', 'NN'), ('corresponding', 'VBG'), ('second', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('information', 'NN'), ('consistent', 'JJ'), ('target', 'NN'), ('user', 'JJ'), ('response', 'NN'), ('determining', 'VBG'), ('current', 'JJ'), ('user', 'JJ'), ('consistent', 'NN'), ('target', 'NN'), ('user', 'IN'), ('determining', 'VBG'), ('whether', 'IN'), ('target', 'NN'), ('user', 'JJ'), ('willingness', 'NN'), ('pay', 'NN'), ('according', 'VBG'), ('second', 'JJ'), ('characteristic', 'JJ'), ('information', 'NN'), ('extracted', 'VBD'), ('second', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('information', 'NN'), ('device', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('extracting', 'VBG'), ('first', 'JJ'), ('characteristic', 'JJ'), ('information', 'NN'), ('first', 'RB'), ('face', 'NN'), ('image', 'NN'), ('information', 'NN'), ('comprises', 'VBZ'), ('determining', 'VBG'), ('head', 'NN'), ('posture', 'NN'), ('information', 'NN'), ('target', 'NN'), ('user', 'NN'), ('using', 'VBG'), ('head', 'NN'), ('posture', 'NN'), ('recognition', 'NN'), ('model', 'NN'), ('based', 'VBN'), ('first', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('information', 'NN'), ('determining', 'VBG'), ('gaze', 'NN'), ('information', 'NN'), ('target', 'NN'), ('user', 'NN'), ('using', 'VBG'), ('gaze', 'JJ'), ('information', 'NN'), ('recognition', 'NN'), ('model', 'NN'), ('based', 'VBN'), ('characteristics', 'NNS'), ('eye', 'NN'), ('region', 'NN'), ('first', 'RB'), ('face', 'JJ'), ('image', 'NN'), ('information', 'NN'), ('device', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('head', 'NN'), ('posture', 'NN'), ('recognition', 'NN'), ('model', 'NN'), ('obtained', 'VBD'), ('training', 'VBG'), ('acquiring', 'VBG'), ('first', 'JJ'), ('sample', 'NN'), ('data', 'NNS'), ('set', 'VBD'), ('wherein', 'NN'), ('first', 'JJ'), ('sample', 'NN'), ('data', 'NNS'), ('set', 'VBD'), ('includes', 'VBZ'), ('plurality', 'NN'), ('pieces', 'NNS'), ('first', 'RB'), ('sample', 'JJ'), ('data', 'NNS'), ('plurality', 'NN'), ('pieces', 'NNS'), ('first', 'RB'), ('sample', 'JJ'), ('data', 'NNS'), ('includes', 'VBZ'), ('correspondence', 'NN'), ('sample', 'NN'), ('face', 'NN'), ('image', 'NN'), ('head', 'NN'), ('posture', 'NN'), ('information', 'NN'), ('determining', 'VBG'), ('mean', 'JJ'), ('image', 'NN'), ('data', 'NNS'), ('variance', 'NN'), ('image', 'NN'), ('data', 'NNS'), ('plurality', 'NN'), ('sample', 'NN'), ('face', 'NN'), ('images', 'VBZ'), ('plurality', 'NN'), ('pieces', 'NNS'), ('first', 'RB'), ('sample', 'JJ'), ('data', 'NNS'), ('preprocessing', 'VBG'), ('sample', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('contained', 'VBD'), ('plurality', 'NN'), ('pieces', 'NNS'), ('first', 'RB'), ('sample', 'VB'), ('data', 'NNS'), ('based', 'VBN'), ('mean', 'JJ'), ('image', 'NN'), ('data', 'NNS'), ('variance', 'NN'), ('image', 'NN'), ('data', 'NNS'), ('obtain', 'VB'), ('preprocessed', 'JJ'), ('sample', 'NN'), ('face', 'NN'), ('image', 'NN'), ('setting', 'VBG'), ('preprocessed', 'JJ'), ('sample', 'NN'), ('face', 'NN'), ('image', 'NN'), ('corresponding', 'VBG'), ('head', 'JJ'), ('posture', 'NN'), ('information', 'NN'), ('first', 'RB'), ('model', 'VBZ'), ('training', 'VBG'), ('sample', 'JJ'), ('performing', 'VBG'), ('training', 'NN'), ('using', 'VBG'), ('machine', 'NN'), ('learning', 'VBG'), ('method', 'NNS'), ('based', 'VBN'), ('plurality', 'NN'), ('first', 'JJ'), ('model', 'NN'), ('training', 'NN'), ('samples', 'NNS'), ('obtain', 'VB'), ('head', 'JJ'), ('posture', 'NN'), ('recognition', 'NN'), ('model', 'NN'), ('device', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('gaze', 'NN'), ('information', 'NN'), ('recognition', 'NN'), ('model', 'NN'), ('obtained', 'VBD'), ('training', 'VBG'), ('acquiring', 'VBG'), ('second', 'JJ'), ('sample', 'NN'), ('data', 'NNS'), ('set', 'VBD'), ('wherein', 'JJ'), ('second', 'JJ'), ('sample', 'NN'), ('data', 'NNS'), ('set', 'VBD'), ('includes', 'VBZ'), ('plurality', 'NN'), ('pieces', 'NNS'), ('second', 'JJ'), ('sample', 'NN'), ('data', 'NNS'), ('plurality', 'NN'), ('pieces', 'NNS'), ('second', 'JJ'), ('sample', 'JJ'), ('data', 'NNS'), ('includes', 'VBZ'), ('correspondence', 'NN'), ('sample', 'NN'), ('eye', 'NN'), ('image', 'NN'), ('gaze', 'JJ'), ('information', 'NN'), ('determining', 'VBG'), ('mean', 'JJ'), ('image', 'NN'), ('data', 'NNS'), ('variance', 'NN'), ('image', 'NN'), ('data', 'NNS'), ('plurality', 'NN'), ('sample', 'NN'), ('eye', 'NN'), ('images', 'VBZ'), ('plurality', 'NN'), ('pieces', 'NNS'), ('second', 'JJ'), ('sample', 'NN'), ('data', 'NNS'), ('preprocessing', 'VBG'), ('sample', 'NN'), ('eye', 'NN'), ('image', 'NN'), ('contained', 'VBD'), ('plurality', 'NN'), ('pieces', 'NNS'), ('second', 'JJ'), ('sample', 'NN'), ('data', 'NNS'), ('based', 'VBN'), ('mean', 'JJ'), ('image', 'NN'), ('data', 'NNS'), ('variance', 'NN'), ('image', 'NN'), ('data', 'NNS'), ('obtain', 'VB'), ('preprocessed', 'JJ'), ('sample', 'NN'), ('eye', 'NN'), ('image', 'NN'), ('setting', 'VBG'), ('preprocessed', 'JJ'), ('sample', 'NN'), ('eye', 'NN'), ('image', 'NN'), ('corresponding', 'VBG'), ('gaze', 'JJ'), ('information', 'NN'), ('second', 'JJ'), ('model', 'NN'), ('training', 'VBG'), ('sample', 'JJ'), ('performing', 'VBG'), ('training', 'NN'), ('using', 'VBG'), ('machine', 'NN'), ('learning', 'VBG'), ('method', 'JJ'), ('plurality', 'NN'), ('second', 'JJ'), ('model', 'NN'), ('training', 'NN'), ('samples', 'NNS'), ('obtain', 'VB'), ('gaze', 'JJ'), ('information', 'NN'), ('recognition', 'NN'), ('model', 'NN'), ('device', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('angle', 'VBZ'), ('rotation', 'NN'), ('preset', 'VBN'), ('direction', 'NN'), ('comprises', 'VBZ'), ('pitch', 'VBP'), ('angle', 'NN'), ('yaw', 'NN'), ('angle', 'NN'), ('roll', 'NN'), ('angle', 'NN'), ('wherein', 'NN'), ('pitch', 'NN'), ('angle', 'NN'), ('refers', 'NNS'), ('angle', 'VBP'), ('rotation', 'NN'), ('around', 'IN'), ('x-axis', 'JJ'), ('yaw', 'NN'), ('angle', 'NN'), ('refers', 'NNS'), ('angle', 'VBP'), ('rotation', 'NN'), ('around', 'IN'), ('y-axis', 'JJ'), ('roll', 'NN'), ('angle', 'NN'), ('refers', 'NNS'), ('angle', 'VBP'), ('rotation', 'NN'), ('around', 'IN'), ('z-axis', 'JJ'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('storage', 'NN'), ('medium', 'NN'), ('payment', 'NN'), ('based', 'VBN'), ('face', 'NN'), ('recognition', 'NN'), ('configured', 'VBD'), ('instructions', 'NNS'), ('executable', 'JJ'), ('one', 'CD'), ('processors', 'NNS'), ('cause', 'VBP'), ('one', 'CD'), ('processors', 'NNS'), ('perform', 'VB'), ('operations', 'NNS'), ('comprising', 'VBG'), ('acquiring', 'VBG'), ('first', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('information', 'NN'), ('target', 'NN'), ('user', 'NN'), ('extracting', 'VBG'), ('first', 'JJ'), ('characteristic', 'JJ'), ('information', 'NN'), ('first', 'RB'), ('face', 'NN'), ('image', 'NN'), ('information', 'NN'), ('wherein', 'IN'), ('first', 'JJ'), ('characteristic', 'JJ'), ('information', 'NN'), ('includes', 'VBZ'), ('head', 'NN'), ('posture', 'NN'), ('information', 'NN'), ('target', 'NN'), ('user', 'NN'), ('gaze', 'NN'), ('information', 'NN'), ('target', 'NN'), ('user', 'NN'), ('determining', 'VBG'), ('whether', 'IN'), ('target', 'NN'), ('user', 'JJ'), ('willingness', 'NN'), ('pay', 'NN'), ('according', 'VBG'), ('head', 'NN'), ('posture', 'NN'), ('information', 'NN'), ('target', 'NN'), ('user', 'NN'), ('gaze', 'NN'), ('information', 'NN'), ('target', 'NN'), ('user', 'NN'), ('including', 'VBG'), ('determining', 'VBG'), ('whether', 'IN'), ('angle', 'JJ'), ('rotation', 'NN'), ('preset', 'VBN'), ('direction', 'NN'), ('less', 'RBR'), ('angle', 'JJ'), ('threshold', 'NN'), ('wherein', 'NN'), ('head', 'NN'), ('posture', 'NN'), ('information', 'NN'), ('includes', 'VBZ'), ('angle', 'JJ'), ('rotation', 'NN'), ('preset', 'VBN'), ('direction', 'NN'), ('determining', 'VBG'), ('whether', 'IN'), ('probability', 'NN'), ('value', 'NN'), ('user', 'NN'), ('gazes', 'JJ'), ('payment', 'NN'), ('screen', 'NN'), ('greater', 'JJR'), ('probability', 'NN'), ('threshold', 'NN'), ('wherein', 'NN'), ('gaze', 'JJ'), ('information', 'NN'), ('includes', 'VBZ'), ('probability', 'NN'), ('value', 'NN'), ('user', 'NN'), ('gazes', 'JJ'), ('payment', 'NN'), ('screen', 'NN'), ('response', 'NN'), ('determining', 'VBG'), ('angle', 'JJ'), ('rotation', 'NN'), ('preset', 'VBN'), ('direction', 'NN'), ('less', 'RBR'), ('angle', 'JJ'), ('threshold', 'NN'), ('probability', 'NN'), ('value', 'NN'), ('user', 'NN'), ('gazes', 'JJ'), ('payment', 'NN'), ('screen', 'NN'), ('greater', 'JJR'), ('probability', 'NN'), ('threshold', 'VBD'), ('determining', 'VBG'), ('target', 'NN'), ('user', 'JJ'), ('willingness', 'NN'), ('pay', 'NN'), ('response', 'NN'), ('determining', 'VBG'), ('target', 'NN'), ('user', 'JJ'), ('willingness', 'NN'), ('pay', 'NN'), ('completing', 'VBG'), ('payment', 'NN'), ('operation', 'NN'), ('based', 'VBN'), ('face', 'NN'), ('recognition', 'NN'), ('storage', 'NN'), ('medium', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('completing', 'VBG'), ('payment', 'NN'), ('operation', 'NN'), ('based', 'VBN'), ('face', 'NN'), ('recognition', 'NN'), ('comprises', 'VBZ'), ('triggering', 'VBG'), ('performing', 'VBG'), ('payment', 'NN'), ('initiating', 'NN'), ('operation', 'NN'), ('acquire', 'VB'), ('second', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('information', 'NN'), ('based', 'VBN'), ('face', 'NN'), ('recognition', 'NN'), ('determining', 'VBG'), ('whether', 'IN'), ('second', 'JJ'), ('characteristic', 'JJ'), ('information', 'NN'), ('extracted', 'VBD'), ('second', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('information', 'NN'), ('indicates', 'VBZ'), ('user', 'JJ'), ('willingness', 'NN'), ('pay', 'NN'), ('response', 'NN'), ('determining', 'VBG'), ('second', 'JJ'), ('characteristic', 'JJ'), ('information', 'NN'), ('indicates', 'VBZ'), ('user', 'JJ'), ('willingness', 'NN'), ('pay', 'NN'), ('triggering', 'VBG'), ('performing', 'VBG'), ('payment', 'NN'), ('confirmation', 'NN'), ('operation', 'NN'), ('complete', 'JJ'), ('payment', 'NN'), ('operation', 'NN'), ('based', 'VBN'), ('payment', 'NN'), ('account', 'NN'), ('information', 'NN'), ('corresponding', 'VBG'), ('target', 'NN'), ('user', 'JJ'), ('storage', 'NN'), ('medium', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('determining', 'VBG'), ('whether', 'IN'), ('second', 'JJ'), ('characteristic', 'JJ'), ('information', 'NN'), ('extracted', 'VBD'), ('second', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('information', 'NN'), ('indicates', 'VBZ'), ('user', 'JJ'), ('willingness', 'NN'), ('pay', 'NN'), ('comprises', 'VBZ'), ('determining', 'VBG'), ('whether', 'IN'), ('current', 'JJ'), ('user', 'NN'), ('corresponding', 'VBG'), ('second', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('information', 'NN'), ('consistent', 'JJ'), ('target', 'NN'), ('user', 'JJ'), ('response', 'NN'), ('determining', 'VBG'), ('current', 'JJ'), ('user', 'JJ'), ('consistent', 'NN'), ('target', 'NN'), ('user', 'IN'), ('determining', 'VBG'), ('whether', 'IN'), ('target', 'NN'), ('user', 'JJ'), ('willingness', 'NN'), ('pay', 'NN'), ('according', 'VBG'), ('second', 'JJ'), ('characteristic', 'JJ'), ('information', 'NN'), ('extracted', 'VBD'), ('second', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('information', 'NN'), ('storage', 'NN'), ('medium', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('extracting', 'VBG'), ('first', 'JJ'), ('characteristic', 'JJ'), ('information', 'NN'), ('first', 'RB'), ('face', 'NN'), ('image', 'NN'), ('information', 'NN'), ('comprises', 'VBZ'), ('determining', 'VBG'), ('head', 'NN'), ('posture', 'NN'), ('information', 'NN'), ('target', 'NN'), ('user', 'NN'), ('using', 'VBG'), ('head', 'NN'), ('posture', 'NN'), ('recognition', 'NN'), ('model', 'NN'), ('based', 'VBN'), ('first', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('information', 'NN'), ('determining', 'VBG'), ('gaze', 'NN'), ('information', 'NN'), ('target', 'NN'), ('user', 'NN'), ('using', 'VBG'), ('gaze', 'JJ'), ('information', 'NN'), ('recognition', 'NN'), ('model', 'NN'), ('based', 'VBN'), ('characteristics', 'NNS'), ('eye', 'NN'), ('region', 'NN'), ('first', 'RB'), ('face', 'JJ'), ('image', 'NN'), ('information', 'NN'), ('storage', 'NN'), ('medium', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('head', 'NN'), ('posture', 'NN'), ('recognition', 'NN'), ('model', 'NN'), ('obtained', 'VBD'), ('training', 'VBG'), ('acquiring', 'VBG'), ('first', 'JJ'), ('sample', 'NN'), ('data', 'NNS'), ('set', 'VBD'), ('wherein', 'NN'), ('first', 'JJ'), ('sample', 'NN'), ('data', 'NNS'), ('set', 'VBD'), ('includes', 'VBZ'), ('plurality', 'NN'), ('pieces', 'NNS'), ('first', 'RB'), ('sample', 'JJ'), ('data', 'NNS'), ('plurality', 'NN'), ('pieces', 'NNS'), ('first', 'RB'), ('sample', 'JJ'), ('data', 'NNS'), ('includes', 'VBZ'), ('correspondence', 'NN'), ('sample', 'NN'), ('face', 'NN'), ('image', 'NN'), ('head', 'NN'), ('posture', 'NN'), ('information', 'NN'), ('determining', 'VBG'), ('mean', 'JJ'), ('image', 'NN'), ('data', 'NNS'), ('variance', 'NN'), ('image', 'NN'), ('data', 'NNS'), ('plurality', 'NN'), ('sample', 'NN'), ('face', 'NN'), ('images', 'VBZ'), ('plurality', 'NN'), ('pieces', 'NNS'), ('first', 'RB'), ('sample', 'JJ'), ('data', 'NNS'), ('preprocessing', 'VBG'), ('sample', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('contained', 'VBD'), ('plurality', 'NN'), ('pieces', 'NNS'), ('first', 'RB'), ('sample', 'VB'), ('data', 'NNS'), ('based', 'VBN'), ('mean', 'JJ'), ('image', 'NN'), ('data', 'NNS'), ('variance', 'NN'), ('image', 'NN'), ('data', 'NNS'), ('obtain', 'VB'), ('preprocessed', 'JJ'), ('sample', 'NN'), ('face', 'NN'), ('image', 'NN'), ('setting', 'VBG'), ('preprocessed', 'JJ'), ('sample', 'NN'), ('face', 'NN'), ('image', 'NN'), ('corresponding', 'VBG'), ('head', 'JJ'), ('posture', 'NN'), ('information', 'NN'), ('first', 'RB'), ('model', 'VBZ'), ('training', 'VBG'), ('sample', 'JJ'), ('performing', 'VBG'), ('training', 'NN'), ('using', 'VBG'), ('machine', 'NN'), ('learning', 'VBG'), ('method', 'NNS'), ('based', 'VBN'), ('plurality', 'NN'), ('first', 'JJ'), ('model', 'NN'), ('training', 'NN'), ('samples', 'NNS'), ('obtain', 'VB'), ('head', 'JJ'), ('posture', 'NN'), ('recognition', 'NN'), ('model', 'NN'), ('wherein', 'VBD'), ('gaze', 'JJ'), ('information', 'NN'), ('recognition', 'NN'), ('model', 'NN'), ('obtained', 'VBD'), ('training', 'VBG'), ('acquiring', 'VBG'), ('second', 'JJ'), ('sample', 'NN'), ('data', 'NNS'), ('set', 'VBD'), ('wherein', 'JJ'), ('second', 'JJ'), ('sample', 'NN'), ('data', 'NNS'), ('set', 'VBD'), ('includes', 'VBZ'), ('plurality', 'NN'), ('pieces', 'NNS'), ('second', 'JJ'), ('sample', 'NN'), ('data', 'NNS'), ('plurality', 'NN'), ('pieces', 'NNS'), ('second', 'JJ'), ('sample', 'JJ'), ('data', 'NNS'), ('includes', 'VBZ'), ('correspondence', 'NN'), ('sample', 'NN'), ('eye', 'NN'), ('image', 'NN'), ('gaze', 'JJ'), ('information', 'NN'), ('determining', 'VBG'), ('mean', 'JJ'), ('image', 'NN'), ('data', 'NNS'), ('variance', 'NN'), ('image', 'NN'), ('data', 'NNS'), ('plurality', 'NN'), ('sample', 'NN'), ('eye', 'NN'), ('images', 'VBZ'), ('plurality', 'NN'), ('pieces', 'NNS'), ('second', 'JJ'), ('sample', 'NN'), ('data', 'NNS'), ('preprocessing', 'VBG'), ('sample', 'NN'), ('eye', 'NN'), ('image', 'NN'), ('contained', 'VBD'), ('plurality', 'NN'), ('pieces', 'NNS'), ('second', 'JJ'), ('sample', 'NN'), ('data', 'NNS'), ('based', 'VBN'), ('mean', 'JJ'), ('image', 'NN'), ('data', 'NNS'), ('variance', 'NN'), ('image', 'NN'), ('data', 'NNS'), ('obtain', 'VB'), ('preprocessed', 'JJ'), ('sample', 'NN'), ('eye', 'NN'), ('image', 'NN'), ('setting', 'VBG'), ('preprocessed', 'JJ'), ('sample', 'NN'), ('eye', 'NN'), ('image', 'NN'), ('corresponding', 'VBG'), ('gaze', 'JJ'), ('information', 'NN'), ('second', 'JJ'), ('model', 'NN'), ('training', 'VBG'), ('sample', 'JJ'), ('performing', 'VBG'), ('training', 'NN'), ('using', 'VBG'), ('machine', 'NN'), ('learning', 'VBG'), ('method', 'NNS'), ('based', 'VBN'), ('plurality', 'NN'), ('second', 'JJ'), ('model', 'NN'), ('training', 'NN'), ('samples', 'NNS'), ('obtain', 'VB'), ('gaze', 'JJ'), ('information', 'NN'), ('recognition', 'NN'), ('model', 'NN'), ('storage', 'NN'), ('medium', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('angle', 'VBZ'), ('rotation', 'NN'), ('preset', 'VBN'), ('direction', 'NN'), ('comprises', 'VBZ'), ('pitch', 'VBP'), ('angle', 'NN'), ('yaw', 'NN'), ('angle', 'NN'), ('roll', 'NN'), ('angle', 'NN'), ('wherein', 'NN'), ('pitch', 'NN'), ('angle', 'NN'), ('refers', 'NNS'), ('angle', 'VBP'), ('rotation', 'NN'), ('around', 'IN'), ('x-axis', 'JJ'), ('yaw', 'NN'), ('angle', 'NN'), ('refers', 'NNS'), ('angle', 'VBP'), ('rotation', 'NN'), ('around', 'IN'), ('y-axis', 'JJ'), ('roll', 'NN'), ('angle', 'NN'), ('refers', 'NNS'), ('angle', 'VBP'), ('rotation', 'NN'), ('around', 'IN'), ('z-axis', 'JJ'), ('method', 'NN'), ('comprising', 'VBG'), ('detecting', 'VBG'), ('motion', 'NN'), ('detection', 'NN'), ('module', 'NN'), ('motion', 'NN'), ('subject', 'NN'), ('within', 'IN'), ('predetermined', 'JJ'), ('area', 'NN'), ('view', 'NN'), ('assigning', 'VBG'), ('unique', 'JJ'), ('session', 'NN'), ('identification', 'NN'), ('number', 'NN'), ('subject', 'JJ'), ('detected', 'VBD'), ('within', 'IN'), ('predetermined', 'JJ'), ('area', 'NN'), ('view', 'NN'), ('detecting', 'VBG'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'NN'), ('detected', 'VBD'), ('within', 'IN'), ('predetermined', 'JJ'), ('area', 'NN'), ('view', 'NN'), ('generating', 'VBG'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'NN'), ('assessing', 'VBG'), ('quality', 'NN'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'JJ'), ('determining', 'VBG'), ('identity', 'NN'), ('subject', 'NN'), ('based', 'VBN'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'JJ'), ('identifying', 'VBG'), ('intent', 'NN'), ('subject', 'JJ'), ('authorizing', 'VBG'), ('access', 'NN'), ('point', 'NN'), ('entry', 'NN'), ('based', 'VBN'), ('determined', 'VBN'), ('identity', 'NN'), ('subject', 'NN'), ('based', 'VBN'), ('intent', 'NN'), ('subject', 'JJ'), ('method', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('determining', 'VBG'), ('one', 'CD'), ('additional', 'JJ'), ('subjects', 'NNS'), ('within', 'IN'), ('predetermined', 'JJ'), ('area', 'NN'), ('view', 'NN'), ('assigning', 'VBG'), ('unique', 'JJ'), ('session', 'NN'), ('identification', 'NN'), ('number', 'NN'), ('one', 'CD'), ('additional', 'JJ'), ('subjects', 'NNS'), ('detected', 'VBN'), ('within', 'IN'), ('predetermined', 'JJ'), ('area', 'NN'), ('view', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('assessing', 'VBG'), ('quality', 'NN'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'JJ'), ('comprises', 'VBZ'), ('assessing', 'VBG'), ('whether', 'IN'), ('quality', 'NN'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('object', 'NN'), ('equates', 'NNS'), ('predetermined', 'VBD'), ('metric', 'JJ'), ('quality', 'NN'), ('upon', 'IN'), ('determining', 'VBG'), ('quality', 'NN'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('object', 'VBP'), ('inferior', 'JJ'), ('predetermined', 'VBN'), ('metric', 'JJ'), ('quality', 'NN'), ('discarding', 'VBG'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'JJ'), ('generating', 'VBG'), ('second', 'JJ'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'JJ'), ('method', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('detecting', 'VBG'), ('whether', 'IN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'JJ'), ('photographic', 'JJ'), ('image', 'NN'), ('upon', 'IN'), ('detecting', 'VBG'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'JJ'), ('photographic', 'JJ'), ('image', 'NN'), ('generating', 'VBG'), ('warning', 'VBG'), ('restrict', 'JJ'), ('access', 'NN'), ('point', 'NN'), ('entry', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('conducing', 'VBG'), ('incremental', 'JJ'), ('training', 'NN'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'JJ'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('conducing', 'VBG'), ('incremental', 'JJ'), ('training', 'NN'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'JJ'), ('comprises', 'NNS'), ('capturing', 'VBG'), ('first', 'JJ'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('facial', 'JJ'), ('landmarks', 'NNS'), ('converting', 'VBG'), ('first', 'JJ'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('first', 'RB'), ('numeric', 'JJ'), ('vector', 'NN'), ('capturing', 'VBG'), ('second', 'JJ'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('facial', 'JJ'), ('landmarks', 'NNS'), ('converting', 'VBG'), ('second', 'JJ'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('second', 'JJ'), ('numeric', 'JJ'), ('vector', 'NN'), ('calculating', 'VBG'), ('weighted', 'VBD'), ('mean', 'JJ'), ('first', 'JJ'), ('numeric', 'JJ'), ('vector', 'NN'), ('second', 'JJ'), ('numeric', 'JJ'), ('vector', 'NN'), ('wherein', 'NN'), ('weighted', 'VBD'), ('mean', 'JJ'), ('represents', 'VBZ'), ('change', 'VBP'), ('facial', 'JJ'), ('area', 'NN'), ('storing', 'VBG'), ('weighted', 'JJ'), ('mean', 'JJ'), ('database', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('determining', 'VBG'), ('identity', 'NN'), ('subject', 'NN'), ('based', 'VBN'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'JJ'), ('comprises', 'VBZ'), ('comparing', 'VBG'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'JJ'), ('plurality', 'NN'), ('images', 'NNS'), ('stored', 'VBD'), ('database', 'NN'), ('authenticating', 'VBG'), ('subject', 'JJ'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('identifying', 'VBG'), ('intent', 'NN'), ('subject', 'NN'), ('comprises', 'VBZ'), ('upon', 'IN'), ('detecting', 'VBG'), ('facial', 'JJ'), ('area', 'NN'), ('bounding', 'VBG'), ('box', 'NN'), ('commencing', 'VBG'), ('authentication', 'NN'), ('subject', 'JJ'), ('calculating', 'VBG'), ('directional', 'JJ'), ('vector', 'NN'), ('face', 'NN'), ('subject', 'JJ'), ('determine', 'JJ'), ('intent', 'NN'), ('subject', 'JJ'), ('gain', 'NN'), ('access', 'NN'), ('point', 'NN'), ('entry', 'NN'), ('based', 'VBN'), ('directional', 'JJ'), ('vector', 'NN'), ('face', 'NN'), ('subject', 'JJ'), ('granting', 'VBG'), ('access', 'NN'), ('point', 'NN'), ('entry', 'NN'), ('based', 'VBN'), ('authentication', 'NN'), ('subject', 'NN'), ('based', 'VBN'), ('determining', 'VBG'), ('intent', 'NN'), ('subject', 'JJ'), ('non-transitory', 'JJ'), ('computer', 'NN'), ('readable', 'JJ'), ('medium', 'NN'), ('program', 'NN'), ('instructions', 'NNS'), ('stored', 'VBD'), ('thereon', 'JJ'), ('response', 'NN'), ('execution', 'NN'), ('computing', 'VBG'), ('device', 'NN'), ('cause', 'NN'), ('computing', 'VBG'), ('device', 'NN'), ('perform', 'NN'), ('operations', 'NNS'), ('comprising', 'VBG'), ('detecting', 'VBG'), ('motion', 'NN'), ('subject', 'NN'), ('within', 'IN'), ('predetermined', 'JJ'), ('area', 'NN'), ('view', 'NN'), ('assigning', 'VBG'), ('unique', 'JJ'), ('session', 'NN'), ('identification', 'NN'), ('number', 'NN'), ('subject', 'JJ'), ('detected', 'VBD'), ('within', 'IN'), ('predetermined', 'JJ'), ('area', 'NN'), ('view', 'NN'), ('detecting', 'VBG'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'NN'), ('detected', 'VBD'), ('within', 'IN'), ('predetermined', 'JJ'), ('area', 'NN'), ('view', 'NN'), ('generating', 'VBG'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'NN'), ('assessing', 'VBG'), ('quality', 'NN'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'JJ'), ('determining', 'VBG'), ('identity', 'NN'), ('subject', 'NN'), ('based', 'VBN'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'JJ'), ('identifying', 'VBG'), ('intent', 'NN'), ('subject', 'JJ'), ('authorizing', 'VBG'), ('access', 'NN'), ('point', 'NN'), ('entry', 'NN'), ('based', 'VBN'), ('determined', 'VBN'), ('identity', 'NN'), ('subject', 'NN'), ('based', 'VBN'), ('intent', 'NN'), ('subject', 'JJ'), ('non-transitory', 'JJ'), ('computer', 'NN'), ('readable', 'JJ'), ('medium', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('determining', 'VBG'), ('one', 'CD'), ('additional', 'JJ'), ('subjects', 'NNS'), ('within', 'IN'), ('predetermined', 'JJ'), ('area', 'NN'), ('view', 'NN'), ('assigning', 'VBG'), ('unique', 'JJ'), ('session', 'NN'), ('identification', 'NN'), ('number', 'NN'), ('one', 'CD'), ('additional', 'JJ'), ('subjects', 'NNS'), ('detected', 'VBN'), ('within', 'IN'), ('predetermined', 'JJ'), ('area', 'NN'), ('view', 'NN'), ('non-transitory', 'JJ'), ('computer', 'NN'), ('readable', 'JJ'), ('medium', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('assessing', 'VBG'), ('quality', 'NN'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'JJ'), ('comprises', 'VBZ'), ('assessing', 'VBG'), ('whether', 'IN'), ('quality', 'NN'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('object', 'NN'), ('equates', 'NNS'), ('predetermined', 'VBD'), ('metric', 'JJ'), ('quality', 'NN'), ('upon', 'IN'), ('determining', 'VBG'), ('quality', 'NN'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('object', 'VBP'), ('inferior', 'JJ'), ('predetermined', 'VBN'), ('metric', 'JJ'), ('quality', 'NN'), ('discarding', 'VBG'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'JJ'), ('generating', 'VBG'), ('second', 'JJ'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'JJ'), ('non-transitory', 'JJ'), ('computer', 'NN'), ('readable', 'JJ'), ('medium', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('detecting', 'VBG'), ('whether', 'IN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'JJ'), ('photographic', 'JJ'), ('image', 'NN'), ('upon', 'IN'), ('detecting', 'VBG'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'JJ'), ('photographic', 'JJ'), ('image', 'NN'), ('generating', 'VBG'), ('warning', 'VBG'), ('restrict', 'JJ'), ('access', 'NN'), ('access', 'NN'), ('point', 'NN'), ('non-transitory', 'JJ'), ('computer', 'NN'), ('readable', 'JJ'), ('medium', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('conducing', 'VBG'), ('incremental', 'JJ'), ('training', 'NN'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'JJ'), ('non-transitory', 'JJ'), ('computer', 'NN'), ('readable', 'JJ'), ('medium', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('conducing', 'VBG'), ('incremental', 'JJ'), ('training', 'NN'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'JJ'), ('comprises', 'NNS'), ('capturing', 'VBG'), ('first', 'JJ'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('facial', 'JJ'), ('landmarks', 'NNS'), ('converting', 'VBG'), ('first', 'JJ'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('first', 'RB'), ('numeric', 'JJ'), ('vector', 'NN'), ('capturing', 'VBG'), ('second', 'JJ'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('facial', 'JJ'), ('landmarks', 'NNS'), ('converting', 'VBG'), ('second', 'JJ'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('second', 'JJ'), ('numeric', 'JJ'), ('vector', 'NN'), ('calculating', 'VBG'), ('weighted', 'VBD'), ('mean', 'JJ'), ('first', 'JJ'), ('numeric', 'JJ'), ('vector', 'NN'), ('second', 'JJ'), ('numeric', 'JJ'), ('vector', 'NN'), ('wherein', 'NN'), ('weighted', 'VBD'), ('mean', 'JJ'), ('represents', 'VBZ'), ('change', 'VBP'), ('facial', 'JJ'), ('area', 'NN'), ('storing', 'VBG'), ('weighted', 'JJ'), ('mean', 'JJ'), ('database', 'NN'), ('apparatus', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('comprising', 'VBG'), ('processor', 'JJ'), ('memory', 'NN'), ('store', 'NN'), ('computer', 'NN'), ('program', 'NN'), ('instructions', 'NNS'), ('computer', 'NN'), ('program', 'NN'), ('instructions', 'NNS'), ('executed', 'VBD'), ('processor', 'NN'), ('cause', 'NN'), ('processor', 'NN'), ('perform', 'NN'), ('operations', 'NNS'), ('comprising', 'VBG'), ('detecting', 'VBG'), ('motion', 'NN'), ('subject', 'NN'), ('within', 'IN'), ('predetermined', 'JJ'), ('area', 'NN'), ('view', 'NN'), ('assigning', 'VBG'), ('unique', 'JJ'), ('session', 'NN'), ('identification', 'NN'), ('number', 'NN'), ('subject', 'JJ'), ('detected', 'VBD'), ('within', 'IN'), ('predetermined', 'JJ'), ('area', 'NN'), ('view', 'NN'), ('detecting', 'VBG'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'NN'), ('detected', 'VBD'), ('within', 'IN'), ('predetermined', 'JJ'), ('area', 'NN'), ('view', 'NN'), ('generating', 'VBG'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'NN'), ('assessing', 'VBG'), ('quality', 'NN'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'JJ'), ('determining', 'VBG'), ('identity', 'NN'), ('subject', 'NN'), ('based', 'VBN'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'JJ'), ('identifying', 'VBG'), ('intent', 'NN'), ('subject', 'JJ'), ('authorizing', 'VBG'), ('access', 'NN'), ('point', 'NN'), ('entry', 'NN'), ('based', 'VBN'), ('determined', 'VBN'), ('identity', 'NN'), ('subject', 'NN'), ('based', 'VBN'), ('intent', 'NN'), ('subject', 'JJ'), ('apparatus', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('determining', 'VBG'), ('one', 'CD'), ('additional', 'JJ'), ('subjects', 'NNS'), ('within', 'IN'), ('predetermined', 'JJ'), ('area', 'NN'), ('view', 'NN'), ('assigning', 'VBG'), ('unique', 'JJ'), ('session', 'NN'), ('identification', 'NN'), ('number', 'NN'), ('one', 'CD'), ('additional', 'JJ'), ('subjects', 'NNS'), ('detected', 'VBN'), ('within', 'IN'), ('predetermined', 'JJ'), ('area', 'NN'), ('view', 'NN'), ('apparatus', 'VBP'), ('claim', 'NN'), ('wherein', 'NN'), ('assessing', 'VBG'), ('quality', 'NN'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'JJ'), ('comprises', 'VBZ'), ('assessing', 'VBG'), ('whether', 'IN'), ('quality', 'NN'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('object', 'NN'), ('equates', 'NNS'), ('predetermined', 'VBD'), ('metric', 'JJ'), ('quality', 'NN'), ('upon', 'IN'), ('determining', 'VBG'), ('quality', 'NN'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('object', 'VBP'), ('inferior', 'JJ'), ('predetermined', 'VBN'), ('metric', 'JJ'), ('quality', 'NN'), ('discarding', 'VBG'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'JJ'), ('generating', 'VBG'), ('second', 'JJ'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'JJ'), ('apparatus', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('detecting', 'VBG'), ('whether', 'IN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'JJ'), ('photographic', 'JJ'), ('image', 'NN'), ('upon', 'IN'), ('detecting', 'VBG'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'JJ'), ('photographic', 'JJ'), ('image', 'NN'), ('generating', 'VBG'), ('warning', 'VBG'), ('restrict', 'JJ'), ('access', 'NN'), ('access', 'NN'), ('point', 'NN'), ('apparatus', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('conducing', 'VBG'), ('incremental', 'JJ'), ('training', 'NN'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'JJ'), ('apparatus', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('conducing', 'VBG'), ('incremental', 'JJ'), ('training', 'NN'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'JJ'), ('comprises', 'NNS'), ('capturing', 'VBG'), ('first', 'JJ'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('facial', 'JJ'), ('landmarks', 'NNS'), ('converting', 'VBG'), ('first', 'JJ'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('first', 'RB'), ('numeric', 'JJ'), ('vector', 'NN'), ('capturing', 'VBG'), ('second', 'JJ'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('facial', 'JJ'), ('landmarks', 'NNS'), ('converting', 'VBG'), ('second', 'JJ'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('second', 'JJ'), ('numeric', 'JJ'), ('vector', 'NN'), ('calculating', 'VBG'), ('weighted', 'VBD'), ('mean', 'JJ'), ('first', 'JJ'), ('numeric', 'JJ'), ('vector', 'NN'), ('second', 'JJ'), ('numeric', 'JJ'), ('vector', 'NN'), ('wherein', 'NN'), ('weighted', 'VBD'), ('mean', 'JJ'), ('represents', 'VBZ'), ('change', 'VBP'), ('facial', 'JJ'), ('area', 'NN'), ('storing', 'VBG'), ('weighted', 'JJ'), ('mean', 'JJ'), ('database', 'NN'), ('robot', 'NN'), ('comprising', 'VBG'), ('body', 'NN'), ('configured', 'VBD'), ('rotate', 'JJ'), ('tilt', 'NN'), ('camera', 'NN'), ('coupled', 'VBN'), ('body', 'NN'), ('configured', 'JJ'), ('rotate', 'NN'), ('tilt', 'NN'), ('according', 'VBG'), ('rotate', 'NN'), ('tilt', 'NN'), ('body', 'NN'), ('wherein', 'JJ'), ('camera', 'NN'), ('configured', 'VBD'), ('acquire', 'VB'), ('video', 'NN'), ('space', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('unit', 'NN'), ('configured', 'VBD'), ('recognize', 'JJ'), ('respective', 'JJ'), ('faces', 'VBZ'), ('one', 'CD'), ('persons', 'NNS'), ('video', 'VBP'), ('tracking', 'VBG'), ('unit', 'NN'), ('configured', 'VBD'), ('track', 'JJ'), ('motion', 'NN'), ('recognized', 'VBD'), ('faces', 'VBZ'), ('one', 'CD'), ('persons', 'NNS'), ('controller', 'NN'), ('configured', 'VBD'), ('calculate', 'JJ'), ('respective', 'JJ'), ('size', 'NN'), ('faces', 'VBZ'), ('one', 'CD'), ('persons', 'NNS'), ('select', 'VBP'), ('first', 'JJ'), ('person', 'NN'), ('among', 'IN'), ('one', 'CD'), ('persons', 'NNS'), ('based', 'VBN'), ('calculated', 'JJ'), ('sizes', 'NNS'), ('faces', 'VBZ'), ('control', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('direction', 'NN'), ('rotation', 'NN'), ('camera', 'NN'), ('angle', 'NN'), ('tilt', 'NN'), ('camera', 'NN'), ('focal', 'JJ'), ('distance', 'NN'), ('camera', 'NN'), ('based', 'VBN'), ('tracked', 'JJ'), ('motion', 'NN'), ('recognized', 'VBD'), ('face', 'NN'), ('first', 'RB'), ('person', 'NN'), ('robot', 'JJ'), ('claim', 'NN'), ('wherein', 'NN'), ('controller', 'NN'), ('configured', 'VBD'), ('control', 'JJ'), ('direction', 'NN'), ('rotation', 'NN'), ('camera', 'NN'), ('angle', 'NN'), ('tilt', 'NN'), ('camera', 'NN'), ('achieve', 'VBP'), ('particular', 'JJ'), ('orientation', 'NN'), ('camera', 'NN'), ('relative', 'JJ'), ('face', 'NN'), ('first', 'RB'), ('person', 'NN'), ('control', 'NN'), ('focal', 'JJ'), ('distance', 'NN'), ('camera', 'NN'), ('comparing', 'VBG'), ('respective', 'JJ'), ('sizes', 'NNS'), ('face', 'VBP'), ('first', 'JJ'), ('person', 'NN'), ('motion', 'NN'), ('first', 'RB'), ('person', 'NN'), ('robot', 'JJ'), ('claim', 'NN'), ('wherein', 'IN'), ('particular', 'JJ'), ('orientation', 'NN'), ('occurs', 'VBZ'), ('camera', 'NN'), ('faces', 'VBZ'), ('general', 'JJ'), ('direction', 'NN'), ('face', 'NN'), ('first', 'RB'), ('person', 'NN'), ('robot', 'JJ'), ('claim', 'NN'), ('wherein', 'NN'), ('controller', 'NN'), ('configured', 'VBD'), ('normalize', 'JJ'), ('sizes', 'NNS'), ('faces', 'VBZ'), ('one', 'CD'), ('persons', 'NNS'), ('based', 'VBN'), ('interocular', 'JJ'), ('distance', 'NN'), ('select', 'NN'), ('first', 'RB'), ('person', 'NN'), ('based', 'VBN'), ('normalized', 'JJ'), ('sizes', 'NNS'), ('faces', 'VBZ'), ('one', 'CD'), ('persons', 'NNS'), ('robot', 'VBP'), ('claim', 'NN'), ('wherein', 'NN'), ('controller', 'NN'), ('configured', 'VBD'), ('select', 'JJ'), ('person', 'NN'), ('largest', 'JJS'), ('face', 'NN'), ('size', 'NN'), ('among', 'IN'), ('one', 'CD'), ('persons', 'NNS'), ('first', 'JJ'), ('person', 'NN'), ('robot', 'JJ'), ('claim', 'NN'), ('comprising', 'VBG'), ('microphone', 'NN'), ('configured', 'VBD'), ('receive', 'JJ'), ('spoken', 'NN'), ('audio', 'NN'), ('present', 'JJ'), ('space', 'NN'), ('wherein', 'NN'), ('controller', 'NN'), ('configured', 'VBD'), ('select', 'JJ'), ('first', 'JJ'), ('person', 'NN'), ('based', 'VBN'), ('received', 'VBN'), ('spoken', 'JJ'), ('audio', 'JJ'), ('robot', 'NN'), ('claim', 'NN'), ('wherein', 'VBP'), ('controller', 'NN'), ('configured', 'VBD'), ('control', 'NN'), ('gain', 'NN'), ('microphone', 'NN'), ('comparing', 'VBG'), ('respective', 'JJ'), ('sizes', 'NNS'), ('face', 'VBP'), ('first', 'JJ'), ('person', 'NN'), ('motion', 'NN'), ('first', 'RB'), ('person', 'NN'), ('robot', 'JJ'), ('claim', 'NN'), ('wherein', 'NN'), ('controller', 'NN'), ('configured', 'VBD'), ('calculate', 'JJ'), ('position', 'NN'), ('spoken', 'VBN'), ('audio', 'NN'), ('provided', 'VBD'), ('select', 'JJ'), ('first', 'JJ'), ('person', 'NN'), ('based', 'VBN'), ('whether', 'IN'), ('one', 'CD'), ('persons', 'NNS'), ('position', 'NN'), ('voice', 'NN'), ('signal', 'NN'), ('provided', 'VBD'), ('robot', 'JJ'), ('claim', 'NN'), ('wherein', 'NN'), ('controller', 'NN'), ('configured', 'VBD'), ('select', 'JJ'), ('second', 'JJ'), ('person', 'NN'), ('first', 'JJ'), ('person', 'NN'), ('among', 'IN'), ('one', 'CD'), ('persons', 'NNS'), ('second', 'JJ'), ('person', 'NN'), ('located', 'VBN'), ('position', 'NN'), ('spoken', 'VBN'), ('audio', 'NN'), ('provided', 'VBD'), ('robot', 'JJ'), ('claim', 'NN'), ('wherein', 'NN'), ('controller', 'NN'), ('configured', 'VBD'), ('select', 'JJ'), ('second', 'JJ'), ('person', 'NN'), ('largest', 'JJS'), ('face', 'NN'), ('size', 'NN'), ('first', 'JJ'), ('person', 'NN'), ('among', 'IN'), ('one', 'CD'), ('persons', 'NNS'), ('none', 'NN'), ('one', 'CD'), ('persons', 'NNS'), ('located', 'VBN'), ('position', 'NN'), ('spoken', 'VBN'), ('audio', 'NN'), ('provided', 'VBD'), ('robot', 'JJ'), ('claim', 'NN'), ('wherein', 'NN'), ('controller', 'NN'), ('configured', 'VBD'), ('select', 'JJ'), ('second', 'JJ'), ('person', 'NN'), ('largest', 'JJS'), ('face', 'NN'), ('size', 'NN'), ('first', 'JJ'), ('person', 'NN'), ('among', 'IN'), ('one', 'CD'), ('persons', 'NNS'), ('plurality', 'NN'), ('persons', 'NNS'), ('among', 'IN'), ('one', 'CD'), ('persons', 'NNS'), ('located', 'VBN'), ('position', 'NN'), ('spoken', 'VBN'), ('audio', 'NN'), ('provided', 'VBD'), ('robot', 'JJ'), ('claim', 'NN'), ('comprising', 'VBG'), ('speaker', 'NN'), ('wherein', 'NN'), ('controller', 'NN'), ('configured', 'VBD'), ('control', 'NN'), ('volume', 'NN'), ('speaker', 'NN'), ('comparing', 'VBG'), ('respective', 'JJ'), ('sizes', 'NNS'), ('face', 'VBP'), ('first', 'JJ'), ('person', 'NN'), ('motion', 'NN'), ('first', 'RB'), ('person', 'NN'), ('robot', 'JJ'), ('claim', 'NN'), ('wherein', 'IN'), ('body', 'NN'), ('configured', 'JJ'), ('rotate', 'JJ'), ('lateral', 'JJ'), ('direction', 'NN'), ('tilt', 'VBD'), ('vertical', 'JJ'), ('direction', 'NN'), ('electronic', 'JJ'), ('device', 'NN'), ('comprising', 'VBG'), ('camera', 'NN'), ('coupled', 'VBN'), ('body', 'NN'), ('configured', 'JJ'), ('rotate', 'NN'), ('tilt', 'NN'), ('wherein', 'NN'), ('camera', 'NN'), ('configured', 'VBD'), ('acquire', 'VB'), ('video', 'NN'), ('space', 'NN'), ('within', 'IN'), ('one', 'CD'), ('persons', 'NNS'), ('positioned', 'VBD'), ('processor', 'NN'), ('configured', 'VBN'), ('recognize', 'VB'), ('respective', 'JJ'), ('faces', 'VBZ'), ('one', 'CD'), ('persons', 'NNS'), ('video', 'VBP'), ('track', 'JJ'), ('motion', 'NN'), ('recognized', 'VBD'), ('faces', 'VBZ'), ('one', 'CD'), ('persons', 'NNS'), ('calculate', 'VBP'), ('respective', 'JJ'), ('size', 'NN'), ('faces', 'VBZ'), ('one', 'CD'), ('persons', 'NNS'), ('select', 'VBP'), ('first', 'JJ'), ('person', 'NN'), ('among', 'IN'), ('one', 'CD'), ('persons', 'NNS'), ('based', 'VBN'), ('calculated', 'JJ'), ('sizes', 'NNS'), ('faces', 'VBZ'), ('control', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('direction', 'NN'), ('rotation', 'NN'), ('camera', 'NN'), ('angle', 'NN'), ('tilt', 'NN'), ('camera', 'NN'), ('focal', 'JJ'), ('distance', 'NN'), ('camera', 'NN'), ('based', 'VBN'), ('tracked', 'JJ'), ('motion', 'NN'), ('recognized', 'VBD'), ('face', 'NN'), ('first', 'RB'), ('person', 'NN'), ('method', 'JJ'), ('comprising', 'VBG'), ('acquiring', 'VBG'), ('camera', 'NN'), ('video', 'NN'), ('space', 'NN'), ('within', 'IN'), ('one', 'CD'), ('persons', 'NNS'), ('positioned', 'VBD'), ('recognizing', 'VBG'), ('respective', 'JJ'), ('faces', 'VBZ'), ('one', 'CD'), ('persons', 'NNS'), ('video', 'IN'), ('tracking', 'VBG'), ('motion', 'NN'), ('recognized', 'VBD'), ('faces', 'VBZ'), ('one', 'CD'), ('persons', 'NNS'), ('calculating', 'VBG'), ('respective', 'JJ'), ('size', 'NN'), ('faces', 'VBZ'), ('one', 'CD'), ('persons', 'NNS'), ('selecting', 'VBG'), ('first', 'JJ'), ('person', 'NN'), ('among', 'IN'), ('one', 'CD'), ('persons', 'NNS'), ('based', 'VBN'), ('calculated', 'JJ'), ('sizes', 'NNS'), ('faces', 'VBZ'), ('controlling', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('direction', 'NN'), ('rotation', 'NN'), ('camera', 'NN'), ('angle', 'NN'), ('tilt', 'NN'), ('camera', 'NN'), ('focal', 'JJ'), ('distance', 'NN'), ('camera', 'NN'), ('based', 'VBN'), ('tracked', 'JJ'), ('motion', 'NN'), ('recognized', 'VBD'), ('face', 'NN'), ('first', 'RB'), ('person', 'NN'), ('method', 'NN'), ('inferring', 'VBG'), ('topics', 'NNS'), ('multimodal', 'VBP'), ('file', 'NN'), ('method', 'NN'), ('comprising', 'VBG'), ('receiving', 'VBG'), ('multimodal', 'NN'), ('file', 'NN'), ('extracting', 'VBG'), ('set', 'VBN'), ('entities', 'NNS'), ('multimodal', 'VBP'), ('file', 'NN'), ('linking', 'VBG'), ('set', 'VBN'), ('entities', 'NNS'), ('produce', 'VBP'), ('set', 'VBN'), ('linked', 'VBN'), ('entities', 'NNS'), ('obtaining', 'VBG'), ('reference', 'NN'), ('information', 'NN'), ('set', 'VBN'), ('entities', 'NNS'), ('based', 'VBN'), ('least', 'JJS'), ('reference', 'NN'), ('information', 'NN'), ('generating', 'VBG'), ('graph', 'NN'), ('set', 'VBN'), ('linked', 'VBN'), ('entities', 'NNS'), ('graph', 'VBP'), ('comprising', 'VBG'), ('nodes', 'NNS'), ('edges', 'NNS'), ('based', 'VBN'), ('least', 'JJS'), ('nodes', 'JJ'), ('edges', 'NNS'), ('graph', 'VBP'), ('determining', 'VBG'), ('clusters', 'NNS'), ('graph', 'VBP'), ('based', 'VBN'), ('least', 'JJS'), ('clusters', 'NNS'), ('graph', 'VBP'), ('identifying', 'VBG'), ('topic', 'NN'), ('candidates', 'NNS'), ('extracting', 'VBG'), ('features', 'NNS'), ('clusters', 'NNS'), ('graph', 'VBP'), ('based', 'VBN'), ('least', 'JJS'), ('extracted', 'JJ'), ('features', 'NNS'), ('selecting', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('topicid', 'NN'), ('among', 'IN'), ('topic', 'JJ'), ('candidates', 'NNS'), ('represent', 'VBP'), ('least', 'JJS'), ('one', 'CD'), ('cluster', 'NN'), ('indexing', 'VBG'), ('multimodal', 'NNS'), ('file', 'RB'), ('least', 'JJS'), ('one', 'CD'), ('topicid', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('multimodal', 'NN'), ('file', 'NN'), ('comprises', 'VBZ'), ('video', 'JJ'), ('portion', 'NN'), ('audio', 'NN'), ('portion', 'NN'), ('wherein', 'IN'), ('extracting', 'VBG'), ('set', 'NN'), ('entities', 'NNS'), ('multimodal', 'VBP'), ('file', 'NN'), ('comprises', 'NNS'), ('detecting', 'VBG'), ('objects', 'NNS'), ('video', 'JJ'), ('portion', 'NN'), ('multimodal', 'NN'), ('file', 'NN'), ('detecting', 'VBG'), ('text', 'JJ'), ('audio', 'JJ'), ('portion', 'NN'), ('multimodal', 'NN'), ('file', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('detecting', 'VBG'), ('objects', 'NNS'), ('comprises', 'VBZ'), ('performing', 'VBG'), ('face', 'NN'), ('recognition', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('detecting', 'VBG'), ('text', 'JJ'), ('comprises', 'NNS'), ('performing', 'VBG'), ('speech', 'NN'), ('text', 'NN'), ('process', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('identifying', 'JJ'), ('language', 'NN'), ('used', 'VBN'), ('audio', 'JJ'), ('portion', 'NN'), ('multimodal', 'NN'), ('file', 'NN'), ('wherein', 'NN'), ('performing', 'VBG'), ('speech', 'JJ'), ('text', 'NN'), ('process', 'NN'), ('comprises', 'VBZ'), ('performing', 'VBG'), ('speech', 'NN'), ('text', 'NN'), ('process', 'NN'), ('identified', 'VBN'), ('language', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('translating', 'VBG'), ('detected', 'VBN'), ('text', 'JJ'), ('method', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('determining', 'VBG'), ('significant', 'JJ'), ('clusters', 'NNS'), ('insignificant', 'JJ'), ('clusters', 'NNS'), ('determined', 'VBD'), ('clusters', 'NNS'), ('wherein', 'VBP'), ('extracting', 'VBG'), ('features', 'NNS'), ('clusters', 'NNS'), ('graph', 'VBP'), ('comprises', 'NNS'), ('extracting', 'VBG'), ('features', 'NNS'), ('significant', 'JJ'), ('clusters', 'NNS'), ('graph', 'VBP'), ('method', 'JJ'), ('claim', 'NN'), ('wherein', 'NN'), ('extracting', 'VBG'), ('features', 'NNS'), ('clusters', 'NNS'), ('graph', 'VBP'), ('comprises', 'NNS'), ('least', 'VBP'), ('one', 'CD'), ('process', 'NN'), ('selected', 'VBN'), ('list', 'NN'), ('consisting', 'VBG'), ('determining', 'VBG'), ('graph', 'JJ'), ('diameter', 'NN'), ('determining', 'VBG'), ('jaccard', 'JJ'), ('coefficient', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('selecting', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('topicid', 'JJ'), ('represent', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('cluster', 'NN'), ('comprises', 'NNS'), ('based', 'VBN'), ('least', 'RB'), ('extracted', 'JJ'), ('features', 'NNS'), ('mapping', 'VBG'), ('topic', 'NN'), ('candidates', 'NNS'), ('probability', 'NN'), ('interval', 'VBP'), ('based', 'VBN'), ('least', 'JJS'), ('mapping', 'VBG'), ('ranking', 'VBG'), ('topic', 'NN'), ('candidates', 'NNS'), ('within', 'IN'), ('least', 'JJS'), ('one', 'CD'), ('cluster', 'NN'), ('selecting', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('topicid', 'NN'), ('based', 'VBN'), ('least', 'JJS'), ('ranking', 'JJ'), ('method', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('translating', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('topicid', 'NN'), ('wherein', 'NN'), ('indexing', 'VBG'), ('multimodal', 'NNS'), ('file', 'RB'), ('least', 'JJS'), ('one', 'CD'), ('topicid', 'NN'), ('comprises', 'VBZ'), ('indexing', 'VBG'), ('multimodal', 'NNS'), ('file', 'RB'), ('least', 'JJS'), ('one', 'CD'), ('translated', 'VBN'), ('topicid', 'NN'), ('system', 'NN'), ('inferring', 'VBG'), ('topics', 'NNS'), ('multimodal', 'VBP'), ('file', 'NN'), ('system', 'NN'), ('comprising', 'VBG'), ('entity', 'NN'), ('extraction', 'NN'), ('component', 'NN'), ('comprising', 'VBG'), ('object', 'JJ'), ('detection', 'NN'), ('component', 'NN'), ('speech', 'NN'), ('text', 'JJ'), ('component', 'NN'), ('operative', 'JJ'), ('extract', 'NN'), ('set', 'VBN'), ('entities', 'NNS'), ('multimodal', 'VBP'), ('file', 'NN'), ('comprising', 'VBG'), ('video', 'JJ'), ('portion', 'NN'), ('audio', 'NN'), ('portion', 'NN'), ('entity', 'NN'), ('linking', 'VBG'), ('component', 'JJ'), ('operative', 'JJ'), ('link', 'NN'), ('extracted', 'VBD'), ('set', 'JJ'), ('entities', 'NNS'), ('produce', 'VBP'), ('set', 'VBN'), ('linked', 'VBN'), ('entities', 'NNS'), ('information', 'NN'), ('retrieval', 'NN'), ('component', 'NN'), ('operative', 'JJ'), ('obtain', 'VB'), ('reference', 'NN'), ('information', 'NN'), ('extracted', 'VBD'), ('set', 'NN'), ('entities', 'NNS'), ('graphing', 'VBG'), ('analysis', 'NN'), ('component', 'NN'), ('operative', 'JJ'), ('generate', 'NN'), ('graph', 'NN'), ('set', 'VBN'), ('linked', 'VBN'), ('entities', 'NNS'), ('graph', 'VBP'), ('comprising', 'VBG'), ('nodes', 'NNS'), ('edges', 'NNS'), ('based', 'VBN'), ('least', 'JJS'), ('nodes', 'JJ'), ('edges', 'NNS'), ('graph', 'VBP'), ('determine', 'JJ'), ('clusters', 'NNS'), ('graph', 'VBP'), ('based', 'VBN'), ('least', 'JJS'), ('clusters', 'NNS'), ('graph', 'VBP'), ('identify', 'VB'), ('topic', 'NN'), ('candidates', 'NNS'), ('extract', 'JJ'), ('features', 'NNS'), ('clusters', 'NNS'), ('graph', 'VBP'), ('topicid', 'JJ'), ('selection', 'NN'), ('component', 'NN'), ('operative', 'JJ'), ('rank', 'NN'), ('topic', 'NN'), ('candidates', 'NNS'), ('within', 'IN'), ('least', 'JJS'), ('one', 'CD'), ('cluster', 'NN'), ('based', 'VBN'), ('least', 'JJS'), ('ranking', 'JJ'), ('select', 'JJ'), ('least', 'JJS'), ('one', 'CD'), ('topicid', 'NN'), ('among', 'IN'), ('topic', 'JJ'), ('candidates', 'NNS'), ('represent', 'VBP'), ('least', 'JJS'), ('one', 'CD'), ('cluster', 'NN'), ('video', 'NN'), ('indexer', 'VBP'), ('operative', 'JJ'), ('index', 'NN'), ('multimodal', 'NNS'), ('file', 'IN'), ('least', 'JJS'), ('one', 'CD'), ('topicid', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('object', 'JJ'), ('detection', 'NN'), ('component', 'NN'), ('operative', 'JJ'), ('perform', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('speech', 'NN'), ('text', 'JJ'), ('component', 'NN'), ('operative', 'JJ'), ('extract', 'JJ'), ('entity', 'NN'), ('information', 'NN'), ('least', 'JJS'), ('two', 'CD'), ('different', 'JJ'), ('languages', 'NNS'), ('one', 'CD'), ('computer', 'NN'), ('storage', 'NN'), ('devices', 'NNS'), ('computer-executable', 'JJ'), ('instructions', 'NNS'), ('stored', 'VBD'), ('thereon', 'NN'), ('inferring', 'VBG'), ('topics', 'NNS'), ('multimodal', 'JJ'), ('file', 'NN'), ('execution', 'NN'), ('computer', 'NN'), ('cause', 'VBP'), ('computer', 'NN'), ('perform', 'NN'), ('operations', 'NNS'), ('comprising', 'VBG'), ('receiving', 'VBG'), ('multimodal', 'NN'), ('file', 'NN'), ('comprising', 'VBG'), ('video', 'JJ'), ('portion', 'NN'), ('audio', 'NN'), ('portion', 'NN'), ('extracting', 'VBG'), ('set', 'NN'), ('entities', 'NNS'), ('multimodal', 'VBP'), ('file', 'NN'), ('wherein', 'NN'), ('extracting', 'VBG'), ('set', 'VBN'), ('entities', 'NNS'), ('multimodal', 'VBP'), ('file', 'NN'), ('comprises', 'NNS'), ('detecting', 'VBG'), ('objects', 'NNS'), ('video', 'JJ'), ('portion', 'NN'), ('multimodal', 'NN'), ('file', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('detecting', 'VBG'), ('text', 'JJ'), ('audio', 'JJ'), ('portion', 'NN'), ('multimodal', 'NN'), ('file', 'NN'), ('speech', 'NN'), ('text', 'NN'), ('process', 'NN'), ('disambiguating', 'VBG'), ('among', 'IN'), ('set', 'VBN'), ('detected', 'VBN'), ('entity', 'NN'), ('names', 'NNS'), ('linking', 'VBG'), ('set', 'NN'), ('entities', 'NNS'), ('produce', 'VBP'), ('set', 'VBN'), ('linked', 'VBN'), ('entities', 'NNS'), ('obtaining', 'VBG'), ('reference', 'NN'), ('information', 'NN'), ('set', 'VBN'), ('entities', 'NNS'), ('based', 'VBN'), ('least', 'JJS'), ('reference', 'NN'), ('information', 'NN'), ('generating', 'VBG'), ('graph', 'NN'), ('set', 'VBN'), ('linked', 'VBN'), ('entities', 'NNS'), ('graph', 'VBP'), ('comprising', 'VBG'), ('nodes', 'NNS'), ('edges', 'NNS'), ('based', 'VBN'), ('least', 'JJS'), ('nodes', 'JJ'), ('edges', 'NNS'), ('graph', 'VBP'), ('determining', 'VBG'), ('clusters', 'NNS'), ('graph', 'VBP'), ('determining', 'VBG'), ('significant', 'JJ'), ('clusters', 'NNS'), ('insignificant', 'JJ'), ('clusters', 'NNS'), ('determined', 'VBD'), ('clusters', 'NNS'), ('based', 'VBN'), ('least', 'JJS'), ('significant', 'JJ'), ('clusters', 'NNS'), ('graph', 'VBP'), ('identifying', 'VBG'), ('topic', 'NN'), ('candidates', 'NNS'), ('extracting', 'VBG'), ('features', 'NNS'), ('significant', 'JJ'), ('clusters', 'NNS'), ('graph', 'VBP'), ('based', 'VBN'), ('least', 'JJS'), ('extracted', 'JJ'), ('features', 'NNS'), ('mapping', 'VBG'), ('topic', 'NN'), ('candidates', 'NNS'), ('probability', 'NN'), ('interval', 'VBP'), ('based', 'VBN'), ('least', 'JJS'), ('mapping', 'VBG'), ('ranking', 'VBG'), ('topic', 'NN'), ('candidates', 'NNS'), ('within', 'IN'), ('least', 'JJS'), ('one', 'CD'), ('significant', 'JJ'), ('cluster', 'NN'), ('based', 'VBN'), ('ranking', 'VBG'), ('selecting', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('topicid', 'NN'), ('among', 'IN'), ('topic', 'JJ'), ('candidates', 'NNS'), ('represent', 'VBP'), ('least', 'JJS'), ('one', 'CD'), ('significant', 'JJ'), ('cluster', 'NN'), ('indexing', 'VBG'), ('multimodal', 'NNS'), ('file', 'RB'), ('least', 'JJS'), ('one', 'CD'), ('topicid', 'NN'), ('one', 'CD'), ('computer', 'NN'), ('storage', 'NN'), ('devices', 'NNS'), ('claim', 'VBP'), ('wherein', 'JJ'), ('operations', 'NNS'), ('comprise', 'VBP'), ('identifying', 'VBG'), ('language', 'NN'), ('used', 'VBN'), ('audio', 'JJ'), ('portion', 'NN'), ('multimodal', 'NN'), ('file', 'NN'), ('detecting', 'VBG'), ('text', 'JJ'), ('audio', 'JJ'), ('portion', 'NN'), ('multimodal', 'NN'), ('file', 'NN'), ('speech', 'NN'), ('text', 'NN'), ('process', 'NN'), ('comprises', 'VBZ'), ('performing', 'VBG'), ('speech', 'NN'), ('text', 'NN'), ('process', 'NN'), ('identified', 'VBD'), ('language权利要求', 'JJ'), ('、', 'NNP'), ('一种人脸识别方法其特征在于包括', 'NNP'), ('通过第一摄像头获取第一人脸图像', 'NNP'), ('提取所述第一人脸图像的第一人脸特征', 'NNP'), ('将所述第一人脸特征与预先存储的第二人脸特征进行对比获得参考相似度所述第', 'NNP'), ('二人脸特征经第二摄像头获取的第二人脸图像的特征提取而得所述第二摄像头与所述第', 'NNP'), ('一摄像头属于不同类型的摄像头', 'NNP'), ('根据所述参考相似度确定所述第一人脸特征与所述第二人脸特征是否对应相同人。', 'NNP'), ('、', 'NNP'), ('根据权利要求', 'NNP'), ('所述的方法其特征在于', 'NNP'), ('所述第一摄像头为热成像摄像头所述第二摄像头为可见光摄像头', 'NNP'), ('或者所述第一摄像头为可见光摄像头所述第一摄像头为热成像摄像头。', 'NNP'), ('、', 'NNP'), ('根据权利要求', 'NNP'), ('或', 'NNP'), ('所述的方法其特征在于所述根据所述参考相似度确定所', 'NNP'), ('述第一人脸特征与所述第二人脸特征是否对应相同人包括', 'NNP'), ('根据所述参考相似度、', 'NNP'), ('参考误报率以及相似度阈值确定所述第一人脸特征与所述第二', 'NNP'), ('人脸特征是否对应相同人其中不同的误报率对应不同的相似度阈值。', 'NNP'), ('、', 'NNP'), ('根据权利要求', 'NNP'), ('或', 'NNP'), ('所述的方法其特征在于所述根据所述参考相似度确定所', 'NNP'), ('述第一人脸特征与所述第二人脸特征是否对应相同人包括', 'NNP'), ('根据所述参考相似度以及阈值信息确定归一化后的参考相似度', 'NNP'), ('根据所述归一化后的参考相似度确定所述第一人脸特征与所述第二人脸特征是否对', 'NNP'), ('应相同人。', 'NNP'), ('、', 'NNP'), ('根据权利要求', 'NNP'), ('-任一项所述的方法其特征在于所述提取所述第一人脸图像的', 'NNP'), ('第_人脸特征包括', 'NNP'), ('将所述第一人脸图像输入预先训练完成的神经网络通过所述神经网络输出所述第一', 'NNP'), ('人脸图像的第一人脸特征其中所述神经网络基于第一类型图像样本和第二类型图像样', 'NNP'), ('本训练得到所述第一类型图像样本和所述第二类型图像样本由不同类型的摄像头拍摄得', 'NNP'), ('到且所述第一类型图像样本和所述第二类型图像样本中包括人脸。', 'NNP'), ('、', 'NNP'), ('根据权利要求', 'NNP'), ('所述的方法其特征在于所述神经网络基于所述第一类型图像', 'NNP'), ('样本、', 'NNP'), ('所述第二类型图像样本和混合类型图像样本训练得到所述混合类型图像样本由所', 'NNP'), ('述第一类型图像样本和所述第二类型图像样本配对而得。', 'NNP'), ('、', 'NNP'), ('根据权利要求', 'NNP'), ('-任一项所述的方法其特征在于所述第一摄像头包括车载摄像', 'NNP'), ('头所述通过第一摄像头获取第一人脸图像包括', 'NNP'), ('通过所述车载摄像头获取所述第一人脸图像所述第一人脸图像包括车辆的用车人的', 'NNP'), ('人脸图像。', 'NNP'), ('、', 'NNP'), ('根据权利要求', 'NNP'), ('所述的方法其特征在于所述用车人包括驾驶所述车辆的人、', 'NNP'), ('乘坐所述车辆的人、', 'NNP'), ('对所述车辆进行修理的人、', 'NNP'), ('给所述车辆加油的人以及控制所述车辆的', 'NNP'), ('人中的一项或多项。', 'NNP'), ('、', 'NNP'), ('根据权利要求', 'NNP'), ('所述的方法其特征在于所述用车人包括驾驶所述车辆的人', 'NNP'), ('所述通过所述车载摄像头获取所述第一人脸图像包括', 'NNP'), ('在接收到触发指令的情况下通过所述车载摄像头获取所述第一人脸图像', 'NNP'), ('或者在所述车辆运行时通过所述车载摄像头获取所述第一人脸图像', 'NNP'), ('或者在所述车辆的运行速度达到参考速度的情况下通过所述车载摄像头获取所述', 'NNP'), ('第一人脸图像。', 'NNP'), ('、', 'NNP'), ('根据权利要求', 'NNP'), ('-任一项所述的方法其特征在于所述第二人脸图像为对所述', 'NNP'), ('用车人进行人脸注册的图像所述将所述第一人脸特征与预先存储的第二人脸特征进行对', 'NNP'), ('比之前所述方法还包括', 'NNP'), ('通过所述第二摄像头获取所述第二人脸图像', 'NNP'), ('提取所述第二人脸图像的第二人脸特征', 'NNP'), ('保存所述第二人脸图像的第二人脸特征。', 'NNP'), ('、', 'NNP'), ('一种神经网络训练方法其特征在于包括', 'NNP'), ('获取第一类型图像样本和第二类型图像样本所述第一类型图像样本和所述第二类型', 'NNP'), ('图像样本由不同类型的摄像头拍摄得到且所述第一类型图像样本和所述第二类型图像样', 'NNP'), ('本中包括人脸', 'NNP'), ('根据所述第一类型图像样本和所述第二类型图像样本训练神经网络。', 'NNP'), ('、', 'NNP'), ('根据权利要求', 'NNP'), ('所述的方法其特征在于所述根据所述第一类型图像样本和所', 'NNP'), ('述第二类型图像样本训练神经网络包括', 'NNP'), ('将所述第一类型图像样本和所述第二类型图像样本配对得到所述第一类型图像样本', 'NNP'), ('和所述第二类型图像样本的混合类型图像样本', 'NNP'), ('根据所述第一类型图像样本、', 'NNP'), ('所述第二类型图像样本和所述混合类型图像样本训练', 'NNP'), ('所述神经网络。', 'NNP'), ('、', 'NNP'), ('根据权利要求', 'NNP'), ('所述的方法其特征在于所述根据所述第一类型图像样本、', 'NNP'), ('所述第二类型图像样本和所述混合类型图像样本训练所述神经网络包括', 'NNP'), ('通过所述神经网络获取所述第一类型图像样本的人脸预测结果、', 'NNP'), ('所述第二类型图像样', 'NNP'), ('本的人脸预测结果和所述混合类型图像样本的人脸预测结果', 'NNP'), ('根据所述第一类型图像样本的人脸预测结果和人脸标注结果的差异、', 'NNP'), ('所述第二类型图', 'NNP'), ('像样本的人脸预测结果和人脸标注结果之间的差异、', 'NNP'), ('以及所述混合类型图像样本的人脸预', 'NNP'), ('测结果和人脸标注结果的差异训练所述神经网络。', 'NNP'), ('、', 'NNP'), ('根据权利要求', 'NNP'), ('所述的方法其特征在于所述神经网络中包括第一分类器、', 'NNP'), ('第二分类器和混合分类器所述通过所述神经网络获取所述第一类型图像样本的人脸预测', 'NNP'), ('结果、', 'NNP'), ('所述第二类型图像样本的人脸预测结果和所述混合类型图像样本的人脸预测结果', 'NNP'), ('包括', 'NNP'), ('将所述第一类型图像样本的人脸特征输入至所述第一分类器中得到所述第一类型图', 'NNP'), ('像样本的人脸预测结果', 'NNP'), ('将所述第二类型图像样本的人脸特征输入至所述第二分类器中得到所述第二类型图', 'NNP'), ('像样本的人脸预测结果', 'NNP'), ('将所述混合类型图像样本的人脸特征输入至所述混合分类器中得到所述混合类型图', 'NNP'), ('像样本的人脸预测结果。', 'NNP'), ('、', 'NNP'), ('根据权利要求', 'NNP'), ('所述的方法其特征在于所述方法还包括', 'NNP'), ('在训练完成的所述神经网络中去除所述第一分类器、', 'NNP'), ('所述第二分类器和所述混合分类', 'NNP'), ('器得到用于进行人脸识别的神经网络。', 'NNP'), ('、', 'NNP'), ('一种人脸识别装置其特征在于包括', 'NNP'), ('第一获取单元用于通过第一摄像头获取第一人脸图像', 'NNP'), ('第一提取单元用于提取所述第一人脸图像的第一人脸特征', 'NNP'), ('对比单元用于将所述第一人脸特征与预先存储的第二人脸特征进行对比获得参考', 'NNP'), ('相似度所述第二人脸特征经第二摄像头获取的第二人脸图像的特征提取而得所述第二', 'NNP'), ('摄像头与所述第一摄像头属于不同类型的摄像头', 'NNP'), ('确定单元用于根据所述参考相似度确定所述第一人脸特征与所述第二人脸特征是否', 'NNP'), ('对应相同人。', 'NNP'), ('、', 'NNP'), ('根据权利要求', 'NNP'), ('所述的装置其特征在于', 'NNP'), ('所述第一摄像头为热成像摄像头所述第二摄像头为可见光摄像头', 'NNP'), ('或者所述第一摄像头为可见光摄像头所述第一摄像头为热成像摄像头。', 'NNP'), ('、', 'NNP'), ('根据权利要求', 'NNP'), ('或', 'NNP'), ('所述的装置其特征在于', 'NNP'), ('所述确定单元具体用于根据所述参考相似度、', 'NNP'), ('参考误报率以及相似度阈值确定所述', 'NNP'), ('第一人脸特征与所述第二人脸特征是否对应相同人其中不同的误报率对应不同的相似', 'NNP'), ('度阈值。', 'NNP'), ('、', 'NNP'), ('根据权利要求', 'NNP'), ('或', 'NNP'), ('所述的装置其特征在于', 'NNP'), ('所述确定单元具体用于根据所述参考相似度以及阈值信息确定归一化后的参考相似', 'NNP'), ('度以及根据所述归一化后的参考相似度确定所述第一人脸特征与所述第二人脸特征是否', 'NNP'), ('对应相同人。', 'NNP'), ('、', 'NNP'), ('根据权利要求', 'NNP'), ('-任_项所述的装置其特征在于', 'NNP'), ('所述第一提取单元具体用于将所述第一人脸图像输入预先训练完成的神经网络通', 'NNP'), ('过所述神经网络输出所述第一人脸图像的第一人脸特征其中所述神经网络基于第一类', 'NNP'), ('型图像样本和第二类型图像样本训练得到所述第一类型图像样本和所述第二类型图像样', 'NNP'), ('本由不同类型的摄像头拍摄得到且所述第一类型图像样本和所述第二类型图像样本中包', 'NNP'), ('括人脸。', 'NNP'), ('、', 'NNP'), ('根据权利要求', 'NNP'), ('所述的装置其特征在于所述神经网络基于所述第一类型图', 'NNP'), ('像样本、', 'NNP'), ('所述第二类型图像样本和混合类型图像样本训练得到所述混合类型图像样本由', 'NNP'), ('所述第一类型图像样本和所述第二类型图像样本配对而得。', 'NNP'), ('、', 'NNP'), ('根据权利要求', 'NNP'), ('-任一项所述的装置其特征在于所述第一摄像头包括车载', 'NNP'), ('摄像头', 'NNP'), ('所述第一获取单元具体用于通过所述车载摄像头获取所述第一人脸图像所述第一', 'NNP'), ('人脸图像包括车辆的用车人的人脸图像。', 'NNP'), ('、', 'NNP'), ('根据权利要求', 'NNP'), ('所述的装置其特征在于所述用车人包括驾驶所述车辆的人、', 'NNP'), ('乘坐所述车辆的人、', 'NNP'), ('对所述车辆进行修理的人、', 'NNP'), ('给所述车辆加油的人以及控制所述车辆的', 'NNP'), ('人中的一项或多项。', 'NNP'), ('、', 'NNP'), ('根据权利要求', 'NNP'), ('所述的装置其特征在于所述用车人包括驾驶所述车辆的人', 'NNP'), ('所述第一获取单元具体用于在接收到触发指令的情况下通过所述车载摄像头获取所述', 'NNP'), ('第一人脸图像', 'NNP'), ('或者所述第一获取单元具体用于在所述车辆运行时通过所述车载摄像头获取所', 'NNP'), ('述第', 'NNP'), ('_人脸图像', 'NNP'), ('或者所述第一获取单元具体用于在所述车辆的运行速度达到参考速度的情况下', 'NNP'), ('通过所述车载摄像头获取所述第一人脸图像。', 'NNP'), ('、', 'NNP'), ('根据权利要求', 'NNP'), ('-任一项所述的装置其特征在于所述第二人脸图像为对所', 'NNP'), ('述用车人进行人脸注册的图像所述装置还包括', 'NNP'), ('第二获取单元用于通过所述第二摄像头获取所述第二人脸图像', 'NNP'), ('第二提取单元用于提取所述第二人脸图像的第二人脸特征', 'NNP'), ('保存单元用于保存所述第二人脸图像的第二人脸特征。', 'NNP'), ('、', 'NNP'), ('一种神经网络训练装置其特征在于包括', 'NNP'), ('获取单元用于获取第一类型图像样本和第二类型图像样本所述第一类型图像样本', 'NNP'), ('和所述第二类型图像样本由不同类型的摄像头拍摄得到且所述第一类型图像样本和所述', 'NNP'), ('第二类型图像样本中包括人脸', 'NNP'), ('训练单元用于根据所述第一类型图像样本和所述第二类型图像样本训练神经网络。', 'NNP'), ('、', 'NNP'), ('根据权利要求', 'NNP'), ('所述的装置其特征在于所述训练单元包括', 'NNP'), ('配对子单元用于将所述第一类型图像样本和所述第二类型图像样本配对得到所述', 'NNP'), ('第一类型图像样本和所述第二类型图像样本的混合类型图像样本', 'NNP'), ('训练子单元用于根据所述第一类型图像样本、', 'NNP'), ('所述第二类型图像样本和所述混合类', 'NNP'), ('型图像样本训练所述神经网络。', 'NNP'), ('、', 'NNP'), ('根据权利要求', 'NNP'), ('所述的装置其特征在于', 'NNP'), ('所述训练子单元具体用于通过所述神经网络获取所述第一类型图像样本的人脸预测', 'NNP'), ('结果、', 'NNP'), ('所述第二类型图像样本的人脸预测结果和所述混合类型图像样本的人脸预测结果', 'NNP'), ('以及根据所述第一类型图像样本的人脸预测结果和人脸标注结果的差异、', 'NNP'), ('所述第二类型图', 'NNP'), ('像样本的人脸预测结果和人脸标注结果之间的差异、', 'NNP'), ('以及所述混合类型图像样本的人脸预', 'NNP'), ('测结果和人脸标注结果的差异训练所述神经网络。', 'NNP'), ('、', 'NNP'), ('根据权利要求', 'NNP'), ('所述的装置其特征在于所述神经网络中包括第一分类器、', 'NNP'), ('第二分类器和混合分类器', 'NNP'), ('所述训练子单元具体用于将所述第一类型图像样本的人脸特征输入至所述第一分类', 'NNP'), ('器中得到所述第一类型图像样本的人脸预测结果以及将所述第二类型图像样本的人脸', 'NNP'), ('特征输入至所述第二分类器中得到所述第二类型图像样本的人脸预测结果以及将所述', 'NNP'), ('混合类型图像样本的人脸特征输入至所述混合分类器中得到所述混合类型图像样本的人', 'NNP'), ('脸预测结果。', 'NNP'), ('、', 'NNP'), ('根据权利要求', 'NNP'), ('所述的装置其特征在于所述装置还包括', 'NNP'), ('神经网络应用单元用于在训练完成的所述神经网络中去除所述第一分类器、', 'NNP'), ('所述第', 'NNP'), ('二分类器和所述混合分类器得到用于进行人脸识别的神经网络。', 'NNP'), ('、', 'NNP'), ('一种电子设备其特征在于包括处理器和存储器所述处理器和所述存储器耦', 'NNP'), ('合其中所述存储器用于存储程序指令所述程序指令被所述处理器执行时使所述处', 'NNP'), ('理器执行权利要求', 'NNP'), ('-任一项所述的方法和或使所述处理器执行权利要求', 'NNP'), ('-任一', 'NNP'), ('项所述的方法。', 'NNP'), ('、', 'NNP'), ('一种计算机可读存储介质其特征在于所述计算机可读存储介质中存储有计算', 'NNP'), ('机程序所述计算机程序包括程序指令所述程序指令当被处理器执行时使所述处理器', 'NNP'), ('执行权利要求', 'NNP'), ('-任一项所述的方法和或使所述处理器执行权利要求', 'NNP'), ('-任一项所', 'NNP'), ('述的方法。', 'NNP'), ('system', 'NN'), ('alerting', 'VBG'), ('vision', 'NN'), ('impairment', 'NN'), ('said', 'VBD'), ('system', 'NN'), ('comprising', 'VBG'), ('processing', 'VBG'), ('unit', 'NN'), ('configured', 'VBD'), ('operable', 'JJ'), ('receiving', 'VBG'), ('scene', 'NN'), ('data', 'NNS'), ('indicative', 'JJ'), ('scene', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('consumer', 'NN'), ('environment', 'NN'), ('identifying', 'VBG'), ('scene', 'NN'), ('data', 'NNS'), ('certain', 'JJ'), ('consumer', 'NN'), ('identifying', 'VBG'), ('event', 'NN'), ('indicative', 'JJ'), ('behavioral', 'JJ'), ('compensation', 'NN'), ('vision', 'NN'), ('impairment', 'NN'), ('upon', 'IN'), ('identification', 'NN'), ('event', 'NN'), ('sending', 'VBG'), ('notification', 'NN'), ('relating', 'VBG'), ('vision', 'NN'), ('impairment', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('sensing', 'VBG'), ('unit', 'NN'), ('configured', 'VBD'), ('operable', 'JJ'), ('detecting', 'VBG'), ('scene', 'NN'), ('data', 'NNS'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('said', 'VBD'), ('least', 'JJS'), ('one', 'CD'), ('sensing', 'VBG'), ('unit', 'NN'), ('comprises', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('least', 'JJS'), ('one', 'CD'), ('imaging', 'VBG'), ('unit', 'NN'), ('configured', 'VBD'), ('operable', 'JJ'), ('capturing', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('image', 'NN'), ('least', 'JJS'), ('portion', 'NN'), ('consumer', 'NN'), (\"'s\", 'POS'), ('body', 'NN'), ('least', 'VBD'), ('one', 'CD'), ('motion', 'NN'), ('detector', 'NN'), ('configured', 'VBD'), ('operable', 'JJ'), ('detecting', 'VBG'), ('consumer', 'NN'), ('data', 'NNS'), ('indicative', 'JJ'), ('motion', 'NN'), ('consumer', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('eye', 'NN'), ('tracker', 'NN'), ('configured', 'VBD'), ('operable', 'JJ'), ('tracking', 'VBG'), ('eye', 'NN'), ('motion', 'NN'), ('consumer', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('least', 'JJS'), ('one', 'CD'), ('imaging', 'VBG'), ('unit', 'NN'), ('comprises', 'VBZ'), ('plurality', 'NN'), ('cameras', 'NNS'), ('placed', 'VBD'), ('different', 'JJ'), ('heights', 'NNS'), ('system', 'NN'), ('one', 'CD'), ('claims', 'VBZ'), ('wherein', 'NN'), ('said', 'VBD'), ('sensing', 'VBG'), ('unit', 'NN'), ('accommodated', 'VBD'), ('optical', 'JJ'), ('digital', 'JJ'), ('eyewear', 'NN'), ('frame', 'NN'), ('display', 'NN'), ('system', 'NN'), ('one', 'CD'), ('claims', 'VBZ'), ('wherein', 'NN'), ('said', 'VBD'), ('processing', 'NN'), ('unit', 'NN'), ('configured', 'VBD'), ('operable', 'JJ'), ('identifying', 'VBG'), ('consumer', 'NN'), (\"'s\", 'POS'), ('condition', 'NN'), ('said', 'VBD'), ('consumer', 'NN'), (\"'s\", 'POS'), ('condition', 'NN'), ('comprising', 'VBG'), ('consumer', 'NN'), ('data', 'NNS'), ('indicative', 'JJ'), ('consumer', 'NN'), (\"'s\", 'POS'), ('position', 'NN'), ('location', 'NN'), ('relative', 'JJ'), ('least', 'JJS'), ('one', 'CD'), ('object', 'JJ'), ('consumer', 'NN'), (\"'s\", 'POS'), ('environment', 'NN'), ('said', 'VBD'), ('consumer', 'NN'), ('data', 'NNS'), ('comprises', 'NNS'), ('least', 'VBP'), ('one', 'CD'), ('consumer', 'NN'), (\"'s\", 'POS'), ('face', 'NN'), ('eyewear', 'JJ'), ('posture', 'NN'), ('position', 'NN'), ('sound', 'NN'), ('motion', 'NN'), ('system', 'NN'), ('one', 'CD'), ('claims', 'VBZ'), ('wherein', 'NN'), ('said', 'VBD'), ('event', 'NN'), ('comprises', 'NNS'), ('least', 'VBP'), ('one', 'CD'), ('position', 'NN'), ('orientation', 'NN'), ('head', 'NN'), ('increase', 'NN'), ('decrease', 'NN'), ('viewing', 'VBG'), ('distance', 'NN'), ('consumer', 'NN'), ('viewed', 'VBD'), ('object', 'JJ'), ('changing', 'VBG'), ('position', 'NN'), ('eyeglasses', 'NNS'), ('worn', 'JJ'), ('consumer', 'NN'), ('system', 'NN'), ('one', 'CD'), ('claims', 'VBZ'), ('wherein', 'NN'), ('said', 'VBD'), ('event', 'NN'), ('identified', 'VBN'), ('identifying', 'NN'), ('images', 'NNS'), ('image', 'NN'), ('feature', 'NN'), ('indicative', 'JJ'), ('behavioral', 'JJ'), ('compensation', 'NN'), ('performing', 'VBG'), ('bruckner', 'JJ'), ('test', 'NN'), ('performing', 'VBG'), ('hirschberg', 'JJ'), ('test', 'NN'), ('measuring', 'VBG'), ('blink', 'NN'), ('count', 'NN'), ('frequency', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('image', 'NN'), ('feature', 'NN'), ('indicative', 'JJ'), ('behavioral', 'JJ'), ('compensation', 'NN'), ('comprises', 'NNS'), ('squinting', 'VBG'), ('head', 'NN'), ('orientation', 'NN'), ('certain', 'JJ'), ('distances', 'NNS'), ('object', 'VBP'), ('consumer', 'NN'), (\"'s\", 'POS'), ('eyes', 'NNS'), ('certain', 'JJ'), ('position', 'NN'), ('eyeglasses', 'VBZ'), ('consumer', 'NN'), (\"'s\", 'POS'), ('face', 'NN'), ('strabismus', 'NN'), ('cataracts', 'VBZ'), ('reflections', 'NNS'), ('eye', 'NN'), ('system', 'NN'), ('one', 'CD'), ('claims', 'VBZ'), ('wherein', 'NN'), ('notification', 'NN'), ('includes', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('data', 'NN'), ('indicative', 'NN'), ('identified', 'VBN'), ('event', 'NN'), ('data', 'NNS'), ('indicative', 'JJ'), ('identified', 'JJ'), ('consumer', 'NN'), ('ophthalmologic', 'NN'), ('recommendations', 'NNS'), ('based', 'VBN'), ('identified', 'JJ'), ('event', 'NN'), ('lack', 'NN'), ('events', 'NNS'), ('appointment', 'JJ'), ('vision', 'NN'), ('test', 'NN'), ('system', 'NN'), ('one', 'CD'), ('claims', 'VBZ'), ('wherein', 'NN'), ('said', 'VBD'), ('processing', 'NN'), ('unit', 'NN'), ('comprises', 'VBZ'), ('memory', 'NN'), ('storing', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('reference', 'NN'), ('data', 'NNS'), ('indicative', 'JJ'), ('behavioral', 'JJ'), ('compensation', 'NN'), ('vision', 'NN'), ('impairment', 'NN'), ('data', 'NNS'), ('indicative', 'JJ'), ('notification', 'NN'), ('data', 'NNS'), ('indicative', 'JJ'), ('follow-up', 'JJ'), ('notification', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('said', 'VBD'), ('processing', 'NN'), ('unit', 'NN'), ('configured', 'VBD'), ('least', 'JJS'), ('one', 'CD'), ('identifying', 'VBG'), ('event', 'NN'), ('upon', 'IN'), ('comparison', 'NN'), ('detected', 'VBN'), ('data', 'NNS'), ('reference', 'NN'), ('data', 'NNS'), ('determining', 'VBG'), ('probability', 'NN'), ('vision', 'NN'), ('impairment', 'JJ'), ('consumer', 'NN'), ('based', 'VBN'), ('comparison', 'NN'), ('system', 'NN'), ('one', 'CD'), ('claims', 'VBZ'), ('wherein', 'NN'), ('said', 'VBD'), ('processing', 'NN'), ('unit', 'NN'), ('comprises', 'VBZ'), ('communication', 'NN'), ('interface', 'NN'), ('configured', 'VBD'), ('sending', 'VBG'), ('notification', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('identified', 'JJ'), ('consumer', 'NN'), ('third', 'NNP'), ('party', 'NN'), ('system', 'NN'), ('one', 'CD'), ('claims', 'VBZ'), ('wherein', 'NN'), ('said', 'VBD'), ('processing', 'NN'), ('unit', 'NN'), ('configured', 'VBD'), ('providing', 'VBG'), ('frame', 'NN'), ('recommendation', 'NN'), ('system', 'NN'), ('one', 'CD'), ('claims', 'VBZ'), ('wherein', 'NN'), ('said', 'VBD'), ('memory', 'NN'), ('configured', 'VBD'), ('storing', 'JJ'), ('database', 'NN'), ('including', 'VBG'), ('multiplicity', 'NN'), ('data', 'NNS'), ('sets', 'NNS'), ('related', 'JJ'), ('plurality', 'NN'), ('spectacle', 'NN'), ('frame', 'NN'), ('models', 'NNS'), ('sizes', 'VBZ'), ('system', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('said', 'VBD'), ('processing', 'NN'), ('unit', 'NN'), ('configured', 'VBD'), ('operable', 'JJ'), ('correlate', 'NN'), ('frames', 'NNS'), ('parameters', 'NNS'), ('ophthalmic', 'VBP'), ('prescriptions', 'NNS'), ('system', 'NN'), ('according', 'VBG'), ('claims', 'NNS'), ('wherein', 'NN'), ('said', 'VBD'), ('processing', 'NN'), ('unit', 'NN'), ('configured', 'VBD'), ('operable', 'JJ'), ('correlate', 'NN'), ('frames', 'NNS'), ('parameters', 'NNS'), ('facial', 'JJ'), ('features', 'NNS'), ('system', 'NN'), ('according', 'VBG'), ('claims', 'NNS'), ('wherein', 'NN'), ('said', 'VBD'), ('processing', 'NN'), ('unit', 'NN'), ('configured', 'VBD'), ('operable', 'JJ'), ('correlate', 'NN'), ('frames', 'NNS'), ('parameters', 'NNS'), ('eyewear', 'VBP'), ('preferences', 'NNS'), ('system', 'NN'), ('according', 'VBG'), ('claims', 'NNS'), ('comprising', 'VBG'), ('server', 'RB'), ('least', 'JJS'), ('one', 'CD'), ('computer', 'NN'), ('entity', 'NN'), ('linked', 'VBN'), ('server', 'RB'), ('via', 'IN'), ('network', 'NN'), ('wherein', 'NN'), ('said', 'VBD'), ('network', 'NN'), ('configured', 'VBD'), ('receive', 'JJ'), ('respond', 'NN'), ('requests', 'NNS'), ('sent', 'VBD'), ('across', 'IN'), ('network', 'NN'), ('transmitting', 'VBG'), ('one', 'CD'), ('modules', 'NNS'), ('computer', 'NN'), ('executable', 'JJ'), ('program', 'NN'), ('instructions', 'NNS'), ('displayable', 'JJ'), ('data', 'NNS'), ('network', 'NN'), ('connected', 'VBN'), ('user', 'RB'), ('computer', 'NN'), ('platform', 'NN'), ('response', 'NN'), ('request', 'NN'), ('wherein', 'NN'), ('said', 'VBD'), ('modules', 'NNS'), ('include', 'VBP'), ('modules', 'NNS'), ('configured', 'VBD'), ('receive', 'JJ'), ('transmit', 'NN'), ('image', 'NN'), ('information', 'NN'), ('transmitting', 'VBG'), ('frame', 'NN'), ('recommendation', 'NN'), ('optical', 'JJ'), ('lens', 'VBZ'), ('option', 'NN'), ('recommendation', 'NN'), ('based', 'VBN'), ('received', 'VBN'), ('image', 'NN'), ('information', 'NN'), ('display', 'NN'), ('network', 'NN'), ('connected', 'VBN'), ('user', 'RB'), ('computer', 'NN'), ('platform', 'NN'), ('computer', 'NN'), ('program', 'NN'), ('instructions', 'NNS'), ('stored', 'VBD'), ('local', 'JJ'), ('storage', 'NN'), ('executed', 'VBD'), ('processing', 'VBG'), ('unit', 'NN'), ('cause', 'NN'), ('processing', 'VBG'), ('unit', 'NN'), ('receive', 'JJ'), ('data', 'NNS'), ('indicative', 'JJ'), ('scene', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('consumer', 'NN'), ('environment', 'NN'), ('identify', 'VB'), ('data', 'NNS'), ('certain', 'JJ'), ('consumer', 'NN'), ('identify', 'VB'), ('event', 'NN'), ('indicative', 'JJ'), ('behavioral', 'JJ'), ('compensation', 'NN'), ('vision', 'NN'), ('impairment', 'NN'), ('upon', 'IN'), ('identification', 'NN'), ('event', 'NN'), ('send', 'VB'), ('notification', 'NN'), ('relating', 'VBG'), ('vision', 'NN'), ('impairment', 'JJ'), ('computer', 'NN'), ('program', 'NN'), ('product', 'NN'), ('stored', 'VBD'), ('tangible', 'JJ'), ('computer', 'NN'), ('readable', 'JJ'), ('medium', 'NN'), ('comprising', 'VBG'), ('library', 'JJ'), ('software', 'NN'), ('modules', 'NNS'), ('cause', 'VBP'), ('computer', 'NN'), ('executing', 'VBG'), ('prompt', 'JJ'), ('information', 'NN'), ('pertinent', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('eyeglasses', 'VBZ'), ('recommendation', 'NN'), ('optical', 'JJ'), ('lens', 'VBZ'), ('option', 'NN'), ('recommendation', 'NN'), ('store', 'NN'), ('said', 'VBD'), ('information', 'NN'), ('display', 'NN'), ('eyewear', 'VBP'), ('recommendations', 'NNS'), ('computer', 'NN'), ('program', 'NN'), ('product', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('said', 'VBD'), ('library', 'JJ'), ('comprises', 'NNS'), ('module', 'NN'), ('frame', 'NN'), ('selection', 'NN'), ('point', 'NN'), ('sales', 'NNS'), ('advertising', 'VBG'), ('computer', 'NN'), ('platform', 'NN'), ('facilitating', 'VBG'), ('eye', 'NN'), ('glasses', 'NNS'), ('marketing', 'VBG'), ('selection', 'NN'), ('comprising', 'VBG'), ('camera', 'NN'), ('processor', 'NN'), ('configured', 'VBD'), ('execute', 'JJ'), ('computer', 'NN'), ('program', 'NN'), ('instructions', 'NNS'), ('cause', 'VBP'), ('processor', 'NN'), ('take', 'VB'), ('image', 'NN'), ('consumer', 'NN'), ('identify', 'VB'), ('image', 'NN'), ('certain', 'JJ'), ('consumer', 'NN'), ('identify', 'VB'), ('event', 'NN'), ('indicative', 'JJ'), ('behavioral', 'JJ'), ('compensation', 'NN'), ('vision', 'NN'), ('impairment', 'NN'), ('upon', 'IN'), ('identification', 'NN'), ('event', 'NN'), ('sending', 'VBG'), ('notification', 'NN'), ('relating', 'VBG'), ('vision', 'NN'), ('impairment', 'JJ'), ('local', 'JJ'), ('storage', 'NN'), ('processor', 'NN'), ('executable', 'JJ'), ('instructions', 'NNS'), ('carrying', 'VBG'), ('storage', 'NN'), ('information', 'NN'), ('method', 'NN'), ('alerting', 'VBG'), ('vision', 'NN'), ('impairment', 'NN'), ('said', 'VBD'), ('method', 'JJ'), ('comprising', 'VBG'), ('identifying', 'VBG'), ('certain', 'JJ'), ('individual', 'JJ'), ('scene', 'NN'), ('data', 'NNS'), ('indicative', 'JJ'), ('scene', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('consumer', 'NN'), ('environment', 'NN'), ('identifying', 'VBG'), ('event', 'NN'), ('indicative', 'JJ'), ('behavioral', 'JJ'), ('compensation', 'NN'), ('vision', 'NN'), ('impairment', 'NN'), ('upon', 'IN'), ('identification', 'NN'), ('event', 'NN'), ('sending', 'VBG'), ('notification', 'NN'), ('vision', 'NN'), ('impairment', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('detecting', 'VBG'), ('data', 'NNS'), ('indicative', 'JJ'), ('scene', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('consumer', 'NN'), ('retail', 'JJ'), ('environment', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('detecting', 'VBG'), ('data', 'NNS'), ('indicative', 'JJ'), ('least', 'JJS'), ('one', 'CD'), ('consumer', 'NN'), ('comprises', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('capturing', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('image', 'NN'), ('least', 'VBD'), ('one', 'CD'), ('consumer', 'NN'), ('detecting', 'VBG'), ('data', 'NNS'), ('indicative', 'JJ'), ('motion', 'NN'), ('consumer', 'NN'), ('tracking', 'VBG'), ('eye', 'NN'), ('motion', 'NN'), ('consumer', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('capturing', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('image', 'NN'), ('least', 'VBD'), ('one', 'CD'), ('consumer', 'NN'), ('comprises', 'VBZ'), ('continuously', 'RB'), ('recording', 'VBG'), ('scene', 'NN'), ('method', 'NN'), ('one', 'CD'), ('claims', 'VBZ'), ('comprising', 'VBG'), ('identifying', 'VBG'), ('data', 'NNS'), ('consumer', 'NN'), (\"'\", 'POS'), ('condition', 'NN'), ('including', 'VBG'), ('data', 'NNS'), ('indicative', 'JJ'), ('consumer', 'NN'), (\"'s\", 'POS'), ('position', 'NN'), ('location', 'NN'), ('relative', 'JJ'), ('consumer', 'NN'), (\"'s\", 'POS'), ('environment', 'NN'), ('said', 'VBD'), ('data', 'NNS'), ('comprising', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('consumer', 'NN'), (\"'s\", 'POS'), ('face', 'NN'), ('posture', 'NN'), ('position', 'NN'), ('sound', 'NN'), ('motion', 'NN'), ('method', 'NN'), ('one', 'CD'), ('claims', 'VBZ'), ('wherein', 'NN'), ('said', 'VBD'), ('event', 'NN'), ('comprises', 'NNS'), ('least', 'VBP'), ('one', 'CD'), ('position', 'NN'), ('orientation', 'NN'), ('head', 'NN'), ('increase', 'NN'), ('decrease', 'NN'), ('viewing', 'VBG'), ('distance', 'NN'), ('consumer', 'NN'), ('viewed', 'VBD'), ('object', 'JJ'), ('changing', 'VBG'), ('position', 'NN'), ('eyeglasses', 'NNS'), ('worn', 'JJ'), ('consumer', 'NN'), ('method', 'NN'), ('one', 'CD'), ('claims', 'VBZ'), ('wherein', 'NN'), ('identifying', 'VBG'), ('event', 'NN'), ('comprises', 'NNS'), ('identifying', 'VBG'), ('images', 'NNS'), ('image', 'NN'), ('feature', 'NN'), ('indicative', 'JJ'), ('behavioral', 'JJ'), ('compensation', 'NN'), ('performing', 'VBG'), ('bruckner', 'JJ'), ('test', 'NN'), ('performing', 'VBG'), ('hirschberg', 'JJ'), ('test', 'NN'), ('measuring', 'VBG'), ('blink', 'NN'), ('countfrequency', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'WRB'), ('image', 'NN'), ('feature', 'NN'), ('indicative', 'JJ'), ('behavioral', 'JJ'), ('compensation', 'NN'), ('comprises', 'NNS'), ('squinting', 'VBG'), ('head', 'NN'), ('orientation', 'NN'), ('certain', 'JJ'), ('distances', 'NNS'), ('object', 'VBP'), ('consumer', 'NN'), (\"'s\", 'POS'), ('eyes', 'NNS'), ('certain', 'JJ'), ('position', 'NN'), ('eyeglasses', 'VBZ'), ('consumer', 'NN'), (\"'s\", 'POS'), ('face', 'NN'), ('strabismus', 'NN'), ('cataracts', 'VBZ'), ('reflections', 'NNS'), ('eye', 'NN'), ('method', 'VBP'), ('one', 'CD'), ('claims', 'NNS'), ('wherein', 'VBP'), ('identifying', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('image', 'NN'), ('consumer', 'NN'), ('retail', 'JJ'), ('environment', 'NN'), ('comprising', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('receiving', 'VBG'), ('data', 'NNS'), ('characterizing', 'VBG'), ('retail', 'JJ'), ('environment', 'NN'), ('performing', 'VBG'), ('face', 'NN'), ('recognition', 'NN'), ('method', 'FW'), ('one', 'CD'), ('claims', 'NNS'), ('wherein', 'VBP'), ('sending', 'VBG'), ('notification', 'NN'), ('comprising', 'VBG'), ('sending', 'VBG'), ('notification', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('identified', 'JJ'), ('consumer', 'NN'), ('third', 'NNP'), ('party', 'NN'), ('method', 'NN'), ('one', 'CD'), ('claims', 'VBZ'), ('wherein', 'NN'), ('notification', 'NN'), ('includes', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('data', 'NN'), ('indicative', 'NN'), ('identified', 'VBN'), ('event', 'NN'), ('data', 'NNS'), ('indicative', 'JJ'), ('identified', 'JJ'), ('consumer', 'NN'), ('ophthalmologic', 'NN'), ('recommendations', 'NNS'), ('based', 'VBN'), ('identified', 'JJ'), ('event', 'NN'), ('lack', 'NN'), ('events', 'NNS'), ('appointment', 'JJ'), ('vision', 'NN'), ('test', 'NN'), ('method', 'NN'), ('one', 'CD'), ('claims', 'VBZ'), ('comprising', 'VBG'), ('storing', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('reference', 'NN'), ('data', 'NNS'), ('indicative', 'JJ'), ('behavioral', 'JJ'), ('compensation', 'NN'), ('vision', 'NN'), ('impairment', 'NN'), ('data', 'NNS'), ('indicative', 'JJ'), ('notification', 'NN'), ('data', 'NNS'), ('indicative', 'JJ'), ('follow-up', 'JJ'), ('notification', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('identifying', 'VBG'), ('event', 'NN'), ('upon', 'IN'), ('comparison', 'NN'), ('detected', 'VBN'), ('data', 'NNS'), ('reference', 'NN'), ('data', 'NNS'), ('determining', 'VBG'), ('probability', 'NN'), ('vision', 'NN'), ('impairment', 'JJ'), ('consumer', 'NN'), ('based', 'VBN'), ('comparison', 'JJ'), ('computer', 'NN'), ('program', 'NN'), ('intended', 'VBN'), ('stored', 'JJ'), ('memory', 'NN'), ('processor', 'NN'), ('unit', 'NN'), ('computer', 'NN'), ('system', 'NN'), ('removable', 'JJ'), ('memory', 'NN'), ('medium', 'NN'), ('adapted', 'VBD'), ('cooperate', 'JJ'), ('reader', 'NN'), ('processor', 'NN'), ('unit', 'NN'), ('comprising', 'VBG'), ('instructions', 'NNS'), ('implementing', 'VBG'), ('method', 'NN'), ('according', 'VBG'), ('claims', 'NNS')]\n"
     ]
    }
   ],
   "source": [
    "pos_tagging_a = nltk.pos_tag(tokenized_vector_a)\n",
    "print(pos_tagging_a)\n",
    "pos_tagging_c = nltk.pos_tag(tokenized_vector_c)\n",
    "print(pos_tagging_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e5c5701c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('electronic', 'JJ'), ('apparatus', 'NN'), ('including', 'VBG'), ('image', 'NN'), ('capturing', 'NN'), ('device', 'NN'), ('storage', 'NN'), ('device', 'NN'), ('processor', 'NN'), ('operation', 'NN'), ('method', 'NN'), ('thereof', 'NN'), ('provided', 'VBD'), ('image', 'NN'), ('capturing', 'VBG'), ('device', 'NN'), ('captures', 'NNS'), ('image', 'NN'), ('user', 'JJ'), ('storage', 'NN'), ('device', 'NN'), ('records', 'NNS'), ('plurality', 'NN'), ('modules', 'VBZ'), ('processor', 'NN'), ('coupled', 'VBN'), ('image', 'NN'), ('capturing', 'VBG'), ('device', 'JJ'), ('storage', 'NN'), ('device', 'NN'), ('configured', 'VBD'), ('configure', 'JJ'), ('image', 'NN'), ('capturing', 'VBG'), ('device', 'JJ'), ('capture', 'NN'), ('head', 'NN'), ('image', 'NN'), ('user', 'NN'), ('perform', 'VB'), ('face', 'NN'), ('recognition', 'NN'), ('operation', 'NN'), ('obtain', 'VB'), ('face', 'JJ'), ('region', 'NN'), ('detect', 'JJ'), ('plurality', 'NN'), ('facial', 'JJ'), ('landmarks', 'NNS'), ('within', 'IN'), ('face', 'NN'), ('region', 'NN'), ('estimate', 'NN'), ('head', 'NN'), ('posture', 'NN'), ('angle', 'VBZ'), ('user', 'RP'), ('according', 'VBG'), ('facial', 'JJ'), ('landmarks', 'NN'), ('calculate', 'NN'), ('gaze', 'NN'), ('position', 'NN'), ('user', 'NN'), ('gazes', 'VBZ'), ('screen', 'JJ'), ('according', 'VBG'), ('head', 'NN'), ('posture', 'NN'), ('angle', 'VBP'), ('plurality', 'NN'), ('rotation', 'NN'), ('reference', 'NN'), ('angle', 'NN'), ('plurality', 'NN'), ('predetermined', 'VBN'), ('calibration', 'NN'), ('positions', 'NNS'), ('configure', 'VBP'), ('screen', 'JJ'), ('display', 'NN'), ('corresponding', 'VBG'), ('visual', 'JJ'), ('effect', 'NN'), ('according', 'VBG'), ('gaze', 'NN'), ('positionthe', 'NN'), ('present', 'JJ'), ('disclosure', 'NN'), ('provides', 'VBZ'), ('computation', 'NN'), ('method', 'NN'), ('product', 'NN'), ('thereof', 'NN'), ('computation', 'NN'), ('method', 'NN'), ('adopts', 'NNS'), ('fusion', 'VBP'), ('method', 'JJ'), ('perform', 'NN'), ('machine', 'NN'), ('learning', 'VBG'), ('computations', 'NNS'), ('technical', 'JJ'), ('effects', 'NNS'), ('present', 'JJ'), ('disclosure', 'NN'), ('include', 'VBP'), ('fewer', 'JJR'), ('computations', 'NNS'), ('less', 'RBR'), ('power', 'NN'), ('consumptiona', 'NN'), ('method', 'NN'), ('detecting', 'VBG'), ('body', 'NN'), ('information', 'NN'), ('passengers', 'NNS'), ('vehicle', 'NN'), ('based', 'VBN'), ('humans', 'NNS'), (\"'\", 'POS'), ('status', 'NN'), ('recognition', 'NN'), ('provided', 'VBD'), ('method', 'NN'), ('includes', 'VBZ'), ('steps', 'NNS'), ('passenger', 'NN'), ('body', 'NN'), ('information-detecting', 'JJ'), ('device', 'NN'), ('inputting', 'VBG'), ('interior', 'JJ'), ('image', 'NN'), ('vehicle', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('network', 'NN'), ('detect', 'JJ'), ('faces', 'VBZ'), ('passengers', 'NNS'), ('output', 'NN'), ('passenger', 'NN'), ('feature', 'NN'), ('information', 'NN'), ('inputting', 'VBG'), ('interior', 'JJ'), ('image', 'NN'), ('body', 'NN'), ('recognition', 'NN'), ('network', 'NN'), ('detect', 'JJ'), ('bodies', 'NNS'), ('output', 'NN'), ('body-part', 'JJ'), ('length', 'NN'), ('information', 'NN'), ('b', 'NN'), ('retrieving', 'VBG'), ('specific', 'JJ'), ('height', 'JJ'), ('mapping', 'NN'), ('information', 'NN'), ('referring', 'VBG'), ('height', 'NN'), ('mapping', 'VBG'), ('table', 'JJ'), ('ratios', 'NNS'), ('segment', 'NN'), ('body', 'NN'), ('portions', 'NNS'), ('human', 'JJ'), ('groups', 'NNS'), ('heights', 'NNS'), ('per', 'IN'), ('human', 'JJ'), ('groups', 'NNS'), ('acquiring', 'VBG'), ('specific', 'JJ'), ('height', 'NN'), ('specific', 'JJ'), ('passenger', 'NN'), ('retrieving', 'VBG'), ('specific', 'JJ'), ('weight', 'NN'), ('mapping', 'VBG'), ('information', 'NN'), ('weight', 'NN'), ('mapping', 'NN'), ('table', 'JJ'), ('correlations', 'NNS'), ('heights', 'NNS'), ('weights', 'NNS'), ('per', 'IN'), ('human', 'JJ'), ('groups', 'NNS'), ('acquiring', 'VBG'), ('weight', 'NN'), ('specific', 'JJ'), ('passenger', 'NN'), ('referring', 'VBG'), ('specific', 'JJ'), ('heighttechniques', 'NNS'), ('related', 'VBN'), ('improved', 'JJ'), ('video', 'NN'), ('coding', 'VBG'), ('based', 'VBN'), ('face', 'NN'), ('detection', 'NN'), ('region', 'NN'), ('extraction', 'NN'), ('tracking', 'VBG'), ('discussed', 'VBN'), ('techniques', 'NNS'), ('may', 'MD'), ('include', 'VB'), ('performing', 'VBG'), ('facial', 'JJ'), ('search', 'NN'), ('video', 'NN'), ('frame', 'NN'), ('determine', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('regions', 'NNS'), ('video', 'VBP'), ('frame', 'JJ'), ('testing', 'VBG'), ('candidate', 'NN'), ('face', 'NN'), ('regions', 'NNS'), ('based', 'VBN'), ('skin', 'JJ'), ('tone', 'NN'), ('information', 'NN'), ('determine', 'NN'), ('valid', 'NN'), ('invalid', 'JJ'), ('face', 'NN'), ('regions', 'NNS'), ('rejecting', 'VBG'), ('invalid', 'JJ'), ('face', 'NN'), ('regions', 'NNS'), ('encoding', 'VBG'), ('video', 'NN'), ('frame', 'NN'), ('based', 'VBN'), ('valid', 'JJ'), ('face', 'NN'), ('regions', 'NNS'), ('generate', 'VBP'), ('coded', 'VBN'), ('bitstreama', 'NN'), ('method', 'NN'), ('managing', 'VBG'), ('smart', 'JJ'), ('database', 'NN'), ('stores', 'NNS'), ('facial', 'JJ'), ('images', 'NNS'), ('face', 'VBP'), ('recognition', 'NN'), ('provided', 'VBN'), ('method', 'NN'), ('includes', 'VBZ'), ('steps', 'NNS'), ('managing', 'VBG'), ('device', 'NN'), ('counting', 'VBG'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('corresponding', 'VBG'), ('specific', 'JJ'), ('person', 'NN'), ('smart', 'JJ'), ('database', 'NN'), ('new', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('continuously', 'RB'), ('stored', 'VBD'), ('determining', 'VBG'), ('whether', 'IN'), ('first', 'JJ'), ('counted', 'VBN'), ('value', 'NN'), ('representing', 'VBG'), ('count', 'NN'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('satisfies', 'NNS'), ('first', 'RB'), ('set', 'VBN'), ('value', 'NN'), ('b', 'NN'), ('first', 'RB'), ('counted', 'VBD'), ('value', 'NN'), ('satisfies', 'NNS'), ('first', 'RB'), ('set', 'VBN'), ('value', 'NN'), ('inputting', 'VBG'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('neural', 'JJ'), ('aggregation', 'NN'), ('network', 'NN'), ('generate', 'VBP'), ('quality', 'NN'), ('scores', 'NNS'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('aggregation', 'VBP'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('second', 'VBP'), ('counted', 'VBN'), ('value', 'NN'), ('representing', 'VBG'), ('count', 'NN'), ('specific', 'JJ'), ('quality', 'NN'), ('scores', 'NNS'), ('among', 'IN'), ('quality', 'NN'), ('scores', 'NNS'), ('highest', 'JJS'), ('counting', 'VBG'), ('thereof', 'JJ'), ('satisfies', 'NNS'), ('second', 'VBP'), ('set', 'VBN'), ('value', 'NN'), ('deleting', 'VBG'), ('part', 'NN'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('corresponding', 'VBG'), ('uncounted', 'JJ'), ('quality', 'NN'), ('scores', 'NNS'), ('smart', 'VBP'), ('databasea', 'NN'), ('system', 'NN'), ('capable', 'JJ'), ('determining', 'VBG'), ('recognition', 'NN'), ('algorithms', 'NNS'), ('applied', 'VBD'), ('regions', 'NNS'), ('interest', 'NN'), ('within', 'IN'), ('digital', 'JJ'), ('representations', 'NNS'), ('presented', 'VBD'), ('preprocessing', 'VBG'), ('module', 'NN'), ('utilizes', 'IN'), ('one', 'CD'), ('feature', 'NN'), ('identification', 'NN'), ('algorithms', 'FW'), ('determine', 'NN'), ('regions', 'NNS'), ('interest', 'NN'), ('based', 'VBN'), ('feature', 'NN'), ('density', 'NN'), ('preprocessing', 'VBG'), ('modules', 'NNS'), ('leverages', 'VBZ'), ('feature', 'VBP'), ('density', 'NN'), ('signature', 'NN'), ('region', 'NN'), ('determine', 'NN'), ('plurality', 'NN'), ('diverse', 'JJ'), ('recognition', 'NN'), ('modules', 'NNS'), ('operate', 'VBP'), ('region', 'NN'), ('interest', 'NN'), ('specific', 'JJ'), ('embodiment', 'NN'), ('focuses', 'NNS'), ('structured', 'VBD'), ('documents', 'NNS'), ('also', 'RB'), ('presented', 'VBD'), ('disclosed', 'JJ'), ('approach', 'NN'), ('enhanced', 'VBD'), ('addition', 'NN'), ('object', 'NN'), ('classifier', 'NN'), ('classifies', 'NNS'), ('types', 'VBZ'), ('objects', 'NNS'), ('found', 'VBN'), ('regions', 'NNS'), ('interestdisclosed', 'VBN'), ('mobile', 'JJ'), ('terminal', 'NN'), ('mobile', 'JJ'), ('terminal', 'NN'), ('may', 'MD'), ('include', 'VB'), ('front', 'JJ'), ('camera', 'NN'), ('obtaining', 'VBG'), ('face', 'NN'), ('image', 'NN'), ('user', 'JJ'), ('glance', 'NN'), ('sensor', 'NN'), ('tilted', 'VBD'), ('certain', 'JJ'), ('angle', 'NN'), ('disposed', 'VBD'), ('adjacent', 'JJ'), ('front', 'JJ'), ('camera', 'NN'), ('obtain', 'VB'), ('metadata', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('controller', 'NN'), ('obtaining', 'VBG'), ('distance', 'NN'), ('glance', 'NN'), ('sensor', 'NN'), ('front', 'NN'), ('camera', 'NN'), ('distance', 'NN'), ('enabling', 'VBG'), ('area', 'NN'), ('overlap', 'IN'), ('region', 'NN'), ('first', 'JJ'), ('region', 'NN'), ('representing', 'VBG'), ('range', 'NN'), ('photographable', 'JJ'), ('front', 'NN'), ('camera', 'NN'), ('overlaps', 'VBZ'), ('second', 'JJ'), ('region', 'NN'), ('representing', 'VBG'), ('range', 'NN'), ('photographable', 'JJ'), ('glance', 'NN'), ('sensor', 'NN'), ('maximumthis', 'NN'), ('disclosure', 'NN'), ('provides', 'VBZ'), ('systems', 'NNS'), ('methods', 'NNS'), ('apparatus', 'RB'), ('including', 'VBG'), ('computer', 'NN'), ('programs', 'NNS'), ('encoded', 'VBD'), ('computer', 'NN'), ('storage', 'NN'), ('media', 'NNS'), ('intelligent', 'JJ'), ('routing', 'VBG'), ('notifications', 'NNS'), ('related', 'JJ'), ('media', 'NNS'), ('programming', 'VBG'), ('one', 'CD'), ('aspect', 'JJ'), ('smart', 'JJ'), ('television', 'NN'), ('tv', 'NN'), ('implemented', 'VBD'), ('track', 'RP'), ('user', 'NN'), (\"'s\", 'POS'), ('tv', 'NN'), ('watching', 'VBG'), ('behavior', 'JJ'), ('anticipate', 'NN'), ('programming', 'NN'), ('based', 'VBN'), ('behavior', 'JJ'), ('aspects', 'NNS'), ('smart', 'JJ'), ('tv', 'NN'), ('implemented', 'VBN'), ('detect', 'JJ'), ('user', 'NN'), (\"'s\", 'POS'), ('presence', 'NN'), ('based', 'VBN'), ('detection', 'NN'), ('automatically', 'RB'), ('change', 'JJ'), ('tv', 'NN'), ('channel', 'NN'), ('media', 'NNS'), ('programming', 'VBG'), ('analyzed', 'VBN'), ('desirable', 'JJ'), ('user', 'JJ'), ('aspects', 'NNS'), ('smart', 'JJ'), ('tv', 'NN'), ('implemented', 'VBD'), ('transmit', 'NN'), ('notification', 'NN'), ('instructions', 'NNS'), ('electronic', 'JJ'), ('devices', 'NNS'), ('within', 'IN'), ('network', 'NN'), ('attempt', 'NN'), ('alert', 'IN'), ('user', 'NN'), ('upcoming', 'JJ'), ('media', 'NNS'), ('programming', 'VBG'), ('additionally', 'RB'), ('smart', 'JJ'), ('tv', 'NN'), ('implemented', 'VBD'), ('transmit', 'NN'), ('detection', 'NN'), ('instructions', 'NNS'), ('electronic', 'JJ'), ('devices', 'NNS'), ('within', 'IN'), ('network', 'NN'), ('whereby', 'WRB'), ('electronic', 'JJ'), ('devices', 'NNS'), ('attempt', 'VBP'), ('detect', 'JJ'), ('user', 'NN'), (\"'s\", 'POS'), ('presence', 'NN'), ('voice', 'NN'), ('facial', 'JJ'), ('recognitiona', 'NN'), ('camera', 'NN'), ('configured', 'VBD'), ('output', 'NN'), ('test', 'NN'), ('depth+multi-spectral', 'JJ'), ('image', 'NN'), ('including', 'VBG'), ('plurality', 'NN'), ('pixels', 'NNS'), ('pixel', 'VBP'), ('corresponds', 'VBZ'), ('one', 'CD'), ('plurality', 'NN'), ('sensors', 'NNS'), ('sensor', 'VBP'), ('array', 'JJ'), ('camera', 'NN'), ('includes', 'VBZ'), ('least', 'JJS'), ('depth', 'JJ'), ('value', 'NN'), ('spectral', 'JJ'), ('value', 'NN'), ('spectral', 'JJ'), ('light', 'JJ'), ('sub-band', 'JJ'), ('plurality', 'NN'), ('spectral', 'JJ'), ('illuminators', 'NNS'), ('camera', 'VBP'), ('face', 'NN'), ('recognition', 'NN'), ('machine', 'NN'), ('previously', 'RB'), ('trained', 'VBN'), ('set', 'VBN'), ('labeled', 'JJ'), ('training', 'NN'), ('depth+multi-spectral', 'JJ'), ('images', 'NNS'), ('structure', 'NN'), ('test', 'NN'), ('depth+multi-spectral', 'JJ'), ('image', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('machine', 'NN'), ('configured', 'VBD'), ('output', 'NN'), ('confidence', 'NN'), ('value', 'NN'), ('indicating', 'VBG'), ('likelihood', 'JJ'), ('test', 'NN'), ('depth+multi-spectral', 'JJ'), ('image', 'NN'), ('includes', 'VBZ'), ('faceembodiments', 'NNS'), ('present', 'JJ'), ('disclosure', 'NN'), ('relate', 'NN'), ('image', 'NN'), ('processing', 'NN'), ('method', 'NN'), ('apparatus', 'NN'), ('electronic', 'JJ'), ('device', 'NN'), ('method', 'NN'), ('includes', 'VBZ'), ('acquiring', 'VBG'), ('photo', 'NN'), ('album', 'NN'), ('obtained', 'VBD'), ('face', 'NN'), ('clustering', 'VBG'), ('collecting', 'VBG'), ('face', 'NN'), ('information', 'NN'), ('respective', 'JJ'), ('images', 'NNS'), ('photo', 'VBP'), ('album', 'IN'), ('acquiring', 'VBG'), ('face', 'NN'), ('parameter', 'NN'), ('image', 'NN'), ('according', 'VBG'), ('face', 'NN'), ('information', 'NN'), ('selecting', 'VBG'), ('cover', 'NN'), ('image', 'NN'), ('according', 'VBG'), ('face', 'NN'), ('parameter', 'NN'), ('image', 'NN'), ('taking', 'VBG'), ('face-region', 'JJ'), ('image', 'NN'), ('cover', 'NN'), ('image', 'NN'), ('setting', 'VBG'), ('face-region', 'JJ'), ('image', 'NN'), ('cover', 'NN'), ('photo', 'NN'), ('albumtechniques', 'NNS'), ('described', 'VBD'), ('herein', 'JJ'), ('provide', 'IN'), ('location-based', 'JJ'), ('access', 'NN'), ('control', 'NN'), ('secured', 'VBD'), ('resources', 'NNS'), ('generally', 'RB'), ('described', 'VBN'), ('configurations', 'NNS'), ('disclosed', 'VBD'), ('herein', 'RBR'), ('enable', 'JJ'), ('system', 'NN'), ('dynamically', 'RB'), ('modify', 'JJ'), ('access', 'NN'), ('secured', 'VBD'), ('resources', 'NNS'), ('based', 'VBN'), ('one', 'CD'), ('location-related', 'JJ'), ('actions', 'NNS'), ('example', 'NN'), ('techniques', 'NNS'), ('disclosed', 'VBN'), ('herein', 'RB'), ('enable', 'JJ'), ('computing', 'VBG'), ('system', 'NN'), ('control', 'NN'), ('access', 'NN'), ('resources', 'NNS'), ('computing', 'VBG'), ('devices', 'NNS'), ('display', 'NN'), ('devices', 'NNS'), ('secured', 'VBD'), ('locations', 'NNS'), ('secured', 'VBN'), ('data', 'NNS'), ('configurations', 'NNS'), ('techniques', 'NNS'), ('disclosed', 'VBD'), ('herein', 'RBR'), ('enable', 'JJ'), ('controlled', 'JJ'), ('access', 'NN'), ('secured', 'VBD'), ('resources', 'NNS'), ('based', 'VBN'), ('least', 'JJS'), ('part', 'NN'), ('invitation', 'NN'), ('associated', 'VBN'), ('location', 'NN'), ('positioning', 'VBG'), ('data', 'NNS'), ('indicating', 'VBG'), ('location', 'NN'), ('userone', 'JJ'), ('embodiment', 'NN'), ('provides', 'VBZ'), ('method', 'JJ'), ('comprising', 'VBG'), ('receiving', 'VBG'), ('piece', 'NN'), ('content', 'NN'), ('salient', 'NN'), ('moments', 'NNS'), ('data', 'NNS'), ('piece', 'NN'), ('content', 'NN'), ('method', 'NN'), ('comprises', 'NNS'), ('based', 'VBN'), ('salient', 'JJ'), ('moments', 'NNS'), ('data', 'NNS'), ('determining', 'VBG'), ('first', 'JJ'), ('path', 'NN'), ('viewport', 'NN'), ('piece', 'NN'), ('content', 'NN'), ('method', 'NN'), ('comprises', 'VBZ'), ('displaying', 'VBG'), ('viewport', 'NN'), ('display', 'NN'), ('device', 'NN'), ('movement', 'NN'), ('viewport', 'NN'), ('based', 'VBN'), ('first', 'JJ'), ('path', 'NN'), ('playback', 'NN'), ('piece', 'NN'), ('content', 'NN'), ('method', 'NN'), ('comprises', 'VBZ'), ('generating', 'VBG'), ('augmentation', 'NN'), ('salient', 'JJ'), ('moment', 'NN'), ('occurring', 'VBG'), ('piece', 'NN'), ('content', 'NN'), ('presenting', 'VBG'), ('augmentation', 'NN'), ('viewport', 'NN'), ('portion', 'NN'), ('playback', 'NN'), ('augmentation', 'NN'), ('comprises', 'VBZ'), ('interactive', 'JJ'), ('hint', 'NN'), ('guiding', 'VBG'), ('viewport', 'NN'), ('salient', 'NN'), ('momenta', 'VBD'), ('computer-implemented', 'JJ'), ('method', 'NN'), ('system', 'NN'), ('computer', 'NN'), ('program', 'NN'), ('product', 'NN'), ('provided', 'VBD'), ('facial', 'JJ'), ('recognition', 'NN'), ('method', 'NN'), ('includes', 'VBZ'), ('receiving', 'VBG'), ('processor', 'NN'), ('device', 'NN'), ('plurality', 'NN'), ('images', 'NNS'), ('method', 'VBP'), ('also', 'RB'), ('includes', 'VBZ'), ('extracting', 'VBG'), ('processor', 'NN'), ('device', 'NN'), ('feature', 'NN'), ('extractor', 'NN'), ('utilizing', 'JJ'), ('convolutional', 'JJ'), ('neural', 'JJ'), ('network', 'NN'), ('cnn', 'NNS'), ('enlarged', 'VBD'), ('intra-class', 'JJ'), ('variance', 'NN'), ('long-tail', 'JJ'), ('classes', 'NNS'), ('feature', 'VBP'), ('vectors', 'NNS'), ('plurality', 'NN'), ('images', 'NNS'), ('method', 'VBP'), ('additionally', 'RB'), ('includes', 'VBZ'), ('generating', 'VBG'), ('processor', 'NN'), ('device', 'NN'), ('feature', 'NN'), ('generator', 'NN'), ('discriminative', 'JJ'), ('feature', 'NN'), ('vectors', 'NNS'), ('feature', 'VBP'), ('vectors', 'NNS'), ('method', 'VBP'), ('includes', 'VBZ'), ('classifying', 'VBG'), ('processor', 'NN'), ('device', 'NN'), ('utilizing', 'VBG'), ('fully', 'RB'), ('connected', 'VBN'), ('classifier', 'JJR'), ('identity', 'NN'), ('discriminative', 'JJ'), ('feature', 'NN'), ('vector', 'NN'), ('method', 'NN'), ('also', 'RB'), ('includes', 'VBZ'), ('control', 'NN'), ('operation', 'NN'), ('processor-based', 'JJ'), ('machine', 'NN'), ('react', 'NN'), ('accordance', 'NN'), ('identitysome', 'JJ'), ('embodiments', 'NNS'), ('invention', 'NN'), ('provide', 'VBP'), ('efficient', 'JJ'), ('expressive', 'JJ'), ('machine-trained', 'JJ'), ('networks', 'NNS'), ('performing', 'VBG'), ('machine', 'NN'), ('learning', 'VBG'), ('machine-trained', 'JJ'), ('mt', 'NN'), ('networks', 'NNS'), ('embodiments', 'NNS'), ('use', 'VBP'), ('novel', 'JJ'), ('processing', 'NN'), ('nodes', 'NNS'), ('novel', 'JJ'), ('activation', 'NN'), ('functions', 'NNS'), ('allow', 'VBP'), ('mt', 'NN'), ('network', 'NN'), ('efficiently', 'RB'), ('define', 'VBZ'), ('fewer', 'JJR'), ('processing', 'NN'), ('node', 'NN'), ('layers', 'NNS'), ('complex', 'JJ'), ('mathematical', 'JJ'), ('expression', 'NN'), ('solves', 'VBZ'), ('particular', 'JJ'), ('problem', 'NN'), ('eg', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('speech', 'NN'), ('recognition', 'NN'), ('etc', 'FW'), ('embodiments', 'NNS'), ('activation', 'NN'), ('function', 'NN'), ('eg', 'FW'), ('cup', 'NN'), ('function', 'NN'), ('used', 'VBN'), ('numerous', 'JJ'), ('processing', 'VBG'), ('nodes', 'NNS'), ('mt', 'JJ'), ('network', 'NN'), ('machine', 'NN'), ('learning', 'VBG'), ('activation', 'NN'), ('function', 'NN'), ('configured', 'VBD'), ('differently', 'RB'), ('different', 'JJ'), ('processing', 'VBG'), ('nodes', 'NNS'), ('different', 'JJ'), ('nodes', 'NNS'), ('emulate', 'VBP'), ('implement', 'JJ'), ('two', 'CD'), ('different', 'JJ'), ('functions', 'NNS'), ('eg', 'VBP'), ('two', 'CD'), ('boolean', 'JJ'), ('logical', 'JJ'), ('operators', 'NNS'), ('xor', 'VBP'), ('activation', 'NN'), ('function', 'NN'), ('embodiments', 'NNS'), ('periodic', 'JJ'), ('function', 'NN'), ('configured', 'VBD'), ('implement', 'JJ'), ('different', 'JJ'), ('functions', 'NNS'), ('eg', 'VBP'), ('different', 'JJ'), ('sinusoidal', 'JJ'), ('functionsmethods', 'NNS'), ('systems', 'NNS'), ('may', 'MD'), ('provide', 'VB'), ('facial', 'JJ'), ('recognition', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('input', 'NN'), ('image', 'NN'), ('utilizing', 'JJ'), ('hierarchical', 'JJ'), ('feature', 'NN'), ('learning', 'VBG'), ('pair-wise', 'JJ'), ('classification', 'NN'), ('receptive', 'JJ'), ('field', 'NN'), ('theory', 'NN'), ('may', 'MD'), ('used', 'VBN'), ('input', 'VB'), ('image', 'NN'), ('generate', 'JJ'), ('pre-processed', 'JJ'), ('multi-channel', 'JJ'), ('image', 'NN'), ('channels', 'NNS'), ('pre-processed', 'JJ'), ('image', 'NN'), ('may', 'MD'), ('activated', 'VB'), ('based', 'VBN'), ('amount', 'NN'), ('feature', 'NN'), ('rich', 'JJ'), ('details', 'NNS'), ('within', 'IN'), ('channels', 'NNS'), ('similarly', 'RB'), ('local', 'JJ'), ('patches', 'NNS'), ('may', 'MD'), ('activated', 'VB'), ('based', 'VBN'), ('discriminant', 'JJ'), ('features', 'NNS'), ('within', 'IN'), ('local', 'JJ'), ('patches', 'NNS'), ('features', 'NNS'), ('may', 'MD'), ('extracted', 'VB'), ('local', 'JJ'), ('patches', 'NNS'), ('discriminant', 'JJ'), ('features', 'NNS'), ('may', 'MD'), ('selected', 'VBN'), ('order', 'NN'), ('perform', 'NN'), ('feature', 'NN'), ('matching', 'VBG'), ('pair', 'NN'), ('sets', 'NNS'), ('system', 'NN'), ('may', 'MD'), ('utilize', 'VB'), ('patch', 'NN'), ('feature', 'NN'), ('pooling', 'VBG'), ('pair-wise', 'JJ'), ('matching', 'JJ'), ('large-scale', 'JJ'), ('training', 'NN'), ('order', 'NN'), ('quickly', 'RB'), ('accurately', 'RB'), ('perform', 'JJ'), ('facial', 'JJ'), ('recognition', 'NN'), ('low', 'JJ'), ('cost', 'NN'), ('system', 'NN'), ('memory', 'NN'), ('computationa', 'NN'), ('method', 'NN'), ('controlling', 'VBG'), ('terminal', 'NN'), ('provided', 'VBD'), ('terminal', 'JJ'), ('includes', 'VBZ'), ('capturing', 'VBG'), ('apparatus', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('processor', 'NN'), ('image', 'NN'), ('acquired', 'VBD'), ('capturing', 'VBG'), ('apparatus', 'NN'), ('motion', 'NN'), ('parameter', 'NN'), ('terminal', 'NN'), ('obtained', 'VBN'), ('image', 'NN'), ('processing', 'NN'), ('acquired', 'VBD'), ('image', 'NN'), ('controlled', 'VBN'), ('performed', 'VBD'), ('based', 'VBN'), ('motion', 'NN'), ('parameter', 'NN'), ('equal', 'JJ'), ('less', 'RBR'), ('preset', 'JJ'), ('parameter', 'NN'), ('threshold', 'NN'), ('skipped', 'VBD'), ('based', 'VBN'), ('motion', 'NN'), ('parameter', 'NN'), ('greater', 'JJR'), ('preset', 'NN'), ('parameter', 'NN'), ('thresholda', 'VBD'), ('drive-through', 'JJ'), ('order', 'NN'), ('processing', 'NN'), ('method', 'NN'), ('apparatus', 'NN'), ('disclosed', 'VBD'), ('drive-through', 'JJ'), ('order', 'NN'), ('processing', 'NN'), ('method', 'NN'), ('includes', 'VBZ'), ('receiving', 'VBG'), ('customer', 'NN'), ('information', 'NN'), ('detected', 'VBN'), ('vision', 'NN'), ('recognition', 'NN'), ('providing', 'VBG'), ('product', 'NN'), ('information', 'NN'), ('based', 'VBN'), ('customer', 'NN'), ('information', 'NN'), ('processing', 'VBG'), ('product', 'NN'), ('order', 'NN'), ('customer', 'NN'), ('according', 'VBG'), ('present', 'JJ'), ('disclosure', 'NN'), ('possible', 'JJ'), ('rapidly', 'RB'), ('process', 'JJ'), ('order', 'NN'), ('using', 'VBG'), ('customer', 'NN'), ('information', 'NN'), ('based', 'VBN'), ('customer', 'NN'), ('recognition', 'NN'), ('using', 'VBG'), ('artificial', 'JJ'), ('intelligence', 'NN'), ('ai', 'JJ'), ('model', 'NN'), ('machine', 'NN'), ('learning', 'VBG'), ('g', 'JJ'), ('networkan', 'JJ'), ('image', 'NN'), ('processing', 'NN'), ('method', 'NN'), ('performed', 'VBD'), ('computing', 'VBG'), ('device', 'NN'), ('includes', 'VBZ'), ('identifying', 'VBG'), ('using', 'VBG'), ('face', 'NN'), ('recognition', 'NN'), ('one', 'CD'), ('faces', 'VBZ'), ('face', 'NN'), ('corresponding', 'VBG'), ('respective', 'JJ'), ('person', 'NN'), ('captured', 'VBD'), ('first', 'JJ'), ('image', 'NN'), ('identified', 'VBN'), ('face', 'NN'), ('extracting', 'VBG'), ('set', 'VBN'), ('profile', 'JJ'), ('parameters', 'NNS'), ('corresponding', 'VBG'), ('person', 'NN'), ('first', 'JJ'), ('image', 'NN'), ('selecting', 'VBG'), ('plurality', 'NN'), ('image', 'NN'), ('tiles', 'NNS'), ('first', 'RB'), ('image', 'NN'), ('tile', 'NN'), ('matches', 'NNS'), ('face', 'VBP'), ('corresponding', 'VBG'), ('person', 'NN'), ('first', 'JJ'), ('image', 'NN'), ('accordance', 'NN'), ('predefined', 'VBD'), ('correspondence', 'NN'), ('set', 'VBN'), ('profile', 'JJ'), ('parameters', 'NNS'), ('corresponding', 'VBG'), ('person', 'NN'), ('set', 'VBN'), ('pre-stored', 'JJ'), ('description', 'NN'), ('parameters', 'NNS'), ('first', 'JJ'), ('image', 'NN'), ('tile', 'NN'), ('generating', 'VBG'), ('second', 'JJ'), ('image', 'NN'), ('covering', 'VBG'), ('faces', 'VBZ'), ('respective', 'JJ'), ('persons', 'NNS'), ('first', 'JJ'), ('image', 'NN'), ('corresponding', 'VBG'), ('first', 'JJ'), ('image', 'NN'), ('tiles', 'NNS'), ('sharing', 'VBG'), ('first', 'JJ'), ('image', 'NN'), ('second', 'JJ'), ('image', 'NN'), ('predefined', 'VBD'), ('order', 'NN'), ('via', 'IN'), ('group', 'NN'), ('chat', 'WP'), ('sessionin', 'VBZ'), ('one', 'CD'), ('embodiment', 'NN'), ('artificial', 'JJ'), ('reality', 'NN'), ('system', 'NN'), ('determines', 'VBZ'), ('performance', 'NN'), ('metric', 'JJ'), ('eye', 'NN'), ('tracking', 'VBG'), ('system', 'NN'), ('first', 'JJ'), ('performance', 'NN'), ('threshold', 'NN'), ('eye', 'NN'), ('tracking', 'VBG'), ('system', 'NN'), ('associated', 'VBN'), ('head-mounted', 'JJ'), ('display', 'NN'), ('worn', 'VBN'), ('user', 'JJ'), ('artificial', 'JJ'), ('reality', 'NN'), ('system', 'NN'), ('receives', 'VBZ'), ('first', 'RB'), ('inputs', 'NNS'), ('associated', 'VBN'), ('body', 'NN'), ('user', 'JJ'), ('determines', 'NNS'), ('region', 'NN'), ('user', 'IN'), ('looking', 'VBG'), ('within', 'IN'), ('field', 'NN'), ('view', 'NN'), ('head-mounted', 'JJ'), ('display', 'NN'), ('based', 'VBN'), ('received', 'VBD'), ('first', 'RB'), ('inputs', 'JJ'), ('system', 'NN'), ('determines', 'VBZ'), ('vergence', 'NN'), ('distance', 'NN'), ('user', 'NN'), ('based', 'VBN'), ('least', 'JJS'), ('first', 'JJ'), ('inputs', 'NNS'), ('associated', 'VBN'), ('body', 'NN'), ('user', 'JJ'), ('region', 'NN'), ('user', 'IN'), ('looking', 'VBG'), ('locations', 'NNS'), ('one', 'CD'), ('objects', 'VBZ'), ('scene', 'NN'), ('displayed', 'VBD'), ('head-mounted', 'JJ'), ('display', 'NN'), ('system', 'NN'), ('adjusts', 'VBZ'), ('one', 'CD'), ('configurations', 'NNS'), ('head-mounted', 'JJ'), ('display', 'NN'), ('based', 'VBN'), ('determined', 'JJ'), ('vergence', 'NN'), ('distance', 'NN'), ('usera', 'JJ'), ('computer-implemented', 'JJ'), ('method', 'NN'), ('provided', 'VBD'), ('image-based', 'JJ'), ('self-guided', 'JJ'), ('object', 'JJ'), ('detection', 'NN'), ('method', 'NN'), ('includes', 'VBZ'), ('receiving', 'VBG'), ('processor', 'NN'), ('device', 'NN'), ('set', 'VBN'), ('images', 'NNS'), ('images', 'NNS'), ('respective', 'VBP'), ('grid', 'JJ'), ('thereon', 'NN'), ('labeled', 'VBD'), ('regarding', 'VBG'), ('respective', 'JJ'), ('object', 'NN'), ('detected', 'VBD'), ('using', 'VBG'), ('grid', 'JJ'), ('level', 'NN'), ('label', 'NN'), ('data', 'NNS'), ('method', 'NN'), ('includes', 'VBZ'), ('training', 'VBG'), ('processor', 'JJ'), ('device', 'NN'), ('grid-based', 'JJ'), ('object', 'NN'), ('detector', 'NN'), ('using', 'VBG'), ('grid', 'JJ'), ('level', 'NN'), ('label', 'NN'), ('data', 'NNS'), ('method', 'NN'), ('also', 'RB'), ('includes', 'VBZ'), ('determining', 'VBG'), ('processor', 'NN'), ('device', 'NN'), ('respective', 'NN'), ('bounding', 'VBG'), ('box', 'NN'), ('respective', 'JJ'), ('object', 'JJ'), ('images', 'NNS'), ('applying', 'VBG'), ('local', 'JJ'), ('segmentation', 'NN'), ('images', 'NNS'), ('method', 'VBP'), ('additionally', 'RB'), ('includes', 'VBZ'), ('training', 'NN'), ('processor', 'NN'), ('device', 'NN'), ('region-based', 'JJ'), ('convolutional', 'JJ'), ('neural', 'JJ'), ('network', 'NN'), ('rcnn', 'NN'), ('joint', 'NN'), ('object', 'JJ'), ('localization', 'NN'), ('object', 'NN'), ('classification', 'NN'), ('using', 'VBG'), ('respective', 'JJ'), ('bounding', 'NN'), ('box', 'NN'), ('respective', 'JJ'), ('object', 'JJ'), ('images', 'NNS'), ('input', 'VBP'), ('rcnna', 'JJ'), ('system', 'NN'), ('method', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('comprising', 'VBG'), ('multiple', 'JJ'), ('phases', 'NNS'), ('implemented', 'VBN'), ('parallel', 'JJ'), ('architecture', 'NN'), ('first', 'JJ'), ('phase', 'NN'), ('normalization', 'NN'), ('phase', 'NN'), ('whereby', 'NN'), ('captured', 'VBD'), ('image', 'NN'), ('normalized', 'VBN'), ('size', 'NN'), ('orientation', 'NN'), ('illumination', 'NN'), ('stored', 'VBD'), ('images', 'NNS'), ('preexisting', 'VBG'), ('database', 'JJ'), ('second', 'JJ'), ('phase', 'NN'), ('feature', 'NN'), ('extractiondistance', 'NN'), ('matrix', 'NN'), ('phase', 'NN'), ('distance', 'NN'), ('matrix', 'NN'), ('generated', 'VBD'), ('captured', 'JJ'), ('image', 'NN'), ('coarse', 'NN'), ('recognition', 'NN'), ('phase', 'NN'), ('generated', 'VBD'), ('distance', 'NN'), ('matrix', 'NNS'), ('compared', 'VBN'), ('distance', 'NN'), ('matrices', 'NNS'), ('database', 'VBP'), ('using', 'VBG'), ('euclidean', 'JJ'), ('distance', 'NN'), ('matches', 'NNS'), ('create', 'VBP'), ('candidate', 'NN'), ('lists', 'NNS'), ('detailed', 'VBD'), ('recognition', 'NN'), ('phase', 'NN'), ('multiple', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('algorithms', 'RB'), ('applied', 'JJ'), ('candidate', 'NN'), ('lists', 'NNS'), ('produce', 'VBP'), ('final', 'JJ'), ('result', 'NN'), ('distance', 'NN'), ('matrices', 'NNS'), ('normalized', 'JJ'), ('database', 'NN'), ('may', 'MD'), ('broken', 'VB'), ('parallel', 'JJ'), ('lists', 'NNS'), ('parallelization', 'VBP'), ('feature', 'NN'), ('extractiondistance', 'NN'), ('matrix', 'NN'), ('phase', 'NN'), ('candidate', 'NN'), ('lists', 'NNS'), ('may', 'MD'), ('also', 'RB'), ('grouped', 'VB'), ('according', 'VBG'), ('dissimilarity', 'NN'), ('algorithm', 'NN'), ('parallel', 'NN'), ('processing', 'NN'), ('detailed', 'JJ'), ('recognition', 'NN'), ('phasean', 'JJ'), ('imaging', 'NN'), ('device', 'NN'), ('including', 'VBG'), ('pixel', 'JJ'), ('matrix', 'NN'), ('processor', 'NN'), ('provided', 'VBD'), ('pixel', 'JJ'), ('matrix', 'NN'), ('includes', 'VBZ'), ('plurality', 'NN'), ('phase', 'NN'), ('detection', 'NN'), ('pixels', 'NNS'), ('plurality', 'NN'), ('regular', 'JJ'), ('pixels', 'NNS'), ('processor', 'NN'), ('performs', 'NNS'), ('autofocusing', 'VBG'), ('according', 'VBG'), ('pixel', 'NN'), ('data', 'NNS'), ('phase', 'NN'), ('detection', 'NN'), ('pixels', 'NNS'), ('determines', 'VBZ'), ('operating', 'VBG'), ('resolution', 'NN'), ('regular', 'JJ'), ('pixels', 'NNS'), ('according', 'VBG'), ('autofocused', 'JJ'), ('pixel', 'NN'), ('data', 'NNS'), ('phase', 'NN'), ('detection', 'NN'), ('pixels', 'NNS'), ('wherein', 'VBP'), ('phase', 'JJ'), ('detection', 'NN'), ('pixels', 'NNS'), ('always-on', 'JJ'), ('pixels', 'NNS'), ('regular', 'JJ'), ('pixels', 'NNS'), ('selectively', 'RB'), ('turned', 'VBD'), ('autofocusing', 'VBG'), ('accomplishedan', 'NN'), ('apparatus', 'NN'), ('includes', 'VBZ'), ('first', 'JJ'), ('camera', 'NN'), ('module', 'NN'), ('providing', 'VBG'), ('first', 'JJ'), ('image', 'NN'), ('object', 'VBP'), ('first', 'JJ'), ('field', 'NN'), ('view', 'NN'), ('second', 'JJ'), ('camera', 'NN'), ('module', 'NN'), ('providing', 'VBG'), ('second', 'JJ'), ('image', 'NN'), ('object', 'JJ'), ('second', 'JJ'), ('field', 'NN'), ('view', 'NN'), ('different', 'JJ'), ('first', 'JJ'), ('field', 'NN'), ('view', 'NN'), ('first', 'RB'), ('depth', 'VBZ'), ('map', 'NN'), ('generator', 'NN'), ('generates', 'NNS'), ('first', 'RB'), ('depth', 'VB'), ('map', 'NN'), ('first', 'RB'), ('image', 'NN'), ('based', 'VBN'), ('first', 'JJ'), ('image', 'NN'), ('second', 'JJ'), ('image', 'NN'), ('second', 'JJ'), ('depth', 'NN'), ('map', 'NN'), ('generator', 'NN'), ('generates', 'VBZ'), ('second', 'JJ'), ('depth', 'NN'), ('map', 'NN'), ('second', 'JJ'), ('image', 'NN'), ('based', 'VBN'), ('first', 'JJ'), ('image', 'NN'), ('second', 'JJ'), ('image', 'NN'), ('first', 'RB'), ('depth', 'JJ'), ('mapmethods', 'NNS'), ('systems', 'NNS'), ('apparatus', 'RB'), ('including', 'VBG'), ('computer', 'NN'), ('programs', 'NNS'), ('encoded', 'VBD'), ('computer', 'NN'), ('storage', 'NN'), ('media', 'NNS'), ('payment', 'NN'), ('based', 'VBN'), ('face', 'NN'), ('recognition', 'NN'), ('provided', 'VBD'), ('one', 'CD'), ('methods', 'NNS'), ('includes', 'VBZ'), ('acquiring', 'VBG'), ('first', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('information', 'NN'), ('target', 'NN'), ('user', 'NN'), ('extracting', 'VBG'), ('first', 'JJ'), ('characteristic', 'JJ'), ('information', 'NN'), ('first', 'RB'), ('face', 'NN'), ('image', 'NN'), ('information', 'NN'), ('wherein', 'IN'), ('first', 'JJ'), ('characteristic', 'JJ'), ('information', 'NN'), ('includes', 'VBZ'), ('head', 'NN'), ('posture', 'NN'), ('information', 'NN'), ('target', 'NN'), ('user', 'NN'), ('gaze', 'NN'), ('information', 'NN'), ('target', 'NN'), ('user', 'NN'), ('determining', 'VBG'), ('whether', 'IN'), ('target', 'NN'), ('user', 'JJ'), ('willingness', 'NN'), ('pay', 'NN'), ('according', 'VBG'), ('head', 'NN'), ('posture', 'NN'), ('information', 'NN'), ('target', 'NN'), ('user', 'NN'), ('gaze', 'NN'), ('information', 'NN'), ('target', 'NN'), ('user', 'NN'), ('including', 'VBG'), ('determining', 'VBG'), ('whether', 'IN'), ('angle', 'JJ'), ('rotation', 'NN'), ('preset', 'VBN'), ('direction', 'NN'), ('less', 'RBR'), ('angle', 'JJ'), ('threshold', 'NN'), ('whether', 'IN'), ('probability', 'NN'), ('value', 'NN'), ('user', 'NN'), ('gazes', 'JJ'), ('payment', 'NN'), ('screen', 'NN'), ('greater', 'JJR'), ('probability', 'NN'), ('threshold', 'JJ'), ('response', 'NN'), ('determining', 'VBG'), ('target', 'NN'), ('user', 'JJ'), ('willingness', 'NN'), ('pay', 'NN'), ('completing', 'VBG'), ('payment', 'NN'), ('operation', 'NN'), ('based', 'VBN'), ('face', 'NN'), ('recognitiona', 'NN'), ('novel', 'JJ'), ('method', 'NN'), ('apparatus', 'NN'), ('face', 'NN'), ('authentication', 'NN'), ('disclosed', 'VBD'), ('disclosed', 'VBN'), ('method', 'NN'), ('comprises', 'VBZ'), ('detecting', 'VBG'), ('motion', 'NN'), ('subject', 'NN'), ('within', 'IN'), ('predetermined', 'JJ'), ('area', 'NN'), ('view', 'NN'), ('assigning', 'VBG'), ('unique', 'JJ'), ('session', 'NN'), ('identification', 'NN'), ('number', 'NN'), ('subject', 'JJ'), ('detected', 'VBD'), ('within', 'IN'), ('predetermined', 'JJ'), ('area', 'NN'), ('view', 'NN'), ('detecting', 'VBG'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'NN'), ('detected', 'VBD'), ('within', 'IN'), ('predetermined', 'JJ'), ('area', 'NN'), ('view', 'NN'), ('generating', 'VBG'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'NN'), ('assessing', 'VBG'), ('quality', 'NN'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'JJ'), ('conducing', 'VBG'), ('incremental', 'JJ'), ('training', 'NN'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'JJ'), ('determining', 'VBG'), ('identity', 'NN'), ('subject', 'NN'), ('based', 'VBN'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'JJ'), ('identifying', 'VBG'), ('intent', 'NN'), ('subject', 'JJ'), ('authorizing', 'VBG'), ('access', 'NN'), ('point', 'NN'), ('entry', 'NN'), ('based', 'VBN'), ('determined', 'VBN'), ('identity', 'NN'), ('subject', 'NN'), ('based', 'VBN'), ('intent', 'NN'), ('subjectdisclosed', 'VBN'), ('herein', 'NN'), ('robot', 'VBZ'), ('electronic', 'JJ'), ('device', 'NN'), ('acquiring', 'VBG'), ('video', 'JJ'), ('method', 'NN'), ('acquiring', 'VBG'), ('video', 'NN'), ('using', 'VBG'), ('robot', 'JJ'), ('robot', 'NN'), ('includes', 'VBZ'), ('camera', 'NN'), ('configured', 'VBD'), ('rotate', 'JJ'), ('lateral', 'JJ'), ('direction', 'NN'), ('tilt', 'VBD'), ('vertical', 'JJ'), ('direction', 'NN'), ('controls', 'NNS'), ('least', 'VBP'), ('one', 'CD'), ('direction', 'NN'), ('rotation', 'NN'), ('camera', 'NN'), ('angle', 'NN'), ('tilt', 'NN'), ('camera', 'NN'), ('focal', 'JJ'), ('distance', 'NN'), ('camera', 'NN'), ('recognizing', 'VBG'), ('tracking', 'VBG'), ('users', 'NNS'), ('video', 'RB'), ('acquired', 'VBD'), ('camerasystems', 'NNS'), ('methods', 'NNS'), ('disclosed', 'VBD'), ('inferring', 'VBG'), ('topics', 'NNS'), ('file', 'NN'), ('containing', 'VBG'), ('audio', 'JJ'), ('video', 'NN'), ('example', 'NN'), ('multimodal', 'JJ'), ('multimedia', 'NN'), ('file', 'NN'), ('order', 'NN'), ('facilitate', 'NN'), ('video', 'NN'), ('indexing', 'VBG'), ('set', 'VBN'), ('entities', 'NNS'), ('extracted', 'VBD'), ('file', 'NN'), ('linked', 'VBN'), ('produce', 'VBP'), ('graph', 'JJ'), ('reference', 'NN'), ('information', 'NN'), ('also', 'RB'), ('obtained', 'VBD'), ('set', 'JJ'), ('entities', 'NNS'), ('entities', 'NNS'), ('may', 'MD'), ('drawn', 'VB'), ('example', 'NN'), ('wikipedia', 'NN'), ('categories', 'NNS'), ('large', 'JJ'), ('ontological', 'JJ'), ('data', 'NNS'), ('sources', 'NNS'), ('analysis', 'NN'), ('graph', 'NN'), ('using', 'VBG'), ('unsupervised', 'JJ'), ('learning', 'VBG'), ('permits', 'NNS'), ('determining', 'VBG'), ('clusters', 'NNS'), ('graph', 'VBP'), ('extracting', 'VBG'), ('features', 'NNS'), ('clusters', 'NNS'), ('possibly', 'RB'), ('using', 'VBG'), ('supervised', 'VBN'), ('learning', 'VBG'), ('provides', 'VBZ'), ('selection', 'NN'), ('topic', 'NN'), ('identifiers', 'NNS'), ('topic', 'VBP'), ('identifiers', 'NNS'), ('used', 'VBD'), ('indexing', 'VBG'), ('filea', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('method', 'FW'), ('neural', 'JJ'), ('network', 'NN'), ('training', 'VBG'), ('method', 'NN'), ('apparatus', 'NN'), ('electronic', 'JJ'), ('device', 'NN'), ('method', 'NN'), ('comprises', 'VBZ'), ('obtaining', 'VBG'), ('first', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('means', 'VBZ'), ('first', 'JJ'), ('camera', 'NN'), ('extracting', 'VBG'), ('first', 'JJ'), ('face', 'NN'), ('feature', 'NN'), ('first', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('comparing', 'VBG'), ('first', 'JJ'), ('face', 'NN'), ('feature', 'NN'), ('pre-stored', 'JJ'), ('second', 'JJ'), ('face', 'NN'), ('feature', 'NN'), ('obtain', 'VB'), ('reference', 'NN'), ('similarity', 'NN'), ('second', 'JJ'), ('face', 'NN'), ('feature', 'NN'), ('obtained', 'VBN'), ('extracting', 'JJ'), ('feature', 'JJ'), ('second', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('obtained', 'VBN'), ('second', 'JJ'), ('camera', 'NN'), ('second', 'JJ'), ('camera', 'NN'), ('first', 'RB'), ('camera', 'VB'), ('different', 'JJ'), ('types', 'NNS'), ('cameras', 'NNS'), ('determining', 'VBG'), ('according', 'VBG'), ('reference', 'NN'), ('similarity', 'NN'), ('whether', 'IN'), ('first', 'JJ'), ('face', 'NN'), ('feature', 'NN'), ('second', 'JJ'), ('face', 'NN'), ('feature', 'NN'), ('correspond', 'NN'), ('person', 'NN'), ('present', 'JJ'), ('invention', 'NN'), ('discloses', 'VBZ'), ('technique', 'JJ'), ('alerting', 'VBG'), ('vision', 'NN'), ('impairment', 'NN'), ('system', 'NN'), ('comprises', 'VBZ'), ('processing', 'VBG'), ('unit', 'NN'), ('configured', 'VBD'), ('operable', 'JJ'), ('receiving', 'VBG'), ('scene', 'NN'), ('data', 'NNS'), ('indicative', 'JJ'), ('scene', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('consumer', 'NN'), ('environment', 'NN'), ('identifying', 'VBG'), ('scene', 'NN'), ('data', 'NNS'), ('certain', 'JJ'), ('consumer', 'NN'), ('identifying', 'VBG'), ('event', 'NN'), ('indicative', 'JJ'), ('behavioral', 'JJ'), ('compensation', 'NN'), ('vision', 'NN'), ('impairment', 'NN'), ('upon', 'IN'), ('identification', 'NN'), ('event', 'NN'), ('sending', 'VBG'), ('notification', 'NN'), ('relating', 'VBG'), ('vision', 'NN'), ('impairment', 'NN')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('electronic', 'JJ'), ('device', 'NN'), ('configured', 'VBD'), ('make', 'VBP'), ('screen', 'JJ'), ('display', 'NN'), ('plurality', 'NN'), ('image', 'NN'), ('frames', 'NNS'), ('comprising', 'VBG'), ('image', 'NN'), ('capturing', 'VBG'), ('device', 'JJ'), ('storage', 'NN'), ('device', 'NN'), ('storing', 'VBG'), ('plurality', 'NN'), ('modules', 'NNS'), ('processor', 'VBP'), ('coupled', 'VBN'), ('image', 'NN'), ('capturing', 'VBG'), ('device', 'JJ'), ('storage', 'NN'), ('device', 'NN'), ('configured', 'VBD'), ('execute', 'JJ'), ('modules', 'NNS'), ('storage', 'NN'), ('device', 'NN'), ('configure', 'NN'), ('screen', 'NN'), ('display', 'NN'), ('plurality', 'NN'), ('marker', 'NN'), ('objects', 'VBZ'), ('plurality', 'NN'), ('predetermined', 'VBN'), ('calibration', 'NN'), ('positions', 'NNS'), ('configure', 'VBP'), ('image', 'NN'), ('capturing', 'NN'), ('device', 'NN'), ('capture', 'NN'), ('plurality', 'NN'), ('first', 'RB'), ('head', 'JJ'), ('images', 'NNS'), ('user', 'VBP'), ('looking', 'VBG'), ('predetermined', 'VBN'), ('calibration', 'NN'), ('positions', 'NNS'), ('perform', 'VBP'), ('plurality', 'NN'), ('first', 'RB'), ('face', 'NN'), ('recognition', 'NN'), ('operations', 'NNS'), ('first', 'RB'), ('head', 'VBP'), ('images', 'NNS'), ('obtain', 'VB'), ('plurality', 'NN'), ('first', 'RB'), ('face', 'NN'), ('regions', 'NNS'), ('corresponding', 'VBG'), ('predetermined', 'JJ'), ('calibration', 'NN'), ('positions', 'NNS'), ('detect', 'VBP'), ('plurality', 'NN'), ('first', 'RB'), ('facial', 'JJ'), ('landmarks', 'NNS'), ('corresponding', 'VBG'), ('first', 'JJ'), ('face', 'NN'), ('regions', 'NNS'), ('calculate', 'VBP'), ('plurality', 'NN'), ('rotation', 'NN'), ('reference', 'NN'), ('angles', 'NNS'), ('user', 'RBR'), ('looking', 'VBG'), ('predetermined', 'JJ'), ('calibration', 'NN'), ('positions', 'NNS'), ('according', 'VBG'), ('first', 'JJ'), ('facial', 'JJ'), ('landmarks', 'NN'), ('configure', 'NN'), ('image', 'NN'), ('capturing', 'VBG'), ('device', 'JJ'), ('capture', 'NN'), ('second', 'JJ'), ('head', 'NN'), ('image', 'NN'), ('user', 'JJ'), ('perform', 'JJ'), ('second', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('operation', 'NN'), ('second', 'JJ'), ('head', 'NN'), ('image', 'NN'), ('obtain', 'VB'), ('second', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('detect', 'JJ'), ('plurality', 'NN'), ('second', 'JJ'), ('facial', 'JJ'), ('landmarks', 'NNS'), ('within', 'IN'), ('second', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('estimate', 'NN'), ('head', 'NN'), ('posture', 'NN'), ('angle', 'VBZ'), ('user', 'RP'), ('according', 'VBG'), ('second', 'JJ'), ('facial', 'JJ'), ('landmarks', 'NNS'), ('calculate', 'VBP'), ('gaze', 'JJ'), ('position', 'NN'), ('user', 'NN'), ('screen', 'NN'), ('according', 'VBG'), ('head', 'NN'), ('posture', 'NN'), ('angle', 'JJ'), ('rotation', 'NN'), ('reference', 'NN'), ('angles', 'NNS'), ('predetermined', 'VBN'), ('calibration', 'NN'), ('positions', 'NNS'), ('configure', 'VBP'), ('screen', 'JJ'), ('display', 'NN'), ('corresponding', 'VBG'), ('visual', 'JJ'), ('effect', 'NN'), ('according', 'VBG'), ('gaze', 'JJ'), ('position', 'NN'), ('electronic', 'JJ'), ('device', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('gaze', 'JJ'), ('position', 'NN'), ('comprises', 'NNS'), ('first', 'JJ'), ('coordinate', 'NN'), ('value', 'NN'), ('first', 'RB'), ('axial', 'JJ'), ('direction', 'NN'), ('second', 'JJ'), ('coordinate', 'NN'), ('value', 'NN'), ('second', 'JJ'), ('axial', 'JJ'), ('direction', 'NN'), ('electronic', 'JJ'), ('device', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('head', 'NN'), ('posture', 'NN'), ('angles', 'VBZ'), ('comprise', 'RB'), ('head', 'JJ'), ('pitch', 'NN'), ('angle', 'NN'), ('head', 'NN'), ('yaw', 'NN'), ('angle', 'JJ'), ('rotation', 'NN'), ('reference', 'NN'), ('angles', 'NNS'), ('comprise', 'VBP'), ('first', 'JJ'), ('pitch', 'NN'), ('angle', 'NN'), ('second', 'JJ'), ('pitch', 'NN'), ('angle', 'NN'), ('first', 'RB'), ('yaw', 'RB'), ('angle', 'JJ'), ('second', 'JJ'), ('yaw', 'NN'), ('angle', 'NN'), ('corresponding', 'VBG'), ('predetermined', 'JJ'), ('calibration', 'NN'), ('positions', 'NNS'), ('electronic', 'JJ'), ('device', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('processor', 'NN'), ('performs', 'NNS'), ('interpolation', 'NN'), ('operation', 'NN'), ('extrapolation', 'NN'), ('operation', 'NN'), ('according', 'VBG'), ('first', 'JJ'), ('yaw', 'NN'), ('angle', 'JJ'), ('second', 'JJ'), ('yaw', 'NN'), ('angle', 'NN'), ('first', 'JJ'), ('position', 'NN'), ('corresponding', 'VBG'), ('first', 'JJ'), ('yaw', 'JJ'), ('angle', 'NN'), ('among', 'IN'), ('predetermined', 'JJ'), ('calibration', 'NN'), ('positions', 'NNS'), ('second', 'JJ'), ('position', 'NN'), ('corresponding', 'VBG'), ('second', 'JJ'), ('yaw', 'JJ'), ('angle', 'NN'), ('among', 'IN'), ('predetermined', 'JJ'), ('calibration', 'NN'), ('positions', 'NNS'), ('head', 'VBP'), ('yaw', 'RB'), ('angle', 'JJ'), ('thereby', 'RB'), ('obtaining', 'VBG'), ('first', 'JJ'), ('coordinate', 'NN'), ('value', 'NN'), ('gaze', 'JJ'), ('position', 'NN'), ('processor', 'NN'), ('performs', 'NNS'), ('interpolation', 'NN'), ('operation', 'NN'), ('extrapolation', 'NN'), ('operation', 'NN'), ('according', 'VBG'), ('first', 'JJ'), ('pitch', 'NN'), ('angle', 'NN'), ('second', 'JJ'), ('pitch', 'NN'), ('angle', 'NN'), ('third', 'JJ'), ('position', 'NN'), ('corresponding', 'VBG'), ('first', 'JJ'), ('pitch', 'NN'), ('angle', 'NN'), ('among', 'IN'), ('predetermined', 'JJ'), ('calibration', 'NN'), ('positions', 'NNS'), ('fourth', 'JJ'), ('position', 'NN'), ('corresponding', 'VBG'), ('second', 'JJ'), ('pitch', 'NN'), ('angle', 'NN'), ('among', 'IN'), ('predetermined', 'JJ'), ('calibration', 'NN'), ('positions', 'NNS'), ('head', 'VBP'), ('pitch', 'NN'), ('angle', 'NN'), ('thereby', 'RB'), ('obtaining', 'VBG'), ('second', 'JJ'), ('coordinate', 'NN'), ('value', 'NN'), ('gaze', 'JJ'), ('position', 'NN'), ('electronic', 'JJ'), ('device', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('processor', 'NN'), ('calculates', 'NNS'), ('plurality', 'NN'), ('first', 'RB'), ('viewing', 'VBG'), ('distances', 'NNS'), ('user', 'RB'), ('screen', 'VBP'), ('according', 'VBG'), ('first', 'RB'), ('facial', 'JJ'), ('landmarks', 'NNS'), ('processor', 'VBP'), ('estimates', 'NNS'), ('second', 'JJ'), ('viewing', 'VBG'), ('distance', 'NN'), ('user', 'NN'), ('screen', 'NN'), ('according', 'VBG'), ('second', 'JJ'), ('facial', 'JJ'), ('landmarks', 'NNS'), ('processor', 'VBP'), ('adjusts', 'NNS'), ('rotation', 'NN'), ('reference', 'NN'), ('angles', 'NNS'), ('gaze', 'VBP'), ('position', 'NN'), ('according', 'VBG'), ('second', 'JJ'), ('viewing', 'NN'), ('distance', 'NN'), ('first', 'RB'), ('viewing', 'VBG'), ('distances', 'NNS'), ('electronic', 'JJ'), ('device', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('processor', 'NN'), ('maps', 'NNS'), ('plurality', 'NN'), ('two-dimensional', 'JJ'), ('position', 'NN'), ('coordinates', 'NNS'), ('second', 'JJ'), ('facial', 'JJ'), ('landmarks', 'NNS'), ('plane', 'NN'), ('coordinate', 'NN'), ('system', 'NN'), ('plurality', 'NN'), ('three-dimensional', 'JJ'), ('position', 'NN'), ('coordinates', 'VBZ'), ('three-dimensional', 'JJ'), ('coordinate', 'NN'), ('system', 'NN'), ('processor', 'NN'), ('estimates', 'NNS'), ('head', 'VBP'), ('posture', 'NN'), ('angle', 'NN'), ('according', 'VBG'), ('three-dimensional', 'JJ'), ('position', 'NN'), ('coordinates', 'NNS'), ('second', 'JJ'), ('facial', 'JJ'), ('landmarks', 'NNS'), ('electronic', 'JJ'), ('device', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('second', 'JJ'), ('head', 'NN'), ('image', 'NN'), ('comprises', 'VBZ'), ('wearable', 'JJ'), ('device', 'NN'), ('second', 'JJ'), ('facial', 'JJ'), ('landmarks', 'NNS'), ('comprise', 'VBP'), ('plurality', 'NN'), ('third', 'JJ'), ('facial', 'JJ'), ('landmarks', 'NNS'), ('user', 'RB'), ('covered', 'VBD'), ('wearable', 'JJ'), ('device', 'NN'), ('electronic', 'JJ'), ('device', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('second', 'JJ'), ('head', 'NN'), ('image', 'NN'), ('comprises', 'VBZ'), ('wearable', 'JJ'), ('device', 'NN'), ('second', 'JJ'), ('facial', 'JJ'), ('landmarks', 'NNS'), ('comprise', 'VBP'), ('one', 'CD'), ('simulated', 'VBN'), ('landmarks', 'NN'), ('marked', 'VBD'), ('wearable', 'JJ'), ('device', 'NN'), ('operating', 'VBG'), ('method', 'NN'), ('adapted', 'VBD'), ('electronic', 'JJ'), ('device', 'NN'), ('comprising', 'VBG'), ('image', 'NN'), ('capturing', 'VBG'), ('device', 'NN'), ('making', 'VBG'), ('screen', 'JJ'), ('display', 'NN'), ('plurality', 'NN'), ('image', 'NN'), ('frames', 'NNS'), ('method', 'VBP'), ('comprising', 'VBG'), ('configuring', 'VBG'), ('screen', 'JJ'), ('display', 'NN'), ('plurality', 'NN'), ('marker', 'NN'), ('objects', 'VBZ'), ('plurality', 'NN'), ('predetermined', 'VBN'), ('calibration', 'NN'), ('positions', 'NNS'), ('configuring', 'VBG'), ('image', 'NN'), ('capturing', 'VBG'), ('device', 'JJ'), ('capture', 'NN'), ('plurality', 'NN'), ('first', 'RB'), ('head', 'JJ'), ('images', 'NNS'), ('user', 'VBP'), ('looking', 'VBG'), ('predetermined', 'VBN'), ('calibration', 'NN'), ('positions', 'NNS'), ('performing', 'VBG'), ('plurality', 'NN'), ('first', 'RB'), ('face', 'NN'), ('recognition', 'NN'), ('operations', 'NNS'), ('first', 'RB'), ('head', 'VBP'), ('images', 'NNS'), ('obtain', 'VB'), ('plurality', 'NN'), ('first', 'RB'), ('face', 'NN'), ('regions', 'NNS'), ('corresponding', 'VBG'), ('predetermined', 'JJ'), ('calibration', 'NN'), ('positions', 'NNS'), ('detecting', 'VBG'), ('plurality', 'NN'), ('first', 'RB'), ('facial', 'JJ'), ('landmarks', 'NNS'), ('corresponding', 'VBG'), ('first', 'JJ'), ('face', 'NN'), ('regions', 'NNS'), ('calculating', 'VBG'), ('plurality', 'NN'), ('rotation', 'NN'), ('reference', 'NN'), ('angles', 'NNS'), ('user', 'RBR'), ('looking', 'VBG'), ('predetermined', 'JJ'), ('calibration', 'NN'), ('positions', 'NNS'), ('according', 'VBG'), ('first', 'JJ'), ('facial', 'JJ'), ('landmarks', 'NNS'), ('configuring', 'VBG'), ('image', 'NN'), ('capturing', 'VBG'), ('device', 'JJ'), ('capture', 'NN'), ('second', 'JJ'), ('head', 'NN'), ('image', 'NN'), ('user', 'JJ'), ('performing', 'VBG'), ('second', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('operation', 'NN'), ('second', 'JJ'), ('head', 'NN'), ('image', 'NN'), ('obtain', 'VB'), ('second', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('detecting', 'VBG'), ('plurality', 'NN'), ('second', 'JJ'), ('facial', 'JJ'), ('landmarks', 'NNS'), ('within', 'IN'), ('second', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('estimating', 'VBG'), ('head', 'NN'), ('posture', 'NN'), ('angle', 'VBZ'), ('user', 'RP'), ('according', 'VBG'), ('second', 'JJ'), ('facial', 'JJ'), ('landmarks', 'NNS'), ('calculating', 'VBG'), ('gaze', 'JJ'), ('position', 'NN'), ('user', 'NN'), ('screen', 'NN'), ('according', 'VBG'), ('head', 'NN'), ('posture', 'NN'), ('angle', 'JJ'), ('rotation', 'NN'), ('reference', 'NN'), ('angles', 'NNS'), ('predetermined', 'VBN'), ('calibration', 'NN'), ('positions', 'NNS'), ('configuring', 'VBG'), ('screen', 'NN'), ('display', 'NN'), ('corresponding', 'VBG'), ('visual', 'JJ'), ('effect', 'NN'), ('according', 'VBG'), ('gaze', 'JJ'), ('position', 'NN'), ('operation', 'NN'), ('method', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('gaze', 'JJ'), ('position', 'NN'), ('comprises', 'NNS'), ('first', 'JJ'), ('coordinate', 'NN'), ('value', 'NN'), ('first', 'RB'), ('axial', 'JJ'), ('direction', 'NN'), ('second', 'JJ'), ('coordinate', 'NN'), ('value', 'NN'), ('second', 'JJ'), ('axial', 'JJ'), ('direction', 'NN'), ('operation', 'NN'), ('method', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('head', 'NN'), ('posture', 'NN'), ('angles', 'VBZ'), ('comprise', 'RB'), ('head', 'JJ'), ('pitch', 'NN'), ('angle', 'NN'), ('head', 'NN'), ('yaw', 'NN'), ('angle', 'JJ'), ('rotation', 'NN'), ('reference', 'NN'), ('angles', 'NNS'), ('comprise', 'VBP'), ('first', 'JJ'), ('pitch', 'NN'), ('angle', 'NN'), ('second', 'JJ'), ('pitch', 'NN'), ('angle', 'NN'), ('first', 'RB'), ('yaw', 'RB'), ('angle', 'JJ'), ('second', 'JJ'), ('yaw', 'NN'), ('angle', 'NN'), ('corresponding', 'VBG'), ('predetermined', 'JJ'), ('calibration', 'NN'), ('positions', 'NNS'), ('operation', 'NN'), ('method', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'JJ'), ('step', 'NN'), ('calculating', 'VBG'), ('gaze', 'JJ'), ('position', 'NN'), ('user', 'NN'), ('screen', 'NN'), ('according', 'VBG'), ('head', 'NN'), ('posture', 'NN'), ('angle', 'JJ'), ('rotation', 'NN'), ('reference', 'NN'), ('angles', 'NNS'), ('predetermined', 'VBN'), ('calibration', 'NN'), ('positions', 'NNS'), ('comprises', 'VBZ'), ('performing', 'VBG'), ('interpolation', 'NN'), ('operation', 'NN'), ('extrapolation', 'NN'), ('operation', 'NN'), ('according', 'VBG'), ('first', 'JJ'), ('yaw', 'NN'), ('angle', 'JJ'), ('second', 'JJ'), ('yaw', 'NN'), ('angle', 'NN'), ('first', 'JJ'), ('position', 'NN'), ('corresponding', 'VBG'), ('first', 'JJ'), ('yaw', 'JJ'), ('angle', 'NN'), ('among', 'IN'), ('predetermined', 'JJ'), ('calibration', 'NN'), ('positions', 'NNS'), ('second', 'JJ'), ('position', 'NN'), ('corresponding', 'VBG'), ('second', 'JJ'), ('yaw', 'JJ'), ('angle', 'NN'), ('among', 'IN'), ('predetermined', 'JJ'), ('calibration', 'NN'), ('positions', 'NNS'), ('head', 'VBP'), ('yaw', 'RB'), ('angle', 'JJ'), ('thereby', 'RB'), ('obtaining', 'VBG'), ('first', 'JJ'), ('coordinate', 'NN'), ('value', 'NN'), ('gaze', 'JJ'), ('position', 'NN'), ('performing', 'VBG'), ('interpolation', 'NN'), ('operation', 'NN'), ('extrapolation', 'NN'), ('operation', 'NN'), ('according', 'VBG'), ('first', 'JJ'), ('pitch', 'NN'), ('angle', 'NN'), ('second', 'JJ'), ('pitch', 'NN'), ('angle', 'NN'), ('third', 'JJ'), ('position', 'NN'), ('corresponding', 'VBG'), ('first', 'JJ'), ('pitch', 'NN'), ('angle', 'NN'), ('among', 'IN'), ('predetermined', 'JJ'), ('calibration', 'NN'), ('positions', 'NNS'), ('fourth', 'JJ'), ('position', 'NN'), ('corresponding', 'VBG'), ('second', 'JJ'), ('pitch', 'NN'), ('angle', 'NN'), ('among', 'IN'), ('predetermined', 'JJ'), ('calibration', 'NN'), ('positions', 'NNS'), ('head', 'VBP'), ('pitch', 'NN'), ('angle', 'NN'), ('thereby', 'RB'), ('obtaining', 'VBG'), ('second', 'JJ'), ('coordinate', 'NN'), ('value', 'NN'), ('gaze', 'JJ'), ('position', 'NN'), ('operation', 'NN'), ('method', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('method', 'NN'), ('comprises', 'VBZ'), ('calculating', 'VBG'), ('plurality', 'NN'), ('first', 'RB'), ('viewing', 'VBG'), ('distances', 'NNS'), ('user', 'RB'), ('screen', 'VBP'), ('according', 'VBG'), ('first', 'RB'), ('facial', 'JJ'), ('landmarks', 'NNS'), ('estimating', 'VBG'), ('second', 'JJ'), ('viewing', 'VBG'), ('distance', 'NN'), ('user', 'NN'), ('screen', 'NN'), ('according', 'VBG'), ('second', 'JJ'), ('facial', 'JJ'), ('landmarks', 'NNS'), ('adjusting', 'VBG'), ('rotation', 'NN'), ('reference', 'NN'), ('angles', 'NNS'), ('gaze', 'VBP'), ('position', 'NN'), ('according', 'VBG'), ('second', 'JJ'), ('viewing', 'NN'), ('distance', 'NN'), ('first', 'RB'), ('viewing', 'VBG'), ('distances', 'NNS'), ('operation', 'NN'), ('method', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('method', 'NN'), ('comprises', 'VBZ'), ('mapping', 'VBG'), ('plurality', 'NN'), ('two-dimensional', 'JJ'), ('position', 'NN'), ('coordinates', 'NNS'), ('second', 'JJ'), ('facial', 'JJ'), ('landmarks', 'NNS'), ('plane', 'NN'), ('coordinate', 'NN'), ('system', 'NN'), ('plurality', 'NN'), ('three-dimensional', 'JJ'), ('position', 'NN'), ('coordinates', 'VBZ'), ('three-dimensional', 'JJ'), ('coordinate', 'NN'), ('system', 'NN'), ('estimating', 'VBG'), ('head', 'NN'), ('posture', 'NN'), ('angle', 'IN'), ('according', 'VBG'), ('three-dimensional', 'JJ'), ('position', 'NN'), ('coordinates', 'NNS'), ('second', 'JJ'), ('facial', 'JJ'), ('landmarks', 'NNS'), ('operation', 'NN'), ('method', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('second', 'JJ'), ('head', 'NN'), ('image', 'NN'), ('comprises', 'VBZ'), ('wearable', 'JJ'), ('device', 'NN'), ('second', 'JJ'), ('facial', 'JJ'), ('landmarks', 'NNS'), ('comprise', 'VBP'), ('plurality', 'NN'), ('third', 'JJ'), ('facial', 'JJ'), ('landmarks', 'NNS'), ('user', 'RB'), ('covered', 'VBD'), ('wearable', 'JJ'), ('device', 'NN'), ('operation', 'NN'), ('method', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('second', 'JJ'), ('head', 'NN'), ('image', 'NN'), ('comprises', 'VBZ'), ('wearable', 'JJ'), ('device', 'NN'), ('second', 'JJ'), ('facial', 'JJ'), ('landmarks', 'NNS'), ('comprise', 'VBP'), ('one', 'CD'), ('simulated', 'VBN'), ('landmarks', 'NN'), ('marked', 'VBD'), ('wearable', 'JJ'), ('device', 'NN'), ('computation', 'NN'), ('method', 'NN'), ('applied', 'VBD'), ('computing', 'VBG'), ('system', 'NN'), ('wherein', 'VBD'), ('computing', 'VBG'), ('system', 'NN'), ('comprises', 'VBZ'), ('control', 'VB'), ('unit', 'NN'), ('computation', 'NN'), ('group', 'NN'), ('general', 'JJ'), ('storage', 'NN'), ('unit', 'NN'), ('wherein', 'VBZ'), ('control', 'JJ'), ('unit', 'NN'), ('comprises', 'VBZ'), ('first', 'JJ'), ('memory', 'NN'), ('decoding', 'VBG'), ('logic', 'JJ'), ('controller', 'NN'), ('wherein', 'NN'), ('computation', 'NN'), ('group', 'NN'), ('comprises', 'VBZ'), ('group', 'NN'), ('controller', 'NN'), ('plurality', 'NN'), ('computing', 'VBG'), ('units', 'NNS'), ('general', 'JJ'), ('storage', 'NN'), ('unit', 'NN'), ('configured', 'VBD'), ('store', 'NN'), ('data', 'NNS'), ('computation', 'NN'), ('method', 'NN'), ('comprises', 'VBZ'), ('receiving', 'VBG'), ('controller', 'NN'), ('first', 'RB'), ('level', 'JJ'), ('instruction', 'NN'), ('sequence', 'NN'), ('partitioning', 'VBG'), ('decoding', 'VBG'), ('logic', 'JJ'), ('first', 'JJ'), ('level', 'NN'), ('instruction', 'NN'), ('sequence', 'NN'), ('plurality', 'NN'), ('second', 'JJ'), ('level', 'NN'), ('instruction', 'NN'), ('sequences', 'NNS'), ('creating', 'VBG'), ('controller', 'NN'), ('threads', 'NNS'), ('plurality', 'JJ'), ('second', 'JJ'), ('level', 'NN'), ('instruction', 'NN'), ('sequences', 'NNS'), ('allocating', 'VBG'), ('controller', 'NN'), ('independent', 'JJ'), ('register', 'NN'), ('well', 'RB'), ('configuring', 'VBG'), ('independent', 'JJ'), ('addressing', 'VBG'), ('function', 'NN'), ('thread', 'NN'), ('threads', 'NNS'), ('wherein', 'VBP'), ('integer', 'JJ'), ('greater', 'JJR'), ('equal', 'JJ'), ('obtaining', 'VBG'), ('group', 'NN'), ('controller', 'NN'), ('plurality', 'NN'), ('computation', 'NN'), ('types', 'NNS'), ('plurality', 'JJ'), ('second', 'JJ'), ('level', 'NN'), ('instruction', 'NN'), ('sequences', 'NNS'), ('obtaining', 'VBG'), ('corresponding', 'VBG'), ('fusion', 'NN'), ('computation', 'NN'), ('manner', 'NN'), ('computation', 'NN'), ('types', 'NNS'), ('according', 'VBG'), ('plurality', 'NN'), ('computation', 'NN'), ('types', 'NNS'), ('adopting', 'VBG'), ('plurality', 'NN'), ('computing', 'VBG'), ('units', 'NNS'), ('fusion', 'NN'), ('computation', 'NN'), ('manner', 'NN'), ('call', 'NN'), ('threads', 'NNS'), ('performing', 'VBG'), ('computations', 'NNS'), ('plurality', 'NN'), ('second', 'JJ'), ('level', 'NN'), ('instruction', 'NN'), ('sequences', 'NNS'), ('obtain', 'VB'), ('final', 'JJ'), ('result', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('obtaining', 'VBG'), ('group', 'NN'), ('controller', 'NN'), ('plurality', 'NN'), ('computation', 'NN'), ('types', 'NNS'), ('plurality', 'JJ'), ('second', 'JJ'), ('level', 'NN'), ('instruction', 'NN'), ('sequences', 'NNS'), ('obtaining', 'VBG'), ('corresponding', 'VBG'), ('fusion', 'NN'), ('computation', 'NN'), ('manner', 'NN'), ('computation', 'NN'), ('types', 'NNS'), ('according', 'VBG'), ('plurality', 'NN'), ('computation', 'NN'), ('types', 'NNS'), ('adopting', 'VBG'), ('plurality', 'NN'), ('computing', 'VBG'), ('units', 'NNS'), ('fusion', 'NN'), ('computation', 'NN'), ('manner', 'NN'), ('call', 'NN'), ('threads', 'NNS'), ('performing', 'VBG'), ('computations', 'NNS'), ('plurality', 'NN'), ('second', 'JJ'), ('instruction', 'NN'), ('sequences', 'NNS'), ('obtain', 'VB'), ('final', 'JJ'), ('result', 'NN'), ('computation', 'NN'), ('types', 'NNS'), ('represent', 'JJ'), ('computation', 'NN'), ('operations', 'NNS'), ('type', 'VBP'), ('group', 'NN'), ('controller', 'NN'), ('calls', 'VBZ'), ('combined', 'VBN'), ('computation', 'NN'), ('manner', 'NN'), ('single', 'JJ'), ('instruction', 'NN'), ('multiple', 'NN'), ('data', 'NNS'), ('type', 'NN'), ('combination', 'NN'), ('single', 'JJ'), ('instruction', 'NN'), ('multiple', 'JJ'), ('threads', 'NNS'), ('uses', 'VBZ'), ('threads', 'NNS'), ('perform', 'NN'), ('combined', 'VBN'), ('computation', 'NN'), ('manner', 'NN'), ('obtain', 'VB'), ('final', 'JJ'), ('result', 'NN'), ('includes', 'VBZ'), ('partitioning', 'VBG'), ('decoding', 'VBG'), ('logic', 'JJ'), ('threads', 'NNS'), ('n', 'RB'), ('wraps', 'VBP'), ('allocating', 'VBG'), ('plurality', 'NN'), ('computing', 'VBG'), ('units', 'NNS'), ('converting', 'VBG'), ('group', 'NN'), ('controller', 'NN'), ('plurality', 'NN'), ('second', 'JJ'), ('instruction', 'NN'), ('sequences', 'NNS'), ('plurality', 'JJ'), ('second', 'JJ'), ('control', 'NN'), ('signals', 'NNS'), ('sending', 'VBG'), ('second', 'JJ'), ('control', 'NN'), ('signals', 'NNS'), ('plurality', 'NN'), ('computing', 'VBG'), ('units', 'NNS'), ('calling', 'VBG'), ('plurality', 'NN'), ('computing', 'VBG'), ('units', 'NNS'), ('wraps', 'NNS'), ('allocated', 'VBD'), ('computing', 'VBG'), ('units', 'NNS'), ('second', 'JJ'), ('control', 'NN'), ('signals', 'NNS'), ('fetch', 'VBP'), ('corresponding', 'VBG'), ('data', 'NNS'), ('according', 'VBG'), ('independent', 'JJ'), ('addressing', 'VBG'), ('function', 'NN'), ('performing', 'VBG'), ('plurality', 'NN'), ('computing', 'VBG'), ('units', 'NNS'), ('computations', 'NNS'), ('data', 'NNS'), ('obtain', 'VB'), ('plurality', 'NN'), ('intermediate', 'JJ'), ('results', 'NNS'), ('splicing', 'VBG'), ('plurality', 'NN'), ('intermediate', 'JJ'), ('results', 'NNS'), ('obtain', 'VB'), ('final', 'JJ'), ('result', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('obtaining', 'VBG'), ('group', 'NN'), ('controller', 'NN'), ('plurality', 'NN'), ('computation', 'NN'), ('types', 'NNS'), ('plurality', 'JJ'), ('second', 'JJ'), ('level', 'NN'), ('instruction', 'NN'), ('sequences', 'NNS'), ('obtaining', 'VBG'), ('corresponding', 'VBG'), ('fusion', 'NN'), ('computation', 'NN'), ('manner', 'NN'), ('computation', 'NN'), ('types', 'NNS'), ('according', 'VBG'), ('plurality', 'NN'), ('computation', 'NN'), ('types', 'NNS'), ('adopting', 'VBG'), ('plurality', 'NN'), ('computing', 'VBG'), ('units', 'NNS'), ('fusion', 'NN'), ('computation', 'NN'), ('manner', 'NN'), ('call', 'NN'), ('threads', 'NNS'), ('performing', 'VBG'), ('computations', 'NNS'), ('plurality', 'NN'), ('second', 'JJ'), ('instruction', 'NN'), ('sequences', 'NNS'), ('obtain', 'VB'), ('final', 'JJ'), ('result', 'NN'), ('computation', 'NN'), ('types', 'NNS'), ('represent', 'JJ'), ('computation', 'NN'), ('operations', 'NNS'), ('different', 'JJ'), ('types', 'NNS'), ('group', 'NN'), ('controller', 'NN'), ('calls', 'VBZ'), ('simultaneous', 'JJ'), ('multi-threading', 'JJ'), ('threads', 'NNS'), ('perform', 'VB'), ('computations', 'NNS'), ('obtain', 'VB'), ('final', 'JJ'), ('result', 'NN'), ('includes', 'VBZ'), ('partitioning', 'VBG'), ('decoding', 'VBG'), ('logic', 'JJ'), ('threads', 'NNS'), ('n', 'RB'), ('wraps', 'VBP'), ('converting', 'VBG'), ('plurality', 'NN'), ('second', 'JJ'), ('instruction', 'NN'), ('sequences', 'NNS'), ('plurality', 'JJ'), ('second', 'JJ'), ('control', 'NN'), ('signals', 'NNS'), ('obtaining', 'VBG'), ('group', 'NN'), ('controller', 'NN'), ('computation', 'NN'), ('types', 'NNS'), ('supported', 'VBD'), ('plurality', 'NN'), ('computing', 'VBG'), ('units', 'NNS'), ('allocating', 'VBG'), ('controller', 'NN'), ('n', 'NN'), ('wraps', 'NNS'), ('plurality', 'JJ'), ('second', 'JJ'), ('control', 'NN'), ('signals', 'NNS'), ('corresponding', 'VBG'), ('computing', 'VBG'), ('units', 'NNS'), ('support', 'NN'), ('computation', 'NN'), ('types', 'NNS'), ('wraps', 'VBP'), ('second', 'JJ'), ('control', 'NN'), ('signals', 'NNS'), ('calling', 'VBG'), ('plurality', 'NN'), ('computing', 'VBG'), ('units', 'NNS'), ('wraps', 'NNS'), ('allocated', 'VBD'), ('computing', 'VBG'), ('units', 'NNS'), ('second', 'JJ'), ('control', 'NN'), ('signals', 'NNS'), ('fetching', 'VBG'), ('plurality', 'NN'), ('computing', 'VBG'), ('units', 'NNS'), ('corresponding', 'VBG'), ('data', 'NNS'), ('performing', 'VBG'), ('plurality', 'NN'), ('computing', 'VBG'), ('units', 'NNS'), ('computations', 'NNS'), ('data', 'NNS'), ('obtain', 'VB'), ('plurality', 'NN'), ('intermediate', 'JJ'), ('results', 'NNS'), ('splicing', 'VBG'), ('intermediate', 'JJ'), ('results', 'NNS'), ('obtain', 'VB'), ('final', 'JJ'), ('result', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('wrap', 'NN'), ('plurality', 'NN'), ('wraps', 'NNS'), ('blocked', 'VBD'), ('adding', 'VBG'), ('wrap', 'NN'), ('waiting', 'VBG'), ('queue', 'NN'), ('data', 'NNS'), ('wrap', 'NN'), ('already', 'RB'), ('fetched', 'VBD'), ('adding', 'VBG'), ('wrap', 'NN'), ('preparation', 'NN'), ('queue', 'NN'), ('wherein', 'WRB'), ('preparation', 'NN'), ('queue', 'NN'), ('queue', 'NN'), ('wrap', 'NN'), ('scheduled', 'VBN'), ('executing', 'VBG'), ('located', 'VBN'), ('computing', 'VBG'), ('resource', 'NN'), ('idle', 'JJ'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'VBP'), ('first', 'JJ'), ('level', 'NN'), ('instruction', 'NN'), ('sequence', 'NN'), ('includes', 'VBZ'), ('long', 'JJ'), ('instruction', 'NN'), ('second', 'JJ'), ('level', 'NN'), ('instruction', 'NN'), ('sequence', 'NN'), ('includes', 'VBZ'), ('instruction', 'NN'), ('sequence', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('computing', 'VBG'), ('system', 'NN'), ('includes', 'VBZ'), ('tree', 'JJ'), ('module', 'NN'), ('wherein', 'VBD'), ('tree', 'JJ'), ('module', 'NN'), ('includes', 'VBZ'), ('root', 'JJ'), ('port', 'NN'), ('plurality', 'NN'), ('branch', 'NN'), ('ports', 'NNS'), ('wherein', 'VBP'), ('root', 'JJ'), ('port', 'NN'), ('tree', 'NN'), ('module', 'NN'), ('connected', 'VBN'), ('group', 'NN'), ('controller', 'NN'), ('plurality', 'NN'), ('branch', 'NN'), ('ports', 'NNS'), ('tree', 'VBP'), ('module', 'NN'), ('connected', 'VBN'), ('computing', 'VBG'), ('unit', 'NN'), ('plurality', 'NN'), ('computing', 'VBG'), ('units', 'NNS'), ('respectively', 'RB'), ('tree', 'VBP'), ('module', 'NN'), ('configured', 'VBN'), ('forward', 'RB'), ('data', 'NN'), ('blocks', 'NNS'), ('wraps', 'VBP'), ('instruction', 'NN'), ('sequences', 'NNS'), ('group', 'NN'), ('controller', 'NN'), ('plurality', 'NN'), ('computing', 'VBG'), ('units', 'NNS'), ('method', 'FW'), ('claim', 'NN'), ('wherein', 'VBP'), ('tree', 'JJ'), ('module', 'NN'), ('n-ary', 'JJ'), ('tree', 'NN'), ('wherein', 'NN'), ('n', 'RB'), ('integer', 'RB'), ('greater', 'JJR'), ('equal', 'JJ'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('computing', 'VBG'), ('system', 'NN'), ('includes', 'VBZ'), ('branch', 'NN'), ('processing', 'VBG'), ('circuit', 'NN'), ('wherein', 'NN'), ('branch', 'NN'), ('processing', 'VBG'), ('circuit', 'NN'), ('connected', 'VBN'), ('group', 'NN'), ('controller', 'NN'), ('plurality', 'NN'), ('computing', 'VBG'), ('units', 'NNS'), ('branch', 'NN'), ('processing', 'VBG'), ('circuit', 'NN'), ('configured', 'VBD'), ('forward', 'RB'), ('data', 'NNS'), ('wraps', 'NNS'), ('instruction', 'NN'), ('sequences', 'NNS'), ('group', 'NN'), ('controller', 'NN'), ('plurality', 'NN'), ('computing', 'VBG'), ('units', 'NNS'), ('computing', 'VBG'), ('system', 'NN'), ('comprising', 'VBG'), ('control', 'NN'), ('unit', 'NN'), ('computation', 'NN'), ('group', 'NN'), ('general', 'JJ'), ('storage', 'NN'), ('unit', 'NN'), ('wherein', 'VBZ'), ('control', 'JJ'), ('unit', 'NN'), ('includes', 'VBZ'), ('first', 'JJ'), ('memory', 'NN'), ('decoding', 'VBG'), ('logic', 'JJ'), ('controller', 'NN'), ('computation', 'NN'), ('group', 'NN'), ('includes', 'VBZ'), ('group', 'NN'), ('controller', 'NN'), ('plurality', 'NN'), ('computing', 'VBG'), ('units', 'NNS'), ('general', 'JJ'), ('storage', 'NN'), ('unit', 'NN'), ('configured', 'VBD'), ('store', 'NN'), ('data', 'NNS'), ('controller', 'NN'), ('configured', 'VBD'), ('receive', 'JJ'), ('first', 'JJ'), ('level', 'NN'), ('instruction', 'NN'), ('sequence', 'NN'), ('control', 'NN'), ('first', 'JJ'), ('memory', 'NN'), ('decoding', 'VBG'), ('logic', 'JJ'), ('decoding', 'VBG'), ('logic', 'NN'), ('configured', 'VBD'), ('partition', 'NN'), ('first', 'RB'), ('level', 'JJ'), ('instruction', 'NN'), ('sequence', 'NN'), ('plurality', 'NN'), ('second', 'JJ'), ('level', 'NN'), ('instruction', 'NN'), ('sequences', 'NNS'), ('controller', 'VBP'), ('configured', 'JJ'), ('create', 'NN'), ('threads', 'NNS'), ('plurality', 'JJ'), ('second', 'JJ'), ('level', 'NN'), ('instruction', 'NN'), ('sequences', 'NNS'), ('allocate', 'VBP'), ('independent', 'JJ'), ('register', 'NN'), ('configure', 'NN'), ('independent', 'JJ'), ('addressing', 'VBG'), ('function', 'NN'), ('thread', 'NN'), ('threads', 'NNS'), ('integer', 'VBP'), ('greater', 'JJR'), ('equal', 'JJ'), ('controller', 'NN'), ('configured', 'VBD'), ('convert', 'JJ'), ('plurality', 'NN'), ('second', 'JJ'), ('instruction', 'NN'), ('sequences', 'NNS'), ('plurality', 'NN'), ('control', 'NN'), ('signals', 'NNS'), ('sending', 'VBG'), ('group', 'NN'), ('controller', 'NN'), ('group', 'NN'), ('controller', 'NN'), ('configured', 'VBD'), ('receive', 'JJ'), ('plurality', 'NN'), ('control', 'NN'), ('signals', 'NNS'), ('obtain', 'VB'), ('plurality', 'JJ'), ('computational', 'JJ'), ('types', 'NNS'), ('plurality', 'NN'), ('control', 'NN'), ('signals', 'NNS'), ('divide', 'VBP'), ('threads', 'NNS'), ('n', 'RB'), ('wraps', 'VBP'), ('allocate', 'JJ'), ('n', 'NN'), ('wraps', 'NNS'), ('plurality', 'NN'), ('control', 'NN'), ('signals', 'NNS'), ('plurality', 'NN'), ('computing', 'VBG'), ('units', 'NNS'), ('according', 'VBG'), ('plurality', 'NN'), ('computational', 'JJ'), ('types', 'NNS'), ('plurality', 'NN'), ('computing', 'VBG'), ('units', 'NNS'), ('configured', 'VBN'), ('fetch', 'RB'), ('data', 'NNS'), ('general', 'JJ'), ('storage', 'NN'), ('unit', 'NN'), ('allocated', 'VBD'), ('wraps', 'NNS'), ('control', 'NN'), ('signals', 'NNS'), ('perform', 'VBP'), ('computations', 'NNS'), ('obtain', 'VB'), ('intermediate', 'JJ'), ('result', 'NN'), ('group', 'NN'), ('controller', 'NN'), ('configured', 'VBD'), ('splice', 'JJ'), ('intermediate', 'JJ'), ('results', 'NNS'), ('obtain', 'VB'), ('final', 'JJ'), ('computation', 'NN'), ('result', 'NN'), ('computing', 'VBG'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'VBP'), ('plurality', 'NN'), ('computing', 'VBG'), ('units', 'NNS'), ('includes', 'VBZ'), ('addition', 'NN'), ('computing', 'VBG'), ('unit', 'NN'), ('multiplication', 'NN'), ('computing', 'VBG'), ('unit', 'NN'), ('activation', 'NN'), ('computing', 'VBG'), ('unit', 'NN'), ('dedicated', 'VBN'), ('computing', 'VBG'), ('unit', 'NN'), ('computing', 'VBG'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'RB'), ('dedicated', 'VBD'), ('computing', 'VBG'), ('unit', 'NN'), ('includes', 'VBZ'), ('face', 'NN'), ('recognition', 'NN'), ('computing', 'VBG'), ('unit', 'NN'), ('graphics', 'NNS'), ('computing', 'VBG'), ('unit', 'NN'), ('fingerprint', 'NN'), ('computing', 'VBG'), ('unit', 'NN'), ('neural', 'JJ'), ('network', 'NN'), ('computing', 'VBG'), ('unit', 'NN'), ('computing', 'VBG'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('group', 'NN'), ('controller', 'NN'), ('configured', 'VBD'), ('computation', 'NN'), ('types', 'NNS'), ('plurality', 'NN'), ('control', 'NN'), ('signals', 'NNS'), ('graphics', 'NNS'), ('computations', 'NNS'), ('fingerprint', 'VBP'), ('identification', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('neural', 'JJ'), ('network', 'NN'), ('operations', 'NNS'), ('allocate', 'VBP'), ('plurality', 'NN'), ('control', 'NN'), ('signals', 'NNS'), ('face', 'VBP'), ('recognition', 'NN'), ('computing', 'VBG'), ('unit', 'NN'), ('graphics', 'NNS'), ('computing', 'VBG'), ('unit', 'NN'), ('fingerprint', 'NN'), ('computing', 'VBG'), ('unit', 'NN'), ('neural', 'JJ'), ('network', 'NN'), ('computing', 'VBG'), ('unit', 'NN'), ('respectively', 'RB'), ('computing', 'VBG'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'VBP'), ('first', 'JJ'), ('level', 'NN'), ('instruction', 'NN'), ('sequence', 'NN'), ('includes', 'VBZ'), ('long', 'JJ'), ('instruction', 'NN'), ('second', 'JJ'), ('level', 'NN'), ('instruction', 'NN'), ('sequence', 'NN'), ('includes', 'VBZ'), ('instruction', 'NN'), ('sequence', 'NN'), ('computing', 'VBG'), ('system', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('tree', 'JJ'), ('module', 'NN'), ('wherein', 'VBD'), ('tree', 'JJ'), ('module', 'NN'), ('includes', 'VBZ'), ('root', 'JJ'), ('port', 'NN'), ('plurality', 'NN'), ('branch', 'NN'), ('ports', 'NNS'), ('wherein', 'VBP'), ('root', 'JJ'), ('port', 'NN'), ('tree', 'NN'), ('module', 'NN'), ('connected', 'VBN'), ('group', 'NN'), ('controller', 'NN'), ('plurality', 'NN'), ('branch', 'NN'), ('ports', 'NNS'), ('tree', 'VBP'), ('module', 'NN'), ('connected', 'VBN'), ('computing', 'VBG'), ('unit', 'NN'), ('plurality', 'NN'), ('computing', 'VBG'), ('units', 'NNS'), ('respectively', 'RB'), ('tree', 'VBP'), ('module', 'NN'), ('configured', 'VBN'), ('forward', 'RB'), ('data', 'NN'), ('blocks', 'NNS'), ('wraps', 'VBP'), ('instruction', 'NN'), ('sequences', 'NNS'), ('group', 'NN'), ('controller', 'NN'), ('plurality', 'NN'), ('computing', 'VBG'), ('units', 'NNS'), ('computing', 'VBG'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'VBP'), ('tree', 'JJ'), ('module', 'NN'), ('n-ary', 'JJ'), ('tree', 'NN'), ('wherein', 'NN'), ('n', 'RB'), ('integer', 'RB'), ('greater', 'JJR'), ('equal', 'JJ'), ('computing', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('computing', 'VBG'), ('system', 'NN'), ('includes', 'VBZ'), ('branch', 'NN'), ('processing', 'NN'), ('circuit', 'NN'), ('branch', 'NN'), ('processing', 'VBG'), ('circuit', 'NN'), ('connected', 'VBN'), ('group', 'NN'), ('controller', 'NN'), ('plurality', 'NN'), ('computing', 'VBG'), ('units', 'NNS'), ('branch', 'NN'), ('processing', 'VBG'), ('circuit', 'NN'), ('configured', 'VBD'), ('forward', 'RB'), ('data', 'NNS'), ('wraps', 'NNS'), ('instruction', 'NN'), ('sequences', 'NNS'), ('group', 'NN'), ('controller', 'NN'), ('plurality', 'NN'), ('computing', 'VBG'), ('units', 'NNS'), ('computer', 'NN'), ('program', 'NN'), ('product', 'NN'), ('comprising', 'VBG'), ('non-instant', 'JJ'), ('computer', 'NN'), ('readable', 'JJ'), ('storage', 'NN'), ('medium', 'NN'), ('wherein', 'VBP'), ('computer', 'NN'), ('program', 'NN'), ('stored', 'VBD'), ('non-instant', 'JJ'), ('computer', 'NN'), ('readable', 'JJ'), ('storage', 'NN'), ('medium', 'NN'), ('computer', 'NN'), ('program', 'NN'), ('capable', 'JJ'), ('causing', 'VBG'), ('computer', 'NN'), ('perform', 'NN'), ('method', 'NN'), ('claims', 'VBZ'), ('operations', 'NNS'), ('method', 'VBP'), ('detecting', 'VBG'), ('body', 'NN'), ('information', 'NN'), ('one', 'CD'), ('passengers', 'NN'), ('vehicle', 'NN'), ('based', 'VBN'), ('humans', 'NNS'), (\"'\", 'POS'), ('status', 'NN'), ('recognition', 'NN'), ('comprising', 'VBG'), ('steps', 'NNS'), ('least', 'JJS'), ('one', 'CD'), ('interior', 'JJ'), ('image', 'NN'), ('interior', 'JJ'), ('vehicle', 'NN'), ('acquired', 'VBD'), ('passenger', 'JJR'), ('body', 'NN'), ('information-detecting', 'JJ'), ('device', 'NN'), ('performing', 'VBG'), ('process', 'NN'), ('inputting', 'VBG'), ('interior', 'JJ'), ('image', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('network', 'NN'), ('thereby', 'RB'), ('allow', 'VB'), ('face', 'NN'), ('recognition', 'NN'), ('network', 'NN'), ('detect', 'JJ'), ('faces', 'VBZ'), ('passengers', 'NNS'), ('interior', 'JJ'), ('image', 'NN'), ('thus', 'RB'), ('output', 'NN'), ('multiple', 'JJ'), ('pieces', 'NNS'), ('passenger', 'NN'), ('feature', 'NN'), ('information', 'NN'), ('corresponding', 'VBG'), ('detected', 'VBD'), ('faces', 'VBZ'), ('ii', 'JJ'), ('process', 'NN'), ('inputting', 'VBG'), ('interior', 'JJ'), ('image', 'NN'), ('body', 'NN'), ('recognition', 'NN'), ('network', 'NN'), ('thereby', 'RB'), ('allow', 'VB'), ('body', 'NN'), ('recognition', 'NN'), ('network', 'NN'), ('detect', 'JJ'), ('bodies', 'NNS'), ('passengers', 'NNS'), ('interior', 'JJ'), ('image', 'NN'), ('thus', 'RB'), ('output', 'NN'), ('body-part', 'JJ'), ('length', 'NN'), ('information', 'NN'), ('detected', 'VBD'), ('bodies', 'NNS'), ('b', 'IN'), ('passenger', 'NN'), ('body', 'NN'), ('information-detecting', 'JJ'), ('device', 'NN'), ('performing', 'VBG'), ('process', 'NN'), ('retrieving', 'VBG'), ('specific', 'JJ'), ('height', 'JJ'), ('mapping', 'NN'), ('information', 'NN'), ('corresponding', 'VBG'), ('specific', 'JJ'), ('passenger', 'NN'), ('feature', 'NN'), ('information', 'NN'), ('specific', 'JJ'), ('passenger', 'NN'), ('height', 'VBD'), ('mapping', 'VBG'), ('table', 'NN'), ('stores', 'NNS'), ('height', 'VBD'), ('mapping', 'VBG'), ('information', 'NN'), ('representing', 'VBG'), ('respective', 'JJ'), ('one', 'CD'), ('predetermined', 'VBD'), ('ratios', 'NNS'), ('one', 'CD'), ('segment', 'NN'), ('body', 'NN'), ('portions', 'NNS'), ('human', 'JJ'), ('groups', 'NNS'), ('heights', 'NNS'), ('per', 'IN'), ('human', 'JJ'), ('groups', 'NNS'), ('process', 'NN'), ('acquiring', 'VBG'), ('specific', 'JJ'), ('height', 'NN'), ('specific', 'JJ'), ('passenger', 'NN'), ('specific', 'JJ'), ('height', 'VBD'), ('mapping', 'VBG'), ('information', 'NN'), ('referring', 'VBG'), ('specific', 'JJ'), ('body-part', 'JJ'), ('length', 'NN'), ('information', 'NN'), ('specific', 'JJ'), ('passenger', 'NN'), ('process', 'NN'), ('retrieving', 'VBG'), ('specific', 'JJ'), ('weight', 'NN'), ('mapping', 'VBG'), ('information', 'NN'), ('corresponding', 'VBG'), ('specific', 'JJ'), ('passenger', 'NN'), ('feature', 'NN'), ('information', 'NN'), ('weight', 'VBD'), ('mapping', 'VBG'), ('table', 'NN'), ('stores', 'NNS'), ('multiple', 'JJ'), ('pieces', 'NNS'), ('weight', 'VBD'), ('mapping', 'VBG'), ('information', 'NN'), ('representing', 'VBG'), ('predetermined', 'VBN'), ('correlations', 'NNS'), ('heights', 'NNS'), ('weights', 'NNS'), ('per', 'IN'), ('human', 'JJ'), ('groups', 'NNS'), ('process', 'NN'), ('acquiring', 'VBG'), ('weight', 'NN'), ('specific', 'JJ'), ('passenger', 'NN'), ('specific', 'JJ'), ('weight', 'VBD'), ('mapping', 'VBG'), ('information', 'NN'), ('referring', 'VBG'), ('specific', 'JJ'), ('height', 'NN'), ('specific', 'JJ'), ('passenger', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'JJ'), ('step', 'NN'), ('passenger', 'NN'), ('body', 'NN'), ('information-detecting', 'JJ'), ('device', 'NN'), ('performs', 'NNS'), ('process', 'NN'), ('inputting', 'VBG'), ('interior', 'JJ'), ('image', 'NN'), ('body', 'NN'), ('recognition', 'NN'), ('network', 'NN'), ('thereby', 'RB'), ('allow', 'VB'), ('body', 'NN'), ('recognition', 'NN'), ('network', 'NN'), ('output', 'NN'), ('one', 'CD'), ('feature', 'NN'), ('tensors', 'VBZ'), ('one', 'CD'), ('channels', 'NNS'), ('corresponding', 'VBG'), ('interior', 'JJ'), ('image', 'NN'), ('via', 'IN'), ('feature', 'NN'), ('extraction', 'NN'), ('network', 'NN'), ('ii', 'JJ'), ('generate', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('keypoint', 'NN'), ('heatmap', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('part', 'NN'), ('affinity', 'NN'), ('field', 'NN'), ('one', 'CD'), ('channels', 'NNS'), ('corresponding', 'VBG'), ('feature', 'NN'), ('tensors', 'NNS'), ('via', 'IN'), ('keypoint', 'NN'), ('heatmap', 'NN'), ('&', 'CC'), ('part', 'NN'), ('affinity', 'NN'), ('field', 'NN'), ('extractor', 'NN'), ('iii', 'JJ'), ('extract', 'JJ'), ('keypoints', 'NNS'), ('keypoint', 'VB'), ('heatmap', 'NN'), ('via', 'IN'), ('keypoint', 'NN'), ('detector', 'NN'), ('group', 'NN'), ('extracted', 'VBD'), ('keypoints', 'NNS'), ('referring', 'VBG'), ('part', 'NN'), ('affinity', 'NN'), ('field', 'NN'), ('thus', 'RB'), ('generate', 'VB'), ('body', 'NN'), ('parts', 'NNS'), ('per', 'IN'), ('passengers', 'NNS'), ('result', 'VBP'), ('allow', 'IN'), ('body', 'NN'), ('recognition', 'NN'), ('network', 'NN'), ('output', 'NN'), ('multiple', 'JJ'), ('pieces', 'NNS'), ('body-part', 'JJ'), ('length', 'NN'), ('information', 'NN'), ('passengers', 'NNS'), ('referring', 'VBG'), ('body', 'NN'), ('parts', 'NNS'), ('per', 'IN'), ('passengers', 'NNS'), ('method', 'VBP'), ('claim', 'NN'), ('wherein', 'NN'), ('feature', 'NN'), ('extraction', 'NN'), ('network', 'NN'), ('includes', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('convolutional', 'JJ'), ('layer', 'NN'), ('applies', 'NNS'), ('least', 'VBP'), ('one', 'CD'), ('convolution', 'NN'), ('operation', 'NN'), ('interior', 'JJ'), ('image', 'NN'), ('thereby', 'NN'), ('output', 'NN'), ('feature', 'NN'), ('tensors', 'NNS'), ('method', 'VBP'), ('claim', 'NN'), ('wherein', 'NN'), ('keypoint', 'NN'), ('heatmap', 'NN'), ('&', 'CC'), ('part', 'NN'), ('affinity', 'NN'), ('field', 'NN'), ('extractor', 'NN'), ('includes', 'VBZ'), ('one', 'CD'), ('fully', 'RB'), ('convolutional', 'JJ'), ('network', 'NN'), ('×', 'NNP'), ('convolutional', 'NN'), ('layer', 'NN'), ('applies', 'VBZ'), ('fully-convolution', 'NN'), ('operation', 'NN'), ('×', 'NNP'), ('convolution', 'NN'), ('operation', 'NN'), ('feature', 'NN'), ('tensors', 'NNS'), ('thereby', 'RB'), ('generate', 'VBP'), ('keypoint', 'NN'), ('heatmap', 'NN'), ('part', 'NN'), ('affinity', 'NN'), ('field', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'VBD'), ('keypoint', 'JJ'), ('detector', 'NN'), ('connects', 'NNS'), ('referring', 'VBG'), ('part', 'NN'), ('affinity', 'NN'), ('field', 'NN'), ('pairs', 'VBZ'), ('respectively', 'RB'), ('highest', 'JJS'), ('mutual', 'JJ'), ('connection', 'NN'), ('probabilities', 'NNS'), ('connected', 'VBN'), ('among', 'IN'), ('extracted', 'JJ'), ('keypoints', 'NNS'), ('thereby', 'RB'), ('group', 'NN'), ('extracted', 'VBD'), ('keypoints', 'NNS'), ('method', 'JJ'), ('claim', 'NN'), ('wherein', 'NN'), ('feature', 'NN'), ('extraction', 'NN'), ('network', 'NN'), ('keypoint', 'NN'), ('heatmap', 'NN'), ('&', 'CC'), ('part', 'NN'), ('affinity', 'NN'), ('field', 'NN'), ('extractor', 'NN'), ('learned', 'VBD'), ('learning', 'JJ'), ('device', 'NN'), ('performing', 'VBG'), ('process', 'NN'), ('inputting', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('training', 'NN'), ('image', 'NN'), ('including', 'VBG'), ('one', 'CD'), ('objects', 'VBZ'), ('training', 'VBG'), ('feature', 'NN'), ('extraction', 'NN'), ('network', 'NN'), ('thereby', 'RB'), ('allow', 'JJ'), ('feature', 'NN'), ('extraction', 'NN'), ('network', 'NN'), ('generate', 'VBP'), ('one', 'CD'), ('feature', 'NN'), ('tensors', 'NNS'), ('training', 'VBG'), ('one', 'CD'), ('channels', 'NNS'), ('applying', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('convolutional', 'JJ'), ('operation', 'NN'), ('training', 'NN'), ('image', 'NN'), ('ii', 'JJ'), ('process', 'NN'), ('inputting', 'VBG'), ('feature', 'NN'), ('tensors', 'NNS'), ('training', 'VBG'), ('keypoint', 'NN'), ('heatmap', 'NN'), ('&', 'CC'), ('part', 'NN'), ('affinity', 'NN'), ('field', 'NN'), ('extractor', 'NN'), ('thereby', 'RB'), ('allow', 'JJ'), ('keypoint', 'NN'), ('heatmap', 'NN'), ('&', 'CC'), ('part', 'NN'), ('affinity', 'NN'), ('field', 'NN'), ('extractor', 'NN'), ('generate', 'VBP'), ('one', 'CD'), ('keypoint', 'NN'), ('heatmaps', 'VBZ'), ('training', 'VBG'), ('one', 'CD'), ('part', 'NN'), ('affinity', 'NN'), ('fields', 'NNS'), ('training', 'VBG'), ('one', 'CD'), ('channels', 'JJ'), ('feature', 'NN'), ('tensors', 'NNS'), ('training', 'VBG'), ('iii', 'JJ'), ('process', 'NN'), ('inputting', 'VBG'), ('keypoint', 'NN'), ('heatmaps', 'NNS'), ('training', 'VBG'), ('part', 'NN'), ('affinity', 'NN'), ('fields', 'NNS'), ('training', 'VBG'), ('keypoint', 'NN'), ('detector', 'NN'), ('thereby', 'RB'), ('allow', 'JJ'), ('keypoint', 'NN'), ('detector', 'NN'), ('extract', 'JJ'), ('keypoints', 'NNS'), ('training', 'VBG'), ('keypoint', 'NN'), ('heatmaps', 'NNS'), ('training', 'VBG'), ('process', 'NN'), ('grouping', 'NN'), ('extracted', 'VBD'), ('keypoints', 'NNS'), ('training', 'VBG'), ('referring', 'VBG'), ('part', 'NN'), ('affinity', 'NN'), ('fields', 'NNS'), ('training', 'VBG'), ('thereby', 'RB'), ('detect', 'JJ'), ('keypoints', 'NNS'), ('per', 'IN'), ('objects', 'NNS'), ('training', 'VBG'), ('iv', 'JJ'), ('process', 'NN'), ('allowing', 'VBG'), ('loss', 'NN'), ('layer', 'NN'), ('calculate', 'VBP'), ('one', 'CD'), ('losses', 'NNS'), ('referring', 'VBG'), ('keypoints', 'NNS'), ('per', 'IN'), ('objects', 'NNS'), ('training', 'VBG'), ('corresponding', 'VBG'), ('ground', 'NN'), ('truths', 'NNS'), ('thereby', 'RB'), ('adjust', 'VBP'), ('one', 'CD'), ('parameters', 'NNS'), ('feature', 'VBP'), ('extraction', 'NN'), ('network', 'NN'), ('keypoint', 'NN'), ('heatmap', 'NN'), ('&', 'CC'), ('part', 'NN'), ('affinity', 'NN'), ('field', 'NN'), ('extractor', 'NN'), ('losses', 'NNS'), ('minimized', 'VBN'), ('backpropagation', 'NN'), ('using', 'VBG'), ('losses', 'NNS'), ('method', 'JJ'), ('claim', 'NN'), ('wherein', 'JJ'), ('step', 'NN'), ('passenger', 'NN'), ('body', 'NN'), ('information-detecting', 'JJ'), ('device', 'NN'), ('performs', 'NNS'), ('process', 'NN'), ('inputting', 'VBG'), ('interior', 'JJ'), ('image', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('network', 'NN'), ('thereby', 'RB'), ('allow', 'VB'), ('face', 'NN'), ('recognition', 'NN'), ('network', 'NN'), ('detect', 'JJ'), ('faces', 'VBZ'), ('passengers', 'NNS'), ('located', 'VBN'), ('interior', 'JJ'), ('image', 'NN'), ('via', 'IN'), ('face', 'NN'), ('detector', 'NN'), ('output', 'NN'), ('multiple', 'JJ'), ('pieces', 'NNS'), ('passenger', 'NN'), ('feature', 'NN'), ('information', 'NN'), ('facial', 'JJ'), ('images', 'NNS'), ('via', 'IN'), ('facial', 'JJ'), ('feature', 'NN'), ('classifier', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'JJ'), ('step', 'NN'), ('passenger', 'NN'), ('body', 'NN'), ('information-detecting', 'JJ'), ('device', 'NN'), ('performs', 'NNS'), ('process', 'NN'), ('inputting', 'VBG'), ('interior', 'JJ'), ('image', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('network', 'NN'), ('thereby', 'RB'), ('allow', 'VB'), ('face', 'NN'), ('recognition', 'NN'), ('network', 'NN'), ('apply', 'RB'), ('least', 'JJS'), ('one', 'CD'), ('convolution', 'NN'), ('operation', 'NN'), ('interior', 'JJ'), ('image', 'NN'), ('thus', 'RB'), ('output', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('feature', 'NN'), ('map', 'NN'), ('corresponding', 'VBG'), ('interior', 'JJ'), ('image', 'NN'), ('via', 'IN'), ('least', 'JJS'), ('one', 'CD'), ('convolutional', 'JJ'), ('layer', 'NN'), ('ii', 'NN'), ('output', 'NN'), ('one', 'CD'), ('proposal', 'NN'), ('boxes', 'VBZ'), ('passengers', 'NNS'), ('estimated', 'VBN'), ('located', 'JJ'), ('feature', 'NN'), ('map', 'NN'), ('via', 'IN'), ('region', 'NN'), ('proposal', 'NN'), ('network', 'NN'), ('iii', 'VBP'), ('apply', 'VB'), ('pooling', 'VBG'), ('operation', 'NN'), ('one', 'CD'), ('regions', 'NNS'), ('corresponding', 'VBG'), ('proposal', 'NN'), ('boxes', 'NNS'), ('feature', 'VBP'), ('map', 'JJ'), ('thus', 'RB'), ('output', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('feature', 'NN'), ('vector', 'NN'), ('via', 'IN'), ('pooling', 'VBG'), ('layer', 'NN'), ('iv', 'JJ'), ('apply', 'RB'), ('fully-connected', 'JJ'), ('operation', 'NN'), ('feature', 'NN'), ('vector', 'NN'), ('thus', 'RB'), ('output', 'NN'), ('multiple', 'JJ'), ('pieces', 'NNS'), ('passenger', 'NN'), ('feature', 'NN'), ('information', 'NN'), ('corresponding', 'VBG'), ('faces', 'VBZ'), ('passengers', 'NNS'), ('corresponding', 'VBG'), ('proposal', 'NN'), ('boxes', 'NNS'), ('via', 'IN'), ('fully', 'RB'), ('connected', 'VBN'), ('layer', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('multiple', 'JJ'), ('pieces', 'NNS'), ('passenger', 'NN'), ('feature', 'NN'), ('information', 'NN'), ('include', 'VBP'), ('ages', 'VBZ'), ('genders', 'NNS'), ('races', 'NNS'), ('corresponding', 'VBG'), ('passengers', 'NNS'), ('passenger', 'NN'), ('body', 'NN'), ('information-detecting', 'JJ'), ('device', 'NN'), ('detecting', 'VBG'), ('body', 'NN'), ('information', 'NN'), ('one', 'CD'), ('passengers', 'NN'), ('vehicle', 'NN'), ('based', 'VBN'), ('humans', 'NNS'), (\"'\", 'POS'), ('status', 'NN'), ('recognition', 'NN'), ('comprising', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('memory', 'NN'), ('stores', 'NNS'), ('instructions', 'NNS'), ('least', 'VBP'), ('one', 'CD'), ('processor', 'NN'), ('configured', 'VBD'), ('execute', 'JJ'), ('instructions', 'NNS'), ('perform', 'VB'), ('support', 'NN'), ('another', 'DT'), ('device', 'NN'), ('perform', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('interior', 'JJ'), ('image', 'NN'), ('interior', 'JJ'), ('vehicle', 'NN'), ('acquired', 'VBD'), ('process', 'NN'), ('inputting', 'VBG'), ('interior', 'JJ'), ('image', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('network', 'NN'), ('thereby', 'RB'), ('allow', 'VB'), ('face', 'NN'), ('recognition', 'NN'), ('network', 'NN'), ('detect', 'JJ'), ('faces', 'VBZ'), ('passengers', 'NNS'), ('interior', 'JJ'), ('image', 'NN'), ('thus', 'RB'), ('output', 'NN'), ('multiple', 'JJ'), ('pieces', 'NNS'), ('passenger', 'NN'), ('feature', 'NN'), ('information', 'NN'), ('corresponding', 'VBG'), ('detected', 'VBD'), ('faces', 'VBZ'), ('ii', 'JJ'), ('process', 'NN'), ('inputting', 'VBG'), ('interior', 'JJ'), ('image', 'NN'), ('body', 'NN'), ('recognition', 'NN'), ('network', 'NN'), ('thereby', 'RB'), ('allow', 'VB'), ('body', 'NN'), ('recognition', 'NN'), ('network', 'NN'), ('detect', 'JJ'), ('bodies', 'NNS'), ('passengers', 'NNS'), ('interior', 'JJ'), ('image', 'NN'), ('thus', 'RB'), ('output', 'NN'), ('body-part', 'JJ'), ('length', 'NN'), ('information', 'NN'), ('detected', 'VBD'), ('bodies', 'NNS'), ('ii', 'JJ'), ('process', 'NN'), ('retrieving', 'VBG'), ('specific', 'JJ'), ('height', 'JJ'), ('mapping', 'NN'), ('information', 'NN'), ('corresponding', 'VBG'), ('specific', 'JJ'), ('passenger', 'NN'), ('feature', 'NN'), ('information', 'NN'), ('specific', 'JJ'), ('passenger', 'NN'), ('height', 'VBD'), ('mapping', 'VBG'), ('table', 'NN'), ('stores', 'NNS'), ('height', 'VBD'), ('mapping', 'VBG'), ('information', 'NN'), ('representing', 'VBG'), ('respective', 'JJ'), ('one', 'CD'), ('predetermined', 'VBD'), ('ratios', 'NNS'), ('one', 'CD'), ('segment', 'NN'), ('body', 'NN'), ('portions', 'NNS'), ('human', 'JJ'), ('groups', 'NNS'), ('heights', 'NNS'), ('per', 'IN'), ('human', 'JJ'), ('groups', 'NNS'), ('process', 'NN'), ('acquiring', 'VBG'), ('specific', 'JJ'), ('height', 'NN'), ('specific', 'JJ'), ('passenger', 'NN'), ('specific', 'JJ'), ('height', 'VBD'), ('mapping', 'VBG'), ('information', 'NN'), ('referring', 'VBG'), ('specific', 'JJ'), ('body-part', 'JJ'), ('length', 'NN'), ('information', 'NN'), ('specific', 'JJ'), ('passenger', 'NN'), ('process', 'NN'), ('retrieving', 'VBG'), ('specific', 'JJ'), ('weight', 'NN'), ('mapping', 'VBG'), ('information', 'NN'), ('corresponding', 'VBG'), ('specific', 'JJ'), ('passenger', 'NN'), ('feature', 'NN'), ('information', 'NN'), ('weight', 'VBD'), ('mapping', 'VBG'), ('table', 'NN'), ('stores', 'NNS'), ('multiple', 'JJ'), ('pieces', 'NNS'), ('weight', 'VBD'), ('mapping', 'VBG'), ('information', 'NN'), ('representing', 'VBG'), ('predetermined', 'VBN'), ('correlations', 'NNS'), ('heights', 'NNS'), ('weights', 'NNS'), ('per', 'IN'), ('human', 'JJ'), ('groups', 'NNS'), ('process', 'NN'), ('acquiring', 'VBG'), ('weight', 'NN'), ('specific', 'JJ'), ('passenger', 'NN'), ('specific', 'JJ'), ('weight', 'VBD'), ('mapping', 'VBG'), ('information', 'NN'), ('referring', 'VBG'), ('specific', 'JJ'), ('height', 'NN'), ('specific', 'JJ'), ('passenger', 'NN'), ('passenger', 'NN'), ('body', 'NN'), ('information-detecting', 'JJ'), ('device', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('process', 'NN'), ('processor', 'NN'), ('performs', 'NNS'), ('process', 'NN'), ('inputting', 'VBG'), ('interior', 'JJ'), ('image', 'NN'), ('body', 'NN'), ('recognition', 'NN'), ('network', 'NN'), ('thereby', 'RB'), ('allow', 'VB'), ('body', 'NN'), ('recognition', 'NN'), ('network', 'NN'), ('output', 'NN'), ('one', 'CD'), ('feature', 'NN'), ('tensors', 'VBZ'), ('one', 'CD'), ('channels', 'NNS'), ('corresponding', 'VBG'), ('interior', 'JJ'), ('image', 'NN'), ('via', 'IN'), ('feature', 'NN'), ('extraction', 'NN'), ('network', 'NN'), ('ii', 'JJ'), ('generate', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('keypoint', 'NN'), ('heatmap', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('part', 'NN'), ('affinity', 'NN'), ('field', 'NN'), ('one', 'CD'), ('channels', 'NNS'), ('corresponding', 'VBG'), ('feature', 'NN'), ('tensors', 'NNS'), ('via', 'IN'), ('keypoint', 'NN'), ('heatmap', 'NN'), ('&', 'CC'), ('part', 'NN'), ('affinity', 'NN'), ('field', 'NN'), ('extractor', 'NN'), ('iii', 'JJ'), ('extract', 'JJ'), ('keypoints', 'NNS'), ('keypoint', 'VB'), ('heatmap', 'NN'), ('via', 'IN'), ('keypoint', 'NN'), ('detector', 'NN'), ('group', 'NN'), ('extracted', 'VBD'), ('keypoints', 'NNS'), ('referring', 'VBG'), ('part', 'NN'), ('affinity', 'NN'), ('field', 'NN'), ('thus', 'RB'), ('generate', 'VB'), ('body', 'NN'), ('parts', 'NNS'), ('per', 'IN'), ('passengers', 'NNS'), ('result', 'VBP'), ('allow', 'IN'), ('body', 'NN'), ('recognition', 'NN'), ('network', 'NN'), ('output', 'NN'), ('multiple', 'JJ'), ('pieces', 'NNS'), ('body-part', 'JJ'), ('length', 'NN'), ('information', 'NN'), ('passengers', 'NNS'), ('referring', 'VBG'), ('body', 'NN'), ('parts', 'NNS'), ('per', 'IN'), ('passengers', 'NNS'), ('passenger', 'VBP'), ('body', 'NN'), ('information-detecting', 'JJ'), ('device', 'NN'), ('claim', 'NN'), ('wherein', 'VBD'), ('keypoint', 'NNP'), ('heatmap', 'NN'), ('&', 'CC'), ('part', 'NN'), ('affinity', 'NN'), ('field', 'NN'), ('extractor', 'NN'), ('includes', 'VBZ'), ('one', 'CD'), ('fully', 'RB'), ('convolutional', 'JJ'), ('network', 'NN'), ('×', 'NNP'), ('convolutional', 'NN'), ('layer', 'NN'), ('applies', 'VBZ'), ('fully-convolution', 'NN'), ('operation', 'NN'), ('×', 'NNP'), ('convolution', 'NN'), ('operation', 'NN'), ('feature', 'NN'), ('tensors', 'NNS'), ('thereby', 'RB'), ('generate', 'VBP'), ('keypoint', 'NN'), ('heatmap', 'NN'), ('part', 'NN'), ('affinity', 'NN'), ('field', 'NN'), ('passenger', 'NN'), ('body', 'NN'), ('information-detecting', 'JJ'), ('device', 'NN'), ('claim', 'NN'), ('wherein', 'VBD'), ('keypoint', 'JJ'), ('detector', 'NN'), ('connects', 'NNS'), ('referring', 'VBG'), ('part', 'NN'), ('affinity', 'NN'), ('field', 'NN'), ('pairs', 'VBZ'), ('respectively', 'RB'), ('highest', 'JJS'), ('mutual', 'JJ'), ('connection', 'NN'), ('probabilities', 'NNS'), ('connected', 'VBN'), ('among', 'IN'), ('extracted', 'JJ'), ('keypoints', 'NNS'), ('thereby', 'RB'), ('group', 'NN'), ('extracted', 'VBD'), ('keypoints', 'NNS'), ('passenger', 'NN'), ('body', 'NN'), ('information-detecting', 'JJ'), ('device', 'NN'), ('claim', 'NN'), ('wherein', 'JJ'), ('feature', 'NN'), ('extraction', 'NN'), ('network', 'NN'), ('keypoint', 'NN'), ('heatmap', 'NN'), ('&', 'CC'), ('part', 'NN'), ('affinity', 'NN'), ('field', 'NN'), ('extractor', 'NN'), ('learned', 'VBD'), ('learning', 'JJ'), ('device', 'NN'), ('performing', 'VBG'), ('process', 'NN'), ('inputting', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('training', 'NN'), ('image', 'NN'), ('including', 'VBG'), ('one', 'CD'), ('objects', 'VBZ'), ('training', 'VBG'), ('feature', 'NN'), ('extraction', 'NN'), ('network', 'NN'), ('thereby', 'RB'), ('allow', 'JJ'), ('feature', 'NN'), ('extraction', 'NN'), ('network', 'NN'), ('generate', 'VBP'), ('one', 'CD'), ('feature', 'NN'), ('tensors', 'NNS'), ('training', 'VBG'), ('one', 'CD'), ('channels', 'NNS'), ('applying', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('convolutional', 'JJ'), ('operation', 'NN'), ('training', 'NN'), ('image', 'NN'), ('ii', 'JJ'), ('process', 'NN'), ('inputting', 'VBG'), ('feature', 'NN'), ('tensors', 'NNS'), ('training', 'VBG'), ('keypoint', 'NN'), ('heatmap', 'NN'), ('&', 'CC'), ('part', 'NN'), ('affinity', 'NN'), ('field', 'NN'), ('extractor', 'NN'), ('thereby', 'RB'), ('allow', 'JJ'), ('keypoint', 'NN'), ('heatmap', 'NN'), ('&', 'CC'), ('part', 'NN'), ('affinity', 'NN'), ('field', 'NN'), ('extractor', 'NN'), ('generate', 'VBP'), ('one', 'CD'), ('keypoint', 'NN'), ('heatmaps', 'VBZ'), ('training', 'VBG'), ('one', 'CD'), ('part', 'NN'), ('affinity', 'NN'), ('fields', 'NNS'), ('training', 'VBG'), ('one', 'CD'), ('channels', 'JJ'), ('feature', 'NN'), ('tensors', 'NNS'), ('training', 'VBG'), ('iii', 'JJ'), ('process', 'NN'), ('inputting', 'VBG'), ('keypoint', 'NN'), ('heatmaps', 'NNS'), ('training', 'VBG'), ('part', 'NN'), ('affinity', 'NN'), ('fields', 'NNS'), ('training', 'VBG'), ('keypoint', 'NN'), ('detector', 'NN'), ('thereby', 'RB'), ('allow', 'JJ'), ('keypoint', 'NN'), ('detector', 'NN'), ('extract', 'JJ'), ('keypoints', 'NNS'), ('training', 'VBG'), ('keypoint', 'NN'), ('heatmaps', 'NNS'), ('training', 'VBG'), ('process', 'NN'), ('grouping', 'NN'), ('extracted', 'VBD'), ('keypoints', 'NNS'), ('training', 'VBG'), ('referring', 'VBG'), ('part', 'NN'), ('affinity', 'NN'), ('fields', 'NNS'), ('training', 'VBG'), ('thereby', 'RB'), ('detect', 'JJ'), ('keypoints', 'NNS'), ('per', 'IN'), ('objects', 'NNS'), ('training', 'VBG'), ('iv', 'JJ'), ('process', 'NN'), ('allowing', 'VBG'), ('loss', 'NN'), ('layer', 'NN'), ('calculate', 'VBP'), ('one', 'CD'), ('losses', 'NNS'), ('referring', 'VBG'), ('keypoints', 'NNS'), ('per', 'IN'), ('objects', 'NNS'), ('training', 'VBG'), ('corresponding', 'VBG'), ('ground', 'NN'), ('truths', 'NNS'), ('thereby', 'RB'), ('adjust', 'VBP'), ('one', 'CD'), ('parameters', 'NNS'), ('feature', 'VBP'), ('extraction', 'NN'), ('network', 'NN'), ('keypoint', 'NN'), ('heatmap', 'NN'), ('&', 'CC'), ('part', 'NN'), ('affinity', 'NN'), ('field', 'NN'), ('extractor', 'NN'), ('losses', 'NNS'), ('minimized', 'VBN'), ('backpropagation', 'NN'), ('using', 'VBG'), ('losses', 'NNS'), ('passenger', 'NN'), ('body', 'NN'), ('information-detecting', 'JJ'), ('device', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('process', 'NN'), ('processor', 'NN'), ('performs', 'NNS'), ('process', 'NN'), ('inputting', 'VBG'), ('interior', 'JJ'), ('image', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('network', 'NN'), ('thereby', 'RB'), ('allow', 'VB'), ('face', 'NN'), ('recognition', 'NN'), ('network', 'NN'), ('apply', 'RB'), ('least', 'JJS'), ('one', 'CD'), ('convolution', 'NN'), ('operation', 'NN'), ('interior', 'JJ'), ('image', 'NN'), ('thus', 'RB'), ('output', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('feature', 'NN'), ('map', 'NN'), ('corresponding', 'VBG'), ('interior', 'JJ'), ('image', 'NN'), ('via', 'IN'), ('least', 'JJS'), ('one', 'CD'), ('convolutional', 'JJ'), ('layer', 'NN'), ('ii', 'NN'), ('output', 'NN'), ('one', 'CD'), ('proposal', 'NN'), ('boxes', 'VBZ'), ('passengers', 'NNS'), ('estimated', 'VBN'), ('located', 'JJ'), ('feature', 'NN'), ('map', 'NN'), ('via', 'IN'), ('region', 'NN'), ('proposal', 'NN'), ('network', 'NN'), ('iii', 'VBP'), ('apply', 'VB'), ('pooling', 'VBG'), ('operation', 'NN'), ('one', 'CD'), ('regions', 'NNS'), ('corresponding', 'VBG'), ('proposal', 'NN'), ('boxes', 'NNS'), ('feature', 'VBP'), ('map', 'JJ'), ('thus', 'RB'), ('output', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('feature', 'NN'), ('vector', 'NN'), ('via', 'IN'), ('pooling', 'VBG'), ('layer', 'NN'), ('iv', 'JJ'), ('apply', 'RB'), ('fully-connected', 'JJ'), ('operation', 'NN'), ('feature', 'NN'), ('vector', 'NN'), ('thus', 'RB'), ('output', 'NN'), ('multiple', 'JJ'), ('pieces', 'NNS'), ('passenger', 'NN'), ('feature', 'NN'), ('information', 'NN'), ('corresponding', 'VBG'), ('faces', 'VBZ'), ('passengers', 'NNS'), ('corresponding', 'VBG'), ('proposal', 'NN'), ('boxes', 'NNS'), ('via', 'IN'), ('fully', 'RB'), ('connected', 'VBN'), ('layer', 'NN'), ('computer', 'NN'), ('implemented', 'VBD'), ('method', 'JJ'), ('performing', 'VBG'), ('video', 'NN'), ('coding', 'VBG'), ('based', 'VBN'), ('face', 'NN'), ('detection', 'NN'), ('comprising', 'VBG'), ('receiving', 'VBG'), ('video', 'NN'), ('frame', 'NN'), ('comprising', 'VBG'), ('one', 'CD'), ('plurality', 'NN'), ('video', 'NN'), ('frames', 'NNS'), ('video', 'VBP'), ('sequence', 'NN'), ('determining', 'VBG'), ('video', 'NN'), ('frame', 'NN'), ('key', 'JJ'), ('frame', 'NN'), ('video', 'NN'), ('sequence', 'NN'), ('performing', 'VBG'), ('response', 'NN'), ('video', 'NN'), ('frame', 'NN'), ('key', 'JJ'), ('frame', 'NN'), ('video', 'JJ'), ('sequence', 'NN'), ('multi-stage', 'NN'), ('facial', 'JJ'), ('search', 'NN'), ('video', 'NN'), ('frame', 'NN'), ('based', 'VBN'), ('predetermined', 'JJ'), ('feature', 'NN'), ('templates', 'NNS'), ('predetermined', 'VBD'), ('number', 'NN'), ('stages', 'NNS'), ('determine', 'VBP'), ('first', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('second', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('video', 'NN'), ('frame', 'NN'), ('testing', 'VBG'), ('first', 'JJ'), ('second', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('regions', 'NNS'), ('based', 'VBN'), ('skin', 'JJ'), ('tone', 'NN'), ('information', 'NN'), ('determine', 'NN'), ('first', 'RB'), ('candidate', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('valid', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('second', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('invalid', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('rejecting', 'VBG'), ('second', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('outputting', 'VBG'), ('first', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('encoding', 'VBG'), ('video', 'NN'), ('frame', 'NN'), ('based', 'VBN'), ('least', 'JJS'), ('part', 'NN'), ('first', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('valid', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('generate', 'NN'), ('coded', 'VBD'), ('bitstream', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('skin', 'VBD'), ('tone', 'NN'), ('information', 'NN'), ('comprises', 'VBZ'), ('skin', 'JJ'), ('probability', 'NN'), ('map', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('said', 'VBD'), ('testing', 'VBG'), ('first', 'JJ'), ('second', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('regions', 'NNS'), ('based', 'VBN'), ('skin', 'JJ'), ('tone', 'NN'), ('information', 'NN'), ('performed', 'VBN'), ('response', 'NN'), ('video', 'NN'), ('frame', 'NN'), ('key', 'JJ'), ('frame', 'NN'), ('video', 'NN'), ('sequence', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('first', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('comprises', 'VBZ'), ('rectangular', 'JJ'), ('region', 'NN'), ('method', 'NN'), ('comprising', 'VBG'), ('determining', 'VBG'), ('free', 'JJ'), ('form', 'NN'), ('shape', 'NN'), ('face', 'NN'), ('region', 'NN'), ('corresponding', 'VBG'), ('first', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('wherein', 'VBD'), ('free', 'JJ'), ('form', 'NN'), ('shape', 'NN'), ('face', 'NN'), ('region', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('pixel', 'NN'), ('accuracy', 'NN'), ('small', 'JJ'), ('block', 'NN'), ('pixels', 'NNS'), ('accuracy', 'VBP'), ('method', 'JJ'), ('claim', 'NN'), ('wherein', 'IN'), ('determining', 'VBG'), ('free', 'JJ'), ('form', 'NN'), ('shape', 'NN'), ('face', 'NN'), ('region', 'NN'), ('comprises', 'VBZ'), ('generating', 'VBG'), ('enhanced', 'VBN'), ('skip', 'JJ'), ('probability', 'NN'), ('map', 'NN'), ('corresponding', 'VBG'), ('first', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('binarizing', 'VBG'), ('enhanced', 'VBD'), ('skip', 'JJ'), ('probability', 'NN'), ('map', 'NN'), ('overlaying', 'VBG'), ('binarized', 'VBN'), ('enhanced', 'JJ'), ('skip', 'NN'), ('probability', 'NN'), ('map', 'NN'), ('least', 'JJS'), ('portion', 'NN'), ('video', 'NN'), ('frame', 'NN'), ('provide', 'VBP'), ('free', 'JJ'), ('form', 'NN'), ('shape', 'NN'), ('face', 'NN'), ('region', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('second', 'JJ'), ('video', 'NN'), ('frame', 'NN'), ('comprises', 'VBZ'), ('non-key', 'JJ'), ('frame', 'NN'), ('video', 'NN'), ('sequence', 'NN'), ('method', 'NN'), ('comprising', 'VBG'), ('performing', 'VBG'), ('face', 'NN'), ('detection', 'NN'), ('second', 'JJ'), ('video', 'NN'), ('frame', 'NN'), ('video', 'NN'), ('sequence', 'NN'), ('based', 'VBN'), ('free', 'JJ'), ('form', 'NN'), ('shape', 'NN'), ('face', 'NN'), ('region', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('tracking', 'VBG'), ('second', 'JJ'), ('free', 'JJ'), ('form', 'NN'), ('shape', 'NN'), ('face', 'NN'), ('region', 'NN'), ('second', 'JJ'), ('video', 'NN'), ('frame', 'NN'), ('based', 'VBN'), ('free', 'JJ'), ('form', 'NN'), ('shape', 'NN'), ('face', 'NN'), ('region', 'NN'), ('video', 'NN'), ('frame', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('tracking', 'VBG'), ('second', 'JJ'), ('free', 'JJ'), ('form', 'NN'), ('shape', 'NN'), ('face', 'NN'), ('region', 'NN'), ('comprises', 'VBZ'), ('determining', 'VBG'), ('location', 'NN'), ('second', 'JJ'), ('valid', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('second', 'JJ'), ('video', 'NN'), ('frame', 'NN'), ('based', 'VBN'), ('displacement', 'JJ'), ('offset', 'NN'), ('respect', 'NN'), ('first', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('determining', 'VBG'), ('displacement', 'NN'), ('offset', 'NN'), ('based', 'VBN'), ('offset', 'VBN'), ('centroid', 'JJ'), ('bounding', 'VBG'), ('box', 'NN'), ('around', 'IN'), ('skin', 'NN'), ('enhanced', 'VBN'), ('region', 'NN'), ('corresponding', 'VBG'), ('first', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('second', 'JJ'), ('centroid', 'JJ'), ('second', 'JJ'), ('bounding', 'NN'), ('box', 'NN'), ('around', 'IN'), ('second', 'JJ'), ('skin', 'NN'), ('enhanced', 'VBD'), ('region', 'NN'), ('second', 'JJ'), ('video', 'NN'), ('frame', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('encoding', 'VBG'), ('video', 'NN'), ('frame', 'NN'), ('based', 'VBN'), ('least', 'JJS'), ('part', 'NN'), ('first', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('valid', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('comprises', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('reducing', 'VBG'), ('quantization', 'NN'), ('parameter', 'NN'), ('corresponding', 'VBG'), ('first', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('adjusting', 'VBG'), ('lambda', 'NN'), ('value', 'NN'), ('first', 'RB'), ('candidate', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('disabling', 'VBG'), ('skip', 'NN'), ('coding', 'VBG'), ('first', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('bitstream', 'NN'), ('comprises', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('hadvanced', 'VBD'), ('video', 'NN'), ('coding', 'VBG'), ('avc', 'JJ'), ('compliant', 'JJ'), ('bitstream', 'NN'), ('hhigh', 'NN'), ('efficiency', 'NN'), ('video', 'NN'), ('coding', 'VBG'), ('hevc', 'NN'), ('compliant', 'JJ'), ('bitstream', 'NN'), ('vp', 'NN'), ('compliant', 'JJ'), ('bitstream', 'NN'), ('vp', 'NN'), ('compliant', 'JJ'), ('bitstream', 'NN'), ('alliance', 'NN'), ('open', 'JJ'), ('media', 'NNS'), ('aom', 'VBP'), ('av', 'JJ'), ('compliant', 'NN'), ('bitstream', 'NN'), ('computer', 'NN'), ('implemented', 'VBD'), ('method', 'NN'), ('performing', 'VBG'), ('face', 'NN'), ('detection', 'NN'), ('comprising', 'VBG'), ('receiving', 'VBG'), ('video', 'NN'), ('frame', 'NN'), ('sequence', 'NN'), ('video', 'NN'), ('frames', 'NNS'), ('performing', 'VBG'), ('multi-stage', 'JJ'), ('facial', 'JJ'), ('search', 'NN'), ('video', 'NN'), ('frame', 'NN'), ('based', 'VBN'), ('predetermined', 'JJ'), ('feature', 'NN'), ('templates', 'NNS'), ('predetermined', 'VBD'), ('number', 'NN'), ('stages', 'NNS'), ('determine', 'VBP'), ('first', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('second', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('video', 'NN'), ('frame', 'NN'), ('testing', 'VBG'), ('first', 'JJ'), ('second', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('regions', 'NNS'), ('based', 'VBN'), ('skin', 'JJ'), ('tone', 'NN'), ('information', 'NN'), ('determine', 'NN'), ('first', 'RB'), ('candidate', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('valid', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('second', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('invalid', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('rejecting', 'VBG'), ('second', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('outputting', 'VBG'), ('first', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('valid', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('processing', 'VBG'), ('providing', 'VBG'), ('index', 'NN'), ('indicative', 'JJ'), ('person', 'NN'), ('present', 'JJ'), ('video', 'NN'), ('frame', 'NN'), ('based', 'VBN'), ('valid', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('sequence', 'NN'), ('video', 'NN'), ('frames', 'VBZ'), ('comprises', 'NNS'), ('sequence', 'NN'), ('surveillance', 'NN'), ('video', 'NN'), ('frames', 'NNS'), ('method', 'VBP'), ('comprising', 'VBG'), ('performing', 'VBG'), ('face', 'NN'), ('recognition', 'NN'), ('surveillance', 'NN'), ('video', 'NN'), ('frames', 'NNS'), ('based', 'VBN'), ('valid', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('sequence', 'NN'), ('video', 'NN'), ('frames', 'VBZ'), ('comprises', 'NNS'), ('sequence', 'NN'), ('decoded', 'VBD'), ('video', 'NN'), ('frames', 'NNS'), ('method', 'VBP'), ('comprising', 'VBG'), ('adding', 'VBG'), ('marker', 'NN'), ('corresponding', 'VBG'), ('received', 'VBD'), ('video', 'JJ'), ('frame', 'NN'), ('perform', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('received', 'VBD'), ('video', 'NN'), ('frame', 'NN'), ('based', 'VBN'), ('valid', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('sequence', 'NN'), ('video', 'NN'), ('frames', 'NNS'), ('received', 'VBD'), ('device', 'NN'), ('login', 'NN'), ('attempt', 'NN'), ('method', 'NN'), ('comprising', 'VBG'), ('performing', 'VBG'), ('face', 'NN'), ('recognition', 'NN'), ('based', 'VBN'), ('valid', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('allowing', 'VBG'), ('access', 'NN'), ('device', 'NN'), ('secured', 'VBD'), ('face', 'NN'), ('recognized', 'VBN'), ('method', 'JJ'), ('claim', 'NN'), ('wherein', 'NN'), ('sequence', 'NN'), ('video', 'NN'), ('frames', 'VBZ'), ('comprises', 'NNS'), ('sequence', 'NN'), ('videoconferencing', 'VBG'), ('frames', 'NNS'), ('method', 'RB'), ('comprising', 'VBG'), ('encoding', 'VBG'), ('video', 'NN'), ('frame', 'NN'), ('based', 'VBN'), ('least', 'JJS'), ('part', 'NN'), ('valid', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('generate', 'NN'), ('coded', 'VBD'), ('bitstream', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('encoding', 'VBG'), ('video', 'NN'), ('frame', 'NN'), ('comprises', 'VBZ'), ('encoding', 'VBG'), ('background', 'RP'), ('region', 'NN'), ('video', 'NN'), ('frame', 'NN'), ('bitstream', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('encoding', 'VBG'), ('video', 'NN'), ('frame', 'NN'), ('based', 'VBN'), ('least', 'JJS'), ('part', 'NN'), ('valid', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('generate', 'NN'), ('coded', 'VBD'), ('bitstream', 'NN'), ('wherein', 'NN'), ('encoding', 'VBG'), ('video', 'NN'), ('frame', 'NN'), ('comprises', 'VBZ'), ('including', 'VBG'), ('metadata', 'NNS'), ('corresponding', 'VBG'), ('valid', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('bitstream', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('decoding', 'VBG'), ('coded', 'VBN'), ('bitstream', 'NN'), ('generate', 'NN'), ('decoded', 'VBD'), ('video', 'NN'), ('frame', 'NN'), ('determine', 'NN'), ('metadata', 'NN'), ('corresponding', 'VBG'), ('valid', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('bitstream', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('replacing', 'VBG'), ('valid', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('based', 'VBN'), ('decoded', 'VBN'), ('metadata', 'NNS'), ('cropping', 'VBG'), ('displaying', 'VBG'), ('image', 'NN'), ('data', 'NNS'), ('corresponding', 'VBG'), ('valid', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('based', 'VBN'), ('decoded', 'VBN'), ('metadata', 'NNS'), ('indexing', 'VBG'), ('decoded', 'VBD'), ('video', 'NN'), ('frame', 'NN'), ('based', 'VBN'), ('decoded', 'VBN'), ('metadata', 'NN'), ('system', 'NN'), ('performing', 'VBG'), ('video', 'NN'), ('coding', 'VBG'), ('based', 'VBN'), ('face', 'NN'), ('detection', 'NN'), ('comprising', 'VBG'), ('memory', 'NN'), ('configured', 'VBD'), ('store', 'NN'), ('video', 'NN'), ('frame', 'NN'), ('comprising', 'VBG'), ('one', 'CD'), ('plurality', 'NN'), ('video', 'NN'), ('frames', 'NNS'), ('video', 'VBP'), ('sequence', 'NN'), ('processor', 'NN'), ('coupled', 'VBD'), ('memory', 'NN'), ('processor', 'NN'), ('receive', 'VBP'), ('video', 'NN'), ('frame', 'NN'), ('determine', 'JJ'), ('video', 'NN'), ('frame', 'NN'), ('key', 'JJ'), ('frame', 'NN'), ('video', 'NN'), ('sequence', 'NN'), ('perform', 'NN'), ('response', 'NN'), ('video', 'NN'), ('frame', 'NN'), ('key', 'JJ'), ('frame', 'NN'), ('video', 'JJ'), ('sequence', 'NN'), ('multi-stage', 'NN'), ('facial', 'JJ'), ('search', 'NN'), ('video', 'NN'), ('frame', 'NN'), ('based', 'VBN'), ('predetermined', 'JJ'), ('feature', 'NN'), ('templates', 'NNS'), ('predetermined', 'VBD'), ('number', 'NN'), ('stages', 'NNS'), ('determine', 'VBP'), ('first', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('second', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('video', 'NN'), ('frame', 'NN'), ('test', 'NN'), ('first', 'RB'), ('second', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('regions', 'NNS'), ('based', 'VBN'), ('skin', 'JJ'), ('tone', 'NN'), ('information', 'NN'), ('determine', 'NN'), ('first', 'RB'), ('candidate', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('valid', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('second', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('invalid', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('reject', 'JJ'), ('second', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('outputting', 'VBG'), ('first', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('encode', 'FW'), ('video', 'NN'), ('frame', 'NN'), ('based', 'VBN'), ('least', 'JJS'), ('part', 'NN'), ('first', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('valid', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('generate', 'NN'), ('coded', 'VBD'), ('bitstream', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('skin', 'VBD'), ('tone', 'NN'), ('information', 'NN'), ('comprises', 'VBZ'), ('skin', 'JJ'), ('probability', 'NN'), ('map', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('first', 'RB'), ('candidate', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('comprises', 'VBZ'), ('rectangular', 'JJ'), ('region', 'NN'), ('processor', 'NN'), ('determine', 'VBP'), ('free', 'JJ'), ('form', 'NN'), ('shape', 'NN'), ('face', 'NN'), ('region', 'NN'), ('corresponding', 'VBG'), ('first', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('wherein', 'VBD'), ('free', 'JJ'), ('form', 'NN'), ('shape', 'NN'), ('face', 'NN'), ('region', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('pixel', 'NN'), ('accuracy', 'NN'), ('small', 'JJ'), ('block', 'NN'), ('pixels', 'NNS'), ('accuracy', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('processor', 'NN'), ('determine', 'VBP'), ('free', 'JJ'), ('form', 'NN'), ('shape', 'NN'), ('face', 'NN'), ('region', 'NN'), ('comprises', 'VBZ'), ('processor', 'NN'), ('generate', 'NN'), ('enhanced', 'VBD'), ('skip', 'JJ'), ('probability', 'NN'), ('map', 'NN'), ('corresponding', 'VBG'), ('first', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('binarize', 'NN'), ('enhanced', 'VBD'), ('skip', 'JJ'), ('probability', 'NN'), ('map', 'NN'), ('overlay', 'NN'), ('binarized', 'VBD'), ('enhanced', 'JJ'), ('skip', 'JJ'), ('probability', 'NN'), ('map', 'NN'), ('least', 'JJS'), ('portion', 'NN'), ('video', 'NN'), ('frame', 'NN'), ('provide', 'VBP'), ('free', 'JJ'), ('form', 'NN'), ('shape', 'NN'), ('face', 'NN'), ('region', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('second', 'JJ'), ('video', 'NN'), ('frame', 'NN'), ('comprises', 'VBZ'), ('non-key', 'JJ'), ('frame', 'NN'), ('video', 'NN'), ('sequence', 'NN'), ('processor', 'NN'), ('perform', 'NN'), ('face', 'NN'), ('detection', 'NN'), ('second', 'JJ'), ('video', 'NN'), ('frame', 'NN'), ('video', 'NN'), ('sequence', 'NN'), ('based', 'VBN'), ('free', 'JJ'), ('form', 'NN'), ('shape', 'NN'), ('face', 'NN'), ('region', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('processor', 'NN'), ('track', 'NN'), ('second', 'JJ'), ('free', 'JJ'), ('form', 'NN'), ('shape', 'NN'), ('face', 'NN'), ('region', 'NN'), ('second', 'JJ'), ('video', 'NN'), ('frame', 'NN'), ('based', 'VBN'), ('free', 'JJ'), ('form', 'NN'), ('shape', 'NN'), ('face', 'NN'), ('region', 'NN'), ('video', 'NN'), ('frame', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('encode', 'VBD'), ('video', 'NN'), ('frame', 'NN'), ('based', 'VBN'), ('least', 'JJS'), ('part', 'NN'), ('first', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('valid', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('comprises', 'VBZ'), ('processor', 'NN'), ('reduce', 'VB'), ('quantization', 'NN'), ('parameter', 'NN'), ('corresponding', 'VBG'), ('first', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('adjust', 'VBP'), ('lambda', 'NN'), ('value', 'NN'), ('first', 'RB'), ('candidate', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('disable', 'JJ'), ('skip', 'NN'), ('coding', 'VBG'), ('first', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('non-transitory', 'JJ'), ('machine', 'NN'), ('readable', 'JJ'), ('medium', 'NN'), ('comprising', 'VBG'), ('plurality', 'NN'), ('instructions', 'NNS'), ('response', 'NN'), ('executed', 'VBD'), ('device', 'NN'), ('cause', 'NN'), ('device', 'NN'), ('perform', 'NN'), ('video', 'NN'), ('coding', 'VBG'), ('based', 'VBN'), ('face', 'NN'), ('detection', 'NN'), ('receiving', 'VBG'), ('video', 'NN'), ('frame', 'NN'), ('comprising', 'VBG'), ('one', 'CD'), ('plurality', 'NN'), ('video', 'NN'), ('frames', 'NNS'), ('video', 'VBP'), ('sequence', 'NN'), ('determining', 'VBG'), ('video', 'NN'), ('frame', 'NN'), ('key', 'JJ'), ('frame', 'NN'), ('video', 'NN'), ('sequence', 'NN'), ('performing', 'VBG'), ('response', 'NN'), ('video', 'NN'), ('frame', 'NN'), ('key', 'JJ'), ('frame', 'NN'), ('video', 'JJ'), ('sequence', 'NN'), ('multi-stage', 'NN'), ('facial', 'JJ'), ('search', 'NN'), ('video', 'NN'), ('frame', 'NN'), ('based', 'VBN'), ('predetermined', 'JJ'), ('feature', 'NN'), ('templates', 'NNS'), ('predetermined', 'VBD'), ('number', 'NN'), ('stages', 'NNS'), ('determine', 'VBP'), ('first', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('second', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('video', 'NN'), ('frame', 'NN'), ('testing', 'VBG'), ('first', 'JJ'), ('second', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('regions', 'NNS'), ('based', 'VBN'), ('skin', 'JJ'), ('tone', 'NN'), ('information', 'NN'), ('determine', 'NN'), ('first', 'RB'), ('candidate', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('valid', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('second', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('invalid', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('rejecting', 'VBG'), ('second', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('outputting', 'VBG'), ('first', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('encoding', 'VBG'), ('video', 'NN'), ('frame', 'NN'), ('based', 'VBN'), ('least', 'JJS'), ('part', 'NN'), ('first', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('valid', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('generate', 'NN'), ('coded', 'VBD'), ('bitstream', 'JJ'), ('non-transitory', 'JJ'), ('machine', 'NN'), ('readable', 'JJ'), ('medium', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('skin', 'VBD'), ('tone', 'NN'), ('information', 'NN'), ('comprises', 'VBZ'), ('skin', 'JJ'), ('probability', 'NN'), ('map', 'VBP'), ('non-transitory', 'JJ'), ('machine', 'NN'), ('readable', 'JJ'), ('medium', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('first', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('comprises', 'VBZ'), ('rectangular', 'JJ'), ('region', 'NN'), ('machine', 'NN'), ('readable', 'JJ'), ('medium', 'NN'), ('comprising', 'VBG'), ('instructions', 'NNS'), ('response', 'NN'), ('executed', 'VBD'), ('device', 'NN'), ('cause', 'NN'), ('device', 'NN'), ('perform', 'NN'), ('video', 'NN'), ('coding', 'VBG'), ('based', 'VBN'), ('face', 'NN'), ('detection', 'NN'), ('determining', 'VBG'), ('free', 'JJ'), ('form', 'NN'), ('shape', 'NN'), ('face', 'NN'), ('region', 'NN'), ('corresponding', 'VBG'), ('first', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('wherein', 'VBD'), ('free', 'JJ'), ('form', 'NN'), ('shape', 'NN'), ('face', 'NN'), ('region', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('pixel', 'NN'), ('accuracy', 'NN'), ('small', 'JJ'), ('block', 'NN'), ('pixels', 'NNS'), ('accuracy', 'IN'), ('non-transitory', 'JJ'), ('machine', 'NN'), ('readable', 'JJ'), ('medium', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('determining', 'VBG'), ('free', 'JJ'), ('form', 'NN'), ('shape', 'NN'), ('face', 'NN'), ('region', 'NN'), ('comprises', 'VBZ'), ('generating', 'VBG'), ('enhanced', 'VBN'), ('skip', 'JJ'), ('probability', 'NN'), ('map', 'NN'), ('corresponding', 'VBG'), ('first', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('binarizing', 'VBG'), ('enhanced', 'VBD'), ('skip', 'JJ'), ('probability', 'NN'), ('map', 'NN'), ('overlaying', 'VBG'), ('binarized', 'VBN'), ('enhanced', 'JJ'), ('skip', 'NN'), ('probability', 'NN'), ('map', 'NN'), ('least', 'JJS'), ('portion', 'NN'), ('video', 'NN'), ('frame', 'NN'), ('provide', 'VBP'), ('free', 'JJ'), ('form', 'NN'), ('shape', 'NN'), ('face', 'NN'), ('region', 'NN'), ('non-transitory', 'JJ'), ('machine', 'NN'), ('readable', 'JJ'), ('medium', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('second', 'JJ'), ('video', 'NN'), ('frame', 'NN'), ('comprises', 'VBZ'), ('non-key', 'JJ'), ('frame', 'NN'), ('video', 'NN'), ('sequence', 'NN'), ('machine', 'NN'), ('readable', 'JJ'), ('medium', 'NN'), ('comprising', 'VBG'), ('instructions', 'NNS'), ('response', 'NN'), ('executed', 'VBD'), ('device', 'NN'), ('cause', 'NN'), ('device', 'NN'), ('perform', 'NN'), ('video', 'NN'), ('coding', 'VBG'), ('based', 'VBN'), ('face', 'NN'), ('detection', 'NN'), ('performing', 'VBG'), ('face', 'NN'), ('detection', 'NN'), ('second', 'JJ'), ('video', 'NN'), ('frame', 'NN'), ('video', 'NN'), ('sequence', 'NN'), ('based', 'VBN'), ('free', 'JJ'), ('form', 'NN'), ('shape', 'NN'), ('face', 'NN'), ('region', 'NN'), ('non-transitory', 'JJ'), ('machine', 'NN'), ('readable', 'JJ'), ('medium', 'NN'), ('claim', 'NN'), ('machine', 'NN'), ('readable', 'JJ'), ('medium', 'NN'), ('comprising', 'VBG'), ('instructions', 'NNS'), ('response', 'NN'), ('executed', 'VBD'), ('device', 'NN'), ('cause', 'NN'), ('device', 'NN'), ('perform', 'NN'), ('video', 'NN'), ('coding', 'VBG'), ('based', 'VBN'), ('face', 'NN'), ('detection', 'NN'), ('tracking', 'VBG'), ('second', 'JJ'), ('free', 'JJ'), ('form', 'NN'), ('shape', 'NN'), ('face', 'NN'), ('region', 'NN'), ('second', 'JJ'), ('video', 'NN'), ('frame', 'NN'), ('based', 'VBN'), ('free', 'JJ'), ('form', 'NN'), ('shape', 'NN'), ('face', 'NN'), ('region', 'NN'), ('video', 'NN'), ('frame', 'NN'), ('non-transitory', 'JJ'), ('machine', 'NN'), ('readable', 'JJ'), ('medium', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('encoding', 'VBG'), ('video', 'NN'), ('frame', 'NN'), ('based', 'VBN'), ('least', 'JJS'), ('part', 'NN'), ('first', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('valid', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('comprises', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('reducing', 'VBG'), ('quantization', 'NN'), ('parameter', 'NN'), ('corresponding', 'VBG'), ('first', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('adjusting', 'VBG'), ('lambda', 'NN'), ('value', 'NN'), ('first', 'RB'), ('candidate', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('disabling', 'VBG'), ('skip', 'NN'), ('coding', 'VBG'), ('first', 'JJ'), ('candidate', 'NN'), ('face', 'NN'), ('region', 'NN'), ('method', 'NN'), ('managing', 'VBG'), ('smart', 'JJ'), ('database', 'NN'), ('stores', 'NNS'), ('facial', 'JJ'), ('images', 'NNS'), ('face', 'VBP'), ('recognition', 'NN'), ('comprising', 'VBG'), ('steps', 'NNS'), ('managing', 'VBG'), ('device', 'NN'), ('performing', 'VBG'), ('process', 'NN'), ('counting', 'VBG'), ('one', 'CD'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('corresponding', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('specific', 'JJ'), ('person', 'NN'), ('stored', 'VBD'), ('smart', 'JJ'), ('database', 'NN'), ('new', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('face', 'VBP'), ('recognition', 'NN'), ('continuously', 'RB'), ('stored', 'VBD'), ('process', 'NN'), ('determining', 'VBG'), ('whether', 'IN'), ('first', 'JJ'), ('counted', 'VBN'), ('value', 'NN'), ('representing', 'VBG'), ('count', 'NN'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('satisfies', 'NNS'), ('preset', 'VBP'), ('first', 'RB'), ('set', 'VBN'), ('value', 'NN'), ('b', 'NN'), ('first', 'RB'), ('counted', 'VBD'), ('value', 'NN'), ('determined', 'VBD'), ('satisfying', 'VBG'), ('first', 'RB'), ('set', 'VBN'), ('value', 'NN'), ('managing', 'VBG'), ('device', 'NN'), ('performing', 'VBG'), ('process', 'NN'), ('inputting', 'VBG'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('neural', 'JJ'), ('aggregation', 'NN'), ('network', 'NN'), ('thereby', 'RB'), ('allow', 'VB'), ('neural', 'JJ'), ('aggregation', 'NN'), ('network', 'NN'), ('generate', 'VBP'), ('quality', 'NN'), ('scores', 'NNS'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('aggregation', 'VBP'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('process', 'NN'), ('sorting', 'VBG'), ('quality', 'NN'), ('scores', 'NNS'), ('corresponding', 'VBG'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('descending', 'VBG'), ('order', 'NN'), ('quality', 'NN'), ('scores', 'VBZ'), ('process', 'NN'), ('counting', 'NN'), ('sorted', 'VBN'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('descending', 'VBG'), ('order', 'NN'), ('second', 'JJ'), ('counted', 'VBN'), ('value', 'NN'), ('represents', 'VBZ'), ('number', 'NN'), ('counted', 'VBN'), ('part', 'NN'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('becomes', 'VBZ'), ('equal', 'JJ'), ('preset', 'JJ'), ('second', 'NN'), ('set', 'VBN'), ('value', 'NN'), ('process', 'NN'), ('deleting', 'VBG'), ('uncounted', 'JJ'), ('part', 'NN'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('smart', 'JJ'), ('database', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('step', 'NN'), ('c', 'RB'), ('managing', 'VBG'), ('device', 'NN'), ('performing', 'VBG'), ('process', 'NN'), ('generating', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('optimal', 'JJ'), ('feature', 'NN'), ('weighted', 'VBD'), ('summation', 'NN'), ('one', 'CD'), ('features', 'VBZ'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('using', 'VBG'), ('counted', 'JJ'), ('part', 'NN'), ('quality', 'NN'), ('scores', 'VBZ'), ('process', 'JJ'), ('setting', 'VBG'), ('optimal', 'JJ'), ('feature', 'NN'), ('representative', 'JJ'), ('face', 'NN'), ('corresponding', 'VBG'), ('specific', 'JJ'), ('person', 'NN'), ('method', 'JJ'), ('claim', 'NN'), ('wherein', 'JJ'), ('step', 'NN'), ('b', 'NN'), ('managing', 'VBG'), ('device', 'NN'), ('performs', 'NNS'), ('process', 'NN'), ('inputting', 'VBG'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('cnn', 'VBP'), ('neural', 'JJ'), ('aggregation', 'NN'), ('network', 'NN'), ('thereby', 'RB'), ('allow', 'VB'), ('cnn', 'NN'), ('generate', 'NN'), ('one', 'CD'), ('features', 'VBZ'), ('corresponding', 'VBG'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('process', 'NN'), ('inputting', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('feature', 'NN'), ('vector', 'NN'), ('features', 'NNS'), ('embedded', 'VBD'), ('aggregation', 'NN'), ('module', 'NN'), ('including', 'VBG'), ('least', 'JJS'), ('two', 'CD'), ('attention', 'NN'), ('blocks', 'NNS'), ('thereby', 'RB'), ('allow', 'VB'), ('aggregation', 'NN'), ('module', 'NN'), ('generate', 'VBP'), ('quality', 'NN'), ('scores', 'NNS'), ('features', 'VBZ'), ('method', 'JJ'), ('claim', 'NN'), ('wherein', 'JJ'), ('step', 'NN'), ('b', 'NN'), ('managing', 'VBG'), ('device', 'NN'), ('performs', 'NNS'), ('process', 'NN'), ('matching', 'VBG'), ('i-', 'JJ'), ('one', 'CD'), ('features', 'VBZ'), ('corresponding', 'VBG'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('stored', 'VBN'), ('smart', 'JJ'), ('database', 'NN'), ('i-', 'JJ'), ('quality', 'NN'), ('scores', 'NNS'), ('ii', 'VBP'), ('specific', 'JJ'), ('person', 'NN'), ('process', 'NN'), ('storing', 'VBG'), ('matched', 'VBN'), ('features', 'NNS'), ('matched', 'VBN'), ('quality', 'NN'), ('scores', 'NNS'), ('smart', 'VBP'), ('database', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('step', 'NN'), ('managing', 'VBG'), ('device', 'NN'), ('performing', 'VBG'), ('one', 'CD'), ('process', 'NN'), ('learning', 'VBG'), ('face', 'NN'), ('recognition', 'NN'), ('system', 'NN'), ('using', 'VBG'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('corresponding', 'VBG'), ('specific', 'JJ'), ('person', 'NN'), ('stored', 'VBD'), ('smart', 'JJ'), ('database', 'NN'), ('ii', 'NN'), ('process', 'NN'), ('transmitting', 'VBG'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('corresponding', 'VBG'), ('specific', 'JJ'), ('person', 'NN'), ('learning', 'JJ'), ('device', 'NN'), ('corresponding', 'VBG'), ('face', 'NN'), ('recognition', 'NN'), ('system', 'NN'), ('thereby', 'RB'), ('allow', 'VB'), ('learning', 'VBG'), ('device', 'NN'), ('learn', 'FW'), ('face', 'NN'), ('recognition', 'NN'), ('system', 'NN'), ('using', 'VBG'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('method', 'VBP'), ('claim', 'NN'), ('wherein', 'JJ'), ('neural', 'JJ'), ('aggregation', 'NN'), ('network', 'NN'), ('learned', 'VBD'), ('learning', 'JJ'), ('device', 'NN'), ('repeating', 'VBG'), ('process', 'NN'), ('inputting', 'VBG'), ('multiple', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('training', 'VBG'), ('corresponding', 'JJ'), ('image', 'NN'), ('set', 'VBN'), ('single', 'JJ'), ('face', 'NN'), ('video', 'NN'), ('single', 'JJ'), ('face', 'NN'), ('cnn', 'JJ'), ('neural', 'JJ'), ('aggregation', 'NN'), ('network', 'NN'), ('thereby', 'RB'), ('allow', 'VB'), ('cnn', 'NN'), ('generate', 'NN'), ('one', 'CD'), ('features', 'VBZ'), ('training', 'VBG'), ('applying', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('convolution', 'NN'), ('operation', 'NN'), ('facial', 'JJ'), ('images', 'NNS'), ('training', 'VBG'), ('ii', 'JJ'), ('process', 'NN'), ('inputting', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('feature', 'NN'), ('vector', 'NN'), ('training', 'NN'), ('features', 'NNS'), ('training', 'VBG'), ('embedded', 'JJ'), ('aggregation', 'NN'), ('module', 'NN'), ('including', 'VBG'), ('least', 'JJS'), ('two', 'CD'), ('attention', 'NN'), ('blocks', 'NNS'), ('neural', 'JJ'), ('aggregation', 'NN'), ('network', 'NN'), ('thereby', 'RB'), ('allow', 'JJ'), ('aggregation', 'NN'), ('module', 'NN'), ('generate', 'VBP'), ('quality', 'NN'), ('scores', 'NNS'), ('training', 'VBG'), ('features', 'NNS'), ('training', 'VBG'), ('aggregation', 'NN'), ('features', 'NNS'), ('training', 'VBG'), ('using', 'VBG'), ('one', 'CD'), ('attention', 'NN'), ('parameters', 'NNS'), ('learned', 'VBD'), ('previous', 'JJ'), ('iteration', 'NN'), ('iii', 'NN'), ('process', 'NN'), ('outputting', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('optimal', 'JJ'), ('feature', 'NN'), ('training', 'NN'), ('weighted', 'JJ'), ('summation', 'NN'), ('features', 'NNS'), ('training', 'VBG'), ('using', 'VBG'), ('quality', 'NN'), ('scores', 'NNS'), ('training', 'VBG'), ('iv', 'JJ'), ('process', 'NN'), ('updating', 'VBG'), ('attention', 'NN'), ('parameters', 'NNS'), ('learned', 'VBD'), ('previous', 'JJ'), ('iteration', 'NN'), ('least', 'JJS'), ('two', 'CD'), ('attention', 'NN'), ('blocks', 'NNS'), ('one', 'CD'), ('losses', 'NNS'), ('minimized', 'VBN'), ('outputted', 'JJ'), ('loss', 'NN'), ('layer', 'NN'), ('referring', 'VBG'), ('optimal', 'JJ'), ('feature', 'NN'), ('training', 'VBG'), ('corresponding', 'VBG'), ('ground', 'NN'), ('truth', 'NN'), ('managing', 'VBG'), ('device', 'NN'), ('managing', 'VBG'), ('smart', 'JJ'), ('database', 'NN'), ('stores', 'NNS'), ('facial', 'JJ'), ('images', 'NNS'), ('face', 'VBP'), ('recognition', 'NN'), ('comprising', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('memory', 'NN'), ('stores', 'NNS'), ('instructions', 'NNS'), ('least', 'VBP'), ('one', 'CD'), ('processor', 'NN'), ('configured', 'VBD'), ('execute', 'JJ'), ('instructions', 'NNS'), ('perform', 'VB'), ('support', 'NN'), ('another', 'DT'), ('device', 'NN'), ('perform', 'NN'), ('process', 'NN'), ('counting', 'VBG'), ('one', 'CD'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('corresponding', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('specific', 'JJ'), ('person', 'NN'), ('stored', 'VBD'), ('smart', 'JJ'), ('database', 'NN'), ('new', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('face', 'VBP'), ('recognition', 'NN'), ('continuously', 'RB'), ('stored', 'VBD'), ('process', 'NN'), ('determining', 'VBG'), ('whether', 'IN'), ('first', 'JJ'), ('counted', 'VBN'), ('value', 'NN'), ('representing', 'VBG'), ('count', 'NN'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('satisfies', 'NNS'), ('preset', 'VBP'), ('first', 'RB'), ('set', 'VBN'), ('value', 'NN'), ('ii', 'NN'), ('first', 'RB'), ('counted', 'VBD'), ('value', 'NN'), ('determined', 'VBD'), ('satisfying', 'VBG'), ('first', 'RB'), ('set', 'VBN'), ('value', 'NN'), ('process', 'NN'), ('inputting', 'VBG'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('neural', 'JJ'), ('aggregation', 'NN'), ('network', 'NN'), ('thereby', 'RB'), ('allow', 'VB'), ('neural', 'JJ'), ('aggregation', 'NN'), ('network', 'NN'), ('generate', 'VBP'), ('quality', 'NN'), ('scores', 'NNS'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('aggregation', 'VBP'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('process', 'NN'), ('sorting', 'VBG'), ('quality', 'NN'), ('scores', 'NNS'), ('corresponding', 'VBG'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('descending', 'VBG'), ('order', 'NN'), ('quality', 'NN'), ('scores', 'VBZ'), ('process', 'NN'), ('counting', 'NN'), ('sorted', 'VBN'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('descending', 'VBG'), ('order', 'NN'), ('second', 'JJ'), ('counted', 'VBN'), ('value', 'NN'), ('represents', 'VBZ'), ('number', 'NN'), ('counted', 'VBN'), ('part', 'NN'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('becomes', 'VBZ'), ('equal', 'JJ'), ('preset', 'JJ'), ('second', 'NN'), ('set', 'VBN'), ('value', 'NN'), ('process', 'NN'), ('deleting', 'VBG'), ('uncounted', 'JJ'), ('part', 'NN'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('smart', 'VBP'), ('database', 'NN'), ('managing', 'VBG'), ('device', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('processor', 'NN'), ('performs', 'NNS'), ('iii', 'VBP'), ('process', 'NN'), ('generating', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('optimal', 'JJ'), ('feature', 'NN'), ('weighted', 'VBD'), ('summation', 'NN'), ('one', 'CD'), ('features', 'VBZ'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('using', 'VBG'), ('counted', 'JJ'), ('part', 'NN'), ('quality', 'NN'), ('scores', 'VBZ'), ('process', 'JJ'), ('setting', 'VBG'), ('optimal', 'JJ'), ('feature', 'NN'), ('representative', 'JJ'), ('face', 'NN'), ('corresponding', 'VBG'), ('specific', 'JJ'), ('person', 'NN'), ('managing', 'VBG'), ('device', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('process', 'NN'), ('ii', 'NN'), ('processor', 'NN'), ('performs', 'NNS'), ('process', 'NN'), ('inputting', 'VBG'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('cnn', 'VBP'), ('neural', 'JJ'), ('aggregation', 'NN'), ('network', 'NN'), ('thereby', 'RB'), ('allow', 'VB'), ('cnn', 'NN'), ('generate', 'NN'), ('one', 'CD'), ('features', 'VBZ'), ('corresponding', 'VBG'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('process', 'NN'), ('inputting', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('feature', 'NN'), ('vector', 'NN'), ('features', 'NNS'), ('embedded', 'VBD'), ('aggregation', 'NN'), ('module', 'NN'), ('including', 'VBG'), ('least', 'JJS'), ('two', 'CD'), ('attention', 'NN'), ('blocks', 'NNS'), ('thereby', 'RB'), ('allow', 'VB'), ('aggregation', 'NN'), ('module', 'NN'), ('generate', 'VBP'), ('quality', 'NN'), ('scores', 'NNS'), ('features', 'VBZ'), ('managing', 'VBG'), ('device', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('process', 'NN'), ('ii', 'NN'), ('processor', 'NN'), ('performs', 'NNS'), ('process', 'NN'), ('matching', 'VBG'), ('i-', 'JJ'), ('one', 'CD'), ('features', 'VBZ'), ('corresponding', 'VBG'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('stored', 'VBN'), ('smart', 'JJ'), ('database', 'NN'), ('i-', 'JJ'), ('quality', 'NN'), ('scores', 'NNS'), ('ii', 'VBP'), ('specific', 'JJ'), ('person', 'NN'), ('process', 'NN'), ('storing', 'VBG'), ('matched', 'VBN'), ('features', 'NNS'), ('matched', 'VBN'), ('quality', 'NN'), ('scores', 'NNS'), ('smart', 'VBP'), ('database', 'NN'), ('managing', 'VBG'), ('device', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('processor', 'NN'), ('performs', 'NNS'), ('iv', 'VBP'), ('one', 'CD'), ('process', 'NN'), ('learning', 'VBG'), ('face', 'NN'), ('recognition', 'NN'), ('system', 'NN'), ('using', 'VBG'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('corresponding', 'VBG'), ('specific', 'JJ'), ('person', 'NN'), ('stored', 'VBD'), ('smart', 'JJ'), ('database', 'NN'), ('ii', 'NN'), ('process', 'NN'), ('transmitting', 'VBG'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('corresponding', 'VBG'), ('specific', 'JJ'), ('person', 'NN'), ('learning', 'JJ'), ('device', 'NN'), ('corresponding', 'VBG'), ('face', 'NN'), ('recognition', 'NN'), ('system', 'NN'), ('thereby', 'RB'), ('allow', 'VB'), ('learning', 'VBG'), ('device', 'NN'), ('learn', 'FW'), ('face', 'NN'), ('recognition', 'NN'), ('system', 'NN'), ('using', 'VBG'), ('specific', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('managing', 'VBG'), ('device', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('neural', 'JJ'), ('aggregation', 'NN'), ('network', 'NN'), ('learned', 'VBD'), ('learning', 'JJ'), ('device', 'NN'), ('repeating', 'VBG'), ('process', 'NN'), ('inputting', 'VBG'), ('multiple', 'JJ'), ('facial', 'JJ'), ('images', 'NNS'), ('training', 'VBG'), ('corresponding', 'JJ'), ('image', 'NN'), ('set', 'VBN'), ('single', 'JJ'), ('face', 'NN'), ('video', 'NN'), ('single', 'JJ'), ('face', 'NN'), ('cnn', 'JJ'), ('neural', 'JJ'), ('aggregation', 'NN'), ('network', 'NN'), ('thereby', 'RB'), ('allow', 'VB'), ('cnn', 'NN'), ('generate', 'NN'), ('one', 'CD'), ('features', 'VBZ'), ('training', 'VBG'), ('applying', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('convolution', 'NN'), ('operation', 'NN'), ('facial', 'JJ'), ('images', 'NNS'), ('training', 'VBG'), ('ii', 'JJ'), ('process', 'NN'), ('inputting', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('feature', 'NN'), ('vector', 'NN'), ('training', 'NN'), ('features', 'NNS'), ('training', 'VBG'), ('embedded', 'JJ'), ('aggregation', 'NN'), ('module', 'NN'), ('including', 'VBG'), ('least', 'JJS'), ('two', 'CD'), ('attention', 'NN'), ('blocks', 'NNS'), ('neural', 'JJ'), ('aggregation', 'NN'), ('network', 'NN'), ('thereby', 'RB'), ('allow', 'JJ'), ('aggregation', 'NN'), ('module', 'NN'), ('generate', 'VBP'), ('quality', 'NN'), ('scores', 'NNS'), ('training', 'VBG'), ('features', 'NNS'), ('training', 'VBG'), ('aggregation', 'NN'), ('features', 'NNS'), ('training', 'VBG'), ('using', 'VBG'), ('one', 'CD'), ('attention', 'NN'), ('parameters', 'NNS'), ('learned', 'VBD'), ('previous', 'JJ'), ('iteration', 'NN'), ('iii', 'NN'), ('process', 'NN'), ('outputting', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('optimal', 'JJ'), ('feature', 'NN'), ('training', 'NN'), ('weighted', 'JJ'), ('summation', 'NN'), ('features', 'NNS'), ('training', 'VBG'), ('using', 'VBG'), ('quality', 'NN'), ('scores', 'NNS'), ('training', 'VBG'), ('iv', 'JJ'), ('process', 'NN'), ('updating', 'VBG'), ('attention', 'NN'), ('parameters', 'NNS'), ('learned', 'VBD'), ('previous', 'JJ'), ('iteration', 'NN'), ('least', 'JJS'), ('two', 'CD'), ('attention', 'NN'), ('blocks', 'NNS'), ('one', 'CD'), ('losses', 'NNS'), ('minimized', 'VBN'), ('outputted', 'JJ'), ('loss', 'NN'), ('layer', 'NN'), ('referring', 'VBG'), ('optimal', 'JJ'), ('feature', 'NN'), ('training', 'VBG'), ('corresponding', 'VBG'), ('ground', 'NN'), ('truth', 'NN'), ('object', 'IN'), ('data', 'NNS'), ('processing', 'VBG'), ('system', 'NN'), ('comprising', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('processor', 'NN'), ('configured', 'VBD'), ('execute', 'CC'), ('least', 'JJS'), ('one', 'CD'), ('implementation', 'NN'), ('plurality', 'NN'), ('recognition', 'NN'), ('algorithms', 'RB'), ('stored', 'VBD'), ('least', 'JJS'), ('one', 'CD'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('storage', 'NN'), ('medium', 'NN'), ('recognition', 'NN'), ('algorithm', 'IN'), ('feature', 'NN'), ('density', 'NN'), ('selection', 'NN'), ('criteria', 'NNS'), ('data', 'NNS'), ('preprocessing', 'VBG'), ('code', 'NN'), ('executed', 'VBD'), ('least', 'JJS'), ('one', 'CD'), ('processor', 'NN'), ('data', 'NNS'), ('preprocessing', 'VBG'), ('code', 'NN'), ('comprising', 'VBG'), ('invariant', 'JJ'), ('feature', 'NN'), ('identification', 'NN'), ('algorithm', 'RB'), ('configured', 'VBD'), ('obtain', 'VB'), ('digital', 'JJ'), ('representation', 'NN'), ('scene', 'NN'), ('scene', 'NN'), ('comprising', 'VBG'), ('one', 'CD'), ('textual', 'JJ'), ('media', 'NNS'), ('generate', 'NN'), ('set', 'VBN'), ('invariant', 'JJ'), ('features', 'NNS'), ('applying', 'VBG'), ('invariant', 'JJ'), ('feature', 'NN'), ('identification', 'NN'), ('algorithm', 'IN'), ('digital', 'JJ'), ('representation', 'NN'), ('cluster', 'NN'), ('set', 'VBN'), ('invariant', 'JJ'), ('features', 'NNS'), ('regions', 'NNS'), ('interest', 'NN'), ('digital', 'JJ'), ('representation', 'NN'), ('scene', 'NN'), ('region', 'NN'), ('interest', 'NN'), ('region', 'NN'), ('feature', 'NN'), ('density', 'NN'), ('classify', 'VB'), ('region', 'NN'), ('classifier', 'JJR'), ('code', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('regions', 'NNS'), ('interest', 'NN'), ('according', 'VBG'), ('object', 'JJ'), ('type', 'NN'), ('function', 'NN'), ('attributes', 'VBZ'), ('derived', 'JJ'), ('region', 'NN'), ('feature', 'NN'), ('density', 'NN'), ('digital', 'JJ'), ('representation', 'NN'), ('wherein', 'VBD'), ('least', 'JJS'), ('one', 'CD'), ('classified', 'JJ'), ('regions', 'NNS'), ('interest', 'NN'), ('corresponds', 'NNS'), ('text', 'JJ'), ('use', 'NN'), ('classification', 'NN'), ('result', 'NN'), ('corresponding', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('regions', 'NNS'), ('interest', 'NN'), ('classify', 'NN'), ('another', 'DT'), ('regions', 'NNS'), ('interest', 'NN'), ('according', 'VBG'), ('object', 'JJ'), ('type', 'NN'), ('wherein', 'NN'), ('another', 'DT'), ('regions', 'NNS'), ('interest', 'NN'), ('corresponds', 'VBZ'), ('region', 'NN'), ('interest', 'NN'), ('images', 'NNS'), ('system', 'NN'), ('claim', 'VBP'), ('wherein', 'IN'), ('preprocessing', 'VBG'), ('code', 'NN'), ('based', 'VBN'), ('feature', 'NN'), ('density', 'NN'), ('selection', 'NN'), ('criteria', 'NNS'), ('determines', 'VBZ'), ('ocr', 'JJ'), ('algorithm', 'NN'), ('applicable', 'JJ'), ('text', 'JJ'), ('recognition', 'NN'), ('algorithms', 'NN'), ('applicable', 'JJ'), ('aspects', 'NNS'), ('photographs', 'VBP'), ('logos', 'JJ'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('user', 'JJ'), ('creates', 'NNS'), ('user', 'VBP'), ('profile', 'IN'), ('camera-equipped', 'JJ'), ('smartphone', 'NN'), ('includes', 'VBZ'), ('information', 'NN'), ('user', 'NN'), ('visually', 'RB'), ('impaired', 'JJ'), ('causes', 'NNS'), ('prioritized', 'JJ'), ('execution', 'NN'), ('ocr', 'IN'), ('algorithm', 'JJ'), ('text', 'JJ'), ('reader', 'NN'), ('program', 'NN'), ('begins', 'VBZ'), ('reading', 'VBG'), ('text', 'IN'), ('user', 'JJ'), ('quickly', 'RB'), ('possible', 'JJ'), ('system', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('audio', 'JJ'), ('tactile', 'NN'), ('feedback', 'NN'), ('mechanism', 'NN'), ('helps', 'VBZ'), ('user', 'JJ'), ('position', 'NN'), ('smart', 'NN'), ('phone', 'NN'), ('relative', 'JJ'), ('text', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('``', '``'), ('hold', 'VB'), ('still', 'RB'), (\"''\", \"''\"), ('audio', 'JJ'), ('feedback', 'NN'), ('signal', 'JJ'), ('sent', 'VBD'), ('user', 'JJ'), ('text', 'NN'), ('center', 'NN'), ('captured', 'VBN'), ('scene', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('digital', 'JJ'), ('representation', 'NN'), ('comprises', 'NNS'), ('least', 'VBP'), ('one', 'CD'), ('following', 'VBG'), ('types', 'NNS'), ('digital', 'JJ'), ('data', 'NNS'), ('image', 'NN'), ('data', 'NNS'), ('video', 'NN'), ('data', 'NNS'), ('audio', 'RB'), ('data', 'NNS'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('invariant', 'JJ'), ('feature', 'NN'), ('identification', 'NN'), ('algorithm', 'NN'), ('comprises', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('following', 'VBG'), ('feature', 'NN'), ('identification', 'NN'), ('algorithms', 'IN'), ('fast', 'JJ'), ('sift', 'NN'), ('freak', 'NN'), ('brisk', 'JJ'), ('harris', 'NN'), ('daisy', 'NN'), ('mser', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('invariant', 'JJ'), ('feature', 'NN'), ('identification', 'NN'), ('algorithm', 'NN'), ('includes', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('following', 'VBG'), ('edge', 'NN'), ('detection', 'NN'), ('algorithm', 'NN'), ('corner', 'NN'), ('detection', 'NN'), ('algorithm', 'JJ'), ('saliency', 'NN'), ('map', 'NN'), ('algorithm', 'NN'), ('curve', 'NN'), ('detection', 'NN'), ('algorithm', 'IN'), ('texton', 'NN'), ('identification', 'NN'), ('algorithm', 'IN'), ('wavelets', 'NNS'), ('algorithm', 'JJ'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('least', 'JJS'), ('one', 'CD'), ('region', 'NN'), ('interest', 'NN'), ('represents', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('physical', 'JJ'), ('object', 'NN'), ('scene', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('least', 'JJS'), ('one', 'CD'), ('region', 'NN'), ('interest', 'NN'), ('represents', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('textual', 'JJ'), ('media', 'NNS'), ('scene', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'JJ'), ('region', 'NN'), ('interest', 'NN'), ('represents', 'VBZ'), ('document', 'JJ'), ('textual', 'JJ'), ('media', 'NNS'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'JJ'), ('region', 'NN'), ('interest', 'NN'), ('represents', 'VBZ'), ('financial', 'JJ'), ('document', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'JJ'), ('region', 'NN'), ('interest', 'NN'), ('represents', 'VBZ'), ('structured', 'VBN'), ('document', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('least', 'JJS'), ('one', 'CD'), ('implementation', 'NN'), ('plurality', 'NN'), ('recognition', 'NN'), ('algorithms', 'VBZ'), ('includes', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('following', 'VBG'), ('template', 'NN'), ('driven', 'VBN'), ('algorithm', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('algorithm', 'RB'), ('optical', 'JJ'), ('character', 'NN'), ('recognition', 'NN'), ('algorithm', 'IN'), ('speech', 'NN'), ('recognition', 'NN'), ('algorithm', 'IN'), ('object', 'JJ'), ('recognition', 'NN'), ('algorithm', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('data', 'NNS'), ('preprocessing', 'VBG'), ('code', 'NN'), ('configured', 'VBD'), ('assign', 'JJ'), ('region', 'NN'), ('interest', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('recognition', 'NN'), ('algorithm', 'NN'), ('function', 'NN'), ('scene', 'NN'), ('context', 'NN'), ('derived', 'VBD'), ('digital', 'JJ'), ('representation', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'WRB'), ('scene', 'NN'), ('context', 'NN'), ('includes', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('following', 'VBG'), ('types', 'NNS'), ('data', 'NNS'), ('location', 'NN'), ('position', 'NN'), ('time', 'NN'), ('user', 'JJ'), ('identity', 'NN'), ('news', 'NN'), ('event', 'NN'), ('medical', 'JJ'), ('event', 'NN'), ('promotion', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('mobile', 'JJ'), ('device', 'NN'), ('comprising', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('implementation', 'NN'), ('plurality', 'NN'), ('recognition', 'NN'), ('algorithms', 'IN'), ('data', 'NNS'), ('preprocessing', 'VBG'), ('code', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'VBP'), ('mobile', 'JJ'), ('device', 'NN'), ('comprises', 'NNS'), ('least', 'VBP'), ('one', 'CD'), ('following', 'VBG'), ('smart', 'JJ'), ('phone', 'NN'), ('tablet', 'NN'), ('wearable', 'JJ'), ('glass', 'NN'), ('toy', 'NN'), ('vehicle', 'NN'), ('computer', 'NN'), ('phablet', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('network-accessible', 'JJ'), ('server', 'NN'), ('device', 'NN'), ('comprising', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('implementation', 'NN'), ('plurality', 'NN'), ('recognition', 'NN'), ('algorithms', 'IN'), ('data', 'NNS'), ('preprocessing', 'VBG'), ('code', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('object', 'VBP'), ('type', 'NN'), ('includes', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('following', 'VBG'), ('face', 'NN'), ('animal', 'JJ'), ('vehicle', 'NN'), ('document', 'NN'), ('plant', 'NN'), ('building', 'NN'), ('appliance', 'NN'), ('clothing', 'NN'), ('body', 'NN'), ('part', 'NN'), ('toy', 'NN'), ('object', 'VBP'), ('data', 'NNS'), ('processing', 'NN'), ('system', 'NN'), ('comprising', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('processor', 'NN'), ('configured', 'VBD'), ('execute', 'CC'), ('least', 'JJS'), ('one', 'CD'), ('implementation', 'NN'), ('plurality', 'NN'), ('recognition', 'NN'), ('algorithms', 'RB'), ('stored', 'VBD'), ('least', 'JJS'), ('one', 'CD'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('storage', 'NN'), ('medium', 'NN'), ('recognition', 'NN'), ('algorithm', 'IN'), ('feature', 'NN'), ('density', 'NN'), ('selection', 'NN'), ('criteria', 'NNS'), ('data', 'NNS'), ('preprocessing', 'VBG'), ('code', 'NN'), ('executed', 'VBD'), ('least', 'JJS'), ('one', 'CD'), ('processor', 'NN'), ('data', 'NNS'), ('preprocessing', 'VBG'), ('code', 'NN'), ('comprising', 'VBG'), ('invariant', 'JJ'), ('feature', 'NN'), ('identification', 'NN'), ('algorithm', 'RB'), ('configured', 'VBD'), ('obtain', 'VB'), ('digital', 'JJ'), ('representation', 'NN'), ('scene', 'NN'), ('scene', 'NN'), ('comprising', 'VBG'), ('one', 'CD'), ('textual', 'JJ'), ('media', 'NNS'), ('generate', 'NN'), ('set', 'VBN'), ('invariant', 'JJ'), ('features', 'NNS'), ('applying', 'VBG'), ('invariant', 'JJ'), ('feature', 'NN'), ('identification', 'NN'), ('algorithm', 'IN'), ('digital', 'JJ'), ('representation', 'NN'), ('cluster', 'NN'), ('set', 'VBN'), ('invariant', 'JJ'), ('features', 'NNS'), ('regions', 'NNS'), ('interest', 'NN'), ('digital', 'JJ'), ('representation', 'NN'), ('scene', 'NN'), ('region', 'NN'), ('interest', 'NN'), ('region', 'NN'), ('feature', 'NN'), ('density', 'NN'), ('classify', 'VB'), ('region', 'NN'), ('classifier', 'JJR'), ('code', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('regions', 'NNS'), ('interest', 'NN'), ('according', 'VBG'), ('object', 'JJ'), ('type', 'NN'), ('function', 'NN'), ('attributes', 'VBZ'), ('derived', 'JJ'), ('region', 'NN'), ('feature', 'NN'), ('density', 'NN'), ('digital', 'JJ'), ('representation', 'NN'), ('wherein', 'VBD'), ('least', 'JJS'), ('one', 'CD'), ('classified', 'JJ'), ('regions', 'NNS'), ('interest', 'NN'), ('corresponds', 'NNS'), ('text', 'JJ'), ('use', 'NN'), ('classification', 'NN'), ('result', 'NN'), ('corresponding', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('regions', 'NNS'), ('interest', 'NN'), ('classify', 'NN'), ('another', 'DT'), ('regions', 'NNS'), ('interest', 'NN'), ('according', 'VBG'), ('object', 'JJ'), ('type', 'NN'), ('wherein', 'NN'), ('another', 'DT'), ('regions', 'NNS'), ('interest', 'NN'), ('corresponds', 'VBZ'), ('region', 'NN'), ('interest', 'NN'), ('images', 'NNS'), ('assign', 'JJ'), ('region', 'NN'), ('interest', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('recognition', 'NN'), ('algorithm', 'IN'), ('least', 'JJS'), ('one', 'CD'), ('implementation', 'NN'), ('plurality', 'NN'), ('diverse', 'JJ'), ('recognition', 'NN'), ('algorithms', 'NN'), ('function', 'NN'), ('region', 'NN'), ('feature', 'NN'), ('density', 'NN'), ('region', 'NN'), ('interest', 'NN'), ('feature', 'NN'), ('density', 'NN'), ('selection', 'NN'), ('criteria', 'NNS'), ('least', 'VBP'), ('one', 'CD'), ('implementation', 'NN'), ('plurality', 'NN'), ('diverse', 'JJ'), ('recognition', 'NN'), ('algorithms', 'IN'), ('configure', 'NN'), ('assigned', 'VBN'), ('recognition', 'NN'), ('algorithms', 'NN'), ('process', 'NN'), ('respective', 'JJ'), ('regions', 'NNS'), ('interest', 'NN'), ('wherein', 'NN'), ('preprocessing', 'VBG'), ('code', 'NN'), ('based', 'VBN'), ('feature', 'NN'), ('density', 'NN'), ('selection', 'NN'), ('criteria', 'NNS'), ('determines', 'VBZ'), ('ocr', 'JJ'), ('algorithm', 'NN'), ('applicable', 'JJ'), ('text', 'JJ'), ('recognition', 'NN'), ('algorithms', 'NN'), ('applicable', 'JJ'), ('aspects', 'NNS'), ('photographs', 'VBP'), ('logos', 'JJ'), ('device', 'NN'), ('comprising', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('processor', 'NN'), ('configured', 'VBD'), ('execute', 'CC'), ('least', 'JJS'), ('one', 'CD'), ('implementation', 'NN'), ('plurality', 'NN'), ('recognition', 'NN'), ('algorithms', 'RB'), ('stored', 'VBD'), ('least', 'JJS'), ('one', 'CD'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('storage', 'NN'), ('medium', 'NN'), ('recognition', 'NN'), ('algorithm', 'IN'), ('feature', 'NN'), ('density', 'NN'), ('selection', 'NN'), ('criteria', 'NNS'), ('data', 'NNS'), ('preprocessing', 'VBG'), ('code', 'NN'), ('executed', 'VBD'), ('least', 'JJS'), ('one', 'CD'), ('processor', 'NN'), ('data', 'NNS'), ('preprocessing', 'VBG'), ('code', 'NN'), ('comprising', 'VBG'), ('invariant', 'JJ'), ('feature', 'NN'), ('identification', 'NN'), ('algorithm', 'RB'), ('configured', 'VBD'), ('obtain', 'VB'), ('digital', 'JJ'), ('representation', 'NN'), ('scene', 'NN'), ('scene', 'NN'), ('comprising', 'VBG'), ('one', 'CD'), ('textual', 'JJ'), ('media', 'NNS'), ('generate', 'NN'), ('set', 'VBN'), ('invariant', 'JJ'), ('features', 'NNS'), ('applying', 'VBG'), ('invariant', 'JJ'), ('feature', 'NN'), ('identification', 'NN'), ('algorithm', 'IN'), ('digital', 'JJ'), ('representation', 'NN'), ('cluster', 'NN'), ('set', 'VBN'), ('invariant', 'JJ'), ('features', 'NNS'), ('regions', 'NNS'), ('interest', 'NN'), ('digital', 'JJ'), ('representation', 'NN'), ('scene', 'NN'), ('region', 'NN'), ('interest', 'NN'), ('region', 'NN'), ('feature', 'NN'), ('density', 'NN'), ('classify', 'VB'), ('region', 'NN'), ('classifier', 'JJR'), ('code', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('regions', 'NNS'), ('interest', 'NN'), ('according', 'VBG'), ('object', 'JJ'), ('type', 'NN'), ('function', 'NN'), ('attributes', 'VBZ'), ('derived', 'JJ'), ('region', 'NN'), ('feature', 'NN'), ('density', 'NN'), ('digital', 'JJ'), ('representation', 'NN'), ('wherein', 'VBD'), ('least', 'JJS'), ('one', 'CD'), ('classified', 'JJ'), ('regions', 'NNS'), ('interest', 'NN'), ('corresponds', 'NNS'), ('text', 'JJ'), ('use', 'NN'), ('classification', 'NN'), ('result', 'NN'), ('corresponding', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('regions', 'NNS'), ('interest', 'NN'), ('classify', 'NN'), ('another', 'DT'), ('regions', 'NNS'), ('interest', 'NN'), ('according', 'VBG'), ('object', 'JJ'), ('type', 'NN'), ('wherein', 'NN'), ('another', 'DT'), ('regions', 'NNS'), ('interest', 'NN'), ('corresponds', 'VBZ'), ('region', 'NN'), ('interest', 'NN'), ('images', 'NNS'), ('mobile', 'VBP'), ('terminal', 'JJ'), ('comprising', 'NN'), ('front', 'JJ'), ('camera', 'NN'), ('configured', 'VBD'), ('obtain', 'VB'), ('two-dimensional', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('user', 'JJ'), ('glance', 'NN'), ('sensor', 'NN'), ('tilted', 'VBD'), ('certain', 'JJ'), ('angle', 'NN'), ('disposed', 'VBD'), ('adjacent', 'JJ'), ('front', 'JJ'), ('camera', 'NN'), ('obtain', 'VB'), ('metadata', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('controller', 'NN'), ('obtaining', 'VBG'), ('distance', 'NN'), ('glance', 'NN'), ('sensor', 'NN'), ('front', 'NN'), ('camera', 'NN'), ('distance', 'NN'), ('enabling', 'VBG'), ('area', 'NN'), ('overlap', 'IN'), ('region', 'NN'), ('first', 'JJ'), ('region', 'NN'), ('representing', 'VBG'), ('range', 'NN'), ('photographable', 'JJ'), ('front', 'NN'), ('camera', 'NN'), ('overlaps', 'VBZ'), ('second', 'JJ'), ('region', 'NN'), ('representing', 'VBG'), ('range', 'NN'), ('photographable', 'JJ'), ('glance', 'NN'), ('sensor', 'NN'), ('maximum', 'NN'), ('mobile', 'JJ'), ('terminal', 'JJ'), ('claim', 'NN'), ('wherein', 'NN'), ('controller', 'NN'), ('configured', 'VBD'), ('obtain', 'VB'), ('distance', 'NN'), ('enabling', 'VBG'), ('area', 'NN'), ('overlap', 'JJ'), ('region', 'NN'), ('maximum', 'JJ'), ('glance', 'NN'), ('sensor', 'NN'), ('front', 'NN'), ('camera', 'NN'), ('varying', 'VBG'), ('tilting', 'VBG'), ('angle', 'JJ'), ('glance', 'NN'), ('sensor', 'NN'), ('mobile', 'JJ'), ('terminal', 'JJ'), ('claim', 'NN'), ('wherein', 'NN'), ('controller', 'NN'), ('configured', 'VBD'), ('set', 'VBN'), ('distance', 'NN'), ('enabling', 'VBG'), ('area', 'NN'), ('overlap', 'JJ'), ('region', 'NN'), ('maximum', 'JJ'), ('glance', 'NN'), ('sensor', 'NN'), ('front', 'NN'), ('camera', 'NN'), ('tilting', 'VBG'), ('angle', 'JJ'), ('glance', 'NN'), ('sensor', 'NN'), ('optimal', 'JJ'), ('disposition', 'NN'), ('location', 'NN'), ('glance', 'NN'), ('sensor', 'NN'), ('mobile', 'JJ'), ('terminal', 'JJ'), ('claim', 'NN'), ('wherein', 'NN'), ('controller', 'NN'), ('configured', 'VBD'), ('set', 'VBN'), ('disposition', 'NN'), ('location', 'NN'), ('front', 'NN'), ('camera', 'NN'), ('original', 'JJ'), ('point', 'NN'), ('calculates', 'NNS'), ('coordinates', 'NNS'), ('first', 'RB'), ('triangle', 'VBP'), ('representing', 'VBG'), ('first', 'JJ'), ('region', 'NN'), ('based', 'VBN'), ('field', 'NN'), ('view', 'NN'), ('front', 'JJ'), ('camera', 'NN'), ('maximum', 'JJ'), ('photographing', 'VBG'), ('distance', 'NN'), ('front', 'NN'), ('camera', 'NN'), ('mobile', 'JJ'), ('terminal', 'JJ'), ('claim', 'NN'), ('wherein', 'NN'), ('controller', 'NN'), ('configured', 'VBD'), ('calculate', 'JJ'), ('coordinates', 'NNS'), ('second', 'JJ'), ('triangle', 'JJ'), ('representing', 'VBG'), ('second', 'JJ'), ('region', 'NN'), ('based', 'VBN'), ('field', 'NN'), ('view', 'NN'), ('glance', 'NN'), ('sensor', 'NN'), ('maximum', 'NN'), ('photographing', 'VBG'), ('distance', 'NN'), ('glance', 'NN'), ('sensor', 'NN'), ('distance', 'NN'), ('front', 'JJ'), ('camera', 'NN'), ('glance', 'NN'), ('sensor', 'NN'), ('tilting', 'VBG'), ('angle', 'JJ'), ('glance', 'NN'), ('sensor', 'NN'), ('mobile', 'JJ'), ('terminal', 'JJ'), ('claim', 'NN'), ('wherein', 'NN'), ('glance', 'NN'), ('sensor', 'NN'), ('tilted', 'VBD'), ('controller', 'NN'), ('configured', 'JJ'), ('calculate', 'NN'), ('coordinates', 'NNS'), ('third', 'JJ'), ('triangle', 'JJ'), ('representing', 'VBG'), ('third', 'JJ'), ('region', 'NN'), ('photographable', 'JJ'), ('glance', 'NN'), ('sensor', 'NN'), ('controller', 'NN'), ('configured', 'VBD'), ('rotation-convert', 'JJ'), ('coordinates', 'NNS'), ('third', 'JJ'), ('triangle', 'NNS'), ('based', 'VBN'), ('tilting', 'VBG'), ('angle', 'JJ'), ('glance', 'NN'), ('sensor', 'NN'), ('calculate', 'NN'), ('coordinates', 'NNS'), ('second', 'JJ'), ('triangle', 'VBP'), ('mobile', 'JJ'), ('terminal', 'JJ'), ('claim', 'NN'), ('wherein', 'NN'), ('controller', 'NN'), ('configured', 'VBD'), ('calculate', 'NN'), ('coordinates', 'NNS'), ('overlap', 'VBP'), ('region', 'NN'), ('based', 'VBN'), ('coordinates', 'NNS'), ('first', 'JJ'), ('triangle', 'JJ'), ('coordinates', 'NNS'), ('second', 'JJ'), ('triangle', 'NN'), ('calculates', 'NNS'), ('area', 'NN'), ('overlap', 'VBP'), ('region', 'NN'), ('based', 'VBN'), ('coordinates', 'NNS'), ('overlap', 'JJ'), ('region', 'NN'), ('mobile', 'JJ'), ('terminal', 'JJ'), ('claim', 'NN'), ('wherein', 'NN'), ('controller', 'NN'), ('configured', 'VBD'), ('generate', 'JJ'), ('three-dimensional', 'JJ'), ('face', 'NN'), ('information', 'NN'), ('based', 'VBN'), ('face', 'NN'), ('image', 'NN'), ('obtained', 'VBD'), ('front', 'JJ'), ('camera', 'NN'), ('metadata', 'NN'), ('obtained', 'VBD'), ('glance', 'NN'), ('sensor', 'NN'), ('mobile', 'JJ'), ('terminal', 'JJ'), ('claim', 'NN'), ('wherein', 'NN'), ('metadata', 'NN'), ('comprises', 'VBZ'), ('one', 'CD'), ('angle', 'NN'), ('face', 'NN'), ('user', 'NN'), ('size', 'NN'), ('face', 'NN'), ('location', 'NN'), ('face', 'NN'), ('mobile', 'JJ'), ('terminal', 'JJ'), ('claim', 'NN'), ('wherein', 'NN'), ('angle', 'VBD'), ('face', 'NN'), ('comprises', 'NNS'), ('angle', 'VBP'), ('face', 'NN'), ('rotated', 'VBD'), ('one', 'CD'), ('pitch', 'NN'), ('axis', 'NN'), ('roll', 'NN'), ('axis', 'NN'), ('yaw', 'NN'), ('axis', 'VBP'), ('mobile', 'JJ'), ('terminal', 'JJ'), ('claim', 'NN'), ('comprising', 'VBG'), ('memory', 'NN'), ('storing', 'VBG'), ('generated', 'VBD'), ('face', 'NN'), ('information', 'NN'), ('wherein', 'WRB'), ('controller', 'NN'), ('configured', 'VBD'), ('performs', 'NNS'), ('user', 'JJ'), ('authentication', 'NN'), ('process', 'NN'), ('comparing', 'VBG'), ('stored', 'VBD'), ('face', 'NN'), ('information', 'NN'), ('face', 'NN'), ('information', 'NN'), ('obtained', 'VBN'), ('user', 'JJ'), ('authentication', 'NN'), ('mobile', 'JJ'), ('terminal', 'JJ'), ('claim', 'NN'), ('wherein', 'NN'), ('glance', 'NN'), ('sensor', 'NN'), ('controlled', 'VBD'), ('permanently', 'RB'), ('activated', 'VBN'), ('low', 'JJ'), ('power', 'NN'), ('obtain', 'VB'), ('front', 'JJ'), ('image', 'NN'), ('metadata', 'NN'), ('front', 'JJ'), ('image', 'NN'), ('mobile', 'JJ'), ('terminal', 'JJ'), ('claim', 'NN'), ('wherein', 'NN'), ('front', 'JJ'), ('camera', 'NN'), ('glance', 'NN'), ('sensor', 'NN'), ('disposed', 'VBD'), ('line', 'NN'), ('upper', 'JJ'), ('end', 'NN'), ('mobile', 'JJ'), ('terminal', 'NN'), ('mobile', 'JJ'), ('terminal', 'JJ'), ('claim', 'NN'), ('wherein', 'NN'), ('glance', 'NN'), ('sensor', 'NN'), ('tilted', 'VBD'), ('one', 'CD'), ('direction', 'NN'), ('direction', 'NN'), ('direction', 'NN'), ('left', 'VBD'), ('direction', 'NN'), ('right', 'JJ'), ('direction', 'NN'), ('mobile', 'JJ'), ('terminal', 'JJ'), ('claim', 'NN'), ('wherein', 'NN'), ('metadata', 'NN'), ('data', 'NNS'), ('changed', 'VBD'), ('mobile', 'JJ'), ('terminal', 'NN'), ('tilted', 'VBD'), ('external', 'JJ'), ('physical', 'JJ'), ('force', 'NN'), ('method', 'NN'), ('comprising', 'VBG'), ('receiving', 'VBG'), ('smart', 'JJ'), ('television', 'NN'), ('tv', 'NN'), ('indication', 'NN'), ('upcoming', 'VBG'), ('media', 'NNS'), ('programming', 'VBG'), ('wherein', 'NN'), ('upcoming', 'JJ'), ('media', 'NNS'), ('programming', 'VBG'), ('based', 'VBN'), ('user', 'NN'), ('profile', 'NN'), ('identifying', 'VBG'), ('one', 'CD'), ('devices', 'NNS'), ('communication', 'NN'), ('smart', 'JJ'), ('tv', 'NN'), ('one', 'CD'), ('devices', 'NNS'), ('including', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('microphone', 'NN'), ('camera', 'NN'), ('instructing', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('identified', 'JJ'), ('device', 'NN'), ('detect', 'NN'), ('audio', 'NN'), ('signals', 'NNS'), ('using', 'VBG'), ('respective', 'JJ'), ('microphone', 'NN'), ('detect', 'JJ'), ('visual', 'JJ'), ('signals', 'NNS'), ('using', 'VBG'), ('respective', 'JJ'), ('camera', 'NN'), ('selecting', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('device', 'NN'), ('one', 'CD'), ('devices', 'NNS'), ('based', 'VBN'), ('detected', 'JJ'), ('audio', 'JJ'), ('signal', 'NN'), ('detected', 'VBD'), ('visual', 'JJ'), ('signal', 'NN'), ('providing', 'VBG'), ('instructions', 'NNS'), ('selected', 'VBN'), ('device', 'NN'), ('output', 'NN'), ('notification', 'NN'), ('related', 'VBN'), ('upcoming', 'JJ'), ('media', 'NNS'), ('programming', 'VBG'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('upcoming', 'VBG'), ('media', 'NNS'), ('programming', 'VBG'), ('one', 'CD'), ('live', 'JJ'), ('television', 'NN'), ('program', 'NN'), ('recorded', 'VBN'), ('television', 'NN'), ('program', 'NN'), ('broadcast', 'NN'), ('television', 'NN'), ('program', 'NN'), ('application-provided', 'JJ'), ('program', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('selecting', 'VBG'), ('first', 'JJ'), ('device', 'NN'), ('based', 'VBN'), ('detected', 'JJ'), ('audio', 'JJ'), ('signal', 'NN'), ('includes', 'VBZ'), ('recognizing', 'VBG'), ('voice', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('determining', 'VBG'), ('distance', 'NN'), ('recognized', 'VBN'), ('voice', 'NN'), ('wherein', 'NN'), ('selecting', 'VBG'), ('first', 'JJ'), ('device', 'NN'), ('based', 'VBN'), ('determined', 'JJ'), ('distance', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('selecting', 'VBG'), ('first', 'JJ'), ('device', 'NN'), ('based', 'VBN'), ('detected', 'VBN'), ('visual', 'JJ'), ('signals', 'NNS'), ('includes', 'VBZ'), ('recognizing', 'VBG'), ('face', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('recognizing', 'VBG'), ('face', 'NN'), ('includes', 'VBZ'), ('face', 'JJ'), ('recognition', 'NN'), ('technique', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('presenting', 'VBG'), ('smart', 'JJ'), ('tv', 'NN'), ('upcoming', 'VBG'), ('media', 'NNS'), ('programming', 'VBG'), ('favorite', 'JJ'), ('channel', 'NNS'), ('list', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('obtaining', 'VBG'), ('media', 'NNS'), ('programming', 'VBG'), ('viewing', 'VBG'), ('data', 'NNS'), ('wherein', 'RB'), ('media', 'NNS'), ('programming', 'VBG'), ('viewing', 'VBG'), ('data', 'NNS'), ('includes', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('historical', 'JJ'), ('time', 'NN'), ('historical', 'JJ'), ('date', 'NN'), ('one', 'CD'), ('media', 'NNS'), ('programs', 'NNS'), ('viewed', 'VBD'), ('obtaining', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('current', 'JJ'), ('time', 'NN'), ('current', 'JJ'), ('date', 'NN'), ('processing', 'NN'), ('media', 'NNS'), ('programming', 'VBG'), ('viewing', 'VBG'), ('data', 'NNS'), ('determine', 'NN'), ('probability', 'NN'), ('one', 'CD'), ('media', 'NNS'), ('programs', 'NNS'), ('viewed', 'VBD'), ('based', 'VBN'), ('least', 'JJS'), ('one', 'CD'), ('current', 'JJ'), ('time', 'NN'), ('current', 'JJ'), ('date', 'NN'), ('presenting', 'NN'), ('favorite', 'JJ'), ('channel', 'NNS'), ('list', 'NN'), ('based', 'VBN'), ('determined', 'JJ'), ('probability', 'NN'), ('one', 'CD'), ('media', 'NNS'), ('programs', 'NNS'), ('viewed', 'VBD'), ('method', 'JJ'), ('claim', 'NN'), ('wherein', 'NN'), ('processing', 'VBG'), ('media', 'NNS'), ('programming', 'VBG'), ('viewing', 'VBG'), ('data', 'NNS'), ('includes', 'VBZ'), ('employing', 'VBG'), ('neural', 'JJ'), ('network', 'NN'), ('model', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('employing', 'VBG'), ('neural', 'JJ'), ('network', 'NN'), ('model', 'NN'), ('comprises', 'VBZ'), ('determining', 'VBG'), ('duration', 'NN'), ('one', 'CD'), ('media', 'NNS'), ('programs', 'NNS'), ('viewed', 'VBD'), ('least', 'JJS'), ('one', 'CD'), ('historical', 'JJ'), ('time', 'NN'), ('historical', 'JJ'), ('date', 'NN'), ('setting', 'VBG'), ('threshold', 'JJ'), ('time', 'NN'), ('duration', 'NN'), ('comparing', 'VBG'), ('determined', 'VBN'), ('duration', 'NN'), ('threshold', 'JJ'), ('time', 'NN'), ('duration', 'NN'), ('filtering', 'VBG'), ('one', 'CD'), ('media', 'NNS'), ('programs', 'NNS'), ('viewed', 'VBD'), ('threshold', 'JJ'), ('time', 'NN'), ('duration', 'NN'), ('smart', 'JJ'), ('television', 'NN'), ('tv', 'NN'), ('comprising', 'VBG'), ('network', 'NN'), ('interface', 'JJ'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('medium', 'NN'), ('processor', 'NN'), ('communication', 'NN'), ('network', 'NN'), ('interface', 'JJ'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('medium', 'NN'), ('capable', 'JJ'), ('executing', 'VBG'), ('processor-executable', 'JJ'), ('program', 'NN'), ('code', 'NN'), ('stored', 'VBD'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('medium', 'NN'), ('cause', 'NN'), ('smart', 'JJ'), ('tv', 'NN'), ('receive', 'NN'), ('indication', 'NN'), ('upcoming', 'VBG'), ('media', 'NNS'), ('programming', 'VBG'), ('wherein', 'NN'), ('upcoming', 'JJ'), ('media', 'NNS'), ('programming', 'VBG'), ('based', 'VBN'), ('user', 'NN'), ('profile', 'NN'), ('identify', 'VB'), ('one', 'CD'), ('devices', 'NNS'), ('communication', 'NN'), ('smart', 'JJ'), ('tv', 'NN'), ('one', 'CD'), ('devices', 'NNS'), ('including', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('microphone', 'NN'), ('camera', 'NN'), ('instruct', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('identified', 'JJ'), ('device', 'NN'), ('detect', 'NN'), ('audio', 'NN'), ('signals', 'NNS'), ('using', 'VBG'), ('respective', 'JJ'), ('microphone', 'NN'), ('detect', 'JJ'), ('visual', 'JJ'), ('signals', 'NNS'), ('using', 'VBG'), ('respective', 'JJ'), ('camera', 'NN'), ('select', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('device', 'NN'), ('one', 'CD'), ('devices', 'NNS'), ('based', 'VBN'), ('detected', 'JJ'), ('audio', 'JJ'), ('signal', 'NN'), ('detected', 'VBD'), ('visual', 'JJ'), ('signal', 'NN'), ('provide', 'NN'), ('instructions', 'NNS'), ('selected', 'VBN'), ('device', 'NN'), ('output', 'NN'), ('notification', 'NN'), ('related', 'VBN'), ('upcoming', 'JJ'), ('media', 'NNS'), ('programming', 'VBG'), ('smart', 'JJ'), ('tv', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('selecting', 'VBG'), ('first', 'JJ'), ('device', 'NN'), ('based', 'VBN'), ('detected', 'JJ'), ('audio', 'JJ'), ('signal', 'NN'), ('includes', 'VBZ'), ('recognizing', 'VBG'), ('voice', 'NN'), ('smart', 'JJ'), ('tv', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('processor', 'NN'), ('capable', 'JJ'), ('executing', 'VBG'), ('processor-executable', 'JJ'), ('program', 'NN'), ('code', 'NN'), ('determine', 'NN'), ('distance', 'NN'), ('recognized', 'VBN'), ('voice', 'NN'), ('wherein', 'NN'), ('selecting', 'VBG'), ('first', 'JJ'), ('device', 'NN'), ('based', 'VBN'), ('determined', 'JJ'), ('distance', 'NN'), ('smart', 'JJ'), ('tv', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('selecting', 'VBG'), ('first', 'JJ'), ('device', 'NN'), ('based', 'VBN'), ('detected', 'VBN'), ('visual', 'JJ'), ('signals', 'NNS'), ('includes', 'VBZ'), ('detecting', 'VBG'), ('presence', 'NN'), ('user', 'JJ'), ('smart', 'JJ'), ('tv', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('detecting', 'VBG'), ('presence', 'NN'), ('user', 'NN'), ('includes', 'VBZ'), ('employing', 'VBG'), ('one', 'CD'), ('camera', 'NN'), ('microphone', 'NN'), ('fingerprint', 'NN'), ('sensor', 'NN'), ('associated', 'VBN'), ('least', 'JJS'), ('one', 'CD'), ('smart', 'JJ'), ('tv', 'NN'), ('mobile', 'NN'), ('device', 'NN'), ('smartphone', 'NN'), ('laptop', 'JJ'), ('computer', 'NN'), ('tablet', 'NN'), ('device', 'NN'), ('wearable', 'JJ'), ('device', 'NN'), ('internet', 'NN'), ('things', 'NNS'), ('iot', 'JJ'), ('device', 'JJ'), ('internet', 'NN'), ('everything', 'NN'), ('ioe', 'NN'), ('device', 'NN'), ('iot', 'NN'), ('hub', 'NN'), ('ioe', 'NN'), ('hub', 'NN'), ('smart', 'JJ'), ('television', 'NN'), ('tv', 'NN'), ('comprising', 'NN'), ('means', 'VBZ'), ('receiving', 'VBG'), ('indication', 'NN'), ('upcoming', 'VBG'), ('media', 'NNS'), ('programming', 'VBG'), ('wherein', 'NN'), ('upcoming', 'JJ'), ('media', 'NNS'), ('programming', 'VBG'), ('based', 'VBN'), ('user', 'NN'), ('profile', 'NN'), ('means', 'VBZ'), ('identifying', 'VBG'), ('one', 'CD'), ('devices', 'NNS'), ('communication', 'NN'), ('smart', 'JJ'), ('tv', 'NN'), ('one', 'CD'), ('devices', 'NNS'), ('including', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('microphone', 'NN'), ('camera', 'NN'), ('means', 'VBZ'), ('instructing', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('identified', 'JJ'), ('device', 'NN'), ('detect', 'NN'), ('audio', 'NN'), ('signals', 'NNS'), ('using', 'VBG'), ('respective', 'JJ'), ('microphone', 'NN'), ('detect', 'JJ'), ('visual', 'JJ'), ('signals', 'NNS'), ('using', 'VBG'), ('respective', 'JJ'), ('camera', 'NN'), ('means', 'VBZ'), ('selecting', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('device', 'NN'), ('one', 'CD'), ('devices', 'NNS'), ('based', 'VBN'), ('detected', 'JJ'), ('audio', 'JJ'), ('signal', 'NN'), ('detected', 'VBD'), ('visual', 'JJ'), ('signal', 'NN'), ('means', 'NNS'), ('providing', 'VBG'), ('instructions', 'NNS'), ('selected', 'VBN'), ('device', 'NN'), ('output', 'NN'), ('notification', 'NN'), ('related', 'VBN'), ('upcoming', 'JJ'), ('media', 'NNS'), ('programming', 'VBG'), ('smart', 'JJ'), ('tv', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('one', 'CD'), ('devices', 'NNS'), ('includes', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('mobile', 'JJ'), ('device', 'NN'), ('smartphone', 'NN'), ('laptop', 'JJ'), ('computer', 'NN'), ('tablet', 'NN'), ('device', 'NN'), ('wearable', 'JJ'), ('device', 'NN'), ('internet', 'NN'), ('things', 'NNS'), ('iot', 'JJ'), ('device', 'JJ'), ('internet', 'NN'), ('everything', 'NN'), ('ioe', 'NN'), ('device', 'NN'), ('iot', 'NN'), ('hub', 'NN'), ('ioe', 'NN'), ('hub', 'NN'), ('another', 'DT'), ('smart', 'JJ'), ('tv', 'NN'), ('smart', 'JJ'), ('tv', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('upcoming', 'VBG'), ('media', 'NNS'), ('programming', 'VBG'), ('one', 'CD'), ('live', 'JJ'), ('television', 'NN'), ('program', 'NN'), ('recorded', 'VBN'), ('television', 'NN'), ('program', 'NN'), ('broadcast', 'NN'), ('television', 'NN'), ('program', 'NN'), ('application-provided', 'JJ'), ('program', 'NN'), ('smart', 'JJ'), ('tv', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('notification', 'NN'), ('includes', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('push', 'NN'), ('message', 'NN'), ('sms', 'JJ'), ('message', 'NN'), ('waysms', 'JJ'), ('message', 'NN'), ('audio', 'NN'), ('alert', 'NN'), ('audio', 'JJ'), ('message', 'NN'), ('email', 'JJ'), ('message', 'NN'), ('smart', 'JJ'), ('tv', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('presenting', 'VBG'), ('upcoming', 'JJ'), ('media', 'NNS'), ('programming', 'VBG'), ('favorite', 'JJ'), ('channel', 'NNS'), ('list', 'NN'), ('smart', 'JJ'), ('tv', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('means', 'NNS'), ('obtaining', 'VBG'), ('media', 'NNS'), ('programming', 'VBG'), ('viewing', 'VBG'), ('data', 'NNS'), ('wherein', 'RB'), ('media', 'NNS'), ('programming', 'VBG'), ('viewing', 'VBG'), ('data', 'NNS'), ('includes', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('historical', 'JJ'), ('time', 'NN'), ('historical', 'JJ'), ('date', 'NN'), ('one', 'CD'), ('media', 'NNS'), ('programs', 'NNS'), ('viewed', 'VBD'), ('smart', 'JJ'), ('tv', 'NN'), ('means', 'NNS'), ('obtaining', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('current', 'JJ'), ('time', 'NN'), ('current', 'JJ'), ('date', 'NN'), ('means', 'VBZ'), ('processing', 'VBG'), ('media', 'NNS'), ('programming', 'VBG'), ('viewing', 'VBG'), ('data', 'NNS'), ('determine', 'NN'), ('probability', 'NN'), ('one', 'CD'), ('media', 'NNS'), ('programs', 'NNS'), ('viewed', 'VBD'), ('smart', 'JJ'), ('tv', 'NN'), ('based', 'VBN'), ('least', 'JJS'), ('one', 'CD'), ('current', 'JJ'), ('time', 'NN'), ('current', 'JJ'), ('date', 'NN'), ('means', 'NNS'), ('presenting', 'VBG'), ('favorite', 'JJ'), ('channel', 'NNS'), ('list', 'NN'), ('based', 'VBN'), ('determined', 'JJ'), ('probability', 'NN'), ('one', 'CD'), ('media', 'NNS'), ('programs', 'NNS'), ('viewed', 'VBD'), ('smart', 'JJ'), ('tv', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('means', 'VBZ'), ('processing', 'VBG'), ('media', 'NNS'), ('programming', 'VBG'), ('viewing', 'VBG'), ('data', 'NNS'), ('includes', 'VBZ'), ('employing', 'VBG'), ('neural', 'JJ'), ('network', 'NN'), ('model', 'NN'), ('smart', 'JJ'), ('tv', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('employing', 'VBG'), ('neural', 'JJ'), ('network', 'NN'), ('model', 'NN'), ('comprises', 'VBZ'), ('determining', 'VBG'), ('duration', 'NN'), ('one', 'CD'), ('media', 'NNS'), ('programs', 'NNS'), ('viewed', 'VBD'), ('smart', 'JJ'), ('tv', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('historical', 'JJ'), ('time', 'NN'), ('historical', 'JJ'), ('date', 'NN'), ('setting', 'VBG'), ('threshold', 'JJ'), ('time', 'NN'), ('duration', 'NN'), ('comparing', 'VBG'), ('determined', 'VBN'), ('duration', 'NN'), ('threshold', 'JJ'), ('time', 'NN'), ('duration', 'NN'), ('filtering', 'VBG'), ('one', 'CD'), ('media', 'NNS'), ('programs', 'NNS'), ('viewed', 'VBD'), ('threshold', 'JJ'), ('time', 'NN'), ('duration', 'NN'), ('smart', 'JJ'), ('tv', 'NN'), ('claim', 'NN'), ('comprising', 'NN'), ('means', 'VBZ'), ('adjusting', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('volume', 'NN'), ('brightness', 'NN'), ('smart', 'JJ'), ('tv', 'NN'), ('wherein', 'NN'), ('adjusting', 'VBG'), ('based', 'VBN'), ('least', 'JJS'), ('one', 'CD'), ('historical', 'JJ'), ('time', 'NN'), ('historical', 'JJ'), ('date', 'NN'), ('smart', 'JJ'), ('tv', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('means', 'NNS'), ('restricting', 'VBG'), ('access', 'NN'), ('one', 'CD'), ('media', 'NNS'), ('programs', 'NNS'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('medium', 'NN'), ('comprising', 'VBG'), ('processor-executable', 'JJ'), ('program', 'NN'), ('code', 'NN'), ('configured', 'VBD'), ('cause', 'NN'), ('processor', 'NN'), ('smart', 'JJ'), ('television', 'NN'), ('tv', 'NN'), ('receive', 'VBP'), ('indication', 'NN'), ('upcoming', 'JJ'), ('media', 'NNS'), ('programming', 'VBG'), ('wherein', 'NN'), ('upcoming', 'JJ'), ('media', 'NNS'), ('programming', 'VBG'), ('based', 'VBN'), ('user', 'NN'), ('profile', 'NN'), ('identify', 'VB'), ('one', 'CD'), ('devices', 'NNS'), ('communication', 'NN'), ('smart', 'JJ'), ('tv', 'NN'), ('one', 'CD'), ('devices', 'NNS'), ('including', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('microphone', 'NN'), ('camera', 'NN'), ('instruct', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('identified', 'JJ'), ('device', 'NN'), ('detect', 'NN'), ('audio', 'NN'), ('signals', 'NNS'), ('using', 'VBG'), ('respective', 'JJ'), ('microphone', 'NN'), ('detect', 'JJ'), ('visual', 'JJ'), ('signals', 'NNS'), ('using', 'VBG'), ('respective', 'JJ'), ('camera', 'NN'), ('select', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('device', 'NN'), ('one', 'CD'), ('devices', 'NNS'), ('based', 'VBN'), ('detected', 'JJ'), ('audio', 'JJ'), ('signal', 'NN'), ('detected', 'VBD'), ('visual', 'JJ'), ('signal', 'NN'), ('provide', 'NN'), ('instructions', 'NNS'), ('selected', 'VBN'), ('device', 'NN'), ('output', 'NN'), ('notification', 'NN'), ('related', 'VBN'), ('upcoming', 'JJ'), ('media', 'NNS'), ('programming', 'VBG'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('medium', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('selecting', 'VBG'), ('first', 'JJ'), ('device', 'NN'), ('based', 'VBN'), ('detected', 'JJ'), ('audio', 'JJ'), ('signal', 'NN'), ('includes', 'VBZ'), ('recognizing', 'VBG'), ('voice', 'NN'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('medium', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('processor', 'NN'), ('capable', 'JJ'), ('executing', 'VBG'), ('processor-executable', 'JJ'), ('program', 'NN'), ('code', 'NN'), ('determine', 'NN'), ('distance', 'NN'), ('recognized', 'VBN'), ('voice', 'NN'), ('wherein', 'NN'), ('selecting', 'VBG'), ('first', 'JJ'), ('device', 'NN'), ('based', 'VBN'), ('determined', 'JJ'), ('distance', 'NN'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('medium', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('selecting', 'VBG'), ('first', 'JJ'), ('device', 'NN'), ('based', 'VBN'), ('detected', 'VBN'), ('visual', 'JJ'), ('signals', 'NNS'), ('includes', 'VBZ'), ('recognizing', 'VBG'), ('face', 'NN'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('medium', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('recognizing', 'VBG'), ('face', 'NN'), ('includes', 'VBZ'), ('face', 'JJ'), ('recognition', 'NN'), ('technique', 'NN'), ('camera', 'NN'), ('comprising', 'VBG'), ('sensor', 'JJ'), ('array', 'NN'), ('including', 'VBG'), ('plurality', 'NN'), ('sensors', 'NNS'), ('infrared', 'VBD'), ('ir', 'JJ'), ('illuminator', 'NN'), ('configured', 'VBD'), ('emit', 'RB'), ('active', 'JJ'), ('ir', 'NN'), ('light', 'JJ'), ('ir', 'JJ'), ('light', 'JJ'), ('sub-band', 'JJ'), ('plurality', 'NN'), ('spectral', 'JJ'), ('illuminators', 'NNS'), ('spectral', 'JJ'), ('illuminator', 'NN'), ('configured', 'VBD'), ('emit', 'RB'), ('active', 'JJ'), ('spectral', 'JJ'), ('light', 'NN'), ('different', 'JJ'), ('spectral', 'JJ'), ('light', 'NN'), ('sub-band', 'NN'), ('depth', 'NN'), ('controller', 'NN'), ('machine', 'NN'), ('configured', 'VBN'), ('determine', 'JJ'), ('depth', 'NN'), ('value', 'NN'), ('plurality', 'NN'), ('sensors', 'NNS'), ('based', 'VBN'), ('active', 'JJ'), ('ir', 'NN'), ('light', 'JJ'), ('spectral', 'JJ'), ('controller', 'NN'), ('machine', 'NN'), ('configured', 'VBN'), ('plurality', 'NN'), ('sensors', 'NNS'), ('determine', 'VBP'), ('spectral', 'JJ'), ('value', 'NN'), ('spectral', 'JJ'), ('light', 'JJ'), ('sub-band', 'JJ'), ('plurality', 'NN'), ('spectral', 'JJ'), ('illuminators', 'NNS'), ('output', 'NN'), ('machine', 'NN'), ('configured', 'VBN'), ('output', 'NN'), ('test', 'NN'), ('depth+multi-spectral', 'JJ'), ('image', 'NN'), ('including', 'VBG'), ('plurality', 'NN'), ('pixels', 'NNS'), ('pixel', 'VBP'), ('corresponding', 'VBG'), ('one', 'CD'), ('plurality', 'NN'), ('sensors', 'NNS'), ('sensor', 'VBP'), ('array', 'JJ'), ('including', 'VBG'), ('least', 'JJS'), ('depth', 'JJ'), ('value', 'NN'), ('spectral', 'JJ'), ('value', 'NN'), ('spectral', 'JJ'), ('light', 'JJ'), ('sub-band', 'JJ'), ('plurality', 'NN'), ('spectral', 'JJ'), ('illuminators', 'NNS'), ('face', 'VBP'), ('recognition', 'NN'), ('machine', 'NN'), ('previously', 'RB'), ('trained', 'VBN'), ('set', 'VBN'), ('labeled', 'JJ'), ('training', 'NN'), ('depth+multi-spectral', 'JJ'), ('images', 'NNS'), ('structure', 'NN'), ('test', 'NN'), ('depth+multi-spectral', 'JJ'), ('image', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('machine', 'NN'), ('configured', 'VBD'), ('output', 'NN'), ('confidence', 'NN'), ('value', 'NN'), ('indicating', 'VBG'), ('likelihood', 'JJ'), ('test', 'NN'), ('depth+multi-spectral', 'JJ'), ('image', 'NN'), ('includes', 'VBZ'), ('face', 'VBP'), ('camera', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('spectral', 'JJ'), ('value', 'NN'), ('calculated', 'VBD'), ('based', 'VBN'), ('depth', 'NN'), ('value', 'NN'), ('determined', 'VBD'), ('sensor', 'JJ'), ('corresponds', 'NNS'), ('pixel', 'JJ'), ('camera', 'NN'), ('claim', 'NN'), ('wherein', 'VBD'), ('face', 'NN'), ('recognition', 'NN'), ('machine', 'NN'), ('configured', 'VBN'), ('use', 'IN'), ('convolutional', 'JJ'), ('neural', 'JJ'), ('network', 'NN'), ('determine', 'NN'), ('confidence', 'NN'), ('value', 'NN'), ('camera', 'NN'), ('claim', 'NN'), ('wherein', 'VBD'), ('face', 'NN'), ('recognition', 'NN'), ('machine', 'NN'), ('includes', 'VBZ'), ('plurality', 'NN'), ('input', 'NN'), ('nodes', 'NNS'), ('wherein', 'VBP'), ('input', 'JJ'), ('node', 'RB'), ('configured', 'VBD'), ('receive', 'JJ'), ('pixel', 'NN'), ('value', 'NN'), ('array', 'NN'), ('corresponding', 'VBG'), ('different', 'JJ'), ('pixel', 'NN'), ('plurality', 'NN'), ('pixels', 'NNS'), ('test', 'VBP'), ('depth+multi-spectral', 'JJ'), ('image', 'NN'), ('wherein', 'NN'), ('pixel', 'VBZ'), ('value', 'NN'), ('array', 'NN'), ('includes', 'VBZ'), ('depth', 'IN'), ('value', 'NN'), ('plurality', 'NN'), ('multi-spectral', 'JJ'), ('values', 'NNS'), ('pixel', 'VBP'), ('camera', 'NN'), ('claim', 'NN'), ('wherein', 'JJ'), ('plurality', 'NN'), ('multi-spectral', 'JJ'), ('values', 'NNS'), ('pixel', 'VBP'), ('include', 'VBP'), ('three', 'CD'), ('spectral', 'JJ'), ('values', 'NNS'), ('camera', 'VBP'), ('claim', 'NN'), ('wherein', 'NN'), ('output', 'NN'), ('machine', 'NN'), ('configured', 'VBN'), ('output', 'NN'), ('surface', 'NN'), ('normal', 'JJ'), ('pixel', 'JJ'), ('test', 'NN'), ('depth+multi-spectral', 'JJ'), ('image', 'NN'), ('wherein', 'NN'), ('pixel', 'VBZ'), ('value', 'NN'), ('array', 'NN'), ('includes', 'VBZ'), ('surface', 'NN'), ('normal', 'JJ'), ('camera', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('output', 'NN'), ('machine', 'NN'), ('configured', 'VBN'), ('output', 'NN'), ('curvature', 'NN'), ('pixel', 'JJ'), ('test', 'NN'), ('depth+multi-spectral', 'JJ'), ('image', 'NN'), ('wherein', 'NN'), ('pixel', 'VBZ'), ('value', 'NN'), ('array', 'NN'), ('includes', 'VBZ'), ('curvature', 'NN'), ('camera', 'NN'), ('claim', 'NN'), ('wherein', 'VBD'), ('face', 'NN'), ('recognition', 'NN'), ('machine', 'NN'), ('configured', 'VBN'), ('use', 'NN'), ('plurality', 'NN'), ('models', 'NNS'), ('determine', 'VBP'), ('confidence', 'NN'), ('value', 'NN'), ('wherein', 'VBP'), ('plurality', 'NN'), ('models', 'NNS'), ('includes', 'VBZ'), ('plurality', 'NN'), ('channel-specific', 'JJ'), ('models', 'NNS'), ('wherein', 'IN'), ('channel-specific', 'JJ'), ('model', 'NN'), ('configured', 'VBD'), ('process', 'JJ'), ('different', 'JJ'), ('pixel', 'NN'), ('parameter', 'NN'), ('plurality', 'NN'), ('pixels', 'NNS'), ('test', 'VBP'), ('depth+multi-spectral', 'JJ'), ('image', 'NN'), ('wherein', 'VBD'), ('channel-specific', 'JJ'), ('model', 'NN'), ('includes', 'VBZ'), ('plurality', 'NN'), ('input', 'NN'), ('nodes', 'NNS'), ('wherein', 'VBP'), ('channel-specific', 'JJ'), ('model', 'NN'), ('input', 'NN'), ('node', 'RB'), ('configured', 'VBD'), ('receive', 'JJ'), ('pixel', 'NN'), ('parameter', 'NN'), ('value', 'NN'), ('different', 'JJ'), ('pixel', 'NN'), ('plurality', 'NN'), ('pixels', 'NNS'), ('test', 'VBP'), ('depth+multi-spectral', 'JJ'), ('image', 'NN'), ('camera', 'NN'), ('claim', 'NN'), ('wherein', 'VBD'), ('face', 'NN'), ('recognition', 'NN'), ('machine', 'NN'), ('configured', 'VBN'), ('use', 'RB'), ('statistical', 'JJ'), ('model', 'NN'), ('determine', 'NN'), ('confidence', 'NN'), ('value', 'NN'), ('camera', 'NN'), ('claim', 'NN'), ('wherein', 'VBD'), ('statistical', 'JJ'), ('model', 'NN'), ('includes', 'VBZ'), ('nearest', 'JJS'), ('neighbor', 'NN'), ('algorithm', 'NN'), ('camera', 'NN'), ('claim', 'NN'), ('wherein', 'VBD'), ('statistical', 'JJ'), ('model', 'NN'), ('includes', 'VBZ'), ('support', 'NN'), ('vector', 'NN'), ('machine', 'NN'), ('camera', 'NN'), ('claim', 'NN'), ('wherein', 'VBD'), ('face', 'NN'), ('recognition', 'NN'), ('machine', 'NN'), ('configured', 'VBD'), ('output', 'NN'), ('location', 'NN'), ('test', 'NN'), ('depth+multi-spectral', 'JJ'), ('image', 'NN'), ('bounding', 'VBG'), ('box', 'NN'), ('around', 'IN'), ('recognized', 'VBN'), ('face', 'NN'), ('camera', 'NN'), ('claim', 'NN'), ('wherein', 'VBD'), ('face', 'NN'), ('recognition', 'NN'), ('machine', 'NN'), ('configured', 'VBD'), ('output', 'NN'), ('location', 'NN'), ('test', 'NN'), ('depth+multi-spectral', 'JJ'), ('image', 'NN'), ('identified', 'VBD'), ('two-dimensional', 'JJ'), ('facial', 'JJ'), ('feature', 'NN'), ('recognized', 'VBN'), ('face', 'NN'), ('camera', 'NN'), ('claim', 'NN'), ('wherein', 'VBD'), ('face', 'NN'), ('recognition', 'NN'), ('machine', 'NN'), ('configured', 'VBD'), ('output', 'NN'), ('location', 'NN'), ('test', 'NN'), ('depth+multi-spectral', 'JJ'), ('image', 'NN'), ('identified', 'VBD'), ('three-dimensional', 'JJ'), ('facial', 'JJ'), ('feature', 'NN'), ('recognized', 'VBN'), ('face', 'NN'), ('camera', 'NN'), ('claim', 'NN'), ('wherein', 'VBD'), ('face', 'NN'), ('recognition', 'NN'), ('machine', 'NN'), ('configured', 'VBD'), ('output', 'NN'), ('location', 'NN'), ('test', 'NN'), ('depth+multi-spectral', 'JJ'), ('image', 'NN'), ('identified', 'VBN'), ('spectral', 'JJ'), ('feature', 'NN'), ('recognized', 'VBN'), ('face', 'NN'), ('camera', 'NN'), ('claim', 'NN'), ('wherein', 'VBD'), ('face', 'NN'), ('recognition', 'NN'), ('machine', 'NN'), ('configured', 'VBD'), ('output', 'NN'), ('pixel', 'JJ'), ('test', 'NN'), ('depth+multi-spectral', 'JJ'), ('image', 'NN'), ('confidence', 'NN'), ('value', 'NN'), ('indicating', 'VBG'), ('likelihood', 'NN'), ('pixel', 'NN'), ('included', 'VBD'), ('face', 'NN'), ('camera', 'NN'), ('claim', 'NN'), ('wherein', 'VBD'), ('face', 'NN'), ('recognition', 'NN'), ('machine', 'NN'), ('configured', 'VBD'), ('output', 'NN'), ('identity', 'NN'), ('face', 'NN'), ('recognized', 'VBN'), ('test', 'IN'), ('depth+multi-spectral', 'JJ'), ('image', 'NN'), ('camera', 'NN'), ('claim', 'NN'), ('wherein', 'VBP'), ('plurality', 'NN'), ('sensors', 'NNS'), ('sensor', 'VBP'), ('array', 'JJ'), ('differential', 'JJ'), ('sensors', 'NNS'), ('wherein', 'VBP'), ('spectral', 'JJ'), ('value', 'NN'), ('determined', 'VBD'), ('based', 'VBN'), ('depth', 'NN'), ('value', 'NN'), ('differential', 'JJ'), ('measurement', 'JJ'), ('differential', 'NN'), ('sensor', 'NN'), ('camera', 'NN'), ('comprising', 'VBG'), ('sensor', 'JJ'), ('array', 'NN'), ('including', 'VBG'), ('plurality', 'NN'), ('sensors', 'NNS'), ('infrared', 'VBD'), ('ir', 'JJ'), ('illuminator', 'NN'), ('configured', 'VBD'), ('emit', 'RB'), ('active', 'JJ'), ('ir', 'NN'), ('light', 'JJ'), ('ir', 'JJ'), ('light', 'JJ'), ('sub-band', 'JJ'), ('plurality', 'NN'), ('spectral', 'JJ'), ('illuminators', 'NNS'), ('spectral', 'JJ'), ('illuminator', 'NN'), ('configured', 'VBD'), ('emit', 'RB'), ('active', 'JJ'), ('spectral', 'JJ'), ('light', 'NN'), ('different', 'JJ'), ('spectral', 'JJ'), ('light', 'NN'), ('sub-band', 'NN'), ('depth', 'NN'), ('controller', 'NN'), ('machine', 'NN'), ('configured', 'VBN'), ('determine', 'JJ'), ('depth', 'NN'), ('value', 'NN'), ('plurality', 'NN'), ('sensors', 'NNS'), ('based', 'VBN'), ('active', 'JJ'), ('ir', 'NN'), ('light', 'JJ'), ('spectral', 'JJ'), ('controller', 'NN'), ('machine', 'NN'), ('configured', 'VBN'), ('plurality', 'NN'), ('sensors', 'NNS'), ('determine', 'VBP'), ('spectral', 'JJ'), ('value', 'NN'), ('spectral', 'JJ'), ('light', 'JJ'), ('sub-band', 'JJ'), ('plurality', 'NN'), ('spectral', 'JJ'), ('illuminators', 'NNS'), ('wherein', 'VBP'), ('spectral', 'JJ'), ('value', 'NN'), ('calculated', 'VBD'), ('based', 'VBN'), ('depth', 'NN'), ('value', 'NN'), ('determined', 'VBD'), ('sensor', 'JJ'), ('corresponds', 'NNS'), ('pixel', 'JJ'), ('output', 'NN'), ('machine', 'NN'), ('configured', 'VBN'), ('output', 'NN'), ('test', 'NN'), ('depth+multi-spectral', 'JJ'), ('image', 'NN'), ('including', 'VBG'), ('plurality', 'NN'), ('pixels', 'NNS'), ('pixel', 'VBP'), ('corresponding', 'VBG'), ('one', 'CD'), ('plurality', 'NN'), ('sensors', 'NNS'), ('sensor', 'VBP'), ('array', 'JJ'), ('including', 'VBG'), ('least', 'JJS'), ('depth', 'JJ'), ('value', 'NN'), ('spectral', 'JJ'), ('value', 'NN'), ('spectral', 'JJ'), ('light', 'JJ'), ('sub-band', 'JJ'), ('plurality', 'NN'), ('spectral', 'JJ'), ('illuminators', 'NNS'), ('face', 'VBP'), ('recognition', 'NN'), ('machine', 'NN'), ('including', 'VBG'), ('convolutional', 'JJ'), ('neural', 'JJ'), ('network', 'NN'), ('previously', 'RB'), ('trained', 'VBN'), ('set', 'VBN'), ('labeled', 'JJ'), ('training', 'NN'), ('depth+multi-spectral', 'JJ'), ('images', 'NNS'), ('structure', 'NN'), ('test', 'NN'), ('depth+multi-spectral', 'JJ'), ('image', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('machine', 'NN'), ('configured', 'VBD'), ('output', 'NN'), ('confidence', 'NN'), ('value', 'NN'), ('indicating', 'VBG'), ('likelihood', 'JJ'), ('test', 'NN'), ('depth+multi-spectral', 'JJ'), ('image', 'NN'), ('includes', 'VBZ'), ('face', 'VBP'), ('image', 'NN'), ('processing', 'NN'), ('method', 'NN'), ('comprising', 'VBG'), ('acquiring', 'VBG'), ('photo', 'NN'), ('album', 'NN'), ('obtained', 'VBD'), ('face', 'NN'), ('clustering', 'VBG'), ('collecting', 'VBG'), ('face', 'NN'), ('information', 'NN'), ('respective', 'JJ'), ('images', 'NNS'), ('photo', 'VBP'), ('album', 'IN'), ('acquiring', 'VBG'), ('face', 'NN'), ('parameter', 'NN'), ('image', 'NN'), ('according', 'VBG'), ('face', 'NN'), ('information', 'NN'), ('selecting', 'VBG'), ('cover', 'NN'), ('image', 'NN'), ('according', 'VBG'), ('face', 'NN'), ('parameter', 'NN'), ('image', 'NN'), ('taking', 'VBG'), ('face-region', 'JJ'), ('image', 'NN'), ('cover', 'NN'), ('image', 'NN'), ('setting', 'VBG'), ('face-region', 'JJ'), ('image', 'NN'), ('cover', 'NN'), ('photo', 'NN'), ('album', 'JJ'), ('wherein', 'NN'), ('selecting', 'VBG'), ('cover', 'NN'), ('image', 'NN'), ('according', 'VBG'), ('face', 'NN'), ('parameter', 'NN'), ('image', 'NN'), ('comprises', 'VBZ'), ('performing', 'VBG'), ('calculation', 'NN'), ('face', 'NN'), ('parameter', 'NN'), ('image', 'NN'), ('preset', 'VB'), ('way', 'NN'), ('obtain', 'VB'), ('cover', 'NN'), ('score', 'NN'), ('image', 'NN'), ('selecting', 'VBG'), ('image', 'NN'), ('highest', 'JJS'), ('cover', 'NN'), ('score', 'NN'), ('cover', 'JJ'), ('image', 'NN'), ('wherein', 'VBD'), ('selecting', 'VBG'), ('image', 'NN'), ('highest', 'JJS'), ('cover', 'NN'), ('score', 'NN'), ('cover', 'JJ'), ('image', 'NN'), ('comprises', 'VBZ'), ('acquiring', 'VBG'), ('source', 'NN'), ('image', 'NN'), ('selecting', 'VBG'), ('image', 'NN'), ('highest', 'JJS'), ('cover', 'NN'), ('score', 'NN'), ('images', 'NNS'), ('coming', 'VBG'), ('preset', 'NN'), ('source', 'NN'), ('cover', 'NN'), ('image', 'NN'), ('method', 'JJ'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('selecting', 'VBG'), ('image', 'NN'), ('highest', 'JJS'), ('cover', 'NN'), ('score', 'NN'), ('cover', 'JJ'), ('image', 'NN'), ('comprises', 'VBZ'), ('acquiring', 'VBG'), ('number', 'NN'), ('faces', 'VBZ'), ('contained', 'VBN'), ('image', 'NN'), ('determining', 'VBG'), ('single-person', 'JJ'), ('images', 'NNS'), ('according', 'VBG'), ('number', 'NN'), ('faces', 'VBZ'), ('selecting', 'VBG'), ('single-person', 'JJ'), ('image', 'NN'), ('highest', 'JJS'), ('cover', 'NN'), ('score', 'NN'), ('cover', 'JJ'), ('image', 'NN'), ('method', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('selecting', 'VBG'), ('image', 'NN'), ('highest', 'JJS'), ('cover', 'NN'), ('score', 'NN'), ('cover', 'JJ'), ('image', 'NN'), ('comprises', 'VBZ'), ('single-person', 'JJ'), ('image', 'NN'), ('photo', 'NN'), ('album', 'IN'), ('determining', 'VBG'), ('images', 'NNS'), ('including', 'VBG'), ('two', 'CD'), ('faces', 'VBZ'), ('photo', 'NN'), ('album', 'NN'), ('selecting', 'VBG'), ('image', 'NN'), ('highest', 'JJS'), ('cover', 'NN'), ('score', 'NN'), ('images', 'NNS'), ('including', 'VBG'), ('two', 'CD'), ('faces', 'VBZ'), ('cover', 'RB'), ('image', 'NN'), ('method', 'JJ'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('face', 'NN'), ('information', 'NN'), ('comprises', 'VBZ'), ('face', 'NN'), ('feature', 'NN'), ('points', 'NNS'), ('face', 'VBP'), ('parameter', 'NN'), ('comprises', 'NNS'), ('face', 'VBP'), ('turning', 'VBG'), ('angle', 'RP'), ('acquiring', 'VBG'), ('face', 'NN'), ('parameter', 'NN'), ('image', 'NN'), ('according', 'VBG'), ('face', 'NN'), ('information', 'NN'), ('comprises', 'VBZ'), ('acquiring', 'VBG'), ('coordinate', 'NN'), ('values', 'NNS'), ('face', 'VBP'), ('feature', 'NN'), ('points', 'NNS'), ('determining', 'VBG'), ('distances', 'NNS'), ('angles', 'NNS'), ('face', 'VBP'), ('feature', 'NN'), ('points', 'NNS'), ('determining', 'VBG'), ('face', 'NN'), ('turning', 'VBG'), ('angle', 'RP'), ('according', 'VBG'), ('distances', 'NNS'), ('angles', 'NNS'), ('method', 'VBP'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('face', 'NN'), ('parameter', 'NN'), ('comprises', 'VBZ'), ('face', 'VBP'), ('ratio', 'NN'), ('acquiring', 'VBG'), ('face', 'NN'), ('parameter', 'NN'), ('image', 'NN'), ('according', 'VBG'), ('face', 'NN'), ('information', 'NN'), ('comprises', 'VBZ'), ('determining', 'VBG'), ('face', 'NN'), ('region', 'NN'), ('image', 'NN'), ('according', 'VBG'), ('face', 'NN'), ('information', 'NN'), ('calculating', 'VBG'), ('ratio', 'NN'), ('area', 'NN'), ('face', 'NN'), ('region', 'NN'), ('area', 'NN'), ('image', 'NN'), ('obtain', 'VB'), ('face', 'NN'), ('ratio', 'NN'), ('method', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('calculating', 'VBG'), ('face', 'NN'), ('ratio', 'NN'), ('comprises', 'VBZ'), ('one', 'CD'), ('face', 'NN'), ('image', 'NN'), ('subtracting', 'VBG'), ('area', 'NN'), ('occupied', 'VBD'), ('faces', 'VBZ'), ('face', 'NN'), ('corresponding', 'VBG'), ('photo', 'NN'), ('album', 'NN'), ('face', 'NN'), ('region', 'NN'), ('obtain', 'VB'), ('remaining', 'VBG'), ('area', 'NN'), ('calculating', 'VBG'), ('ratio', 'NN'), ('remaining', 'VBG'), ('area', 'NN'), ('area', 'NN'), ('image', 'NN'), ('obtain', 'VB'), ('face', 'NN'), ('ratio', 'NN'), ('method', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('collecting', 'VBG'), ('face', 'NN'), ('information', 'NN'), ('respective', 'JJ'), ('images', 'NNS'), ('photo', 'VBP'), ('album', 'JJ'), ('comprises', 'NNS'), ('acquiring', 'VBG'), ('image', 'NN'), ('identifications', 'NNS'), ('images', 'VBZ'), ('photo', 'NN'), ('album', 'NN'), ('extracting', 'VBG'), ('face', 'NN'), ('information', 'NN'), ('corresponding', 'VBG'), ('image', 'NN'), ('identifications', 'NNS'), ('face', 'VBP'), ('database', 'JJ'), ('face', 'NN'), ('database', 'NN'), ('stored', 'VBD'), ('face', 'NN'), ('recognition', 'NN'), ('results', 'NNS'), ('images', 'NNS'), ('face', 'VBP'), ('recognition', 'NN'), ('results', 'NNS'), ('including', 'VBG'), ('face', 'NN'), ('information', 'NN'), ('image', 'NN'), ('processing', 'NN'), ('apparatus', 'NN'), ('comprising', 'VBG'), ('processor', 'JJ'), ('memory', 'NN'), ('configured', 'VBD'), ('store', 'NN'), ('instructions', 'NNS'), ('executable', 'JJ'), ('processor', 'NN'), ('wherein', 'NN'), ('processor', 'NN'), ('configured', 'VBD'), ('run', 'VBN'), ('program', 'NN'), ('corresponding', 'NN'), ('instructions', 'NNS'), ('reading', 'VBG'), ('instructions', 'NNS'), ('stored', 'VBD'), ('memory', 'NN'), ('perform', 'NN'), ('acquiring', 'VBG'), ('photo', 'NN'), ('album', 'NN'), ('obtained', 'VBD'), ('face', 'NN'), ('clustering', 'VBG'), ('collecting', 'VBG'), ('face', 'NN'), ('information', 'NN'), ('image', 'NN'), ('photo', 'NN'), ('album', 'IN'), ('acquiring', 'VBG'), ('face', 'NN'), ('parameter', 'NN'), ('image', 'NN'), ('according', 'VBG'), ('face', 'NN'), ('information', 'NN'), ('selecting', 'VBG'), ('cover', 'NN'), ('image', 'NN'), ('according', 'VBG'), ('face', 'NN'), ('parameter', 'NN'), ('image', 'NN'), ('taking', 'VBG'), ('face-region', 'JJ'), ('image', 'NN'), ('cover', 'NN'), ('image', 'NN'), ('setting', 'VBG'), ('face-region', 'JJ'), ('image', 'NN'), ('cover', 'NN'), ('photo', 'NN'), ('album', 'JJ'), ('wherein', 'NN'), ('processor', 'NN'), ('configured', 'VBD'), ('perform', 'JJ'), ('calculation', 'NN'), ('face', 'NN'), ('parameter', 'NN'), ('image', 'NN'), ('preset', 'VB'), ('way', 'NN'), ('obtain', 'VB'), ('cover', 'NN'), ('score', 'NN'), ('image', 'NN'), ('select', 'JJ'), ('image', 'NN'), ('highest', 'JJS'), ('cover', 'NN'), ('score', 'NN'), ('cover', 'JJ'), ('image', 'NN'), ('wherein', 'NN'), ('processor', 'NN'), ('configured', 'VBD'), ('acquire', 'VB'), ('source', 'NN'), ('image', 'NN'), ('select', 'JJ'), ('image', 'NN'), ('highest', 'JJS'), ('cover', 'NN'), ('score', 'NN'), ('images', 'NNS'), ('coming', 'VBG'), ('preset', 'NN'), ('source', 'NN'), ('cover', 'NN'), ('image', 'NN'), ('apparatus', 'JJ'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('processor', 'NN'), ('configured', 'VBD'), ('acquire', 'VB'), ('number', 'NN'), ('faces', 'VBZ'), ('contained', 'VBN'), ('image', 'NN'), ('determine', 'JJ'), ('single-person', 'JJ'), ('images', 'NNS'), ('according', 'VBG'), ('number', 'NN'), ('faces', 'VBZ'), ('select', 'JJ'), ('single-person', 'JJ'), ('image', 'NN'), ('highest', 'JJS'), ('cover', 'NN'), ('score', 'NN'), ('cover', 'JJ'), ('image', 'NN'), ('apparatus', 'JJ'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('processor', 'NN'), ('configured', 'VBD'), ('single-person', 'JJ'), ('image', 'NN'), ('photo', 'NN'), ('album', 'JJ'), ('determine', 'NN'), ('images', 'NNS'), ('including', 'VBG'), ('two', 'CD'), ('faces', 'VBZ'), ('photo', 'NN'), ('album', 'NN'), ('select', 'JJ'), ('image', 'NN'), ('highest', 'JJS'), ('cover', 'NN'), ('score', 'NN'), ('images', 'NNS'), ('including', 'VBG'), ('two', 'CD'), ('faces', 'VBZ'), ('cover', 'RB'), ('image', 'NN'), ('apparatus', 'JJ'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('face', 'NN'), ('information', 'NN'), ('comprises', 'VBZ'), ('face', 'NN'), ('feature', 'NN'), ('points', 'NNS'), ('face', 'VBP'), ('parameter', 'NN'), ('comprises', 'NNS'), ('face', 'VBP'), ('turning', 'VBG'), ('angle', 'NN'), ('processor', 'NN'), ('configured', 'VBD'), ('acquire', 'VB'), ('coordinate', 'NN'), ('values', 'NNS'), ('face', 'VBP'), ('feature', 'NN'), ('points', 'NNS'), ('determine', 'JJ'), ('distances', 'NNS'), ('angles', 'NNS'), ('face', 'VBP'), ('feature', 'NN'), ('points', 'NNS'), ('determine', 'JJ'), ('face', 'NN'), ('turning', 'VBG'), ('angle', 'RP'), ('according', 'VBG'), ('distances', 'NNS'), ('angles', 'NNS'), ('apparatus', 'VBP'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('face', 'NN'), ('parameter', 'NN'), ('comprises', 'VBZ'), ('face', 'VBP'), ('ratio', 'NN'), ('processor', 'NN'), ('configured', 'VBD'), ('determine', 'JJ'), ('face', 'NN'), ('region', 'NN'), ('image', 'NN'), ('according', 'VBG'), ('face', 'NN'), ('information', 'NN'), ('calculate', 'NN'), ('ratio', 'NN'), ('area', 'NN'), ('face', 'NN'), ('region', 'NN'), ('area', 'NN'), ('image', 'NN'), ('obtain', 'VB'), ('face', 'NN'), ('ratio', 'NN'), ('apparatus', 'IN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('processor', 'NN'), ('configured', 'VBD'), ('one', 'CD'), ('face', 'NN'), ('image', 'NN'), ('subtract', 'JJ'), ('area', 'NN'), ('occupied', 'VBD'), ('faces', 'VBZ'), ('face', 'NN'), ('corresponding', 'VBG'), ('photo', 'NN'), ('album', 'NN'), ('face', 'NN'), ('region', 'NN'), ('obtain', 'VB'), ('remaining', 'VBG'), ('area', 'NN'), ('calculate', 'NN'), ('ratio', 'NN'), ('remaining', 'VBG'), ('area', 'NN'), ('area', 'NN'), ('image', 'NN'), ('obtain', 'VB'), ('face', 'NN'), ('ratio', 'NN'), ('apparatus', 'IN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('processor', 'NN'), ('configured', 'VBD'), ('acquire', 'VB'), ('image', 'NN'), ('identifications', 'NNS'), ('images', 'VBZ'), ('photo', 'NN'), ('album', 'NN'), ('extract', 'JJ'), ('face', 'NN'), ('information', 'NN'), ('corresponding', 'VBG'), ('image', 'NN'), ('identifications', 'NNS'), ('face', 'VBP'), ('database', 'JJ'), ('face', 'NN'), ('database', 'NN'), ('stored', 'VBD'), ('face', 'NN'), ('recognition', 'NN'), ('results', 'NNS'), ('images', 'NNS'), ('face', 'VBP'), ('recognition', 'NN'), ('results', 'NNS'), ('including', 'VBG'), ('face', 'NN'), ('information', 'NN'), ('electronic', 'JJ'), ('device', 'NN'), ('comprising', 'VBG'), ('processor', 'JJ'), ('memory', 'NN'), ('display', 'NN'), ('screen', 'NN'), ('input', 'NN'), ('device', 'NN'), ('connected', 'VBN'), ('via', 'IN'), ('system', 'NN'), ('bus', 'JJ'), ('wherein', 'JJ'), ('memory', 'NN'), ('stored', 'VBN'), ('computer', 'NN'), ('programs', 'NNS'), ('executed', 'VBD'), ('processor', 'NN'), ('cause', 'NN'), ('processor', 'NN'), ('implement', 'JJ'), ('image', 'NN'), ('processing', 'NN'), ('method', 'JJ'), ('image', 'NN'), ('processing', 'NN'), ('method', 'NN'), ('comprising', 'VBG'), ('acquiring', 'VBG'), ('photo', 'NN'), ('album', 'NN'), ('obtained', 'VBD'), ('face', 'NN'), ('clustering', 'VBG'), ('collecting', 'VBG'), ('face', 'NN'), ('information', 'NN'), ('respective', 'JJ'), ('images', 'NNS'), ('photo', 'VBP'), ('album', 'IN'), ('acquiring', 'VBG'), ('face', 'NN'), ('parameter', 'NN'), ('image', 'NN'), ('according', 'VBG'), ('face', 'NN'), ('information', 'NN'), ('selecting', 'VBG'), ('cover', 'NN'), ('image', 'NN'), ('according', 'VBG'), ('face', 'NN'), ('parameter', 'NN'), ('image', 'NN'), ('taking', 'VBG'), ('face-region', 'JJ'), ('image', 'NN'), ('cover', 'NN'), ('image', 'NN'), ('setting', 'VBG'), ('face-region', 'JJ'), ('image', 'NN'), ('cover', 'NN'), ('photo', 'NN'), ('album', 'JJ'), ('wherein', 'NN'), ('selecting', 'VBG'), ('cover', 'NN'), ('image', 'NN'), ('according', 'VBG'), ('face', 'NN'), ('parameter', 'NN'), ('image', 'NN'), ('comprises', 'VBZ'), ('performing', 'VBG'), ('calculation', 'NN'), ('face', 'NN'), ('parameter', 'NN'), ('image', 'NN'), ('preset', 'VB'), ('way', 'NN'), ('obtain', 'VB'), ('cover', 'NN'), ('score', 'NN'), ('image', 'NN'), ('selecting', 'VBG'), ('image', 'NN'), ('highest', 'JJS'), ('cover', 'NN'), ('score', 'NN'), ('cover', 'JJ'), ('image', 'NN'), ('wherein', 'VBD'), ('selecting', 'VBG'), ('image', 'NN'), ('highest', 'JJS'), ('cover', 'NN'), ('score', 'NN'), ('cover', 'JJ'), ('image', 'NN'), ('comprises', 'VBZ'), ('acquiring', 'VBG'), ('source', 'NN'), ('image', 'NN'), ('selecting', 'VBG'), ('image', 'NN'), ('highest', 'JJS'), ('cover', 'NN'), ('score', 'NN'), ('images', 'NNS'), ('coming', 'VBG'), ('preset', 'NN'), ('source', 'NN'), ('cover', 'NN'), ('image', 'NN'), ('electronic', 'JJ'), ('device', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('electronic', 'JJ'), ('device', 'NN'), ('comprises', 'NNS'), ('least', 'VBP'), ('one', 'CD'), ('mobile', 'JJ'), ('phone', 'NN'), ('tablet', 'NN'), ('computer', 'NN'), ('personal', 'JJ'), ('digital', 'NN'), ('assistant', 'NN'), ('wearable', 'JJ'), ('device', 'NN'), ('computer-implemented', 'JJ'), ('method', 'NN'), ('comprising', 'VBG'), ('receiving', 'VBG'), ('computing', 'VBG'), ('device', 'NN'), ('meeting', 'NN'), ('invitation', 'NN'), ('identifying', 'VBG'), ('location', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('meeting', 'NN'), ('invitation', 'NN'), ('configured', 'VBD'), ('provide', 'IN'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('physical', 'JJ'), ('access', 'NN'), ('location', 'NN'), ('wherein', 'NN'), ('meeting', 'NN'), ('invitation', 'NN'), ('causes', 'VBZ'), ('system', 'NN'), ('control', 'NN'), ('pathway', 'RB'), ('allowing', 'VBG'), ('physical', 'JJ'), ('access', 'NN'), ('location', 'NN'), ('providing', 'VBG'), ('based', 'VBN'), ('meeting', 'VBG'), ('invitation', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('physical', 'JJ'), ('access', 'NN'), ('location', 'NN'), ('controlling', 'VBG'), ('pathway', 'RB'), ('allowing', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('physically', 'RB'), ('access', 'NN'), ('location', 'NN'), ('pathway', 'NN'), ('response', 'NN'), ('positioning', 'VBG'), ('data', 'NNS'), ('indicating', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('predetermined', 'VBN'), ('location', 'NN'), ('near', 'IN'), ('location', 'NN'), ('wherein', 'NN'), ('positioning', 'VBG'), ('data', 'NNS'), ('based', 'VBN'), ('part', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('camera', 'NN'), ('system', 'NN'), ('identifying', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('receiving', 'VBG'), ('positioning', 'VBG'), ('data', 'NNS'), ('face', 'NN'), ('recognition', 'NN'), ('camera', 'NN'), ('system', 'NN'), ('identifying', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('wherein', 'NN'), ('positioning', 'VBG'), ('data', 'NNS'), ('indicates', 'VBZ'), ('pattern', 'JJ'), ('movement', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('determining', 'VBG'), ('pattern', 'JJ'), ('movement', 'NN'), ('indicates', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('exited', 'VBN'), ('location', 'NN'), ('revoking', 'VBG'), ('physical', 'JJ'), ('access', 'NN'), ('location', 'NN'), ('identified', 'VBD'), ('meeting', 'VBG'), ('invitation', 'NN'), ('controlling', 'VBG'), ('pathway', 'RB'), ('restrict', 'VB'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('identified', 'VBD'), ('meeting', 'VBG'), ('invitation', 'NN'), ('physical', 'JJ'), ('access', 'NN'), ('location', 'NN'), ('pathway', 'NN'), ('response', 'NN'), ('determining', 'VBG'), ('pattern', 'JJ'), ('movement', 'NN'), ('indicates', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('exited', 'VBN'), ('location', 'NN'), ('computer-implemented', 'JJ'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('determining', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('exited', 'VBN'), ('location', 'NN'), ('comprises', 'VBZ'), ('determining', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('passed', 'VBD'), ('egress', 'RB'), ('associated', 'VBN'), ('location', 'NN'), ('predetermined', 'VBN'), ('direction', 'NN'), ('computer-implemented', 'JJ'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('determining', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('exited', 'VBN'), ('location', 'NN'), ('comprises', 'VBZ'), ('determining', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('moved', 'VBD'), ('area', 'NN'), ('predetermined', 'VBN'), ('direction', 'NN'), ('computer-implemented', 'JJ'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('positioning', 'VBG'), ('data', 'NNS'), ('indicates', 'VBZ'), ('second', 'JJ'), ('pattern', 'JJ'), ('movement', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('wherein', 'NN'), ('access', 'NN'), ('secured', 'VBN'), ('data', 'NNS'), ('associated', 'VBN'), ('location', 'NN'), ('provided', 'VBN'), ('response', 'NN'), ('detecting', 'VBG'), ('second', 'JJ'), ('pattern', 'JJ'), ('movement', 'NN'), ('computer-implemented', 'JJ'), ('method', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('collating', 'VBG'), ('secured', 'VBN'), ('data', 'NNS'), ('public', 'JJ'), ('data', 'NNS'), ('generate', 'VBP'), ('resource', 'NN'), ('data', 'NNS'), ('communicating', 'VBG'), ('resource', 'NN'), ('data', 'NNS'), ('client', 'NN'), ('computing', 'VBG'), ('device', 'NN'), ('associated', 'VBN'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('access', 'NN'), ('location', 'NN'), ('provided', 'VBD'), ('computer-implemented', 'JJ'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('positioning', 'VBG'), ('data', 'NNS'), ('indicates', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('predetermined', 'VBN'), ('location', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('passes', 'NNS'), ('predetermined', 'VBD'), ('location', 'NN'), ('computer-implemented', 'JJ'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('positioning', 'VBG'), ('data', 'NNS'), ('indicates', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('predetermined', 'VBN'), ('location', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('passes', 'NNS'), ('predetermined', 'VBD'), ('location', 'NN'), ('near', 'IN'), ('location', 'NN'), ('predetermined', 'VBN'), ('direction', 'NN'), ('system', 'NN'), ('comprising', 'VBG'), ('processor', 'JJ'), ('memory', 'NN'), ('communication', 'NN'), ('processor', 'NN'), ('memory', 'NN'), ('computer-readable', 'JJ'), ('instructions', 'NNS'), ('stored', 'VBD'), ('thereupon', 'RB'), ('executed', 'VBN'), ('processor', 'NN'), ('cause', 'NN'), ('processor', 'NN'), ('receive', 'VBP'), ('meeting', 'NN'), ('invitation', 'NN'), ('indicating', 'VBG'), ('location', 'NN'), ('identity', 'NN'), ('meeting', 'NN'), ('invitation', 'NN'), ('configured', 'VBD'), ('provide', 'IN'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('physical', 'JJ'), ('access', 'NN'), ('location', 'NN'), ('wherein', 'NN'), ('meeting', 'NN'), ('invitation', 'NN'), ('causes', 'VBZ'), ('system', 'NN'), ('control', 'NN'), ('pathway', 'RB'), ('allowing', 'VBG'), ('physical', 'JJ'), ('access', 'NN'), ('location', 'NN'), ('provide', 'IN'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('associated', 'VBN'), ('identity', 'NN'), ('access', 'NN'), ('location', 'NN'), ('controlling', 'VBG'), ('pathway', 'RB'), ('allowing', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('physically', 'RB'), ('access', 'NN'), ('location', 'NN'), ('pathway', 'NN'), ('response', 'NN'), ('positioning', 'VBG'), ('data', 'NNS'), ('indicating', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('predetermined', 'VBN'), ('location', 'NN'), ('near', 'IN'), ('location', 'NN'), ('wherein', 'NN'), ('positioning', 'VBG'), ('data', 'NNS'), ('based', 'VBN'), ('part', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('camera', 'NN'), ('system', 'NN'), ('identifying', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('receive', 'VBP'), ('positioning', 'VBG'), ('data', 'NNS'), ('face', 'NN'), ('recognition', 'NN'), ('camera', 'NN'), ('system', 'NN'), ('identifying', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('wherein', 'NN'), ('positioning', 'VBG'), ('data', 'NNS'), ('indicates', 'VBZ'), ('pattern', 'JJ'), ('movement', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('determine', 'NN'), ('pattern', 'JJ'), ('movement', 'NN'), ('indicates', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('exited', 'VBN'), ('location', 'NN'), ('revoke', 'VBD'), ('physical', 'JJ'), ('access', 'NN'), ('location', 'NN'), ('identified', 'VBD'), ('meeting', 'VBG'), ('invitation', 'NN'), ('controlling', 'VBG'), ('pathway', 'RB'), ('restrict', 'VB'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('identified', 'VBD'), ('meeting', 'VBG'), ('invitation', 'NN'), ('physical', 'JJ'), ('access', 'NN'), ('location', 'NN'), ('pathway', 'NN'), ('response', 'NN'), ('determining', 'VBG'), ('pattern', 'JJ'), ('movement', 'NN'), ('indicates', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('exited', 'VBN'), ('location', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('determining', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('exited', 'VBN'), ('location', 'NN'), ('comprises', 'VBZ'), ('determining', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('passed', 'VBD'), ('egress', 'RB'), ('associated', 'VBN'), ('location', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('determining', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('exited', 'VBN'), ('location', 'NN'), ('comprises', 'VBZ'), ('determining', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('moved', 'VBD'), ('area', 'NN'), ('predetermined', 'VBN'), ('direction', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('positioning', 'VBG'), ('data', 'NNS'), ('indicates', 'VBZ'), ('second', 'JJ'), ('pattern', 'JJ'), ('movement', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('wherein', 'NN'), ('access', 'NN'), ('secured', 'VBN'), ('data', 'NNS'), ('associated', 'VBN'), ('location', 'NN'), ('provided', 'VBN'), ('response', 'NN'), ('detecting', 'VBG'), ('second', 'JJ'), ('pattern', 'JJ'), ('movement', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('instructions', 'NNS'), ('cause', 'VBP'), ('processor', 'NN'), ('collate', 'NN'), ('secured', 'VBN'), ('data', 'NNS'), ('public', 'JJ'), ('data', 'NNS'), ('generate', 'VBP'), ('resource', 'NN'), ('data', 'NNS'), ('communicate', 'VBP'), ('resource', 'NN'), ('data', 'NNS'), ('client', 'NN'), ('computing', 'VBG'), ('device', 'NN'), ('associated', 'VBN'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('access', 'NN'), ('location', 'NN'), ('provided', 'VBD'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('storage', 'NN'), ('medium', 'NN'), ('computer-executable', 'JJ'), ('instructions', 'NNS'), ('stored', 'VBD'), ('thereupon', 'RB'), ('executed', 'VBN'), ('one', 'CD'), ('processors', 'NNS'), ('computing', 'VBG'), ('device', 'NN'), ('cause', 'NN'), ('one', 'CD'), ('processors', 'NNS'), ('computing', 'VBG'), ('device', 'NN'), ('receive', 'VBP'), ('meeting', 'NN'), ('invitation', 'NN'), ('indicating', 'VBG'), ('location', 'NN'), ('identity', 'NN'), ('meeting', 'NN'), ('invitation', 'NN'), ('configured', 'VBD'), ('provide', 'IN'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('physical', 'JJ'), ('access', 'NN'), ('location', 'NN'), ('wherein', 'NN'), ('meeting', 'NN'), ('invitation', 'NN'), ('causes', 'VBZ'), ('system', 'NN'), ('control', 'NN'), ('pathway', 'RB'), ('allowing', 'VBG'), ('physical', 'JJ'), ('access', 'NN'), ('location', 'NN'), ('provide', 'IN'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('associated', 'VBN'), ('identity', 'NN'), ('access', 'NN'), ('location', 'NN'), ('controlling', 'VBG'), ('pathway', 'RB'), ('allowing', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('physically', 'RB'), ('access', 'NN'), ('location', 'NN'), ('pathway', 'NN'), ('response', 'NN'), ('positioning', 'VBG'), ('data', 'NNS'), ('indicating', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('predetermined', 'VBN'), ('location', 'NN'), ('near', 'IN'), ('location', 'NN'), ('wherein', 'NN'), ('positioning', 'VBG'), ('data', 'NNS'), ('based', 'VBN'), ('part', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('camera', 'NN'), ('system', 'NN'), ('identifying', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('receive', 'VBP'), ('positioning', 'VBG'), ('data', 'NNS'), ('face', 'NN'), ('recognition', 'NN'), ('camera', 'NN'), ('system', 'NN'), ('identifying', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('wherein', 'NN'), ('positioning', 'VBG'), ('data', 'NNS'), ('indicates', 'VBZ'), ('pattern', 'JJ'), ('movement', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('determine', 'NN'), ('pattern', 'JJ'), ('movement', 'NN'), ('indicates', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('exited', 'VBN'), ('location', 'NN'), ('revoke', 'VBD'), ('physical', 'JJ'), ('access', 'NN'), ('location', 'NN'), ('identified', 'VBD'), ('meeting', 'VBG'), ('invitation', 'NN'), ('controlling', 'VBG'), ('pathway', 'RB'), ('restrict', 'VB'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('identified', 'VBD'), ('meeting', 'VBG'), ('invitation', 'NN'), ('physical', 'JJ'), ('access', 'NN'), ('location', 'NN'), ('pathway', 'NN'), ('response', 'NN'), ('determining', 'VBG'), ('pattern', 'JJ'), ('movement', 'NN'), ('indicates', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('exited', 'VBN'), ('location', 'NN'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('storage', 'NN'), ('medium', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('determining', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('exited', 'VBN'), ('location', 'NN'), ('comprises', 'VBZ'), ('determining', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('passed', 'VBD'), ('egress', 'RB'), ('associated', 'VBN'), ('location', 'NN'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('storage', 'NN'), ('medium', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('positioning', 'VBG'), ('data', 'NNS'), ('indicates', 'VBZ'), ('second', 'JJ'), ('pattern', 'JJ'), ('movement', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('wherein', 'NN'), ('access', 'NN'), ('secured', 'VBN'), ('data', 'NNS'), ('associated', 'VBN'), ('location', 'NN'), ('provided', 'VBN'), ('response', 'NN'), ('detecting', 'VBG'), ('second', 'JJ'), ('pattern', 'JJ'), ('movement', 'NN'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('storage', 'NN'), ('medium', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('instructions', 'NNS'), ('cause', 'VBP'), ('one', 'CD'), ('processors', 'NNS'), ('collate', 'VBP'), ('secured', 'VBN'), ('data', 'NNS'), ('public', 'JJ'), ('data', 'NNS'), ('generate', 'VBP'), ('resource', 'NN'), ('data', 'NNS'), ('communicate', 'VBP'), ('resource', 'NN'), ('data', 'NNS'), ('client', 'NN'), ('computing', 'VBG'), ('device', 'NN'), ('associated', 'VBN'), ('least', 'JJS'), ('one', 'CD'), ('invitee', 'NN'), ('access', 'NN'), ('location', 'NN'), ('provided', 'VBD'), ('method', 'NN'), ('comprising', 'VBG'), ('receiving', 'VBG'), ('piece', 'NN'), ('content', 'JJ'), ('salient', 'NN'), ('data', 'NNS'), ('piece', 'NN'), ('content', 'NN'), ('based', 'VBN'), ('salient', 'JJ'), ('data', 'NNS'), ('determining', 'VBG'), ('first', 'JJ'), ('path', 'NN'), ('viewport', 'NN'), ('piece', 'NN'), ('content', 'NN'), ('wherein', 'NN'), ('first', 'JJ'), ('path', 'NN'), ('viewport', 'NN'), ('includes', 'VBZ'), ('different', 'JJ'), ('salient', 'JJ'), ('events', 'NNS'), ('occurring', 'VBG'), ('piece', 'NN'), ('content', 'NN'), ('different', 'JJ'), ('times', 'NNS'), ('playback', 'VBP'), ('piece', 'NN'), ('content', 'NN'), ('providing', 'VBG'), ('viewport', 'NN'), ('display', 'NN'), ('device', 'NN'), ('wherein', 'VBD'), ('movement', 'NN'), ('viewport', 'NN'), ('based', 'VBN'), ('first', 'JJ'), ('path', 'NN'), ('viewport', 'NN'), ('salient', 'NN'), ('data', 'NNS'), ('playback', 'NN'), ('detecting', 'VBG'), ('additional', 'JJ'), ('salient', 'NN'), ('event', 'NN'), ('piece', 'NN'), ('content', 'NN'), ('included', 'VBD'), ('first', 'JJ'), ('path', 'NN'), ('viewport', 'NN'), ('providing', 'VBG'), ('indication', 'JJ'), ('additional', 'JJ'), ('salient', 'NN'), ('event', 'NN'), ('viewport', 'NN'), ('playback', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'VBP'), ('salient', 'NN'), ('data', 'NNS'), ('identifies', 'NNS'), ('salient', 'JJ'), ('event', 'NN'), ('piece', 'NN'), ('content', 'JJ'), ('salient', 'NN'), ('data', 'NNS'), ('indicates', 'VBZ'), ('salient', 'JJ'), ('event', 'NN'), ('piece', 'NN'), ('content', 'NN'), ('corresponding', 'VBG'), ('point', 'NN'), ('location', 'NN'), ('salient', 'JJ'), ('event', 'NN'), ('piece', 'NN'), ('content', 'NN'), ('corresponding', 'VBG'), ('time', 'NN'), ('salient', 'JJ'), ('event', 'NN'), ('occurs', 'VBZ'), ('playback', 'JJ'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'VBP'), ('salient', 'NN'), ('data', 'NNS'), ('indicates', 'VBZ'), ('salient', 'JJ'), ('event', 'NN'), ('piece', 'NN'), ('content', 'NN'), ('corresponding', 'VBG'), ('type', 'JJ'), ('salient', 'JJ'), ('event', 'NN'), ('corresponding', 'VBG'), ('strength', 'NN'), ('value', 'NN'), ('salient', 'JJ'), ('event', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('first', 'JJ'), ('path', 'NN'), ('viewport', 'NN'), ('controls', 'NNS'), ('movement', 'NN'), ('viewport', 'NN'), ('put', 'VBD'), ('different', 'JJ'), ('salient', 'JJ'), ('events', 'NNS'), ('view', 'VBP'), ('viewport', 'RB'), ('different', 'JJ'), ('times', 'NNS'), ('playback', 'VBP'), ('method', 'JJ'), ('claim', 'NN'), ('comprising', 'VBG'), ('detecting', 'VBG'), ('one', 'CD'), ('salient', 'NN'), ('events', 'NNS'), ('piece', 'VBP'), ('content', 'NN'), ('based', 'VBN'), ('least', 'JJS'), ('one', 'CD'), ('following', 'VBG'), ('visual', 'JJ'), ('data', 'NNS'), ('piece', 'NN'), ('content', 'NN'), ('audio', 'NN'), ('data', 'NNS'), ('piece', 'NN'), ('content', 'NN'), ('content', 'JJ'), ('consumption', 'NN'), ('experience', 'NN'), ('data', 'NNS'), ('piece', 'NN'), ('content', 'NN'), ('wherein', 'WRB'), ('salient', 'NN'), ('data', 'NNS'), ('indicative', 'JJ'), ('salient', 'JJ'), ('event', 'NN'), ('detected', 'VBD'), ('method', 'JJ'), ('claim', 'NN'), ('comprising', 'VBG'), ('detecting', 'VBG'), ('one', 'CD'), ('salient', 'NN'), ('events', 'NNS'), ('piece', 'VBP'), ('content', 'NN'), ('based', 'VBN'), ('least', 'JJS'), ('one', 'CD'), ('following', 'VBG'), ('face', 'NN'), ('recognition', 'NN'), ('facial', 'JJ'), ('emotion', 'NN'), ('recognition', 'NN'), ('object', 'JJ'), ('recognition', 'NN'), ('motion', 'NN'), ('recognition', 'NN'), ('metadata', 'NNS'), ('piece', 'NN'), ('content', 'NN'), ('wherein', 'WRB'), ('salient', 'NN'), ('data', 'NNS'), ('indicative', 'JJ'), ('salient', 'JJ'), ('event', 'NN'), ('detected', 'VBD'), ('method', 'JJ'), ('claim', 'NN'), ('comprising', 'VBG'), ('detecting', 'VBG'), ('user', 'JJ'), ('interaction', 'NN'), ('indication', 'NN'), ('wherein', 'WRB'), ('indication', 'NN'), ('comprises', 'VBZ'), ('interactive', 'JJ'), ('hint', 'NN'), ('response', 'NN'), ('detecting', 'VBG'), ('user', 'JJ'), ('interaction', 'NN'), ('adapting', 'VBG'), ('first', 'JJ'), ('path', 'NN'), ('viewport', 'NN'), ('second', 'JJ'), ('path', 'NN'), ('viewport', 'NN'), ('based', 'VBN'), ('user', 'JJ'), ('interaction', 'NN'), ('wherein', 'IN'), ('second', 'JJ'), ('path', 'NN'), ('viewport', 'NN'), ('includes', 'VBZ'), ('additional', 'JJ'), ('salient', 'NN'), ('event', 'NN'), ('providing', 'VBG'), ('updated', 'JJ'), ('viewport', 'NN'), ('piece', 'NN'), ('content', 'NN'), ('display', 'NN'), ('device', 'NN'), ('wherein', 'VBD'), ('movement', 'NN'), ('updated', 'VBN'), ('viewport', 'NN'), ('based', 'VBN'), ('second', 'JJ'), ('path', 'NN'), ('viewport', 'NN'), ('salient', 'NN'), ('data', 'NNS'), ('playback', 'VBP'), ('second', 'JJ'), ('path', 'NN'), ('viewport', 'NN'), ('controls', 'NNS'), ('movement', 'NN'), ('updated', 'VBN'), ('viewport', 'NN'), ('put', 'VBD'), ('additional', 'JJ'), ('salient', 'NN'), ('event', 'NN'), ('view', 'NN'), ('updated', 'VBD'), ('viewport', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('changing', 'VBG'), ('weight', 'NN'), ('assigned', 'VBD'), ('additional', 'JJ'), ('salient', 'NN'), ('event', 'NN'), ('one', 'CD'), ('salient', 'NN'), ('events', 'NNS'), ('piece', 'VBP'), ('content', 'JJ'), ('type', 'JJ'), ('additional', 'JJ'), ('salient', 'NN'), ('event', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('second', 'JJ'), ('path', 'NN'), ('viewport', 'NN'), ('includes', 'VBZ'), ('one', 'CD'), ('salient', 'NN'), ('events', 'NNS'), ('piece', 'VBP'), ('content', 'JJ'), ('type', 'JJ'), ('additional', 'JJ'), ('salient', 'NN'), ('event', 'NN'), ('system', 'NN'), ('comprising', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('processor', 'NN'), ('non-transitory', 'JJ'), ('processor-readable', 'JJ'), ('memory', 'NN'), ('device', 'NN'), ('storing', 'VBG'), ('instructions', 'NNS'), ('executed', 'VBD'), ('least', 'JJS'), ('one', 'CD'), ('processor', 'NN'), ('causes', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('processor', 'NN'), ('perform', 'NN'), ('operations', 'NNS'), ('including', 'VBG'), ('receiving', 'VBG'), ('piece', 'NN'), ('content', 'JJ'), ('salient', 'NN'), ('data', 'NNS'), ('piece', 'NN'), ('content', 'NN'), ('based', 'VBN'), ('salient', 'JJ'), ('data', 'NNS'), ('determining', 'VBG'), ('first', 'JJ'), ('path', 'NN'), ('viewport', 'NN'), ('piece', 'NN'), ('content', 'NN'), ('wherein', 'NN'), ('first', 'JJ'), ('path', 'NN'), ('viewport', 'NN'), ('includes', 'VBZ'), ('different', 'JJ'), ('salient', 'JJ'), ('events', 'NNS'), ('occurring', 'VBG'), ('piece', 'NN'), ('content', 'NN'), ('different', 'JJ'), ('times', 'NNS'), ('playback', 'VBP'), ('piece', 'NN'), ('content', 'NN'), ('providing', 'VBG'), ('viewport', 'NN'), ('display', 'NN'), ('device', 'NN'), ('wherein', 'VBD'), ('movement', 'NN'), ('viewport', 'NN'), ('based', 'VBN'), ('first', 'JJ'), ('path', 'NN'), ('viewport', 'NN'), ('salient', 'NN'), ('data', 'NNS'), ('playback', 'NN'), ('detecting', 'VBG'), ('additional', 'JJ'), ('salient', 'NN'), ('event', 'NN'), ('piece', 'NN'), ('content', 'NN'), ('included', 'VBD'), ('first', 'JJ'), ('path', 'NN'), ('viewport', 'NN'), ('providing', 'VBG'), ('indication', 'JJ'), ('additional', 'JJ'), ('salient', 'NN'), ('event', 'NN'), ('viewport', 'NN'), ('playback', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'VBP'), ('salient', 'NN'), ('data', 'NNS'), ('identifies', 'NNS'), ('salient', 'JJ'), ('event', 'NN'), ('piece', 'NN'), ('content', 'JJ'), ('salient', 'NN'), ('data', 'NNS'), ('indicates', 'VBZ'), ('salient', 'JJ'), ('event', 'NN'), ('piece', 'NN'), ('content', 'NN'), ('corresponding', 'VBG'), ('point', 'NN'), ('location', 'NN'), ('salient', 'JJ'), ('event', 'NN'), ('piece', 'NN'), ('content', 'NN'), ('corresponding', 'VBG'), ('time', 'NN'), ('salient', 'JJ'), ('event', 'NN'), ('occurs', 'VBZ'), ('playback', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'VBP'), ('salient', 'NN'), ('data', 'NNS'), ('indicates', 'VBZ'), ('salient', 'JJ'), ('event', 'NN'), ('piece', 'NN'), ('content', 'NN'), ('corresponding', 'VBG'), ('type', 'JJ'), ('salient', 'JJ'), ('event', 'NN'), ('corresponding', 'VBG'), ('strength', 'NN'), ('value', 'NN'), ('salient', 'NN'), ('event', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'VBP'), ('salient', 'NN'), ('data', 'NNS'), ('generated', 'VBD'), ('offline', 'JJ'), ('server', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('operations', 'NNS'), ('comprising', 'VBG'), ('detecting', 'VBG'), ('one', 'CD'), ('salient', 'NN'), ('events', 'NNS'), ('piece', 'VBP'), ('content', 'NN'), ('based', 'VBN'), ('least', 'JJS'), ('one', 'CD'), ('following', 'VBG'), ('visual', 'JJ'), ('data', 'NNS'), ('piece', 'NN'), ('content', 'NN'), ('audio', 'NN'), ('data', 'NNS'), ('piece', 'NN'), ('content', 'NN'), ('content', 'JJ'), ('consumption', 'NN'), ('experience', 'NN'), ('data', 'NNS'), ('piece', 'NN'), ('content', 'NN'), ('wherein', 'WRB'), ('salient', 'NN'), ('data', 'NNS'), ('indicative', 'JJ'), ('salient', 'JJ'), ('event', 'NN'), ('detected', 'VBD'), ('system', 'NN'), ('claim', 'NN'), ('operations', 'NNS'), ('comprising', 'VBG'), ('detecting', 'VBG'), ('one', 'CD'), ('salient', 'NN'), ('events', 'NNS'), ('piece', 'VBP'), ('content', 'NN'), ('based', 'VBN'), ('least', 'JJS'), ('one', 'CD'), ('following', 'VBG'), ('face', 'NN'), ('recognition', 'NN'), ('facial', 'JJ'), ('emotion', 'NN'), ('recognition', 'NN'), ('object', 'JJ'), ('recognition', 'NN'), ('motion', 'NN'), ('recognition', 'NN'), ('metadata', 'NNS'), ('piece', 'NN'), ('content', 'NN'), ('wherein', 'WRB'), ('salient', 'NN'), ('data', 'NNS'), ('indicative', 'JJ'), ('salient', 'JJ'), ('event', 'NN'), ('detected', 'VBD'), ('system', 'NN'), ('claim', 'NN'), ('operations', 'NNS'), ('comprising', 'VBG'), ('detecting', 'VBG'), ('user', 'JJ'), ('interaction', 'NN'), ('indication', 'NN'), ('wherein', 'WRB'), ('indication', 'NN'), ('comprises', 'VBZ'), ('interactive', 'JJ'), ('hint', 'NN'), ('response', 'NN'), ('detecting', 'VBG'), ('user', 'JJ'), ('interaction', 'NN'), ('adapting', 'VBG'), ('first', 'JJ'), ('path', 'NN'), ('viewport', 'NN'), ('second', 'JJ'), ('path', 'NN'), ('viewport', 'NN'), ('based', 'VBN'), ('user', 'JJ'), ('interaction', 'NN'), ('wherein', 'IN'), ('second', 'JJ'), ('path', 'NN'), ('viewport', 'NN'), ('includes', 'VBZ'), ('additional', 'JJ'), ('salient', 'NN'), ('event', 'NN'), ('providing', 'VBG'), ('updated', 'JJ'), ('viewport', 'NN'), ('piece', 'NN'), ('content', 'NN'), ('display', 'NN'), ('device', 'NN'), ('wherein', 'VBD'), ('movement', 'NN'), ('updated', 'VBN'), ('viewport', 'NN'), ('based', 'VBN'), ('second', 'JJ'), ('path', 'NN'), ('viewport', 'NN'), ('salient', 'NN'), ('data', 'NNS'), ('playback', 'VBP'), ('second', 'JJ'), ('path', 'NN'), ('viewport', 'NN'), ('controls', 'NNS'), ('movement', 'NN'), ('updated', 'VBN'), ('viewport', 'NN'), ('put', 'VBD'), ('additional', 'JJ'), ('salient', 'NN'), ('event', 'NN'), ('view', 'NN'), ('updated', 'VBN'), ('viewport', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('operations', 'NNS'), ('comprising', 'VBG'), ('changing', 'VBG'), ('weight', 'NN'), ('assigned', 'VBD'), ('additional', 'JJ'), ('salient', 'NN'), ('event', 'NN'), ('one', 'CD'), ('salient', 'NN'), ('events', 'NNS'), ('piece', 'VBP'), ('content', 'JJ'), ('type', 'JJ'), ('additional', 'JJ'), ('salient', 'NN'), ('event', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('second', 'JJ'), ('path', 'NN'), ('viewport', 'NN'), ('includes', 'VBZ'), ('one', 'CD'), ('salient', 'NN'), ('events', 'NNS'), ('piece', 'VBP'), ('content', 'JJ'), ('type', 'JJ'), ('additional', 'JJ'), ('salient', 'NN'), ('event', 'NN'), ('non-transitory', 'JJ'), ('computer', 'NN'), ('readable', 'JJ'), ('storage', 'NN'), ('medium', 'NN'), ('including', 'VBG'), ('instructions', 'NNS'), ('perform', 'VBP'), ('method', 'NN'), ('comprising', 'VBG'), ('receiving', 'VBG'), ('piece', 'NN'), ('content', 'JJ'), ('salient', 'NN'), ('data', 'NNS'), ('piece', 'NN'), ('content', 'NN'), ('based', 'VBN'), ('salient', 'JJ'), ('data', 'NNS'), ('determining', 'VBG'), ('first', 'JJ'), ('path', 'NN'), ('viewport', 'NN'), ('piece', 'NN'), ('content', 'NN'), ('wherein', 'NN'), ('first', 'JJ'), ('path', 'NN'), ('viewport', 'NN'), ('includes', 'VBZ'), ('different', 'JJ'), ('salient', 'JJ'), ('events', 'NNS'), ('occurring', 'VBG'), ('piece', 'NN'), ('content', 'NN'), ('different', 'JJ'), ('times', 'NNS'), ('playback', 'VBP'), ('piece', 'NN'), ('content', 'NN'), ('providing', 'VBG'), ('viewport', 'NN'), ('display', 'NN'), ('device', 'NN'), ('wherein', 'VBD'), ('movement', 'NN'), ('viewport', 'NN'), ('based', 'VBN'), ('first', 'JJ'), ('path', 'NN'), ('viewport', 'NN'), ('salient', 'NN'), ('data', 'NNS'), ('playback', 'NN'), ('detecting', 'VBG'), ('additional', 'JJ'), ('salient', 'NN'), ('event', 'NN'), ('piece', 'NN'), ('content', 'NN'), ('included', 'VBD'), ('first', 'JJ'), ('path', 'NN'), ('viewport', 'NN'), ('providing', 'VBG'), ('indication', 'JJ'), ('additional', 'JJ'), ('salient', 'NN'), ('event', 'NN'), ('viewport', 'NN'), ('playback', 'NN'), ('computer', 'NN'), ('readable', 'JJ'), ('storage', 'NN'), ('medium', 'NN'), ('claim', 'NN'), ('method', 'NN'), ('comprising', 'VBG'), ('detecting', 'VBG'), ('user', 'JJ'), ('interaction', 'NN'), ('indication', 'NN'), ('wherein', 'WRB'), ('indication', 'NN'), ('comprises', 'VBZ'), ('interactive', 'JJ'), ('hint', 'NN'), ('response', 'NN'), ('detecting', 'VBG'), ('user', 'JJ'), ('interaction', 'NN'), ('adapting', 'VBG'), ('first', 'JJ'), ('path', 'NN'), ('viewport', 'NN'), ('second', 'JJ'), ('path', 'NN'), ('viewport', 'NN'), ('based', 'VBN'), ('user', 'JJ'), ('interaction', 'NN'), ('wherein', 'IN'), ('second', 'JJ'), ('path', 'NN'), ('viewport', 'NN'), ('includes', 'VBZ'), ('additional', 'JJ'), ('salient', 'NN'), ('event', 'NN'), ('providing', 'VBG'), ('updated', 'JJ'), ('viewport', 'NN'), ('piece', 'NN'), ('content', 'NN'), ('display', 'NN'), ('device', 'NN'), ('wherein', 'VBD'), ('movement', 'NN'), ('updated', 'VBN'), ('viewport', 'NN'), ('based', 'VBN'), ('second', 'JJ'), ('path', 'NN'), ('viewport', 'NN'), ('salient', 'NN'), ('data', 'NNS'), ('playback', 'VBP'), ('second', 'JJ'), ('path', 'NN'), ('viewport', 'NN'), ('controls', 'NNS'), ('movement', 'NN'), ('updated', 'VBN'), ('viewport', 'NN'), ('put', 'VBD'), ('additional', 'JJ'), ('salient', 'NN'), ('event', 'NN'), ('view', 'NN'), ('updated', 'VBD'), ('viewport', 'NN'), ('mobile', 'NN'), ('device', 'NN'), ('facial', 'JJ'), ('recognition', 'NN'), ('mobile', 'JJ'), ('device', 'NN'), ('comprising', 'VBG'), ('one', 'CD'), ('cameras', 'NN'), ('processor', 'NN'), ('device', 'NN'), ('memory', 'NN'), ('coupled', 'VBN'), ('processor', 'NN'), ('device', 'NN'), ('processing', 'NN'), ('system', 'NN'), ('programmed', 'VBD'), ('receive', 'JJ'), ('plurality', 'NN'), ('images', 'VBZ'), ('one', 'CD'), ('cameras', 'NN'), ('extract', 'JJ'), ('feature', 'NN'), ('extractor', 'NN'), ('utilizing', 'JJ'), ('convolutional', 'JJ'), ('neural', 'JJ'), ('network', 'NN'), ('cnn', 'NNS'), ('enlarged', 'VBD'), ('intra-class', 'JJ'), ('variance', 'NN'), ('long-tail', 'JJ'), ('classes', 'NNS'), ('feature', 'VBP'), ('vectors', 'NNS'), ('plurality', 'NN'), ('images', 'NNS'), ('generate', 'VBP'), ('feature', 'NN'), ('generator', 'NN'), ('discriminative', 'JJ'), ('feature', 'NN'), ('vectors', 'NNS'), ('feature', 'VBP'), ('vectors', 'NNS'), ('classify', 'VBP'), ('fully', 'RB'), ('connected', 'VBN'), ('classifier', 'JJR'), ('identity', 'NN'), ('discriminative', 'JJ'), ('feature', 'NN'), ('vectors', 'NNS'), ('control', 'VBP'), ('operation', 'NN'), ('mobile', 'JJ'), ('device', 'NN'), ('react', 'NN'), ('accordance', 'NN'), ('identity', 'NN'), ('mobile', 'JJ'), ('device', 'NN'), ('recited', 'VBD'), ('claim', 'NN'), ('includes', 'VBZ'), ('communication', 'NN'), ('system', 'NN'), ('mobile', 'JJ'), ('device', 'NN'), ('recited', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('operation', 'NN'), ('tags', 'NNS'), ('video', 'VBP'), ('identity', 'NN'), ('uploads', 'NNS'), ('video', 'VBP'), ('social', 'JJ'), ('media', 'NNS'), ('mobile', 'JJ'), ('device', 'NN'), ('recited', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('operation', 'NN'), ('tags', 'NNS'), ('video', 'VBP'), ('identity', 'NN'), ('sends', 'NNS'), ('video', 'VBP'), ('user', 'RB'), ('mobile', 'JJ'), ('device', 'NN'), ('recited', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('mobile', 'JJ'), ('device', 'NN'), ('smart', 'VBD'), ('phone', 'NN'), ('mobile', 'JJ'), ('device', 'NN'), ('recited', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('mobile', 'JJ'), ('device', 'NN'), ('body', 'NN'), ('cam', 'VBP'), ('mobile', 'JJ'), ('device', 'NN'), ('recited', 'VBD'), ('claim', 'NN'), ('programmed', 'VBD'), ('train', 'JJ'), ('feature', 'NN'), ('extractor', 'NN'), ('feature', 'NN'), ('generator', 'NN'), ('fully', 'RB'), ('connected', 'VBN'), ('classifier', 'JJ'), ('alternative', 'JJ'), ('bi-stage', 'NN'), ('strategy', 'NN'), ('mobile', 'JJ'), ('device', 'NN'), ('recited', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('feature', 'NN'), ('extractor', 'NN'), ('shares', 'NNS'), ('covariance', 'NN'), ('matrices', 'NNS'), ('across', 'IN'), ('classes', 'NNS'), ('transfer', 'VBP'), ('intra-class', 'JJ'), ('variance', 'NN'), ('regular', 'JJ'), ('classes', 'NNS'), ('long-tail', 'JJ'), ('classes', 'NNS'), ('mobile', 'JJ'), ('device', 'NN'), ('recited', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('feature', 'NN'), ('generator', 'NN'), ('optimizes', 'VBZ'), ('softmax', 'JJ'), ('loss', 'NN'), ('joint', 'NN'), ('regularization', 'NN'), ('weights', 'NNS'), ('features', 'NNS'), ('magnitude', 'VBP'), ('inner', 'JJ'), ('product', 'NN'), ('weights', 'NNS'), ('features', 'NNS'), ('mobile', 'JJ'), ('device', 'NN'), ('recited', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('feature', 'NN'), ('extractor', 'NN'), ('averages', 'NNS'), ('feature', 'VBP'), ('vector', 'NN'), ('flipped', 'VBD'), ('feature', 'NN'), ('vector', 'NN'), ('flipped', 'VBD'), ('feature', 'NN'), ('vector', 'NN'), ('generated', 'VBD'), ('horizontally', 'RB'), ('flipped', 'VBN'), ('frame', 'VB'), ('one', 'CD'), ('plurality', 'NN'), ('images', 'VBZ'), ('mobile', 'JJ'), ('device', 'NN'), ('recited', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('plurality', 'NN'), ('images', 'NNS'), ('selected', 'VBN'), ('group', 'NN'), ('consisting', 'VBG'), ('image', 'NN'), ('video', 'NN'), ('frame', 'NN'), ('video', 'NN'), ('mobile', 'JJ'), ('device', 'NN'), ('recited', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('communication', 'NN'), ('system', 'NN'), ('connects', 'VBZ'), ('remote', 'JJ'), ('server', 'NN'), ('includes', 'VBZ'), ('facial', 'JJ'), ('recognition', 'NN'), ('network', 'NN'), ('mobile', 'JJ'), ('device', 'NN'), ('recited', 'VBD'), ('claim', 'NN'), ('wherein', 'IN'), ('one', 'CD'), ('stage', 'NN'), ('alternative', 'JJ'), ('bi-stage', 'NN'), ('strategy', 'NN'), ('fixes', 'NNS'), ('feature', 'VBP'), ('extractor', 'NN'), ('applies', 'NNS'), ('feature', 'VBP'), ('generator', 'NN'), ('generate', 'VBP'), ('new', 'JJ'), ('transferred', 'VBN'), ('features', 'NNS'), ('diverse', 'JJ'), ('violate', 'JJ'), ('decision', 'NN'), ('boundary', 'NN'), ('mobile', 'JJ'), ('device', 'NN'), ('recited', 'VBD'), ('claim', 'NN'), ('wherein', 'IN'), ('one', 'CD'), ('stage', 'NN'), ('alternative', 'JJ'), ('bi-stage', 'NN'), ('strategy', 'NN'), ('fixes', 'NNS'), ('fully', 'RB'), ('connected', 'VBN'), ('classifier', 'JJR'), ('updates', 'JJ'), ('feature', 'NN'), ('extractor', 'NN'), ('feature', 'NN'), ('generator', 'NN'), ('computer', 'NN'), ('program', 'NN'), ('product', 'NN'), ('mobile', 'JJ'), ('device', 'NN'), ('facial', 'JJ'), ('recognition', 'NN'), ('computer', 'NN'), ('program', 'NN'), ('product', 'NN'), ('comprising', 'VBG'), ('non-transitory', 'JJ'), ('computer', 'NN'), ('readable', 'JJ'), ('storage', 'NN'), ('medium', 'NN'), ('program', 'NN'), ('instructions', 'NNS'), ('embodied', 'VBD'), ('therewith', 'JJ'), ('program', 'NN'), ('instructions', 'NNS'), ('executable', 'JJ'), ('computer', 'NN'), ('cause', 'NN'), ('computer', 'NN'), ('perform', 'NN'), ('method', 'NN'), ('comprising', 'VBG'), ('receiving', 'VBG'), ('processor', 'NN'), ('device', 'NN'), ('plurality', 'NN'), ('images', 'VBZ'), ('extracting', 'VBG'), ('processor', 'NN'), ('device', 'NN'), ('feature', 'NN'), ('extractor', 'NN'), ('utilizing', 'JJ'), ('convolutional', 'JJ'), ('neural', 'JJ'), ('network', 'NN'), ('cnn', 'NNS'), ('enlarged', 'VBD'), ('intra-class', 'JJ'), ('variance', 'NN'), ('long-tail', 'JJ'), ('classes', 'NNS'), ('feature', 'VBP'), ('vectors', 'NNS'), ('plurality', 'NN'), ('images', 'NNS'), ('generating', 'VBG'), ('processor', 'NN'), ('device', 'NN'), ('feature', 'NN'), ('generator', 'NN'), ('discriminative', 'JJ'), ('feature', 'NN'), ('vectors', 'NNS'), ('feature', 'VBP'), ('vectors', 'NNS'), ('classifying', 'VBG'), ('processor', 'NN'), ('device', 'NN'), ('utilizing', 'VBG'), ('fully', 'RB'), ('connected', 'VBN'), ('classifier', 'JJR'), ('identity', 'NN'), ('discriminative', 'JJ'), ('feature', 'NN'), ('vector', 'NN'), ('controlling', 'VBG'), ('operation', 'NN'), ('mobile', 'JJ'), ('device', 'NN'), ('react', 'NN'), ('accordance', 'NN'), ('identity', 'NN'), ('computer-implemented', 'JJ'), ('method', 'NN'), ('facial', 'JJ'), ('recognition', 'NN'), ('mobile', 'JJ'), ('device', 'NN'), ('method', 'NN'), ('comprising', 'VBG'), ('receiving', 'VBG'), ('processor', 'NN'), ('device', 'NN'), ('plurality', 'NN'), ('images', 'VBZ'), ('extracting', 'VBG'), ('processor', 'NN'), ('device', 'NN'), ('feature', 'NN'), ('extractor', 'NN'), ('utilizing', 'JJ'), ('convolutional', 'JJ'), ('neural', 'JJ'), ('network', 'NN'), ('cnn', 'NNS'), ('enlarged', 'VBD'), ('intra-class', 'JJ'), ('variance', 'NN'), ('long-tail', 'JJ'), ('classes', 'NNS'), ('feature', 'VBP'), ('vectors', 'NNS'), ('plurality', 'NN'), ('images', 'NNS'), ('generating', 'VBG'), ('processor', 'NN'), ('device', 'NN'), ('feature', 'NN'), ('generator', 'NN'), ('discriminative', 'JJ'), ('feature', 'NN'), ('vectors', 'NNS'), ('feature', 'VBP'), ('vectors', 'NNS'), ('classifying', 'VBG'), ('processor', 'NN'), ('device', 'NN'), ('utilizing', 'VBG'), ('fully', 'RB'), ('connected', 'VBN'), ('classifier', 'JJR'), ('identity', 'NN'), ('discriminative', 'JJ'), ('feature', 'NN'), ('vector', 'NN'), ('controlling', 'VBG'), ('operation', 'NN'), ('mobile', 'JJ'), ('device', 'NN'), ('react', 'NN'), ('accordance', 'NN'), ('identity', 'NN'), ('computer-implemented', 'JJ'), ('method', 'NN'), ('recited', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('controlling', 'VBG'), ('includes', 'VBZ'), ('tagging', 'VBG'), ('video', 'NN'), ('identity', 'NN'), ('uploading', 'VBG'), ('video', 'JJ'), ('social', 'JJ'), ('media', 'NNS'), ('computer-implemented', 'JJ'), ('method', 'NN'), ('recited', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('controlling', 'VBG'), ('includes', 'VBZ'), ('tagging', 'VBG'), ('video', 'NN'), ('identity', 'NN'), ('sending', 'VBG'), ('video', 'JJ'), ('user', 'JJ'), ('computer-implemented', 'JJ'), ('method', 'NN'), ('recited', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('extracting', 'VBG'), ('includes', 'VBZ'), ('sharing', 'VBG'), ('covariance', 'NN'), ('matrices', 'NNS'), ('across', 'IN'), ('classes', 'NNS'), ('transfer', 'VBP'), ('intra-class', 'JJ'), ('variance', 'NN'), ('regular', 'JJ'), ('classes', 'NNS'), ('long-tail', 'JJ'), ('classes', 'NNS'), ('computing', 'VBG'), ('device', 'NN'), ('comprising', 'VBG'), ('non-transitory', 'JJ'), ('machine', 'NN'), ('readable', 'JJ'), ('medium', 'NN'), ('storing', 'VBG'), ('machine', 'NN'), ('trained', 'VBN'), ('mt', 'JJ'), ('network', 'NN'), ('comprising', 'VBG'), ('plurality', 'NN'), ('layers', 'NNS'), ('processing', 'VBG'), ('nodes', 'NNS'), ('processing', 'VBG'), ('node', 'RB'), ('configured', 'VBN'), ('compute', 'NN'), ('first', 'RB'), ('output', 'NN'), ('value', 'NN'), ('combining', 'VBG'), ('set', 'VBN'), ('output', 'NN'), ('values', 'NNS'), ('set', 'VBD'), ('processing', 'VBG'), ('nodes', 'NNS'), ('use', 'VBP'), ('piecewise', 'JJ'), ('linear', 'JJ'), ('cup', 'NN'), ('function', 'NN'), ('compute', 'JJ'), ('second', 'JJ'), ('output', 'NN'), ('value', 'NN'), ('first', 'RB'), ('output', 'NN'), ('value', 'NN'), ('processing', 'VBG'), ('node', 'JJ'), ('wherein', 'NN'), ('piecewise', 'NN'), ('linear', 'JJ'), ('cup', 'NN'), ('function', 'NN'), ('prior', 'RB'), ('training', 'VBG'), ('mt', 'NN'), ('network', 'NN'), ('comprises', 'NNS'), ('least', 'VBP'), ('first', 'JJ'), ('linear', 'JJ'), ('section', 'NN'), ('first', 'RB'), ('slope', 'NN'), ('followed', 'VBD'), ('ii', 'JJ'), ('second', 'JJ'), ('linear', 'JJ'), ('section', 'NN'), ('negative', 'JJ'), ('second', 'JJ'), ('slope', 'NN'), ('followed', 'VBD'), ('iii', 'JJ'), ('third', 'JJ'), ('linear', 'JJ'), ('section', 'NN'), ('negative', 'JJ'), ('third', 'JJ'), ('slope', 'NN'), ('different', 'JJ'), ('second', 'JJ'), ('slope', 'NN'), ('followed', 'VBD'), ('iv', 'JJ'), ('fourth', 'JJ'), ('linear', 'JJ'), ('section', 'NN'), ('positive', 'JJ'), ('fourth', 'JJ'), ('slope', 'NN'), ('followed', 'VBD'), ('v', 'JJ'), ('fifth', 'JJ'), ('linear', 'JJ'), ('section', 'NN'), ('positive', 'JJ'), ('fifth', 'JJ'), ('slope', 'NN'), ('different', 'JJ'), ('fourth', 'JJ'), ('slope', 'NN'), ('followed', 'VBD'), ('vi', 'JJ'), ('sixth', 'JJ'), ('linear', 'JJ'), ('section', 'NN'), ('sixth', 'VBD'), ('slope', 'NN'), ('wherein', 'NN'), ('piecewise', 'NN'), ('linear', 'JJ'), ('cup', 'NN'), ('function', 'NN'), ('symmetric', 'JJ'), ('vertical', 'JJ'), ('axis', 'NN'), ('third', 'JJ'), ('fourth', 'JJ'), ('linear', 'JJ'), ('sections', 'NNS'), ('prior', 'RB'), ('training', 'VBG'), ('mt', 'NN'), ('network', 'NN'), ('content', 'JJ'), ('capturing', 'NN'), ('circuit', 'NN'), ('capturing', 'VBG'), ('content', 'JJ'), ('processing', 'NN'), ('mt', 'NN'), ('network', 'NN'), ('set', 'VBN'), ('processing', 'VBG'), ('units', 'NNS'), ('executing', 'VBG'), ('processing', 'VBG'), ('nodes', 'NNS'), ('process', 'NN'), ('content', 'NN'), ('captured', 'VBD'), ('content', 'JJ'), ('capturing', 'VBG'), ('circuit', 'NN'), ('wherein', 'NN'), ('training', 'NN'), ('set', 'VBN'), ('parameters', 'NNS'), ('define', 'VBP'), ('piecewise', 'NN'), ('linear', 'JJ'), ('cup', 'NN'), ('function', 'NN'), ('node', 'IN'), ('first', 'JJ'), ('second', 'JJ'), ('pluralities', 'NNS'), ('processing', 'VBG'), ('nodes', 'NNS'), ('processing', 'VBG'), ('node', 'NN'), ('first', 'JJ'), ('plurality', 'NN'), ('processing', 'NN'), ('nodes', 'NNS'), ('configured', 'VBD'), ('emulate', 'JJ'), ('boolean', 'NN'), ('operator', 'NN'), ('output', 'NN'), ('value', 'NN'), ('processing', 'NN'), ('node', 'JJ'), ('range', 'NN'), ('associated', 'VBN'), ('``', '``'), (\"''\", \"''\"), ('value', 'NN'), ('set', 'VBN'), ('inputs', 'NNS'), ('processing', 'VBG'), ('node', 'NN'), ('set', 'VBN'), ('values', 'NNS'), ('range', 'VBP'), ('associated', 'VBN'), ('``', '``'), (\"''\", \"''\"), ('ii', 'NN'), ('processing', 'NN'), ('node', 'JJ'), ('second', 'JJ'), ('plurality', 'NN'), ('processing', 'NN'), ('nodes', 'NNS'), ('configured', 'VBD'), ('emulate', 'JJ'), ('boolean', 'JJ'), ('xnor', 'NN'), ('operator', 'NN'), ('output', 'NN'), ('value', 'NN'), ('processing', 'NN'), ('node', 'JJ'), ('range', 'NN'), ('associated', 'VBN'), ('``', '``'), (\"''\", \"''\"), ('set', 'NN'), ('inputs', 'NNS'), ('node', 'JJ'), ('set', 'NN'), ('values', 'NNS'), ('range', 'VBP'), ('associated', 'VBN'), ('``', '``'), (\"''\", \"''\"), ('b', 'NN'), ('set', 'VBN'), ('inputs', 'NNS'), ('node', 'JJ'), ('set', 'NN'), ('values', 'NNS'), ('range', 'VBP'), ('associated', 'VBN'), ('``', '``'), (\"''\", \"''\"), ('value', 'NN'), ('computing', 'VBG'), ('device', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('third', 'JJ'), ('linear', 'JJ'), ('section', 'NN'), ('piecewise', 'NN'), ('linear', 'JJ'), ('cup', 'NN'), ('function', 'NN'), ('first', 'RB'), ('processing', 'VBG'), ('node', 'NN'), ('mt', 'NN'), ('network', 'NN'), ('different', 'JJ'), ('slope', 'NN'), ('third', 'JJ'), ('linear', 'JJ'), ('section', 'NN'), ('second', 'JJ'), ('processing', 'NN'), ('node', 'NN'), ('mt', 'NN'), ('network', 'NN'), ('computing', 'VBG'), ('device', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('length', 'VBZ'), ('third', 'JJ'), ('section', 'NN'), ('piecewise', 'NN'), ('linear', 'JJ'), ('cup', 'NN'), ('function', 'NN'), ('first', 'RB'), ('processing', 'VBG'), ('node', 'NN'), ('mt', 'NN'), ('network', 'NN'), ('different', 'JJ'), ('length', 'NN'), ('third', 'JJ'), ('section', 'NN'), ('piecewise', 'NN'), ('linear', 'JJ'), ('cup', 'NN'), ('function', 'NN'), ('second', 'JJ'), ('processing', 'NN'), ('node', 'NN'), ('mt', 'NN'), ('network', 'NN'), ('computing', 'VBG'), ('device', 'NN'), ('claim', 'NN'), ('wherein', 'JJ'), ('sets', 'VBZ'), ('parameters', 'NNS'), ('trained', 'VBD'), ('part', 'NN'), ('back', 'RB'), ('propagating', 'VBG'), ('module', 'NN'), ('back', 'RB'), ('propagating', 'JJ'), ('errors', 'NNS'), ('output', 'NN'), ('values', 'NNS'), ('later', 'RBR'), ('layers', 'NNS'), ('processing', 'VBG'), ('nodes', 'NNS'), ('earlier', 'RBR'), ('layers', 'NNS'), ('processing', 'VBG'), ('nodes', 'NNS'), ('adjusting', 'VBG'), ('set', 'NN'), ('parameters', 'NNS'), ('define', 'VBP'), ('piecewise', 'NN'), ('linear', 'JJ'), ('cup', 'NN'), ('functions', 'NNS'), ('earlier', 'RBR'), ('layers', 'NNS'), ('processing', 'VBG'), ('nodes', 'NNS'), ('computing', 'VBG'), ('device', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('processing', 'NN'), ('node', 'JJ'), ('uses', 'NNS'), ('linear', 'JJ'), ('function', 'NN'), ('defined', 'VBD'), ('set', 'VBN'), ('parameters', 'NNS'), ('compute', 'VBP'), ('first', 'JJ'), ('output', 'NN'), ('value', 'NN'), ('processing', 'VBG'), ('node', 'CC'), ('wherein', 'JJ'), ('back', 'RB'), ('propagating', 'VBG'), ('module', 'NN'), ('back', 'RB'), ('propagates', 'VBZ'), ('errors', 'NNS'), ('output', 'NN'), ('values', 'NNS'), ('later', 'RBR'), ('layers', 'NNS'), ('processing', 'VBG'), ('nodes', 'NNS'), ('earlier', 'RBR'), ('layers', 'NNS'), ('processing', 'VBG'), ('nodes', 'NNS'), ('adjusting', 'VBG'), ('set', 'NN'), ('parameters', 'NNS'), ('define', 'VBP'), ('linear', 'JJ'), ('functions', 'NNS'), ('earlier', 'RBR'), ('layers', 'NNS'), ('processing', 'VBG'), ('nodes', 'NNS'), ('computing', 'VBG'), ('device', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('first', 'JJ'), ('plurality', 'NN'), ('processing', 'NN'), ('nodes', 'NNS'), ('emulate', 'VBP'), ('boolean', 'JJ'), ('operator', 'NN'), ('second', 'JJ'), ('plurality', 'NN'), ('processing', 'NN'), ('nodes', 'NNS'), ('emulate', 'VBP'), ('boolean', 'JJ'), ('xnor', 'NNP'), ('operator', 'NN'), ('enable', 'JJ'), ('mt', 'NN'), ('network', 'NN'), ('implement', 'JJ'), ('mathematical', 'JJ'), ('problems', 'NNS'), ('computing', 'VBG'), ('device', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('plurality', 'NN'), ('processing', 'NN'), ('node', 'NN'), ('layers', 'NNS'), ('plurality', 'NN'), ('processing', 'NN'), ('nodes', 'NNS'), ('receive', 'VBP'), ('input', 'NN'), ('values', 'NNS'), ('output', 'NN'), ('values', 'NNS'), ('plurality', 'NN'), ('processing', 'NN'), ('nodes', 'NNS'), ('set', 'VBD'), ('prior', 'JJ'), ('layers', 'NNS'), ('computing', 'VBG'), ('device', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('processing', 'NN'), ('node', 'JJ'), ('uses', 'NNS'), ('linear', 'JJ'), ('function', 'NN'), ('compute', 'NN'), ('first', 'RB'), ('output', 'NN'), ('value', 'NN'), ('processing', 'VBG'), ('node', 'JJ'), ('wherein', 'NN'), ('processing', 'VBG'), ('node', 'NN'), (\"'s\", 'POS'), ('piecewise', 'NN'), ('linear', 'JJ'), ('cup', 'NN'), ('function', 'NN'), ('defined', 'VBD'), ('along', 'IN'), ('first', 'JJ'), ('second', 'JJ'), ('axes', 'NNS'), ('first', 'RB'), ('axis', 'VBP'), ('defining', 'VBG'), ('range', 'NN'), ('output', 'NN'), ('values', 'NNS'), ('processing', 'VBG'), ('node', 'NN'), (\"'s\", 'POS'), ('linear', 'JJ'), ('function', 'NN'), ('second', 'JJ'), ('axis', 'NN'), ('defining', 'VBG'), ('range', 'NN'), ('output', 'NN'), ('values', 'NNS'), ('produced', 'VBD'), ('piecewise', 'JJ'), ('linear', 'JJ'), ('cup', 'NN'), ('function', 'NN'), ('range', 'NN'), ('output', 'NN'), ('values', 'NNS'), ('processing', 'VBG'), ('node', 'NN'), (\"'s\", 'POS'), ('linear', 'JJ'), ('function', 'NN'), ('computing', 'VBG'), ('device', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('content', 'JJ'), ('output', 'NN'), ('circuit', 'NN'), ('presenting', 'VBG'), ('output', 'NN'), ('based', 'VBN'), ('processing', 'NN'), ('content', 'NN'), ('mt', 'NN'), ('network', 'NN'), ('computing', 'VBG'), ('device', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('captured', 'VBD'), ('content', 'JJ'), ('one', 'CD'), ('image', 'NN'), ('audio', 'NN'), ('segment', 'NN'), ('wherein', 'NN'), ('presented', 'VBD'), ('output', 'NN'), ('output', 'NN'), ('display', 'VBP'), ('display', 'NN'), ('screen', 'NN'), ('computing', 'VBG'), ('device', 'NN'), ('audio', 'NN'), ('presentation', 'NN'), ('output', 'NN'), ('speaker', 'NN'), ('computing', 'VBG'), ('device', 'NN'), ('computing', 'VBG'), ('device', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('computing', 'VBG'), ('device', 'NN'), ('mobile', 'JJ'), ('device', 'NN'), ('computing', 'VBG'), ('device', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('mt', 'NN'), ('network', 'NN'), ('mt', 'NN'), ('neural', 'JJ'), ('network', 'NN'), ('processing', 'VBG'), ('nodes', 'NNS'), ('mt', 'JJ'), ('neurons', 'NNS'), ('computing', 'VBG'), ('device', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('set', 'VBN'), ('parameters', 'NNS'), ('configured', 'VBD'), ('training', 'VBG'), ('plurality', 'NN'), ('processing', 'NN'), ('nodes', 'NNS'), ('comprise', 'VBP'), ('least', 'JJS'), ('one', 'CD'), ('negative', 'JJ'), ('second', 'JJ'), ('third', 'JJ'), ('slopes', 'NNS'), ('second', 'JJ'), ('third', 'JJ'), ('linear', 'JJ'), ('sections', 'NNS'), ('positive', 'JJ'), ('fourth', 'JJ'), ('fifth', 'JJ'), ('slopes', 'NNS'), ('fourth', 'JJ'), ('fifth', 'JJ'), ('linear', 'NN'), ('sections', 'NNS'), ('first', 'RB'), ('intercept', 'JJ'), ('second', 'JJ'), ('linear', 'JJ'), ('section', 'NN'), ('second', 'JJ'), ('intercept', 'NN'), ('fifth', 'JJ'), ('linear', 'JJ'), ('section', 'NN'), ('set', 'VBN'), ('lengths', 'NNS'), ('least', 'JJS'), ('second', 'JJ'), ('third', 'JJ'), ('fourth', 'JJ'), ('fifth', 'JJ'), ('sections', 'NNS'), ('computing', 'VBG'), ('device', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('trained', 'VBD'), ('set', 'VBN'), ('parameters', 'NNS'), ('define', 'VBP'), ('piecewise', 'NN'), ('linear', 'JJ'), ('cup', 'NN'), ('function', 'NN'), ('node', 'NN'), ('comprise', 'NN'), ('plurality', 'NN'), ('output', 'NN'), ('values', 'NNS'), ('computing', 'VBG'), ('device', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('first', 'JJ'), ('sixth', 'JJ'), ('slopes', 'NNS'), ('zerowe', 'VBP'), ('claim', 'NN'), ('system', 'NN'), ('comprising', 'VBG'), ('memory', 'NN'), ('device', 'NN'), ('store', 'NN'), ('input', 'NN'), ('image', 'NN'), ('processor', 'NN'), ('including', 'VBG'), ('image', 'NN'), ('input', 'NN'), ('interface', 'VBP'), ('receive', 'JJ'), ('input', 'NN'), ('image', 'NN'), ('pre-processor', 'JJ'), ('model', 'NN'), ('input', 'NN'), ('image', 'NN'), ('yield', 'NN'), ('multi-channel', 'JJ'), ('image', 'NN'), ('feature', 'NN'), ('extractor', 'NN'), ('extract', 'NN'), ('set', 'VBN'), ('features', 'NNS'), ('based', 'VBN'), ('multi-channel', 'JJ'), ('image', 'NN'), ('feature', 'NN'), ('selector', 'NN'), ('select', 'VBP'), ('one', 'CD'), ('features', 'VBZ'), ('set', 'VBN'), ('features', 'NNS'), ('multi-channel', 'JJ'), ('image', 'NN'), ('wherein', 'VBD'), ('one', 'CD'), ('features', 'NNS'), ('selected', 'VBN'), ('based', 'VBN'), ('ability', 'NN'), ('differentiate', 'NN'), ('features', 'NNS'), ('feature', 'VBP'), ('matcher', 'JJR'), ('match', 'NN'), ('one', 'CD'), ('features', 'NNS'), ('learned', 'VBD'), ('feature', 'NN'), ('set', 'VBN'), ('similarity', 'NN'), ('detector', 'NN'), ('determine', 'NN'), ('whether', 'IN'), ('one', 'CD'), ('features', 'VBZ'), ('meet', 'RBS'), ('pre-defined', 'JJ'), ('similarity', 'NN'), ('threshold', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('pre-processor', 'JJ'), ('activate', 'NN'), ('one', 'CD'), ('channels', 'VBZ'), ('multi-channel', 'NN'), ('image', 'NN'), ('yield', 'NN'), ('one', 'CD'), ('activated', 'VBN'), ('channels', 'NNS'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'VBP'), ('one', 'CD'), ('activated', 'VBN'), ('channels', 'NNS'), ('determined', 'VBN'), ('based', 'VBN'), ('ability', 'NN'), ('differentiate', 'NN'), ('features', 'NNS'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('pre-processor', 'JJ'), ('activate', 'NN'), ('one', 'CD'), ('local', 'JJ'), ('patches', 'VBZ'), ('one', 'CD'), ('activated', 'VBN'), ('channels', 'NNS'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'VBP'), ('one', 'CD'), ('local', 'JJ'), ('patches', 'NNS'), ('determined', 'VBD'), ('based', 'VBN'), ('ability', 'NN'), ('differentiate', 'NN'), ('features', 'NNS'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'JJ'), ('feature', 'NN'), ('matcher', 'NN'), ('utilize', 'JJ'), ('large-scale', 'JJ'), ('data', 'NNS'), ('learning', 'VBG'), ('process', 'NN'), ('perform', 'NN'), ('feature', 'NN'), ('matching', 'VBG'), ('apparatus', 'NN'), ('comprising', 'VBG'), ('image', 'NN'), ('input', 'NN'), ('interface', 'VBP'), ('receive', 'JJ'), ('input', 'NN'), ('image', 'NN'), ('pre-processor', 'JJ'), ('model', 'NN'), ('input', 'NN'), ('image', 'NN'), ('yield', 'NN'), ('multi-channel', 'JJ'), ('image', 'NN'), ('feature', 'NN'), ('extractor', 'NN'), ('extract', 'NN'), ('set', 'VBN'), ('features', 'NNS'), ('based', 'VBN'), ('multi-channel', 'JJ'), ('image', 'NN'), ('feature', 'NN'), ('selector', 'NN'), ('select', 'VBP'), ('one', 'CD'), ('features', 'VBZ'), ('set', 'VBN'), ('features', 'NNS'), ('multi-channel', 'JJ'), ('image', 'NN'), ('wherein', 'VBD'), ('one', 'CD'), ('features', 'NNS'), ('selected', 'VBN'), ('based', 'VBN'), ('ability', 'NN'), ('differentiate', 'NN'), ('features', 'NNS'), ('feature', 'VBP'), ('matcher', 'JJR'), ('match', 'NN'), ('one', 'CD'), ('features', 'NNS'), ('learned', 'VBD'), ('feature', 'NN'), ('set', 'VBN'), ('similarity', 'NN'), ('detector', 'NN'), ('determine', 'NN'), ('whether', 'IN'), ('one', 'CD'), ('features', 'VBZ'), ('meet', 'RBS'), ('pre-defined', 'JJ'), ('similarity', 'NN'), ('threshold', 'NN'), ('apparatus', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('pre-processor', 'JJ'), ('activate', 'NN'), ('one', 'CD'), ('channels', 'VBZ'), ('multi-channel', 'NN'), ('image', 'NN'), ('yield', 'NN'), ('one', 'CD'), ('activated', 'VBN'), ('channels', 'NNS'), ('apparatus', 'VBP'), ('claim', 'NN'), ('wherein', 'VBP'), ('one', 'CD'), ('activated', 'VBN'), ('channels', 'NNS'), ('determined', 'VBN'), ('based', 'VBN'), ('ability', 'NN'), ('differentiate', 'NN'), ('features', 'NNS'), ('apparatus', 'VBP'), ('claim', 'NN'), ('wherein', 'IN'), ('pre-processor', 'JJ'), ('activate', 'NN'), ('one', 'CD'), ('local', 'JJ'), ('patches', 'VBZ'), ('one', 'CD'), ('activated', 'JJ'), ('channels', 'NNS'), ('apparatus', 'VBP'), ('claim', 'NN'), ('wherein', 'VBP'), ('one', 'CD'), ('local', 'JJ'), ('patches', 'NNS'), ('determined', 'VBD'), ('based', 'VBN'), ('ability', 'NN'), ('differentiate', 'NN'), ('features', 'NNS'), ('apparatus', 'VBP'), ('claim', 'NN'), ('wherein', 'NN'), ('feature', 'NN'), ('matcher', 'NN'), ('utilize', 'JJ'), ('large-scale', 'JJ'), ('data', 'NNS'), ('learning', 'VBG'), ('process', 'NN'), ('perform', 'NN'), ('feature', 'NN'), ('matching', 'VBG'), ('method', 'NN'), ('comprising', 'VBG'), ('modeling', 'VBG'), ('input', 'NN'), ('image', 'NN'), ('yield', 'NN'), ('multi-channel', 'JJ'), ('image', 'NN'), ('extracting', 'VBG'), ('set', 'VBN'), ('features', 'NNS'), ('based', 'VBN'), ('multi-channel', 'JJ'), ('image', 'NN'), ('selecting', 'VBG'), ('one', 'CD'), ('features', 'VBZ'), ('set', 'VBN'), ('features', 'NNS'), ('multi-channel', 'JJ'), ('image', 'NN'), ('wherein', 'VBD'), ('one', 'CD'), ('features', 'NNS'), ('selected', 'VBN'), ('based', 'VBN'), ('ability', 'NN'), ('differentiate', 'NN'), ('features', 'NNS'), ('matching', 'VBG'), ('one', 'CD'), ('features', 'NNS'), ('learned', 'VBD'), ('feature', 'NN'), ('set', 'VBN'), ('determining', 'VBG'), ('whether', 'IN'), ('one', 'CD'), ('features', 'VBZ'), ('meet', 'RBS'), ('pre-defined', 'JJ'), ('similarity', 'NN'), ('threshold', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('modeling', 'VBG'), ('input', 'JJ'), ('image', 'NN'), ('include', 'VBP'), ('activating', 'VBG'), ('one', 'CD'), ('channels', 'JJ'), ('multi-channel', 'JJ'), ('image', 'NN'), ('yield', 'NN'), ('one', 'CD'), ('activated', 'VBN'), ('channels', 'NNS'), ('method', 'VBP'), ('claim', 'NN'), ('wherein', 'VBP'), ('one', 'CD'), ('activated', 'VBN'), ('channels', 'NNS'), ('determined', 'VBN'), ('based', 'VBN'), ('ability', 'NN'), ('differentiate', 'NN'), ('features', 'NNS'), ('method', 'VBP'), ('claim', 'NN'), ('wherein', 'NN'), ('extracting', 'VBG'), ('features', 'NNS'), ('input', 'JJ'), ('image', 'NN'), ('include', 'VBP'), ('activating', 'VBG'), ('one', 'CD'), ('local', 'JJ'), ('patches', 'VBZ'), ('one', 'CD'), ('activated', 'JJ'), ('channels', 'NNS'), ('method', 'VBP'), ('claim', 'NN'), ('wherein', 'VBP'), ('one', 'CD'), ('local', 'JJ'), ('patches', 'NNS'), ('determined', 'VBD'), ('based', 'VBN'), ('ability', 'NN'), ('differentiate', 'NN'), ('features', 'NNS'), ('method', 'VBP'), ('claim', 'NN'), ('wherein', 'NN'), ('feature', 'NN'), ('matcher', 'NN'), ('utilizes', 'JJ'), ('large-scale', 'JJ'), ('data', 'NNS'), ('learning', 'VBG'), ('process', 'NN'), ('perform', 'NN'), ('feature', 'NN'), ('matching', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('non-transitory', 'JJ'), ('computer', 'NN'), ('readable', 'JJ'), ('storage', 'NN'), ('medium', 'NN'), ('comprising', 'VBG'), ('set', 'VBN'), ('instructions', 'NNS'), ('executed', 'VBD'), ('computing', 'VBG'), ('device', 'NN'), ('cause', 'NN'), ('computing', 'VBG'), ('device', 'NN'), ('model', 'NN'), ('input', 'NN'), ('image', 'NN'), ('yield', 'NN'), ('multi-channel', 'JJ'), ('image', 'NN'), ('extract', 'NN'), ('set', 'VBN'), ('features', 'NNS'), ('based', 'VBN'), ('multi-channel', 'JJ'), ('image', 'NN'), ('select', 'VBP'), ('one', 'CD'), ('features', 'VBZ'), ('set', 'VBN'), ('features', 'NNS'), ('multi-channel', 'JJ'), ('image', 'NN'), ('wherein', 'NN'), ('features', 'VBZ'), ('selected', 'VBN'), ('based', 'VBN'), ('ability', 'NN'), ('differentiate', 'NN'), ('features', 'NNS'), ('match', 'VBP'), ('one', 'CD'), ('features', 'NNS'), ('learned', 'VBD'), ('feature', 'NN'), ('set', 'VBN'), ('determine', 'NN'), ('whether', 'IN'), ('one', 'CD'), ('features', 'VBZ'), ('meet', 'RBS'), ('pre-defined', 'JJ'), ('similarity', 'NN'), ('threshold', 'VBD'), ('least', 'JJS'), ('one', 'CD'), ('non-transitory', 'JJ'), ('computer', 'NN'), ('readable', 'JJ'), ('storage', 'NN'), ('medium', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('instructions', 'NNS'), ('executed', 'VBD'), ('cause', 'NN'), ('computing', 'VBG'), ('device', 'NN'), ('activate', 'VBP'), ('one', 'CD'), ('channels', 'NNS'), ('multi-channel', 'JJ'), ('image', 'NN'), ('yield', 'NN'), ('one', 'CD'), ('activated', 'VBN'), ('channels', 'NNS'), ('least', 'JJS'), ('one', 'CD'), ('non-transitory', 'JJ'), ('computer', 'NN'), ('readable', 'JJ'), ('storage', 'NN'), ('medium', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('instructions', 'NNS'), ('executed', 'VBD'), ('cause', 'NN'), ('computing', 'VBG'), ('device', 'NN'), ('determine', 'NN'), ('one', 'CD'), ('activated', 'VBN'), ('channels', 'NNS'), ('based', 'VBN'), ('ability', 'NN'), ('differentiate', 'NN'), ('features', 'NNS'), ('least', 'VBP'), ('one', 'CD'), ('non-transitory', 'JJ'), ('computer', 'NN'), ('readable', 'JJ'), ('storage', 'NN'), ('medium', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('extracting', 'VBG'), ('features', 'NNS'), ('input', 'JJ'), ('image', 'NN'), ('include', 'VBP'), ('activating', 'VBG'), ('one', 'CD'), ('local', 'JJ'), ('patches', 'VBZ'), ('one', 'CD'), ('activated', 'JJ'), ('channels', 'NNS'), ('least', 'JJS'), ('one', 'CD'), ('non-transitory', 'JJ'), ('computer', 'NN'), ('readable', 'JJ'), ('storage', 'NN'), ('medium', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('one', 'CD'), ('local', 'JJ'), ('patches', 'NNS'), ('determined', 'VBD'), ('based', 'VBN'), ('ability', 'NN'), ('differentiate', 'NN'), ('features', 'NNS'), ('least', 'VBP'), ('one', 'CD'), ('non-transitory', 'JJ'), ('computer', 'NN'), ('readable', 'JJ'), ('storage', 'NN'), ('medium', 'NN'), ('claim', 'NN'), ('wherein', 'JJ'), ('feature', 'NN'), ('matcher', 'NN'), ('utilize', 'JJ'), ('large-scale', 'JJ'), ('data', 'NNS'), ('learning', 'VBG'), ('process', 'NN'), ('perform', 'NN'), ('feature', 'NN'), ('matching', 'VBG'), ('apparatus', 'NN'), ('comprising', 'VBG'), ('means', 'NNS'), ('modeling', 'VBG'), ('input', 'NN'), ('image', 'NN'), ('yield', 'NN'), ('multi-channel', 'JJ'), ('image', 'NN'), ('means', 'VBZ'), ('extracting', 'VBG'), ('set', 'VBN'), ('features', 'NNS'), ('based', 'VBN'), ('multi-channel', 'JJ'), ('image', 'NN'), ('means', 'VBZ'), ('selecting', 'VBG'), ('one', 'CD'), ('features', 'VBZ'), ('set', 'VBN'), ('features', 'NNS'), ('multi-channel', 'JJ'), ('image', 'NN'), ('wherein', 'VBD'), ('one', 'CD'), ('features', 'NNS'), ('selected', 'VBN'), ('based', 'VBN'), ('ability', 'NN'), ('differentiate', 'NN'), ('features', 'NNS'), ('means', 'VBZ'), ('matching', 'VBG'), ('one', 'CD'), ('features', 'NNS'), ('learned', 'VBD'), ('feature', 'NN'), ('set', 'VBN'), ('means', 'VBZ'), ('determining', 'VBG'), ('whether', 'IN'), ('one', 'CD'), ('features', 'VBZ'), ('meet', 'RBS'), ('pre-defined', 'JJ'), ('similarity', 'NN'), ('threshold', 'NN'), ('method', 'NN'), ('controlling', 'VBG'), ('terminal', 'JJ'), ('terminal', 'JJ'), ('comprising', 'VBG'), ('capturing', 'VBG'), ('apparatus', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('processor', 'NN'), ('method', 'NN'), ('comprising', 'VBG'), ('acquiring', 'VBG'), ('capturing', 'VBG'), ('apparatus', 'JJ'), ('image', 'NN'), ('obtaining', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('processor', 'NN'), ('motion', 'NN'), ('parameter', 'NN'), ('terminal', 'JJ'), ('motion', 'NN'), ('parameter', 'NN'), ('comprising', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('motion', 'NN'), ('frequency', 'NN'), ('motion', 'NN'), ('time', 'NN'), ('two', 'CD'), ('parameters', 'NNS'), ('among', 'IN'), ('acceleration', 'NN'), ('angular', 'JJ'), ('velocity', 'NN'), ('motion', 'NN'), ('amplitude', 'NN'), ('motion', 'NN'), ('frequency', 'NN'), ('motion', 'NN'), ('time', 'NN'), ('transmitting', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('processor', 'NN'), ('parameter', 'NN'), ('threshold', 'VBD'), ('obtaining', 'VBG'), ('request', 'NN'), ('data', 'NNS'), ('management', 'NN'), ('server', 'RB'), ('parameter', 'RB'), ('threshold', 'JJ'), ('obtaining', 'VBG'), ('request', 'NN'), ('comprising', 'VBG'), ('configuration', 'NN'), ('information', 'NN'), ('terminal', 'NN'), ('receiving', 'NN'), ('corresponding', 'VBG'), ('preset', 'NN'), ('thresholds', 'NNS'), ('correspond', 'NN'), ('configuration', 'NN'), ('information', 'NN'), ('response', 'NN'), ('parameter', 'NN'), ('threshold', 'VBD'), ('obtaining', 'VBG'), ('request', 'NN'), ('comparing', 'VBG'), ('two', 'CD'), ('parameters', 'NNS'), ('corresponding', 'VBG'), ('preset', 'NN'), ('thresholds', 'NNS'), ('controlling', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('processor', 'NN'), ('perform', 'NN'), ('image', 'NN'), ('processing', 'NN'), ('acquired', 'VBD'), ('image', 'NN'), ('based', 'VBN'), ('least', 'JJS'), ('one', 'CD'), ('two', 'CD'), ('parameters', 'NNS'), ('motion', 'VBP'), ('parameter', 'RB'), ('greater', 'JJR'), ('corresponding', 'VBG'), ('preset', 'NN'), ('threshold', 'NN'), ('based', 'VBN'), ('two', 'CD'), ('parameters', 'NNS'), ('motion', 'VBP'), ('parameter', 'NN'), ('respectively', 'RB'), ('greater', 'JJR'), ('corresponding', 'VBG'), ('preset', 'NN'), ('thresholds', 'NNS'), ('wherein', 'VBP'), ('acquiring', 'VBG'), ('comprises', 'NNS'), ('acquiring', 'VBG'), ('image', 'NN'), ('real', 'JJ'), ('time', 'NN'), ('obtaining', 'VBG'), ('comprises', 'NNS'), ('obtaining', 'VBG'), ('motion', 'NN'), ('parameter', 'NN'), ('terminal', 'JJ'), ('real', 'JJ'), ('time', 'NN'), ('method', 'NN'), ('comprising', 'VBG'), ('response', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('two', 'CD'), ('parameters', 'NNS'), ('motion', 'VBP'), ('parameter', 'RB'), ('greater', 'JJR'), ('corresponding', 'VBG'), ('preset', 'NN'), ('threshold', 'VBD'), ('obtaining', 'VBG'), ('motion', 'NN'), ('parameter', 'FW'), ('terminal', 'JJ'), ('response', 'NN'), ('two', 'CD'), ('parameters', 'NNS'), ('motion', 'VBP'), ('parameter', 'NN'), ('obtained', 'VBN'), ('latest', 'JJS'), ('time', 'NN'), ('less', 'CC'), ('equal', 'JJ'), ('corresponding', 'NN'), ('preset', 'NN'), ('thresholds', 'NNS'), ('performing', 'VBG'), ('image', 'NN'), ('processing', 'NN'), ('image', 'NN'), ('acquired', 'VBD'), ('latest', 'JJS'), ('time', 'NN'), ('method', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('acquiring', 'VBG'), ('comprises', 'NNS'), ('controlling', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('processor', 'NN'), ('turn', 'NN'), ('capturing', 'VBG'), ('apparatus', 'NNS'), ('based', 'VBN'), ('face', 'NN'), ('recognition', 'NN'), ('instruction', 'NN'), ('acquiring', 'VBG'), ('capturing', 'VBG'), ('apparatus', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('capturing', 'VBG'), ('apparatus', 'NNS'), ('turned', 'VBD'), ('method', 'JJ'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('controlling', 'VBG'), ('perform', 'JJ'), ('image', 'NN'), ('processing', 'NN'), ('comprises', 'VBZ'), ('skipping', 'VBG'), ('performing', 'VBG'), ('face', 'NN'), ('recognition', 'NN'), ('acquired', 'VBD'), ('face', 'NN'), ('image', 'NN'), ('based', 'VBN'), ('least', 'JJS'), ('one', 'CD'), ('two', 'CD'), ('parameters', 'NNS'), ('motion', 'VBP'), ('parameter', 'RB'), ('greater', 'JJR'), ('corresponding', 'VBG'), ('preset', 'NN'), ('threshold', 'NN'), ('based', 'VBN'), ('two', 'CD'), ('parameters', 'NNS'), ('motion', 'VBP'), ('parameter', 'NN'), ('respectively', 'RB'), ('greater', 'JJR'), ('corresponding', 'VBG'), ('preset', 'NN'), ('thresholds', 'NNS'), ('method', 'VBP'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('obtaining', 'VBG'), ('comprises', 'NNS'), ('least', 'JJS'), ('one', 'CD'), ('obtaining', 'VBG'), ('acceleration', 'NN'), ('terminal', 'NN'), ('using', 'VBG'), ('acceleration', 'NN'), ('sensor', 'NN'), ('obtaining', 'VBG'), ('angular', 'JJ'), ('velocity', 'NN'), ('terminal', 'NN'), ('using', 'VBG'), ('gyro', 'JJ'), ('sensor', 'NN'), ('method', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('transmitting', 'VBG'), ('comprises', 'NNS'), ('transmitting', 'VBG'), ('parameter', 'NN'), ('threshold', 'VBD'), ('obtaining', 'VBG'), ('request', 'NN'), ('data', 'NNS'), ('management', 'NN'), ('server', 'NN'), ('according', 'VBG'), ('preset', 'JJ'), ('time', 'NN'), ('period', 'NN'), ('method', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('comprising', 'VBG'), ('generating', 'VBG'), ('prompt', 'JJ'), ('information', 'NN'), ('based', 'VBN'), ('least', 'JJS'), ('one', 'CD'), ('two', 'CD'), ('parameters', 'NNS'), ('motion', 'VBP'), ('parameter', 'RB'), ('greater', 'JJR'), ('corresponding', 'VBG'), ('preset', 'NN'), ('threshold', 'VBD'), ('prompt', 'JJ'), ('information', 'NN'), ('used', 'VBN'), ('prompting', 'VBG'), ('terminal', 'JJ'), ('stop', 'NN'), ('moving', 'VBG'), ('method', 'JJ'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('motion', 'NN'), ('parameter', 'NN'), ('comprises', 'VBZ'), ('motion', 'NN'), ('frequency', 'NN'), ('motion', 'NN'), ('time', 'NN'), ('terminal', 'JJ'), ('comprising', 'VBG'), ('capturing', 'VBG'), ('apparatus', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('memory', 'NN'), ('configured', 'VBD'), ('store', 'NN'), ('program', 'NN'), ('code', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('processor', 'NN'), ('configured', 'VBD'), ('access', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('memory', 'NN'), ('operate', 'NN'), ('according', 'VBG'), ('program', 'NN'), ('code', 'NN'), ('program', 'NN'), ('code', 'NN'), ('comprising', 'VBG'), ('motion', 'NN'), ('parameter', 'NN'), ('obtaining', 'VBG'), ('code', 'NN'), ('configured', 'VBN'), ('cause', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('processor', 'NN'), ('acquire', 'VB'), ('image', 'NN'), ('using', 'VBG'), ('capturing', 'VBG'), ('apparatus', 'NN'), ('obtain', 'VB'), ('motion', 'NN'), ('parameter', 'NN'), ('terminal', 'JJ'), ('motion', 'NN'), ('parameter', 'NN'), ('comprising', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('motion', 'NN'), ('frequency', 'NN'), ('motion', 'NN'), ('time', 'NN'), ('two', 'CD'), ('parameters', 'NNS'), ('among', 'IN'), ('acceleration', 'NN'), ('angular', 'JJ'), ('velocity', 'NN'), ('motion', 'NN'), ('amplitude', 'NN'), ('motion', 'NN'), ('frequency', 'NN'), ('motion', 'NN'), ('time', 'NN'), ('request', 'NN'), ('transmitting', 'VBG'), ('code', 'NN'), ('configured', 'VBN'), ('cause', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('processor', 'NN'), ('transmit', 'NN'), ('parameter', 'NN'), ('threshold', 'VBD'), ('obtaining', 'VBG'), ('request', 'NN'), ('data', 'NNS'), ('management', 'NN'), ('server', 'RB'), ('parameter', 'RB'), ('threshold', 'JJ'), ('obtaining', 'VBG'), ('request', 'NN'), ('comprising', 'VBG'), ('configuration', 'NN'), ('information', 'NN'), ('terminal', 'NN'), ('parameter', 'NN'), ('threshold', 'VBD'), ('receiving', 'VBG'), ('code', 'NN'), ('configured', 'VBN'), ('cause', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('processor', 'NN'), ('receive', 'NN'), ('corresponding', 'VBG'), ('preset', 'NN'), ('thresholds', 'NNS'), ('correspond', 'NN'), ('configuration', 'NN'), ('information', 'NN'), ('response', 'NN'), ('parameter', 'NN'), ('threshold', 'VBD'), ('obtaining', 'VBG'), ('request', 'NN'), ('comparing', 'VBG'), ('code', 'NN'), ('configured', 'VBN'), ('cause', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('processor', 'NN'), ('compare', 'NN'), ('two', 'CD'), ('parameters', 'NNS'), ('corresponding', 'VBG'), ('preset', 'NN'), ('thresholds', 'NNS'), ('control', 'NN'), ('code', 'NN'), ('configured', 'VBN'), ('cause', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('processor', 'NN'), ('perform', 'NN'), ('image', 'NN'), ('processing', 'NN'), ('acquired', 'VBD'), ('image', 'NN'), ('based', 'VBN'), ('least', 'JJS'), ('one', 'CD'), ('two', 'CD'), ('parameters', 'NNS'), ('motion', 'VBP'), ('parameter', 'RB'), ('greater', 'JJR'), ('corresponding', 'VBG'), ('preset', 'NN'), ('threshold', 'NN'), ('based', 'VBN'), ('two', 'CD'), ('parameters', 'NNS'), ('motion', 'VBP'), ('parameter', 'NN'), ('respectively', 'RB'), ('greater', 'JJR'), ('corresponding', 'VBG'), ('preset', 'NN'), ('thresholds', 'NNS'), ('wherein', 'VBP'), ('motion', 'NN'), ('parameter', 'NN'), ('obtaining', 'VBG'), ('code', 'NN'), ('causes', 'NNS'), ('least', 'VBP'), ('one', 'CD'), ('processor', 'NN'), ('acquire', 'VB'), ('image', 'NN'), ('real', 'JJ'), ('time', 'NN'), ('obtain', 'VB'), ('motion', 'NN'), ('parameter', 'IN'), ('terminal', 'JJ'), ('real', 'JJ'), ('time', 'NN'), ('response', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('two', 'CD'), ('parameters', 'NNS'), ('motion', 'VBP'), ('parameter', 'RB'), ('greater', 'JJR'), ('corresponding', 'VBG'), ('preset', 'VBN'), ('threshold', 'JJ'), ('obtain', 'VB'), ('motion', 'NN'), ('parameter', 'NN'), ('terminal', 'JJ'), ('wherein', 'NN'), ('control', 'NN'), ('code', 'NN'), ('causes', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('processor', 'NN'), ('response', 'NN'), ('two', 'CD'), ('parameters', 'NNS'), ('motion', 'VBP'), ('parameter', 'NN'), ('obtained', 'VBN'), ('latest', 'JJS'), ('time', 'NN'), ('less', 'CC'), ('equal', 'JJ'), ('corresponding', 'NN'), ('preset', 'NN'), ('thresholds', 'NNS'), ('perform', 'VBP'), ('image', 'NN'), ('processing', 'NN'), ('image', 'NN'), ('acquired', 'VBD'), ('latest', 'JJS'), ('time', 'NN'), ('terminal', 'JJ'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('program', 'NN'), ('code', 'NN'), ('comprises', 'VBZ'), ('face', 'VBP'), ('instruction', 'NN'), ('receiving', 'VBG'), ('code', 'NN'), ('configured', 'VBN'), ('cause', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('processor', 'NN'), ('receive', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('instruction', 'NN'), ('wherein', 'WRB'), ('motion', 'NN'), ('parameter', 'NN'), ('obtaining', 'VBG'), ('code', 'NN'), ('causes', 'NNS'), ('least', 'VBP'), ('one', 'CD'), ('processor', 'NN'), ('control', 'NN'), ('according', 'VBG'), ('face', 'NN'), ('recognition', 'NN'), ('instruction', 'NN'), ('capturing', 'VBG'), ('apparatus', 'NN'), ('turn', 'NN'), ('acquire', 'VB'), ('face', 'NN'), ('image', 'NN'), ('using', 'VBG'), ('capturing', 'VBG'), ('apparatus', 'NN'), ('capturing', 'VBG'), ('apparatus', 'NN'), ('turned', 'VBD'), ('wherein', 'JJ'), ('control', 'NN'), ('code', 'NN'), ('causes', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('processor', 'NN'), ('skip', 'NN'), ('performing', 'VBG'), ('face', 'NN'), ('recognition', 'NN'), ('acquired', 'VBD'), ('face', 'NN'), ('image', 'NN'), ('based', 'VBN'), ('least', 'JJS'), ('one', 'CD'), ('two', 'CD'), ('parameters', 'NNS'), ('motion', 'VBP'), ('parameter', 'RB'), ('greater', 'JJR'), ('corresponding', 'VBG'), ('preset', 'NN'), ('threshold', 'NN'), ('based', 'VBN'), ('two', 'CD'), ('parameters', 'NNS'), ('motion', 'VBP'), ('parameter', 'NN'), ('respectively', 'RB'), ('greater', 'JJR'), ('corresponding', 'VBG'), ('preset', 'NN'), ('thresholds', 'NNS'), ('terminal', 'JJ'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('request', 'NN'), ('transmitting', 'VBG'), ('code', 'NN'), ('causes', 'NNS'), ('least', 'VBP'), ('one', 'CD'), ('processor', 'NN'), ('transmit', 'NN'), ('parameter', 'NN'), ('threshold', 'VBD'), ('obtaining', 'VBG'), ('request', 'NN'), ('data', 'NNS'), ('management', 'NN'), ('server', 'NN'), ('according', 'VBG'), ('preset', 'JJ'), ('time', 'NN'), ('period', 'NN'), ('terminal', 'JJ'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('program', 'NN'), ('code', 'NN'), ('comprises', 'VBZ'), ('prompt', 'JJ'), ('information', 'NN'), ('generation', 'NN'), ('code', 'NN'), ('configured', 'VBN'), ('cause', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('processor', 'NN'), ('generate', 'NN'), ('prompt', 'NN'), ('information', 'NN'), ('based', 'VBN'), ('least', 'JJS'), ('one', 'CD'), ('two', 'CD'), ('parameters', 'NNS'), ('motion', 'VBP'), ('parameter', 'RB'), ('greater', 'JJR'), ('corresponding', 'VBG'), ('preset', 'NN'), ('threshold', 'VBD'), ('prompt', 'JJ'), ('information', 'NN'), ('used', 'VBN'), ('prompting', 'VBG'), ('terminal', 'JJ'), ('stop', 'NN'), ('moving', 'VBG'), ('terminal', 'JJ'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('motion', 'NN'), ('parameter', 'NN'), ('comprises', 'VBZ'), ('motion', 'NN'), ('frequency', 'NN'), ('motion', 'NN'), ('time', 'NN'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('storage', 'NN'), ('medium', 'NN'), ('storing', 'VBG'), ('machine', 'NN'), ('instruction', 'NN'), ('executed', 'VBD'), ('one', 'CD'), ('processors', 'NNS'), ('causes', 'VBZ'), ('one', 'CD'), ('processors', 'NNS'), ('perform', 'VBP'), ('obtaining', 'VBG'), ('image', 'NN'), ('acquired', 'VBD'), ('capturing', 'VBG'), ('apparatus', 'NN'), ('obtaining', 'VBG'), ('motion', 'NN'), ('parameter', 'NN'), ('terminal', 'JJ'), ('terminal', 'NN'), ('comprising', 'VBG'), ('capturing', 'VBG'), ('apparatus', 'JJ'), ('motion', 'NN'), ('parameter', 'NN'), ('comprising', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('motion', 'NN'), ('frequency', 'NN'), ('motion', 'NN'), ('time', 'NN'), ('two', 'CD'), ('parameters', 'NNS'), ('among', 'IN'), ('acceleration', 'NN'), ('angular', 'JJ'), ('velocity', 'NN'), ('motion', 'NN'), ('amplitude', 'NN'), ('motion', 'NN'), ('frequency', 'NN'), ('motion', 'NN'), ('time', 'NN'), ('transmitting', 'VBG'), ('parameter', 'NN'), ('threshold', 'VBD'), ('obtaining', 'VBG'), ('request', 'NN'), ('data', 'NNS'), ('management', 'NN'), ('server', 'RB'), ('parameter', 'RB'), ('threshold', 'JJ'), ('obtaining', 'VBG'), ('request', 'NN'), ('comprising', 'VBG'), ('configuration', 'NN'), ('information', 'NN'), ('terminal', 'NN'), ('receiving', 'NN'), ('corresponding', 'VBG'), ('preset', 'NN'), ('thresholds', 'NNS'), ('correspond', 'NN'), ('configuration', 'NN'), ('information', 'NN'), ('response', 'NN'), ('parameter', 'NN'), ('threshold', 'VBD'), ('obtaining', 'VBG'), ('request', 'NN'), ('comparing', 'VBG'), ('two', 'CD'), ('parameters', 'NNS'), ('corresponding', 'VBG'), ('preset', 'NN'), ('thresholds', 'NNS'), ('controlling', 'VBG'), ('perform', 'JJ'), ('image', 'NN'), ('processing', 'NN'), ('acquired', 'VBD'), ('image', 'NN'), ('based', 'VBN'), ('least', 'JJS'), ('one', 'CD'), ('two', 'CD'), ('parameters', 'NNS'), ('motion', 'VBP'), ('parameter', 'RB'), ('greater', 'JJR'), ('corresponding', 'VBG'), ('preset', 'NN'), ('threshold', 'NN'), ('based', 'VBN'), ('two', 'CD'), ('parameters', 'NNS'), ('motion', 'VBP'), ('parameter', 'NN'), ('respectively', 'RB'), ('greater', 'JJR'), ('corresponding', 'VBG'), ('preset', 'NN'), ('thresholds', 'NNS'), ('wherein', 'VBP'), ('acquiring', 'VBG'), ('comprises', 'NNS'), ('acquiring', 'VBG'), ('image', 'NN'), ('real', 'JJ'), ('time', 'NN'), ('obtaining', 'VBG'), ('comprises', 'NNS'), ('obtaining', 'VBG'), ('motion', 'NN'), ('parameter', 'NN'), ('terminal', 'JJ'), ('real', 'JJ'), ('time', 'NN'), ('method', 'NN'), ('comprising', 'VBG'), ('response', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('two', 'CD'), ('parameters', 'NNS'), ('motion', 'VBP'), ('parameter', 'RB'), ('greater', 'JJR'), ('corresponding', 'VBG'), ('preset', 'NN'), ('threshold', 'VBD'), ('obtaining', 'VBG'), ('motion', 'NN'), ('parameter', 'FW'), ('terminal', 'JJ'), ('response', 'NN'), ('two', 'CD'), ('parameters', 'NNS'), ('motion', 'VBP'), ('parameter', 'NN'), ('obtained', 'VBN'), ('latest', 'JJS'), ('time', 'NN'), ('less', 'CC'), ('equal', 'JJ'), ('corresponding', 'NN'), ('preset', 'NN'), ('thresholds', 'NNS'), ('performing', 'VBG'), ('image', 'NN'), ('processing', 'NN'), ('image', 'NN'), ('acquired', 'VBD'), ('latest', 'JJS'), ('time', 'NN'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('storage', 'NN'), ('medium', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('acquired', 'VBD'), ('image', 'NN'), ('face', 'NN'), ('image', 'NN'), ('image', 'NN'), ('processing', 'NN'), ('comprises', 'VBZ'), ('performing', 'VBG'), ('face', 'NN'), ('recognition', 'NN'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('storage', 'NN'), ('medium', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('obtaining', 'VBG'), ('motion', 'NN'), ('parameter', 'NN'), ('comprises', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('obtaining', 'VBG'), ('acceleration', 'NN'), ('terminal', 'NN'), ('using', 'VBG'), ('acceleration', 'NN'), ('sensor', 'NN'), ('obtaining', 'VBG'), ('angular', 'JJ'), ('velocity', 'NN'), ('terminal', 'NN'), ('using', 'VBG'), ('gyro', 'JJ'), ('sensor', 'JJ'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('storage', 'NN'), ('medium', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('motion', 'NN'), ('parameter', 'NN'), ('comprises', 'VBZ'), ('motion', 'NN'), ('frequency', 'NN'), ('motion', 'NN'), ('time', 'NN'), ('method', 'NN'), ('processing', 'VBG'), ('drive-through', 'JJ'), ('order', 'NN'), ('method', 'NN'), ('comprising', 'VBG'), ('receiving', 'VBG'), ('customer', 'NN'), ('information', 'NN'), ('detected', 'VBN'), ('vision', 'NN'), ('recognition', 'NN'), ('providing', 'VBG'), ('product', 'NN'), ('information', 'NN'), ('customer', 'NN'), ('based', 'VBN'), ('customer', 'NN'), ('information', 'NN'), ('processing', 'VBG'), ('product', 'NN'), ('order', 'NN'), ('customer', 'NN'), ('method', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('receiving', 'VBG'), ('customer', 'NN'), ('information', 'NN'), ('comprises', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('receiving', 'VBG'), ('customer', 'NN'), ('information', 'NN'), ('associated', 'VBN'), ('vehicle', 'NN'), ('information', 'NN'), ('detected', 'VBD'), ('vehicle', 'NN'), ('recognition', 'NN'), ('receiving', 'VBG'), ('customer', 'NN'), ('information', 'NN'), ('associated', 'VBN'), ('identification', 'NN'), ('information', 'NN'), ('detected', 'VBD'), ('face', 'NN'), ('recognition', 'NN'), ('method', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('comprising', 'VBG'), ('determining', 'VBG'), ('whether', 'IN'), ('customer', 'NN'), ('pre-order', 'NN'), ('customer', 'NN'), ('based', 'VBN'), ('customer', 'NN'), ('information', 'NN'), ('wherein', 'NN'), ('customer', 'NN'), ('determined', 'VBD'), ('pre-order', 'JJ'), ('customer', 'NN'), ('providing', 'VBG'), ('product', 'NN'), ('information', 'NN'), ('based', 'VBN'), ('customer', 'NN'), ('information', 'NN'), ('comprises', 'VBZ'), ('providing', 'VBG'), ('pre-order', 'JJ'), ('information', 'NN'), ('using', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('audio', 'JJ'), ('video', 'NN'), ('processing', 'VBG'), ('product', 'NN'), ('order', 'NN'), ('customer', 'NN'), ('comprises', 'VBZ'), ('providing', 'VBG'), ('information', 'NN'), ('promptly', 'RB'), ('guiding', 'VBG'), ('vehicle', 'NN'), ('pickup', 'NN'), ('stand', 'VBP'), ('using', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('audio', 'NN'), ('video', 'NN'), ('providing', 'VBG'), ('information', 'NN'), ('additional', 'JJ'), ('order', 'NN'), ('available', 'JJ'), ('method', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('product', 'NN'), ('information', 'NN'), ('based', 'VBN'), ('customer', 'NN'), ('information', 'NN'), ('comprises', 'VBZ'), ('recently', 'RB'), ('ordered', 'VBN'), ('product', 'NN'), ('component', 'NN'), ('frequently', 'RB'), ('ordered', 'VBD'), ('product', 'NN'), ('component', 'NN'), ('order', 'NN'), ('history', 'NN'), ('customer', 'NN'), ('information', 'NN'), ('method', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('receiving', 'VBG'), ('customer', 'NN'), ('information', 'NN'), ('comprises', 'VBZ'), ('receiving', 'VBG'), ('information', 'NN'), ('age', 'NN'), ('gender', 'NN'), ('passenger', 'NN'), ('detected', 'VBD'), ('face', 'NN'), ('recognition', 'NN'), ('providing', 'VBG'), ('product', 'NN'), ('information', 'NN'), ('customer', 'NN'), ('based', 'VBN'), ('customer', 'NN'), ('information', 'NN'), ('comprises', 'VBZ'), ('providing', 'VBG'), ('recommended', 'VBD'), ('menu', 'JJ'), ('information', 'NN'), ('differentiated', 'VBD'), ('according', 'VBG'), ('age', 'NN'), ('gender', 'NN'), ('method', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('processing', 'VBG'), ('product', 'NN'), ('order', 'NN'), ('customer', 'NN'), ('comprises', 'VBZ'), ('determining', 'VBG'), ('product', 'NN'), ('component', 'NN'), ('past', 'JJ'), ('order', 'NN'), ('history', 'NN'), ('component', 'NN'), ('modified', 'VBD'), ('product', 'NN'), ('component', 'NN'), ('product', 'NN'), ('order', 'NN'), ('method', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('processing', 'VBG'), ('product', 'NN'), ('order', 'NN'), ('customer', 'NN'), ('comprises', 'VBZ'), ('paying', 'VBG'), ('product', 'NN'), ('price', 'NN'), ('according', 'VBG'), ('biometrics-based', 'JJ'), ('authentication', 'NN'), ('communication', 'NN'), ('system', 'NN'), ('vehicle', 'NN'), ('mobile', 'JJ'), ('terminal', 'NN'), ('method', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('processing', 'VBG'), ('product', 'NN'), ('order', 'NN'), ('customer', 'NN'), ('comprises', 'VBZ'), ('issuing', 'VBG'), ('payment', 'NN'), ('number', 'NN'), ('divided', 'VBN'), ('payment', 'NN'), ('performing', 'VBG'), ('divided', 'VBD'), ('payments', 'NNS'), ('according', 'VBG'), ('payment', 'NN'), ('requests', 'NNS'), ('plurality', 'VBP'), ('mobile', 'JJ'), ('terminals', 'NNS'), ('payment', 'NN'), ('numbers', 'NNS'), ('inputted', 'VBD'), ('method', 'JJ'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('processing', 'VBG'), ('product', 'NN'), ('order', 'NN'), ('customer', 'NN'), ('comprises', 'VBZ'), ('accumulating', 'VBG'), ('mileage', 'NN'), ('account', 'NN'), ('corresponding', 'VBG'), ('mobile', 'JJ'), ('terminal', 'JJ'), ('undergoing', 'JJ'), ('payment', 'NN'), ('method', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('processing', 'VBG'), ('product', 'NN'), ('order', 'NN'), ('customer', 'NN'), ('comprises', 'VBZ'), ('suggesting', 'VBG'), ('takeout', 'RP'), ('packaging', 'VBG'), ('method', 'NN'), ('according', 'VBG'), ('temperature', 'NN'), ('product', 'NN'), ('atmospheric', 'JJ'), ('temperature', 'NN'), ('weather', 'NN'), ('vehicle', 'NN'), ('type', 'NN'), ('apparatus', 'NN'), ('configured', 'VBD'), ('process', 'JJ'), ('drive-through', 'JJ'), ('order', 'NN'), ('apparatus', 'NN'), ('comprising', 'VBG'), ('transceiver', 'RB'), ('configured', 'VBN'), ('receive', 'JJ'), ('customer', 'NN'), ('information', 'NN'), ('detected', 'VBN'), ('vision', 'NN'), ('recognition', 'NN'), ('digital', 'JJ'), ('signage', 'NN'), ('configured', 'VBD'), ('provide', 'JJ'), ('product', 'NN'), ('information', 'NN'), ('customer', 'NN'), ('based', 'VBN'), ('customer', 'NN'), ('information', 'NN'), ('processor', 'NN'), ('configured', 'VBD'), ('process', 'JJ'), ('product', 'NN'), ('order', 'NN'), ('customer', 'NN'), ('apparatus', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('transceiver', 'WDT'), ('receives', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('customer', 'NN'), ('information', 'NN'), ('associated', 'VBN'), ('vehicle', 'NN'), ('information', 'NN'), ('detected', 'VBD'), ('vehicle', 'NN'), ('recognition', 'NN'), ('customer', 'NN'), ('information', 'NN'), ('associated', 'VBN'), ('identification', 'NN'), ('information', 'NN'), ('detected', 'VBD'), ('face', 'NN'), ('recognition', 'NN'), ('apparatus', 'IN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('processor', 'NN'), ('configured', 'VBD'), ('determine', 'NN'), ('whether', 'IN'), ('customer', 'NN'), ('pre-order', 'NN'), ('customer', 'NN'), ('based', 'VBN'), ('customer', 'NN'), ('information', 'NN'), ('customer', 'NN'), ('determined', 'VBD'), ('pre-order', 'JJ'), ('customer', 'NN'), ('perform', 'NN'), ('control', 'NN'), ('operation', 'NN'), ('provide', 'IN'), ('pre-order', 'JJ'), ('information', 'NN'), ('control', 'NN'), ('digital', 'JJ'), ('signage', 'NN'), ('output', 'NN'), ('information', 'NN'), ('promptly', 'RB'), ('guiding', 'VBG'), ('vehicle', 'NN'), ('pickup', 'NN'), ('stand', 'VB'), ('provide', 'JJ'), ('information', 'NN'), ('additional', 'JJ'), ('order', 'NN'), ('available', 'JJ'), ('apparatus', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('product', 'NN'), ('information', 'NN'), ('based', 'VBN'), ('customer', 'NN'), ('information', 'NN'), ('comprises', 'VBZ'), ('recently', 'RB'), ('ordered', 'VBN'), ('product', 'NN'), ('component', 'NN'), ('frequently', 'RB'), ('ordered', 'VBD'), ('product', 'NN'), ('component', 'NN'), ('order', 'NN'), ('history', 'NN'), ('customer', 'NN'), ('information', 'NN'), ('apparatus', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('transceiver', 'RB'), ('configured', 'VBD'), ('receive', 'JJ'), ('information', 'NN'), ('age', 'NN'), ('gender', 'NN'), ('passenger', 'NN'), ('detected', 'VBD'), ('face', 'NN'), ('recognition', 'NN'), ('processor', 'NN'), ('configured', 'VBD'), ('control', 'NN'), ('digital', 'JJ'), ('signage', 'NN'), ('provide', 'NN'), ('recommended', 'VBD'), ('menu', 'JJ'), ('information', 'NN'), ('differentiated', 'VBD'), ('according', 'VBG'), ('age', 'NN'), ('gender', 'NN'), ('apparatus', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('processor', 'NN'), ('configured', 'VBD'), ('determine', 'JJ'), ('product', 'NN'), ('component', 'NN'), ('past', 'JJ'), ('order', 'NN'), ('history', 'NN'), ('component', 'NN'), ('modified', 'VBD'), ('product', 'NN'), ('component', 'NN'), ('product', 'NN'), ('order', 'NN'), ('apparatus', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('processor', 'NN'), ('configured', 'VBD'), ('pay', 'JJ'), ('product', 'NN'), ('price', 'NN'), ('according', 'VBG'), ('biometrics-based', 'JJ'), ('authentication', 'NN'), ('communication', 'NN'), ('system', 'NN'), ('vehicle', 'NN'), ('mobile', 'JJ'), ('terminal', 'NN'), ('apparatus', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('processor', 'NN'), ('configured', 'VBD'), ('issue', 'NN'), ('payment', 'NN'), ('number', 'NN'), ('divided', 'VBN'), ('payment', 'NN'), ('perform', 'NN'), ('divided', 'VBD'), ('payments', 'NNS'), ('according', 'VBG'), ('requests', 'NNS'), ('plurality', 'NN'), ('mobile', 'NN'), ('terminals', 'NNS'), ('payment', 'NN'), ('numbers', 'NNS'), ('inputted', 'VBD'), ('apparatus', 'JJ'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('processor', 'NN'), ('configured', 'VBD'), ('accumulate', 'JJ'), ('mileage', 'NN'), ('account', 'NN'), ('corresponding', 'VBG'), ('mobile', 'JJ'), ('terminal', 'JJ'), ('undergoing', 'JJ'), ('payment', 'NN'), ('apparatus', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('processor', 'NN'), ('configured', 'VBD'), ('control', 'NN'), ('digital', 'JJ'), ('signage', 'NN'), ('suggest', 'VBP'), ('takeout', 'IN'), ('packaging', 'NN'), ('method', 'NN'), ('according', 'VBG'), ('temperature', 'NN'), ('product', 'NN'), ('atmospheric', 'JJ'), ('temperature', 'NN'), ('weather', 'NN'), ('vehicle', 'NN'), ('type', 'JJ'), ('image', 'NN'), ('information', 'NN'), ('processing', 'VBG'), ('method', 'NN'), ('performed', 'VBD'), ('computing', 'VBG'), ('device', 'NN'), ('one', 'CD'), ('processors', 'NNS'), ('memory', 'NN'), ('storing', 'VBG'), ('plurality', 'NN'), ('programs', 'NNS'), ('executed', 'VBD'), ('one', 'CD'), ('processors', 'NNS'), ('method', 'VBP'), ('comprising', 'VBG'), ('identifying', 'VBG'), ('using', 'VBG'), ('face', 'NN'), ('recognition', 'NN'), ('one', 'CD'), ('faces', 'VBZ'), ('face', 'NN'), ('corresponding', 'VBG'), ('respective', 'JJ'), ('person', 'NN'), ('captured', 'VBD'), ('first', 'JJ'), ('image', 'NN'), ('identified', 'VBN'), ('face', 'NN'), ('extracting', 'VBG'), ('set', 'VBN'), ('profile', 'JJ'), ('parameters', 'NNS'), ('corresponding', 'VBG'), ('person', 'NN'), ('first', 'JJ'), ('image', 'NN'), ('selecting', 'VBG'), ('plurality', 'NN'), ('image', 'NN'), ('tiles', 'NNS'), ('first', 'RB'), ('image', 'NN'), ('tile', 'NN'), ('matches', 'NNS'), ('face', 'VBP'), ('corresponding', 'VBG'), ('person', 'NN'), ('first', 'JJ'), ('image', 'NN'), ('accordance', 'NN'), ('predefined', 'VBD'), ('correspondence', 'NN'), ('set', 'VBN'), ('profile', 'JJ'), ('parameters', 'NNS'), ('corresponding', 'VBG'), ('person', 'NN'), ('set', 'VBN'), ('pre-stored', 'JJ'), ('description', 'NN'), ('parameters', 'NNS'), ('first', 'JJ'), ('image', 'NN'), ('tile', 'NN'), ('generating', 'VBG'), ('second', 'JJ'), ('image', 'NN'), ('covering', 'VBG'), ('faces', 'VBZ'), ('respective', 'JJ'), ('persons', 'NNS'), ('first', 'JJ'), ('image', 'NN'), ('corresponding', 'VBG'), ('first', 'JJ'), ('image', 'NN'), ('tiles', 'NNS'), ('sharing', 'VBG'), ('first', 'JJ'), ('image', 'NN'), ('second', 'JJ'), ('image', 'NN'), ('predefined', 'VBD'), ('order', 'NN'), ('via', 'IN'), ('group', 'NN'), ('chat', 'WP'), ('session', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('first', 'RB'), ('image', 'NN'), ('second', 'JJ'), ('image', 'NN'), ('displayed', 'VBD'), ('group', 'NN'), ('chat', 'WP'), ('session', 'NN'), ('one', 'CD'), ('image', 'NN'), ('time', 'NN'), ('one', 'CD'), ('two', 'CD'), ('images', 'NNS'), ('replaced', 'VBD'), ('two', 'CD'), ('images', 'NNS'), ('periodically', 'RB'), ('method', 'VBP'), ('claim', 'NN'), ('wherein', 'NN'), ('extracting', 'VBG'), ('set', 'VBN'), ('profile', 'JJ'), ('parameters', 'NNS'), ('corresponding', 'VBG'), ('person', 'NN'), ('first', 'JJ'), ('image', 'NN'), ('includes', 'VBZ'), ('determining', 'VBG'), ('one', 'CD'), ('descriptive', 'JJ'), ('labels', 'NNS'), ('corresponding', 'VBG'), ('identified', 'JJ'), ('face', 'NN'), ('corresponding', 'VBG'), ('person', 'NN'), ('using', 'VBG'), ('first', 'JJ'), ('machine', 'NN'), ('learning', 'VBG'), ('model', 'NN'), ('wherein', 'NN'), ('first', 'JJ'), ('machine', 'NN'), ('learning', 'VBG'), ('model', 'NN'), ('trained', 'VBD'), ('facial', 'JJ'), ('images', 'NNS'), ('corresponding', 'VBG'), ('descriptive', 'JJ'), ('labels', 'NNS'), ('method', 'VBP'), ('claim', 'NN'), ('wherein', 'NN'), ('extracting', 'VBG'), ('set', 'VBN'), ('profile', 'JJ'), ('parameters', 'NNS'), ('corresponding', 'VBG'), ('person', 'NN'), ('first', 'JJ'), ('image', 'NN'), ('includes', 'VBZ'), ('determining', 'VBG'), ('identity', 'NN'), ('corresponding', 'VBG'), ('person', 'NN'), ('based', 'VBN'), ('identified', 'JJ'), ('face', 'NN'), ('corresponding', 'VBG'), ('person', 'NN'), ('locating', 'VBG'), ('respective', 'JJ'), ('profile', 'NN'), ('information', 'NN'), ('first', 'RB'), ('person', 'NN'), ('based', 'VBN'), ('determined', 'VBN'), ('identity', 'NN'), ('corresponding', 'VBG'), ('person', 'NN'), ('using', 'VBG'), ('one', 'CD'), ('characteristics', 'NNS'), ('respective', 'JJ'), ('profile', 'JJ'), ('information', 'NN'), ('first', 'RB'), ('person', 'NN'), ('set', 'VBN'), ('profile', 'NN'), ('parameters', 'NNS'), ('corresponding', 'VBG'), ('identified', 'JJ'), ('face', 'NN'), ('corresponding', 'VBG'), ('person', 'NN'), ('method', 'JJ'), ('claim', 'NN'), ('wherein', 'NN'), ('least', 'VBD'), ('first', 'JJ'), ('one', 'CD'), ('first', 'JJ'), ('image', 'NN'), ('tiles', 'NNS'), ('dynamic', 'JJ'), ('image', 'NN'), ('tile', 'NN'), ('least', 'JJS'), ('second', 'JJ'), ('one', 'CD'), ('first', 'JJ'), ('image', 'NN'), ('tiles', 'NNS'), ('static', 'JJ'), ('image', 'NN'), ('tile', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('including', 'VBG'), ('receiving', 'VBG'), ('plurality', 'NN'), ('user', 'JJ'), ('comments', 'NNS'), ('different', 'JJ'), ('users', 'NNS'), ('group', 'NN'), ('chat', 'VBZ'), ('session', 'NN'), ('user', 'JJ'), ('comment', 'NN'), ('including', 'VBG'), ('descriptive', 'JJ'), ('term', 'NN'), ('respective', 'JJ'), ('person', 'NN'), ('identified', 'VBD'), ('first', 'JJ'), ('image', 'NN'), ('choosing', 'VBG'), ('descriptive', 'JJ'), ('label', 'NN'), ('respective', 'JJ'), ('person', 'NN'), ('according', 'VBG'), ('plurality', 'NN'), ('user', 'NN'), ('comments', 'NNS'), ('updating', 'VBG'), ('second', 'JJ'), ('image', 'NN'), ('adding', 'VBG'), ('descriptive', 'JJ'), ('label', 'NN'), ('adjacent', 'NN'), ('first', 'RB'), ('image', 'NN'), ('tile', 'NN'), ('respective', 'JJ'), ('person', 'NN'), ('computing', 'VBG'), ('device', 'NN'), ('image', 'NN'), ('information', 'NN'), ('processing', 'VBG'), ('comprising', 'VBG'), ('one', 'CD'), ('processors', 'NNS'), ('memory', 'NN'), ('storing', 'VBG'), ('instructions', 'NNS'), ('executed', 'VBD'), ('one', 'CD'), ('processors', 'NNS'), ('cause', 'VBP'), ('processors', 'NNS'), ('perform', 'VBP'), ('plurality', 'NN'), ('operations', 'NNS'), ('comprising', 'VBG'), ('identifying', 'VBG'), ('using', 'VBG'), ('face', 'NN'), ('recognition', 'NN'), ('one', 'CD'), ('faces', 'VBZ'), ('face', 'NN'), ('corresponding', 'VBG'), ('respective', 'JJ'), ('person', 'NN'), ('captured', 'VBD'), ('first', 'JJ'), ('image', 'NN'), ('identified', 'VBN'), ('face', 'NN'), ('extracting', 'VBG'), ('set', 'VBN'), ('profile', 'JJ'), ('parameters', 'NNS'), ('corresponding', 'VBG'), ('person', 'NN'), ('first', 'JJ'), ('image', 'NN'), ('selecting', 'VBG'), ('plurality', 'NN'), ('image', 'NN'), ('tiles', 'NNS'), ('first', 'RB'), ('image', 'NN'), ('tile', 'NN'), ('matches', 'NNS'), ('face', 'VBP'), ('corresponding', 'VBG'), ('person', 'NN'), ('first', 'JJ'), ('image', 'NN'), ('accordance', 'NN'), ('predefined', 'VBD'), ('correspondence', 'NN'), ('set', 'VBN'), ('profile', 'JJ'), ('parameters', 'NNS'), ('corresponding', 'VBG'), ('person', 'NN'), ('set', 'VBN'), ('pre-stored', 'JJ'), ('description', 'NN'), ('parameters', 'NNS'), ('first', 'JJ'), ('image', 'NN'), ('tile', 'NN'), ('generating', 'VBG'), ('second', 'JJ'), ('image', 'NN'), ('covering', 'VBG'), ('faces', 'VBZ'), ('respective', 'JJ'), ('persons', 'NNS'), ('first', 'JJ'), ('image', 'NN'), ('corresponding', 'VBG'), ('first', 'JJ'), ('image', 'NN'), ('tiles', 'NNS'), ('sharing', 'VBG'), ('first', 'JJ'), ('image', 'NN'), ('second', 'JJ'), ('image', 'NN'), ('predefined', 'VBD'), ('order', 'NN'), ('via', 'IN'), ('group', 'NN'), ('chat', 'WP'), ('session', 'NN'), ('computing', 'VBG'), ('device', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('first', 'RB'), ('image', 'NN'), ('second', 'JJ'), ('image', 'NN'), ('displayed', 'VBD'), ('group', 'NN'), ('chat', 'WP'), ('session', 'NN'), ('one', 'CD'), ('image', 'NN'), ('time', 'NN'), ('one', 'CD'), ('two', 'CD'), ('images', 'NNS'), ('replaced', 'VBD'), ('two', 'CD'), ('images', 'NNS'), ('periodically', 'RB'), ('computing', 'VBG'), ('device', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('extracting', 'VBG'), ('set', 'VBN'), ('profile', 'JJ'), ('parameters', 'NNS'), ('corresponding', 'VBG'), ('person', 'NN'), ('first', 'JJ'), ('image', 'NN'), ('includes', 'VBZ'), ('determining', 'VBG'), ('one', 'CD'), ('descriptive', 'JJ'), ('labels', 'NNS'), ('corresponding', 'VBG'), ('identified', 'JJ'), ('face', 'NN'), ('corresponding', 'VBG'), ('person', 'NN'), ('using', 'VBG'), ('first', 'JJ'), ('machine', 'NN'), ('learning', 'VBG'), ('model', 'NN'), ('wherein', 'NN'), ('first', 'JJ'), ('machine', 'NN'), ('learning', 'VBG'), ('model', 'NN'), ('trained', 'VBD'), ('facial', 'JJ'), ('images', 'NNS'), ('corresponding', 'VBG'), ('descriptive', 'JJ'), ('labels', 'NNS'), ('computing', 'VBG'), ('device', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('extracting', 'VBG'), ('set', 'VBN'), ('profile', 'JJ'), ('parameters', 'NNS'), ('corresponding', 'VBG'), ('person', 'NN'), ('first', 'JJ'), ('image', 'NN'), ('includes', 'VBZ'), ('determining', 'VBG'), ('identity', 'NN'), ('corresponding', 'VBG'), ('person', 'NN'), ('based', 'VBN'), ('identified', 'JJ'), ('face', 'NN'), ('corresponding', 'VBG'), ('person', 'NN'), ('locating', 'VBG'), ('respective', 'JJ'), ('profile', 'NN'), ('information', 'NN'), ('first', 'RB'), ('person', 'NN'), ('based', 'VBN'), ('determined', 'VBN'), ('identity', 'NN'), ('corresponding', 'VBG'), ('person', 'NN'), ('using', 'VBG'), ('one', 'CD'), ('characteristics', 'NNS'), ('respective', 'JJ'), ('profile', 'JJ'), ('information', 'NN'), ('first', 'RB'), ('person', 'NN'), ('set', 'VBN'), ('profile', 'NN'), ('parameters', 'NNS'), ('corresponding', 'VBG'), ('identified', 'JJ'), ('face', 'NN'), ('corresponding', 'VBG'), ('person', 'NN'), ('computing', 'VBG'), ('device', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('least', 'JJS'), ('first', 'JJ'), ('one', 'CD'), ('first', 'JJ'), ('image', 'NN'), ('tiles', 'NNS'), ('dynamic', 'JJ'), ('image', 'NN'), ('tile', 'NN'), ('least', 'JJS'), ('second', 'JJ'), ('one', 'CD'), ('first', 'JJ'), ('image', 'NN'), ('tiles', 'NNS'), ('static', 'JJ'), ('image', 'NN'), ('tile', 'NN'), ('computing', 'VBG'), ('device', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('plurality', 'NN'), ('operations', 'NNS'), ('include', 'VBP'), ('receiving', 'VBG'), ('plurality', 'NN'), ('user', 'JJ'), ('comments', 'NNS'), ('different', 'JJ'), ('users', 'NNS'), ('group', 'NN'), ('chat', 'VBZ'), ('session', 'NN'), ('user', 'JJ'), ('comment', 'NN'), ('including', 'VBG'), ('descriptive', 'JJ'), ('term', 'NN'), ('respective', 'JJ'), ('person', 'NN'), ('identified', 'VBD'), ('first', 'JJ'), ('image', 'NN'), ('choosing', 'VBG'), ('descriptive', 'JJ'), ('label', 'NN'), ('respective', 'JJ'), ('person', 'NN'), ('according', 'VBG'), ('plurality', 'NN'), ('user', 'NN'), ('comments', 'NNS'), ('updating', 'VBG'), ('second', 'JJ'), ('image', 'NN'), ('adding', 'VBG'), ('descriptive', 'JJ'), ('label', 'NN'), ('adjacent', 'NN'), ('first', 'RB'), ('image', 'NN'), ('tile', 'NN'), ('respective', 'JJ'), ('person', 'NN'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('storage', 'NN'), ('medium', 'NN'), ('storing', 'VBG'), ('instructions', 'NNS'), ('executed', 'VBD'), ('computing', 'VBG'), ('device', 'NN'), ('one', 'CD'), ('processors', 'NNS'), ('cause', 'VBP'), ('computing', 'VBG'), ('device', 'NN'), ('perform', 'NN'), ('plurality', 'NN'), ('operations', 'NNS'), ('comprising', 'VBG'), ('identifying', 'VBG'), ('using', 'VBG'), ('face', 'NN'), ('recognition', 'NN'), ('one', 'CD'), ('faces', 'VBZ'), ('face', 'NN'), ('corresponding', 'VBG'), ('respective', 'JJ'), ('person', 'NN'), ('captured', 'VBD'), ('first', 'JJ'), ('image', 'NN'), ('identified', 'VBN'), ('face', 'NN'), ('extracting', 'VBG'), ('set', 'VBN'), ('profile', 'JJ'), ('parameters', 'NNS'), ('corresponding', 'VBG'), ('person', 'NN'), ('first', 'JJ'), ('image', 'NN'), ('selecting', 'VBG'), ('plurality', 'NN'), ('image', 'NN'), ('tiles', 'NNS'), ('first', 'RB'), ('image', 'NN'), ('tile', 'NN'), ('matches', 'NNS'), ('face', 'VBP'), ('corresponding', 'VBG'), ('person', 'NN'), ('first', 'JJ'), ('image', 'NN'), ('accordance', 'NN'), ('predefined', 'VBD'), ('correspondence', 'NN'), ('set', 'VBN'), ('profile', 'JJ'), ('parameters', 'NNS'), ('corresponding', 'VBG'), ('person', 'NN'), ('set', 'VBN'), ('pre-stored', 'JJ'), ('description', 'NN'), ('parameters', 'NNS'), ('first', 'JJ'), ('image', 'NN'), ('tile', 'NN'), ('generating', 'VBG'), ('second', 'JJ'), ('image', 'NN'), ('covering', 'VBG'), ('faces', 'VBZ'), ('respective', 'JJ'), ('persons', 'NNS'), ('first', 'JJ'), ('image', 'NN'), ('corresponding', 'VBG'), ('first', 'JJ'), ('image', 'NN'), ('tiles', 'NNS'), ('sharing', 'VBG'), ('first', 'JJ'), ('image', 'NN'), ('second', 'JJ'), ('image', 'NN'), ('predefined', 'VBD'), ('order', 'NN'), ('via', 'IN'), ('group', 'NN'), ('chat', 'DT'), ('session', 'NN'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('storage', 'NN'), ('medium', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('first', 'RB'), ('image', 'NN'), ('second', 'JJ'), ('image', 'NN'), ('displayed', 'VBD'), ('group', 'NN'), ('chat', 'WP'), ('session', 'NN'), ('one', 'CD'), ('image', 'NN'), ('time', 'NN'), ('one', 'CD'), ('two', 'CD'), ('images', 'NNS'), ('replaced', 'VBD'), ('two', 'CD'), ('images', 'NNS'), ('periodically', 'RB'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('storage', 'NN'), ('medium', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('extracting', 'VBG'), ('set', 'VBN'), ('profile', 'JJ'), ('parameters', 'NNS'), ('corresponding', 'VBG'), ('person', 'NN'), ('first', 'JJ'), ('image', 'NN'), ('includes', 'VBZ'), ('determining', 'VBG'), ('one', 'CD'), ('descriptive', 'JJ'), ('labels', 'NNS'), ('corresponding', 'VBG'), ('identified', 'JJ'), ('face', 'NN'), ('corresponding', 'VBG'), ('person', 'NN'), ('using', 'VBG'), ('first', 'JJ'), ('machine', 'NN'), ('learning', 'VBG'), ('model', 'NN'), ('wherein', 'NN'), ('first', 'JJ'), ('machine', 'NN'), ('learning', 'VBG'), ('model', 'NN'), ('trained', 'VBD'), ('facial', 'JJ'), ('images', 'NNS'), ('corresponding', 'VBG'), ('descriptive', 'JJ'), ('labels', 'NNS'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('storage', 'NN'), ('medium', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('extracting', 'VBG'), ('set', 'VBN'), ('profile', 'JJ'), ('parameters', 'NNS'), ('corresponding', 'VBG'), ('person', 'NN'), ('first', 'JJ'), ('image', 'NN'), ('includes', 'VBZ'), ('determining', 'VBG'), ('identity', 'NN'), ('corresponding', 'VBG'), ('person', 'NN'), ('based', 'VBN'), ('identified', 'JJ'), ('face', 'NN'), ('corresponding', 'VBG'), ('person', 'NN'), ('locating', 'VBG'), ('respective', 'JJ'), ('profile', 'NN'), ('information', 'NN'), ('first', 'RB'), ('person', 'NN'), ('based', 'VBN'), ('determined', 'VBN'), ('identity', 'NN'), ('corresponding', 'VBG'), ('person', 'NN'), ('using', 'VBG'), ('one', 'CD'), ('characteristics', 'NNS'), ('respective', 'JJ'), ('profile', 'JJ'), ('information', 'NN'), ('first', 'RB'), ('person', 'NN'), ('set', 'VBN'), ('profile', 'NN'), ('parameters', 'NNS'), ('corresponding', 'VBG'), ('identified', 'JJ'), ('face', 'NN'), ('corresponding', 'VBG'), ('person', 'NN'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('storage', 'NN'), ('medium', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('least', 'JJS'), ('first', 'JJ'), ('one', 'CD'), ('first', 'JJ'), ('image', 'NN'), ('tiles', 'NNS'), ('dynamic', 'JJ'), ('image', 'NN'), ('tile', 'NN'), ('least', 'JJS'), ('second', 'JJ'), ('one', 'CD'), ('first', 'JJ'), ('image', 'NN'), ('tiles', 'NNS'), ('static', 'JJ'), ('image', 'NN'), ('tile', 'JJ'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('storage', 'NN'), ('medium', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('plurality', 'NN'), ('operations', 'NNS'), ('include', 'VBP'), ('receiving', 'VBG'), ('plurality', 'NN'), ('user', 'JJ'), ('comments', 'NNS'), ('different', 'JJ'), ('users', 'NNS'), ('group', 'NN'), ('chat', 'VBZ'), ('session', 'NN'), ('user', 'JJ'), ('comment', 'NN'), ('including', 'VBG'), ('descriptive', 'JJ'), ('term', 'NN'), ('respective', 'JJ'), ('person', 'NN'), ('identified', 'VBD'), ('first', 'JJ'), ('image', 'NN'), ('choosing', 'VBG'), ('descriptive', 'JJ'), ('label', 'NN'), ('respective', 'JJ'), ('person', 'NN'), ('according', 'VBG'), ('plurality', 'NN'), ('user', 'NN'), ('comments', 'NNS'), ('updating', 'VBG'), ('second', 'JJ'), ('image', 'NN'), ('adding', 'VBG'), ('descriptive', 'JJ'), ('label', 'NN'), ('adjacent', 'NN'), ('first', 'RB'), ('image', 'NN'), ('tile', 'NN'), ('respective', 'JJ'), ('person', 'NN'), ('method', 'NN'), ('comprising', 'VBG'), ('computing', 'VBG'), ('system', 'NN'), ('determining', 'VBG'), ('performance', 'NN'), ('metric', 'JJ'), ('eye', 'NN'), ('tracking', 'VBG'), ('system', 'NN'), ('first', 'JJ'), ('performance', 'NN'), ('threshold', 'NN'), ('wherein', 'NN'), ('eye', 'NN'), ('tracking', 'VBG'), ('system', 'NN'), ('associated', 'VBN'), ('head-mounted', 'JJ'), ('display', 'NN'), ('worn', 'VBN'), ('user', 'RB'), ('based', 'VBN'), ('determination', 'NN'), ('performance', 'NN'), ('metric', 'JJ'), ('eye', 'NN'), ('tracking', 'VBG'), ('system', 'NN'), ('first', 'JJ'), ('performance', 'NN'), ('threshold', 'VBN'), ('computer', 'NN'), ('system', 'NN'), ('performing', 'VBG'), ('receiving', 'VBG'), ('one', 'CD'), ('first', 'JJ'), ('inputs', 'NNS'), ('associated', 'VBN'), ('body', 'NN'), ('user', 'RBR'), ('estimating', 'VBG'), ('region', 'NN'), ('user', 'NN'), ('looking', 'VBG'), ('within', 'IN'), ('field', 'NN'), ('view', 'NN'), ('head-mounted', 'JJ'), ('display', 'NN'), ('based', 'VBN'), ('received', 'VBD'), ('one', 'CD'), ('first', 'JJ'), ('inputs', 'NNS'), ('associated', 'VBN'), ('body', 'NN'), ('user', 'RBR'), ('determining', 'VBG'), ('vergence', 'NN'), ('distance', 'NN'), ('user', 'NN'), ('based', 'VBN'), ('least', 'JJS'), ('one', 'CD'), ('first', 'JJ'), ('inputs', 'NNS'), ('associated', 'VBN'), ('body', 'NN'), ('user', 'RBR'), ('estimated', 'VBN'), ('region', 'NN'), ('user', 'RBR'), ('looking', 'VBG'), ('locations', 'NNS'), ('one', 'CD'), ('objects', 'VBZ'), ('scene', 'NN'), ('displayed', 'VBD'), ('head-mounted', 'JJ'), ('display', 'NN'), ('adjusting', 'VBG'), ('one', 'CD'), ('configurations', 'NNS'), ('head-mounted', 'JJ'), ('display', 'NN'), ('based', 'VBN'), ('determined', 'JJ'), ('vergence', 'NN'), ('distance', 'NN'), ('user', 'JJ'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('one', 'CD'), ('configurations', 'NNS'), ('head-mounted', 'JJ'), ('display', 'NN'), ('comprise', 'NN'), ('one', 'CD'), ('rendering', 'NN'), ('image', 'NN'), ('position', 'NN'), ('display', 'NN'), ('screen', 'JJ'), ('position', 'NN'), ('optics', 'NNS'), ('block', 'VBP'), ('method', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('determining', 'VBG'), ('performance', 'NN'), ('metric', 'JJ'), ('eye', 'NN'), ('tracking', 'VBG'), ('system', 'NN'), ('second', 'JJ'), ('performance', 'NN'), ('threshold', 'VBD'), ('receiving', 'VBG'), ('eye', 'NN'), ('tracking', 'VBG'), ('data', 'NNS'), ('eye', 'NN'), ('tracking', 'VBG'), ('system', 'NN'), ('determining', 'VBG'), ('vergence', 'NN'), ('distance', 'NN'), ('user', 'NN'), ('based', 'VBN'), ('eye', 'NN'), ('tracking', 'VBG'), ('data', 'NNS'), ('one', 'CD'), ('first', 'JJ'), ('inputs', 'NNS'), ('associated', 'VBN'), ('body', 'NN'), ('user', 'JJ'), ('method', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('receiving', 'VBG'), ('one', 'CD'), ('second', 'JJ'), ('inputs', 'NNS'), ('associated', 'VBD'), ('one', 'CD'), ('displaying', 'NN'), ('elements', 'NNS'), ('scene', 'VBP'), ('displayed', 'VBN'), ('head-mounted', 'JJ'), ('display', 'NN'), ('determining', 'VBG'), ('vergence', 'NN'), ('distance', 'NN'), ('user', 'NN'), ('based', 'VBN'), ('least', 'JJS'), ('eye', 'NN'), ('tracking', 'VBG'), ('data', 'NNS'), ('one', 'CD'), ('first', 'JJ'), ('inputs', 'NNS'), ('associated', 'VBN'), ('body', 'NN'), ('user', 'JJ'), ('one', 'CD'), ('second', 'NN'), ('inputs', 'NNS'), ('associated', 'VBD'), ('one', 'CD'), ('displaying', 'NN'), ('elements', 'NNS'), ('scene', 'VBP'), ('method', 'JJ'), ('claim', 'NN'), ('comprising', 'VBG'), ('feeding', 'VBG'), ('one', 'CD'), ('first', 'JJ'), ('inputs', 'NNS'), ('associated', 'VBN'), ('body', 'NN'), ('user', 'JJ'), ('fusion', 'NN'), ('algorithm', 'NN'), ('wherein', 'WRB'), ('fusion', 'NN'), ('algorithm', 'NN'), ('assigns', 'NNS'), ('weight', 'VBD'), ('score', 'RB'), ('input', 'JJ'), ('one', 'CD'), ('first', 'JJ'), ('inputs', 'VBZ'), ('determining', 'VBG'), ('vergence', 'NN'), ('distance', 'NN'), ('user', 'NN'), ('using', 'VBG'), ('fusion', 'NN'), ('algorithm', 'NNS'), ('based', 'VBN'), ('one', 'CD'), ('first', 'JJ'), ('inputs', 'NNS'), ('associated', 'VBN'), ('body', 'NN'), ('user', 'JJ'), ('determining', 'VBG'), ('z-depth', 'JJ'), ('display', 'NN'), ('screen', 'NN'), ('confidence', 'NN'), ('score', 'NN'), ('based', 'VBN'), ('one', 'CD'), ('first', 'JJ'), ('inputs', 'NNS'), ('associated', 'VBN'), ('body', 'NN'), ('user', 'JJ'), ('method', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('comparing', 'VBG'), ('confidence', 'NN'), ('score', 'NN'), ('confidence', 'NN'), ('level', 'NN'), ('threshold', 'JJ'), ('response', 'NN'), ('determination', 'NN'), ('confidence', 'NN'), ('score', 'NN'), ('confidence', 'NN'), ('level', 'NN'), ('threshold', 'VBD'), ('feeding', 'VBG'), ('one', 'CD'), ('second', 'JJ'), ('inputs', 'NNS'), ('associated', 'VBD'), ('one', 'CD'), ('displaying', 'NN'), ('elements', 'NNS'), ('scene', 'JJ'), ('fusion', 'NN'), ('algorithm', 'IN'), ('determining', 'VBG'), ('z-depth', 'JJ'), ('display', 'NN'), ('screen', 'NN'), ('using', 'VBG'), ('fusion', 'NN'), ('algorithm', 'NNS'), ('based', 'VBN'), ('one', 'CD'), ('first', 'JJ'), ('inputs', 'NNS'), ('associated', 'VBN'), ('body', 'NN'), ('user', 'JJ'), ('one', 'CD'), ('second', 'NN'), ('inputs', 'NNS'), ('associated', 'VBD'), ('one', 'CD'), ('displaying', 'NN'), ('elements', 'NNS'), ('scene', 'VBP'), ('method', 'JJ'), ('claim', 'NN'), ('comparing', 'VBG'), ('comparing', 'VBG'), ('fusion', 'NN'), ('algorithm', 'NN'), ('confidence', 'NN'), ('scores', 'NNS'), ('associated', 'VBN'), ('plurality', 'NN'), ('combinations', 'NNS'), ('inputs', 'VBP'), ('determining', 'VBG'), ('fusion', 'NN'), ('algorithm', 'IN'), ('z-depth', 'JJ'), ('display', 'NN'), ('screen', 'NN'), ('based', 'VBN'), ('combination', 'NN'), ('inputs', 'NNS'), ('associated', 'VBN'), ('highest', 'JJS'), ('confidence', 'NN'), ('score', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('z-depth', 'JJ'), ('confidence', 'NN'), ('score', 'NN'), ('determined', 'VBD'), ('fusion', 'NN'), ('algorithm', 'IN'), ('using', 'VBG'), ('piecewise', 'NN'), ('comparison', 'NN'), ('one', 'CD'), ('first', 'JJ'), ('inputs', 'VBZ'), ('one', 'CD'), ('second', 'NN'), ('inputs', 'VBZ'), ('method', 'JJ'), ('claim', 'NN'), ('wherein', 'IN'), ('z-depth', 'JJ'), ('confidence', 'NN'), ('score', 'NN'), ('determined', 'VBD'), ('based', 'VBN'), ('correlation', 'NN'), ('two', 'CD'), ('inputs', 'NNS'), ('one', 'CD'), ('first', 'JJ'), ('inputs', 'VBZ'), ('one', 'CD'), ('second', 'NN'), ('inputs', 'VBZ'), ('method', 'JJ'), ('claim', 'NN'), ('wherein', 'NN'), ('fusion', 'NN'), ('algorithm', 'NN'), ('comprises', 'VBZ'), ('machine', 'NN'), ('learning', 'VBG'), ('ml', 'JJ'), ('algorithm', 'JJ'), ('wherein', 'NN'), ('machine', 'NN'), ('learning', 'VBG'), ('ml', 'JJ'), ('algorithm', 'JJ'), ('determines', 'NNS'), ('combination', 'NN'), ('first', 'RB'), ('inputs', 'VBZ'), ('fed', 'JJ'), ('fusion', 'NN'), ('algorithm', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('one', 'CD'), ('first', 'JJ'), ('inputs', 'NNS'), ('associated', 'VBN'), ('body', 'NN'), ('user', 'JJ'), ('comprise', 'NN'), ('one', 'CD'), ('hand', 'NN'), ('position', 'NN'), ('hand', 'NN'), ('direction', 'NN'), ('hand', 'NN'), ('movement', 'NN'), ('hand', 'NN'), ('gesture', 'NN'), ('head', 'NN'), ('position', 'NN'), ('head', 'NN'), ('direction', 'NN'), ('head', 'NN'), ('movement', 'NN'), ('head', 'NN'), ('gesture', 'NN'), ('gaze', 'NN'), ('angle', 'VBP'), ('rea', 'NN'), ('body', 'NN'), ('gesture', 'NN'), ('body', 'NN'), ('posture', 'NN'), ('body', 'NN'), ('movement', 'NN'), ('behavior', 'IN'), ('user', 'NN'), ('weighted', 'VBN'), ('combination', 'NN'), ('one', 'CD'), ('related', 'JJ'), ('parameters', 'NNS'), ('method', 'VBP'), ('claim', 'NN'), ('wherein', 'NN'), ('one', 'CD'), ('first', 'JJ'), ('inputs', 'NNS'), ('associated', 'VBN'), ('body', 'NN'), ('user', 'NN'), ('received', 'VBD'), ('one', 'CD'), ('controller', 'NN'), ('sensor', 'NN'), ('camera', 'NN'), ('microphone', 'NN'), ('accelerometer', 'NN'), ('headset', 'VBN'), ('worn', 'JJ'), ('user', 'NN'), ('mobile', 'JJ'), ('device', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'VBP'), ('one', 'CD'), ('second', 'JJ'), ('inputs', 'NNS'), ('associated', 'VBD'), ('one', 'CD'), ('displaying', 'NN'), ('elements', 'NNS'), ('comprise', 'VBP'), ('one', 'CD'), ('z-buffer', 'NN'), ('value', 'NN'), ('associated', 'VBN'), ('displaying', 'VBG'), ('element', 'NN'), ('displaying', 'VBG'), ('element', 'NN'), ('marked', 'VBD'), ('developer', 'JJ'), ('image', 'NN'), ('analysis', 'NN'), ('result', 'NN'), ('shape', 'NN'), ('displaying', 'VBG'), ('element', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('result', 'NN'), ('object', 'JJ'), ('recognition', 'NN'), ('result', 'NN'), ('person', 'NN'), ('identified', 'VBD'), ('displaying', 'VBG'), ('content', 'NN'), ('object', 'NN'), ('identified', 'VBD'), ('displaying', 'VBG'), ('content', 'JJ'), ('correlation', 'NN'), ('two', 'CD'), ('displaying', 'VBG'), ('elements', 'NNS'), ('weighted', 'VBN'), ('combination', 'NN'), ('one', 'CD'), ('second', 'NN'), ('inputs', 'VBZ'), ('method', 'JJ'), ('claim', 'NN'), ('comprising', 'VBG'), ('determining', 'VBG'), ('performance', 'NN'), ('metric', 'JJ'), ('eye', 'NN'), ('tracking', 'VBG'), ('system', 'NN'), ('second', 'JJ'), ('performance', 'NN'), ('threshold', 'VBD'), ('receiving', 'VBG'), ('one', 'CD'), ('second', 'JJ'), ('inputs', 'NNS'), ('associated', 'VBD'), ('one', 'CD'), ('displaying', 'NN'), ('elements', 'NNS'), ('scene', 'VBP'), ('displayed', 'VBN'), ('head-mounted', 'JJ'), ('display', 'NN'), ('determining', 'VBG'), ('vergence', 'NN'), ('distance', 'NN'), ('user', 'NN'), ('based', 'VBN'), ('least', 'JJS'), ('one', 'CD'), ('first', 'JJ'), ('inputs', 'NNS'), ('associated', 'VBN'), ('body', 'NN'), ('user', 'JJ'), ('one', 'CD'), ('second', 'NN'), ('inputs', 'NNS'), ('associated', 'VBD'), ('one', 'CD'), ('displaying', 'NN'), ('elements', 'NNS'), ('method', 'VBP'), ('claim', 'NN'), ('wherein', 'NN'), ('determining', 'VBG'), ('performance', 'NN'), ('metric', 'JJ'), ('eye', 'NN'), ('tracking', 'VBG'), ('system', 'NN'), ('second', 'JJ'), ('performance', 'NN'), ('threshold', 'NN'), ('comprises', 'VBZ'), ('determining', 'VBG'), ('eye', 'NN'), ('tracking', 'VBG'), ('system', 'NN'), ('exist', 'VBP'), ('fails', 'NNS'), ('provide', 'VBP'), ('eye', 'NN'), ('tracking', 'VBG'), ('data', 'NNS'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('performance', 'NN'), ('metric', 'JJ'), ('eye', 'NN'), ('tracking', 'VBG'), ('system', 'NN'), ('comprises', 'VBZ'), ('one', 'CD'), ('accuracy', 'NN'), ('parameter', 'NN'), ('eye', 'NN'), ('tracking', 'VBG'), ('system', 'NN'), ('precision', 'NN'), ('parameter', 'NN'), ('eye', 'NN'), ('tracking', 'VBG'), ('system', 'NN'), ('value', 'NN'), ('parameter', 'NN'), ('eye', 'NN'), ('tracking', 'VBG'), ('system', 'NN'), ('detectability', 'NN'), ('pupil', 'VBP'), ('metric', 'JJ'), ('based', 'VBN'), ('one', 'CD'), ('parameters', 'NNS'), ('associated', 'VBN'), ('user', 'JJ'), ('parameter', 'NN'), ('change', 'NN'), ('parameter', 'NN'), ('changing', 'VBG'), ('trend', 'NN'), ('data', 'NNS'), ('availability', 'NN'), ('weighted', 'VBD'), ('combination', 'NN'), ('one', 'CD'), ('performance', 'NN'), ('related', 'JJ'), ('parameters', 'NNS'), ('method', 'VBP'), ('claim', 'NN'), ('wherein', 'VBP'), ('one', 'CD'), ('parameters', 'NNS'), ('associated', 'VBN'), ('user', 'RB'), ('comprise', 'VB'), ('one', 'CD'), ('eye', 'NN'), ('distance', 'NN'), ('user', 'NN'), ('pupil', 'NN'), ('position', 'NN'), ('pupil', 'NN'), ('status', 'NN'), ('correlation', 'NN'), ('two', 'CD'), ('pupils', 'NNS'), ('user', 'JJ'), ('head', 'NN'), ('size', 'NN'), ('user', 'JJ'), ('position', 'NN'), ('headset', 'NN'), ('worn', 'JJ'), ('user', 'NN'), ('angle', 'NN'), ('headset', 'NN'), ('worn', 'WRB'), ('user', 'JJ'), ('direction', 'NN'), ('headset', 'NN'), ('worn', 'WRB'), ('user', 'NN'), ('alignment', 'JJ'), ('eyes', 'NNS'), ('user', 'RB'), ('weighted', 'VBD'), ('combination', 'NN'), ('one', 'CD'), ('related', 'JJ'), ('parameters', 'NNS'), ('associated', 'VBN'), ('user', 'JJ'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('first', 'JJ'), ('performance', 'NN'), ('threshold', 'NN'), ('comprises', 'VBZ'), ('one', 'CD'), ('pre-determined', 'JJ'), ('value', 'NN'), ('pre-determined', 'JJ'), ('range', 'NN'), ('state', 'NN'), ('data', 'NNS'), ('changing', 'VBG'), ('speed', 'NN'), ('data', 'NNS'), ('trend', 'NN'), ('data', 'NNS'), ('change', 'VBP'), ('one', 'CD'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('storage', 'NN'), ('media', 'NNS'), ('embodying', 'VBG'), ('software', 'NN'), ('operable', 'JJ'), ('executed', 'VBN'), ('computing', 'NN'), ('system', 'NN'), ('determine', 'JJ'), ('performance', 'NN'), ('metric', 'JJ'), ('eye', 'NN'), ('tracking', 'VBG'), ('system', 'NN'), ('first', 'JJ'), ('performance', 'NN'), ('threshold', 'NN'), ('wherein', 'NN'), ('eye', 'NN'), ('tracking', 'VBG'), ('system', 'NN'), ('associated', 'VBN'), ('head-mounted', 'JJ'), ('display', 'NN'), ('worn', 'VBN'), ('user', 'RB'), ('based', 'VBN'), ('determination', 'NN'), ('performance', 'NN'), ('metric', 'JJ'), ('eye', 'NN'), ('tracking', 'VBG'), ('system', 'NN'), ('first', 'JJ'), ('performance', 'NN'), ('threshold', 'JJ'), ('media', 'NNS'), ('embodying', 'VBG'), ('software', 'NN'), ('operable', 'JJ'), ('executed', 'VBN'), ('computing', 'VBG'), ('system', 'NN'), ('receive', 'VBP'), ('one', 'CD'), ('first', 'JJ'), ('inputs', 'NNS'), ('associated', 'VBN'), ('body', 'NN'), ('user', 'JJ'), ('estimate', 'NN'), ('region', 'NN'), ('user', 'IN'), ('looking', 'VBG'), ('within', 'IN'), ('field', 'NN'), ('view', 'NN'), ('head-mounted', 'JJ'), ('display', 'NN'), ('based', 'VBN'), ('received', 'VBD'), ('one', 'CD'), ('first', 'JJ'), ('inputs', 'NNS'), ('associated', 'VBN'), ('body', 'NN'), ('user', 'JJ'), ('determine', 'JJ'), ('vergence', 'NN'), ('distance', 'NN'), ('user', 'NN'), ('based', 'VBN'), ('least', 'JJS'), ('one', 'CD'), ('first', 'JJ'), ('inputs', 'NNS'), ('associated', 'VBN'), ('body', 'NN'), ('user', 'RBR'), ('estimated', 'VBN'), ('region', 'NN'), ('user', 'RBR'), ('looking', 'VBG'), ('locations', 'NNS'), ('one', 'CD'), ('objects', 'VBZ'), ('scene', 'NN'), ('displayed', 'VBD'), ('head-mounted', 'JJ'), ('display', 'NN'), ('adjust', 'VBP'), ('one', 'CD'), ('configurations', 'NNS'), ('head-mounted', 'JJ'), ('display', 'NN'), ('based', 'VBN'), ('determined', 'JJ'), ('vergence', 'NN'), ('distance', 'NN'), ('user', 'NN'), ('system', 'NN'), ('comprising', 'VBG'), ('one', 'CD'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('storage', 'NN'), ('media', 'NNS'), ('embodying', 'VBG'), ('instructions', 'NNS'), ('one', 'CD'), ('processors', 'NNS'), ('coupled', 'VBD'), ('storage', 'NN'), ('media', 'NNS'), ('operable', 'JJ'), ('execute', 'JJ'), ('instructions', 'NNS'), ('determine', 'VBP'), ('performance', 'NN'), ('metric', 'JJ'), ('eye', 'NN'), ('tracking', 'VBG'), ('system', 'NN'), ('first', 'JJ'), ('performance', 'NN'), ('threshold', 'NN'), ('wherein', 'NN'), ('eye', 'NN'), ('tracking', 'VBG'), ('system', 'NN'), ('associated', 'VBN'), ('head-mounted', 'JJ'), ('display', 'NN'), ('worn', 'VBN'), ('user', 'RB'), ('based', 'VBN'), ('determination', 'NN'), ('performance', 'NN'), ('metric', 'JJ'), ('eye', 'NN'), ('tracking', 'VBG'), ('system', 'NN'), ('first', 'JJ'), ('performance', 'NN'), ('threshold', 'NN'), ('system', 'NN'), ('configured', 'VBD'), ('receive', 'JJ'), ('one', 'CD'), ('first', 'JJ'), ('inputs', 'NNS'), ('associated', 'VBN'), ('body', 'NN'), ('user', 'JJ'), ('estimate', 'NN'), ('region', 'NN'), ('user', 'IN'), ('looking', 'VBG'), ('within', 'IN'), ('field', 'NN'), ('view', 'NN'), ('head-mounted', 'JJ'), ('display', 'NN'), ('based', 'VBN'), ('received', 'VBD'), ('one', 'CD'), ('first', 'JJ'), ('inputs', 'NNS'), ('associated', 'VBN'), ('body', 'NN'), ('user', 'JJ'), ('determine', 'JJ'), ('vergence', 'NN'), ('distance', 'NN'), ('user', 'NN'), ('based', 'VBN'), ('least', 'JJS'), ('one', 'CD'), ('first', 'JJ'), ('inputs', 'NNS'), ('associated', 'VBN'), ('body', 'NN'), ('user', 'RBR'), ('estimated', 'VBN'), ('region', 'NN'), ('user', 'RBR'), ('looking', 'VBG'), ('locations', 'NNS'), ('one', 'CD'), ('objects', 'VBZ'), ('scene', 'NN'), ('displayed', 'VBD'), ('head-mounted', 'JJ'), ('display', 'NN'), ('adjust', 'VBP'), ('one', 'CD'), ('configurations', 'NNS'), ('head-mounted', 'JJ'), ('display', 'NN'), ('based', 'VBN'), ('determined', 'JJ'), ('vergence', 'NN'), ('distance', 'NN'), ('user', 'JJ'), ('computer-implemented', 'JJ'), ('method', 'NN'), ('image-based', 'JJ'), ('self-guided', 'JJ'), ('object', 'JJ'), ('detection', 'NN'), ('comprising', 'VBG'), ('receiving', 'VBG'), ('processor', 'NN'), ('device', 'NN'), ('set', 'VBN'), ('images', 'NNS'), ('images', 'NNS'), ('respective', 'VBP'), ('grid', 'JJ'), ('thereon', 'NN'), ('labeled', 'VBD'), ('regarding', 'VBG'), ('respective', 'JJ'), ('object', 'NN'), ('detected', 'VBD'), ('using', 'VBG'), ('grid', 'JJ'), ('level', 'NN'), ('label', 'NN'), ('data', 'NNS'), ('training', 'NN'), ('processor', 'NN'), ('device', 'NN'), ('grid-based', 'JJ'), ('object', 'NN'), ('detector', 'NN'), ('using', 'VBG'), ('grid', 'JJ'), ('level', 'NN'), ('label', 'NN'), ('data', 'NNS'), ('determining', 'VBG'), ('processor', 'NN'), ('device', 'NN'), ('respective', 'NN'), ('bounding', 'VBG'), ('box', 'NN'), ('respective', 'JJ'), ('object', 'JJ'), ('images', 'NNS'), ('applying', 'VBG'), ('local', 'JJ'), ('segmentation', 'NN'), ('images', 'NNS'), ('training', 'VBG'), ('processor', 'JJ'), ('device', 'NN'), ('region-based', 'JJ'), ('convolutional', 'JJ'), ('neural', 'JJ'), ('network', 'NN'), ('rcnn', 'NN'), ('joint', 'NN'), ('object', 'JJ'), ('localization', 'NN'), ('object', 'NN'), ('classification', 'NN'), ('using', 'VBG'), ('respective', 'JJ'), ('bounding', 'NN'), ('box', 'NN'), ('respective', 'JJ'), ('object', 'JJ'), ('images', 'NNS'), ('input', 'VBP'), ('rcnn', 'JJ'), ('computer-implemented', 'JJ'), ('method', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('performing', 'VBG'), ('action', 'NN'), ('responsive', 'JJ'), ('object', 'NN'), ('localization', 'NN'), ('object', 'JJ'), ('classification', 'NN'), ('respective', 'JJ'), ('new', 'JJ'), ('object', 'JJ'), ('new', 'JJ'), ('image', 'NN'), ('rcnn', 'NN'), ('applied', 'VBD'), ('computer-implemented', 'JJ'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'WRB'), ('action', 'NN'), ('comprises', 'VBZ'), ('autonomously', 'RB'), ('controlling', 'VBG'), ('motor', 'NN'), ('vehicle', 'NN'), ('avoid', 'VBP'), ('collision', 'NN'), ('new', 'JJ'), ('object', 'JJ'), ('responsive', 'JJ'), ('object', 'NN'), ('localization', 'NN'), ('object', 'JJ'), ('classification', 'NN'), ('respective', 'JJ'), ('new', 'JJ'), ('object', 'JJ'), ('computer-implemented', 'JJ'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'VBD'), ('local', 'JJ'), ('segmentation', 'NN'), ('performed', 'VBD'), ('using', 'VBG'), ('self-similarity', 'JJ'), ('search', 'NN'), ('template', 'NN'), ('matching', 'VBG'), ('provide', 'RB'), ('respective', 'JJ'), ('bounding', 'VBG'), ('box', 'NN'), ('around', 'IN'), ('respective', 'JJ'), ('object', 'NN'), ('set', 'VBN'), ('images', 'NNS'), ('computer-implemented', 'JJ'), ('method', 'JJ'), ('claim', 'NN'), ('wherein', 'VBD'), ('local', 'JJ'), ('segmentation', 'NN'), ('applied', 'VBD'), ('images', 'NNS'), ('segment', 'NN'), ('respective', 'JJ'), ('target', 'NN'), ('region', 'NN'), ('therein', 'IN'), ('computer-implemented', 'JJ'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('region-based', 'JJ'), ('convolutional', 'JJ'), ('neural', 'JJ'), ('network', 'NN'), ('rcnn', 'NN'), ('forms', 'NNS'), ('model', 'VBP'), ('object', 'JJ'), ('training', 'NN'), ('stage', 'NN'), ('detect', 'JJ'), ('objects', 'VBZ'), ('new', 'JJ'), ('images', 'NNS'), ('inference', 'NN'), ('stage', 'NN'), ('computer-implemented', 'JJ'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('method', 'NN'), ('performed', 'VBD'), ('system', 'NN'), ('selected', 'VBN'), ('group', 'NN'), ('consisting', 'VBG'), ('surveillance', 'NN'), ('system', 'NN'), ('face', 'NN'), ('detection', 'NN'), ('system', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('system', 'NN'), ('cancer', 'NN'), ('detection', 'NN'), ('system', 'NN'), ('object', 'VBP'), ('tracking', 'VBG'), ('system', 'NN'), ('advanced', 'VBD'), ('driver-assistance', 'NN'), ('system', 'NN'), ('computer', 'NN'), ('program', 'NN'), ('product', 'NN'), ('image-based', 'JJ'), ('self-guided', 'JJ'), ('object', 'NN'), ('detection', 'NN'), ('computer', 'NN'), ('program', 'NN'), ('product', 'NN'), ('comprising', 'VBG'), ('non-transitory', 'JJ'), ('computer', 'NN'), ('readable', 'JJ'), ('storage', 'NN'), ('medium', 'NN'), ('program', 'NN'), ('instructions', 'NNS'), ('embodied', 'VBD'), ('therewith', 'JJ'), ('program', 'NN'), ('instructions', 'NNS'), ('executable', 'JJ'), ('computer', 'NN'), ('cause', 'NN'), ('computer', 'NN'), ('perform', 'NN'), ('method', 'NN'), ('comprising', 'VBG'), ('receiving', 'VBG'), ('processor', 'NN'), ('device', 'NN'), ('set', 'VBN'), ('images', 'NNS'), ('images', 'NNS'), ('respective', 'VBP'), ('grid', 'JJ'), ('thereon', 'NN'), ('labeled', 'VBD'), ('regarding', 'VBG'), ('respective', 'JJ'), ('object', 'NN'), ('detected', 'VBD'), ('using', 'VBG'), ('grid', 'JJ'), ('level', 'NN'), ('label', 'NN'), ('data', 'NNS'), ('training', 'NN'), ('processor', 'NN'), ('device', 'NN'), ('grid-based', 'JJ'), ('object', 'NN'), ('detector', 'NN'), ('using', 'VBG'), ('grid', 'JJ'), ('level', 'NN'), ('label', 'NN'), ('data', 'NNS'), ('determining', 'VBG'), ('processor', 'NN'), ('device', 'NN'), ('respective', 'NN'), ('bounding', 'VBG'), ('box', 'NN'), ('respective', 'JJ'), ('object', 'JJ'), ('images', 'NNS'), ('applying', 'VBG'), ('local', 'JJ'), ('segmentation', 'NN'), ('images', 'NNS'), ('training', 'VBG'), ('processor', 'JJ'), ('device', 'NN'), ('region-based', 'JJ'), ('convolutional', 'JJ'), ('neural', 'JJ'), ('network', 'NN'), ('rcnn', 'NN'), ('joint', 'NN'), ('object', 'JJ'), ('localization', 'NN'), ('object', 'NN'), ('classification', 'NN'), ('using', 'VBG'), ('respective', 'JJ'), ('bounding', 'NN'), ('box', 'NN'), ('respective', 'JJ'), ('object', 'JJ'), ('images', 'NNS'), ('input', 'VBP'), ('rcnn', 'JJ'), ('computer', 'NN'), ('program', 'NN'), ('product', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('method', 'NN'), ('comprises', 'VBZ'), ('performing', 'VBG'), ('action', 'NN'), ('responsive', 'JJ'), ('object', 'NN'), ('localization', 'NN'), ('object', 'JJ'), ('classification', 'NN'), ('respective', 'JJ'), ('new', 'JJ'), ('object', 'JJ'), ('new', 'JJ'), ('image', 'NN'), ('rcnn', 'NN'), ('applied', 'VBN'), ('computer', 'NN'), ('program', 'NN'), ('product', 'NN'), ('claim', 'NN'), ('wherein', 'JJ'), ('action', 'NN'), ('comprises', 'VBZ'), ('autonomously', 'RB'), ('controlling', 'VBG'), ('motor', 'NN'), ('vehicle', 'NN'), ('avoid', 'VBP'), ('collision', 'NN'), ('new', 'JJ'), ('object', 'JJ'), ('responsive', 'JJ'), ('object', 'NN'), ('localization', 'NN'), ('object', 'JJ'), ('classification', 'NN'), ('respective', 'JJ'), ('new', 'JJ'), ('object', 'JJ'), ('computer', 'NN'), ('program', 'NN'), ('product', 'NN'), ('claim', 'NN'), ('wherein', 'JJ'), ('local', 'JJ'), ('segmentation', 'NN'), ('performed', 'VBD'), ('using', 'VBG'), ('self-similarity', 'JJ'), ('search', 'NN'), ('template', 'NN'), ('matching', 'VBG'), ('provide', 'RB'), ('respective', 'JJ'), ('bounding', 'VBG'), ('box', 'NN'), ('around', 'IN'), ('respective', 'JJ'), ('object', 'NN'), ('set', 'VBN'), ('images', 'NNS'), ('computer', 'NN'), ('program', 'NN'), ('product', 'NN'), ('claim', 'NN'), ('wherein', 'JJ'), ('local', 'JJ'), ('segmentation', 'NN'), ('applied', 'VBD'), ('images', 'NNS'), ('segment', 'NN'), ('respective', 'JJ'), ('target', 'NN'), ('region', 'NN'), ('therein', 'JJ'), ('computer', 'NN'), ('program', 'NN'), ('product', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('region-based', 'JJ'), ('convolutional', 'JJ'), ('neural', 'JJ'), ('network', 'NN'), ('rcnn', 'NN'), ('forms', 'NNS'), ('model', 'VBP'), ('object', 'JJ'), ('training', 'NN'), ('stage', 'NN'), ('detect', 'JJ'), ('objects', 'VBZ'), ('new', 'JJ'), ('images', 'NNS'), ('inference', 'NN'), ('stage', 'NN'), ('computer', 'NN'), ('program', 'NN'), ('product', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('method', 'NN'), ('performed', 'VBD'), ('system', 'NN'), ('selected', 'VBN'), ('group', 'NN'), ('consisting', 'VBG'), ('surveillance', 'NN'), ('system', 'NN'), ('face', 'NN'), ('detection', 'NN'), ('system', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('system', 'NN'), ('cancer', 'NN'), ('detection', 'NN'), ('system', 'NN'), ('object', 'VBP'), ('tracking', 'VBG'), ('system', 'NN'), ('advanced', 'VBD'), ('driver-assistance', 'NN'), ('system', 'NN'), ('computer', 'NN'), ('processing', 'VBG'), ('system', 'NN'), ('image-based', 'JJ'), ('self-guided', 'JJ'), ('object', 'JJ'), ('detection', 'NN'), ('comprising', 'VBG'), ('memory', 'NN'), ('device', 'NN'), ('storing', 'VBG'), ('program', 'NN'), ('code', 'NN'), ('processor', 'NN'), ('device', 'NN'), ('running', 'VBG'), ('program', 'NN'), ('code', 'NN'), ('receive', 'VBP'), ('set', 'VBN'), ('images', 'NNS'), ('images', 'NNS'), ('respective', 'VBP'), ('grid', 'JJ'), ('thereon', 'NN'), ('labeled', 'VBD'), ('regarding', 'VBG'), ('respective', 'JJ'), ('object', 'NN'), ('detected', 'VBD'), ('using', 'VBG'), ('grid', 'JJ'), ('level', 'NN'), ('label', 'NN'), ('data', 'NNS'), ('train', 'VBP'), ('grid-based', 'JJ'), ('object', 'NN'), ('detector', 'NN'), ('using', 'VBG'), ('grid', 'JJ'), ('level', 'NN'), ('label', 'NN'), ('data', 'NNS'), ('determine', 'VBP'), ('respective', 'JJ'), ('bounding', 'NN'), ('box', 'NN'), ('respective', 'JJ'), ('object', 'JJ'), ('images', 'NNS'), ('applying', 'VBG'), ('local', 'JJ'), ('segmentation', 'NN'), ('images', 'NNS'), ('train', 'VBP'), ('region-based', 'JJ'), ('convolutional', 'JJ'), ('neural', 'JJ'), ('network', 'NN'), ('rcnn', 'NN'), ('joint', 'NN'), ('object', 'JJ'), ('localization', 'NN'), ('object', 'NN'), ('classification', 'NN'), ('using', 'VBG'), ('respective', 'JJ'), ('bounding', 'NN'), ('box', 'NN'), ('respective', 'JJ'), ('object', 'JJ'), ('images', 'NNS'), ('input', 'VBP'), ('rcnn', 'RB'), ('computer', 'NN'), ('processing', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('processor', 'NN'), ('device', 'NN'), ('runs', 'VBZ'), ('program', 'NN'), ('code', 'NN'), ('perform', 'VB'), ('action', 'NN'), ('responsive', 'JJ'), ('object', 'NN'), ('localization', 'NN'), ('object', 'JJ'), ('classification', 'NN'), ('respective', 'JJ'), ('new', 'JJ'), ('object', 'JJ'), ('new', 'JJ'), ('image', 'NN'), ('rcnn', 'NN'), ('applied', 'VBD'), ('computer', 'NN'), ('processing', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'WRB'), ('action', 'NN'), ('comprises', 'VBZ'), ('autonomously', 'RB'), ('controlling', 'VBG'), ('motor', 'NN'), ('vehicle', 'NN'), ('avoid', 'VBP'), ('collision', 'NN'), ('new', 'JJ'), ('object', 'JJ'), ('responsive', 'JJ'), ('object', 'NN'), ('localization', 'NN'), ('object', 'JJ'), ('classification', 'NN'), ('respective', 'JJ'), ('new', 'JJ'), ('object', 'JJ'), ('computer', 'NN'), ('processing', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'RB'), ('local', 'JJ'), ('segmentation', 'NN'), ('performed', 'VBD'), ('using', 'VBG'), ('self-similarity', 'JJ'), ('search', 'NN'), ('template', 'NN'), ('matching', 'VBG'), ('provide', 'RB'), ('respective', 'JJ'), ('bounding', 'VBG'), ('box', 'NN'), ('around', 'IN'), ('respective', 'JJ'), ('object', 'NN'), ('set', 'VBN'), ('images', 'NNS'), ('computer', 'NN'), ('processing', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('region-based', 'JJ'), ('convolutional', 'JJ'), ('neural', 'JJ'), ('network', 'NN'), ('rcnn', 'NN'), ('forms', 'NNS'), ('model', 'VBP'), ('object', 'JJ'), ('training', 'NN'), ('stage', 'NN'), ('detect', 'JJ'), ('objects', 'VBZ'), ('new', 'JJ'), ('images', 'NNS'), ('inference', 'NN'), ('stage', 'NN'), ('computer', 'NN'), ('processing', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'VBP'), ('computer', 'NN'), ('processing', 'NN'), ('system', 'NN'), ('comprised', 'VBD'), ('system', 'NN'), ('selected', 'VBN'), ('group', 'NN'), ('consisting', 'VBG'), ('surveillance', 'NN'), ('system', 'NN'), ('face', 'NN'), ('detection', 'NN'), ('system', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('system', 'NN'), ('cancer', 'NN'), ('detection', 'NN'), ('system', 'NN'), ('object', 'VBP'), ('tracking', 'VBG'), ('system', 'NN'), ('advanced', 'VBD'), ('driver-assistance', 'NN'), ('system', 'NN'), ('method', 'RBR'), ('scalable', 'JJ'), ('parallel', 'JJ'), ('cloud-based', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('utilizing', 'VBG'), ('database', 'NN'), ('normalized', 'VBN'), ('stored', 'JJ'), ('images', 'NNS'), ('comprising', 'VBG'), ('capturing', 'VBG'), ('image', 'NN'), ('using', 'VBG'), ('camera', 'NN'), ('detecting', 'VBG'), ('face', 'NN'), ('captured', 'VBN'), ('image', 'NN'), ('normalizing', 'VBG'), ('detected', 'VBN'), ('facial', 'JJ'), ('image', 'NN'), ('match', 'NN'), ('normalized', 'VBN'), ('stored', 'JJ'), ('images', 'NNS'), ('identifying', 'VBG'), ('facial', 'JJ'), ('features', 'NNS'), ('normalized', 'VBN'), ('detected', 'JJ'), ('facial', 'JJ'), ('image', 'NN'), ('generating', 'VBG'), ('plurality', 'NN'), ('facial', 'JJ'), ('metrics', 'NNS'), ('facial', 'JJ'), ('features', 'NNS'), ('calculating', 'VBG'), ('euclidean', 'JJ'), ('distances', 'NNS'), ('facial', 'JJ'), ('metrics', 'NNS'), ('normalized', 'VBN'), ('detected', 'JJ'), ('facial', 'JJ'), ('image', 'NN'), ('corresponding', 'VBG'), ('facial', 'JJ'), ('metrics', 'NNS'), ('stored', 'VBD'), ('images', 'NNS'), ('comparing', 'VBG'), ('euclidean', 'JJ'), ('distance', 'NN'), ('predetermined', 'VBD'), ('threshold', 'JJ'), ('responsive', 'JJ'), ('euclidean', 'JJ'), ('distance', 'NN'), ('comparison', 'NN'), ('producing', 'VBG'), ('reduced', 'JJ'), ('candidate', 'JJ'), ('list', 'NN'), ('best', 'JJS'), ('possible', 'JJ'), ('image', 'NN'), ('matches', 'NNS'), ('normalized', 'VBN'), ('stored', 'JJ'), ('images', 'NNS'), ('comparing', 'VBG'), ('parallel', 'JJ'), ('normalized', 'VBN'), ('detected', 'JJ'), ('facial', 'JJ'), ('image', 'NN'), ('normalized', 'VBN'), ('stored', 'JJ'), ('images', 'NNS'), ('reduced', 'VBN'), ('candidate', 'JJ'), ('list', 'NN'), ('utilizing', 'VBG'), ('plurality', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('algorithms', 'NN'), ('processor', 'NN'), ('parallel', 'RB'), ('processing', 'VBG'), ('system', 'NN'), ('uses', 'VBZ'), ('different', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('algorithm', 'IN'), ('responsive', 'JJ'), ('comparison', 'NN'), ('producing', 'VBG'), ('best', 'JJS'), ('match', 'NN'), ('results', 'NNS'), ('parallel', 'JJ'), ('subset', 'NN'), ('reduced', 'VBN'), ('candidate', 'JJ'), ('list', 'NN'), ('selecting', 'VBG'), ('final', 'JJ'), ('match', 'NN'), ('best', 'JJS'), ('match', 'NN'), ('results', 'NNS'), ('using', 'VBG'), ('deep', 'JJ'), ('learning', 'VBG'), ('neural', 'JJ'), ('network', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('algorithm', 'NN'), ('trained', 'VBD'), ('outputs', 'NNS'), ('individual', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('algorithms', 'IN'), ('method', 'NN'), ('scalable', 'JJ'), ('parallel', 'JJ'), ('cloud-based', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('detecting', 'VBG'), ('face', 'NN'), ('captured', 'VBN'), ('image', 'NN'), ('comprises', 'VBZ'), ('utilizing', 'VBG'), ('opencv', 'RP'), ('detect', 'JJ'), ('face', 'NN'), ('captured', 'VBD'), ('image', 'NN'), ('extracting', 'VBG'), ('location', 'JJ'), ('eyes', 'NNS'), ('tip', 'VBP'), ('nose', 'JJ'), ('face', 'NN'), ('determining', 'VBG'), ('distance', 'NN'), ('eyes', 'NNS'), ('cropping', 'VBG'), ('face', 'NN'), ('captured', 'VBN'), ('image', 'NN'), ('width', 'NN'), ('height', 'VBD'), ('cropped', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('function', 'NN'), ('distance', 'NN'), ('eyes', 'NNS'), ('rotating', 'VBG'), ('face', 'NN'), ('angle', 'NN'), ('rotation', 'NN'), ('function', 'NN'), ('distance', 'NN'), ('eyes', 'NNS'), ('method', 'RBR'), ('scalable', 'JJ'), ('parallel', 'JJ'), ('cloud-based', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('width', 'NN'), ('cropped', 'VBD'), ('face', 'NN'), ('image', 'NN'), ('times', 'NNS'), ('distance', 'VB'), ('eyes', 'NNS'), ('height', 'MD'), ('cropped', 'VB'), ('face', 'NN'), ('image', 'NN'), ('times', 'NNS'), ('distance', 'VB'), ('eyes', 'NNS'), ('angle', 'JJ'), ('rotation', 'NN'), ('angle', 'NN'), ('formed', 'VBD'), ('straight', 'JJ'), ('line', 'NN'), ('joining', 'VBG'), ('eyes', 'NNS'), ('x-axis', 'JJ'), ('face', 'NN'), ('method', 'NN'), ('scalable', 'JJ'), ('parallel', 'JJ'), ('cloud-based', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('rotating', 'VBG'), ('face', 'NN'), ('comprises', 'NNS'), ('rotating', 'VBG'), ('face', 'NN'), ('provide', 'VBP'), ('frontal', 'JJ'), ('face', 'NN'), ('pattern', 'NN'), ('method', 'NN'), ('scalable', 'JJ'), ('parallel', 'JJ'), ('cloud-based', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('step', 'NN'), ('proportionally', 'RB'), ('rescaling', 'VBG'), ('cropped', 'VBN'), ('rotated', 'VBN'), ('image', 'NN'), ('method', 'NN'), ('scalable', 'JJ'), ('parallel', 'JJ'), ('cloud-based', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('claim', 'NN'), ('proportional', 'JJ'), ('rescaling', 'NN'), ('yields', 'NNS'), ('cropped', 'VBD'), ('rotated', 'VBN'), ('image', 'NN'), ('size', 'NN'), ('=', 'NNP'), ('pixels', 'NNS'), ('method', 'RBR'), ('scalable', 'JJ'), ('parallel', 'JJ'), ('cloud-based', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('claim', 'NN'), ('wherein', 'VBP'), ('facial', 'JJ'), ('features', 'NNS'), ('identified', 'VBN'), ('normalized', 'JJ'), ('detected', 'VBN'), ('facial', 'JJ'), ('image', 'NN'), ('comprise', 'NN'), ('pair', 'JJ'), ('eyes', 'NNS'), ('tip', 'VBP'), ('nose', 'JJ'), ('mouth', 'NN'), ('center', 'NN'), ('mouth', 'NN'), ('chin', 'JJ'), ('area', 'NN'), ('comprising', 'VBG'), ('bottom', 'JJ'), ('top', 'JJ'), ('left', 'VBN'), ('landmark', 'NN'), ('top', 'JJ'), ('right', 'NN'), ('landmark', 'NN'), ('method', 'NN'), ('scalable', 'JJ'), ('parallel', 'JJ'), ('cloud-based', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('generating', 'VBG'), ('plurality', 'NN'), ('facial', 'JJ'), ('metrics', 'NNS'), ('comprises', 'NNS'), ('calculating', 'VBG'), ('distance', 'NN'), ('pair', 'NN'), ('eyes', 'NNS'), ('distance', 'VB'), ('eyes', 'NNS'), ('tip', 'VBP'), ('nose', 'JJ'), ('distance', 'NN'), ('equal', 'JJ'), ('width', 'NN'), ('mouth', 'NN'), ('distance', 'NN'), ('tip', 'NN'), ('nose', 'RB'), ('center', 'JJ'), ('mouth', 'NN'), ('distance', 'NN'), ('bottom', 'NN'), ('chin', 'NN'), ('center', 'NN'), ('mouth', 'NN'), ('distance', 'NN'), ('top', 'NN'), ('left', 'VBD'), ('landmark', 'NN'), ('chin', 'NN'), ('tip', 'NN'), ('nose', 'JJ'), ('distance', 'NN'), ('top', 'JJ'), ('right', 'NN'), ('landmark', 'NN'), ('chin', 'JJ'), ('tip', 'NN'), ('nose', 'JJ'), ('method', 'NN'), ('scalable', 'JJ'), ('parallel', 'JJ'), ('cloud-based', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('performing', 'VBG'), ('euclidean', 'JJ'), ('distance', 'NN'), ('match', 'NN'), ('comprises', 'VBZ'), ('partitioning', 'VBG'), ('normalized', 'VBN'), ('stored', 'JJ'), ('images', 'NNS'), ('plurality', 'VBP'), ('substantially', 'RB'), ('equal', 'JJ'), ('subsets', 'NNS'), ('performing', 'VBG'), ('euclidean', 'JJ'), ('distance', 'NN'), ('match', 'NN'), ('facial', 'JJ'), ('metrics', 'NNS'), ('normalized', 'VBN'), ('detected', 'JJ'), ('facial', 'JJ'), ('image', 'NN'), ('corresponding', 'VBG'), ('facial', 'JJ'), ('metrics', 'NNS'), ('stored', 'VBD'), ('images', 'NNS'), ('subsets', 'NNS'), ('normalized', 'VBN'), ('stored', 'JJ'), ('images', 'NNS'), ('separate', 'VBP'), ('processor', 'NN'), ('parallel', 'NN'), ('processing', 'NN'), ('system', 'NN'), ('generate', 'JJ'), ('euclidean', 'JJ'), ('distance', 'NN'), ('stored', 'VBN'), ('image', 'NN'), ('subset', 'NN'), ('comparing', 'VBG'), ('euclidean', 'JJ'), ('distance', 'NN'), ('predetermined', 'VBD'), ('threshold', 'JJ'), ('separate', 'JJ'), ('processors', 'NNS'), ('responsive', 'JJ'), ('euclidean', 'JJ'), ('distance', 'NN'), ('comparison', 'NN'), ('producing', 'VBG'), ('reduced', 'JJ'), ('candidate', 'JJ'), ('list', 'NN'), ('best', 'JJS'), ('possible', 'JJ'), ('image', 'NN'), ('matches', 'NNS'), ('normalized', 'VBN'), ('stored', 'JJ'), ('images', 'NNS'), ('subset', 'VBP'), ('combining', 'VBG'), ('reduced', 'VBN'), ('candidate', 'NN'), ('lists', 'NNS'), ('subset', 'VBP'), ('produce', 'VBP'), ('single', 'JJ'), ('reduced', 'VBN'), ('candidate', 'JJ'), ('list', 'NN'), ('method', 'NN'), ('scalable', 'JJ'), ('parallel', 'JJ'), ('cloud-based', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('plurality', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('algorithms', 'IN'), ('utilized', 'JJ'), ('comparing', 'VBG'), ('parallel', 'JJ'), ('normalized', 'VBN'), ('detected', 'JJ'), ('facial', 'JJ'), ('image', 'NN'), ('normalized', 'VBN'), ('stored', 'JJ'), ('images', 'NNS'), ('reduced', 'VBN'), ('candidate', 'JJ'), ('list', 'NN'), ('consists', 'VBZ'), ('face', 'VBP'), ('recognition', 'NN'), ('algorithms', 'RB'), ('selected', 'VBN'), ('group', 'NN'), ('consisting', 'VBG'), ('principle', 'JJ'), ('component', 'JJ'), ('analysis', 'NN'), ('pca-based', 'JJ'), ('algorithms', 'NN'), ('linear', 'JJ'), ('discriminant', 'JJ'), ('analysis', 'NN'), ('lda', 'NN'), ('algorithms', 'JJ'), ('independent', 'JJ'), ('component', 'NN'), ('analysis', 'NN'), ('ica', 'NN'), ('algorithms', 'IN'), ('kernel-based', 'JJ'), ('algorithms', 'JJ'), ('feature-based', 'JJ'), ('techniques', 'NNS'), ('algorithms', 'VBP'), ('based', 'VBN'), ('neural', 'JJ'), ('networks', 'NNS'), ('algorithms', 'VBP'), ('based', 'VBN'), ('transforms', 'NNS'), ('model-based', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('algorithms', 'IN'), ('method', 'NN'), ('scalable', 'JJ'), ('parallel', 'JJ'), ('cloud-based', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('pca-based', 'JJ'), ('algorithms', 'NNS'), ('include', 'VBP'), ('eigenfaces', 'NNS'), ('face', 'VBP'), ('detectionrecognition', 'NN'), ('lda', 'NN'), ('algorithms', 'NN'), ('include', 'VBP'), ('fisherfaces', 'NNS'), ('method', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('method', 'NN'), ('scalable', 'JJ'), ('parallel', 'JJ'), ('cloud-based', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('comparing', 'VBG'), ('parallel', 'NN'), ('captured', 'VBN'), ('image', 'NN'), ('normalized', 'VBN'), ('stored', 'JJ'), ('images', 'NNS'), ('reduced', 'VBN'), ('candidate', 'JJ'), ('list', 'NN'), ('comprises', 'NNS'), ('partitioning', 'VBG'), ('reduced', 'JJ'), ('candidate', 'NN'), ('list', 'NN'), ('plurality', 'NN'), ('substantially', 'RB'), ('equal', 'JJ'), ('subsets', 'NNS'), ('processing', 'VBG'), ('subset', 'JJ'), ('different', 'JJ'), ('processor', 'NN'), ('parallel', 'NN'), ('processing', 'NN'), ('system', 'NN'), ('uses', 'VBZ'), ('unique', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('algorithm', 'IN'), ('produce', 'NN'), ('best', 'JJS'), ('match', 'NN'), ('results', 'NNS'), ('using', 'VBG'), ('reduce', 'VB'), ('function', 'NN'), ('mapreduce', 'NN'), ('program', 'NN'), ('combine', 'NN'), ('best', 'RBS'), ('match', 'NN'), ('results', 'NNS'), ('subsets', 'NNS'), ('produce', 'VBP'), ('single', 'JJ'), ('set', 'NN'), ('best', 'JJS'), ('match', 'NN'), ('results', 'NNS'), ('method', 'RBR'), ('scalable', 'JJ'), ('parallel', 'JJ'), ('cloud-based', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('partitioning', 'VBG'), ('reduced', 'VBN'), ('candidate', 'JJ'), ('list', 'NN'), ('comprises', 'NNS'), ('selecting', 'VBG'), ('images', 'NNS'), ('comprising', 'VBG'), ('subset', 'NN'), ('optimizing', 'VBG'), ('variance', 'NN'), ('images', 'NNS'), ('according', 'VBG'), ('following', 'VBG'), ('equation', 'NN'), ('n', 'IN'), ('number', 'NN'), ('rows', 'NNS'), ('columns', 'VBP'), ('face', 'NN'), ('vector', 'NN'), ('image', 'NN'), ('n', 'JJ'), ('number', 'NN'), ('groups', 'NNS'), ('σij', 'VBP'), ('standard', 'JJ'), ('deviation', 'NN'), ('image', 'NN'), ('dimension', 'NN'), ('group', 'NN'), ('j', 'NN'), ('face', 'NN'), ('image', 'NN'), ('vector', 'NN'), ('method', 'NN'), ('scalable', 'JJ'), ('parallel', 'JJ'), ('cloud-based', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('selecting', 'VBG'), ('images', 'NNS'), ('comprising', 'VBG'), ('subset', 'NN'), ('optimizing', 'VBG'), ('variance', 'NN'), ('images', 'NNS'), ('according', 'VBG'), ('following', 'VBG'), ('equation', 'NN'), ('dμi', 'FW'), ('μj', 'JJ'), ('euclidean', 'JJ'), ('distance', 'NN'), ('mean', 'NN'), ('group', 'NN'), ('mean', 'VBD'), ('group', 'NN'), ('j', 'NN'), ('face', 'NN'), ('image', 'NN'), ('vector', 'NN'), ('l', 'JJ'), ('number', 'NN'), ('group', 'NN'), ('levels', 'NNS'), ('method', 'VBP'), ('scalable', 'JJ'), ('parallel', 'JJ'), ('cloud-based', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('claim', 'NN'), ('selecting', 'VBG'), ('final', 'JJ'), ('match', 'NN'), ('best', 'JJS'), ('match', 'NN'), ('results', 'NNS'), ('utilizing', 'JJ'), ('deep', 'JJ'), ('learning', 'NN'), ('neural', 'JJ'), ('network', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('algorithm', 'NN'), ('comprises', 'VBZ'), ('utilizing', 'VBG'), ('either', 'DT'), ('adaboost', 'JJ'), ('machine-learning', 'JJ'), ('algorithm', 'JJ'), ('neural', 'JJ'), ('networks', 'NNS'), ('machine-learning', 'JJ'), ('model', 'NN'), ('method', 'NN'), ('scalable', 'JJ'), ('parallel', 'JJ'), ('cloud-based', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('claim', 'NN'), ('normalizing', 'VBG'), ('detected', 'VBN'), ('facial', 'JJ'), ('image', 'NN'), ('match', 'NN'), ('normalized', 'VBN'), ('stored', 'JJ'), ('images', 'NNS'), ('includes', 'VBZ'), ('normalizing', 'VBG'), ('detected', 'VBN'), ('facial', 'JJ'), ('image', 'NN'), ('size', 'NN'), ('orientation', 'NN'), ('illumination', 'NN'), ('normalized', 'VBN'), ('stored', 'JJ'), ('images', 'NNS'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('medium', 'NN'), ('containing', 'VBG'), ('executable', 'JJ'), ('program', 'NN'), ('instructions', 'NNS'), ('causing', 'VBG'), ('computer', 'NN'), ('perform', 'NN'), ('method', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('method', 'NN'), ('comprising', 'VBG'), ('detecting', 'VBG'), ('face', 'NN'), ('image', 'NN'), ('captured', 'VBD'), ('camera', 'NN'), ('normalizing', 'NN'), ('detected', 'VBN'), ('facial', 'JJ'), ('image', 'NN'), ('match', 'NN'), ('normalized', 'VBN'), ('stored', 'JJ'), ('images', 'NNS'), ('identifying', 'VBG'), ('facial', 'JJ'), ('features', 'NNS'), ('normalized', 'VBN'), ('detected', 'JJ'), ('facial', 'JJ'), ('image', 'NN'), ('generating', 'VBG'), ('plurality', 'NN'), ('facial', 'JJ'), ('metrics', 'NNS'), ('facial', 'JJ'), ('features', 'NNS'), ('calculating', 'VBG'), ('euclidean', 'JJ'), ('distances', 'NNS'), ('facial', 'JJ'), ('metrics', 'NNS'), ('normalized', 'VBN'), ('detected', 'JJ'), ('facial', 'JJ'), ('image', 'NN'), ('corresponding', 'VBG'), ('facial', 'JJ'), ('metrics', 'NNS'), ('stored', 'VBD'), ('images', 'NNS'), ('comparing', 'VBG'), ('euclidean', 'JJ'), ('distance', 'NN'), ('predetermined', 'VBD'), ('threshold', 'JJ'), ('responsive', 'JJ'), ('euclidean', 'JJ'), ('distance', 'NN'), ('comparison', 'NN'), ('producing', 'VBG'), ('reduced', 'JJ'), ('candidate', 'JJ'), ('list', 'NN'), ('best', 'JJS'), ('possible', 'JJ'), ('image', 'NN'), ('matches', 'NNS'), ('normalized', 'VBN'), ('stored', 'JJ'), ('images', 'NNS'), ('comparing', 'VBG'), ('parallel', 'RB'), ('captured', 'VBN'), ('image', 'NN'), ('normalized', 'VBN'), ('stored', 'JJ'), ('images', 'NNS'), ('reduced', 'VBN'), ('candidate', 'JJ'), ('list', 'NN'), ('utilizing', 'VBG'), ('plurality', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('algorithms', 'NN'), ('processor', 'NN'), ('parallel', 'RB'), ('processing', 'VBG'), ('system', 'NN'), ('uses', 'VBZ'), ('different', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('algorithm', 'IN'), ('responsive', 'JJ'), ('comparison', 'NN'), ('producing', 'VBG'), ('best', 'JJS'), ('match', 'NN'), ('results', 'NNS'), ('parallel', 'JJ'), ('subset', 'NN'), ('reduced', 'VBN'), ('candidate', 'JJ'), ('list', 'NN'), ('selecting', 'VBG'), ('final', 'JJ'), ('match', 'NN'), ('best', 'JJS'), ('match', 'NN'), ('results', 'NNS'), ('using', 'VBG'), ('deep', 'JJ'), ('learning', 'VBG'), ('neural', 'JJ'), ('network', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('algorithm', 'NN'), ('trained', 'VBD'), ('outputs', 'NNS'), ('individual', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('algorithms', 'IN'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('medium', 'NN'), ('containing', 'VBG'), ('executable', 'JJ'), ('program', 'NN'), ('instructions', 'NNS'), ('claim', 'VBP'), ('wherein', 'JJ'), ('plurality', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('algorithms', 'IN'), ('utilized', 'JJ'), ('comparing', 'VBG'), ('parallel', 'JJ'), ('normalized', 'VBN'), ('detected', 'JJ'), ('facial', 'JJ'), ('image', 'NN'), ('normalized', 'VBN'), ('stored', 'JJ'), ('images', 'NNS'), ('reduced', 'VBN'), ('candidate', 'JJ'), ('list', 'NN'), ('consists', 'VBZ'), ('face', 'VBP'), ('recognition', 'NN'), ('algorithms', 'RB'), ('selected', 'VBN'), ('group', 'NN'), ('consisting', 'VBG'), ('principle', 'JJ'), ('component', 'JJ'), ('analysis', 'NN'), ('pca-based', 'JJ'), ('algorithms', 'NN'), ('linear', 'JJ'), ('discriminant', 'JJ'), ('analysis', 'NN'), ('lda', 'NN'), ('algorithms', 'JJ'), ('independent', 'JJ'), ('component', 'NN'), ('analysis', 'NN'), ('ica', 'NN'), ('algorithms', 'IN'), ('kernel-based', 'JJ'), ('algorithms', 'JJ'), ('feature-based', 'JJ'), ('techniques', 'NNS'), ('algorithms', 'VBP'), ('based', 'VBN'), ('neural', 'JJ'), ('networks', 'NNS'), ('algorithms', 'VBP'), ('based', 'VBN'), ('transforms', 'NNS'), ('model-based', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('algorithms', 'IN'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('medium', 'NN'), ('containing', 'VBG'), ('executable', 'JJ'), ('program', 'NN'), ('instructions', 'NNS'), ('claim', 'VBP'), ('wherein', 'IN'), ('pca-based', 'JJ'), ('algorithms', 'NNS'), ('include', 'VBP'), ('eigenfaces', 'NNS'), ('face', 'VBP'), ('detectionrecognition', 'NN'), ('lda', 'NN'), ('algorithms', 'NN'), ('include', 'VBP'), ('fisherfaces', 'NNS'), ('method', 'JJ'), ('face', 'NN'), ('recognition', 'NN'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('medium', 'NN'), ('containing', 'VBG'), ('executable', 'JJ'), ('program', 'NN'), ('instructions', 'NNS'), ('claim', 'VBP'), ('selecting', 'VBG'), ('final', 'JJ'), ('match', 'NN'), ('best', 'JJS'), ('match', 'NN'), ('results', 'NNS'), ('utilizing', 'JJ'), ('deep', 'JJ'), ('learning', 'NN'), ('neural', 'JJ'), ('network', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('algorithm', 'NN'), ('comprises', 'VBZ'), ('utilizing', 'VBG'), ('either', 'DT'), ('adaboost', 'JJ'), ('machine-learning', 'JJ'), ('algorithm', 'JJ'), ('neural', 'JJ'), ('networks', 'NNS'), ('machine-learning', 'JJ'), ('model', 'NN'), ('imaging', 'VBG'), ('device', 'NN'), ('comprising', 'VBG'), ('condensing', 'VBG'), ('lens', 'JJ'), ('image', 'NN'), ('sensor', 'NN'), ('configured', 'VBD'), ('detect', 'JJ'), ('light', 'JJ'), ('passing', 'VBG'), ('condensing', 'VBG'), ('lens', 'NNS'), ('comprising', 'VBG'), ('pixel', 'NN'), ('matrix', 'NN'), ('wherein', 'NN'), ('pixel', 'NN'), ('matrix', 'NN'), ('comprises', 'VBZ'), ('plurality', 'NN'), ('phase', 'NN'), ('detection', 'NN'), ('pixel', 'NN'), ('pairs', 'NNS'), ('plurality', 'NN'), ('regular', 'JJ'), ('pixels', 'NNS'), ('processor', 'NN'), ('configured', 'VBD'), ('turn', 'JJ'), ('phase', 'JJ'), ('detection', 'NN'), ('pixel', 'NN'), ('pairs', 'NNS'), ('autofocusing', 'VBG'), ('output', 'NN'), ('autofocused', 'VBD'), ('pixel', 'JJ'), ('data', 'NNS'), ('completing', 'VBG'), ('autofocusing', 'VBG'), ('divide', 'NN'), ('autofocused', 'VBD'), ('pixel', 'NN'), ('data', 'NNS'), ('first', 'RB'), ('subframe', 'JJ'), ('second', 'JJ'), ('subframe', 'NN'), ('calculate', 'NN'), ('image', 'NN'), ('features', 'NNS'), ('least', 'VBP'), ('one', 'CD'), ('first', 'JJ'), ('subframe', 'JJ'), ('second', 'JJ'), ('subframe', 'NN'), ('wherein', 'NN'), ('image', 'NN'), ('features', 'NNS'), ('comprise', 'VBP'), ('module', 'JJ'), ('widths', 'NNS'), ('finder', 'VBP'), ('pattern', 'JJ'), ('finder', 'NN'), ('pattern', 'NN'), ('predetermined', 'VBN'), ('ratio', 'JJ'), ('harr-like', 'JJ'), ('feature', 'NN'), ('gabor', 'NN'), ('feature', 'NN'), ('determine', 'NN'), ('operating', 'VBG'), ('resolution', 'NN'), ('regular', 'JJ'), ('pixels', 'NNS'), ('according', 'VBG'), ('image', 'NN'), ('features', 'NNS'), ('calculated', 'VBD'), ('least', 'JJS'), ('one', 'CD'), ('first', 'JJ'), ('subframe', 'JJ'), ('second', 'JJ'), ('subframe', 'NN'), ('divided', 'VBD'), ('autofocused', 'JJ'), ('pixel', 'NN'), ('data', 'NNS'), ('imaging', 'VBG'), ('device', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('phase', 'NN'), ('detection', 'NN'), ('pixel', 'NN'), ('pairs', 'NN'), ('comprises', 'VBZ'), ('first', 'JJ'), ('pixel', 'JJ'), ('second', 'JJ'), ('pixel', 'NN'), ('cover', 'NN'), ('layer', 'NN'), ('covering', 'VBG'), ('upon', 'IN'), ('first', 'JJ'), ('region', 'NN'), ('first', 'RB'), ('pixel', 'VBZ'), ('upon', 'IN'), ('second', 'JJ'), ('region', 'NN'), ('second', 'JJ'), ('pixel', 'NN'), ('wherein', 'NN'), ('first', 'JJ'), ('region', 'NN'), ('second', 'JJ'), ('region', 'NN'), ('mirror', 'NN'), ('symmetrical', 'JJ'), ('microlens', 'NNS'), ('aligned', 'VBN'), ('least', 'JJS'), ('one', 'CD'), ('first', 'JJ'), ('pixel', 'JJ'), ('second', 'JJ'), ('pixel', 'NN'), ('imaging', 'VBG'), ('device', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('first', 'JJ'), ('region', 'NN'), ('second', 'JJ'), ('region', 'NN'), ('%', 'NN'), ('%', 'NN'), ('area', 'NN'), ('single', 'JJ'), ('pixel', 'NN'), ('imaging', 'VBG'), ('device', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('processor', 'NN'), ('configured', 'VBD'), ('perform', 'NN'), ('autofocusing', 'VBG'), ('using', 'VBG'), ('dual', 'JJ'), ('pixel', 'NN'), ('autofocus', 'NN'), ('technique', 'NN'), ('according', 'VBG'), ('pixel', 'NN'), ('data', 'NNS'), ('phase', 'NN'), ('detection', 'NN'), ('pixel', 'NN'), ('pairs', 'NNS'), ('completing', 'VBG'), ('autofocusing', 'VBG'), ('imaging', 'JJ'), ('device', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('processor', 'NN'), ('configured', 'VBD'), ('divide', 'JJ'), ('pixel', 'NN'), ('data', 'NNS'), ('phase', 'NN'), ('detection', 'NN'), ('pixel', 'NN'), ('pairs', 'NNS'), ('third', 'JJ'), ('subframe', 'JJ'), ('fourth', 'JJ'), ('subframe', 'NN'), ('completing', 'VBG'), ('autofocusing', 'VBG'), ('perform', 'NN'), ('autofocusing', 'VBG'), ('according', 'VBG'), ('third', 'JJ'), ('subframe', 'JJ'), ('fourth', 'JJ'), ('subframe', 'NN'), ('imaging', 'VBG'), ('device', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('processor', 'NN'), ('configured', 'VBD'), ('calibrate', 'JJ'), ('brightness', 'JJ'), ('third', 'JJ'), ('subframe', 'NN'), ('fourth', 'JJ'), ('subframe', 'JJ'), ('identical', 'JJ'), ('using', 'VBG'), ('shading', 'VBG'), ('algorithm', 'JJ'), ('imaging', 'VBG'), ('device', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('operating', 'VBG'), ('resolution', 'NN'), ('selected', 'VBN'), ('first', 'JJ'), ('resolution', 'NN'), ('smaller', 'JJR'), ('number', 'NN'), ('regular', 'JJ'), ('pixels', 'NNS'), ('second', 'JJ'), ('resolution', 'NN'), ('larger', 'JJR'), ('first', 'JJ'), ('resolution', 'NN'), ('imaging', 'VBG'), ('device', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('regular', 'JJ'), ('pixels', 'NNS'), ('turned', 'VBD'), ('autofocusing', 'VBG'), ('imaging', 'VBG'), ('device', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('number', 'NN'), ('phase', 'NN'), ('detection', 'NN'), ('pixel', 'NN'), ('pairs', 'VBZ'), ('smaller', 'JJR'), ('regular', 'JJ'), ('pixels', 'NNS'), ('imaging', 'VBG'), ('device', 'NN'), ('comprising', 'VBG'), ('condensing', 'VBG'), ('lens', 'JJ'), ('image', 'NN'), ('sensor', 'NN'), ('configured', 'VBD'), ('detect', 'JJ'), ('light', 'JJ'), ('passing', 'VBG'), ('condensing', 'VBG'), ('lens', 'NNS'), ('comprising', 'VBG'), ('pixel', 'NN'), ('matrix', 'NN'), ('wherein', 'NN'), ('pixel', 'NN'), ('matrix', 'NN'), ('comprises', 'VBZ'), ('plurality', 'NN'), ('phase', 'NN'), ('detection', 'NN'), ('pixel', 'NN'), ('pairs', 'NNS'), ('plurality', 'NN'), ('regular', 'JJ'), ('pixels', 'NNS'), ('processor', 'NN'), ('configured', 'VBD'), ('turn', 'JJ'), ('phase', 'JJ'), ('detection', 'NN'), ('pixel', 'NN'), ('pairs', 'NNS'), ('autofocusing', 'VBG'), ('output', 'NN'), ('autofocused', 'VBD'), ('pixel', 'JJ'), ('data', 'NNS'), ('completing', 'VBG'), ('autofocusing', 'VBG'), ('divide', 'NN'), ('autofocused', 'VBD'), ('pixel', 'NN'), ('data', 'NNS'), ('first', 'RB'), ('subframe', 'JJ'), ('second', 'JJ'), ('subframe', 'NN'), ('calculate', 'NN'), ('image', 'NN'), ('features', 'NNS'), ('least', 'VBP'), ('one', 'CD'), ('first', 'JJ'), ('subframe', 'JJ'), ('second', 'JJ'), ('subframe', 'NN'), ('wherein', 'NN'), ('image', 'NN'), ('features', 'NNS'), ('comprise', 'VBP'), ('module', 'JJ'), ('widths', 'NNS'), ('finder', 'VBP'), ('pattern', 'JJ'), ('finder', 'NN'), ('pattern', 'NN'), ('predetermined', 'VBN'), ('ratio', 'JJ'), ('harr-like', 'JJ'), ('feature', 'NN'), ('gabor', 'NN'), ('feature', 'NN'), ('select', 'JJ'), ('image', 'NN'), ('decoding', 'VBG'), ('image', 'NN'), ('recognition', 'NN'), ('using', 'VBG'), ('pixel', 'JJ'), ('data', 'NNS'), ('regular', 'JJ'), ('pixels', 'NNS'), ('according', 'VBG'), ('image', 'NN'), ('features', 'NNS'), ('calculated', 'VBD'), ('least', 'JJS'), ('one', 'CD'), ('first', 'JJ'), ('subframe', 'JJ'), ('second', 'JJ'), ('subframe', 'NN'), ('divided', 'VBD'), ('autofocused', 'JJ'), ('pixel', 'NN'), ('data', 'NNS'), ('imaging', 'VBG'), ('device', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('phase', 'NN'), ('detection', 'NN'), ('pixel', 'NN'), ('pairs', 'NN'), ('comprises', 'VBZ'), ('first', 'JJ'), ('pixel', 'JJ'), ('second', 'JJ'), ('pixel', 'NN'), ('cover', 'NN'), ('layer', 'NN'), ('covering', 'VBG'), ('upon', 'IN'), ('first', 'JJ'), ('region', 'NN'), ('first', 'RB'), ('pixel', 'VBZ'), ('upon', 'IN'), ('second', 'JJ'), ('region', 'NN'), ('second', 'JJ'), ('pixel', 'NN'), ('wherein', 'NN'), ('first', 'JJ'), ('region', 'NN'), ('second', 'JJ'), ('region', 'NN'), ('mirror', 'NN'), ('symmetrical', 'JJ'), ('microlens', 'NNS'), ('aligned', 'VBN'), ('least', 'JJS'), ('one', 'CD'), ('first', 'JJ'), ('pixel', 'JJ'), ('second', 'JJ'), ('pixel', 'NN'), ('imaging', 'VBG'), ('device', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('processor', 'NN'), ('configured', 'VBD'), ('perform', 'NN'), ('autofocusing', 'VBG'), ('using', 'VBG'), ('dual', 'JJ'), ('pixel', 'NN'), ('autofocus', 'NN'), ('technique', 'NN'), ('according', 'VBG'), ('pixel', 'NN'), ('data', 'NNS'), ('phase', 'NN'), ('detection', 'NN'), ('pixel', 'NN'), ('pairs', 'NNS'), ('completing', 'VBG'), ('autofocusing', 'VBG'), ('imaging', 'JJ'), ('device', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('processor', 'NN'), ('configured', 'VBD'), ('divide', 'JJ'), ('pixel', 'NN'), ('data', 'NNS'), ('phase', 'NN'), ('detection', 'NN'), ('pixel', 'NN'), ('pairs', 'NNS'), ('third', 'JJ'), ('subframe', 'JJ'), ('fourth', 'JJ'), ('subframe', 'NN'), ('completing', 'VBG'), ('autofocusing', 'VBG'), ('calibrate', 'JJ'), ('brightness', 'JJ'), ('third', 'JJ'), ('subframe', 'NN'), ('fourth', 'JJ'), ('subframe', 'JJ'), ('identical', 'JJ'), ('using', 'VBG'), ('shading', 'VBG'), ('algorithm', 'JJ'), ('perform', 'NN'), ('autofocusing', 'VBG'), ('according', 'VBG'), ('third', 'JJ'), ('subframe', 'JJ'), ('fourth', 'JJ'), ('subframe', 'NN'), ('imaging', 'VBG'), ('device', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('processor', 'NN'), ('configured', 'VBD'), ('calculate', 'JJ'), ('image', 'NN'), ('features', 'NNS'), ('using', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('rule', 'NN'), ('based', 'VBN'), ('algorithm', 'RB'), ('machine', 'NN'), ('learning', 'VBG'), ('algorithm', 'JJ'), ('imaging', 'VBG'), ('device', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('image', 'NN'), ('decoding', 'VBG'), ('decoding', 'VBG'), ('qr', 'NN'), ('codes', 'NNS'), ('image', 'NN'), ('recognition', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('operating', 'VBG'), ('method', 'NN'), ('imaging', 'VBG'), ('device', 'NN'), ('imaging', 'VBG'), ('device', 'NN'), ('comprising', 'VBG'), ('plurality', 'NN'), ('phase', 'NN'), ('detection', 'NN'), ('pixel', 'NN'), ('pairs', 'NNS'), ('plurality', 'NN'), ('regular', 'JJ'), ('pixels', 'NNS'), ('operating', 'VBG'), ('method', 'NN'), ('comprising', 'VBG'), ('turning', 'VBG'), ('phase', 'NN'), ('detection', 'NN'), ('pixel', 'NN'), ('pairs', 'NNS'), ('autofocusing', 'VBG'), ('outputting', 'VBG'), ('autofocused', 'VBN'), ('image', 'NN'), ('frame', 'NN'), ('completing', 'VBG'), ('autofocusing', 'VBG'), ('dividing', 'VBG'), ('autofocused', 'VBN'), ('image', 'NN'), ('frame', 'NN'), ('acquired', 'VBD'), ('phase', 'JJ'), ('detection', 'NN'), ('pixel', 'NN'), ('pairs', 'NNS'), ('first', 'RB'), ('subframe', 'JJ'), ('second', 'JJ'), ('subframe', 'NN'), ('calculating', 'VBG'), ('image', 'NN'), ('features', 'NNS'), ('least', 'VBP'), ('one', 'CD'), ('first', 'JJ'), ('subframe', 'JJ'), ('second', 'JJ'), ('subframe', 'NN'), ('wherein', 'JJ'), ('image', 'NN'), ('feature', 'NN'), ('comprise', 'NN'), ('module', 'NN'), ('widths', 'NNS'), ('finder', 'VBP'), ('pattern', 'JJ'), ('finder', 'NN'), ('pattern', 'NN'), ('predetermined', 'VBN'), ('ratio', 'JJ'), ('harr-like', 'JJ'), ('feature', 'NN'), ('gabor', 'NN'), ('feature', 'NN'), ('selectively', 'RB'), ('activating', 'VBG'), ('least', 'JJS'), ('part', 'NN'), ('regular', 'JJ'), ('pixels', 'NNS'), ('according', 'VBG'), ('image', 'NN'), ('features', 'NNS'), ('calculated', 'VBD'), ('least', 'JJS'), ('one', 'CD'), ('first', 'JJ'), ('subframe', 'JJ'), ('second', 'JJ'), ('subframe', 'NN'), ('divided', 'VBD'), ('autofocused', 'JJ'), ('image', 'NN'), ('frame', 'NN'), ('operating', 'VBG'), ('method', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('selectively', 'RB'), ('activating', 'VBG'), ('comprises', 'NNS'), ('activating', 'VBG'), ('first', 'JJ'), ('part', 'NN'), ('regular', 'JJ'), ('pixels', 'NNS'), ('perform', 'VBP'), ('image', 'NN'), ('decoding', 'VBG'), ('according', 'VBG'), ('pixel', 'NN'), ('data', 'NNS'), ('first', 'JJ'), ('part', 'NN'), ('regular', 'JJ'), ('pixels', 'NNS'), ('activating', 'VBG'), ('regular', 'JJ'), ('pixels', 'NNS'), ('perform', 'VBP'), ('image', 'NN'), ('recognition', 'NN'), ('according', 'VBG'), ('pixel', 'NN'), ('data', 'NNS'), ('regular', 'JJ'), ('pixels', 'NNS'), ('operating', 'VBG'), ('method', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('pixel', 'NN'), ('data', 'NNS'), ('phase', 'NN'), ('detection', 'NN'), ('pixel', 'NN'), ('pairs', 'NNS'), ('captured', 'VBD'), ('frame', 'JJ'), ('pixel', 'NN'), ('data', 'NNS'), ('regular', 'JJ'), ('pixels', 'NNS'), ('also', 'RB'), ('used', 'VBD'), ('performing', 'VBG'), ('image', 'NN'), ('decoding', 'VBG'), ('image', 'NN'), ('recognition', 'NN'), ('operating', 'VBG'), ('method', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('image', 'NN'), ('decoding', 'VBG'), ('decoding', 'VBG'), ('qr', 'NN'), ('codes', 'NNS'), ('image', 'NN'), ('recognition', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('operating', 'VBG'), ('method', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('phase', 'NN'), ('detection', 'NN'), ('pixel', 'NN'), ('pairs', 'NNS'), ('partially', 'RB'), ('covered', 'VBD'), ('pixels', 'NNS'), ('structure', 'NN'), ('dual', 'JJ'), ('pixel', 'NN'), ('apparatus', 'NN'), ('comprising', 'VBG'), ('first', 'JJ'), ('camera', 'NN'), ('module', 'NN'), ('configured', 'VBD'), ('obtain', 'VB'), ('first', 'JJ'), ('image', 'NN'), ('object', 'VBP'), ('first', 'JJ'), ('field', 'NN'), ('view', 'NN'), ('second', 'JJ'), ('camera', 'NN'), ('module', 'NN'), ('configured', 'VBD'), ('obtain', 'VB'), ('second', 'JJ'), ('image', 'NN'), ('object', 'JJ'), ('second', 'JJ'), ('field', 'NN'), ('view', 'NN'), ('different', 'JJ'), ('first', 'JJ'), ('field', 'NN'), ('view', 'NN'), ('first', 'RB'), ('depth', 'VBZ'), ('map', 'NN'), ('generator', 'NN'), ('configured', 'VBD'), ('generate', 'NN'), ('first', 'RB'), ('depth', 'VBZ'), ('map', 'NN'), ('first', 'RB'), ('image', 'NN'), ('based', 'VBN'), ('first', 'JJ'), ('image', 'NN'), ('second', 'JJ'), ('image', 'NN'), ('second', 'JJ'), ('depth', 'NN'), ('map', 'NN'), ('generator', 'NN'), ('configured', 'VBD'), ('generate', 'JJ'), ('second', 'JJ'), ('depth', 'NN'), ('map', 'NN'), ('second', 'JJ'), ('image', 'NN'), ('based', 'VBN'), ('first', 'JJ'), ('image', 'NN'), ('second', 'JJ'), ('image', 'NN'), ('first', 'RB'), ('depth', 'VBZ'), ('map', 'JJ'), ('apparatus', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('first', 'JJ'), ('field', 'NN'), ('view', 'NN'), ('narrow', 'JJ'), ('angle', 'JJ'), ('second', 'JJ'), ('field', 'NN'), ('view', 'NN'), ('wider', 'VBP'), ('angle', 'NN'), ('apparatus', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('second', 'JJ'), ('image', 'NN'), ('divided', 'VBD'), ('primary', 'JJ'), ('region', 'NN'), ('residual', 'JJ'), ('region', 'NN'), ('second', 'JJ'), ('depth', 'NN'), ('map', 'NN'), ('generator', 'NN'), ('comprises', 'VBZ'), ('relationship', 'NN'), ('estimating', 'VBG'), ('module', 'NN'), ('configured', 'VBD'), ('estimate', 'NN'), ('relationship', 'NN'), ('primary', 'JJ'), ('region', 'NN'), ('residual', 'JJ'), ('region', 'NN'), ('based', 'VBN'), ('first', 'JJ'), ('image', 'NN'), ('second', 'JJ'), ('image', 'NN'), ('depth', 'NN'), ('map', 'NN'), ('estimating', 'VBG'), ('module', 'NN'), ('configured', 'VBD'), ('estimate', 'NN'), ('depth', 'NN'), ('map', 'VBP'), ('residual', 'JJ'), ('region', 'NN'), ('based', 'VBN'), ('estimated', 'VBN'), ('relationship', 'NN'), ('first', 'JJ'), ('depth', 'NN'), ('map', 'NN'), ('apparatus', 'NN'), ('claim', 'NN'), ('wherein', 'VBD'), ('least', 'JJS'), ('one', 'CD'), ('relationship', 'NN'), ('estimating', 'VBG'), ('module', 'NN'), ('depth', 'NN'), ('map', 'NN'), ('estimating', 'VBG'), ('module', 'NN'), ('performs', 'NNS'), ('estimating', 'VBG'), ('operation', 'NN'), ('based', 'VBN'), ('neural', 'JJ'), ('network', 'NN'), ('module', 'NN'), ('apparatus', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('depth', 'NN'), ('map', 'FW'), ('fusion', 'NN'), ('unit', 'NN'), ('configured', 'VBD'), ('generate', 'JJ'), ('third', 'JJ'), ('depth', 'NN'), ('map', 'NN'), ('second', 'JJ'), ('image', 'NN'), ('performing', 'VBG'), ('fusion', 'NN'), ('operation', 'NN'), ('based', 'VBN'), ('first', 'RB'), ('depth', 'JJ'), ('map', 'JJ'), ('second', 'JJ'), ('depth', 'NN'), ('map', 'NN'), ('apparatus', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('depth', 'NN'), ('map', 'JJ'), ('fusion', 'NN'), ('unit', 'NN'), ('comprises', 'VBZ'), ('tone', 'CD'), ('mapping', 'NN'), ('module', 'NN'), ('configured', 'VBD'), ('generate', 'JJ'), ('tone-mapped', 'JJ'), ('second', 'JJ'), ('depth', 'NN'), ('map', 'NN'), ('correspond', 'NN'), ('first', 'RB'), ('depth', 'VBZ'), ('map', 'NN'), ('performing', 'VBG'), ('bias', 'JJ'), ('removing', 'VBG'), ('operation', 'NN'), ('second', 'JJ'), ('depth', 'NN'), ('map', 'NN'), ('fusion', 'NN'), ('module', 'NN'), ('configured', 'VBD'), ('generate', 'JJ'), ('third', 'JJ'), ('depth', 'NN'), ('map', 'NN'), ('fusing', 'VBG'), ('tone-mapped', 'JJ'), ('second', 'JJ'), ('depth', 'NN'), ('map', 'NN'), ('first', 'RB'), ('depth', 'VBZ'), ('map', 'JJ'), ('apparatus', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('depth', 'NN'), ('map', 'JJ'), ('fusion', 'NN'), ('unit', 'NN'), ('comprises', 'VBZ'), ('propagating', 'VBG'), ('module', 'NN'), ('configured', 'VBD'), ('generate', 'NN'), ('propagated', 'VBN'), ('first', 'JJ'), ('depth', 'NN'), ('map', 'NN'), ('second', 'JJ'), ('image', 'NN'), ('iterated', 'VBD'), ('propagating', 'VBG'), ('first', 'JJ'), ('depth', 'NN'), ('map', 'NN'), ('based', 'VBN'), ('first', 'RB'), ('depth', 'JJ'), ('map', 'NN'), ('second', 'JJ'), ('image', 'NN'), ('fusion', 'NN'), ('module', 'NN'), ('generates', 'VBZ'), ('third', 'JJ'), ('depth', 'NN'), ('map', 'NN'), ('fusing', 'VBG'), ('tone-mapped', 'JJ'), ('second', 'JJ'), ('depth', 'NN'), ('map', 'NN'), ('propagated', 'VBD'), ('first', 'JJ'), ('depth', 'NN'), ('map', 'NN'), ('apparatus', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('depth', 'NN'), ('map', 'JJ'), ('fusion', 'NN'), ('unit', 'NN'), ('comprises', 'VBZ'), ('post-processing', 'JJ'), ('module', 'NN'), ('configured', 'VBD'), ('perform', 'JJ'), ('post-processing', 'JJ'), ('operation', 'NN'), ('third', 'JJ'), ('depth', 'NN'), ('map', 'NN'), ('generated', 'VBD'), ('fusion', 'NN'), ('module', 'NN'), ('provide', 'IN'), ('post-processed', 'JJ'), ('third', 'JJ'), ('depth', 'NN'), ('map', 'NN'), ('apparatus', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('post-processing', 'JJ'), ('module', 'NN'), ('performs', 'NNS'), ('post-processing', 'JJ'), ('operation', 'NN'), ('filtering', 'VBG'), ('interface', 'NN'), ('generated', 'VBD'), ('third', 'JJ'), ('depth', 'JJ'), ('map', 'NN'), ('accordance', 'NN'), ('fusion', 'NN'), ('fusion', 'NN'), ('module', 'NN'), ('apparatus', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('post-processing', 'JJ'), ('module', 'NN'), ('removes', 'VBZ'), ('artifacts', 'NNS'), ('generated', 'VBD'), ('third', 'JJ'), ('depth', 'JJ'), ('map', 'NN'), ('accordance', 'NN'), ('fusion', 'NN'), ('fusion', 'NN'), ('module', 'NN'), ('apparatus', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('first', 'JJ'), ('depth', 'NN'), ('map', 'NN'), ('generator', 'NN'), ('analyses', 'VBZ'), ('distance', 'NN'), ('relationship', 'NN'), ('first', 'JJ'), ('image', 'NN'), ('second', 'JJ'), ('image', 'NN'), ('generates', 'NNS'), ('first', 'RB'), ('depth', 'VB'), ('map', 'NN'), ('first', 'RB'), ('image', 'NN'), ('based', 'VBN'), ('distance', 'NN'), ('relationship', 'NN'), ('method', 'NN'), ('processing', 'NN'), ('image', 'NN'), ('electronic', 'JJ'), ('apparatus', 'NN'), ('method', 'NN'), ('comprising', 'VBG'), ('obtaining', 'VBG'), ('first', 'JJ'), ('image', 'NN'), ('object', 'NN'), ('using', 'VBG'), ('first', 'JJ'), ('camera', 'NN'), ('module', 'NN'), ('obtaining', 'VBG'), ('second', 'JJ'), ('image', 'NN'), ('object', 'NN'), ('using', 'VBG'), ('second', 'JJ'), ('camera', 'NN'), ('module', 'NN'), ('generating', 'VBG'), ('first', 'JJ'), ('depth', 'NN'), ('map', 'NN'), ('first', 'RB'), ('image', 'NN'), ('based', 'VBN'), ('first', 'JJ'), ('image', 'NN'), ('second', 'JJ'), ('image', 'NN'), ('estimating', 'VBG'), ('relationship', 'NN'), ('primary', 'JJ'), ('region', 'NN'), ('second', 'JJ'), ('image', 'NN'), ('residual', 'JJ'), ('region', 'NN'), ('second', 'JJ'), ('image', 'NN'), ('based', 'VBN'), ('first', 'JJ'), ('image', 'NN'), ('second', 'JJ'), ('image', 'NN'), ('generating', 'VBG'), ('second', 'JJ'), ('depth', 'NN'), ('map', 'NN'), ('second', 'JJ'), ('image', 'NN'), ('based', 'VBN'), ('estimated', 'VBN'), ('relationship', 'NN'), ('primary', 'JJ'), ('region', 'NN'), ('residual', 'JJ'), ('region', 'NN'), ('first', 'RB'), ('depth', 'VBZ'), ('map', 'JJ'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'VBZ'), ('electronic', 'JJ'), ('apparatus', 'NN'), ('comprises', 'NNS'), ('first', 'RB'), ('camera', 'VBP'), ('module', 'NN'), ('including', 'VBG'), ('first', 'JJ'), ('lens', 'NNS'), ('first', 'JJ'), ('field', 'NN'), ('view', 'NN'), ('second', 'JJ'), ('camera', 'NN'), ('module', 'NN'), ('including', 'VBG'), ('second', 'JJ'), ('lens', 'JJ'), ('second', 'JJ'), ('field', 'NN'), ('view', 'NN'), ('wider', 'VBP'), ('first', 'JJ'), ('field', 'NN'), ('view', 'NN'), ('method', 'VBP'), ('claim', 'NN'), ('wherein', 'NN'), ('generating', 'VBG'), ('second', 'JJ'), ('depth', 'NN'), ('map', 'NN'), ('comprises', 'VBZ'), ('estimating', 'VBG'), ('depth', 'NN'), ('map', 'FW'), ('residual', 'JJ'), ('region', 'NN'), ('based', 'VBN'), ('estimated', 'VBN'), ('relationship', 'NN'), ('primary', 'JJ'), ('region', 'NN'), ('residual', 'JJ'), ('region', 'NN'), ('first', 'RB'), ('depth', 'VBZ'), ('map', 'JJ'), ('generating', 'VBG'), ('second', 'JJ'), ('depth', 'NN'), ('map', 'NNS'), ('based', 'VBN'), ('depth', 'JJ'), ('map', 'JJ'), ('residual', 'JJ'), ('region', 'NN'), ('first', 'RB'), ('depth', 'VBZ'), ('map', 'JJ'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('estimating', 'VBG'), ('relationship', 'NN'), ('primary', 'JJ'), ('region', 'NN'), ('second', 'JJ'), ('image', 'NN'), ('performed', 'VBD'), ('using', 'VBG'), ('neural', 'JJ'), ('network', 'NN'), ('model', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('performing', 'VBG'), ('pre-processing', 'JJ'), ('operation', 'NN'), ('second', 'JJ'), ('depth', 'NN'), ('map', 'NN'), ('generating', 'VBG'), ('third', 'JJ'), ('depth', 'NN'), ('map', 'NN'), ('residual', 'JJ'), ('image', 'NN'), ('fusing', 'VBG'), ('second', 'JJ'), ('depth', 'JJ'), ('map', 'NN'), ('pre-processing', 'JJ'), ('operation', 'NN'), ('performed', 'VBD'), ('first', 'JJ'), ('depth', 'NN'), ('map', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('performing', 'VBG'), ('pre-processing', 'JJ'), ('operation', 'NN'), ('comprises', 'NNS'), ('performing', 'VBG'), ('tone', 'NN'), ('mapping', 'NN'), ('operation', 'NN'), ('depth', 'NN'), ('map', 'NN'), ('primary', 'JJ'), ('region', 'NN'), ('depth', 'NN'), ('map', 'VBP'), ('residual', 'JJ'), ('region', 'NN'), ('based', 'VBN'), ('second', 'JJ'), ('depth', 'NN'), ('map', 'NN'), ('operating', 'VBG'), ('method', 'NN'), ('electronic', 'JJ'), ('apparatus', 'NN'), ('electronic', 'JJ'), ('apparatus', 'NN'), ('including', 'VBG'), ('first', 'JJ'), ('camera', 'NN'), ('module', 'NN'), ('providing', 'VBG'), ('first', 'JJ'), ('image', 'NN'), ('object', 'NN'), ('using', 'VBG'), ('first', 'JJ'), ('field', 'NN'), ('view', 'NN'), ('second', 'JJ'), ('camera', 'NN'), ('module', 'NN'), ('providing', 'VBG'), ('second', 'JJ'), ('image', 'NN'), ('object', 'NN'), ('using', 'VBG'), ('second', 'JJ'), ('field', 'NN'), ('view', 'NN'), ('wider', 'VBP'), ('first', 'JJ'), ('field', 'NN'), ('view', 'NN'), ('processor', 'NN'), ('generating', 'VBG'), ('depth', 'JJ'), ('map', 'JJ'), ('second', 'JJ'), ('image', 'NN'), ('based', 'VBN'), ('primary', 'JJ'), ('region', 'NN'), ('second', 'JJ'), ('image', 'NN'), ('residual', 'JJ'), ('region', 'NN'), ('second', 'JJ'), ('image', 'NN'), ('operating', 'VBG'), ('method', 'NN'), ('comprising', 'VBG'), ('generating', 'VBG'), ('first', 'JJ'), ('depth', 'NN'), ('map', 'NN'), ('primary', 'JJ'), ('region', 'NN'), ('estimating', 'VBG'), ('relationship', 'NN'), ('first', 'JJ'), ('image', 'NN'), ('second', 'JJ'), ('image', 'NN'), ('estimating', 'VBG'), ('relationship', 'NN'), ('primary', 'JJ'), ('region', 'NN'), ('residual', 'JJ'), ('region', 'NN'), ('based', 'VBN'), ('first', 'JJ'), ('image', 'NN'), ('second', 'JJ'), ('image', 'NN'), ('generating', 'VBG'), ('second', 'JJ'), ('depth', 'NN'), ('map', 'NN'), ('second', 'JJ'), ('image', 'NN'), ('estimating', 'VBG'), ('depth', 'JJ'), ('map', 'JJ'), ('second', 'JJ'), ('region', 'NN'), ('based', 'VBN'), ('estimated', 'VBN'), ('relationship', 'NN'), ('primary', 'JJ'), ('region', 'NN'), ('residual', 'JJ'), ('region', 'NN'), ('generating', 'VBG'), ('depth', 'JJ'), ('map', 'JJ'), ('second', 'JJ'), ('image', 'NN'), ('fusing', 'VBG'), ('first', 'JJ'), ('depth', 'NN'), ('map', 'NN'), ('second', 'JJ'), ('depth', 'NN'), ('map', 'NN'), ('operation', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('executing', 'VBG'), ('application', 'NN'), ('applies', 'NNS'), ('image', 'NN'), ('effect', 'NN'), ('second', 'JJ'), ('image', 'NN'), ('based', 'VBN'), ('depth', 'JJ'), ('map', 'NN'), ('residual', 'JJ'), ('image', 'NN'), ('operation', 'NN'), ('method', 'FW'), ('claim', 'NN'), ('wherein', 'WRB'), ('application', 'NN'), ('applies', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('image', 'NN'), ('effect', 'NN'), ('auto-focusing', 'JJ'), ('out-focusing', 'JJ'), ('forebackground', 'NN'), ('separation', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('object', 'JJ'), ('detection', 'NN'), ('within', 'IN'), ('frame', 'NN'), ('augmented', 'JJ'), ('reality', 'NN'), ('second', 'JJ'), ('image', 'NN'), ('based', 'VBN'), ('depth', 'JJ'), ('map', 'JJ'), ('second', 'JJ'), ('image', 'NN'), ('payment', 'NN'), ('method', 'NN'), ('based', 'VBN'), ('face', 'NN'), ('recognition', 'NN'), ('comprising', 'VBG'), ('acquiring', 'VBG'), ('first', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('information', 'NN'), ('target', 'NN'), ('user', 'NN'), ('extracting', 'VBG'), ('first', 'JJ'), ('characteristic', 'JJ'), ('information', 'NN'), ('first', 'RB'), ('face', 'NN'), ('image', 'NN'), ('information', 'NN'), ('wherein', 'IN'), ('first', 'JJ'), ('characteristic', 'JJ'), ('information', 'NN'), ('includes', 'VBZ'), ('head', 'NN'), ('posture', 'NN'), ('information', 'NN'), ('target', 'NN'), ('user', 'NN'), ('gaze', 'NN'), ('information', 'NN'), ('target', 'NN'), ('user', 'NN'), ('determining', 'VBG'), ('whether', 'IN'), ('target', 'NN'), ('user', 'JJ'), ('willingness', 'NN'), ('pay', 'NN'), ('according', 'VBG'), ('head', 'NN'), ('posture', 'NN'), ('information', 'NN'), ('target', 'NN'), ('user', 'NN'), ('gaze', 'NN'), ('information', 'NN'), ('target', 'NN'), ('user', 'NN'), ('including', 'VBG'), ('determining', 'VBG'), ('whether', 'IN'), ('angle', 'JJ'), ('rotation', 'NN'), ('preset', 'VBN'), ('direction', 'NN'), ('less', 'RBR'), ('angle', 'JJ'), ('threshold', 'NN'), ('wherein', 'NN'), ('head', 'NN'), ('posture', 'NN'), ('information', 'NN'), ('includes', 'VBZ'), ('angle', 'JJ'), ('rotation', 'NN'), ('preset', 'VBN'), ('direction', 'NN'), ('determining', 'VBG'), ('whether', 'IN'), ('probability', 'NN'), ('value', 'NN'), ('user', 'NN'), ('gazes', 'JJ'), ('payment', 'NN'), ('screen', 'NN'), ('greater', 'JJR'), ('probability', 'NN'), ('threshold', 'NN'), ('wherein', 'NN'), ('gaze', 'JJ'), ('information', 'NN'), ('includes', 'VBZ'), ('probability', 'NN'), ('value', 'NN'), ('user', 'NN'), ('gazes', 'JJ'), ('payment', 'NN'), ('screen', 'NN'), ('response', 'NN'), ('determining', 'VBG'), ('angle', 'JJ'), ('rotation', 'NN'), ('preset', 'VBN'), ('direction', 'NN'), ('less', 'RBR'), ('angle', 'JJ'), ('threshold', 'NN'), ('probability', 'NN'), ('value', 'NN'), ('user', 'NN'), ('gazes', 'JJ'), ('payment', 'NN'), ('screen', 'NN'), ('greater', 'JJR'), ('probability', 'NN'), ('threshold', 'VBD'), ('determining', 'VBG'), ('target', 'NN'), ('user', 'JJ'), ('willingness', 'NN'), ('pay', 'NN'), ('response', 'NN'), ('determining', 'VBG'), ('target', 'NN'), ('user', 'JJ'), ('willingness', 'NN'), ('pay', 'NN'), ('completing', 'VBG'), ('payment', 'NN'), ('operation', 'NN'), ('based', 'VBN'), ('face', 'NN'), ('recognition', 'NN'), ('method', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('completing', 'VBG'), ('payment', 'NN'), ('operation', 'NN'), ('based', 'VBN'), ('face', 'NN'), ('recognition', 'NN'), ('comprises', 'VBZ'), ('triggering', 'VBG'), ('performing', 'VBG'), ('payment', 'NN'), ('initiating', 'NN'), ('operation', 'NN'), ('acquire', 'VB'), ('second', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('information', 'NN'), ('based', 'VBN'), ('face', 'NN'), ('recognition', 'NN'), ('determining', 'VBG'), ('whether', 'IN'), ('second', 'JJ'), ('characteristic', 'JJ'), ('information', 'NN'), ('extracted', 'VBD'), ('second', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('information', 'NN'), ('indicates', 'VBZ'), ('user', 'JJ'), ('willingness', 'NN'), ('pay', 'NN'), ('response', 'NN'), ('determining', 'VBG'), ('second', 'JJ'), ('characteristic', 'JJ'), ('information', 'NN'), ('indicates', 'VBZ'), ('user', 'JJ'), ('willingness', 'NN'), ('pay', 'NN'), ('triggering', 'VBG'), ('performing', 'VBG'), ('payment', 'NN'), ('confirmation', 'NN'), ('operation', 'NN'), ('complete', 'JJ'), ('payment', 'NN'), ('operation', 'NN'), ('based', 'VBN'), ('payment', 'NN'), ('account', 'NN'), ('information', 'NN'), ('corresponding', 'VBG'), ('target', 'NN'), ('user', 'JJ'), ('method', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('determining', 'VBG'), ('whether', 'IN'), ('second', 'JJ'), ('characteristic', 'JJ'), ('information', 'NN'), ('extracted', 'VBD'), ('second', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('information', 'NN'), ('indicates', 'VBZ'), ('user', 'JJ'), ('willingness', 'NN'), ('pay', 'NN'), ('comprises', 'VBZ'), ('determining', 'VBG'), ('whether', 'IN'), ('current', 'JJ'), ('user', 'NN'), ('corresponding', 'VBG'), ('second', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('information', 'NN'), ('consistent', 'JJ'), ('target', 'NN'), ('user', 'JJ'), ('response', 'NN'), ('determining', 'VBG'), ('current', 'JJ'), ('user', 'JJ'), ('consistent', 'NN'), ('target', 'NN'), ('user', 'IN'), ('determining', 'VBG'), ('whether', 'IN'), ('target', 'NN'), ('user', 'JJ'), ('willingness', 'NN'), ('pay', 'NN'), ('according', 'VBG'), ('second', 'JJ'), ('characteristic', 'JJ'), ('information', 'NN'), ('extracted', 'VBD'), ('second', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('information', 'NN'), ('method', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('extracting', 'VBG'), ('first', 'JJ'), ('characteristic', 'JJ'), ('information', 'NN'), ('first', 'RB'), ('face', 'NN'), ('image', 'NN'), ('information', 'NN'), ('comprises', 'VBZ'), ('determining', 'VBG'), ('head', 'NN'), ('posture', 'NN'), ('information', 'NN'), ('target', 'NN'), ('user', 'NN'), ('using', 'VBG'), ('head', 'NN'), ('posture', 'NN'), ('recognition', 'NN'), ('model', 'NN'), ('based', 'VBN'), ('first', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('information', 'NN'), ('determining', 'VBG'), ('gaze', 'NN'), ('information', 'NN'), ('target', 'NN'), ('user', 'NN'), ('using', 'VBG'), ('gaze', 'JJ'), ('information', 'NN'), ('recognition', 'NN'), ('model', 'NN'), ('based', 'VBN'), ('characteristics', 'NNS'), ('eye', 'NN'), ('region', 'NN'), ('first', 'RB'), ('face', 'JJ'), ('image', 'NN'), ('information', 'NN'), ('method', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('head', 'NN'), ('posture', 'NN'), ('recognition', 'NN'), ('model', 'NN'), ('obtained', 'VBD'), ('training', 'VBG'), ('acquiring', 'VBG'), ('first', 'JJ'), ('sample', 'NN'), ('data', 'NNS'), ('set', 'VBD'), ('wherein', 'NN'), ('first', 'JJ'), ('sample', 'NN'), ('data', 'NNS'), ('set', 'VBD'), ('includes', 'VBZ'), ('plurality', 'NN'), ('pieces', 'NNS'), ('first', 'RB'), ('sample', 'JJ'), ('data', 'NNS'), ('plurality', 'NN'), ('pieces', 'NNS'), ('first', 'RB'), ('sample', 'JJ'), ('data', 'NNS'), ('includes', 'VBZ'), ('correspondence', 'NN'), ('sample', 'NN'), ('face', 'NN'), ('image', 'NN'), ('head', 'NN'), ('posture', 'NN'), ('information', 'NN'), ('determining', 'VBG'), ('mean', 'JJ'), ('image', 'NN'), ('data', 'NNS'), ('variance', 'NN'), ('image', 'NN'), ('data', 'NNS'), ('plurality', 'NN'), ('sample', 'NN'), ('face', 'NN'), ('images', 'VBZ'), ('plurality', 'NN'), ('pieces', 'NNS'), ('first', 'RB'), ('sample', 'JJ'), ('data', 'NNS'), ('preprocessing', 'VBG'), ('sample', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('contained', 'VBD'), ('plurality', 'NN'), ('pieces', 'NNS'), ('first', 'RB'), ('sample', 'VB'), ('data', 'NNS'), ('based', 'VBN'), ('mean', 'JJ'), ('image', 'NN'), ('data', 'NNS'), ('variance', 'NN'), ('image', 'NN'), ('data', 'NNS'), ('obtain', 'VB'), ('preprocessed', 'JJ'), ('sample', 'NN'), ('face', 'NN'), ('image', 'NN'), ('setting', 'VBG'), ('preprocessed', 'JJ'), ('sample', 'NN'), ('face', 'NN'), ('image', 'NN'), ('corresponding', 'VBG'), ('head', 'JJ'), ('posture', 'NN'), ('information', 'NN'), ('first', 'RB'), ('model', 'VBZ'), ('training', 'VBG'), ('sample', 'JJ'), ('performing', 'VBG'), ('training', 'NN'), ('using', 'VBG'), ('machine', 'NN'), ('learning', 'VBG'), ('method', 'NNS'), ('based', 'VBN'), ('plurality', 'NN'), ('first', 'JJ'), ('model', 'NN'), ('training', 'NN'), ('samples', 'NNS'), ('obtain', 'VB'), ('head', 'JJ'), ('posture', 'NN'), ('recognition', 'NN'), ('model', 'NN'), ('method', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('gaze', 'NN'), ('information', 'NN'), ('recognition', 'NN'), ('model', 'NN'), ('obtained', 'VBD'), ('training', 'VBG'), ('acquiring', 'VBG'), ('second', 'JJ'), ('sample', 'NN'), ('data', 'NNS'), ('set', 'VBD'), ('wherein', 'JJ'), ('second', 'JJ'), ('sample', 'NN'), ('data', 'NNS'), ('set', 'VBD'), ('includes', 'VBZ'), ('plurality', 'NN'), ('pieces', 'NNS'), ('second', 'JJ'), ('sample', 'NN'), ('data', 'NNS'), ('plurality', 'NN'), ('pieces', 'NNS'), ('second', 'JJ'), ('sample', 'JJ'), ('data', 'NNS'), ('includes', 'VBZ'), ('correspondence', 'NN'), ('sample', 'NN'), ('eye', 'NN'), ('image', 'NN'), ('gaze', 'JJ'), ('information', 'NN'), ('determining', 'VBG'), ('mean', 'JJ'), ('image', 'NN'), ('data', 'NNS'), ('variance', 'NN'), ('image', 'NN'), ('data', 'NNS'), ('plurality', 'NN'), ('sample', 'NN'), ('eye', 'NN'), ('images', 'VBZ'), ('plurality', 'NN'), ('pieces', 'NNS'), ('second', 'JJ'), ('sample', 'NN'), ('data', 'NNS'), ('preprocessing', 'VBG'), ('sample', 'NN'), ('eye', 'NN'), ('image', 'NN'), ('contained', 'VBD'), ('plurality', 'NN'), ('pieces', 'NNS'), ('second', 'JJ'), ('sample', 'NN'), ('data', 'NNS'), ('based', 'VBN'), ('mean', 'JJ'), ('image', 'NN'), ('data', 'NNS'), ('variance', 'NN'), ('image', 'NN'), ('data', 'NNS'), ('obtain', 'VB'), ('preprocessed', 'JJ'), ('sample', 'NN'), ('eye', 'NN'), ('image', 'NN'), ('setting', 'VBG'), ('preprocessed', 'JJ'), ('sample', 'NN'), ('eye', 'NN'), ('image', 'NN'), ('corresponding', 'VBG'), ('gaze', 'JJ'), ('information', 'NN'), ('second', 'JJ'), ('model', 'NN'), ('training', 'VBG'), ('sample', 'JJ'), ('performing', 'VBG'), ('training', 'NN'), ('using', 'VBG'), ('machine', 'NN'), ('learning', 'VBG'), ('method', 'NNS'), ('based', 'VBN'), ('plurality', 'NN'), ('second', 'JJ'), ('model', 'NN'), ('training', 'NN'), ('samples', 'NNS'), ('obtain', 'VB'), ('gaze', 'JJ'), ('information', 'NN'), ('recognition', 'NN'), ('model', 'NN'), ('method', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('angle', 'VBZ'), ('rotation', 'NN'), ('preset', 'VBN'), ('direction', 'NN'), ('comprises', 'VBZ'), ('pitch', 'VBP'), ('angle', 'NN'), ('yaw', 'NN'), ('angle', 'NN'), ('roll', 'NN'), ('angle', 'NN'), ('wherein', 'NN'), ('pitch', 'NN'), ('angle', 'NN'), ('refers', 'NNS'), ('angle', 'VBP'), ('rotation', 'NN'), ('around', 'IN'), ('x-axis', 'JJ'), ('yaw', 'NN'), ('angle', 'NN'), ('refers', 'NNS'), ('angle', 'VBP'), ('rotation', 'NN'), ('around', 'IN'), ('y-axis', 'JJ'), ('roll', 'NN'), ('angle', 'NN'), ('refers', 'NNS'), ('angle', 'VBP'), ('rotation', 'NN'), ('around', 'IN'), ('z-axis', 'JJ'), ('payment', 'NN'), ('device', 'NN'), ('based', 'VBN'), ('face', 'NN'), ('recognition', 'NN'), ('comprising', 'VBG'), ('processor', 'JJ'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('storage', 'NN'), ('medium', 'NN'), ('storing', 'VBG'), ('instructions', 'NNS'), ('executable', 'JJ'), ('processor', 'NN'), ('cause', 'NN'), ('device', 'NN'), ('perform', 'NN'), ('operations', 'NNS'), ('comprising', 'VBG'), ('acquiring', 'VBG'), ('first', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('information', 'NN'), ('target', 'NN'), ('user', 'NN'), ('extracting', 'VBG'), ('first', 'JJ'), ('characteristic', 'JJ'), ('information', 'NN'), ('first', 'RB'), ('face', 'NN'), ('image', 'NN'), ('information', 'NN'), ('wherein', 'IN'), ('first', 'JJ'), ('characteristic', 'JJ'), ('information', 'NN'), ('includes', 'VBZ'), ('head', 'NN'), ('posture', 'NN'), ('information', 'NN'), ('target', 'NN'), ('user', 'NN'), ('gaze', 'NN'), ('information', 'NN'), ('target', 'NN'), ('user', 'NN'), ('determining', 'VBG'), ('whether', 'IN'), ('target', 'NN'), ('user', 'JJ'), ('willingness', 'NN'), ('pay', 'NN'), ('according', 'VBG'), ('head', 'NN'), ('posture', 'NN'), ('information', 'NN'), ('target', 'NN'), ('user', 'NN'), ('gaze', 'NN'), ('information', 'NN'), ('target', 'NN'), ('user', 'NN'), ('including', 'VBG'), ('determining', 'VBG'), ('whether', 'IN'), ('angle', 'JJ'), ('rotation', 'NN'), ('preset', 'VBN'), ('direction', 'NN'), ('less', 'RBR'), ('angle', 'JJ'), ('threshold', 'NN'), ('wherein', 'NN'), ('head', 'NN'), ('posture', 'NN'), ('information', 'NN'), ('includes', 'VBZ'), ('angle', 'JJ'), ('rotation', 'NN'), ('preset', 'VBN'), ('direction', 'NN'), ('determining', 'VBG'), ('whether', 'IN'), ('probability', 'NN'), ('value', 'NN'), ('user', 'NN'), ('gazes', 'JJ'), ('payment', 'NN'), ('screen', 'NN'), ('greater', 'JJR'), ('probability', 'NN'), ('threshold', 'NN'), ('wherein', 'NN'), ('gaze', 'JJ'), ('information', 'NN'), ('includes', 'VBZ'), ('probability', 'NN'), ('value', 'NN'), ('user', 'NN'), ('gazes', 'JJ'), ('payment', 'NN'), ('screen', 'NN'), ('response', 'NN'), ('determining', 'VBG'), ('angle', 'JJ'), ('rotation', 'NN'), ('preset', 'VBN'), ('direction', 'NN'), ('less', 'RBR'), ('angle', 'JJ'), ('threshold', 'NN'), ('probability', 'NN'), ('value', 'NN'), ('user', 'NN'), ('gazes', 'JJ'), ('payment', 'NN'), ('screen', 'NN'), ('greater', 'JJR'), ('probability', 'NN'), ('threshold', 'VBD'), ('determining', 'VBG'), ('target', 'NN'), ('user', 'JJ'), ('willingness', 'NN'), ('pay', 'NN'), ('response', 'NN'), ('determining', 'VBG'), ('target', 'NN'), ('user', 'JJ'), ('willingness', 'NN'), ('pay', 'NN'), ('completing', 'VBG'), ('payment', 'NN'), ('operation', 'NN'), ('based', 'VBN'), ('face', 'NN'), ('recognition', 'NN'), ('device', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('completing', 'VBG'), ('payment', 'NN'), ('operation', 'NN'), ('based', 'VBN'), ('face', 'NN'), ('recognition', 'NN'), ('comprises', 'VBZ'), ('triggering', 'VBG'), ('performing', 'VBG'), ('payment', 'NN'), ('initiating', 'NN'), ('operation', 'NN'), ('acquire', 'VB'), ('second', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('information', 'NN'), ('based', 'VBN'), ('face', 'NN'), ('recognition', 'NN'), ('determining', 'VBG'), ('whether', 'IN'), ('second', 'JJ'), ('characteristic', 'JJ'), ('information', 'NN'), ('extracted', 'VBD'), ('second', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('information', 'NN'), ('indicates', 'VBZ'), ('user', 'JJ'), ('willingness', 'NN'), ('pay', 'NN'), ('response', 'NN'), ('determining', 'VBG'), ('second', 'JJ'), ('characteristic', 'JJ'), ('information', 'NN'), ('indicates', 'VBZ'), ('user', 'JJ'), ('willingness', 'NN'), ('pay', 'NN'), ('triggering', 'VBG'), ('performing', 'VBG'), ('payment', 'NN'), ('confirmation', 'NN'), ('operation', 'NN'), ('complete', 'JJ'), ('payment', 'NN'), ('operation', 'NN'), ('based', 'VBN'), ('payment', 'NN'), ('account', 'NN'), ('information', 'NN'), ('corresponding', 'VBG'), ('target', 'NN'), ('user', 'JJ'), ('device', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('determining', 'VBG'), ('whether', 'IN'), ('second', 'JJ'), ('characteristic', 'JJ'), ('information', 'NN'), ('extracted', 'VBD'), ('second', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('information', 'NN'), ('indicates', 'VBZ'), ('user', 'JJ'), ('willingness', 'NN'), ('pay', 'NN'), ('comprises', 'VBZ'), ('determining', 'VBG'), ('whether', 'IN'), ('current', 'JJ'), ('user', 'NN'), ('corresponding', 'VBG'), ('second', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('information', 'NN'), ('consistent', 'JJ'), ('target', 'NN'), ('user', 'JJ'), ('response', 'NN'), ('determining', 'VBG'), ('current', 'JJ'), ('user', 'JJ'), ('consistent', 'NN'), ('target', 'NN'), ('user', 'IN'), ('determining', 'VBG'), ('whether', 'IN'), ('target', 'NN'), ('user', 'JJ'), ('willingness', 'NN'), ('pay', 'NN'), ('according', 'VBG'), ('second', 'JJ'), ('characteristic', 'JJ'), ('information', 'NN'), ('extracted', 'VBD'), ('second', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('information', 'NN'), ('device', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('extracting', 'VBG'), ('first', 'JJ'), ('characteristic', 'JJ'), ('information', 'NN'), ('first', 'RB'), ('face', 'NN'), ('image', 'NN'), ('information', 'NN'), ('comprises', 'VBZ'), ('determining', 'VBG'), ('head', 'NN'), ('posture', 'NN'), ('information', 'NN'), ('target', 'NN'), ('user', 'NN'), ('using', 'VBG'), ('head', 'NN'), ('posture', 'NN'), ('recognition', 'NN'), ('model', 'NN'), ('based', 'VBN'), ('first', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('information', 'NN'), ('determining', 'VBG'), ('gaze', 'NN'), ('information', 'NN'), ('target', 'NN'), ('user', 'NN'), ('using', 'VBG'), ('gaze', 'JJ'), ('information', 'NN'), ('recognition', 'NN'), ('model', 'NN'), ('based', 'VBN'), ('characteristics', 'NNS'), ('eye', 'NN'), ('region', 'NN'), ('first', 'RB'), ('face', 'JJ'), ('image', 'NN'), ('information', 'NN'), ('device', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('head', 'NN'), ('posture', 'NN'), ('recognition', 'NN'), ('model', 'NN'), ('obtained', 'VBD'), ('training', 'VBG'), ('acquiring', 'VBG'), ('first', 'JJ'), ('sample', 'NN'), ('data', 'NNS'), ('set', 'VBD'), ('wherein', 'NN'), ('first', 'JJ'), ('sample', 'NN'), ('data', 'NNS'), ('set', 'VBD'), ('includes', 'VBZ'), ('plurality', 'NN'), ('pieces', 'NNS'), ('first', 'RB'), ('sample', 'JJ'), ('data', 'NNS'), ('plurality', 'NN'), ('pieces', 'NNS'), ('first', 'RB'), ('sample', 'JJ'), ('data', 'NNS'), ('includes', 'VBZ'), ('correspondence', 'NN'), ('sample', 'NN'), ('face', 'NN'), ('image', 'NN'), ('head', 'NN'), ('posture', 'NN'), ('information', 'NN'), ('determining', 'VBG'), ('mean', 'JJ'), ('image', 'NN'), ('data', 'NNS'), ('variance', 'NN'), ('image', 'NN'), ('data', 'NNS'), ('plurality', 'NN'), ('sample', 'NN'), ('face', 'NN'), ('images', 'VBZ'), ('plurality', 'NN'), ('pieces', 'NNS'), ('first', 'RB'), ('sample', 'JJ'), ('data', 'NNS'), ('preprocessing', 'VBG'), ('sample', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('contained', 'VBD'), ('plurality', 'NN'), ('pieces', 'NNS'), ('first', 'RB'), ('sample', 'VB'), ('data', 'NNS'), ('based', 'VBN'), ('mean', 'JJ'), ('image', 'NN'), ('data', 'NNS'), ('variance', 'NN'), ('image', 'NN'), ('data', 'NNS'), ('obtain', 'VB'), ('preprocessed', 'JJ'), ('sample', 'NN'), ('face', 'NN'), ('image', 'NN'), ('setting', 'VBG'), ('preprocessed', 'JJ'), ('sample', 'NN'), ('face', 'NN'), ('image', 'NN'), ('corresponding', 'VBG'), ('head', 'JJ'), ('posture', 'NN'), ('information', 'NN'), ('first', 'RB'), ('model', 'VBZ'), ('training', 'VBG'), ('sample', 'JJ'), ('performing', 'VBG'), ('training', 'NN'), ('using', 'VBG'), ('machine', 'NN'), ('learning', 'VBG'), ('method', 'NNS'), ('based', 'VBN'), ('plurality', 'NN'), ('first', 'JJ'), ('model', 'NN'), ('training', 'NN'), ('samples', 'NNS'), ('obtain', 'VB'), ('head', 'JJ'), ('posture', 'NN'), ('recognition', 'NN'), ('model', 'NN'), ('device', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('gaze', 'NN'), ('information', 'NN'), ('recognition', 'NN'), ('model', 'NN'), ('obtained', 'VBD'), ('training', 'VBG'), ('acquiring', 'VBG'), ('second', 'JJ'), ('sample', 'NN'), ('data', 'NNS'), ('set', 'VBD'), ('wherein', 'JJ'), ('second', 'JJ'), ('sample', 'NN'), ('data', 'NNS'), ('set', 'VBD'), ('includes', 'VBZ'), ('plurality', 'NN'), ('pieces', 'NNS'), ('second', 'JJ'), ('sample', 'NN'), ('data', 'NNS'), ('plurality', 'NN'), ('pieces', 'NNS'), ('second', 'JJ'), ('sample', 'JJ'), ('data', 'NNS'), ('includes', 'VBZ'), ('correspondence', 'NN'), ('sample', 'NN'), ('eye', 'NN'), ('image', 'NN'), ('gaze', 'JJ'), ('information', 'NN'), ('determining', 'VBG'), ('mean', 'JJ'), ('image', 'NN'), ('data', 'NNS'), ('variance', 'NN'), ('image', 'NN'), ('data', 'NNS'), ('plurality', 'NN'), ('sample', 'NN'), ('eye', 'NN'), ('images', 'VBZ'), ('plurality', 'NN'), ('pieces', 'NNS'), ('second', 'JJ'), ('sample', 'NN'), ('data', 'NNS'), ('preprocessing', 'VBG'), ('sample', 'NN'), ('eye', 'NN'), ('image', 'NN'), ('contained', 'VBD'), ('plurality', 'NN'), ('pieces', 'NNS'), ('second', 'JJ'), ('sample', 'NN'), ('data', 'NNS'), ('based', 'VBN'), ('mean', 'JJ'), ('image', 'NN'), ('data', 'NNS'), ('variance', 'NN'), ('image', 'NN'), ('data', 'NNS'), ('obtain', 'VB'), ('preprocessed', 'JJ'), ('sample', 'NN'), ('eye', 'NN'), ('image', 'NN'), ('setting', 'VBG'), ('preprocessed', 'JJ'), ('sample', 'NN'), ('eye', 'NN'), ('image', 'NN'), ('corresponding', 'VBG'), ('gaze', 'JJ'), ('information', 'NN'), ('second', 'JJ'), ('model', 'NN'), ('training', 'VBG'), ('sample', 'JJ'), ('performing', 'VBG'), ('training', 'NN'), ('using', 'VBG'), ('machine', 'NN'), ('learning', 'VBG'), ('method', 'JJ'), ('plurality', 'NN'), ('second', 'JJ'), ('model', 'NN'), ('training', 'NN'), ('samples', 'NNS'), ('obtain', 'VB'), ('gaze', 'JJ'), ('information', 'NN'), ('recognition', 'NN'), ('model', 'NN'), ('device', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('angle', 'VBZ'), ('rotation', 'NN'), ('preset', 'VBN'), ('direction', 'NN'), ('comprises', 'VBZ'), ('pitch', 'VBP'), ('angle', 'NN'), ('yaw', 'NN'), ('angle', 'NN'), ('roll', 'NN'), ('angle', 'NN'), ('wherein', 'NN'), ('pitch', 'NN'), ('angle', 'NN'), ('refers', 'NNS'), ('angle', 'VBP'), ('rotation', 'NN'), ('around', 'IN'), ('x-axis', 'JJ'), ('yaw', 'NN'), ('angle', 'NN'), ('refers', 'NNS'), ('angle', 'VBP'), ('rotation', 'NN'), ('around', 'IN'), ('y-axis', 'JJ'), ('roll', 'NN'), ('angle', 'NN'), ('refers', 'NNS'), ('angle', 'VBP'), ('rotation', 'NN'), ('around', 'IN'), ('z-axis', 'JJ'), ('non-transitory', 'JJ'), ('computer-readable', 'JJ'), ('storage', 'NN'), ('medium', 'NN'), ('payment', 'NN'), ('based', 'VBN'), ('face', 'NN'), ('recognition', 'NN'), ('configured', 'VBD'), ('instructions', 'NNS'), ('executable', 'JJ'), ('one', 'CD'), ('processors', 'NNS'), ('cause', 'VBP'), ('one', 'CD'), ('processors', 'NNS'), ('perform', 'VB'), ('operations', 'NNS'), ('comprising', 'VBG'), ('acquiring', 'VBG'), ('first', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('information', 'NN'), ('target', 'NN'), ('user', 'NN'), ('extracting', 'VBG'), ('first', 'JJ'), ('characteristic', 'JJ'), ('information', 'NN'), ('first', 'RB'), ('face', 'NN'), ('image', 'NN'), ('information', 'NN'), ('wherein', 'IN'), ('first', 'JJ'), ('characteristic', 'JJ'), ('information', 'NN'), ('includes', 'VBZ'), ('head', 'NN'), ('posture', 'NN'), ('information', 'NN'), ('target', 'NN'), ('user', 'NN'), ('gaze', 'NN'), ('information', 'NN'), ('target', 'NN'), ('user', 'NN'), ('determining', 'VBG'), ('whether', 'IN'), ('target', 'NN'), ('user', 'JJ'), ('willingness', 'NN'), ('pay', 'NN'), ('according', 'VBG'), ('head', 'NN'), ('posture', 'NN'), ('information', 'NN'), ('target', 'NN'), ('user', 'NN'), ('gaze', 'NN'), ('information', 'NN'), ('target', 'NN'), ('user', 'NN'), ('including', 'VBG'), ('determining', 'VBG'), ('whether', 'IN'), ('angle', 'JJ'), ('rotation', 'NN'), ('preset', 'VBN'), ('direction', 'NN'), ('less', 'RBR'), ('angle', 'JJ'), ('threshold', 'NN'), ('wherein', 'NN'), ('head', 'NN'), ('posture', 'NN'), ('information', 'NN'), ('includes', 'VBZ'), ('angle', 'JJ'), ('rotation', 'NN'), ('preset', 'VBN'), ('direction', 'NN'), ('determining', 'VBG'), ('whether', 'IN'), ('probability', 'NN'), ('value', 'NN'), ('user', 'NN'), ('gazes', 'JJ'), ('payment', 'NN'), ('screen', 'NN'), ('greater', 'JJR'), ('probability', 'NN'), ('threshold', 'NN'), ('wherein', 'NN'), ('gaze', 'JJ'), ('information', 'NN'), ('includes', 'VBZ'), ('probability', 'NN'), ('value', 'NN'), ('user', 'NN'), ('gazes', 'JJ'), ('payment', 'NN'), ('screen', 'NN'), ('response', 'NN'), ('determining', 'VBG'), ('angle', 'JJ'), ('rotation', 'NN'), ('preset', 'VBN'), ('direction', 'NN'), ('less', 'RBR'), ('angle', 'JJ'), ('threshold', 'NN'), ('probability', 'NN'), ('value', 'NN'), ('user', 'NN'), ('gazes', 'JJ'), ('payment', 'NN'), ('screen', 'NN'), ('greater', 'JJR'), ('probability', 'NN'), ('threshold', 'VBD'), ('determining', 'VBG'), ('target', 'NN'), ('user', 'JJ'), ('willingness', 'NN'), ('pay', 'NN'), ('response', 'NN'), ('determining', 'VBG'), ('target', 'NN'), ('user', 'JJ'), ('willingness', 'NN'), ('pay', 'NN'), ('completing', 'VBG'), ('payment', 'NN'), ('operation', 'NN'), ('based', 'VBN'), ('face', 'NN'), ('recognition', 'NN'), ('storage', 'NN'), ('medium', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('completing', 'VBG'), ('payment', 'NN'), ('operation', 'NN'), ('based', 'VBN'), ('face', 'NN'), ('recognition', 'NN'), ('comprises', 'VBZ'), ('triggering', 'VBG'), ('performing', 'VBG'), ('payment', 'NN'), ('initiating', 'NN'), ('operation', 'NN'), ('acquire', 'VB'), ('second', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('information', 'NN'), ('based', 'VBN'), ('face', 'NN'), ('recognition', 'NN'), ('determining', 'VBG'), ('whether', 'IN'), ('second', 'JJ'), ('characteristic', 'JJ'), ('information', 'NN'), ('extracted', 'VBD'), ('second', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('information', 'NN'), ('indicates', 'VBZ'), ('user', 'JJ'), ('willingness', 'NN'), ('pay', 'NN'), ('response', 'NN'), ('determining', 'VBG'), ('second', 'JJ'), ('characteristic', 'JJ'), ('information', 'NN'), ('indicates', 'VBZ'), ('user', 'JJ'), ('willingness', 'NN'), ('pay', 'NN'), ('triggering', 'VBG'), ('performing', 'VBG'), ('payment', 'NN'), ('confirmation', 'NN'), ('operation', 'NN'), ('complete', 'JJ'), ('payment', 'NN'), ('operation', 'NN'), ('based', 'VBN'), ('payment', 'NN'), ('account', 'NN'), ('information', 'NN'), ('corresponding', 'VBG'), ('target', 'NN'), ('user', 'JJ'), ('storage', 'NN'), ('medium', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('determining', 'VBG'), ('whether', 'IN'), ('second', 'JJ'), ('characteristic', 'JJ'), ('information', 'NN'), ('extracted', 'VBD'), ('second', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('information', 'NN'), ('indicates', 'VBZ'), ('user', 'JJ'), ('willingness', 'NN'), ('pay', 'NN'), ('comprises', 'VBZ'), ('determining', 'VBG'), ('whether', 'IN'), ('current', 'JJ'), ('user', 'NN'), ('corresponding', 'VBG'), ('second', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('information', 'NN'), ('consistent', 'JJ'), ('target', 'NN'), ('user', 'JJ'), ('response', 'NN'), ('determining', 'VBG'), ('current', 'JJ'), ('user', 'JJ'), ('consistent', 'NN'), ('target', 'NN'), ('user', 'IN'), ('determining', 'VBG'), ('whether', 'IN'), ('target', 'NN'), ('user', 'JJ'), ('willingness', 'NN'), ('pay', 'NN'), ('according', 'VBG'), ('second', 'JJ'), ('characteristic', 'JJ'), ('information', 'NN'), ('extracted', 'VBD'), ('second', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('information', 'NN'), ('storage', 'NN'), ('medium', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('extracting', 'VBG'), ('first', 'JJ'), ('characteristic', 'JJ'), ('information', 'NN'), ('first', 'RB'), ('face', 'NN'), ('image', 'NN'), ('information', 'NN'), ('comprises', 'VBZ'), ('determining', 'VBG'), ('head', 'NN'), ('posture', 'NN'), ('information', 'NN'), ('target', 'NN'), ('user', 'NN'), ('using', 'VBG'), ('head', 'NN'), ('posture', 'NN'), ('recognition', 'NN'), ('model', 'NN'), ('based', 'VBN'), ('first', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('information', 'NN'), ('determining', 'VBG'), ('gaze', 'NN'), ('information', 'NN'), ('target', 'NN'), ('user', 'NN'), ('using', 'VBG'), ('gaze', 'JJ'), ('information', 'NN'), ('recognition', 'NN'), ('model', 'NN'), ('based', 'VBN'), ('characteristics', 'NNS'), ('eye', 'NN'), ('region', 'NN'), ('first', 'RB'), ('face', 'JJ'), ('image', 'NN'), ('information', 'NN'), ('storage', 'NN'), ('medium', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('head', 'NN'), ('posture', 'NN'), ('recognition', 'NN'), ('model', 'NN'), ('obtained', 'VBD'), ('training', 'VBG'), ('acquiring', 'VBG'), ('first', 'JJ'), ('sample', 'NN'), ('data', 'NNS'), ('set', 'VBD'), ('wherein', 'NN'), ('first', 'JJ'), ('sample', 'NN'), ('data', 'NNS'), ('set', 'VBD'), ('includes', 'VBZ'), ('plurality', 'NN'), ('pieces', 'NNS'), ('first', 'RB'), ('sample', 'JJ'), ('data', 'NNS'), ('plurality', 'NN'), ('pieces', 'NNS'), ('first', 'RB'), ('sample', 'JJ'), ('data', 'NNS'), ('includes', 'VBZ'), ('correspondence', 'NN'), ('sample', 'NN'), ('face', 'NN'), ('image', 'NN'), ('head', 'NN'), ('posture', 'NN'), ('information', 'NN'), ('determining', 'VBG'), ('mean', 'JJ'), ('image', 'NN'), ('data', 'NNS'), ('variance', 'NN'), ('image', 'NN'), ('data', 'NNS'), ('plurality', 'NN'), ('sample', 'NN'), ('face', 'NN'), ('images', 'VBZ'), ('plurality', 'NN'), ('pieces', 'NNS'), ('first', 'RB'), ('sample', 'JJ'), ('data', 'NNS'), ('preprocessing', 'VBG'), ('sample', 'JJ'), ('face', 'NN'), ('image', 'NN'), ('contained', 'VBD'), ('plurality', 'NN'), ('pieces', 'NNS'), ('first', 'RB'), ('sample', 'VB'), ('data', 'NNS'), ('based', 'VBN'), ('mean', 'JJ'), ('image', 'NN'), ('data', 'NNS'), ('variance', 'NN'), ('image', 'NN'), ('data', 'NNS'), ('obtain', 'VB'), ('preprocessed', 'JJ'), ('sample', 'NN'), ('face', 'NN'), ('image', 'NN'), ('setting', 'VBG'), ('preprocessed', 'JJ'), ('sample', 'NN'), ('face', 'NN'), ('image', 'NN'), ('corresponding', 'VBG'), ('head', 'JJ'), ('posture', 'NN'), ('information', 'NN'), ('first', 'RB'), ('model', 'VBZ'), ('training', 'VBG'), ('sample', 'JJ'), ('performing', 'VBG'), ('training', 'NN'), ('using', 'VBG'), ('machine', 'NN'), ('learning', 'VBG'), ('method', 'NNS'), ('based', 'VBN'), ('plurality', 'NN'), ('first', 'JJ'), ('model', 'NN'), ('training', 'NN'), ('samples', 'NNS'), ('obtain', 'VB'), ('head', 'JJ'), ('posture', 'NN'), ('recognition', 'NN'), ('model', 'NN'), ('wherein', 'VBD'), ('gaze', 'JJ'), ('information', 'NN'), ('recognition', 'NN'), ('model', 'NN'), ('obtained', 'VBD'), ('training', 'VBG'), ('acquiring', 'VBG'), ('second', 'JJ'), ('sample', 'NN'), ('data', 'NNS'), ('set', 'VBD'), ('wherein', 'JJ'), ('second', 'JJ'), ('sample', 'NN'), ('data', 'NNS'), ('set', 'VBD'), ('includes', 'VBZ'), ('plurality', 'NN'), ('pieces', 'NNS'), ('second', 'JJ'), ('sample', 'NN'), ('data', 'NNS'), ('plurality', 'NN'), ('pieces', 'NNS'), ('second', 'JJ'), ('sample', 'JJ'), ('data', 'NNS'), ('includes', 'VBZ'), ('correspondence', 'NN'), ('sample', 'NN'), ('eye', 'NN'), ('image', 'NN'), ('gaze', 'JJ'), ('information', 'NN'), ('determining', 'VBG'), ('mean', 'JJ'), ('image', 'NN'), ('data', 'NNS'), ('variance', 'NN'), ('image', 'NN'), ('data', 'NNS'), ('plurality', 'NN'), ('sample', 'NN'), ('eye', 'NN'), ('images', 'VBZ'), ('plurality', 'NN'), ('pieces', 'NNS'), ('second', 'JJ'), ('sample', 'NN'), ('data', 'NNS'), ('preprocessing', 'VBG'), ('sample', 'NN'), ('eye', 'NN'), ('image', 'NN'), ('contained', 'VBD'), ('plurality', 'NN'), ('pieces', 'NNS'), ('second', 'JJ'), ('sample', 'NN'), ('data', 'NNS'), ('based', 'VBN'), ('mean', 'JJ'), ('image', 'NN'), ('data', 'NNS'), ('variance', 'NN'), ('image', 'NN'), ('data', 'NNS'), ('obtain', 'VB'), ('preprocessed', 'JJ'), ('sample', 'NN'), ('eye', 'NN'), ('image', 'NN'), ('setting', 'VBG'), ('preprocessed', 'JJ'), ('sample', 'NN'), ('eye', 'NN'), ('image', 'NN'), ('corresponding', 'VBG'), ('gaze', 'JJ'), ('information', 'NN'), ('second', 'JJ'), ('model', 'NN'), ('training', 'VBG'), ('sample', 'JJ'), ('performing', 'VBG'), ('training', 'NN'), ('using', 'VBG'), ('machine', 'NN'), ('learning', 'VBG'), ('method', 'NNS'), ('based', 'VBN'), ('plurality', 'NN'), ('second', 'JJ'), ('model', 'NN'), ('training', 'NN'), ('samples', 'NNS'), ('obtain', 'VB'), ('gaze', 'JJ'), ('information', 'NN'), ('recognition', 'NN'), ('model', 'NN'), ('storage', 'NN'), ('medium', 'NN'), ('claimed', 'VBD'), ('claim', 'NN'), ('wherein', 'NN'), ('angle', 'VBZ'), ('rotation', 'NN'), ('preset', 'VBN'), ('direction', 'NN'), ('comprises', 'VBZ'), ('pitch', 'VBP'), ('angle', 'NN'), ('yaw', 'NN'), ('angle', 'NN'), ('roll', 'NN'), ('angle', 'NN'), ('wherein', 'NN'), ('pitch', 'NN'), ('angle', 'NN'), ('refers', 'NNS'), ('angle', 'VBP'), ('rotation', 'NN'), ('around', 'IN'), ('x-axis', 'JJ'), ('yaw', 'NN'), ('angle', 'NN'), ('refers', 'NNS'), ('angle', 'VBP'), ('rotation', 'NN'), ('around', 'IN'), ('y-axis', 'JJ'), ('roll', 'NN'), ('angle', 'NN'), ('refers', 'NNS'), ('angle', 'VBP'), ('rotation', 'NN'), ('around', 'IN'), ('z-axis', 'JJ'), ('method', 'NN'), ('comprising', 'VBG'), ('detecting', 'VBG'), ('motion', 'NN'), ('detection', 'NN'), ('module', 'NN'), ('motion', 'NN'), ('subject', 'NN'), ('within', 'IN'), ('predetermined', 'JJ'), ('area', 'NN'), ('view', 'NN'), ('assigning', 'VBG'), ('unique', 'JJ'), ('session', 'NN'), ('identification', 'NN'), ('number', 'NN'), ('subject', 'JJ'), ('detected', 'VBD'), ('within', 'IN'), ('predetermined', 'JJ'), ('area', 'NN'), ('view', 'NN'), ('detecting', 'VBG'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'NN'), ('detected', 'VBD'), ('within', 'IN'), ('predetermined', 'JJ'), ('area', 'NN'), ('view', 'NN'), ('generating', 'VBG'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'NN'), ('assessing', 'VBG'), ('quality', 'NN'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'JJ'), ('determining', 'VBG'), ('identity', 'NN'), ('subject', 'NN'), ('based', 'VBN'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'JJ'), ('identifying', 'VBG'), ('intent', 'NN'), ('subject', 'JJ'), ('authorizing', 'VBG'), ('access', 'NN'), ('point', 'NN'), ('entry', 'NN'), ('based', 'VBN'), ('determined', 'VBN'), ('identity', 'NN'), ('subject', 'NN'), ('based', 'VBN'), ('intent', 'NN'), ('subject', 'JJ'), ('method', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('determining', 'VBG'), ('one', 'CD'), ('additional', 'JJ'), ('subjects', 'NNS'), ('within', 'IN'), ('predetermined', 'JJ'), ('area', 'NN'), ('view', 'NN'), ('assigning', 'VBG'), ('unique', 'JJ'), ('session', 'NN'), ('identification', 'NN'), ('number', 'NN'), ('one', 'CD'), ('additional', 'JJ'), ('subjects', 'NNS'), ('detected', 'VBN'), ('within', 'IN'), ('predetermined', 'JJ'), ('area', 'NN'), ('view', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('assessing', 'VBG'), ('quality', 'NN'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'JJ'), ('comprises', 'VBZ'), ('assessing', 'VBG'), ('whether', 'IN'), ('quality', 'NN'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('object', 'NN'), ('equates', 'NNS'), ('predetermined', 'VBD'), ('metric', 'JJ'), ('quality', 'NN'), ('upon', 'IN'), ('determining', 'VBG'), ('quality', 'NN'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('object', 'VBP'), ('inferior', 'JJ'), ('predetermined', 'VBN'), ('metric', 'JJ'), ('quality', 'NN'), ('discarding', 'VBG'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'JJ'), ('generating', 'VBG'), ('second', 'JJ'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'JJ'), ('method', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('detecting', 'VBG'), ('whether', 'IN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'JJ'), ('photographic', 'JJ'), ('image', 'NN'), ('upon', 'IN'), ('detecting', 'VBG'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'JJ'), ('photographic', 'JJ'), ('image', 'NN'), ('generating', 'VBG'), ('warning', 'VBG'), ('restrict', 'JJ'), ('access', 'NN'), ('point', 'NN'), ('entry', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('conducing', 'VBG'), ('incremental', 'JJ'), ('training', 'NN'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'JJ'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('conducing', 'VBG'), ('incremental', 'JJ'), ('training', 'NN'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'JJ'), ('comprises', 'NNS'), ('capturing', 'VBG'), ('first', 'JJ'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('facial', 'JJ'), ('landmarks', 'NNS'), ('converting', 'VBG'), ('first', 'JJ'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('first', 'RB'), ('numeric', 'JJ'), ('vector', 'NN'), ('capturing', 'VBG'), ('second', 'JJ'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('facial', 'JJ'), ('landmarks', 'NNS'), ('converting', 'VBG'), ('second', 'JJ'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('second', 'JJ'), ('numeric', 'JJ'), ('vector', 'NN'), ('calculating', 'VBG'), ('weighted', 'VBD'), ('mean', 'JJ'), ('first', 'JJ'), ('numeric', 'JJ'), ('vector', 'NN'), ('second', 'JJ'), ('numeric', 'JJ'), ('vector', 'NN'), ('wherein', 'NN'), ('weighted', 'VBD'), ('mean', 'JJ'), ('represents', 'VBZ'), ('change', 'VBP'), ('facial', 'JJ'), ('area', 'NN'), ('storing', 'VBG'), ('weighted', 'JJ'), ('mean', 'JJ'), ('database', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('determining', 'VBG'), ('identity', 'NN'), ('subject', 'NN'), ('based', 'VBN'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'JJ'), ('comprises', 'VBZ'), ('comparing', 'VBG'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'JJ'), ('plurality', 'NN'), ('images', 'NNS'), ('stored', 'VBD'), ('database', 'NN'), ('authenticating', 'VBG'), ('subject', 'JJ'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('identifying', 'VBG'), ('intent', 'NN'), ('subject', 'NN'), ('comprises', 'VBZ'), ('upon', 'IN'), ('detecting', 'VBG'), ('facial', 'JJ'), ('area', 'NN'), ('bounding', 'VBG'), ('box', 'NN'), ('commencing', 'VBG'), ('authentication', 'NN'), ('subject', 'JJ'), ('calculating', 'VBG'), ('directional', 'JJ'), ('vector', 'NN'), ('face', 'NN'), ('subject', 'JJ'), ('determine', 'JJ'), ('intent', 'NN'), ('subject', 'JJ'), ('gain', 'NN'), ('access', 'NN'), ('point', 'NN'), ('entry', 'NN'), ('based', 'VBN'), ('directional', 'JJ'), ('vector', 'NN'), ('face', 'NN'), ('subject', 'JJ'), ('granting', 'VBG'), ('access', 'NN'), ('point', 'NN'), ('entry', 'NN'), ('based', 'VBN'), ('authentication', 'NN'), ('subject', 'NN'), ('based', 'VBN'), ('determining', 'VBG'), ('intent', 'NN'), ('subject', 'JJ'), ('non-transitory', 'JJ'), ('computer', 'NN'), ('readable', 'JJ'), ('medium', 'NN'), ('program', 'NN'), ('instructions', 'NNS'), ('stored', 'VBD'), ('thereon', 'JJ'), ('response', 'NN'), ('execution', 'NN'), ('computing', 'VBG'), ('device', 'NN'), ('cause', 'NN'), ('computing', 'VBG'), ('device', 'NN'), ('perform', 'NN'), ('operations', 'NNS'), ('comprising', 'VBG'), ('detecting', 'VBG'), ('motion', 'NN'), ('subject', 'NN'), ('within', 'IN'), ('predetermined', 'JJ'), ('area', 'NN'), ('view', 'NN'), ('assigning', 'VBG'), ('unique', 'JJ'), ('session', 'NN'), ('identification', 'NN'), ('number', 'NN'), ('subject', 'JJ'), ('detected', 'VBD'), ('within', 'IN'), ('predetermined', 'JJ'), ('area', 'NN'), ('view', 'NN'), ('detecting', 'VBG'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'NN'), ('detected', 'VBD'), ('within', 'IN'), ('predetermined', 'JJ'), ('area', 'NN'), ('view', 'NN'), ('generating', 'VBG'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'NN'), ('assessing', 'VBG'), ('quality', 'NN'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'JJ'), ('determining', 'VBG'), ('identity', 'NN'), ('subject', 'NN'), ('based', 'VBN'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'JJ'), ('identifying', 'VBG'), ('intent', 'NN'), ('subject', 'JJ'), ('authorizing', 'VBG'), ('access', 'NN'), ('point', 'NN'), ('entry', 'NN'), ('based', 'VBN'), ('determined', 'VBN'), ('identity', 'NN'), ('subject', 'NN'), ('based', 'VBN'), ('intent', 'NN'), ('subject', 'JJ'), ('non-transitory', 'JJ'), ('computer', 'NN'), ('readable', 'JJ'), ('medium', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('determining', 'VBG'), ('one', 'CD'), ('additional', 'JJ'), ('subjects', 'NNS'), ('within', 'IN'), ('predetermined', 'JJ'), ('area', 'NN'), ('view', 'NN'), ('assigning', 'VBG'), ('unique', 'JJ'), ('session', 'NN'), ('identification', 'NN'), ('number', 'NN'), ('one', 'CD'), ('additional', 'JJ'), ('subjects', 'NNS'), ('detected', 'VBN'), ('within', 'IN'), ('predetermined', 'JJ'), ('area', 'NN'), ('view', 'NN'), ('non-transitory', 'JJ'), ('computer', 'NN'), ('readable', 'JJ'), ('medium', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('assessing', 'VBG'), ('quality', 'NN'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'JJ'), ('comprises', 'VBZ'), ('assessing', 'VBG'), ('whether', 'IN'), ('quality', 'NN'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('object', 'NN'), ('equates', 'NNS'), ('predetermined', 'VBD'), ('metric', 'JJ'), ('quality', 'NN'), ('upon', 'IN'), ('determining', 'VBG'), ('quality', 'NN'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('object', 'VBP'), ('inferior', 'JJ'), ('predetermined', 'VBN'), ('metric', 'JJ'), ('quality', 'NN'), ('discarding', 'VBG'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'JJ'), ('generating', 'VBG'), ('second', 'JJ'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'JJ'), ('non-transitory', 'JJ'), ('computer', 'NN'), ('readable', 'JJ'), ('medium', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('detecting', 'VBG'), ('whether', 'IN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'JJ'), ('photographic', 'JJ'), ('image', 'NN'), ('upon', 'IN'), ('detecting', 'VBG'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'JJ'), ('photographic', 'JJ'), ('image', 'NN'), ('generating', 'VBG'), ('warning', 'VBG'), ('restrict', 'JJ'), ('access', 'NN'), ('access', 'NN'), ('point', 'NN'), ('non-transitory', 'JJ'), ('computer', 'NN'), ('readable', 'JJ'), ('medium', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('conducing', 'VBG'), ('incremental', 'JJ'), ('training', 'NN'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'JJ'), ('non-transitory', 'JJ'), ('computer', 'NN'), ('readable', 'JJ'), ('medium', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('conducing', 'VBG'), ('incremental', 'JJ'), ('training', 'NN'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'JJ'), ('comprises', 'NNS'), ('capturing', 'VBG'), ('first', 'JJ'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('facial', 'JJ'), ('landmarks', 'NNS'), ('converting', 'VBG'), ('first', 'JJ'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('first', 'RB'), ('numeric', 'JJ'), ('vector', 'NN'), ('capturing', 'VBG'), ('second', 'JJ'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('facial', 'JJ'), ('landmarks', 'NNS'), ('converting', 'VBG'), ('second', 'JJ'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('second', 'JJ'), ('numeric', 'JJ'), ('vector', 'NN'), ('calculating', 'VBG'), ('weighted', 'VBD'), ('mean', 'JJ'), ('first', 'JJ'), ('numeric', 'JJ'), ('vector', 'NN'), ('second', 'JJ'), ('numeric', 'JJ'), ('vector', 'NN'), ('wherein', 'NN'), ('weighted', 'VBD'), ('mean', 'JJ'), ('represents', 'VBZ'), ('change', 'VBP'), ('facial', 'JJ'), ('area', 'NN'), ('storing', 'VBG'), ('weighted', 'JJ'), ('mean', 'JJ'), ('database', 'NN'), ('apparatus', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('comprising', 'VBG'), ('processor', 'JJ'), ('memory', 'NN'), ('store', 'NN'), ('computer', 'NN'), ('program', 'NN'), ('instructions', 'NNS'), ('computer', 'NN'), ('program', 'NN'), ('instructions', 'NNS'), ('executed', 'VBD'), ('processor', 'NN'), ('cause', 'NN'), ('processor', 'NN'), ('perform', 'NN'), ('operations', 'NNS'), ('comprising', 'VBG'), ('detecting', 'VBG'), ('motion', 'NN'), ('subject', 'NN'), ('within', 'IN'), ('predetermined', 'JJ'), ('area', 'NN'), ('view', 'NN'), ('assigning', 'VBG'), ('unique', 'JJ'), ('session', 'NN'), ('identification', 'NN'), ('number', 'NN'), ('subject', 'JJ'), ('detected', 'VBD'), ('within', 'IN'), ('predetermined', 'JJ'), ('area', 'NN'), ('view', 'NN'), ('detecting', 'VBG'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'NN'), ('detected', 'VBD'), ('within', 'IN'), ('predetermined', 'JJ'), ('area', 'NN'), ('view', 'NN'), ('generating', 'VBG'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'NN'), ('assessing', 'VBG'), ('quality', 'NN'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'JJ'), ('determining', 'VBG'), ('identity', 'NN'), ('subject', 'NN'), ('based', 'VBN'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'JJ'), ('identifying', 'VBG'), ('intent', 'NN'), ('subject', 'JJ'), ('authorizing', 'VBG'), ('access', 'NN'), ('point', 'NN'), ('entry', 'NN'), ('based', 'VBN'), ('determined', 'VBN'), ('identity', 'NN'), ('subject', 'NN'), ('based', 'VBN'), ('intent', 'NN'), ('subject', 'JJ'), ('apparatus', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('determining', 'VBG'), ('one', 'CD'), ('additional', 'JJ'), ('subjects', 'NNS'), ('within', 'IN'), ('predetermined', 'JJ'), ('area', 'NN'), ('view', 'NN'), ('assigning', 'VBG'), ('unique', 'JJ'), ('session', 'NN'), ('identification', 'NN'), ('number', 'NN'), ('one', 'CD'), ('additional', 'JJ'), ('subjects', 'NNS'), ('detected', 'VBN'), ('within', 'IN'), ('predetermined', 'JJ'), ('area', 'NN'), ('view', 'NN'), ('apparatus', 'VBP'), ('claim', 'NN'), ('wherein', 'NN'), ('assessing', 'VBG'), ('quality', 'NN'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'JJ'), ('comprises', 'VBZ'), ('assessing', 'VBG'), ('whether', 'IN'), ('quality', 'NN'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('object', 'NN'), ('equates', 'NNS'), ('predetermined', 'VBD'), ('metric', 'JJ'), ('quality', 'NN'), ('upon', 'IN'), ('determining', 'VBG'), ('quality', 'NN'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('object', 'VBP'), ('inferior', 'JJ'), ('predetermined', 'VBN'), ('metric', 'JJ'), ('quality', 'NN'), ('discarding', 'VBG'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'JJ'), ('generating', 'VBG'), ('second', 'JJ'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'JJ'), ('apparatus', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('detecting', 'VBG'), ('whether', 'IN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'JJ'), ('photographic', 'JJ'), ('image', 'NN'), ('upon', 'IN'), ('detecting', 'VBG'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'JJ'), ('photographic', 'JJ'), ('image', 'NN'), ('generating', 'VBG'), ('warning', 'VBG'), ('restrict', 'JJ'), ('access', 'NN'), ('access', 'NN'), ('point', 'NN'), ('apparatus', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('conducing', 'VBG'), ('incremental', 'JJ'), ('training', 'NN'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'JJ'), ('apparatus', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('conducing', 'VBG'), ('incremental', 'JJ'), ('training', 'NN'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('subject', 'JJ'), ('comprises', 'NNS'), ('capturing', 'VBG'), ('first', 'JJ'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('facial', 'JJ'), ('landmarks', 'NNS'), ('converting', 'VBG'), ('first', 'JJ'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('first', 'RB'), ('numeric', 'JJ'), ('vector', 'NN'), ('capturing', 'VBG'), ('second', 'JJ'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('facial', 'JJ'), ('landmarks', 'NNS'), ('converting', 'VBG'), ('second', 'JJ'), ('image', 'NN'), ('facial', 'JJ'), ('area', 'NN'), ('second', 'JJ'), ('numeric', 'JJ'), ('vector', 'NN'), ('calculating', 'VBG'), ('weighted', 'VBD'), ('mean', 'JJ'), ('first', 'JJ'), ('numeric', 'JJ'), ('vector', 'NN'), ('second', 'JJ'), ('numeric', 'JJ'), ('vector', 'NN'), ('wherein', 'NN'), ('weighted', 'VBD'), ('mean', 'JJ'), ('represents', 'VBZ'), ('change', 'VBP'), ('facial', 'JJ'), ('area', 'NN'), ('storing', 'VBG'), ('weighted', 'JJ'), ('mean', 'JJ'), ('database', 'NN'), ('robot', 'NN'), ('comprising', 'VBG'), ('body', 'NN'), ('configured', 'VBD'), ('rotate', 'JJ'), ('tilt', 'NN'), ('camera', 'NN'), ('coupled', 'VBN'), ('body', 'NN'), ('configured', 'JJ'), ('rotate', 'NN'), ('tilt', 'NN'), ('according', 'VBG'), ('rotate', 'NN'), ('tilt', 'NN'), ('body', 'NN'), ('wherein', 'JJ'), ('camera', 'NN'), ('configured', 'VBD'), ('acquire', 'VB'), ('video', 'NN'), ('space', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('unit', 'NN'), ('configured', 'VBD'), ('recognize', 'JJ'), ('respective', 'JJ'), ('faces', 'VBZ'), ('one', 'CD'), ('persons', 'NNS'), ('video', 'VBP'), ('tracking', 'VBG'), ('unit', 'NN'), ('configured', 'VBD'), ('track', 'JJ'), ('motion', 'NN'), ('recognized', 'VBD'), ('faces', 'VBZ'), ('one', 'CD'), ('persons', 'NNS'), ('controller', 'NN'), ('configured', 'VBD'), ('calculate', 'JJ'), ('respective', 'JJ'), ('size', 'NN'), ('faces', 'VBZ'), ('one', 'CD'), ('persons', 'NNS'), ('select', 'VBP'), ('first', 'JJ'), ('person', 'NN'), ('among', 'IN'), ('one', 'CD'), ('persons', 'NNS'), ('based', 'VBN'), ('calculated', 'JJ'), ('sizes', 'NNS'), ('faces', 'VBZ'), ('control', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('direction', 'NN'), ('rotation', 'NN'), ('camera', 'NN'), ('angle', 'NN'), ('tilt', 'NN'), ('camera', 'NN'), ('focal', 'JJ'), ('distance', 'NN'), ('camera', 'NN'), ('based', 'VBN'), ('tracked', 'JJ'), ('motion', 'NN'), ('recognized', 'VBD'), ('face', 'NN'), ('first', 'RB'), ('person', 'NN'), ('robot', 'JJ'), ('claim', 'NN'), ('wherein', 'NN'), ('controller', 'NN'), ('configured', 'VBD'), ('control', 'JJ'), ('direction', 'NN'), ('rotation', 'NN'), ('camera', 'NN'), ('angle', 'NN'), ('tilt', 'NN'), ('camera', 'NN'), ('achieve', 'VBP'), ('particular', 'JJ'), ('orientation', 'NN'), ('camera', 'NN'), ('relative', 'JJ'), ('face', 'NN'), ('first', 'RB'), ('person', 'NN'), ('control', 'NN'), ('focal', 'JJ'), ('distance', 'NN'), ('camera', 'NN'), ('comparing', 'VBG'), ('respective', 'JJ'), ('sizes', 'NNS'), ('face', 'VBP'), ('first', 'JJ'), ('person', 'NN'), ('motion', 'NN'), ('first', 'RB'), ('person', 'NN'), ('robot', 'JJ'), ('claim', 'NN'), ('wherein', 'IN'), ('particular', 'JJ'), ('orientation', 'NN'), ('occurs', 'VBZ'), ('camera', 'NN'), ('faces', 'VBZ'), ('general', 'JJ'), ('direction', 'NN'), ('face', 'NN'), ('first', 'RB'), ('person', 'NN'), ('robot', 'JJ'), ('claim', 'NN'), ('wherein', 'NN'), ('controller', 'NN'), ('configured', 'VBD'), ('normalize', 'JJ'), ('sizes', 'NNS'), ('faces', 'VBZ'), ('one', 'CD'), ('persons', 'NNS'), ('based', 'VBN'), ('interocular', 'JJ'), ('distance', 'NN'), ('select', 'NN'), ('first', 'RB'), ('person', 'NN'), ('based', 'VBN'), ('normalized', 'JJ'), ('sizes', 'NNS'), ('faces', 'VBZ'), ('one', 'CD'), ('persons', 'NNS'), ('robot', 'VBP'), ('claim', 'NN'), ('wherein', 'NN'), ('controller', 'NN'), ('configured', 'VBD'), ('select', 'JJ'), ('person', 'NN'), ('largest', 'JJS'), ('face', 'NN'), ('size', 'NN'), ('among', 'IN'), ('one', 'CD'), ('persons', 'NNS'), ('first', 'JJ'), ('person', 'NN'), ('robot', 'JJ'), ('claim', 'NN'), ('comprising', 'VBG'), ('microphone', 'NN'), ('configured', 'VBD'), ('receive', 'JJ'), ('spoken', 'NN'), ('audio', 'NN'), ('present', 'JJ'), ('space', 'NN'), ('wherein', 'NN'), ('controller', 'NN'), ('configured', 'VBD'), ('select', 'JJ'), ('first', 'JJ'), ('person', 'NN'), ('based', 'VBN'), ('received', 'VBN'), ('spoken', 'JJ'), ('audio', 'JJ'), ('robot', 'NN'), ('claim', 'NN'), ('wherein', 'VBP'), ('controller', 'NN'), ('configured', 'VBD'), ('control', 'NN'), ('gain', 'NN'), ('microphone', 'NN'), ('comparing', 'VBG'), ('respective', 'JJ'), ('sizes', 'NNS'), ('face', 'VBP'), ('first', 'JJ'), ('person', 'NN'), ('motion', 'NN'), ('first', 'RB'), ('person', 'NN'), ('robot', 'JJ'), ('claim', 'NN'), ('wherein', 'NN'), ('controller', 'NN'), ('configured', 'VBD'), ('calculate', 'JJ'), ('position', 'NN'), ('spoken', 'VBN'), ('audio', 'NN'), ('provided', 'VBD'), ('select', 'JJ'), ('first', 'JJ'), ('person', 'NN'), ('based', 'VBN'), ('whether', 'IN'), ('one', 'CD'), ('persons', 'NNS'), ('position', 'NN'), ('voice', 'NN'), ('signal', 'NN'), ('provided', 'VBD'), ('robot', 'JJ'), ('claim', 'NN'), ('wherein', 'NN'), ('controller', 'NN'), ('configured', 'VBD'), ('select', 'JJ'), ('second', 'JJ'), ('person', 'NN'), ('first', 'JJ'), ('person', 'NN'), ('among', 'IN'), ('one', 'CD'), ('persons', 'NNS'), ('second', 'JJ'), ('person', 'NN'), ('located', 'VBN'), ('position', 'NN'), ('spoken', 'VBN'), ('audio', 'NN'), ('provided', 'VBD'), ('robot', 'JJ'), ('claim', 'NN'), ('wherein', 'NN'), ('controller', 'NN'), ('configured', 'VBD'), ('select', 'JJ'), ('second', 'JJ'), ('person', 'NN'), ('largest', 'JJS'), ('face', 'NN'), ('size', 'NN'), ('first', 'JJ'), ('person', 'NN'), ('among', 'IN'), ('one', 'CD'), ('persons', 'NNS'), ('none', 'NN'), ('one', 'CD'), ('persons', 'NNS'), ('located', 'VBN'), ('position', 'NN'), ('spoken', 'VBN'), ('audio', 'NN'), ('provided', 'VBD'), ('robot', 'JJ'), ('claim', 'NN'), ('wherein', 'NN'), ('controller', 'NN'), ('configured', 'VBD'), ('select', 'JJ'), ('second', 'JJ'), ('person', 'NN'), ('largest', 'JJS'), ('face', 'NN'), ('size', 'NN'), ('first', 'JJ'), ('person', 'NN'), ('among', 'IN'), ('one', 'CD'), ('persons', 'NNS'), ('plurality', 'NN'), ('persons', 'NNS'), ('among', 'IN'), ('one', 'CD'), ('persons', 'NNS'), ('located', 'VBN'), ('position', 'NN'), ('spoken', 'VBN'), ('audio', 'NN'), ('provided', 'VBD'), ('robot', 'JJ'), ('claim', 'NN'), ('comprising', 'VBG'), ('speaker', 'NN'), ('wherein', 'NN'), ('controller', 'NN'), ('configured', 'VBD'), ('control', 'NN'), ('volume', 'NN'), ('speaker', 'NN'), ('comparing', 'VBG'), ('respective', 'JJ'), ('sizes', 'NNS'), ('face', 'VBP'), ('first', 'JJ'), ('person', 'NN'), ('motion', 'NN'), ('first', 'RB'), ('person', 'NN'), ('robot', 'JJ'), ('claim', 'NN'), ('wherein', 'IN'), ('body', 'NN'), ('configured', 'JJ'), ('rotate', 'JJ'), ('lateral', 'JJ'), ('direction', 'NN'), ('tilt', 'VBD'), ('vertical', 'JJ'), ('direction', 'NN'), ('electronic', 'JJ'), ('device', 'NN'), ('comprising', 'VBG'), ('camera', 'NN'), ('coupled', 'VBN'), ('body', 'NN'), ('configured', 'JJ'), ('rotate', 'NN'), ('tilt', 'NN'), ('wherein', 'NN'), ('camera', 'NN'), ('configured', 'VBD'), ('acquire', 'VB'), ('video', 'NN'), ('space', 'NN'), ('within', 'IN'), ('one', 'CD'), ('persons', 'NNS'), ('positioned', 'VBD'), ('processor', 'NN'), ('configured', 'VBN'), ('recognize', 'VB'), ('respective', 'JJ'), ('faces', 'VBZ'), ('one', 'CD'), ('persons', 'NNS'), ('video', 'VBP'), ('track', 'JJ'), ('motion', 'NN'), ('recognized', 'VBD'), ('faces', 'VBZ'), ('one', 'CD'), ('persons', 'NNS'), ('calculate', 'VBP'), ('respective', 'JJ'), ('size', 'NN'), ('faces', 'VBZ'), ('one', 'CD'), ('persons', 'NNS'), ('select', 'VBP'), ('first', 'JJ'), ('person', 'NN'), ('among', 'IN'), ('one', 'CD'), ('persons', 'NNS'), ('based', 'VBN'), ('calculated', 'JJ'), ('sizes', 'NNS'), ('faces', 'VBZ'), ('control', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('direction', 'NN'), ('rotation', 'NN'), ('camera', 'NN'), ('angle', 'NN'), ('tilt', 'NN'), ('camera', 'NN'), ('focal', 'JJ'), ('distance', 'NN'), ('camera', 'NN'), ('based', 'VBN'), ('tracked', 'JJ'), ('motion', 'NN'), ('recognized', 'VBD'), ('face', 'NN'), ('first', 'RB'), ('person', 'NN'), ('method', 'JJ'), ('comprising', 'VBG'), ('acquiring', 'VBG'), ('camera', 'NN'), ('video', 'NN'), ('space', 'NN'), ('within', 'IN'), ('one', 'CD'), ('persons', 'NNS'), ('positioned', 'VBD'), ('recognizing', 'VBG'), ('respective', 'JJ'), ('faces', 'VBZ'), ('one', 'CD'), ('persons', 'NNS'), ('video', 'IN'), ('tracking', 'VBG'), ('motion', 'NN'), ('recognized', 'VBD'), ('faces', 'VBZ'), ('one', 'CD'), ('persons', 'NNS'), ('calculating', 'VBG'), ('respective', 'JJ'), ('size', 'NN'), ('faces', 'VBZ'), ('one', 'CD'), ('persons', 'NNS'), ('selecting', 'VBG'), ('first', 'JJ'), ('person', 'NN'), ('among', 'IN'), ('one', 'CD'), ('persons', 'NNS'), ('based', 'VBN'), ('calculated', 'JJ'), ('sizes', 'NNS'), ('faces', 'VBZ'), ('controlling', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('direction', 'NN'), ('rotation', 'NN'), ('camera', 'NN'), ('angle', 'NN'), ('tilt', 'NN'), ('camera', 'NN'), ('focal', 'JJ'), ('distance', 'NN'), ('camera', 'NN'), ('based', 'VBN'), ('tracked', 'JJ'), ('motion', 'NN'), ('recognized', 'VBD'), ('face', 'NN'), ('first', 'RB'), ('person', 'NN'), ('method', 'NN'), ('inferring', 'VBG'), ('topics', 'NNS'), ('multimodal', 'VBP'), ('file', 'NN'), ('method', 'NN'), ('comprising', 'VBG'), ('receiving', 'VBG'), ('multimodal', 'NN'), ('file', 'NN'), ('extracting', 'VBG'), ('set', 'VBN'), ('entities', 'NNS'), ('multimodal', 'VBP'), ('file', 'NN'), ('linking', 'VBG'), ('set', 'VBN'), ('entities', 'NNS'), ('produce', 'VBP'), ('set', 'VBN'), ('linked', 'VBN'), ('entities', 'NNS'), ('obtaining', 'VBG'), ('reference', 'NN'), ('information', 'NN'), ('set', 'VBN'), ('entities', 'NNS'), ('based', 'VBN'), ('least', 'JJS'), ('reference', 'NN'), ('information', 'NN'), ('generating', 'VBG'), ('graph', 'NN'), ('set', 'VBN'), ('linked', 'VBN'), ('entities', 'NNS'), ('graph', 'VBP'), ('comprising', 'VBG'), ('nodes', 'NNS'), ('edges', 'NNS'), ('based', 'VBN'), ('least', 'JJS'), ('nodes', 'JJ'), ('edges', 'NNS'), ('graph', 'VBP'), ('determining', 'VBG'), ('clusters', 'NNS'), ('graph', 'VBP'), ('based', 'VBN'), ('least', 'JJS'), ('clusters', 'NNS'), ('graph', 'VBP'), ('identifying', 'VBG'), ('topic', 'NN'), ('candidates', 'NNS'), ('extracting', 'VBG'), ('features', 'NNS'), ('clusters', 'NNS'), ('graph', 'VBP'), ('based', 'VBN'), ('least', 'JJS'), ('extracted', 'JJ'), ('features', 'NNS'), ('selecting', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('topicid', 'NN'), ('among', 'IN'), ('topic', 'JJ'), ('candidates', 'NNS'), ('represent', 'VBP'), ('least', 'JJS'), ('one', 'CD'), ('cluster', 'NN'), ('indexing', 'VBG'), ('multimodal', 'NNS'), ('file', 'RB'), ('least', 'JJS'), ('one', 'CD'), ('topicid', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('multimodal', 'NN'), ('file', 'NN'), ('comprises', 'VBZ'), ('video', 'JJ'), ('portion', 'NN'), ('audio', 'NN'), ('portion', 'NN'), ('wherein', 'IN'), ('extracting', 'VBG'), ('set', 'NN'), ('entities', 'NNS'), ('multimodal', 'VBP'), ('file', 'NN'), ('comprises', 'NNS'), ('detecting', 'VBG'), ('objects', 'NNS'), ('video', 'JJ'), ('portion', 'NN'), ('multimodal', 'NN'), ('file', 'NN'), ('detecting', 'VBG'), ('text', 'JJ'), ('audio', 'JJ'), ('portion', 'NN'), ('multimodal', 'NN'), ('file', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('detecting', 'VBG'), ('objects', 'NNS'), ('comprises', 'VBZ'), ('performing', 'VBG'), ('face', 'NN'), ('recognition', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('detecting', 'VBG'), ('text', 'JJ'), ('comprises', 'NNS'), ('performing', 'VBG'), ('speech', 'NN'), ('text', 'NN'), ('process', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('identifying', 'JJ'), ('language', 'NN'), ('used', 'VBN'), ('audio', 'JJ'), ('portion', 'NN'), ('multimodal', 'NN'), ('file', 'NN'), ('wherein', 'NN'), ('performing', 'VBG'), ('speech', 'JJ'), ('text', 'NN'), ('process', 'NN'), ('comprises', 'VBZ'), ('performing', 'VBG'), ('speech', 'NN'), ('text', 'NN'), ('process', 'NN'), ('identified', 'VBN'), ('language', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('translating', 'VBG'), ('detected', 'VBN'), ('text', 'JJ'), ('method', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('determining', 'VBG'), ('significant', 'JJ'), ('clusters', 'NNS'), ('insignificant', 'JJ'), ('clusters', 'NNS'), ('determined', 'VBD'), ('clusters', 'NNS'), ('wherein', 'VBP'), ('extracting', 'VBG'), ('features', 'NNS'), ('clusters', 'NNS'), ('graph', 'VBP'), ('comprises', 'NNS'), ('extracting', 'VBG'), ('features', 'NNS'), ('significant', 'JJ'), ('clusters', 'NNS'), ('graph', 'VBP'), ('method', 'JJ'), ('claim', 'NN'), ('wherein', 'NN'), ('extracting', 'VBG'), ('features', 'NNS'), ('clusters', 'NNS'), ('graph', 'VBP'), ('comprises', 'NNS'), ('least', 'VBP'), ('one', 'CD'), ('process', 'NN'), ('selected', 'VBN'), ('list', 'NN'), ('consisting', 'VBG'), ('determining', 'VBG'), ('graph', 'JJ'), ('diameter', 'NN'), ('determining', 'VBG'), ('jaccard', 'JJ'), ('coefficient', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('selecting', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('topicid', 'JJ'), ('represent', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('cluster', 'NN'), ('comprises', 'NNS'), ('based', 'VBN'), ('least', 'RB'), ('extracted', 'JJ'), ('features', 'NNS'), ('mapping', 'VBG'), ('topic', 'NN'), ('candidates', 'NNS'), ('probability', 'NN'), ('interval', 'VBP'), ('based', 'VBN'), ('least', 'JJS'), ('mapping', 'VBG'), ('ranking', 'VBG'), ('topic', 'NN'), ('candidates', 'NNS'), ('within', 'IN'), ('least', 'JJS'), ('one', 'CD'), ('cluster', 'NN'), ('selecting', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('topicid', 'NN'), ('based', 'VBN'), ('least', 'JJS'), ('ranking', 'JJ'), ('method', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('translating', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('topicid', 'NN'), ('wherein', 'NN'), ('indexing', 'VBG'), ('multimodal', 'NNS'), ('file', 'RB'), ('least', 'JJS'), ('one', 'CD'), ('topicid', 'NN'), ('comprises', 'VBZ'), ('indexing', 'VBG'), ('multimodal', 'NNS'), ('file', 'RB'), ('least', 'JJS'), ('one', 'CD'), ('translated', 'VBN'), ('topicid', 'NN'), ('system', 'NN'), ('inferring', 'VBG'), ('topics', 'NNS'), ('multimodal', 'VBP'), ('file', 'NN'), ('system', 'NN'), ('comprising', 'VBG'), ('entity', 'NN'), ('extraction', 'NN'), ('component', 'NN'), ('comprising', 'VBG'), ('object', 'JJ'), ('detection', 'NN'), ('component', 'NN'), ('speech', 'NN'), ('text', 'JJ'), ('component', 'NN'), ('operative', 'JJ'), ('extract', 'NN'), ('set', 'VBN'), ('entities', 'NNS'), ('multimodal', 'VBP'), ('file', 'NN'), ('comprising', 'VBG'), ('video', 'JJ'), ('portion', 'NN'), ('audio', 'NN'), ('portion', 'NN'), ('entity', 'NN'), ('linking', 'VBG'), ('component', 'JJ'), ('operative', 'JJ'), ('link', 'NN'), ('extracted', 'VBD'), ('set', 'JJ'), ('entities', 'NNS'), ('produce', 'VBP'), ('set', 'VBN'), ('linked', 'VBN'), ('entities', 'NNS'), ('information', 'NN'), ('retrieval', 'NN'), ('component', 'NN'), ('operative', 'JJ'), ('obtain', 'VB'), ('reference', 'NN'), ('information', 'NN'), ('extracted', 'VBD'), ('set', 'NN'), ('entities', 'NNS'), ('graphing', 'VBG'), ('analysis', 'NN'), ('component', 'NN'), ('operative', 'JJ'), ('generate', 'NN'), ('graph', 'NN'), ('set', 'VBN'), ('linked', 'VBN'), ('entities', 'NNS'), ('graph', 'VBP'), ('comprising', 'VBG'), ('nodes', 'NNS'), ('edges', 'NNS'), ('based', 'VBN'), ('least', 'JJS'), ('nodes', 'JJ'), ('edges', 'NNS'), ('graph', 'VBP'), ('determine', 'JJ'), ('clusters', 'NNS'), ('graph', 'VBP'), ('based', 'VBN'), ('least', 'JJS'), ('clusters', 'NNS'), ('graph', 'VBP'), ('identify', 'VB'), ('topic', 'NN'), ('candidates', 'NNS'), ('extract', 'JJ'), ('features', 'NNS'), ('clusters', 'NNS'), ('graph', 'VBP'), ('topicid', 'JJ'), ('selection', 'NN'), ('component', 'NN'), ('operative', 'JJ'), ('rank', 'NN'), ('topic', 'NN'), ('candidates', 'NNS'), ('within', 'IN'), ('least', 'JJS'), ('one', 'CD'), ('cluster', 'NN'), ('based', 'VBN'), ('least', 'JJS'), ('ranking', 'JJ'), ('select', 'JJ'), ('least', 'JJS'), ('one', 'CD'), ('topicid', 'NN'), ('among', 'IN'), ('topic', 'JJ'), ('candidates', 'NNS'), ('represent', 'VBP'), ('least', 'JJS'), ('one', 'CD'), ('cluster', 'NN'), ('video', 'NN'), ('indexer', 'VBP'), ('operative', 'JJ'), ('index', 'NN'), ('multimodal', 'NNS'), ('file', 'IN'), ('least', 'JJS'), ('one', 'CD'), ('topicid', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('object', 'JJ'), ('detection', 'NN'), ('component', 'NN'), ('operative', 'JJ'), ('perform', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('speech', 'NN'), ('text', 'JJ'), ('component', 'NN'), ('operative', 'JJ'), ('extract', 'JJ'), ('entity', 'NN'), ('information', 'NN'), ('least', 'JJS'), ('two', 'CD'), ('different', 'JJ'), ('languages', 'NNS'), ('one', 'CD'), ('computer', 'NN'), ('storage', 'NN'), ('devices', 'NNS'), ('computer-executable', 'JJ'), ('instructions', 'NNS'), ('stored', 'VBD'), ('thereon', 'NN'), ('inferring', 'VBG'), ('topics', 'NNS'), ('multimodal', 'JJ'), ('file', 'NN'), ('execution', 'NN'), ('computer', 'NN'), ('cause', 'VBP'), ('computer', 'NN'), ('perform', 'NN'), ('operations', 'NNS'), ('comprising', 'VBG'), ('receiving', 'VBG'), ('multimodal', 'NN'), ('file', 'NN'), ('comprising', 'VBG'), ('video', 'JJ'), ('portion', 'NN'), ('audio', 'NN'), ('portion', 'NN'), ('extracting', 'VBG'), ('set', 'NN'), ('entities', 'NNS'), ('multimodal', 'VBP'), ('file', 'NN'), ('wherein', 'NN'), ('extracting', 'VBG'), ('set', 'VBN'), ('entities', 'NNS'), ('multimodal', 'VBP'), ('file', 'NN'), ('comprises', 'NNS'), ('detecting', 'VBG'), ('objects', 'NNS'), ('video', 'JJ'), ('portion', 'NN'), ('multimodal', 'NN'), ('file', 'NN'), ('face', 'NN'), ('recognition', 'NN'), ('detecting', 'VBG'), ('text', 'JJ'), ('audio', 'JJ'), ('portion', 'NN'), ('multimodal', 'NN'), ('file', 'NN'), ('speech', 'NN'), ('text', 'NN'), ('process', 'NN'), ('disambiguating', 'VBG'), ('among', 'IN'), ('set', 'VBN'), ('detected', 'VBN'), ('entity', 'NN'), ('names', 'NNS'), ('linking', 'VBG'), ('set', 'NN'), ('entities', 'NNS'), ('produce', 'VBP'), ('set', 'VBN'), ('linked', 'VBN'), ('entities', 'NNS'), ('obtaining', 'VBG'), ('reference', 'NN'), ('information', 'NN'), ('set', 'VBN'), ('entities', 'NNS'), ('based', 'VBN'), ('least', 'JJS'), ('reference', 'NN'), ('information', 'NN'), ('generating', 'VBG'), ('graph', 'NN'), ('set', 'VBN'), ('linked', 'VBN'), ('entities', 'NNS'), ('graph', 'VBP'), ('comprising', 'VBG'), ('nodes', 'NNS'), ('edges', 'NNS'), ('based', 'VBN'), ('least', 'JJS'), ('nodes', 'JJ'), ('edges', 'NNS'), ('graph', 'VBP'), ('determining', 'VBG'), ('clusters', 'NNS'), ('graph', 'VBP'), ('determining', 'VBG'), ('significant', 'JJ'), ('clusters', 'NNS'), ('insignificant', 'JJ'), ('clusters', 'NNS'), ('determined', 'VBD'), ('clusters', 'NNS'), ('based', 'VBN'), ('least', 'JJS'), ('significant', 'JJ'), ('clusters', 'NNS'), ('graph', 'VBP'), ('identifying', 'VBG'), ('topic', 'NN'), ('candidates', 'NNS'), ('extracting', 'VBG'), ('features', 'NNS'), ('significant', 'JJ'), ('clusters', 'NNS'), ('graph', 'VBP'), ('based', 'VBN'), ('least', 'JJS'), ('extracted', 'JJ'), ('features', 'NNS'), ('mapping', 'VBG'), ('topic', 'NN'), ('candidates', 'NNS'), ('probability', 'NN'), ('interval', 'VBP'), ('based', 'VBN'), ('least', 'JJS'), ('mapping', 'VBG'), ('ranking', 'VBG'), ('topic', 'NN'), ('candidates', 'NNS'), ('within', 'IN'), ('least', 'JJS'), ('one', 'CD'), ('significant', 'JJ'), ('cluster', 'NN'), ('based', 'VBN'), ('ranking', 'VBG'), ('selecting', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('topicid', 'NN'), ('among', 'IN'), ('topic', 'JJ'), ('candidates', 'NNS'), ('represent', 'VBP'), ('least', 'JJS'), ('one', 'CD'), ('significant', 'JJ'), ('cluster', 'NN'), ('indexing', 'VBG'), ('multimodal', 'NNS'), ('file', 'RB'), ('least', 'JJS'), ('one', 'CD'), ('topicid', 'NN'), ('one', 'CD'), ('computer', 'NN'), ('storage', 'NN'), ('devices', 'NNS'), ('claim', 'VBP'), ('wherein', 'JJ'), ('operations', 'NNS'), ('comprise', 'VBP'), ('identifying', 'VBG'), ('language', 'NN'), ('used', 'VBN'), ('audio', 'JJ'), ('portion', 'NN'), ('multimodal', 'NN'), ('file', 'NN'), ('detecting', 'VBG'), ('text', 'JJ'), ('audio', 'JJ'), ('portion', 'NN'), ('multimodal', 'NN'), ('file', 'NN'), ('speech', 'NN'), ('text', 'NN'), ('process', 'NN'), ('comprises', 'VBZ'), ('performing', 'VBG'), ('speech', 'NN'), ('text', 'NN'), ('process', 'NN'), ('identified', 'VBD'), ('language权利要求', 'JJ'), ('、', 'NNP'), ('一种人脸识别方法其特征在于包括', 'NNP'), ('通过第一摄像头获取第一人脸图像', 'NNP'), ('提取所述第一人脸图像的第一人脸特征', 'NNP'), ('将所述第一人脸特征与预先存储的第二人脸特征进行对比获得参考相似度所述第', 'NNP'), ('二人脸特征经第二摄像头获取的第二人脸图像的特征提取而得所述第二摄像头与所述第', 'NNP'), ('一摄像头属于不同类型的摄像头', 'NNP'), ('根据所述参考相似度确定所述第一人脸特征与所述第二人脸特征是否对应相同人。', 'NNP'), ('、', 'NNP'), ('根据权利要求', 'NNP'), ('所述的方法其特征在于', 'NNP'), ('所述第一摄像头为热成像摄像头所述第二摄像头为可见光摄像头', 'NNP'), ('或者所述第一摄像头为可见光摄像头所述第一摄像头为热成像摄像头。', 'NNP'), ('、', 'NNP'), ('根据权利要求', 'NNP'), ('或', 'NNP'), ('所述的方法其特征在于所述根据所述参考相似度确定所', 'NNP'), ('述第一人脸特征与所述第二人脸特征是否对应相同人包括', 'NNP'), ('根据所述参考相似度、', 'NNP'), ('参考误报率以及相似度阈值确定所述第一人脸特征与所述第二', 'NNP'), ('人脸特征是否对应相同人其中不同的误报率对应不同的相似度阈值。', 'NNP'), ('、', 'NNP'), ('根据权利要求', 'NNP'), ('或', 'NNP'), ('所述的方法其特征在于所述根据所述参考相似度确定所', 'NNP'), ('述第一人脸特征与所述第二人脸特征是否对应相同人包括', 'NNP'), ('根据所述参考相似度以及阈值信息确定归一化后的参考相似度', 'NNP'), ('根据所述归一化后的参考相似度确定所述第一人脸特征与所述第二人脸特征是否对', 'NNP'), ('应相同人。', 'NNP'), ('、', 'NNP'), ('根据权利要求', 'NNP'), ('-任一项所述的方法其特征在于所述提取所述第一人脸图像的', 'NNP'), ('第_人脸特征包括', 'NNP'), ('将所述第一人脸图像输入预先训练完成的神经网络通过所述神经网络输出所述第一', 'NNP'), ('人脸图像的第一人脸特征其中所述神经网络基于第一类型图像样本和第二类型图像样', 'NNP'), ('本训练得到所述第一类型图像样本和所述第二类型图像样本由不同类型的摄像头拍摄得', 'NNP'), ('到且所述第一类型图像样本和所述第二类型图像样本中包括人脸。', 'NNP'), ('、', 'NNP'), ('根据权利要求', 'NNP'), ('所述的方法其特征在于所述神经网络基于所述第一类型图像', 'NNP'), ('样本、', 'NNP'), ('所述第二类型图像样本和混合类型图像样本训练得到所述混合类型图像样本由所', 'NNP'), ('述第一类型图像样本和所述第二类型图像样本配对而得。', 'NNP'), ('、', 'NNP'), ('根据权利要求', 'NNP'), ('-任一项所述的方法其特征在于所述第一摄像头包括车载摄像', 'NNP'), ('头所述通过第一摄像头获取第一人脸图像包括', 'NNP'), ('通过所述车载摄像头获取所述第一人脸图像所述第一人脸图像包括车辆的用车人的', 'NNP'), ('人脸图像。', 'NNP'), ('、', 'NNP'), ('根据权利要求', 'NNP'), ('所述的方法其特征在于所述用车人包括驾驶所述车辆的人、', 'NNP'), ('乘坐所述车辆的人、', 'NNP'), ('对所述车辆进行修理的人、', 'NNP'), ('给所述车辆加油的人以及控制所述车辆的', 'NNP'), ('人中的一项或多项。', 'NNP'), ('、', 'NNP'), ('根据权利要求', 'NNP'), ('所述的方法其特征在于所述用车人包括驾驶所述车辆的人', 'NNP'), ('所述通过所述车载摄像头获取所述第一人脸图像包括', 'NNP'), ('在接收到触发指令的情况下通过所述车载摄像头获取所述第一人脸图像', 'NNP'), ('或者在所述车辆运行时通过所述车载摄像头获取所述第一人脸图像', 'NNP'), ('或者在所述车辆的运行速度达到参考速度的情况下通过所述车载摄像头获取所述', 'NNP'), ('第一人脸图像。', 'NNP'), ('、', 'NNP'), ('根据权利要求', 'NNP'), ('-任一项所述的方法其特征在于所述第二人脸图像为对所述', 'NNP'), ('用车人进行人脸注册的图像所述将所述第一人脸特征与预先存储的第二人脸特征进行对', 'NNP'), ('比之前所述方法还包括', 'NNP'), ('通过所述第二摄像头获取所述第二人脸图像', 'NNP'), ('提取所述第二人脸图像的第二人脸特征', 'NNP'), ('保存所述第二人脸图像的第二人脸特征。', 'NNP'), ('、', 'NNP'), ('一种神经网络训练方法其特征在于包括', 'NNP'), ('获取第一类型图像样本和第二类型图像样本所述第一类型图像样本和所述第二类型', 'NNP'), ('图像样本由不同类型的摄像头拍摄得到且所述第一类型图像样本和所述第二类型图像样', 'NNP'), ('本中包括人脸', 'NNP'), ('根据所述第一类型图像样本和所述第二类型图像样本训练神经网络。', 'NNP'), ('、', 'NNP'), ('根据权利要求', 'NNP'), ('所述的方法其特征在于所述根据所述第一类型图像样本和所', 'NNP'), ('述第二类型图像样本训练神经网络包括', 'NNP'), ('将所述第一类型图像样本和所述第二类型图像样本配对得到所述第一类型图像样本', 'NNP'), ('和所述第二类型图像样本的混合类型图像样本', 'NNP'), ('根据所述第一类型图像样本、', 'NNP'), ('所述第二类型图像样本和所述混合类型图像样本训练', 'NNP'), ('所述神经网络。', 'NNP'), ('、', 'NNP'), ('根据权利要求', 'NNP'), ('所述的方法其特征在于所述根据所述第一类型图像样本、', 'NNP'), ('所述第二类型图像样本和所述混合类型图像样本训练所述神经网络包括', 'NNP'), ('通过所述神经网络获取所述第一类型图像样本的人脸预测结果、', 'NNP'), ('所述第二类型图像样', 'NNP'), ('本的人脸预测结果和所述混合类型图像样本的人脸预测结果', 'NNP'), ('根据所述第一类型图像样本的人脸预测结果和人脸标注结果的差异、', 'NNP'), ('所述第二类型图', 'NNP'), ('像样本的人脸预测结果和人脸标注结果之间的差异、', 'NNP'), ('以及所述混合类型图像样本的人脸预', 'NNP'), ('测结果和人脸标注结果的差异训练所述神经网络。', 'NNP'), ('、', 'NNP'), ('根据权利要求', 'NNP'), ('所述的方法其特征在于所述神经网络中包括第一分类器、', 'NNP'), ('第二分类器和混合分类器所述通过所述神经网络获取所述第一类型图像样本的人脸预测', 'NNP'), ('结果、', 'NNP'), ('所述第二类型图像样本的人脸预测结果和所述混合类型图像样本的人脸预测结果', 'NNP'), ('包括', 'NNP'), ('将所述第一类型图像样本的人脸特征输入至所述第一分类器中得到所述第一类型图', 'NNP'), ('像样本的人脸预测结果', 'NNP'), ('将所述第二类型图像样本的人脸特征输入至所述第二分类器中得到所述第二类型图', 'NNP'), ('像样本的人脸预测结果', 'NNP'), ('将所述混合类型图像样本的人脸特征输入至所述混合分类器中得到所述混合类型图', 'NNP'), ('像样本的人脸预测结果。', 'NNP'), ('、', 'NNP'), ('根据权利要求', 'NNP'), ('所述的方法其特征在于所述方法还包括', 'NNP'), ('在训练完成的所述神经网络中去除所述第一分类器、', 'NNP'), ('所述第二分类器和所述混合分类', 'NNP'), ('器得到用于进行人脸识别的神经网络。', 'NNP'), ('、', 'NNP'), ('一种人脸识别装置其特征在于包括', 'NNP'), ('第一获取单元用于通过第一摄像头获取第一人脸图像', 'NNP'), ('第一提取单元用于提取所述第一人脸图像的第一人脸特征', 'NNP'), ('对比单元用于将所述第一人脸特征与预先存储的第二人脸特征进行对比获得参考', 'NNP'), ('相似度所述第二人脸特征经第二摄像头获取的第二人脸图像的特征提取而得所述第二', 'NNP'), ('摄像头与所述第一摄像头属于不同类型的摄像头', 'NNP'), ('确定单元用于根据所述参考相似度确定所述第一人脸特征与所述第二人脸特征是否', 'NNP'), ('对应相同人。', 'NNP'), ('、', 'NNP'), ('根据权利要求', 'NNP'), ('所述的装置其特征在于', 'NNP'), ('所述第一摄像头为热成像摄像头所述第二摄像头为可见光摄像头', 'NNP'), ('或者所述第一摄像头为可见光摄像头所述第一摄像头为热成像摄像头。', 'NNP'), ('、', 'NNP'), ('根据权利要求', 'NNP'), ('或', 'NNP'), ('所述的装置其特征在于', 'NNP'), ('所述确定单元具体用于根据所述参考相似度、', 'NNP'), ('参考误报率以及相似度阈值确定所述', 'NNP'), ('第一人脸特征与所述第二人脸特征是否对应相同人其中不同的误报率对应不同的相似', 'NNP'), ('度阈值。', 'NNP'), ('、', 'NNP'), ('根据权利要求', 'NNP'), ('或', 'NNP'), ('所述的装置其特征在于', 'NNP'), ('所述确定单元具体用于根据所述参考相似度以及阈值信息确定归一化后的参考相似', 'NNP'), ('度以及根据所述归一化后的参考相似度确定所述第一人脸特征与所述第二人脸特征是否', 'NNP'), ('对应相同人。', 'NNP'), ('、', 'NNP'), ('根据权利要求', 'NNP'), ('-任_项所述的装置其特征在于', 'NNP'), ('所述第一提取单元具体用于将所述第一人脸图像输入预先训练完成的神经网络通', 'NNP'), ('过所述神经网络输出所述第一人脸图像的第一人脸特征其中所述神经网络基于第一类', 'NNP'), ('型图像样本和第二类型图像样本训练得到所述第一类型图像样本和所述第二类型图像样', 'NNP'), ('本由不同类型的摄像头拍摄得到且所述第一类型图像样本和所述第二类型图像样本中包', 'NNP'), ('括人脸。', 'NNP'), ('、', 'NNP'), ('根据权利要求', 'NNP'), ('所述的装置其特征在于所述神经网络基于所述第一类型图', 'NNP'), ('像样本、', 'NNP'), ('所述第二类型图像样本和混合类型图像样本训练得到所述混合类型图像样本由', 'NNP'), ('所述第一类型图像样本和所述第二类型图像样本配对而得。', 'NNP'), ('、', 'NNP'), ('根据权利要求', 'NNP'), ('-任一项所述的装置其特征在于所述第一摄像头包括车载', 'NNP'), ('摄像头', 'NNP'), ('所述第一获取单元具体用于通过所述车载摄像头获取所述第一人脸图像所述第一', 'NNP'), ('人脸图像包括车辆的用车人的人脸图像。', 'NNP'), ('、', 'NNP'), ('根据权利要求', 'NNP'), ('所述的装置其特征在于所述用车人包括驾驶所述车辆的人、', 'NNP'), ('乘坐所述车辆的人、', 'NNP'), ('对所述车辆进行修理的人、', 'NNP'), ('给所述车辆加油的人以及控制所述车辆的', 'NNP'), ('人中的一项或多项。', 'NNP'), ('、', 'NNP'), ('根据权利要求', 'NNP'), ('所述的装置其特征在于所述用车人包括驾驶所述车辆的人', 'NNP'), ('所述第一获取单元具体用于在接收到触发指令的情况下通过所述车载摄像头获取所述', 'NNP'), ('第一人脸图像', 'NNP'), ('或者所述第一获取单元具体用于在所述车辆运行时通过所述车载摄像头获取所', 'NNP'), ('述第', 'NNP'), ('_人脸图像', 'NNP'), ('或者所述第一获取单元具体用于在所述车辆的运行速度达到参考速度的情况下', 'NNP'), ('通过所述车载摄像头获取所述第一人脸图像。', 'NNP'), ('、', 'NNP'), ('根据权利要求', 'NNP'), ('-任一项所述的装置其特征在于所述第二人脸图像为对所', 'NNP'), ('述用车人进行人脸注册的图像所述装置还包括', 'NNP'), ('第二获取单元用于通过所述第二摄像头获取所述第二人脸图像', 'NNP'), ('第二提取单元用于提取所述第二人脸图像的第二人脸特征', 'NNP'), ('保存单元用于保存所述第二人脸图像的第二人脸特征。', 'NNP'), ('、', 'NNP'), ('一种神经网络训练装置其特征在于包括', 'NNP'), ('获取单元用于获取第一类型图像样本和第二类型图像样本所述第一类型图像样本', 'NNP'), ('和所述第二类型图像样本由不同类型的摄像头拍摄得到且所述第一类型图像样本和所述', 'NNP'), ('第二类型图像样本中包括人脸', 'NNP'), ('训练单元用于根据所述第一类型图像样本和所述第二类型图像样本训练神经网络。', 'NNP'), ('、', 'NNP'), ('根据权利要求', 'NNP'), ('所述的装置其特征在于所述训练单元包括', 'NNP'), ('配对子单元用于将所述第一类型图像样本和所述第二类型图像样本配对得到所述', 'NNP'), ('第一类型图像样本和所述第二类型图像样本的混合类型图像样本', 'NNP'), ('训练子单元用于根据所述第一类型图像样本、', 'NNP'), ('所述第二类型图像样本和所述混合类', 'NNP'), ('型图像样本训练所述神经网络。', 'NNP'), ('、', 'NNP'), ('根据权利要求', 'NNP'), ('所述的装置其特征在于', 'NNP'), ('所述训练子单元具体用于通过所述神经网络获取所述第一类型图像样本的人脸预测', 'NNP'), ('结果、', 'NNP'), ('所述第二类型图像样本的人脸预测结果和所述混合类型图像样本的人脸预测结果', 'NNP'), ('以及根据所述第一类型图像样本的人脸预测结果和人脸标注结果的差异、', 'NNP'), ('所述第二类型图', 'NNP'), ('像样本的人脸预测结果和人脸标注结果之间的差异、', 'NNP'), ('以及所述混合类型图像样本的人脸预', 'NNP'), ('测结果和人脸标注结果的差异训练所述神经网络。', 'NNP'), ('、', 'NNP'), ('根据权利要求', 'NNP'), ('所述的装置其特征在于所述神经网络中包括第一分类器、', 'NNP'), ('第二分类器和混合分类器', 'NNP'), ('所述训练子单元具体用于将所述第一类型图像样本的人脸特征输入至所述第一分类', 'NNP'), ('器中得到所述第一类型图像样本的人脸预测结果以及将所述第二类型图像样本的人脸', 'NNP'), ('特征输入至所述第二分类器中得到所述第二类型图像样本的人脸预测结果以及将所述', 'NNP'), ('混合类型图像样本的人脸特征输入至所述混合分类器中得到所述混合类型图像样本的人', 'NNP'), ('脸预测结果。', 'NNP'), ('、', 'NNP'), ('根据权利要求', 'NNP'), ('所述的装置其特征在于所述装置还包括', 'NNP'), ('神经网络应用单元用于在训练完成的所述神经网络中去除所述第一分类器、', 'NNP'), ('所述第', 'NNP'), ('二分类器和所述混合分类器得到用于进行人脸识别的神经网络。', 'NNP'), ('、', 'NNP'), ('一种电子设备其特征在于包括处理器和存储器所述处理器和所述存储器耦', 'NNP'), ('合其中所述存储器用于存储程序指令所述程序指令被所述处理器执行时使所述处', 'NNP'), ('理器执行权利要求', 'NNP'), ('-任一项所述的方法和或使所述处理器执行权利要求', 'NNP'), ('-任一', 'NNP'), ('项所述的方法。', 'NNP'), ('、', 'NNP'), ('一种计算机可读存储介质其特征在于所述计算机可读存储介质中存储有计算', 'NNP'), ('机程序所述计算机程序包括程序指令所述程序指令当被处理器执行时使所述处理器', 'NNP'), ('执行权利要求', 'NNP'), ('-任一项所述的方法和或使所述处理器执行权利要求', 'NNP'), ('-任一项所', 'NNP'), ('述的方法。', 'NNP'), ('system', 'NN'), ('alerting', 'VBG'), ('vision', 'NN'), ('impairment', 'NN'), ('said', 'VBD'), ('system', 'NN'), ('comprising', 'VBG'), ('processing', 'VBG'), ('unit', 'NN'), ('configured', 'VBD'), ('operable', 'JJ'), ('receiving', 'VBG'), ('scene', 'NN'), ('data', 'NNS'), ('indicative', 'JJ'), ('scene', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('consumer', 'NN'), ('environment', 'NN'), ('identifying', 'VBG'), ('scene', 'NN'), ('data', 'NNS'), ('certain', 'JJ'), ('consumer', 'NN'), ('identifying', 'VBG'), ('event', 'NN'), ('indicative', 'JJ'), ('behavioral', 'JJ'), ('compensation', 'NN'), ('vision', 'NN'), ('impairment', 'NN'), ('upon', 'IN'), ('identification', 'NN'), ('event', 'NN'), ('sending', 'VBG'), ('notification', 'NN'), ('relating', 'VBG'), ('vision', 'NN'), ('impairment', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('sensing', 'VBG'), ('unit', 'NN'), ('configured', 'VBD'), ('operable', 'JJ'), ('detecting', 'VBG'), ('scene', 'NN'), ('data', 'NNS'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('said', 'VBD'), ('least', 'JJS'), ('one', 'CD'), ('sensing', 'VBG'), ('unit', 'NN'), ('comprises', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('least', 'JJS'), ('one', 'CD'), ('imaging', 'VBG'), ('unit', 'NN'), ('configured', 'VBD'), ('operable', 'JJ'), ('capturing', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('image', 'NN'), ('least', 'JJS'), ('portion', 'NN'), ('consumer', 'NN'), (\"'s\", 'POS'), ('body', 'NN'), ('least', 'VBD'), ('one', 'CD'), ('motion', 'NN'), ('detector', 'NN'), ('configured', 'VBD'), ('operable', 'JJ'), ('detecting', 'VBG'), ('consumer', 'NN'), ('data', 'NNS'), ('indicative', 'JJ'), ('motion', 'NN'), ('consumer', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('eye', 'NN'), ('tracker', 'NN'), ('configured', 'VBD'), ('operable', 'JJ'), ('tracking', 'VBG'), ('eye', 'NN'), ('motion', 'NN'), ('consumer', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('least', 'JJS'), ('one', 'CD'), ('imaging', 'VBG'), ('unit', 'NN'), ('comprises', 'VBZ'), ('plurality', 'NN'), ('cameras', 'NNS'), ('placed', 'VBD'), ('different', 'JJ'), ('heights', 'NNS'), ('system', 'NN'), ('one', 'CD'), ('claims', 'VBZ'), ('wherein', 'NN'), ('said', 'VBD'), ('sensing', 'VBG'), ('unit', 'NN'), ('accommodated', 'VBD'), ('optical', 'JJ'), ('digital', 'JJ'), ('eyewear', 'NN'), ('frame', 'NN'), ('display', 'NN'), ('system', 'NN'), ('one', 'CD'), ('claims', 'VBZ'), ('wherein', 'NN'), ('said', 'VBD'), ('processing', 'NN'), ('unit', 'NN'), ('configured', 'VBD'), ('operable', 'JJ'), ('identifying', 'VBG'), ('consumer', 'NN'), (\"'s\", 'POS'), ('condition', 'NN'), ('said', 'VBD'), ('consumer', 'NN'), (\"'s\", 'POS'), ('condition', 'NN'), ('comprising', 'VBG'), ('consumer', 'NN'), ('data', 'NNS'), ('indicative', 'JJ'), ('consumer', 'NN'), (\"'s\", 'POS'), ('position', 'NN'), ('location', 'NN'), ('relative', 'JJ'), ('least', 'JJS'), ('one', 'CD'), ('object', 'JJ'), ('consumer', 'NN'), (\"'s\", 'POS'), ('environment', 'NN'), ('said', 'VBD'), ('consumer', 'NN'), ('data', 'NNS'), ('comprises', 'NNS'), ('least', 'VBP'), ('one', 'CD'), ('consumer', 'NN'), (\"'s\", 'POS'), ('face', 'NN'), ('eyewear', 'JJ'), ('posture', 'NN'), ('position', 'NN'), ('sound', 'NN'), ('motion', 'NN'), ('system', 'NN'), ('one', 'CD'), ('claims', 'VBZ'), ('wherein', 'NN'), ('said', 'VBD'), ('event', 'NN'), ('comprises', 'NNS'), ('least', 'VBP'), ('one', 'CD'), ('position', 'NN'), ('orientation', 'NN'), ('head', 'NN'), ('increase', 'NN'), ('decrease', 'NN'), ('viewing', 'VBG'), ('distance', 'NN'), ('consumer', 'NN'), ('viewed', 'VBD'), ('object', 'JJ'), ('changing', 'VBG'), ('position', 'NN'), ('eyeglasses', 'NNS'), ('worn', 'JJ'), ('consumer', 'NN'), ('system', 'NN'), ('one', 'CD'), ('claims', 'VBZ'), ('wherein', 'NN'), ('said', 'VBD'), ('event', 'NN'), ('identified', 'VBN'), ('identifying', 'NN'), ('images', 'NNS'), ('image', 'NN'), ('feature', 'NN'), ('indicative', 'JJ'), ('behavioral', 'JJ'), ('compensation', 'NN'), ('performing', 'VBG'), ('bruckner', 'JJ'), ('test', 'NN'), ('performing', 'VBG'), ('hirschberg', 'JJ'), ('test', 'NN'), ('measuring', 'VBG'), ('blink', 'NN'), ('count', 'NN'), ('frequency', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('image', 'NN'), ('feature', 'NN'), ('indicative', 'JJ'), ('behavioral', 'JJ'), ('compensation', 'NN'), ('comprises', 'NNS'), ('squinting', 'VBG'), ('head', 'NN'), ('orientation', 'NN'), ('certain', 'JJ'), ('distances', 'NNS'), ('object', 'VBP'), ('consumer', 'NN'), (\"'s\", 'POS'), ('eyes', 'NNS'), ('certain', 'JJ'), ('position', 'NN'), ('eyeglasses', 'VBZ'), ('consumer', 'NN'), (\"'s\", 'POS'), ('face', 'NN'), ('strabismus', 'NN'), ('cataracts', 'VBZ'), ('reflections', 'NNS'), ('eye', 'NN'), ('system', 'NN'), ('one', 'CD'), ('claims', 'VBZ'), ('wherein', 'NN'), ('notification', 'NN'), ('includes', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('data', 'NN'), ('indicative', 'NN'), ('identified', 'VBN'), ('event', 'NN'), ('data', 'NNS'), ('indicative', 'JJ'), ('identified', 'JJ'), ('consumer', 'NN'), ('ophthalmologic', 'NN'), ('recommendations', 'NNS'), ('based', 'VBN'), ('identified', 'JJ'), ('event', 'NN'), ('lack', 'NN'), ('events', 'NNS'), ('appointment', 'JJ'), ('vision', 'NN'), ('test', 'NN'), ('system', 'NN'), ('one', 'CD'), ('claims', 'VBZ'), ('wherein', 'NN'), ('said', 'VBD'), ('processing', 'NN'), ('unit', 'NN'), ('comprises', 'VBZ'), ('memory', 'NN'), ('storing', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('reference', 'NN'), ('data', 'NNS'), ('indicative', 'JJ'), ('behavioral', 'JJ'), ('compensation', 'NN'), ('vision', 'NN'), ('impairment', 'NN'), ('data', 'NNS'), ('indicative', 'JJ'), ('notification', 'NN'), ('data', 'NNS'), ('indicative', 'JJ'), ('follow-up', 'JJ'), ('notification', 'NN'), ('system', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('said', 'VBD'), ('processing', 'NN'), ('unit', 'NN'), ('configured', 'VBD'), ('least', 'JJS'), ('one', 'CD'), ('identifying', 'VBG'), ('event', 'NN'), ('upon', 'IN'), ('comparison', 'NN'), ('detected', 'VBN'), ('data', 'NNS'), ('reference', 'NN'), ('data', 'NNS'), ('determining', 'VBG'), ('probability', 'NN'), ('vision', 'NN'), ('impairment', 'JJ'), ('consumer', 'NN'), ('based', 'VBN'), ('comparison', 'NN'), ('system', 'NN'), ('one', 'CD'), ('claims', 'VBZ'), ('wherein', 'NN'), ('said', 'VBD'), ('processing', 'NN'), ('unit', 'NN'), ('comprises', 'VBZ'), ('communication', 'NN'), ('interface', 'NN'), ('configured', 'VBD'), ('sending', 'VBG'), ('notification', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('identified', 'JJ'), ('consumer', 'NN'), ('third', 'NNP'), ('party', 'NN'), ('system', 'NN'), ('one', 'CD'), ('claims', 'VBZ'), ('wherein', 'NN'), ('said', 'VBD'), ('processing', 'NN'), ('unit', 'NN'), ('configured', 'VBD'), ('providing', 'VBG'), ('frame', 'NN'), ('recommendation', 'NN'), ('system', 'NN'), ('one', 'CD'), ('claims', 'VBZ'), ('wherein', 'NN'), ('said', 'VBD'), ('memory', 'NN'), ('configured', 'VBD'), ('storing', 'JJ'), ('database', 'NN'), ('including', 'VBG'), ('multiplicity', 'NN'), ('data', 'NNS'), ('sets', 'NNS'), ('related', 'JJ'), ('plurality', 'NN'), ('spectacle', 'NN'), ('frame', 'NN'), ('models', 'NNS'), ('sizes', 'VBZ'), ('system', 'NN'), ('according', 'VBG'), ('claim', 'NN'), ('wherein', 'NN'), ('said', 'VBD'), ('processing', 'NN'), ('unit', 'NN'), ('configured', 'VBD'), ('operable', 'JJ'), ('correlate', 'NN'), ('frames', 'NNS'), ('parameters', 'NNS'), ('ophthalmic', 'VBP'), ('prescriptions', 'NNS'), ('system', 'NN'), ('according', 'VBG'), ('claims', 'NNS'), ('wherein', 'NN'), ('said', 'VBD'), ('processing', 'NN'), ('unit', 'NN'), ('configured', 'VBD'), ('operable', 'JJ'), ('correlate', 'NN'), ('frames', 'NNS'), ('parameters', 'NNS'), ('facial', 'JJ'), ('features', 'NNS'), ('system', 'NN'), ('according', 'VBG'), ('claims', 'NNS'), ('wherein', 'NN'), ('said', 'VBD'), ('processing', 'NN'), ('unit', 'NN'), ('configured', 'VBD'), ('operable', 'JJ'), ('correlate', 'NN'), ('frames', 'NNS'), ('parameters', 'NNS'), ('eyewear', 'VBP'), ('preferences', 'NNS'), ('system', 'NN'), ('according', 'VBG'), ('claims', 'NNS'), ('comprising', 'VBG'), ('server', 'RB'), ('least', 'JJS'), ('one', 'CD'), ('computer', 'NN'), ('entity', 'NN'), ('linked', 'VBN'), ('server', 'RB'), ('via', 'IN'), ('network', 'NN'), ('wherein', 'NN'), ('said', 'VBD'), ('network', 'NN'), ('configured', 'VBD'), ('receive', 'JJ'), ('respond', 'NN'), ('requests', 'NNS'), ('sent', 'VBD'), ('across', 'IN'), ('network', 'NN'), ('transmitting', 'VBG'), ('one', 'CD'), ('modules', 'NNS'), ('computer', 'NN'), ('executable', 'JJ'), ('program', 'NN'), ('instructions', 'NNS'), ('displayable', 'JJ'), ('data', 'NNS'), ('network', 'NN'), ('connected', 'VBN'), ('user', 'RB'), ('computer', 'NN'), ('platform', 'NN'), ('response', 'NN'), ('request', 'NN'), ('wherein', 'NN'), ('said', 'VBD'), ('modules', 'NNS'), ('include', 'VBP'), ('modules', 'NNS'), ('configured', 'VBD'), ('receive', 'JJ'), ('transmit', 'NN'), ('image', 'NN'), ('information', 'NN'), ('transmitting', 'VBG'), ('frame', 'NN'), ('recommendation', 'NN'), ('optical', 'JJ'), ('lens', 'VBZ'), ('option', 'NN'), ('recommendation', 'NN'), ('based', 'VBN'), ('received', 'VBN'), ('image', 'NN'), ('information', 'NN'), ('display', 'NN'), ('network', 'NN'), ('connected', 'VBN'), ('user', 'RB'), ('computer', 'NN'), ('platform', 'NN'), ('computer', 'NN'), ('program', 'NN'), ('instructions', 'NNS'), ('stored', 'VBD'), ('local', 'JJ'), ('storage', 'NN'), ('executed', 'VBD'), ('processing', 'VBG'), ('unit', 'NN'), ('cause', 'NN'), ('processing', 'VBG'), ('unit', 'NN'), ('receive', 'JJ'), ('data', 'NNS'), ('indicative', 'JJ'), ('scene', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('consumer', 'NN'), ('environment', 'NN'), ('identify', 'VB'), ('data', 'NNS'), ('certain', 'JJ'), ('consumer', 'NN'), ('identify', 'VB'), ('event', 'NN'), ('indicative', 'JJ'), ('behavioral', 'JJ'), ('compensation', 'NN'), ('vision', 'NN'), ('impairment', 'NN'), ('upon', 'IN'), ('identification', 'NN'), ('event', 'NN'), ('send', 'VB'), ('notification', 'NN'), ('relating', 'VBG'), ('vision', 'NN'), ('impairment', 'JJ'), ('computer', 'NN'), ('program', 'NN'), ('product', 'NN'), ('stored', 'VBD'), ('tangible', 'JJ'), ('computer', 'NN'), ('readable', 'JJ'), ('medium', 'NN'), ('comprising', 'VBG'), ('library', 'JJ'), ('software', 'NN'), ('modules', 'NNS'), ('cause', 'VBP'), ('computer', 'NN'), ('executing', 'VBG'), ('prompt', 'JJ'), ('information', 'NN'), ('pertinent', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('eyeglasses', 'VBZ'), ('recommendation', 'NN'), ('optical', 'JJ'), ('lens', 'VBZ'), ('option', 'NN'), ('recommendation', 'NN'), ('store', 'NN'), ('said', 'VBD'), ('information', 'NN'), ('display', 'NN'), ('eyewear', 'VBP'), ('recommendations', 'NNS'), ('computer', 'NN'), ('program', 'NN'), ('product', 'NN'), ('claim', 'NN'), ('wherein', 'NN'), ('said', 'VBD'), ('library', 'JJ'), ('comprises', 'NNS'), ('module', 'NN'), ('frame', 'NN'), ('selection', 'NN'), ('point', 'NN'), ('sales', 'NNS'), ('advertising', 'VBG'), ('computer', 'NN'), ('platform', 'NN'), ('facilitating', 'VBG'), ('eye', 'NN'), ('glasses', 'NNS'), ('marketing', 'VBG'), ('selection', 'NN'), ('comprising', 'VBG'), ('camera', 'NN'), ('processor', 'NN'), ('configured', 'VBD'), ('execute', 'JJ'), ('computer', 'NN'), ('program', 'NN'), ('instructions', 'NNS'), ('cause', 'VBP'), ('processor', 'NN'), ('take', 'VB'), ('image', 'NN'), ('consumer', 'NN'), ('identify', 'VB'), ('image', 'NN'), ('certain', 'JJ'), ('consumer', 'NN'), ('identify', 'VB'), ('event', 'NN'), ('indicative', 'JJ'), ('behavioral', 'JJ'), ('compensation', 'NN'), ('vision', 'NN'), ('impairment', 'NN'), ('upon', 'IN'), ('identification', 'NN'), ('event', 'NN'), ('sending', 'VBG'), ('notification', 'NN'), ('relating', 'VBG'), ('vision', 'NN'), ('impairment', 'JJ'), ('local', 'JJ'), ('storage', 'NN'), ('processor', 'NN'), ('executable', 'JJ'), ('instructions', 'NNS'), ('carrying', 'VBG'), ('storage', 'NN'), ('information', 'NN'), ('method', 'NN'), ('alerting', 'VBG'), ('vision', 'NN'), ('impairment', 'NN'), ('said', 'VBD'), ('method', 'JJ'), ('comprising', 'VBG'), ('identifying', 'VBG'), ('certain', 'JJ'), ('individual', 'JJ'), ('scene', 'NN'), ('data', 'NNS'), ('indicative', 'JJ'), ('scene', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('consumer', 'NN'), ('environment', 'NN'), ('identifying', 'VBG'), ('event', 'NN'), ('indicative', 'JJ'), ('behavioral', 'JJ'), ('compensation', 'NN'), ('vision', 'NN'), ('impairment', 'NN'), ('upon', 'IN'), ('identification', 'NN'), ('event', 'NN'), ('sending', 'VBG'), ('notification', 'NN'), ('vision', 'NN'), ('impairment', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('detecting', 'VBG'), ('data', 'NNS'), ('indicative', 'JJ'), ('scene', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('consumer', 'NN'), ('retail', 'JJ'), ('environment', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('detecting', 'VBG'), ('data', 'NNS'), ('indicative', 'JJ'), ('least', 'JJS'), ('one', 'CD'), ('consumer', 'NN'), ('comprises', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('capturing', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('image', 'NN'), ('least', 'VBD'), ('one', 'CD'), ('consumer', 'NN'), ('detecting', 'VBG'), ('data', 'NNS'), ('indicative', 'JJ'), ('motion', 'NN'), ('consumer', 'NN'), ('tracking', 'VBG'), ('eye', 'NN'), ('motion', 'NN'), ('consumer', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'IN'), ('capturing', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('image', 'NN'), ('least', 'VBD'), ('one', 'CD'), ('consumer', 'NN'), ('comprises', 'VBZ'), ('continuously', 'RB'), ('recording', 'VBG'), ('scene', 'NN'), ('method', 'NN'), ('one', 'CD'), ('claims', 'VBZ'), ('comprising', 'VBG'), ('identifying', 'VBG'), ('data', 'NNS'), ('consumer', 'NN'), (\"'\", 'POS'), ('condition', 'NN'), ('including', 'VBG'), ('data', 'NNS'), ('indicative', 'JJ'), ('consumer', 'NN'), (\"'s\", 'POS'), ('position', 'NN'), ('location', 'NN'), ('relative', 'JJ'), ('consumer', 'NN'), (\"'s\", 'POS'), ('environment', 'NN'), ('said', 'VBD'), ('data', 'NNS'), ('comprising', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('consumer', 'NN'), (\"'s\", 'POS'), ('face', 'NN'), ('posture', 'NN'), ('position', 'NN'), ('sound', 'NN'), ('motion', 'NN'), ('method', 'NN'), ('one', 'CD'), ('claims', 'VBZ'), ('wherein', 'NN'), ('said', 'VBD'), ('event', 'NN'), ('comprises', 'NNS'), ('least', 'VBP'), ('one', 'CD'), ('position', 'NN'), ('orientation', 'NN'), ('head', 'NN'), ('increase', 'NN'), ('decrease', 'NN'), ('viewing', 'VBG'), ('distance', 'NN'), ('consumer', 'NN'), ('viewed', 'VBD'), ('object', 'JJ'), ('changing', 'VBG'), ('position', 'NN'), ('eyeglasses', 'NNS'), ('worn', 'JJ'), ('consumer', 'NN'), ('method', 'NN'), ('one', 'CD'), ('claims', 'VBZ'), ('wherein', 'NN'), ('identifying', 'VBG'), ('event', 'NN'), ('comprises', 'NNS'), ('identifying', 'VBG'), ('images', 'NNS'), ('image', 'NN'), ('feature', 'NN'), ('indicative', 'JJ'), ('behavioral', 'JJ'), ('compensation', 'NN'), ('performing', 'VBG'), ('bruckner', 'JJ'), ('test', 'NN'), ('performing', 'VBG'), ('hirschberg', 'JJ'), ('test', 'NN'), ('measuring', 'VBG'), ('blink', 'NN'), ('countfrequency', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('wherein', 'WRB'), ('image', 'NN'), ('feature', 'NN'), ('indicative', 'JJ'), ('behavioral', 'JJ'), ('compensation', 'NN'), ('comprises', 'NNS'), ('squinting', 'VBG'), ('head', 'NN'), ('orientation', 'NN'), ('certain', 'JJ'), ('distances', 'NNS'), ('object', 'VBP'), ('consumer', 'NN'), (\"'s\", 'POS'), ('eyes', 'NNS'), ('certain', 'JJ'), ('position', 'NN'), ('eyeglasses', 'VBZ'), ('consumer', 'NN'), (\"'s\", 'POS'), ('face', 'NN'), ('strabismus', 'NN'), ('cataracts', 'VBZ'), ('reflections', 'NNS'), ('eye', 'NN'), ('method', 'VBP'), ('one', 'CD'), ('claims', 'NNS'), ('wherein', 'VBP'), ('identifying', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('image', 'NN'), ('consumer', 'NN'), ('retail', 'JJ'), ('environment', 'NN'), ('comprising', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('receiving', 'VBG'), ('data', 'NNS'), ('characterizing', 'VBG'), ('retail', 'JJ'), ('environment', 'NN'), ('performing', 'VBG'), ('face', 'NN'), ('recognition', 'NN'), ('method', 'FW'), ('one', 'CD'), ('claims', 'NNS'), ('wherein', 'VBP'), ('sending', 'VBG'), ('notification', 'NN'), ('comprising', 'VBG'), ('sending', 'VBG'), ('notification', 'NN'), ('least', 'JJS'), ('one', 'CD'), ('identified', 'JJ'), ('consumer', 'NN'), ('third', 'NNP'), ('party', 'NN'), ('method', 'NN'), ('one', 'CD'), ('claims', 'VBZ'), ('wherein', 'NN'), ('notification', 'NN'), ('includes', 'VBZ'), ('least', 'JJS'), ('one', 'CD'), ('data', 'NN'), ('indicative', 'NN'), ('identified', 'VBN'), ('event', 'NN'), ('data', 'NNS'), ('indicative', 'JJ'), ('identified', 'JJ'), ('consumer', 'NN'), ('ophthalmologic', 'NN'), ('recommendations', 'NNS'), ('based', 'VBN'), ('identified', 'JJ'), ('event', 'NN'), ('lack', 'NN'), ('events', 'NNS'), ('appointment', 'JJ'), ('vision', 'NN'), ('test', 'NN'), ('method', 'NN'), ('one', 'CD'), ('claims', 'VBZ'), ('comprising', 'VBG'), ('storing', 'VBG'), ('least', 'JJS'), ('one', 'CD'), ('reference', 'NN'), ('data', 'NNS'), ('indicative', 'JJ'), ('behavioral', 'JJ'), ('compensation', 'NN'), ('vision', 'NN'), ('impairment', 'NN'), ('data', 'NNS'), ('indicative', 'JJ'), ('notification', 'NN'), ('data', 'NNS'), ('indicative', 'JJ'), ('follow-up', 'JJ'), ('notification', 'NN'), ('method', 'NN'), ('claim', 'NN'), ('comprising', 'VBG'), ('identifying', 'VBG'), ('event', 'NN'), ('upon', 'IN'), ('comparison', 'NN'), ('detected', 'VBN'), ('data', 'NNS'), ('reference', 'NN'), ('data', 'NNS'), ('determining', 'VBG'), ('probability', 'NN'), ('vision', 'NN'), ('impairment', 'JJ'), ('consumer', 'NN'), ('based', 'VBN'), ('comparison', 'JJ'), ('computer', 'NN'), ('program', 'NN'), ('intended', 'VBN'), ('stored', 'JJ'), ('memory', 'NN'), ('processor', 'NN'), ('unit', 'NN'), ('computer', 'NN'), ('system', 'NN'), ('removable', 'JJ'), ('memory', 'NN'), ('medium', 'NN'), ('adapted', 'VBD'), ('cooperate', 'JJ'), ('reader', 'NN'), ('processor', 'NN'), ('unit', 'NN'), ('comprising', 'VBG'), ('instructions', 'NNS'), ('implementing', 'VBG'), ('method', 'NN'), ('according', 'VBG'), ('claims', 'NNS')]\n"
     ]
    }
   ],
   "source": [
    "cleaned_POS_text_a = []\n",
    "\n",
    "for tuple in pos_tagging_a:\n",
    "    # POS tagged text is a list of tuples, where the first element tuple[0] is a token and the second one tuple[1] is\n",
    "    # the Part of Speech. If the POS has length == 1, the token is punctuation, otherwise it is not, and we insert it\n",
    "    # in the list cleaned_POS_text\n",
    "    if len(tuple[1]) > 1:\n",
    "        cleaned_POS_text_a.append(tuple)\n",
    "        \n",
    "print(cleaned_POS_text_a) \n",
    "\n",
    "cleaned_POS_text_c = []\n",
    "\n",
    "for tuple in pos_tagging_c:\n",
    "    # POS tagged text is a list of tuples, where the first element tuple[0] is a token and the second one tuple[1] is\n",
    "    # the Part of Speech. If the POS has length == 1, the token is punctuation, otherwise it is not, and we insert it\n",
    "    # in the list cleaned_POS_text\n",
    "    if len(tuple[1]) > 1:\n",
    "        cleaned_POS_text_c.append(tuple)\n",
    "        \n",
    "print(cleaned_POS_text_c) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2f4cd6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('electronic', 'a'), ('apparatus', 'n'), ('including', 'v'), ('image', 'n'), ('capturing', 'n'), ('device', 'n'), ('storage', 'n'), ('device', 'n'), ('processor', 'n'), ('operation', 'n'), ('method', 'n'), ('thereof', 'n'), ('provided', 'v'), ('image', 'n'), ('capturing', 'v'), ('device', 'n'), ('captures', 'n'), ('image', 'n'), ('user', 'a'), ('storage', 'n'), ('device', 'n'), ('records', 'n'), ('plurality', 'n'), ('modules', 'v'), ('processor', 'n'), ('coupled', 'v'), ('image', 'n'), ('capturing', 'v'), ('device', 'a'), ('storage', 'n'), ('device', 'n'), ('configured', 'v'), ('configure', 'a'), ('image', 'n'), ('capturing', 'v'), ('device', 'a'), ('capture', 'n'), ('head', 'n'), ('image', 'n'), ('user', 'n'), ('perform', 'v'), ('face', 'n'), ('recognition', 'n'), ('operation', 'n'), ('obtain', 'v'), ('face', 'a'), ('region', 'n'), ('detect', 'a'), ('plurality', 'n'), ('facial', 'a'), ('landmarks', 'n'), ('within', None), ('face', 'n'), ('region', 'n'), ('estimate', 'n'), ('head', 'n'), ('posture', 'n'), ('angle', 'v'), ('user', 'r'), ('according', 'v'), ('facial', 'a'), ('landmarks', 'n'), ('calculate', 'n'), ('gaze', 'n'), ('position', 'n'), ('user', 'n'), ('gazes', 'v'), ('screen', 'a'), ('according', 'v'), ('head', 'n'), ('posture', 'n'), ('angle', 'v'), ('plurality', 'n'), ('rotation', 'n'), ('reference', 'n'), ('angle', 'n'), ('plurality', 'n'), ('predetermined', 'v'), ('calibration', 'n'), ('positions', 'n'), ('configure', 'v'), ('screen', 'a'), ('display', 'n'), ('corresponding', 'v'), ('visual', 'a'), ('effect', 'n'), ('according', 'v'), ('gaze', 'n'), ('positionthe', 'n'), ('present', 'a'), ('disclosure', 'n'), ('provides', 'v'), ('computation', 'n'), ('method', 'n'), ('product', 'n'), ('thereof', 'n'), ('computation', 'n'), ('method', 'n'), ('adopts', 'n'), ('fusion', 'v'), ('method', 'a'), ('perform', 'n'), ('machine', 'n'), ('learning', 'v'), ('computations', 'n'), ('technical', 'a'), ('effects', 'n'), ('present', 'a'), ('disclosure', 'n'), ('include', 'v'), ('fewer', 'a'), ('computations', 'n'), ('less', 'r'), ('power', 'n'), ('consumptiona', 'n'), ('method', 'n'), ('detecting', 'v'), ('body', 'n'), ('information', 'n'), ('passengers', 'n'), ('vehicle', 'n'), ('based', 'v'), ('humans', 'n'), (\"'\", None), ('status', 'n'), ('recognition', 'n'), ('provided', 'v'), ('method', 'n'), ('includes', 'v'), ('steps', 'n'), ('passenger', 'n'), ('body', 'n'), ('information-detecting', 'a'), ('device', 'n'), ('inputting', 'v'), ('interior', 'a'), ('image', 'n'), ('vehicle', 'n'), ('face', 'n'), ('recognition', 'n'), ('network', 'n'), ('detect', 'a'), ('faces', 'v'), ('passengers', 'n'), ('output', 'n'), ('passenger', 'n'), ('feature', 'n'), ('information', 'n'), ('inputting', 'v'), ('interior', 'a'), ('image', 'n'), ('body', 'n'), ('recognition', 'n'), ('network', 'n'), ('detect', 'a'), ('bodies', 'n'), ('output', 'n'), ('body-part', 'a'), ('length', 'n'), ('information', 'n'), ('b', 'n'), ('retrieving', 'v'), ('specific', 'a'), ('height', 'a'), ('mapping', 'n'), ('information', 'n'), ('referring', 'v'), ('height', 'n'), ('mapping', 'v'), ('table', 'a'), ('ratios', 'n'), ('segment', 'n'), ('body', 'n'), ('portions', 'n'), ('human', 'a'), ('groups', 'n'), ('heights', 'n'), ('per', None), ('human', 'a'), ('groups', 'n'), ('acquiring', 'v'), ('specific', 'a'), ('height', 'n'), ('specific', 'a'), ('passenger', 'n'), ('retrieving', 'v'), ('specific', 'a'), ('weight', 'n'), ('mapping', 'v'), ('information', 'n'), ('weight', 'n'), ('mapping', 'n'), ('table', 'a'), ('correlations', 'n'), ('heights', 'n'), ('weights', 'n'), ('per', None), ('human', 'a'), ('groups', 'n'), ('acquiring', 'v'), ('weight', 'n'), ('specific', 'a'), ('passenger', 'n'), ('referring', 'v'), ('specific', 'a'), ('heighttechniques', 'n'), ('related', 'v'), ('improved', 'a'), ('video', 'n'), ('coding', 'v'), ('based', 'v'), ('face', 'n'), ('detection', 'n'), ('region', 'n'), ('extraction', 'n'), ('tracking', 'v'), ('discussed', 'v'), ('techniques', 'n'), ('may', None), ('include', 'v'), ('performing', 'v'), ('facial', 'a'), ('search', 'n'), ('video', 'n'), ('frame', 'n'), ('determine', 'a'), ('candidate', 'n'), ('face', 'n'), ('regions', 'n'), ('video', 'v'), ('frame', 'a'), ('testing', 'v'), ('candidate', 'n'), ('face', 'n'), ('regions', 'n'), ('based', 'v'), ('skin', 'a'), ('tone', 'n'), ('information', 'n'), ('determine', 'n'), ('valid', 'n'), ('invalid', 'a'), ('face', 'n'), ('regions', 'n'), ('rejecting', 'v'), ('invalid', 'a'), ('face', 'n'), ('regions', 'n'), ('encoding', 'v'), ('video', 'n'), ('frame', 'n'), ('based', 'v'), ('valid', 'a'), ('face', 'n'), ('regions', 'n'), ('generate', 'v'), ('coded', 'v'), ('bitstreama', 'n'), ('method', 'n'), ('managing', 'v'), ('smart', 'a'), ('database', 'n'), ('stores', 'n'), ('facial', 'a'), ('images', 'n'), ('face', 'v'), ('recognition', 'n'), ('provided', 'v'), ('method', 'n'), ('includes', 'v'), ('steps', 'n'), ('managing', 'v'), ('device', 'n'), ('counting', 'v'), ('specific', 'a'), ('facial', 'a'), ('images', 'n'), ('corresponding', 'v'), ('specific', 'a'), ('person', 'n'), ('smart', 'a'), ('database', 'n'), ('new', 'a'), ('facial', 'a'), ('images', 'n'), ('continuously', 'r'), ('stored', 'v'), ('determining', 'v'), ('whether', None), ('first', 'a'), ('counted', 'v'), ('value', 'n'), ('representing', 'v'), ('count', 'n'), ('specific', 'a'), ('facial', 'a'), ('images', 'n'), ('satisfies', 'n'), ('first', 'r'), ('set', 'v'), ('value', 'n'), ('b', 'n'), ('first', 'r'), ('counted', 'v'), ('value', 'n'), ('satisfies', 'n'), ('first', 'r'), ('set', 'v'), ('value', 'n'), ('inputting', 'v'), ('specific', 'a'), ('facial', 'a'), ('images', 'n'), ('neural', 'a'), ('aggregation', 'n'), ('network', 'n'), ('generate', 'v'), ('quality', 'n'), ('scores', 'n'), ('specific', 'a'), ('facial', 'a'), ('images', 'n'), ('aggregation', 'v'), ('specific', 'a'), ('facial', 'a'), ('images', 'n'), ('second', 'v'), ('counted', 'v'), ('value', 'n'), ('representing', 'v'), ('count', 'n'), ('specific', 'a'), ('quality', 'n'), ('scores', 'n'), ('among', None), ('quality', 'n'), ('scores', 'n'), ('highest', 'a'), ('counting', 'v'), ('thereof', 'a'), ('satisfies', 'n'), ('second', 'v'), ('set', 'v'), ('value', 'n'), ('deleting', 'v'), ('part', 'n'), ('specific', 'a'), ('facial', 'a'), ('images', 'n'), ('corresponding', 'v'), ('uncounted', 'a'), ('quality', 'n'), ('scores', 'n'), ('smart', 'v'), ('databasea', 'n'), ('system', 'n'), ('capable', 'a'), ('determining', 'v'), ('recognition', 'n'), ('algorithms', 'n'), ('applied', 'v'), ('regions', 'n'), ('interest', 'n'), ('within', None), ('digital', 'a'), ('representations', 'n'), ('presented', 'v'), ('preprocessing', 'v'), ('module', 'n'), ('utilizes', None), ('one', None), ('feature', 'n'), ('identification', 'n'), ('algorithms', None), ('determine', 'n'), ('regions', 'n'), ('interest', 'n'), ('based', 'v'), ('feature', 'n'), ('density', 'n'), ('preprocessing', 'v'), ('modules', 'n'), ('leverages', 'v'), ('feature', 'v'), ('density', 'n'), ('signature', 'n'), ('region', 'n'), ('determine', 'n'), ('plurality', 'n'), ('diverse', 'a'), ('recognition', 'n'), ('modules', 'n'), ('operate', 'v'), ('region', 'n'), ('interest', 'n'), ('specific', 'a'), ('embodiment', 'n'), ('focuses', 'n'), ('structured', 'v'), ('documents', 'n'), ('also', 'r'), ('presented', 'v'), ('disclosed', 'a'), ('approach', 'n'), ('enhanced', 'v'), ('addition', 'n'), ('object', 'n'), ('classifier', 'n'), ('classifies', 'n'), ('types', 'v'), ('objects', 'n'), ('found', 'v'), ('regions', 'n'), ('interestdisclosed', 'v'), ('mobile', 'a'), ('terminal', 'n'), ('mobile', 'a'), ('terminal', 'n'), ('may', None), ('include', 'v'), ('front', 'a'), ('camera', 'n'), ('obtaining', 'v'), ('face', 'n'), ('image', 'n'), ('user', 'a'), ('glance', 'n'), ('sensor', 'n'), ('tilted', 'v'), ('certain', 'a'), ('angle', 'n'), ('disposed', 'v'), ('adjacent', 'a'), ('front', 'a'), ('camera', 'n'), ('obtain', 'v'), ('metadata', 'a'), ('face', 'n'), ('image', 'n'), ('controller', 'n'), ('obtaining', 'v'), ('distance', 'n'), ('glance', 'n'), ('sensor', 'n'), ('front', 'n'), ('camera', 'n'), ('distance', 'n'), ('enabling', 'v'), ('area', 'n'), ('overlap', None), ('region', 'n'), ('first', 'a'), ('region', 'n'), ('representing', 'v'), ('range', 'n'), ('photographable', 'a'), ('front', 'n'), ('camera', 'n'), ('overlaps', 'v'), ('second', 'a'), ('region', 'n'), ('representing', 'v'), ('range', 'n'), ('photographable', 'a'), ('glance', 'n'), ('sensor', 'n'), ('maximumthis', 'n'), ('disclosure', 'n'), ('provides', 'v'), ('systems', 'n'), ('methods', 'n'), ('apparatus', 'r'), ('including', 'v'), ('computer', 'n'), ('programs', 'n'), ('encoded', 'v'), ('computer', 'n'), ('storage', 'n'), ('media', 'n'), ('intelligent', 'a'), ('routing', 'v'), ('notifications', 'n'), ('related', 'a'), ('media', 'n'), ('programming', 'v'), ('one', None), ('aspect', 'a'), ('smart', 'a'), ('television', 'n'), ('tv', 'n'), ('implemented', 'v'), ('track', 'r'), ('user', 'n'), (\"'s\", None), ('tv', 'n'), ('watching', 'v'), ('behavior', 'a'), ('anticipate', 'n'), ('programming', 'n'), ('based', 'v'), ('behavior', 'a'), ('aspects', 'n'), ('smart', 'a'), ('tv', 'n'), ('implemented', 'v'), ('detect', 'a'), ('user', 'n'), (\"'s\", None), ('presence', 'n'), ('based', 'v'), ('detection', 'n'), ('automatically', 'r'), ('change', 'a'), ('tv', 'n'), ('channel', 'n'), ('media', 'n'), ('programming', 'v'), ('analyzed', 'v'), ('desirable', 'a'), ('user', 'a'), ('aspects', 'n'), ('smart', 'a'), ('tv', 'n'), ('implemented', 'v'), ('transmit', 'n'), ('notification', 'n'), ('instructions', 'n'), ('electronic', 'a'), ('devices', 'n'), ('within', None), ('network', 'n'), ('attempt', 'n'), ('alert', None), ('user', 'n'), ('upcoming', 'a'), ('media', 'n'), ('programming', 'v'), ('additionally', 'r'), ('smart', 'a'), ('tv', 'n'), ('implemented', 'v'), ('transmit', 'n'), ('detection', 'n'), ('instructions', 'n'), ('electronic', 'a'), ('devices', 'n'), ('within', None), ('network', 'n'), ('whereby', None), ('electronic', 'a'), ('devices', 'n'), ('attempt', 'v'), ('detect', 'a'), ('user', 'n'), (\"'s\", None), ('presence', 'n'), ('voice', 'n'), ('facial', 'a'), ('recognitiona', 'n'), ('camera', 'n'), ('configured', 'v'), ('output', 'n'), ('test', 'n'), ('depth+multi-spectral', 'a'), ('image', 'n'), ('including', 'v'), ('plurality', 'n'), ('pixels', 'n'), ('pixel', 'v'), ('corresponds', 'v'), ('one', None), ('plurality', 'n'), ('sensors', 'n'), ('sensor', 'v'), ('array', 'a'), ('camera', 'n'), ('includes', 'v'), ('least', 'a'), ('depth', 'a'), ('value', 'n'), ('spectral', 'a'), ('value', 'n'), ('spectral', 'a'), ('light', 'a'), ('sub-band', 'a'), ('plurality', 'n'), ('spectral', 'a'), ('illuminators', 'n'), ('camera', 'v'), ('face', 'n'), ('recognition', 'n'), ('machine', 'n'), ('previously', 'r'), ('trained', 'v'), ('set', 'v'), ('labeled', 'a'), ('training', 'n'), ('depth+multi-spectral', 'a'), ('images', 'n'), ('structure', 'n'), ('test', 'n'), ('depth+multi-spectral', 'a'), ('image', 'n'), ('face', 'n'), ('recognition', 'n'), ('machine', 'n'), ('configured', 'v'), ('output', 'n'), ('confidence', 'n'), ('value', 'n'), ('indicating', 'v'), ('likelihood', 'a'), ('test', 'n'), ('depth+multi-spectral', 'a'), ('image', 'n'), ('includes', 'v'), ('faceembodiments', 'n'), ('present', 'a'), ('disclosure', 'n'), ('relate', 'n'), ('image', 'n'), ('processing', 'n'), ('method', 'n'), ('apparatus', 'n'), ('electronic', 'a'), ('device', 'n'), ('method', 'n'), ('includes', 'v'), ('acquiring', 'v'), ('photo', 'n'), ('album', 'n'), ('obtained', 'v'), ('face', 'n'), ('clustering', 'v'), ('collecting', 'v'), ('face', 'n'), ('information', 'n'), ('respective', 'a'), ('images', 'n'), ('photo', 'v'), ('album', None), ('acquiring', 'v'), ('face', 'n'), ('parameter', 'n'), ('image', 'n'), ('according', 'v'), ('face', 'n'), ('information', 'n'), ('selecting', 'v'), ('cover', 'n'), ('image', 'n'), ('according', 'v'), ('face', 'n'), ('parameter', 'n'), ('image', 'n'), ('taking', 'v'), ('face-region', 'a'), ('image', 'n'), ('cover', 'n'), ('image', 'n'), ('setting', 'v'), ('face-region', 'a'), ('image', 'n'), ('cover', 'n'), ('photo', 'n'), ('albumtechniques', 'n'), ('described', 'v'), ('herein', 'a'), ('provide', None), ('location-based', 'a'), ('access', 'n'), ('control', 'n'), ('secured', 'v'), ('resources', 'n'), ('generally', 'r'), ('described', 'v'), ('configurations', 'n'), ('disclosed', 'v'), ('herein', 'r'), ('enable', 'a'), ('system', 'n'), ('dynamically', 'r'), ('modify', 'a'), ('access', 'n'), ('secured', 'v'), ('resources', 'n'), ('based', 'v'), ('one', None), ('location-related', 'a'), ('actions', 'n'), ('example', 'n'), ('techniques', 'n'), ('disclosed', 'v'), ('herein', 'r'), ('enable', 'a'), ('computing', 'v'), ('system', 'n'), ('control', 'n'), ('access', 'n'), ('resources', 'n'), ('computing', 'v'), ('devices', 'n'), ('display', 'n'), ('devices', 'n'), ('secured', 'v'), ('locations', 'n'), ('secured', 'v'), ('data', 'n'), ('configurations', 'n'), ('techniques', 'n'), ('disclosed', 'v'), ('herein', 'r'), ('enable', 'a'), ('controlled', 'a'), ('access', 'n'), ('secured', 'v'), ('resources', 'n'), ('based', 'v'), ('least', 'a'), ('part', 'n'), ('invitation', 'n'), ('associated', 'v'), ('location', 'n'), ('positioning', 'v'), ('data', 'n'), ('indicating', 'v'), ('location', 'n'), ('userone', 'a'), ('embodiment', 'n'), ('provides', 'v'), ('method', 'a'), ('comprising', 'v'), ('receiving', 'v'), ('piece', 'n'), ('content', 'n'), ('salient', 'n'), ('moments', 'n'), ('data', 'n'), ('piece', 'n'), ('content', 'n'), ('method', 'n'), ('comprises', 'n'), ('based', 'v'), ('salient', 'a'), ('moments', 'n'), ('data', 'n'), ('determining', 'v'), ('first', 'a'), ('path', 'n'), ('viewport', 'n'), ('piece', 'n'), ('content', 'n'), ('method', 'n'), ('comprises', 'v'), ('displaying', 'v'), ('viewport', 'n'), ('display', 'n'), ('device', 'n'), ('movement', 'n'), ('viewport', 'n'), ('based', 'v'), ('first', 'a'), ('path', 'n'), ('playback', 'n'), ('piece', 'n'), ('content', 'n'), ('method', 'n'), ('comprises', 'v'), ('generating', 'v'), ('augmentation', 'n'), ('salient', 'a'), ('moment', 'n'), ('occurring', 'v'), ('piece', 'n'), ('content', 'n'), ('presenting', 'v'), ('augmentation', 'n'), ('viewport', 'n'), ('portion', 'n'), ('playback', 'n'), ('augmentation', 'n'), ('comprises', 'v'), ('interactive', 'a'), ('hint', 'n'), ('guiding', 'v'), ('viewport', 'n'), ('salient', 'n'), ('momenta', 'v'), ('computer-implemented', 'a'), ('method', 'n'), ('system', 'n'), ('computer', 'n'), ('program', 'n'), ('product', 'n'), ('provided', 'v'), ('facial', 'a'), ('recognition', 'n'), ('method', 'n'), ('includes', 'v'), ('receiving', 'v'), ('processor', 'n'), ('device', 'n'), ('plurality', 'n'), ('images', 'n'), ('method', 'v'), ('also', 'r'), ('includes', 'v'), ('extracting', 'v'), ('processor', 'n'), ('device', 'n'), ('feature', 'n'), ('extractor', 'n'), ('utilizing', 'a'), ('convolutional', 'a'), ('neural', 'a'), ('network', 'n'), ('cnn', 'n'), ('enlarged', 'v'), ('intra-class', 'a'), ('variance', 'n'), ('long-tail', 'a'), ('classes', 'n'), ('feature', 'v'), ('vectors', 'n'), ('plurality', 'n'), ('images', 'n'), ('method', 'v'), ('additionally', 'r'), ('includes', 'v'), ('generating', 'v'), ('processor', 'n'), ('device', 'n'), ('feature', 'n'), ('generator', 'n'), ('discriminative', 'a'), ('feature', 'n'), ('vectors', 'n'), ('feature', 'v'), ('vectors', 'n'), ('method', 'v'), ('includes', 'v'), ('classifying', 'v'), ('processor', 'n'), ('device', 'n'), ('utilizing', 'v'), ('fully', 'r'), ('connected', 'v'), ('classifier', 'a'), ('identity', 'n'), ('discriminative', 'a'), ('feature', 'n'), ('vector', 'n'), ('method', 'n'), ('also', 'r'), ('includes', 'v'), ('control', 'n'), ('operation', 'n'), ('processor-based', 'a'), ('machine', 'n'), ('react', 'n'), ('accordance', 'n'), ('identitysome', 'a'), ('embodiments', 'n'), ('invention', 'n'), ('provide', 'v'), ('efficient', 'a'), ('expressive', 'a'), ('machine-trained', 'a'), ('networks', 'n'), ('performing', 'v'), ('machine', 'n'), ('learning', 'v'), ('machine-trained', 'a'), ('mt', 'n'), ('networks', 'n'), ('embodiments', 'n'), ('use', 'v'), ('novel', 'a'), ('processing', 'n'), ('nodes', 'n'), ('novel', 'a'), ('activation', 'n'), ('functions', 'n'), ('allow', 'v'), ('mt', 'n'), ('network', 'n'), ('efficiently', 'r'), ('define', 'v'), ('fewer', 'a'), ('processing', 'n'), ('node', 'n'), ('layers', 'n'), ('complex', 'a'), ('mathematical', 'a'), ('expression', 'n'), ('solves', 'v'), ('particular', 'a'), ('problem', 'n'), ('eg', 'n'), ('face', 'n'), ('recognition', 'n'), ('speech', 'n'), ('recognition', 'n'), ('etc', None), ('embodiments', 'n'), ('activation', 'n'), ('function', 'n'), ('eg', None), ('cup', 'n'), ('function', 'n'), ('used', 'v'), ('numerous', 'a'), ('processing', 'v'), ('nodes', 'n'), ('mt', 'a'), ('network', 'n'), ('machine', 'n'), ('learning', 'v'), ('activation', 'n'), ('function', 'n'), ('configured', 'v'), ('differently', 'r'), ('different', 'a'), ('processing', 'v'), ('nodes', 'n'), ('different', 'a'), ('nodes', 'n'), ('emulate', 'v'), ('implement', 'a'), ('two', None), ('different', 'a'), ('functions', 'n'), ('eg', 'v'), ('two', None), ('boolean', 'a'), ('logical', 'a'), ('operators', 'n'), ('xor', 'v'), ('activation', 'n'), ('function', 'n'), ('embodiments', 'n'), ('periodic', 'a'), ('function', 'n'), ('configured', 'v'), ('implement', 'a'), ('different', 'a'), ('functions', 'n'), ('eg', 'v'), ('different', 'a'), ('sinusoidal', 'a'), ('functionsmethods', 'n'), ('systems', 'n'), ('may', None), ('provide', 'v'), ('facial', 'a'), ('recognition', 'n'), ('least', 'a'), ('one', None), ('input', 'n'), ('image', 'n'), ('utilizing', 'a'), ('hierarchical', 'a'), ('feature', 'n'), ('learning', 'v'), ('pair-wise', 'a'), ('classification', 'n'), ('receptive', 'a'), ('field', 'n'), ('theory', 'n'), ('may', None), ('used', 'v'), ('input', 'v'), ('image', 'n'), ('generate', 'a'), ('pre-processed', 'a'), ('multi-channel', 'a'), ('image', 'n'), ('channels', 'n'), ('pre-processed', 'a'), ('image', 'n'), ('may', None), ('activated', 'v'), ('based', 'v'), ('amount', 'n'), ('feature', 'n'), ('rich', 'a'), ('details', 'n'), ('within', None), ('channels', 'n'), ('similarly', 'r'), ('local', 'a'), ('patches', 'n'), ('may', None), ('activated', 'v'), ('based', 'v'), ('discriminant', 'a'), ('features', 'n'), ('within', None), ('local', 'a'), ('patches', 'n'), ('features', 'n'), ('may', None), ('extracted', 'v'), ('local', 'a'), ('patches', 'n'), ('discriminant', 'a'), ('features', 'n'), ('may', None), ('selected', 'v'), ('order', 'n'), ('perform', 'n'), ('feature', 'n'), ('matching', 'v'), ('pair', 'n'), ('sets', 'n'), ('system', 'n'), ('may', None), ('utilize', 'v'), ('patch', 'n'), ('feature', 'n'), ('pooling', 'v'), ('pair-wise', 'a'), ('matching', 'a'), ('large-scale', 'a'), ('training', 'n'), ('order', 'n'), ('quickly', 'r'), ('accurately', 'r'), ('perform', 'a'), ('facial', 'a'), ('recognition', 'n'), ('low', 'a'), ('cost', 'n'), ('system', 'n'), ('memory', 'n'), ('computationa', 'n'), ('method', 'n'), ('controlling', 'v'), ('terminal', 'n'), ('provided', 'v'), ('terminal', 'a'), ('includes', 'v'), ('capturing', 'v'), ('apparatus', 'n'), ('least', 'a'), ('one', None), ('processor', 'n'), ('image', 'n'), ('acquired', 'v'), ('capturing', 'v'), ('apparatus', 'n'), ('motion', 'n'), ('parameter', 'n'), ('terminal', 'n'), ('obtained', 'v'), ('image', 'n'), ('processing', 'n'), ('acquired', 'v'), ('image', 'n'), ('controlled', 'v'), ('performed', 'v'), ('based', 'v'), ('motion', 'n'), ('parameter', 'n'), ('equal', 'a'), ('less', 'r'), ('preset', 'a'), ('parameter', 'n'), ('threshold', 'n'), ('skipped', 'v'), ('based', 'v'), ('motion', 'n'), ('parameter', 'n'), ('greater', 'a'), ('preset', 'n'), ('parameter', 'n'), ('thresholda', 'v'), ('drive-through', 'a'), ('order', 'n'), ('processing', 'n'), ('method', 'n'), ('apparatus', 'n'), ('disclosed', 'v'), ('drive-through', 'a'), ('order', 'n'), ('processing', 'n'), ('method', 'n'), ('includes', 'v'), ('receiving', 'v'), ('customer', 'n'), ('information', 'n'), ('detected', 'v'), ('vision', 'n'), ('recognition', 'n'), ('providing', 'v'), ('product', 'n'), ('information', 'n'), ('based', 'v'), ('customer', 'n'), ('information', 'n'), ('processing', 'v'), ('product', 'n'), ('order', 'n'), ('customer', 'n'), ('according', 'v'), ('present', 'a'), ('disclosure', 'n'), ('possible', 'a'), ('rapidly', 'r'), ('process', 'a'), ('order', 'n'), ('using', 'v'), ('customer', 'n'), ('information', 'n'), ('based', 'v'), ('customer', 'n'), ('recognition', 'n'), ('using', 'v'), ('artificial', 'a'), ('intelligence', 'n'), ('ai', 'a'), ('model', 'n'), ('machine', 'n'), ('learning', 'v'), ('g', 'a'), ('networkan', 'a'), ('image', 'n'), ('processing', 'n'), ('method', 'n'), ('performed', 'v'), ('computing', 'v'), ('device', 'n'), ('includes', 'v'), ('identifying', 'v'), ('using', 'v'), ('face', 'n'), ('recognition', 'n'), ('one', None), ('faces', 'v'), ('face', 'n'), ('corresponding', 'v'), ('respective', 'a'), ('person', 'n'), ('captured', 'v'), ('first', 'a'), ('image', 'n'), ('identified', 'v'), ('face', 'n'), ('extracting', 'v'), ('set', 'v'), ('profile', 'a'), ('parameters', 'n'), ('corresponding', 'v'), ('person', 'n'), ('first', 'a'), ('image', 'n'), ('selecting', 'v'), ('plurality', 'n'), ('image', 'n'), ('tiles', 'n'), ('first', 'r'), ('image', 'n'), ('tile', 'n'), ('matches', 'n'), ('face', 'v'), ('corresponding', 'v'), ('person', 'n'), ('first', 'a'), ('image', 'n'), ('accordance', 'n'), ('predefined', 'v'), ('correspondence', 'n'), ('set', 'v'), ('profile', 'a'), ('parameters', 'n'), ('corresponding', 'v'), ('person', 'n'), ('set', 'v'), ('pre-stored', 'a'), ('description', 'n'), ('parameters', 'n'), ('first', 'a'), ('image', 'n'), ('tile', 'n'), ('generating', 'v'), ('second', 'a'), ('image', 'n'), ('covering', 'v'), ('faces', 'v'), ('respective', 'a'), ('persons', 'n'), ('first', 'a'), ('image', 'n'), ('corresponding', 'v'), ('first', 'a'), ('image', 'n'), ('tiles', 'n'), ('sharing', 'v'), ('first', 'a'), ('image', 'n'), ('second', 'a'), ('image', 'n'), ('predefined', 'v'), ('order', 'n'), ('via', None), ('group', 'n'), ('chat', None), ('sessionin', 'v'), ('one', None), ('embodiment', 'n'), ('artificial', 'a'), ('reality', 'n'), ('system', 'n'), ('determines', 'v'), ('performance', 'n'), ('metric', 'a'), ('eye', 'n'), ('tracking', 'v'), ('system', 'n'), ('first', 'a'), ('performance', 'n'), ('threshold', 'n'), ('eye', 'n'), ('tracking', 'v'), ('system', 'n'), ('associated', 'v'), ('head-mounted', 'a'), ('display', 'n'), ('worn', 'v'), ('user', 'a'), ('artificial', 'a'), ('reality', 'n'), ('system', 'n'), ('receives', 'v'), ('first', 'r'), ('inputs', 'n'), ('associated', 'v'), ('body', 'n'), ('user', 'a'), ('determines', 'n'), ('region', 'n'), ('user', None), ('looking', 'v'), ('within', None), ('field', 'n'), ('view', 'n'), ('head-mounted', 'a'), ('display', 'n'), ('based', 'v'), ('received', 'v'), ('first', 'r'), ('inputs', 'a'), ('system', 'n'), ('determines', 'v'), ('vergence', 'n'), ('distance', 'n'), ('user', 'n'), ('based', 'v'), ('least', 'a'), ('first', 'a'), ('inputs', 'n'), ('associated', 'v'), ('body', 'n'), ('user', 'a'), ('region', 'n'), ('user', None), ('looking', 'v'), ('locations', 'n'), ('one', None), ('objects', 'v'), ('scene', 'n'), ('displayed', 'v'), ('head-mounted', 'a'), ('display', 'n'), ('system', 'n'), ('adjusts', 'v'), ('one', None), ('configurations', 'n'), ('head-mounted', 'a'), ('display', 'n'), ('based', 'v'), ('determined', 'a'), ('vergence', 'n'), ('distance', 'n'), ('usera', 'a'), ('computer-implemented', 'a'), ('method', 'n'), ('provided', 'v'), ('image-based', 'a'), ('self-guided', 'a'), ('object', 'a'), ('detection', 'n'), ('method', 'n'), ('includes', 'v'), ('receiving', 'v'), ('processor', 'n'), ('device', 'n'), ('set', 'v'), ('images', 'n'), ('images', 'n'), ('respective', 'v'), ('grid', 'a'), ('thereon', 'n'), ('labeled', 'v'), ('regarding', 'v'), ('respective', 'a'), ('object', 'n'), ('detected', 'v'), ('using', 'v'), ('grid', 'a'), ('level', 'n'), ('label', 'n'), ('data', 'n'), ('method', 'n'), ('includes', 'v'), ('training', 'v'), ('processor', 'a'), ('device', 'n'), ('grid-based', 'a'), ('object', 'n'), ('detector', 'n'), ('using', 'v'), ('grid', 'a'), ('level', 'n'), ('label', 'n'), ('data', 'n'), ('method', 'n'), ('also', 'r'), ('includes', 'v'), ('determining', 'v'), ('processor', 'n'), ('device', 'n'), ('respective', 'n'), ('bounding', 'v'), ('box', 'n'), ('respective', 'a'), ('object', 'a'), ('images', 'n'), ('applying', 'v'), ('local', 'a'), ('segmentation', 'n'), ('images', 'n'), ('method', 'v'), ('additionally', 'r'), ('includes', 'v'), ('training', 'n'), ('processor', 'n'), ('device', 'n'), ('region-based', 'a'), ('convolutional', 'a'), ('neural', 'a'), ('network', 'n'), ('rcnn', 'n'), ('joint', 'n'), ('object', 'a'), ('localization', 'n'), ('object', 'n'), ('classification', 'n'), ('using', 'v'), ('respective', 'a'), ('bounding', 'n'), ('box', 'n'), ('respective', 'a'), ('object', 'a'), ('images', 'n'), ('input', 'v'), ('rcnna', 'a'), ('system', 'n'), ('method', 'a'), ('face', 'n'), ('recognition', 'n'), ('comprising', 'v'), ('multiple', 'a'), ('phases', 'n'), ('implemented', 'v'), ('parallel', 'a'), ('architecture', 'n'), ('first', 'a'), ('phase', 'n'), ('normalization', 'n'), ('phase', 'n'), ('whereby', 'n'), ('captured', 'v'), ('image', 'n'), ('normalized', 'v'), ('size', 'n'), ('orientation', 'n'), ('illumination', 'n'), ('stored', 'v'), ('images', 'n'), ('preexisting', 'v'), ('database', 'a'), ('second', 'a'), ('phase', 'n'), ('feature', 'n'), ('extractiondistance', 'n'), ('matrix', 'n'), ('phase', 'n'), ('distance', 'n'), ('matrix', 'n'), ('generated', 'v'), ('captured', 'a'), ('image', 'n'), ('coarse', 'n'), ('recognition', 'n'), ('phase', 'n'), ('generated', 'v'), ('distance', 'n'), ('matrix', 'n'), ('compared', 'v'), ('distance', 'n'), ('matrices', 'n'), ('database', 'v'), ('using', 'v'), ('euclidean', 'a'), ('distance', 'n'), ('matches', 'n'), ('create', 'v'), ('candidate', 'n'), ('lists', 'n'), ('detailed', 'v'), ('recognition', 'n'), ('phase', 'n'), ('multiple', 'a'), ('face', 'n'), ('recognition', 'n'), ('algorithms', 'r'), ('applied', 'a'), ('candidate', 'n'), ('lists', 'n'), ('produce', 'v'), ('final', 'a'), ('result', 'n'), ('distance', 'n'), ('matrices', 'n'), ('normalized', 'a'), ('database', 'n'), ('may', None), ('broken', 'v'), ('parallel', 'a'), ('lists', 'n'), ('parallelization', 'v'), ('feature', 'n'), ('extractiondistance', 'n'), ('matrix', 'n'), ('phase', 'n'), ('candidate', 'n'), ('lists', 'n'), ('may', None), ('also', 'r'), ('grouped', 'v'), ('according', 'v'), ('dissimilarity', 'n'), ('algorithm', 'n'), ('parallel', 'n'), ('processing', 'n'), ('detailed', 'a'), ('recognition', 'n'), ('phasean', 'a'), ('imaging', 'n'), ('device', 'n'), ('including', 'v'), ('pixel', 'a'), ('matrix', 'n'), ('processor', 'n'), ('provided', 'v'), ('pixel', 'a'), ('matrix', 'n'), ('includes', 'v'), ('plurality', 'n'), ('phase', 'n'), ('detection', 'n'), ('pixels', 'n'), ('plurality', 'n'), ('regular', 'a'), ('pixels', 'n'), ('processor', 'n'), ('performs', 'n'), ('autofocusing', 'v'), ('according', 'v'), ('pixel', 'n'), ('data', 'n'), ('phase', 'n'), ('detection', 'n'), ('pixels', 'n'), ('determines', 'v'), ('operating', 'v'), ('resolution', 'n'), ('regular', 'a'), ('pixels', 'n'), ('according', 'v'), ('autofocused', 'a'), ('pixel', 'n'), ('data', 'n'), ('phase', 'n'), ('detection', 'n'), ('pixels', 'n'), ('wherein', 'v'), ('phase', 'a'), ('detection', 'n'), ('pixels', 'n'), ('always-on', 'a'), ('pixels', 'n'), ('regular', 'a'), ('pixels', 'n'), ('selectively', 'r'), ('turned', 'v'), ('autofocusing', 'v'), ('accomplishedan', 'n'), ('apparatus', 'n'), ('includes', 'v'), ('first', 'a'), ('camera', 'n'), ('module', 'n'), ('providing', 'v'), ('first', 'a'), ('image', 'n'), ('object', 'v'), ('first', 'a'), ('field', 'n'), ('view', 'n'), ('second', 'a'), ('camera', 'n'), ('module', 'n'), ('providing', 'v'), ('second', 'a'), ('image', 'n'), ('object', 'a'), ('second', 'a'), ('field', 'n'), ('view', 'n'), ('different', 'a'), ('first', 'a'), ('field', 'n'), ('view', 'n'), ('first', 'r'), ('depth', 'v'), ('map', 'n'), ('generator', 'n'), ('generates', 'n'), ('first', 'r'), ('depth', 'v'), ('map', 'n'), ('first', 'r'), ('image', 'n'), ('based', 'v'), ('first', 'a'), ('image', 'n'), ('second', 'a'), ('image', 'n'), ('second', 'a'), ('depth', 'n'), ('map', 'n'), ('generator', 'n'), ('generates', 'v'), ('second', 'a'), ('depth', 'n'), ('map', 'n'), ('second', 'a'), ('image', 'n'), ('based', 'v'), ('first', 'a'), ('image', 'n'), ('second', 'a'), ('image', 'n'), ('first', 'r'), ('depth', 'a'), ('mapmethods', 'n'), ('systems', 'n'), ('apparatus', 'r'), ('including', 'v'), ('computer', 'n'), ('programs', 'n'), ('encoded', 'v'), ('computer', 'n'), ('storage', 'n'), ('media', 'n'), ('payment', 'n'), ('based', 'v'), ('face', 'n'), ('recognition', 'n'), ('provided', 'v'), ('one', None), ('methods', 'n'), ('includes', 'v'), ('acquiring', 'v'), ('first', 'a'), ('face', 'n'), ('image', 'n'), ('information', 'n'), ('target', 'n'), ('user', 'n'), ('extracting', 'v'), ('first', 'a'), ('characteristic', 'a'), ('information', 'n'), ('first', 'r'), ('face', 'n'), ('image', 'n'), ('information', 'n'), ('wherein', None), ('first', 'a'), ('characteristic', 'a'), ('information', 'n'), ('includes', 'v'), ('head', 'n'), ('posture', 'n'), ('information', 'n'), ('target', 'n'), ('user', 'n'), ('gaze', 'n'), ('information', 'n'), ('target', 'n'), ('user', 'n'), ('determining', 'v'), ('whether', None), ('target', 'n'), ('user', 'a'), ('willingness', 'n'), ('pay', 'n'), ('according', 'v'), ('head', 'n'), ('posture', 'n'), ('information', 'n'), ('target', 'n'), ('user', 'n'), ('gaze', 'n'), ('information', 'n'), ('target', 'n'), ('user', 'n'), ('including', 'v'), ('determining', 'v'), ('whether', None), ('angle', 'a'), ('rotation', 'n'), ('preset', 'v'), ('direction', 'n'), ('less', 'r'), ('angle', 'a'), ('threshold', 'n'), ('whether', None), ('probability', 'n'), ('value', 'n'), ('user', 'n'), ('gazes', 'a'), ('payment', 'n'), ('screen', 'n'), ('greater', 'a'), ('probability', 'n'), ('threshold', 'a'), ('response', 'n'), ('determining', 'v'), ('target', 'n'), ('user', 'a'), ('willingness', 'n'), ('pay', 'n'), ('completing', 'v'), ('payment', 'n'), ('operation', 'n'), ('based', 'v'), ('face', 'n'), ('recognitiona', 'n'), ('novel', 'a'), ('method', 'n'), ('apparatus', 'n'), ('face', 'n'), ('authentication', 'n'), ('disclosed', 'v'), ('disclosed', 'v'), ('method', 'n'), ('comprises', 'v'), ('detecting', 'v'), ('motion', 'n'), ('subject', 'n'), ('within', None), ('predetermined', 'a'), ('area', 'n'), ('view', 'n'), ('assigning', 'v'), ('unique', 'a'), ('session', 'n'), ('identification', 'n'), ('number', 'n'), ('subject', 'a'), ('detected', 'v'), ('within', None), ('predetermined', 'a'), ('area', 'n'), ('view', 'n'), ('detecting', 'v'), ('facial', 'a'), ('area', 'n'), ('subject', 'n'), ('detected', 'v'), ('within', None), ('predetermined', 'a'), ('area', 'n'), ('view', 'n'), ('generating', 'v'), ('image', 'n'), ('facial', 'a'), ('area', 'n'), ('subject', 'n'), ('assessing', 'v'), ('quality', 'n'), ('image', 'n'), ('facial', 'a'), ('area', 'n'), ('subject', 'a'), ('conducing', 'v'), ('incremental', 'a'), ('training', 'n'), ('image', 'n'), ('facial', 'a'), ('area', 'n'), ('subject', 'a'), ('determining', 'v'), ('identity', 'n'), ('subject', 'n'), ('based', 'v'), ('image', 'n'), ('facial', 'a'), ('area', 'n'), ('subject', 'a'), ('identifying', 'v'), ('intent', 'n'), ('subject', 'a'), ('authorizing', 'v'), ('access', 'n'), ('point', 'n'), ('entry', 'n'), ('based', 'v'), ('determined', 'v'), ('identity', 'n'), ('subject', 'n'), ('based', 'v'), ('intent', 'n'), ('subjectdisclosed', 'v'), ('herein', 'n'), ('robot', 'v'), ('electronic', 'a'), ('device', 'n'), ('acquiring', 'v'), ('video', 'a'), ('method', 'n'), ('acquiring', 'v'), ('video', 'n'), ('using', 'v'), ('robot', 'a'), ('robot', 'n'), ('includes', 'v'), ('camera', 'n'), ('configured', 'v'), ('rotate', 'a'), ('lateral', 'a'), ('direction', 'n'), ('tilt', 'v'), ('vertical', 'a'), ('direction', 'n'), ('controls', 'n'), ('least', 'v'), ('one', None), ('direction', 'n'), ('rotation', 'n'), ('camera', 'n'), ('angle', 'n'), ('tilt', 'n'), ('camera', 'n'), ('focal', 'a'), ('distance', 'n'), ('camera', 'n'), ('recognizing', 'v'), ('tracking', 'v'), ('users', 'n'), ('video', 'r'), ('acquired', 'v'), ('camerasystems', 'n'), ('methods', 'n'), ('disclosed', 'v'), ('inferring', 'v'), ('topics', 'n'), ('file', 'n'), ('containing', 'v'), ('audio', 'a'), ('video', 'n'), ('example', 'n'), ('multimodal', 'a'), ('multimedia', 'n'), ('file', 'n'), ('order', 'n'), ('facilitate', 'n'), ('video', 'n'), ('indexing', 'v'), ('set', 'v'), ('entities', 'n'), ('extracted', 'v'), ('file', 'n'), ('linked', 'v'), ('produce', 'v'), ('graph', 'a'), ('reference', 'n'), ('information', 'n'), ('also', 'r'), ('obtained', 'v'), ('set', 'a'), ('entities', 'n'), ('entities', 'n'), ('may', None), ('drawn', 'v'), ('example', 'n'), ('wikipedia', 'n'), ('categories', 'n'), ('large', 'a'), ('ontological', 'a'), ('data', 'n'), ('sources', 'n'), ('analysis', 'n'), ('graph', 'n'), ('using', 'v'), ('unsupervised', 'a'), ('learning', 'v'), ('permits', 'n'), ('determining', 'v'), ('clusters', 'n'), ('graph', 'v'), ('extracting', 'v'), ('features', 'n'), ('clusters', 'n'), ('possibly', 'r'), ('using', 'v'), ('supervised', 'v'), ('learning', 'v'), ('provides', 'v'), ('selection', 'n'), ('topic', 'n'), ('identifiers', 'n'), ('topic', 'v'), ('identifiers', 'n'), ('used', 'v'), ('indexing', 'v'), ('filea', 'a'), ('face', 'n'), ('recognition', 'n'), ('method', None), ('neural', 'a'), ('network', 'n'), ('training', 'v'), ('method', 'n'), ('apparatus', 'n'), ('electronic', 'a'), ('device', 'n'), ('method', 'n'), ('comprises', 'v'), ('obtaining', 'v'), ('first', 'a'), ('face', 'n'), ('image', 'n'), ('means', 'v'), ('first', 'a'), ('camera', 'n'), ('extracting', 'v'), ('first', 'a'), ('face', 'n'), ('feature', 'n'), ('first', 'a'), ('face', 'n'), ('image', 'n'), ('comparing', 'v'), ('first', 'a'), ('face', 'n'), ('feature', 'n'), ('pre-stored', 'a'), ('second', 'a'), ('face', 'n'), ('feature', 'n'), ('obtain', 'v'), ('reference', 'n'), ('similarity', 'n'), ('second', 'a'), ('face', 'n'), ('feature', 'n'), ('obtained', 'v'), ('extracting', 'a'), ('feature', 'a'), ('second', 'a'), ('face', 'n'), ('image', 'n'), ('obtained', 'v'), ('second', 'a'), ('camera', 'n'), ('second', 'a'), ('camera', 'n'), ('first', 'r'), ('camera', 'v'), ('different', 'a'), ('types', 'n'), ('cameras', 'n'), ('determining', 'v'), ('according', 'v'), ('reference', 'n'), ('similarity', 'n'), ('whether', None), ('first', 'a'), ('face', 'n'), ('feature', 'n'), ('second', 'a'), ('face', 'n'), ('feature', 'n'), ('correspond', 'n'), ('person', 'n'), ('present', 'a'), ('invention', 'n'), ('discloses', 'v'), ('technique', 'a'), ('alerting', 'v'), ('vision', 'n'), ('impairment', 'n'), ('system', 'n'), ('comprises', 'v'), ('processing', 'v'), ('unit', 'n'), ('configured', 'v'), ('operable', 'a'), ('receiving', 'v'), ('scene', 'n'), ('data', 'n'), ('indicative', 'a'), ('scene', 'n'), ('least', 'a'), ('one', None), ('consumer', 'n'), ('environment', 'n'), ('identifying', 'v'), ('scene', 'n'), ('data', 'n'), ('certain', 'a'), ('consumer', 'n'), ('identifying', 'v'), ('event', 'n'), ('indicative', 'a'), ('behavioral', 'a'), ('compensation', 'n'), ('vision', 'n'), ('impairment', 'n'), ('upon', None), ('identification', 'n'), ('event', 'n'), ('sending', 'v'), ('notification', 'n'), ('relating', 'v'), ('vision', 'n'), ('impairment', 'n')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('electronic', 'a'), ('device', 'n'), ('configured', 'v'), ('make', 'v'), ('screen', 'a'), ('display', 'n'), ('plurality', 'n'), ('image', 'n'), ('frames', 'n'), ('comprising', 'v'), ('image', 'n'), ('capturing', 'v'), ('device', 'a'), ('storage', 'n'), ('device', 'n'), ('storing', 'v'), ('plurality', 'n'), ('modules', 'n'), ('processor', 'v'), ('coupled', 'v'), ('image', 'n'), ('capturing', 'v'), ('device', 'a'), ('storage', 'n'), ('device', 'n'), ('configured', 'v'), ('execute', 'a'), ('modules', 'n'), ('storage', 'n'), ('device', 'n'), ('configure', 'n'), ('screen', 'n'), ('display', 'n'), ('plurality', 'n'), ('marker', 'n'), ('objects', 'v'), ('plurality', 'n'), ('predetermined', 'v'), ('calibration', 'n'), ('positions', 'n'), ('configure', 'v'), ('image', 'n'), ('capturing', 'n'), ('device', 'n'), ('capture', 'n'), ('plurality', 'n'), ('first', 'r'), ('head', 'a'), ('images', 'n'), ('user', 'v'), ('looking', 'v'), ('predetermined', 'v'), ('calibration', 'n'), ('positions', 'n'), ('perform', 'v'), ('plurality', 'n'), ('first', 'r'), ('face', 'n'), ('recognition', 'n'), ('operations', 'n'), ('first', 'r'), ('head', 'v'), ('images', 'n'), ('obtain', 'v'), ('plurality', 'n'), ('first', 'r'), ('face', 'n'), ('regions', 'n'), ('corresponding', 'v'), ('predetermined', 'a'), ('calibration', 'n'), ('positions', 'n'), ('detect', 'v'), ('plurality', 'n'), ('first', 'r'), ('facial', 'a'), ('landmarks', 'n'), ('corresponding', 'v'), ('first', 'a'), ('face', 'n'), ('regions', 'n'), ('calculate', 'v'), ('plurality', 'n'), ('rotation', 'n'), ('reference', 'n'), ('angles', 'n'), ('user', 'r'), ('looking', 'v'), ('predetermined', 'a'), ('calibration', 'n'), ('positions', 'n'), ('according', 'v'), ('first', 'a'), ('facial', 'a'), ('landmarks', 'n'), ('configure', 'n'), ('image', 'n'), ('capturing', 'v'), ('device', 'a'), ('capture', 'n'), ('second', 'a'), ('head', 'n'), ('image', 'n'), ('user', 'a'), ('perform', 'a'), ('second', 'a'), ('face', 'n'), ('recognition', 'n'), ('operation', 'n'), ('second', 'a'), ('head', 'n'), ('image', 'n'), ('obtain', 'v'), ('second', 'a'), ('face', 'n'), ('region', 'n'), ('detect', 'a'), ('plurality', 'n'), ('second', 'a'), ('facial', 'a'), ('landmarks', 'n'), ('within', None), ('second', 'a'), ('face', 'n'), ('region', 'n'), ('estimate', 'n'), ('head', 'n'), ('posture', 'n'), ('angle', 'v'), ('user', 'r'), ('according', 'v'), ('second', 'a'), ('facial', 'a'), ('landmarks', 'n'), ('calculate', 'v'), ('gaze', 'a'), ('position', 'n'), ('user', 'n'), ('screen', 'n'), ('according', 'v'), ('head', 'n'), ('posture', 'n'), ('angle', 'a'), ('rotation', 'n'), ('reference', 'n'), ('angles', 'n'), ('predetermined', 'v'), ('calibration', 'n'), ('positions', 'n'), ('configure', 'v'), ('screen', 'a'), ('display', 'n'), ('corresponding', 'v'), ('visual', 'a'), ('effect', 'n'), ('according', 'v'), ('gaze', 'a'), ('position', 'n'), ('electronic', 'a'), ('device', 'n'), ('according', 'v'), ('claim', 'n'), ('wherein', 'n'), ('gaze', 'a'), ('position', 'n'), ('comprises', 'n'), ('first', 'a'), ('coordinate', 'n'), ('value', 'n'), ('first', 'r'), ('axial', 'a'), ('direction', 'n'), ('second', 'a'), ('coordinate', 'n'), ('value', 'n'), ('second', 'a'), ('axial', 'a'), ('direction', 'n'), ('electronic', 'a'), ('device', 'n'), ('according', 'v'), ('claim', 'n'), ('wherein', 'n'), ('head', 'n'), ('posture', 'n'), ('angles', 'v'), ('comprise', 'r'), ('head', 'a'), ('pitch', 'n'), ('angle', 'n'), ('head', 'n'), ('yaw', 'n'), ('angle', 'a'), ('rotation', 'n'), ('reference', 'n'), ('angles', 'n'), ('comprise', 'v'), ('first', 'a'), ('pitch', 'n'), ('angle', 'n'), ('second', 'a'), ('pitch', 'n'), ('angle', 'n'), ('first', 'r'), ('yaw', 'r'), ('angle', 'a'), ('second', 'a'), ('yaw', 'n'), ('angle', 'n'), ('corresponding', 'v'), ('predetermined', 'a'), ('calibration', 'n'), ('positions', 'n'), ('electronic', 'a'), ('device', 'n'), ('according', 'v'), ('claim', 'n'), ('wherein', 'n'), ('processor', 'n'), ('performs', 'n'), ('interpolation', 'n'), ('operation', 'n'), ('extrapolation', 'n'), ('operation', 'n'), ('according', 'v'), ('first', 'a'), ('yaw', 'n'), ('angle', 'a'), ('second', 'a'), ('yaw', 'n'), ('angle', 'n'), ('first', 'a'), ('position', 'n'), ('corresponding', 'v'), ('first', 'a'), ('yaw', 'a'), ('angle', 'n'), ('among', None), ('predetermined', 'a'), ('calibration', 'n'), ('positions', 'n'), ('second', 'a'), ('position', 'n'), ('corresponding', 'v'), ('second', 'a'), ('yaw', 'a'), ('angle', 'n'), ('among', None), ('predetermined', 'a'), ('calibration', 'n'), ('positions', 'n'), ('head', 'v'), ('yaw', 'r'), ('angle', 'a'), ('thereby', 'r'), ('obtaining', 'v'), ('first', 'a'), ('coordinate', 'n'), ('value', 'n'), ('gaze', 'a'), ('position', 'n'), ('processor', 'n'), ('performs', 'n'), ('interpolation', 'n'), ('operation', 'n'), ('extrapolation', 'n'), ('operation', 'n'), ('according', 'v'), ('first', 'a'), ('pitch', 'n'), ('angle', 'n'), ('second', 'a'), ('pitch', 'n'), ('angle', 'n'), ('third', 'a'), ('position', 'n'), ('corresponding', 'v'), ('first', 'a'), ('pitch', 'n'), ('angle', 'n'), ('among', None), ('predetermined', 'a'), ('calibration', 'n'), ('positions', 'n'), ('fourth', 'a'), ('position', 'n'), ('corresponding', 'v'), ('second', 'a'), ('pitch', 'n'), ('angle', 'n'), ('among', None), ('predetermined', 'a'), ('calibration', 'n'), ('positions', 'n'), ('head', 'v'), ('pitch', 'n'), ('angle', 'n'), ('thereby', 'r'), ('obtaining', 'v'), ('second', 'a'), ('coordinate', 'n'), ('value', 'n'), ('gaze', 'a'), ('position', 'n'), ('electronic', 'a'), ('device', 'n'), ('according', 'v'), ('claim', 'n'), ('wherein', 'n'), ('processor', 'n'), ('calculates', 'n'), ('plurality', 'n'), ('first', 'r'), ('viewing', 'v'), ('distances', 'n'), ('user', 'r'), ('screen', 'v'), ('according', 'v'), ('first', 'r'), ('facial', 'a'), ('landmarks', 'n'), ('processor', 'v'), ('estimates', 'n'), ('second', 'a'), ('viewing', 'v'), ('distance', 'n'), ('user', 'n'), ('screen', 'n'), ('according', 'v'), ('second', 'a'), ('facial', 'a'), ('landmarks', 'n'), ('processor', 'v'), ('adjusts', 'n'), ('rotation', 'n'), ('reference', 'n'), ('angles', 'n'), ('gaze', 'v'), ('position', 'n'), ('according', 'v'), ('second', 'a'), ('viewing', 'n'), ('distance', 'n'), ('first', 'r'), ('viewing', 'v'), ('distances', 'n'), ('electronic', 'a'), ('device', 'n'), ('according', 'v'), ('claim', 'n'), ('wherein', 'n'), ('processor', 'n'), ('maps', 'n'), ('plurality', 'n'), ('two-dimensional', 'a'), ('position', 'n'), ('coordinates', 'n'), ('second', 'a'), ('facial', 'a'), ('landmarks', 'n'), ('plane', 'n'), ('coordinate', 'n'), ('system', 'n'), ('plurality', 'n'), ('three-dimensional', 'a'), ('position', 'n'), ('coordinates', 'v'), ('three-dimensional', 'a'), ('coordinate', 'n'), ('system', 'n'), ('processor', 'n'), ('estimates', 'n'), ('head', 'v'), ('posture', 'n'), ('angle', 'n'), ('according', 'v'), ('three-dimensional', 'a'), ('position', 'n'), ('coordinates', 'n'), ('second', 'a'), ('facial', 'a'), ('landmarks', 'n'), ('electronic', 'a'), ('device', 'n'), ('according', 'v'), ('claim', 'n'), ('wherein', 'n'), ('second', 'a'), ('head', 'n'), ('image', 'n'), ('comprises', 'v'), ('wearable', 'a'), ('device', 'n'), ('second', 'a'), ('facial', 'a'), ('landmarks', 'n'), ('comprise', 'v'), ('plurality', 'n'), ('third', 'a'), ('facial', 'a'), ('landmarks', 'n'), ('user', 'r'), ('covered', 'v'), ('wearable', 'a'), ('device', 'n'), ('electronic', 'a'), ('device', 'n'), ('according', 'v'), ('claim', 'n'), ('wherein', 'n'), ('second', 'a'), ('head', 'n'), ('image', 'n'), ('comprises', 'v'), ('wearable', 'a'), ('device', 'n'), ('second', 'a'), ('facial', 'a'), ('landmarks', 'n'), ('comprise', 'v'), ('one', None), ('simulated', 'v'), ('landmarks', 'n'), ('marked', 'v'), ('wearable', 'a'), ('device', 'n'), ('operating', 'v'), ('method', 'n'), ('adapted', 'v'), ('electronic', 'a'), ('device', 'n'), ('comprising', 'v'), ('image', 'n'), ('capturing', 'v'), ('device', 'n'), ('making', 'v'), ('screen', 'a'), ('display', 'n'), ('plurality', 'n'), ('image', 'n'), ('frames', 'n'), ('method', 'v'), ('comprising', 'v'), ('configuring', 'v'), ('screen', 'a'), ('display', 'n'), ('plurality', 'n'), ('marker', 'n'), ('objects', 'v'), ('plurality', 'n'), ('predetermined', 'v'), ('calibration', 'n'), ('positions', 'n'), ('configuring', 'v'), ('image', 'n'), ('capturing', 'v'), ('device', 'a'), ('capture', 'n'), ('plurality', 'n'), ('first', 'r'), ('head', 'a'), ('images', 'n'), ('user', 'v'), ('looking', 'v'), ('predetermined', 'v'), ('calibration', 'n'), ('positions', 'n'), ('performing', 'v'), ('plurality', 'n'), ('first', 'r'), ('face', 'n'), ('recognition', 'n'), ('operations', 'n'), ('first', 'r'), ('head', 'v'), ('images', 'n'), ('obtain', 'v'), ('plurality', 'n'), ('first', 'r'), ('face', 'n'), ('regions', 'n'), ('corresponding', 'v'), ('predetermined', 'a'), ('calibration', 'n'), ('positions', 'n'), ('detecting', 'v'), ('plurality', 'n'), ('first', 'r'), ('facial', 'a'), ('landmarks', 'n'), ('corresponding', 'v'), ('first', 'a'), ('face', 'n'), ('regions', 'n'), ('calculating', 'v'), ('plurality', 'n'), ('rotation', 'n'), ('reference', 'n'), ('angles', 'n'), ('user', 'r'), ('looking', 'v'), ('predetermined', 'a'), ('calibration', 'n'), ('positions', 'n'), ('according', 'v'), ('first', 'a'), ('facial', 'a'), ('landmarks', 'n'), ('configuring', 'v'), ('image', 'n'), ('capturing', 'v'), ('device', 'a'), ('capture', 'n'), ('second', 'a'), ('head', 'n'), ('image', 'n'), ('user', 'a'), ('performing', 'v'), ('second', 'a'), ('face', 'n'), ('recognition', 'n'), ('operation', 'n'), ('second', 'a'), ('head', 'n'), ('image', 'n'), ('obtain', 'v'), ('second', 'a'), ('face', 'n'), ('region', 'n'), ('detecting', 'v'), ('plurality', 'n'), ('second', 'a'), ('facial', 'a'), ('landmarks', 'n'), ('within', None), ('second', 'a'), ('face', 'n'), ('region', 'n'), ('estimating', 'v'), ('head', 'n'), ('posture', 'n'), ('angle', 'v'), ('user', 'r'), ('according', 'v'), ('second', 'a'), ('facial', 'a'), ('landmarks', 'n'), ('calculating', 'v'), ('gaze', 'a'), ('position', 'n'), ('user', 'n'), ('screen', 'n'), ('according', 'v'), ('head', 'n'), ('posture', 'n'), ('angle', 'a'), ('rotation', 'n'), ('reference', 'n'), ('angles', 'n'), ('predetermined', 'v'), ('calibration', 'n'), ('positions', 'n'), ('configuring', 'v'), ('screen', 'n'), ('display', 'n'), ('corresponding', 'v'), ('visual', 'a'), ('effect', 'n'), ('according', 'v'), ('gaze', 'a'), ('position', 'n'), ('operation', 'n'), ('method', 'n'), ('according', 'v'), ('claim', 'n'), ('wherein', 'n'), ('gaze', 'a'), ('position', 'n'), ('comprises', 'n'), ('first', 'a'), ('coordinate', 'n'), ('value', 'n'), ('first', 'r'), ('axial', 'a'), ('direction', 'n'), ('second', 'a'), ('coordinate', 'n'), ('value', 'n'), ('second', 'a'), ('axial', 'a'), ('direction', 'n'), ('operation', 'n'), ('method', 'n'), ('according', 'v'), ('claim', 'n'), ('wherein', 'n'), ('head', 'n'), ('posture', 'n'), ('angles', 'v'), ('comprise', 'r'), ('head', 'a'), ('pitch', 'n'), ('angle', 'n'), ('head', 'n'), ('yaw', 'n'), ('angle', 'a'), ('rotation', 'n'), ('reference', 'n'), ('angles', 'n'), ('comprise', 'v'), ('first', 'a'), ('pitch', 'n'), ('angle', 'n'), ('second', 'a'), ('pitch', 'n'), ('angle', 'n'), ('first', 'r'), ('yaw', 'r'), ('angle', 'a'), ('second', 'a'), ('yaw', 'n'), ('angle', 'n'), ('corresponding', 'v'), ('predetermined', 'a'), ('calibration', 'n'), ('positions', 'n'), ('operation', 'n'), ('method', 'n'), ('according', 'v'), ('claim', 'n'), ('wherein', 'a'), ('step', 'n'), ('calculating', 'v'), ('gaze', 'a'), ('position', 'n'), ('user', 'n'), ('screen', 'n'), ('according', 'v'), ('head', 'n'), ('posture', 'n'), ('angle', 'a'), ('rotation', 'n'), ('reference', 'n'), ('angles', 'n'), ('predetermined', 'v'), ('calibration', 'n'), ('positions', 'n'), ('comprises', 'v'), ('performing', 'v'), ('interpolation', 'n'), ('operation', 'n'), ('extrapolation', 'n'), ('operation', 'n'), ('according', 'v'), ('first', 'a'), ('yaw', 'n'), ('angle', 'a'), ('second', 'a'), ('yaw', 'n'), ('angle', 'n'), ('first', 'a'), ('position', 'n'), ('corresponding', 'v'), ('first', 'a'), ('yaw', 'a'), ('angle', 'n'), ('among', None), ('predetermined', 'a'), ('calibration', 'n'), ('positions', 'n'), ('second', 'a'), ('position', 'n'), ('corresponding', 'v'), ('second', 'a'), ('yaw', 'a'), ('angle', 'n'), ('among', None), ('predetermined', 'a'), ('calibration', 'n'), ('positions', 'n'), ('head', 'v'), ('yaw', 'r'), ('angle', 'a'), ('thereby', 'r'), ('obtaining', 'v'), ('first', 'a'), ('coordinate', 'n'), ('value', 'n'), ('gaze', 'a'), ('position', 'n'), ('performing', 'v'), ('interpolation', 'n'), ('operation', 'n'), ('extrapolation', 'n'), ('operation', 'n'), ('according', 'v'), ('first', 'a'), ('pitch', 'n'), ('angle', 'n'), ('second', 'a'), ('pitch', 'n'), ('angle', 'n'), ('third', 'a'), ('position', 'n'), ('corresponding', 'v'), ('first', 'a'), ('pitch', 'n'), ('angle', 'n'), ('among', None), ('predetermined', 'a'), ('calibration', 'n'), ('positions', 'n'), ('fourth', 'a'), ('position', 'n'), ('corresponding', 'v'), ('second', 'a'), ('pitch', 'n'), ('angle', 'n'), ('among', None), ('predetermined', 'a'), ('calibration', 'n'), ('positions', 'n'), ('head', 'v'), ('pitch', 'n'), ('angle', 'n'), ('thereby', 'r'), ('obtaining', 'v'), ('second', 'a'), ('coordinate', 'n'), ('value', 'n'), ('gaze', 'a'), ('position', 'n'), ('operation', 'n'), ('method', 'n'), ('according', 'v'), ('claim', 'n'), ('wherein', 'n'), ('method', 'n'), ('comprises', 'v'), ('calculating', 'v'), ('plurality', 'n'), ('first', 'r'), ('viewing', 'v'), ('distances', 'n'), ('user', 'r'), ('screen', 'v'), ('according', 'v'), ('first', 'r'), ('facial', 'a'), ('landmarks', 'n'), ('estimating', 'v'), ('second', 'a'), ('viewing', 'v'), ('distance', 'n'), ('user', 'n'), ('screen', 'n'), ('according', 'v'), ('second', 'a'), ('facial', 'a'), ('landmarks', 'n'), ('adjusting', 'v'), ('rotation', 'n'), ('reference', 'n'), ('angles', 'n'), ('gaze', 'v'), ('position', 'n'), ('according', 'v'), ('second', 'a'), ('viewing', 'n'), ('distance', 'n'), ('first', 'r'), ('viewing', 'v'), ('distances', 'n'), ('operation', 'n'), ('method', 'n'), ('according', 'v'), ('claim', 'n'), ('wherein', 'n'), ('method', 'n'), ('comprises', 'v'), ('mapping', 'v'), ('plurality', 'n'), ('two-dimensional', 'a'), ('position', 'n'), ('coordinates', 'n'), ('second', 'a'), ('facial', 'a'), ('landmarks', 'n'), ('plane', 'n'), ('coordinate', 'n'), ('system', 'n'), ('plurality', 'n'), ('three-dimensional', 'a'), ('position', 'n'), ('coordinates', 'v'), ('three-dimensional', 'a'), ('coordinate', 'n'), ('system', 'n'), ('estimating', 'v'), ('head', 'n'), ('posture', 'n'), ('angle', None), ('according', 'v'), ('three-dimensional', 'a'), ('position', 'n'), ('coordinates', 'n'), ('second', 'a'), ('facial', 'a'), ('landmarks', 'n'), ('operation', 'n'), ('method', 'n'), ('according', 'v'), ('claim', 'n'), ('wherein', 'n'), ('second', 'a'), ('head', 'n'), ('image', 'n'), ('comprises', 'v'), ('wearable', 'a'), ('device', 'n'), ('second', 'a'), ('facial', 'a'), ('landmarks', 'n'), ('comprise', 'v'), ('plurality', 'n'), ('third', 'a'), ('facial', 'a'), ('landmarks', 'n'), ('user', 'r'), ('covered', 'v'), ('wearable', 'a'), ('device', 'n'), ('operation', 'n'), ('method', 'n'), ('according', 'v'), ('claim', 'n'), ('wherein', 'n'), ('second', 'a'), ('head', 'n'), ('image', 'n'), ('comprises', 'v'), ('wearable', 'a'), ('device', 'n'), ('second', 'a'), ('facial', 'a'), ('landmarks', 'n'), ('comprise', 'v'), ('one', None), ('simulated', 'v'), ('landmarks', 'n'), ('marked', 'v'), ('wearable', 'a'), ('device', 'n'), ('computation', 'n'), ('method', 'n'), ('applied', 'v'), ('computing', 'v'), ('system', 'n'), ('wherein', 'v'), ('computing', 'v'), ('system', 'n'), ('comprises', 'v'), ('control', 'v'), ('unit', 'n'), ('computation', 'n'), ('group', 'n'), ('general', 'a'), ('storage', 'n'), ('unit', 'n'), ('wherein', 'v'), ('control', 'a'), ('unit', 'n'), ('comprises', 'v'), ('first', 'a'), ('memory', 'n'), ('decoding', 'v'), ('logic', 'a'), ('controller', 'n'), ('wherein', 'n'), ('computation', 'n'), ('group', 'n'), ('comprises', 'v'), ('group', 'n'), ('controller', 'n'), ('plurality', 'n'), ('computing', 'v'), ('units', 'n'), ('general', 'a'), ('storage', 'n'), ('unit', 'n'), ('configured', 'v'), ('store', 'n'), ('data', 'n'), ('computation', 'n'), ('method', 'n'), ('comprises', 'v'), ('receiving', 'v'), ('controller', 'n'), ('first', 'r'), ('level', 'a'), ('instruction', 'n'), ('sequence', 'n'), ('partitioning', 'v'), ('decoding', 'v'), ('logic', 'a'), ('first', 'a'), ('level', 'n'), ('instruction', 'n'), ('sequence', 'n'), ('plurality', 'n'), ('second', 'a'), ('level', 'n'), ('instruction', 'n'), ('sequences', 'n'), ('creating', 'v'), ('controller', 'n'), ('threads', 'n'), ('plurality', 'a'), ('second', 'a'), ('level', 'n'), ('instruction', 'n'), ('sequences', 'n'), ('allocating', 'v'), ('controller', 'n'), ('independent', 'a'), ('register', 'n'), ('well', 'r'), ('configuring', 'v'), ('independent', 'a'), ('addressing', 'v'), ('function', 'n'), ('thread', 'n'), ('threads', 'n'), ('wherein', 'v'), ('integer', 'a'), ('greater', 'a'), ('equal', 'a'), ('obtaining', 'v'), ('group', 'n'), ('controller', 'n'), ('plurality', 'n'), ('computation', 'n'), ('types', 'n'), ('plurality', 'a'), ('second', 'a'), ('level', 'n'), ('instruction', 'n'), ('sequences', 'n'), ('obtaining', 'v'), ('corresponding', 'v'), ('fusion', 'n'), ('computation', 'n'), ('manner', 'n'), ('computation', 'n'), ('types', 'n'), ('according', 'v'), ('plurality', 'n'), ('computation', 'n'), ('types', 'n'), ('adopting', 'v'), ('plurality', 'n'), ('computing', 'v'), ('units', 'n'), ('fusion', 'n'), ('computation', 'n'), ('manner', 'n'), ('call', 'n'), ('threads', 'n'), ('performing', 'v'), ('computations', 'n'), ('plurality', 'n'), ('second', 'a'), ('level', 'n'), ('instruction', 'n'), ('sequences', 'n'), ('obtain', 'v'), ('final', 'a'), ('result', 'n'), ('method', 'n'), ('claim', 'n'), ('wherein', None), ('obtaining', 'v'), ('group', 'n'), ('controller', 'n'), ('plurality', 'n'), ('computation', 'n'), ('types', 'n'), ('plurality', 'a'), ('second', 'a'), ('level', 'n'), ('instruction', 'n'), ('sequences', 'n'), ('obtaining', 'v'), ('corresponding', 'v'), ('fusion', 'n'), ('computation', 'n'), ('manner', 'n'), ('computation', 'n'), ('types', 'n'), ('according', 'v'), ('plurality', 'n'), ('computation', 'n'), ('types', 'n'), ('adopting', 'v'), ('plurality', 'n'), ('computing', 'v'), ('units', 'n'), ('fusion', 'n'), ('computation', 'n'), ('manner', 'n'), ('call', 'n'), ('threads', 'n'), ('performing', 'v'), ('computations', 'n'), ('plurality', 'n'), ('second', 'a'), ('instruction', 'n'), ('sequences', 'n'), ('obtain', 'v'), ('final', 'a'), ('result', 'n'), ('computation', 'n'), ('types', 'n'), ('represent', 'a'), ('computation', 'n'), ('operations', 'n'), ('type', 'v'), ('group', 'n'), ('controller', 'n'), ('calls', 'v'), ('combined', 'v'), ('computation', 'n'), ('manner', 'n'), ('single', 'a'), ('instruction', 'n'), ('multiple', 'n'), ('data', 'n'), ('type', 'n'), ('combination', 'n'), ('single', 'a'), ('instruction', 'n'), ('multiple', 'a'), ('threads', 'n'), ('uses', 'v'), ('threads', 'n'), ('perform', 'n'), ('combined', 'v'), ('computation', 'n'), ('manner', 'n'), ('obtain', 'v'), ('final', 'a'), ('result', 'n'), ('includes', 'v'), ('partitioning', 'v'), ('decoding', 'v'), ('logic', 'a'), ('threads', 'n'), ('n', 'r'), ('wraps', 'v'), ('allocating', 'v'), ('plurality', 'n'), ('computing', 'v'), ('units', 'n'), ('converting', 'v'), ('group', 'n'), ('controller', 'n'), ('plurality', 'n'), ('second', 'a'), ('instruction', 'n'), ('sequences', 'n'), ('plurality', 'a'), ('second', 'a'), ('control', 'n'), ('signals', 'n'), ('sending', 'v'), ('second', 'a'), ('control', 'n'), ('signals', 'n'), ('plurality', 'n'), ('computing', 'v'), ('units', 'n'), ('calling', 'v'), ('plurality', 'n'), ('computing', 'v'), ('units', 'n'), ('wraps', 'n'), ('allocated', 'v'), ('computing', 'v'), ('units', 'n'), ('second', 'a'), ('control', 'n'), ('signals', 'n'), ('fetch', 'v'), ('corresponding', 'v'), ('data', 'n'), ('according', 'v'), ('independent', 'a'), ('addressing', 'v'), ('function', 'n'), ('performing', 'v'), ('plurality', 'n'), ('computing', 'v'), ('units', 'n'), ('computations', 'n'), ('data', 'n'), ('obtain', 'v'), ('plurality', 'n'), ('intermediate', 'a'), ('results', 'n'), ('splicing', 'v'), ('plurality', 'n'), ('intermediate', 'a'), ('results', 'n'), ('obtain', 'v'), ('final', 'a'), ('result', 'n'), ('method', 'n'), ('claim', 'n'), ('wherein', None), ('obtaining', 'v'), ('group', 'n'), ('controller', 'n'), ('plurality', 'n'), ('computation', 'n'), ('types', 'n'), ('plurality', 'a'), ('second', 'a'), ('level', 'n'), ('instruction', 'n'), ('sequences', 'n'), ('obtaining', 'v'), ('corresponding', 'v'), ('fusion', 'n'), ('computation', 'n'), ('manner', 'n'), ('computation', 'n'), ('types', 'n'), ('according', 'v'), ('plurality', 'n'), ('computation', 'n'), ('types', 'n'), ('adopting', 'v'), ('plurality', 'n'), ('computing', 'v'), ('units', 'n'), ('fusion', 'n'), ('computation', 'n'), ('manner', 'n'), ('call', 'n'), ('threads', 'n'), ('performing', 'v'), ('computations', 'n'), ('plurality', 'n'), ('second', 'a'), ('instruction', 'n'), ('sequences', 'n'), ('obtain', 'v'), ('final', 'a'), ('result', 'n'), ('computation', 'n'), ('types', 'n'), ('represent', 'a'), ('computation', 'n'), ('operations', 'n'), ('different', 'a'), ('types', 'n'), ('group', 'n'), ('controller', 'n'), ('calls', 'v'), ('simultaneous', 'a'), ('multi-threading', 'a'), ('threads', 'n'), ('perform', 'v'), ('computations', 'n'), ('obtain', 'v'), ('final', 'a'), ('result', 'n'), ('includes', 'v'), ('partitioning', 'v'), ('decoding', 'v'), ('logic', 'a'), ('threads', 'n'), ('n', 'r'), ('wraps', 'v'), ('converting', 'v'), ('plurality', 'n'), ('second', 'a'), ('instruction', 'n'), ('sequences', 'n'), ('plurality', 'a'), ('second', 'a'), ('control', 'n'), ('signals', 'n'), ('obtaining', 'v'), ('group', 'n'), ('controller', 'n'), ('computation', 'n'), ('types', 'n'), ('supported', 'v'), ('plurality', 'n'), ('computing', 'v'), ('units', 'n'), ('allocating', 'v'), ('controller', 'n'), ('n', 'n'), ('wraps', 'n'), ('plurality', 'a'), ('second', 'a'), ('control', 'n'), ('signals', 'n'), ('corresponding', 'v'), ('computing', 'v'), ('units', 'n'), ('support', 'n'), ('computation', 'n'), ('types', 'n'), ('wraps', 'v'), ('second', 'a'), ('control', 'n'), ('signals', 'n'), ('calling', 'v'), ('plurality', 'n'), ('computing', 'v'), ('units', 'n'), ('wraps', 'n'), ('allocated', 'v'), ('computing', 'v'), ('units', 'n'), ('second', 'a'), ('control', 'n'), ('signals', 'n'), ('fetching', 'v'), ('plurality', 'n'), ('computing', 'v'), ('units', 'n'), ('corresponding', 'v'), ('data', 'n'), ('performing', 'v'), ('plurality', 'n'), ('computing', 'v'), ('units', 'n'), ('computations', 'n'), ('data', 'n'), ('obtain', 'v'), ('plurality', 'n'), ('intermediate', 'a'), ('results', 'n'), ('splicing', 'v'), ('intermediate', 'a'), ('results', 'n'), ('obtain', 'v'), ('final', 'a'), ('result', 'n'), ('method', 'n'), ('claim', 'n'), ('comprising', 'v'), ('wrap', 'n'), ('plurality', 'n'), ('wraps', 'n'), ('blocked', 'v'), ('adding', 'v'), ('wrap', 'n'), ('waiting', 'v'), ('queue', 'n'), ('data', 'n'), ('wrap', 'n'), ('already', 'r'), ('fetched', 'v'), ('adding', 'v'), ('wrap', 'n'), ('preparation', 'n'), ('queue', 'n'), ('wherein', None), ('preparation', 'n'), ('queue', 'n'), ('queue', 'n'), ('wrap', 'n'), ('scheduled', 'v'), ('executing', 'v'), ('located', 'v'), ('computing', 'v'), ('resource', 'n'), ('idle', 'a'), ('method', 'n'), ('claim', 'n'), ('wherein', 'v'), ('first', 'a'), ('level', 'n'), ('instruction', 'n'), ('sequence', 'n'), ('includes', 'v'), ('long', 'a'), ('instruction', 'n'), ('second', 'a'), ('level', 'n'), ('instruction', 'n'), ('sequence', 'n'), ('includes', 'v'), ('instruction', 'n'), ('sequence', 'n'), ('method', 'n'), ('claim', 'n'), ('wherein', None), ('computing', 'v'), ('system', 'n'), ('includes', 'v'), ('tree', 'a'), ('module', 'n'), ('wherein', 'v'), ('tree', 'a'), ('module', 'n'), ('includes', 'v'), ('root', 'a'), ('port', 'n'), ('plurality', 'n'), ('branch', 'n'), ('ports', 'n'), ('wherein', 'v'), ('root', 'a'), ('port', 'n'), ('tree', 'n'), ('module', 'n'), ('connected', 'v'), ('group', 'n'), ('controller', 'n'), ('plurality', 'n'), ('branch', 'n'), ('ports', 'n'), ('tree', 'v'), ('module', 'n'), ('connected', 'v'), ('computing', 'v'), ('unit', 'n'), ('plurality', 'n'), ('computing', 'v'), ('units', 'n'), ('respectively', 'r'), ('tree', 'v'), ('module', 'n'), ('configured', 'v'), ('forward', 'r'), ('data', 'n'), ('blocks', 'n'), ('wraps', 'v'), ('instruction', 'n'), ('sequences', 'n'), ('group', 'n'), ('controller', 'n'), ('plurality', 'n'), ('computing', 'v'), ('units', 'n'), ('method', None), ('claim', 'n'), ('wherein', 'v'), ('tree', 'a'), ('module', 'n'), ('n-ary', 'a'), ('tree', 'n'), ('wherein', 'n'), ('n', 'r'), ('integer', 'r'), ('greater', 'a'), ('equal', 'a'), ('method', 'n'), ('claim', 'n'), ('wherein', None), ('computing', 'v'), ('system', 'n'), ('includes', 'v'), ('branch', 'n'), ('processing', 'v'), ('circuit', 'n'), ('wherein', 'n'), ('branch', 'n'), ('processing', 'v'), ('circuit', 'n'), ('connected', 'v'), ('group', 'n'), ('controller', 'n'), ('plurality', 'n'), ('computing', 'v'), ('units', 'n'), ('branch', 'n'), ('processing', 'v'), ('circuit', 'n'), ('configured', 'v'), ('forward', 'r'), ('data', 'n'), ('wraps', 'n'), ('instruction', 'n'), ('sequences', 'n'), ('group', 'n'), ('controller', 'n'), ('plurality', 'n'), ('computing', 'v'), ('units', 'n'), ('computing', 'v'), ('system', 'n'), ('comprising', 'v'), ('control', 'n'), ('unit', 'n'), ('computation', 'n'), ('group', 'n'), ('general', 'a'), ('storage', 'n'), ('unit', 'n'), ('wherein', 'v'), ('control', 'a'), ('unit', 'n'), ('includes', 'v'), ('first', 'a'), ('memory', 'n'), ('decoding', 'v'), ('logic', 'a'), ('controller', 'n'), ('computation', 'n'), ('group', 'n'), ('includes', 'v'), ('group', 'n'), ('controller', 'n'), ('plurality', 'n'), ('computing', 'v'), ('units', 'n'), ('general', 'a'), ('storage', 'n'), ('unit', 'n'), ('configured', 'v'), ('store', 'n'), ('data', 'n'), ('controller', 'n'), ('configured', 'v'), ('receive', 'a'), ('first', 'a'), ('level', 'n'), ('instruction', 'n'), ('sequence', 'n'), ('control', 'n'), ('first', 'a'), ('memory', 'n'), ('decoding', 'v'), ('logic', 'a'), ('decoding', 'v'), ('logic', 'n'), ('configured', 'v'), ('partition', 'n'), ('first', 'r'), ('level', 'a'), ('instruction', 'n'), ('sequence', 'n'), ('plurality', 'n'), ('second', 'a'), ('level', 'n'), ('instruction', 'n'), ('sequences', 'n'), ('controller', 'v'), ('configured', 'a'), ('create', 'n'), ('threads', 'n'), ('plurality', 'a'), ('second', 'a'), ('level', 'n'), ('instruction', 'n'), ('sequences', 'n'), ('allocate', 'v'), ('independent', 'a'), ('register', 'n'), ('configure', 'n'), ('independent', 'a'), ('addressing', 'v'), ('function', 'n'), ('thread', 'n'), ('threads', 'n'), ('integer', 'v'), ('greater', 'a'), ('equal', 'a'), ('controller', 'n'), ('configured', 'v'), ('convert', 'a'), ('plurality', 'n'), ('second', 'a'), ('instruction', 'n'), ('sequences', 'n'), ('plurality', 'n'), ('control', 'n'), ('signals', 'n'), ('sending', 'v'), ('group', 'n'), ('controller', 'n'), ('group', 'n'), ('controller', 'n'), ('configured', 'v'), ('receive', 'a'), ('plurality', 'n'), ('control', 'n'), ('signals', 'n'), ('obtain', 'v'), ('plurality', 'a'), ('computational', 'a'), ('types', 'n'), ('plurality', 'n'), ('control', 'n'), ('signals', 'n'), ('divide', 'v'), ('threads', 'n'), ('n', 'r'), ('wraps', 'v'), ('allocate', 'a'), ('n', 'n'), ('wraps', 'n'), ('plurality', 'n'), ('control', 'n'), ('signals', 'n'), ('plurality', 'n'), ('computing', 'v'), ('units', 'n'), ('according', 'v'), ('plurality', 'n'), ('computational', 'a'), ('types', 'n'), ('plurality', 'n'), ('computing', 'v'), ('units', 'n'), ('configured', 'v'), ('fetch', 'r'), ('data', 'n'), ('general', 'a'), ('storage', 'n'), ('unit', 'n'), ('allocated', 'v'), ('wraps', 'n'), ('control', 'n'), ('signals', 'n'), ('perform', 'v'), ('computations', 'n'), ('obtain', 'v'), ('intermediate', 'a'), ('result', 'n'), ('group', 'n'), ('controller', 'n'), ('configured', 'v'), ('splice', 'a'), ('intermediate', 'a'), ('results', 'n'), ('obtain', 'v'), ('final', 'a'), ('computation', 'n'), ('result', 'n'), ('computing', 'v'), ('system', 'n'), ('claim', 'n'), ('wherein', 'v'), ('plurality', 'n'), ('computing', 'v'), ('units', 'n'), ('includes', 'v'), ('addition', 'n'), ('computing', 'v'), ('unit', 'n'), ('multiplication', 'n'), ('computing', 'v'), ('unit', 'n'), ('activation', 'n'), ('computing', 'v'), ('unit', 'n'), ('dedicated', 'v'), ('computing', 'v'), ('unit', 'n'), ('computing', 'v'), ('system', 'n'), ('claim', 'n'), ('wherein', 'r'), ('dedicated', 'v'), ('computing', 'v'), ('unit', 'n'), ('includes', 'v'), ('face', 'n'), ('recognition', 'n'), ('computing', 'v'), ('unit', 'n'), ('graphics', 'n'), ('computing', 'v'), ('unit', 'n'), ('fingerprint', 'n'), ('computing', 'v'), ('unit', 'n'), ('neural', 'a'), ('network', 'n'), ('computing', 'v'), ('unit', 'n'), ('computing', 'v'), ('system', 'n'), ('claim', 'n'), ('wherein', 'n'), ('group', 'n'), ('controller', 'n'), ('configured', 'v'), ('computation', 'n'), ('types', 'n'), ('plurality', 'n'), ('control', 'n'), ('signals', 'n'), ('graphics', 'n'), ('computations', 'n'), ('fingerprint', 'v'), ('identification', 'n'), ('face', 'n'), ('recognition', 'n'), ('neural', 'a'), ('network', 'n'), ('operations', 'n'), ('allocate', 'v'), ('plurality', 'n'), ('control', 'n'), ('signals', 'n'), ('face', 'v'), ('recognition', 'n'), ('computing', 'v'), ('unit', 'n'), ('graphics', 'n'), ('computing', 'v'), ('unit', 'n'), ('fingerprint', 'n'), ('computing', 'v'), ('unit', 'n'), ('neural', 'a'), ('network', 'n'), ('computing', 'v'), ('unit', 'n'), ('respectively', 'r'), ('computing', 'v'), ('system', 'n'), ('claim', 'n'), ('wherein', 'v'), ('first', 'a'), ('level', 'n'), ('instruction', 'n'), ('sequence', 'n'), ('includes', 'v'), ('long', 'a'), ('instruction', 'n'), ('second', 'a'), ('level', 'n'), ('instruction', 'n'), ('sequence', 'n'), ('includes', 'v'), ('instruction', 'n'), ('sequence', 'n'), ('computing', 'v'), ('system', 'n'), ('claim', 'n'), ('comprising', 'v'), ('tree', 'a'), ('module', 'n'), ('wherein', 'v'), ('tree', 'a'), ('module', 'n'), ('includes', 'v'), ('root', 'a'), ('port', 'n'), ('plurality', 'n'), ('branch', 'n'), ('ports', 'n'), ('wherein', 'v'), ('root', 'a'), ('port', 'n'), ('tree', 'n'), ('module', 'n'), ('connected', 'v'), ('group', 'n'), ('controller', 'n'), ('plurality', 'n'), ('branch', 'n'), ('ports', 'n'), ('tree', 'v'), ('module', 'n'), ('connected', 'v'), ('computing', 'v'), ('unit', 'n'), ('plurality', 'n'), ('computing', 'v'), ('units', 'n'), ('respectively', 'r'), ('tree', 'v'), ('module', 'n'), ('configured', 'v'), ('forward', 'r'), ('data', 'n'), ('blocks', 'n'), ('wraps', 'v'), ('instruction', 'n'), ('sequences', 'n'), ('group', 'n'), ('controller', 'n'), ('plurality', 'n'), ('computing', 'v'), ('units', 'n'), ('computing', 'v'), ('system', 'n'), ('claim', 'n'), ('wherein', 'v'), ('tree', 'a'), ('module', 'n'), ('n-ary', 'a'), ('tree', 'n'), ('wherein', 'n'), ('n', 'r'), ('integer', 'r'), ('greater', 'a'), ('equal', 'a'), ('computing', 'n'), ('system', 'n'), ('claim', 'n'), ('wherein', None), ('computing', 'v'), ('system', 'n'), ('includes', 'v'), ('branch', 'n'), ('processing', 'n'), ('circuit', 'n'), ('branch', 'n'), ('processing', 'v'), ('circuit', 'n'), ('connected', 'v'), ('group', 'n'), ('controller', 'n'), ('plurality', 'n'), ('computing', 'v'), ('units', 'n'), ('branch', 'n'), ('processing', 'v'), ('circuit', 'n'), ('configured', 'v'), ('forward', 'r'), ('data', 'n'), ('wraps', 'n'), ('instruction', 'n'), ('sequences', 'n'), ('group', 'n'), ('controller', 'n'), ('plurality', 'n'), ('computing', 'v'), ('units', 'n'), ('computer', 'n'), ('program', 'n'), ('product', 'n'), ('comprising', 'v'), ('non-instant', 'a'), ('computer', 'n'), ('readable', 'a'), ('storage', 'n'), ('medium', 'n'), ('wherein', 'v'), ('computer', 'n'), ('program', 'n'), ('stored', 'v'), ('non-instant', 'a'), ('computer', 'n'), ('readable', 'a'), ('storage', 'n'), ('medium', 'n'), ('computer', 'n'), ('program', 'n'), ('capable', 'a'), ('causing', 'v'), ('computer', 'n'), ('perform', 'n'), ('method', 'n'), ('claims', 'v'), ('operations', 'n'), ('method', 'v'), ('detecting', 'v'), ('body', 'n'), ('information', 'n'), ('one', None), ('passengers', 'n'), ('vehicle', 'n'), ('based', 'v'), ('humans', 'n'), (\"'\", None), ('status', 'n'), ('recognition', 'n'), ('comprising', 'v'), ('steps', 'n'), ('least', 'a'), ('one', None), ('interior', 'a'), ('image', 'n'), ('interior', 'a'), ('vehicle', 'n'), ('acquired', 'v'), ('passenger', 'a'), ('body', 'n'), ('information-detecting', 'a'), ('device', 'n'), ('performing', 'v'), ('process', 'n'), ('inputting', 'v'), ('interior', 'a'), ('image', 'n'), ('face', 'n'), ('recognition', 'n'), ('network', 'n'), ('thereby', 'r'), ('allow', 'v'), ('face', 'n'), ('recognition', 'n'), ('network', 'n'), ('detect', 'a'), ('faces', 'v'), ('passengers', 'n'), ('interior', 'a'), ('image', 'n'), ('thus', 'r'), ('output', 'n'), ('multiple', 'a'), ('pieces', 'n'), ('passenger', 'n'), ('feature', 'n'), ('information', 'n'), ('corresponding', 'v'), ('detected', 'v'), ('faces', 'v'), ('ii', 'a'), ('process', 'n'), ('inputting', 'v'), ('interior', 'a'), ('image', 'n'), ('body', 'n'), ('recognition', 'n'), ('network', 'n'), ('thereby', 'r'), ('allow', 'v'), ('body', 'n'), ('recognition', 'n'), ('network', 'n'), ('detect', 'a'), ('bodies', 'n'), ('passengers', 'n'), ('interior', 'a'), ('image', 'n'), ('thus', 'r'), ('output', 'n'), ('body-part', 'a'), ('length', 'n'), ('information', 'n'), ('detected', 'v'), ('bodies', 'n'), ('b', None), ('passenger', 'n'), ('body', 'n'), ('information-detecting', 'a'), ('device', 'n'), ('performing', 'v'), ('process', 'n'), ('retrieving', 'v'), ('specific', 'a'), ('height', 'a'), ('mapping', 'n'), ('information', 'n'), ('corresponding', 'v'), ('specific', 'a'), ('passenger', 'n'), ('feature', 'n'), ('information', 'n'), ('specific', 'a'), ('passenger', 'n'), ('height', 'v'), ('mapping', 'v'), ('table', 'n'), ('stores', 'n'), ('height', 'v'), ('mapping', 'v'), ('information', 'n'), ('representing', 'v'), ('respective', 'a'), ('one', None), ('predetermined', 'v'), ('ratios', 'n'), ('one', None), ('segment', 'n'), ('body', 'n'), ('portions', 'n'), ('human', 'a'), ('groups', 'n'), ('heights', 'n'), ('per', None), ('human', 'a'), ('groups', 'n'), ('process', 'n'), ('acquiring', 'v'), ('specific', 'a'), ('height', 'n'), ('specific', 'a'), ('passenger', 'n'), ('specific', 'a'), ('height', 'v'), ('mapping', 'v'), ('information', 'n'), ('referring', 'v'), ('specific', 'a'), ('body-part', 'a'), ('length', 'n'), ('information', 'n'), ('specific', 'a'), ('passenger', 'n'), ('process', 'n'), ('retrieving', 'v'), ('specific', 'a'), ('weight', 'n'), ('mapping', 'v'), ('information', 'n'), ('corresponding', 'v'), ('specific', 'a'), ('passenger', 'n'), ('feature', 'n'), ('information', 'n'), ('weight', 'v'), ('mapping', 'v'), ('table', 'n'), ('stores', 'n'), ('multiple', 'a'), ('pieces', 'n'), ('weight', 'v'), ('mapping', 'v'), ('information', 'n'), ('representing', 'v'), ('predetermined', 'v'), ('correlations', 'n'), ('heights', 'n'), ('weights', 'n'), ('per', None), ('human', 'a'), ('groups', 'n'), ('process', 'n'), ('acquiring', 'v'), ('weight', 'n'), ('specific', 'a'), ('passenger', 'n'), ('specific', 'a'), ('weight', 'v'), ('mapping', 'v'), ('information', 'n'), ('referring', 'v'), ('specific', 'a'), ('height', 'n'), ('specific', 'a'), ('passenger', 'n'), ('method', 'n'), ('claim', 'n'), ('wherein', 'a'), ('step', 'n'), ('passenger', 'n'), ('body', 'n'), ('information-detecting', 'a'), ('device', 'n'), ('performs', 'n'), ('process', 'n'), ('inputting', 'v'), ('interior', 'a'), ('image', 'n'), ('body', 'n'), ('recognition', 'n'), ('network', 'n'), ('thereby', 'r'), ('allow', 'v'), ('body', 'n'), ('recognition', 'n'), ('network', 'n'), ('output', 'n'), ('one', None), ('feature', 'n'), ('tensors', 'v'), ('one', None), ('channels', 'n'), ('corresponding', 'v'), ('interior', 'a'), ('image', 'n'), ('via', None), ('feature', 'n'), ('extraction', 'n'), ('network', 'n'), ('ii', 'a'), ('generate', 'n'), ('least', 'a'), ('one', None), ('keypoint', 'n'), ('heatmap', 'n'), ('least', 'a'), ('one', None), ('part', 'n'), ('affinity', 'n'), ('field', 'n'), ('one', None), ('channels', 'n'), ('corresponding', 'v'), ('feature', 'n'), ('tensors', 'n'), ('via', None), ('keypoint', 'n'), ('heatmap', 'n'), ('&', None), ('part', 'n'), ('affinity', 'n'), ('field', 'n'), ('extractor', 'n'), ('iii', 'a'), ('extract', 'a'), ('keypoints', 'n'), ('keypoint', 'v'), ('heatmap', 'n'), ('via', None), ('keypoint', 'n'), ('detector', 'n'), ('group', 'n'), ('extracted', 'v'), ('keypoints', 'n'), ('referring', 'v'), ('part', 'n'), ('affinity', 'n'), ('field', 'n'), ('thus', 'r'), ('generate', 'v'), ('body', 'n'), ('parts', 'n'), ('per', None), ('passengers', 'n'), ('result', 'v'), ('allow', None), ('body', 'n'), ('recognition', 'n'), ('network', 'n'), ('output', 'n'), ('multiple', 'a'), ('pieces', 'n'), ('body-part', 'a'), ('length', 'n'), ('information', 'n'), ('passengers', 'n'), ('referring', 'v'), ('body', 'n'), ('parts', 'n'), ('per', None), ('passengers', 'n'), ('method', 'v'), ('claim', 'n'), ('wherein', 'n'), ('feature', 'n'), ('extraction', 'n'), ('network', 'n'), ('includes', 'v'), ('least', 'a'), ('one', None), ('convolutional', 'a'), ('layer', 'n'), ('applies', 'n'), ('least', 'v'), ('one', None), ('convolution', 'n'), ('operation', 'n'), ('interior', 'a'), ('image', 'n'), ('thereby', 'n'), ('output', 'n'), ('feature', 'n'), ('tensors', 'n'), ('method', 'v'), ('claim', 'n'), ('wherein', 'n'), ('keypoint', 'n'), ('heatmap', 'n'), ('&', None), ('part', 'n'), ('affinity', 'n'), ('field', 'n'), ('extractor', 'n'), ('includes', 'v'), ('one', None), ('fully', 'r'), ('convolutional', 'a'), ('network', 'n'), ('convolutional', 'n'), ('layer', 'n'), ('applies', 'v'), ('fully-convolution', 'n'), ('operation', 'n'), ('convolution', 'n'), ('operation', 'n'), ('feature', 'n'), ('tensors', 'n'), ('thereby', 'r'), ('generate', 'v'), ('keypoint', 'n'), ('heatmap', 'n'), ('part', 'n'), ('affinity', 'n'), ('field', 'n'), ('method', 'n'), ('claim', 'n'), ('wherein', 'v'), ('keypoint', 'a'), ('detector', 'n'), ('connects', 'n'), ('referring', 'v'), ('part', 'n'), ('affinity', 'n'), ('field', 'n'), ('pairs', 'v'), ('respectively', 'r'), ('highest', 'a'), ('mutual', 'a'), ('connection', 'n'), ('probabilities', 'n'), ('connected', 'v'), ('among', None), ('extracted', 'a'), ('keypoints', 'n'), ('thereby', 'r'), ('group', 'n'), ('extracted', 'v'), ('keypoints', 'n'), ('method', 'a'), ('claim', 'n'), ('wherein', 'n'), ('feature', 'n'), ('extraction', 'n'), ('network', 'n'), ('keypoint', 'n'), ('heatmap', 'n'), ('&', None), ('part', 'n'), ('affinity', 'n'), ('field', 'n'), ('extractor', 'n'), ('learned', 'v'), ('learning', 'a'), ('device', 'n'), ('performing', 'v'), ('process', 'n'), ('inputting', 'v'), ('least', 'a'), ('one', None), ('training', 'n'), ('image', 'n'), ('including', 'v'), ('one', None), ('objects', 'v'), ('training', 'v'), ('feature', 'n'), ('extraction', 'n'), ('network', 'n'), ('thereby', 'r'), ('allow', 'a'), ('feature', 'n'), ('extraction', 'n'), ('network', 'n'), ('generate', 'v'), ('one', None), ('feature', 'n'), ('tensors', 'n'), ('training', 'v'), ('one', None), ('channels', 'n'), ('applying', 'v'), ('least', 'a'), ('one', None), ('convolutional', 'a'), ('operation', 'n'), ('training', 'n'), ('image', 'n'), ('ii', 'a'), ('process', 'n'), ('inputting', 'v'), ('feature', 'n'), ('tensors', 'n'), ('training', 'v'), ('keypoint', 'n'), ('heatmap', 'n'), ('&', None), ('part', 'n'), ('affinity', 'n'), ('field', 'n'), ('extractor', 'n'), ('thereby', 'r'), ('allow', 'a'), ('keypoint', 'n'), ('heatmap', 'n'), ('&', None), ('part', 'n'), ('affinity', 'n'), ('field', 'n'), ('extractor', 'n'), ('generate', 'v'), ('one', None), ('keypoint', 'n'), ('heatmaps', 'v'), ('training', 'v'), ('one', None), ('part', 'n'), ('affinity', 'n'), ('fields', 'n'), ('training', 'v'), ('one', None), ('channels', 'a'), ('feature', 'n'), ('tensors', 'n'), ('training', 'v'), ('iii', 'a'), ('process', 'n'), ('inputting', 'v'), ('keypoint', 'n'), ('heatmaps', 'n'), ('training', 'v'), ('part', 'n'), ('affinity', 'n'), ('fields', 'n'), ('training', 'v'), ('keypoint', 'n'), ('detector', 'n'), ('thereby', 'r'), ('allow', 'a'), ('keypoint', 'n'), ('detector', 'n'), ('extract', 'a'), ('keypoints', 'n'), ('training', 'v'), ('keypoint', 'n'), ('heatmaps', 'n'), ('training', 'v'), ('process', 'n'), ('grouping', 'n'), ('extracted', 'v'), ('keypoints', 'n'), ('training', 'v'), ('referring', 'v'), ('part', 'n'), ('affinity', 'n'), ('fields', 'n'), ('training', 'v'), ('thereby', 'r'), ('detect', 'a'), ('keypoints', 'n'), ('per', None), ('objects', 'n'), ('training', 'v'), ('iv', 'a'), ('process', 'n'), ('allowing', 'v'), ('loss', 'n'), ('layer', 'n'), ('calculate', 'v'), ('one', None), ('losses', 'n'), ('referring', 'v'), ('keypoints', 'n'), ('per', None), ('objects', 'n'), ('training', 'v'), ('corresponding', 'v'), ('ground', 'n'), ('truths', 'n'), ('thereby', 'r'), ('adjust', 'v'), ('one', None), ('parameters', 'n'), ('feature', 'v'), ('extraction', 'n'), ('network', 'n'), ('keypoint', 'n'), ('heatmap', 'n'), ('&', None), ('part', 'n'), ('affinity', 'n'), ('field', 'n'), ('extractor', 'n'), ('losses', 'n'), ('minimized', 'v'), ('backpropagation', 'n'), ('using', 'v'), ('losses', 'n'), ('method', 'a'), ('claim', 'n'), ('wherein', 'a'), ('step', 'n'), ('passenger', 'n'), ('body', 'n'), ('information-detecting', 'a'), ('device', 'n'), ('performs', 'n'), ('process', 'n'), ('inputting', 'v'), ('interior', 'a'), ('image', 'n'), ('face', 'n'), ('recognition', 'n'), ('network', 'n'), ('thereby', 'r'), ('allow', 'v'), ('face', 'n'), ('recognition', 'n'), ('network', 'n'), ('detect', 'a'), ('faces', 'v'), ('passengers', 'n'), ('located', 'v'), ('interior', 'a'), ('image', 'n'), ('via', None), ('face', 'n'), ('detector', 'n'), ('output', 'n'), ('multiple', 'a'), ('pieces', 'n'), ('passenger', 'n'), ('feature', 'n'), ('information', 'n'), ('facial', 'a'), ('images', 'n'), ('via', None), ('facial', 'a'), ('feature', 'n'), ('classifier', 'n'), ('method', 'n'), ('claim', 'n'), ('wherein', 'a'), ('step', 'n'), ('passenger', 'n'), ('body', 'n'), ('information-detecting', 'a'), ('device', 'n'), ('performs', 'n'), ('process', 'n'), ('inputting', 'v'), ('interior', 'a'), ('image', 'n'), ('face', 'n'), ('recognition', 'n'), ('network', 'n'), ('thereby', 'r'), ('allow', 'v'), ('face', 'n'), ('recognition', 'n'), ('network', 'n'), ('apply', 'r'), ('least', 'a'), ('one', None), ('convolution', 'n'), ('operation', 'n'), ('interior', 'a'), ('image', 'n'), ('thus', 'r'), ('output', 'n'), ('least', 'a'), ('one', None), ('feature', 'n'), ('map', 'n'), ('corresponding', 'v'), ('interior', 'a'), ('image', 'n'), ('via', None), ('least', 'a'), ('one', None), ('convolutional', 'a'), ('layer', 'n'), ('ii', 'n'), ('output', 'n'), ('one', None), ('proposal', 'n'), ('boxes', 'v'), ('passengers', 'n'), ('estimated', 'v'), ('located', 'a'), ('feature', 'n'), ('map', 'n'), ('via', None), ('region', 'n'), ('proposal', 'n'), ('network', 'n'), ('iii', 'v'), ('apply', 'v'), ('pooling', 'v'), ('operation', 'n'), ('one', None), ('regions', 'n'), ('corresponding', 'v'), ('proposal', 'n'), ('boxes', 'n'), ('feature', 'v'), ('map', 'a'), ('thus', 'r'), ('output', 'n'), ('least', 'a'), ('one', None), ('feature', 'n'), ('vector', 'n'), ('via', None), ('pooling', 'v'), ('layer', 'n'), ('iv', 'a'), ('apply', 'r'), ('fully-connected', 'a'), ('operation', 'n'), ('feature', 'n'), ('vector', 'n'), ('thus', 'r'), ('output', 'n'), ('multiple', 'a'), ('pieces', 'n'), ('passenger', 'n'), ('feature', 'n'), ('information', 'n'), ('corresponding', 'v'), ('faces', 'v'), ('passengers', 'n'), ('corresponding', 'v'), ('proposal', 'n'), ('boxes', 'n'), ('via', None), ('fully', 'r'), ('connected', 'v'), ('layer', 'n'), ('method', 'n'), ('claim', 'n'), ('wherein', 'n'), ('multiple', 'a'), ('pieces', 'n'), ('passenger', 'n'), ('feature', 'n'), ('information', 'n'), ('include', 'v'), ('ages', 'v'), ('genders', 'n'), ('races', 'n'), ('corresponding', 'v'), ('passengers', 'n'), ('passenger', 'n'), ('body', 'n'), ('information-detecting', 'a'), ('device', 'n'), ('detecting', 'v'), ('body', 'n'), ('information', 'n'), ('one', None), ('passengers', 'n'), ('vehicle', 'n'), ('based', 'v'), ('humans', 'n'), (\"'\", None), ('status', 'n'), ('recognition', 'n'), ('comprising', 'v'), ('least', 'a'), ('one', None), ('memory', 'n'), ('stores', 'n'), ('instructions', 'n'), ('least', 'v'), ('one', None), ('processor', 'n'), ('configured', 'v'), ('execute', 'a'), ('instructions', 'n'), ('perform', 'v'), ('support', 'n'), ('another', None), ('device', 'n'), ('perform', 'n'), ('least', 'a'), ('one', None), ('interior', 'a'), ('image', 'n'), ('interior', 'a'), ('vehicle', 'n'), ('acquired', 'v'), ('process', 'n'), ('inputting', 'v'), ('interior', 'a'), ('image', 'n'), ('face', 'n'), ('recognition', 'n'), ('network', 'n'), ('thereby', 'r'), ('allow', 'v'), ('face', 'n'), ('recognition', 'n'), ('network', 'n'), ('detect', 'a'), ('faces', 'v'), ('passengers', 'n'), ('interior', 'a'), ('image', 'n'), ('thus', 'r'), ('output', 'n'), ('multiple', 'a'), ('pieces', 'n'), ('passenger', 'n'), ('feature', 'n'), ('information', 'n'), ('corresponding', 'v'), ('detected', 'v'), ('faces', 'v'), ('ii', 'a'), ('process', 'n'), ('inputting', 'v'), ('interior', 'a'), ('image', 'n'), ('body', 'n'), ('recognition', 'n'), ('network', 'n'), ('thereby', 'r'), ('allow', 'v'), ('body', 'n'), ('recognition', 'n'), ('network', 'n'), ('detect', 'a'), ('bodies', 'n'), ('passengers', 'n'), ('interior', 'a'), ('image', 'n'), ('thus', 'r'), ('output', 'n'), ('body-part', 'a'), ('length', 'n'), ('information', 'n'), ('detected', 'v'), ('bodies', 'n'), ('ii', 'a'), ('process', 'n'), ('retrieving', 'v'), ('specific', 'a'), ('height', 'a'), ('mapping', 'n'), ('information', 'n'), ('corresponding', 'v'), ('specific', 'a'), ('passenger', 'n'), ('feature', 'n'), ('information', 'n'), ('specific', 'a'), ('passenger', 'n'), ('height', 'v'), ('mapping', 'v'), ('table', 'n'), ('stores', 'n'), ('height', 'v'), ('mapping', 'v'), ('information', 'n'), ('representing', 'v'), ('respective', 'a'), ('one', None), ('predetermined', 'v'), ('ratios', 'n'), ('one', None), ('segment', 'n'), ('body', 'n'), ('portions', 'n'), ('human', 'a'), ('groups', 'n'), ('heights', 'n'), ('per', None), ('human', 'a'), ('groups', 'n'), ('process', 'n'), ('acquiring', 'v'), ('specific', 'a'), ('height', 'n'), ('specific', 'a'), ('passenger', 'n'), ('specific', 'a'), ('height', 'v'), ('mapping', 'v'), ('information', 'n'), ('referring', 'v'), ('specific', 'a'), ('body-part', 'a'), ('length', 'n'), ('information', 'n'), ('specific', 'a'), ('passenger', 'n'), ('process', 'n'), ('retrieving', 'v'), ('specific', 'a'), ('weight', 'n'), ('mapping', 'v'), ('information', 'n'), ('corresponding', 'v'), ('specific', 'a'), ('passenger', 'n'), ('feature', 'n'), ('information', 'n'), ('weight', 'v'), ('mapping', 'v'), ('table', 'n'), ('stores', 'n'), ('multiple', 'a'), ('pieces', 'n'), ('weight', 'v'), ('mapping', 'v'), ('information', 'n'), ('representing', 'v'), ('predetermined', 'v'), ('correlations', 'n'), ('heights', 'n'), ('weights', 'n'), ('per', None), ('human', 'a'), ('groups', 'n'), ('process', 'n'), ('acquiring', 'v'), ('weight', 'n'), ('specific', 'a'), ('passenger', 'n'), ('specific', 'a'), ('weight', 'v'), ('mapping', 'v'), ('information', 'n'), ('referring', 'v'), ('specific', 'a'), ('height', 'n'), ('specific', 'a'), ('passenger', 'n'), ('passenger', 'n'), ('body', 'n'), ('information-detecting', 'a'), ('device', 'n'), ('claim', 'n'), ('wherein', 'n'), ('process', 'n'), ('processor', 'n'), ('performs', 'n'), ('process', 'n'), ('inputting', 'v'), ('interior', 'a'), ('image', 'n'), ('body', 'n'), ('recognition', 'n'), ('network', 'n'), ('thereby', 'r'), ('allow', 'v'), ('body', 'n'), ('recognition', 'n'), ('network', 'n'), ('output', 'n'), ('one', None), ('feature', 'n'), ('tensors', 'v'), ('one', None), ('channels', 'n'), ('corresponding', 'v'), ('interior', 'a'), ('image', 'n'), ('via', None), ('feature', 'n'), ('extraction', 'n'), ('network', 'n'), ('ii', 'a'), ('generate', 'n'), ('least', 'a'), ('one', None), ('keypoint', 'n'), ('heatmap', 'n'), ('least', 'a'), ('one', None), ('part', 'n'), ('affinity', 'n'), ('field', 'n'), ('one', None), ('channels', 'n'), ('corresponding', 'v'), ('feature', 'n'), ('tensors', 'n'), ('via', None), ('keypoint', 'n'), ('heatmap', 'n'), ('&', None), ('part', 'n'), ('affinity', 'n'), ('field', 'n'), ('extractor', 'n'), ('iii', 'a'), ('extract', 'a'), ('keypoints', 'n'), ('keypoint', 'v'), ('heatmap', 'n'), ('via', None), ('keypoint', 'n'), ('detector', 'n'), ('group', 'n'), ('extracted', 'v'), ('keypoints', 'n'), ('referring', 'v'), ('part', 'n'), ('affinity', 'n'), ('field', 'n'), ('thus', 'r'), ('generate', 'v'), ('body', 'n'), ('parts', 'n'), ('per', None), ('passengers', 'n'), ('result', 'v'), ('allow', None), ('body', 'n'), ('recognition', 'n'), ('network', 'n'), ('output', 'n'), ('multiple', 'a'), ('pieces', 'n'), ('body-part', 'a'), ('length', 'n'), ('information', 'n'), ('passengers', 'n'), ('referring', 'v'), ('body', 'n'), ('parts', 'n'), ('per', None), ('passengers', 'n'), ('passenger', 'v'), ('body', 'n'), ('information-detecting', 'a'), ('device', 'n'), ('claim', 'n'), ('wherein', 'v'), ('heatmap', 'n'), ('&', None), ('part', 'n'), ('affinity', 'n'), ('field', 'n'), ('extractor', 'n'), ('includes', 'v'), ('one', None), ('fully', 'r'), ('convolutional', 'a'), ('network', 'n'), ('convolutional', 'n'), ('layer', 'n'), ('applies', 'v'), ('fully-convolution', 'n'), ('operation', 'n'), ('convolution', 'n'), ('operation', 'n'), ('feature', 'n'), ('tensors', 'n'), ('thereby', 'r'), ('generate', 'v'), ('keypoint', 'n'), ('heatmap', 'n'), ('part', 'n'), ('affinity', 'n'), ('field', 'n'), ('passenger', 'n'), ('body', 'n'), ('information-detecting', 'a'), ('device', 'n'), ('claim', 'n'), ('wherein', 'v'), ('keypoint', 'a'), ('detector', 'n'), ('connects', 'n'), ('referring', 'v'), ('part', 'n'), ('affinity', 'n'), ('field', 'n'), ('pairs', 'v'), ('respectively', 'r'), ('highest', 'a'), ('mutual', 'a'), ('connection', 'n'), ('probabilities', 'n'), ('connected', 'v'), ('among', None), ('extracted', 'a'), ('keypoints', 'n'), ('thereby', 'r'), ('group', 'n'), ('extracted', 'v'), ('keypoints', 'n'), ('passenger', 'n'), ('body', 'n'), ('information-detecting', 'a'), ('device', 'n'), ('claim', 'n'), ('wherein', 'a'), ('feature', 'n'), ('extraction', 'n'), ('network', 'n'), ('keypoint', 'n'), ('heatmap', 'n'), ('&', None), ('part', 'n'), ('affinity', 'n'), ('field', 'n'), ('extractor', 'n'), ('learned', 'v'), ('learning', 'a'), ('device', 'n'), ('performing', 'v'), ('process', 'n'), ('inputting', 'v'), ('least', 'a'), ('one', None), ('training', 'n'), ('image', 'n'), ('including', 'v'), ('one', None), ('objects', 'v'), ('training', 'v'), ('feature', 'n'), ('extraction', 'n'), ('network', 'n'), ('thereby', 'r'), ('allow', 'a'), ('feature', 'n'), ('extraction', 'n'), ('network', 'n'), ('generate', 'v'), ('one', None), ('feature', 'n'), ('tensors', 'n'), ('training', 'v'), ('one', None), ('channels', 'n'), ('applying', 'v'), ('least', 'a'), ('one', None), ('convolutional', 'a'), ('operation', 'n'), ('training', 'n'), ('image', 'n'), ('ii', 'a'), ('process', 'n'), ('inputting', 'v'), ('feature', 'n'), ('tensors', 'n'), ('training', 'v'), ('keypoint', 'n'), ('heatmap', 'n'), ('&', None), ('part', 'n'), ('affinity', 'n'), ('field', 'n'), ('extractor', 'n'), ('thereby', 'r'), ('allow', 'a'), ('keypoint', 'n'), ('heatmap', 'n'), ('&', None), ('part', 'n'), ('affinity', 'n'), ('field', 'n'), ('extractor', 'n'), ('generate', 'v'), ('one', None), ('keypoint', 'n'), ('heatmaps', 'v'), ('training', 'v'), ('one', None), ('part', 'n'), ('affinity', 'n'), ('fields', 'n'), ('training', 'v'), ('one', None), ('channels', 'a'), ('feature', 'n'), ('tensors', 'n'), ('training', 'v'), ('iii', 'a'), ('process', 'n'), ('inputting', 'v'), ('keypoint', 'n'), ('heatmaps', 'n'), ('training', 'v'), ('part', 'n'), ('affinity', 'n'), ('fields', 'n'), ('training', 'v'), ('keypoint', 'n'), ('detector', 'n'), ('thereby', 'r'), ('allow', 'a'), ('keypoint', 'n'), ('detector', 'n'), ('extract', 'a'), ('keypoints', 'n'), ('training', 'v'), ('keypoint', 'n'), ('heatmaps', 'n'), ('training', 'v'), ('process', 'n'), ('grouping', 'n'), ('extracted', 'v'), ('keypoints', 'n'), ('training', 'v'), ('referring', 'v'), ('part', 'n'), ('affinity', 'n'), ('fields', 'n'), ('training', 'v'), ('thereby', 'r'), ('detect', 'a'), ('keypoints', 'n'), ('per', None), ('objects', 'n'), ('training', 'v'), ('iv', 'a'), ('process', 'n'), ('allowing', 'v'), ('loss', 'n'), ('layer', 'n'), ('calculate', 'v'), ('one', None), ('losses', 'n'), ('referring', 'v'), ('keypoints', 'n'), ('per', None), ('objects', 'n'), ('training', 'v'), ('corresponding', 'v'), ('ground', 'n'), ('truths', 'n'), ('thereby', 'r'), ('adjust', 'v'), ('one', None), ('parameters', 'n'), ('feature', 'v'), ('extraction', 'n'), ('network', 'n'), ('keypoint', 'n'), ('heatmap', 'n'), ('&', None), ('part', 'n'), ('affinity', 'n'), ('field', 'n'), ('extractor', 'n'), ('losses', 'n'), ('minimized', 'v'), ('backpropagation', 'n'), ('using', 'v'), ('losses', 'n'), ('passenger', 'n'), ('body', 'n'), ('information-detecting', 'a'), ('device', 'n'), ('claim', 'n'), ('wherein', 'n'), ('process', 'n'), ('processor', 'n'), ('performs', 'n'), ('process', 'n'), ('inputting', 'v'), ('interior', 'a'), ('image', 'n'), ('face', 'n'), ('recognition', 'n'), ('network', 'n'), ('thereby', 'r'), ('allow', 'v'), ('face', 'n'), ('recognition', 'n'), ('network', 'n'), ('apply', 'r'), ('least', 'a'), ('one', None), ('convolution', 'n'), ('operation', 'n'), ('interior', 'a'), ('image', 'n'), ('thus', 'r'), ('output', 'n'), ('least', 'a'), ('one', None), ('feature', 'n'), ('map', 'n'), ('corresponding', 'v'), ('interior', 'a'), ('image', 'n'), ('via', None), ('least', 'a'), ('one', None), ('convolutional', 'a'), ('layer', 'n'), ('ii', 'n'), ('output', 'n'), ('one', None), ('proposal', 'n'), ('boxes', 'v'), ('passengers', 'n'), ('estimated', 'v'), ('located', 'a'), ('feature', 'n'), ('map', 'n'), ('via', None), ('region', 'n'), ('proposal', 'n'), ('network', 'n'), ('iii', 'v'), ('apply', 'v'), ('pooling', 'v'), ('operation', 'n'), ('one', None), ('regions', 'n'), ('corresponding', 'v'), ('proposal', 'n'), ('boxes', 'n'), ('feature', 'v'), ('map', 'a'), ('thus', 'r'), ('output', 'n'), ('least', 'a'), ('one', None), ('feature', 'n'), ('vector', 'n'), ('via', None), ('pooling', 'v'), ('layer', 'n'), ('iv', 'a'), ('apply', 'r'), ('fully-connected', 'a'), ('operation', 'n'), ('feature', 'n'), ('vector', 'n'), ('thus', 'r'), ('output', 'n'), ('multiple', 'a'), ('pieces', 'n'), ('passenger', 'n'), ('feature', 'n'), ('information', 'n'), ('corresponding', 'v'), ('faces', 'v'), ('passengers', 'n'), ('corresponding', 'v'), ('proposal', 'n'), ('boxes', 'n'), ('via', None), ('fully', 'r'), ('connected', 'v'), ('layer', 'n'), ('computer', 'n'), ('implemented', 'v'), ('method', 'a'), ('performing', 'v'), ('video', 'n'), ('coding', 'v'), ('based', 'v'), ('face', 'n'), ('detection', 'n'), ('comprising', 'v'), ('receiving', 'v'), ('video', 'n'), ('frame', 'n'), ('comprising', 'v'), ('one', None), ('plurality', 'n'), ('video', 'n'), ('frames', 'n'), ('video', 'v'), ('sequence', 'n'), ('determining', 'v'), ('video', 'n'), ('frame', 'n'), ('key', 'a'), ('frame', 'n'), ('video', 'n'), ('sequence', 'n'), ('performing', 'v'), ('response', 'n'), ('video', 'n'), ('frame', 'n'), ('key', 'a'), ('frame', 'n'), ('video', 'a'), ('sequence', 'n'), ('multi-stage', 'n'), ('facial', 'a'), ('search', 'n'), ('video', 'n'), ('frame', 'n'), ('based', 'v'), ('predetermined', 'a'), ('feature', 'n'), ('templates', 'n'), ('predetermined', 'v'), ('number', 'n'), ('stages', 'n'), ('determine', 'v'), ('first', 'a'), ('candidate', 'n'), ('face', 'n'), ('region', 'n'), ('second', 'a'), ('candidate', 'n'), ('face', 'n'), ('region', 'n'), ('video', 'n'), ('frame', 'n'), ('testing', 'v'), ('first', 'a'), ('second', 'a'), ('candidate', 'n'), ('face', 'n'), ('regions', 'n'), ('based', 'v'), ('skin', 'a'), ('tone', 'n'), ('information', 'n'), ('determine', 'n'), ('first', 'r'), ('candidate', 'a'), ('face', 'n'), ('region', 'n'), ('valid', 'a'), ('face', 'n'), ('region', 'n'), ('second', 'a'), ('candidate', 'n'), ('face', 'n'), ('region', 'n'), ('invalid', 'a'), ('face', 'n'), ('region', 'n'), ('rejecting', 'v'), ('second', 'a'), ('candidate', 'n'), ('face', 'n'), ('region', 'n'), ('outputting', 'v'), ('first', 'a'), ('candidate', 'n'), ('face', 'n'), ('region', 'n'), ('encoding', 'v'), ('video', 'n'), ('frame', 'n'), ('based', 'v'), ('least', 'a'), ('part', 'n'), ('first', 'a'), ('candidate', 'n'), ('face', 'n'), ('region', 'n'), ('valid', 'a'), ('face', 'n'), ('region', 'n'), ('generate', 'n'), ('coded', 'v'), ('bitstream', 'n'), ('method', 'n'), ('claim', 'n'), ('wherein', 'n'), ('skin', 'v'), ('tone', 'n'), ('information', 'n'), ('comprises', 'v'), ('skin', 'a'), ('probability', 'n'), ('map', 'n'), ('method', 'n'), ('claim', 'n'), ('wherein', 'n'), ('said', 'v'), ('testing', 'v'), ('first', 'a'), ('second', 'a'), ('candidate', 'n'), ('face', 'n'), ('regions', 'n'), ('based', 'v'), ('skin', 'a'), ('tone', 'n'), ('information', 'n'), ('performed', 'v'), ('response', 'n'), ('video', 'n'), ('frame', 'n'), ('key', 'a'), ('frame', 'n'), ('video', 'n'), ('sequence', 'n'), ('method', 'n'), ('claim', 'n'), ('wherein', None), ('first', 'a'), ('candidate', 'n'), ('face', 'n'), ('region', 'n'), ('comprises', 'v'), ('rectangular', 'a'), ('region', 'n'), ('method', 'n'), ('comprising', 'v'), ('determining', 'v'), ('free', 'a'), ('form', 'n'), ('shape', 'n'), ('face', 'n'), ('region', 'n'), ('corresponding', 'v'), ('first', 'a'), ('candidate', 'n'), ('face', 'n'), ('region', 'n'), ('wherein', 'v'), ('free', 'a'), ('form', 'n'), ('shape', 'n'), ('face', 'n'), ('region', 'n'), ('least', 'a'), ('one', None), ('pixel', 'n'), ('accuracy', 'n'), ('small', 'a'), ('block', 'n'), ('pixels', 'n'), ('accuracy', 'v'), ('method', 'a'), ('claim', 'n'), ('wherein', None), ('determining', 'v'), ('free', 'a'), ('form', 'n'), ('shape', 'n'), ('face', 'n'), ('region', 'n'), ('comprises', 'v'), ('generating', 'v'), ('enhanced', 'v'), ('skip', 'a'), ('probability', 'n'), ('map', 'n'), ('corresponding', 'v'), ('first', 'a'), ('candidate', 'n'), ('face', 'n'), ('region', 'n'), ('binarizing', 'v'), ('enhanced', 'v'), ('skip', 'a'), ('probability', 'n'), ('map', 'n'), ('overlaying', 'v'), ('binarized', 'v'), ('enhanced', 'a'), ('skip', 'n'), ('probability', 'n'), ('map', 'n'), ('least', 'a'), ('portion', 'n'), ('video', 'n'), ('frame', 'n'), ('provide', 'v'), ('free', 'a'), ('form', 'n'), ('shape', 'n'), ('face', 'n'), ('region', 'n'), ('method', 'n'), ('claim', 'n'), ('wherein', None), ('second', 'a'), ('video', 'n'), ('frame', 'n'), ('comprises', 'v'), ('non-key', 'a'), ('frame', 'n'), ('video', 'n'), ('sequence', 'n'), ('method', 'n'), ('comprising', 'v'), ('performing', 'v'), ('face', 'n'), ('detection', 'n'), ('second', 'a'), ('video', 'n'), ('frame', 'n'), ('video', 'n'), ('sequence', 'n'), ('based', 'v'), ('free', 'a'), ('form', 'n'), ('shape', 'n'), ('face', 'n'), ('region', 'n'), ('method', 'n'), ('claim', 'n'), ('comprising', 'v'), ('tracking', 'v'), ('second', 'a'), ('free', 'a'), ('form', 'n'), ('shape', 'n'), ('face', 'n'), ('region', 'n'), ('second', 'a'), ('video', 'n'), ('frame', 'n'), ('based', 'v'), ('free', 'a'), ('form', 'n'), ('shape', 'n'), ('face', 'n'), ('region', 'n'), ('video', 'n'), ('frame', 'n'), ('method', 'n'), ('claim', 'n'), ('wherein', None), ('tracking', 'v'), ('second', 'a'), ('free', 'a'), ('form', 'n'), ('shape', 'n'), ('face', 'n'), ('region', 'n'), ('comprises', 'v'), ('determining', 'v'), ('location', 'n'), ('second', 'a'), ('valid', 'a'), ('face', 'n'), ('region', 'n'), ('second', 'a'), ('video', 'n'), ('frame', 'n'), ('based', 'v'), ('displacement', 'a'), ('offset', 'n'), ('respect', 'n'), ('first', 'a'), ('candidate', 'n'), ('face', 'n'), ('region', 'n'), ('method', 'n'), ('claim', 'n'), ('comprising', 'v'), ('determining', 'v'), ('displacement', 'n'), ('offset', 'n'), ('based', 'v'), ('offset', 'v'), ('centroid', 'a'), ('bounding', 'v'), ('box', 'n'), ('around', None), ('skin', 'n'), ('enhanced', 'v'), ('region', 'n'), ('corresponding', 'v'), ('first', 'a'), ('candidate', 'n'), ('face', 'n'), ('region', 'n'), ('second', 'a'), ('centroid', 'a'), ('second', 'a'), ('bounding', 'n'), ('box', 'n'), ('around', None), ('second', 'a'), ('skin', 'n'), ('enhanced', 'v'), ('region', 'n'), ('second', 'a'), ('video', 'n'), ('frame', 'n'), ('method', 'n'), ('claim', 'n'), ('wherein', None), ('encoding', 'v'), ('video', 'n'), ('frame', 'n'), ('based', 'v'), ('least', 'a'), ('part', 'n'), ('first', 'a'), ('candidate', 'n'), ('face', 'n'), ('region', 'n'), ('valid', 'a'), ('face', 'n'), ('region', 'n'), ('comprises', 'v'), ('least', 'a'), ('one', None), ('reducing', 'v'), ('quantization', 'n'), ('parameter', 'n'), ('corresponding', 'v'), ('first', 'a'), ('candidate', 'n'), ('face', 'n'), ('region', 'n'), ('adjusting', 'v'), ('lambda', 'n'), ('value', 'n'), ('first', 'r'), ('candidate', 'a'), ('face', 'n'), ('region', 'n'), ('disabling', 'v'), ('skip', 'n'), ('coding', 'v'), ('first', 'a'), ('candidate', 'n'), ('face', 'n'), ('region', 'n'), ('method', 'n'), ('claim', 'n'), ('wherein', 'n'), ('bitstream', 'n'), ('comprises', 'v'), ('least', 'a'), ('one', None), ('hadvanced', 'v'), ('video', 'n'), ('coding', 'v'), ('avc', 'a'), ('compliant', 'a'), ('bitstream', 'n'), ('hhigh', 'n'), ('efficiency', 'n'), ('video', 'n'), ('coding', 'v'), ('hevc', 'n'), ('compliant', 'a'), ('bitstream', 'n'), ('vp', 'n'), ('compliant', 'a'), ('bitstream', 'n'), ('vp', 'n'), ('compliant', 'a'), ('bitstream', 'n'), ('alliance', 'n'), ('open', 'a'), ('media', 'n'), ('aom', 'v'), ('av', 'a'), ('compliant', 'n'), ('bitstream', 'n'), ('computer', 'n'), ('implemented', 'v'), ('method', 'n'), ('performing', 'v'), ('face', 'n'), ('detection', 'n'), ('comprising', 'v'), ('receiving', 'v'), ('video', 'n'), ('frame', 'n'), ('sequence', 'n'), ('video', 'n'), ('frames', 'n'), ('performing', 'v'), ('multi-stage', 'a'), ('facial', 'a'), ('search', 'n'), ('video', 'n'), ('frame', 'n'), ('based', 'v'), ('predetermined', 'a'), ('feature', 'n'), ('templates', 'n'), ('predetermined', 'v'), ('number', 'n'), ('stages', 'n'), ('determine', 'v'), ('first', 'a'), ('candidate', 'n'), ('face', 'n'), ('region', 'n'), ('second', 'a'), ('candidate', 'n'), ('face', 'n'), ('region', 'n'), ('video', 'n'), ('frame', 'n'), ('testing', 'v'), ('first', 'a'), ('second', 'a'), ('candidate', 'n'), ('face', 'n'), ('regions', 'n'), ('based', 'v'), ('skin', 'a'), ('tone', 'n'), ('information', 'n'), ('determine', 'n'), ('first', 'r'), ('candidate', 'a'), ('face', 'n'), ('region', 'n'), ('valid', 'a'), ('face', 'n'), ('region', 'n'), ('second', 'a'), ('candidate', 'n'), ('face', 'n'), ('region', 'n'), ('invalid', 'a'), ('face', 'n'), ('region', 'n'), ('rejecting', 'v'), ('second', 'a'), ('candidate', 'n'), ('face', 'n'), ('region', 'n'), ('outputting', 'v'), ('first', 'a'), ('candidate', 'n'), ('face', 'n'), ('region', 'n'), ('valid', 'a'), ('face', 'n'), ('region', 'n'), ('processing', 'v'), ('providing', 'v'), ('index', 'n'), ('indicative', 'a'), ('person', 'n'), ('present', 'a'), ('video', 'n'), ('frame', 'n'), ('based', 'v'), ('valid', 'a'), ('face', 'n'), ('region', 'n'), ('method', 'n'), ('claim', 'n'), ('wherein', 'n'), ('sequence', 'n'), ('video', 'n'), ('frames', 'v'), ('comprises', 'n'), ('sequence', 'n'), ('surveillance', 'n'), ('video', 'n'), ('frames', 'n'), ('method', 'v'), ('comprising', 'v'), ('performing', 'v'), ('face', 'n'), ('recognition', 'n'), ('surveillance', 'n'), ('video', 'n'), ('frames', 'n'), ('based', 'v'), ('valid', 'a'), ('face', 'n'), ('region', 'n'), ('method', 'n'), ('claim', 'n'), ('wherein', 'n'), ('sequence', 'n'), ('video', 'n'), ('frames', 'v'), ('comprises', 'n'), ('sequence', 'n'), ('decoded', 'v'), ('video', 'n'), ('frames', 'n'), ('method', 'v'), ('comprising', 'v'), ('adding', 'v'), ('marker', 'n'), ('corresponding', 'v'), ('received', 'v'), ('video', 'a'), ('frame', 'n'), ('perform', 'a'), ('face', 'n'), ('recognition', 'n'), ('received', 'v'), ('video', 'n'), ('frame', 'n'), ('based', 'v'), ('valid', 'a'), ('face', 'n'), ('region', 'n'), ('method', 'n'), ('claim', 'n'), ('wherein', 'n'), ('sequence', 'n'), ('video', 'n'), ('frames', 'n'), ('received', 'v'), ('device', 'n'), ('login', 'n'), ('attempt', 'n'), ('method', 'n'), ('comprising', 'v'), ('performing', 'v'), ('face', 'n'), ('recognition', 'n'), ('based', 'v'), ('valid', 'a'), ('face', 'n'), ('region', 'n'), ('allowing', 'v'), ('access', 'n'), ('device', 'n'), ('secured', 'v'), ('face', 'n'), ('recognized', 'v'), ('method', 'a'), ('claim', 'n'), ('wherein', 'n'), ('sequence', 'n'), ('video', 'n'), ('frames', 'v'), ('comprises', 'n'), ('sequence', 'n'), ('videoconferencing', 'v'), ('frames', 'n'), ('method', 'r'), ('comprising', 'v'), ('encoding', 'v'), ('video', 'n'), ('frame', 'n'), ('based', 'v'), ('least', 'a'), ('part', 'n'), ('valid', 'a'), ('face', 'n'), ('region', 'n'), ('generate', 'n'), ('coded', 'v'), ('bitstream', 'n'), ('method', 'n'), ('claim', 'n'), ('wherein', None), ('encoding', 'v'), ('video', 'n'), ('frame', 'n'), ('comprises', 'v'), ('encoding', 'v'), ('background', 'r'), ('region', 'n'), ('video', 'n'), ('frame', 'n'), ('bitstream', 'n'), ('method', 'n'), ('claim', 'n'), ('comprising', 'v'), ('encoding', 'v'), ('video', 'n'), ('frame', 'n'), ('based', 'v'), ('least', 'a'), ('part', 'n'), ('valid', 'a'), ('face', 'n'), ('region', 'n'), ('generate', 'n'), ('coded', 'v'), ('bitstream', 'n'), ('wherein', 'n'), ('encoding', 'v'), ('video', 'n'), ('frame', 'n'), ('comprises', 'v'), ('including', 'v'), ('metadata', 'n'), ('corresponding', 'v'), ('valid', 'a'), ('face', 'n'), ('region', 'n'), ('bitstream', 'n'), ('method', 'n'), ('claim', 'n'), ('comprising', 'v'), ('decoding', 'v'), ('coded', 'v'), ('bitstream', 'n'), ('generate', 'n'), ('decoded', 'v'), ('video', 'n'), ('frame', 'n'), ('determine', 'n'), ('metadata', 'n'), ('corresponding', 'v'), ('valid', 'a'), ('face', 'n'), ('region', 'n'), ('bitstream', 'n'), ('method', 'n'), ('claim', 'n'), ('comprising', 'v'), ('least', 'a'), ('one', None), ('replacing', 'v'), ('valid', 'a'), ('face', 'n'), ('region', 'n'), ('based', 'v'), ('decoded', 'v'), ('metadata', 'n'), ('cropping', 'v'), ('displaying', 'v'), ('image', 'n'), ('data', 'n'), ('corresponding', 'v'), ('valid', 'a'), ('face', 'n'), ('region', 'n'), ('based', 'v'), ('decoded', 'v'), ('metadata', 'n'), ('indexing', 'v'), ('decoded', 'v'), ('video', 'n'), ('frame', 'n'), ('based', 'v'), ('decoded', 'v'), ('metadata', 'n'), ('system', 'n'), ('performing', 'v'), ('video', 'n'), ('coding', 'v'), ('based', 'v'), ('face', 'n'), ('detection', 'n'), ('comprising', 'v'), ('memory', 'n'), ('configured', 'v'), ('store', 'n'), ('video', 'n'), ('frame', 'n'), ('comprising', 'v'), ('one', None), ('plurality', 'n'), ('video', 'n'), ('frames', 'n'), ('video', 'v'), ('sequence', 'n'), ('processor', 'n'), ('coupled', 'v'), ('memory', 'n'), ('processor', 'n'), ('receive', 'v'), ('video', 'n'), ('frame', 'n'), ('determine', 'a'), ('video', 'n'), ('frame', 'n'), ('key', 'a'), ('frame', 'n'), ('video', 'n'), ('sequence', 'n'), ('perform', 'n'), ('response', 'n'), ('video', 'n'), ('frame', 'n'), ('key', 'a'), ('frame', 'n'), ('video', 'a'), ('sequence', 'n'), ('multi-stage', 'n'), ('facial', 'a'), ('search', 'n'), ('video', 'n'), ('frame', 'n'), ('based', 'v'), ('predetermined', 'a'), ('feature', 'n'), ('templates', 'n'), ('predetermined', 'v'), ('number', 'n'), ('stages', 'n'), ('determine', 'v'), ('first', 'a'), ('candidate', 'n'), ('face', 'n'), ('region', 'n'), ('second', 'a'), ('candidate', 'n'), ('face', 'n'), ('region', 'n'), ('video', 'n'), ('frame', 'n'), ('test', 'n'), ('first', 'r'), ('second', 'a'), ('candidate', 'n'), ('face', 'n'), ('regions', 'n'), ('based', 'v'), ('skin', 'a'), ('tone', 'n'), ('information', 'n'), ('determine', 'n'), ('first', 'r'), ('candidate', 'a'), ('face', 'n'), ('region', 'n'), ('valid', 'a'), ('face', 'n'), ('region', 'n'), ('second', 'a'), ('candidate', 'n'), ('face', 'n'), ('region', 'n'), ('invalid', 'a'), ('face', 'n'), ('region', 'n'), ('reject', 'a'), ('second', 'a'), ('candidate', 'n'), ('face', 'n'), ('region', 'n'), ('outputting', 'v'), ('first', 'a'), ('candidate', 'n'), ('face', 'n'), ('region', 'n'), ('encode', None), ('video', 'n'), ('frame', 'n'), ('based', 'v'), ('least', 'a'), ('part', 'n'), ('first', 'a'), ('candidate', 'n'), ('face', 'n'), ('region', 'n'), ('valid', 'a'), ('face', 'n'), ('region', 'n'), ('generate', 'n'), ('coded', 'v'), ('bitstream', 'n'), ('system', 'n'), ('claim', 'n'), ('wherein', 'n'), ('skin', 'v'), ('tone', 'n'), ('information', 'n'), ('comprises', 'v'), ('skin', 'a'), ('probability', 'n'), ('map', 'n'), ('system', 'n'), ('claim', 'n'), ('wherein', 'n'), ('first', 'r'), ('candidate', 'a'), ('face', 'n'), ('region', 'n'), ('comprises', 'v'), ('rectangular', 'a'), ('region', 'n'), ('processor', 'n'), ('determine', 'v'), ('free', 'a'), ('form', 'n'), ('shape', 'n'), ('face', 'n'), ('region', 'n'), ('corresponding', 'v'), ('first', 'a'), ('candidate', 'n'), ('face', 'n'), ('region', 'n'), ('wherein', 'v'), ('free', 'a'), ('form', 'n'), ('shape', 'n'), ('face', 'n'), ('region', 'n'), ('least', 'a'), ('one', None), ('pixel', 'n'), ('accuracy', 'n'), ('small', 'a'), ('block', 'n'), ('pixels', 'n'), ('accuracy', 'n'), ('system', 'n'), ('claim', 'n'), ('wherein', 'n'), ('processor', 'n'), ('determine', 'v'), ('free', 'a'), ('form', 'n'), ('shape', 'n'), ('face', 'n'), ('region', 'n'), ('comprises', 'v'), ('processor', 'n'), ('generate', 'n'), ('enhanced', 'v'), ('skip', 'a'), ('probability', 'n'), ('map', 'n'), ('corresponding', 'v'), ('first', 'a'), ('candidate', 'n'), ('face', 'n'), ('region', 'n'), ('binarize', 'n'), ('enhanced', 'v'), ('skip', 'a'), ('probability', 'n'), ('map', 'n'), ('overlay', 'n'), ('binarized', 'v'), ('enhanced', 'a'), ('skip', 'a'), ('probability', 'n'), ('map', 'n'), ('least', 'a'), ('portion', 'n'), ('video', 'n'), ('frame', 'n'), ('provide', 'v'), ('free', 'a'), ('form', 'n'), ('shape', 'n'), ('face', 'n'), ('region', 'n'), ('system', 'n'), ('claim', 'n'), ('wherein', None), ('second', 'a'), ('video', 'n'), ('frame', 'n'), ('comprises', 'v'), ('non-key', 'a'), ('frame', 'n'), ('video', 'n'), ('sequence', 'n'), ('processor', 'n'), ('perform', 'n'), ('face', 'n'), ('detection', 'n'), ('second', 'a'), ('video', 'n'), ('frame', 'n'), ('video', 'n'), ('sequence', 'n'), ('based', 'v'), ('free', 'a'), ('form', 'n'), ('shape', 'n'), ('face', 'n'), ('region', 'n'), ('system', 'n'), ('claim', 'n'), ('wherein', 'n'), ('processor', 'n'), ('track', 'n'), ('second', 'a'), ('free', 'a'), ('form', 'n'), ('shape', 'n'), ('face', 'n'), ('region', 'n'), ('second', 'a'), ('video', 'n'), ('frame', 'n'), ('based', 'v'), ('free', 'a'), ('form', 'n'), ('shape', 'n'), ('face', 'n'), ('region', 'n'), ('video', 'n'), ('frame', 'n'), ('system', 'n'), ('claim', 'n'), ('wherein', 'n'), ('encode', 'v'), ('video', 'n'), ('frame', 'n'), ('based', 'v'), ('least', 'a'), ('part', 'n'), ('first', 'a'), ('candidate', 'n'), ('face', 'n'), ('region', 'n'), ('valid', 'a'), ('face', 'n'), ('region', 'n'), ('comprises', 'v'), ('processor', 'n'), ('reduce', 'v'), ('quantization', 'n'), ('parameter', 'n'), ('corresponding', 'v'), ('first', 'a'), ('candidate', 'n'), ('face', 'n'), ('region', 'n'), ('adjust', 'v'), ('lambda', 'n'), ('value', 'n'), ('first', 'r'), ('candidate', 'a'), ('face', 'n'), ('region', 'n'), ('disable', 'a'), ('skip', 'n'), ('coding', 'v'), ('first', 'a'), ('candidate', 'n'), ('face', 'n'), ('region', 'n'), ('least', 'a'), ('one', None), ('non-transitory', 'a'), ('machine', 'n'), ('readable', 'a'), ('medium', 'n'), ('comprising', 'v'), ('plurality', 'n'), ('instructions', 'n'), ('response', 'n'), ('executed', 'v'), ('device', 'n'), ('cause', 'n'), ('device', 'n'), ('perform', 'n'), ('video', 'n'), ('coding', 'v'), ('based', 'v'), ('face', 'n'), ('detection', 'n'), ('receiving', 'v'), ('video', 'n'), ('frame', 'n'), ('comprising', 'v'), ('one', None), ('plurality', 'n'), ('video', 'n'), ('frames', 'n'), ('video', 'v'), ('sequence', 'n'), ('determining', 'v'), ('video', 'n'), ('frame', 'n'), ('key', 'a'), ('frame', 'n'), ('video', 'n'), ('sequence', 'n'), ('performing', 'v'), ('response', 'n'), ('video', 'n'), ('frame', 'n'), ('key', 'a'), ('frame', 'n'), ('video', 'a'), ('sequence', 'n'), ('multi-stage', 'n'), ('facial', 'a'), ('search', 'n'), ('video', 'n'), ('frame', 'n'), ('based', 'v'), ('predetermined', 'a'), ('feature', 'n'), ('templates', 'n'), ('predetermined', 'v'), ('number', 'n'), ('stages', 'n'), ('determine', 'v'), ('first', 'a'), ('candidate', 'n'), ('face', 'n'), ('region', 'n'), ('second', 'a'), ('candidate', 'n'), ('face', 'n'), ('region', 'n'), ('video', 'n'), ('frame', 'n'), ('testing', 'v'), ('first', 'a'), ('second', 'a'), ('candidate', 'n'), ('face', 'n'), ('regions', 'n'), ('based', 'v'), ('skin', 'a'), ('tone', 'n'), ('information', 'n'), ('determine', 'n'), ('first', 'r'), ('candidate', 'a'), ('face', 'n'), ('region', 'n'), ('valid', 'a'), ('face', 'n'), ('region', 'n'), ('second', 'a'), ('candidate', 'n'), ('face', 'n'), ('region', 'n'), ('invalid', 'a'), ('face', 'n'), ('region', 'n'), ('rejecting', 'v'), ('second', 'a'), ('candidate', 'n'), ('face', 'n'), ('region', 'n'), ('outputting', 'v'), ('first', 'a'), ('candidate', 'n'), ('face', 'n'), ('region', 'n'), ('encoding', 'v'), ('video', 'n'), ('frame', 'n'), ('based', 'v'), ('least', 'a'), ('part', 'n'), ('first', 'a'), ('candidate', 'n'), ('face', 'n'), ('region', 'n'), ('valid', 'a'), ('face', 'n'), ('region', 'n'), ('generate', 'n'), ('coded', 'v'), ('bitstream', 'a'), ('non-transitory', 'a'), ('machine', 'n'), ('readable', 'a'), ('medium', 'n'), ('claim', 'n'), ('wherein', 'n'), ('skin', 'v'), ('tone', 'n'), ('information', 'n'), ('comprises', 'v'), ('skin', 'a'), ('probability', 'n'), ('map', 'v'), ('non-transitory', 'a'), ('machine', 'n'), ('readable', 'a'), ('medium', 'n'), ('claim', 'n'), ('wherein', None), ('first', 'a'), ('candidate', 'n'), ('face', 'n'), ('region', 'n'), ('comprises', 'v'), ('rectangular', 'a'), ('region', 'n'), ('machine', 'n'), ('readable', 'a'), ('medium', 'n'), ('comprising', 'v'), ('instructions', 'n'), ('response', 'n'), ('executed', 'v'), ('device', 'n'), ('cause', 'n'), ('device', 'n'), ('perform', 'n'), ('video', 'n'), ('coding', 'v'), ('based', 'v'), ('face', 'n'), ('detection', 'n'), ('determining', 'v'), ('free', 'a'), ('form', 'n'), ('shape', 'n'), ('face', 'n'), ('region', 'n'), ('corresponding', 'v'), ('first', 'a'), ('candidate', 'n'), ('face', 'n'), ('region', 'n'), ('wherein', 'v'), ('free', 'a'), ('form', 'n'), ('shape', 'n'), ('face', 'n'), ('region', 'n'), ('least', 'a'), ('one', None), ('pixel', 'n'), ('accuracy', 'n'), ('small', 'a'), ('block', 'n'), ('pixels', 'n'), ('accuracy', None), ('non-transitory', 'a'), ('machine', 'n'), ('readable', 'a'), ('medium', 'n'), ('claim', 'n'), ('wherein', None), ('determining', 'v'), ('free', 'a'), ('form', 'n'), ('shape', 'n'), ('face', 'n'), ('region', 'n'), ('comprises', 'v'), ('generating', 'v'), ('enhanced', 'v'), ('skip', 'a'), ('probability', 'n'), ('map', 'n'), ('corresponding', 'v'), ('first', 'a'), ('candidate', 'n'), ('face', 'n'), ('region', 'n'), ('binarizing', 'v'), ('enhanced', 'v'), ('skip', 'a'), ('probability', 'n'), ('map', 'n'), ('overlaying', 'v'), ('binarized', 'v'), ('enhanced', 'a'), ('skip', 'n'), ('probability', 'n'), ('map', 'n'), ('least', 'a'), ('portion', 'n'), ('video', 'n'), ('frame', 'n'), ('provide', 'v'), ('free', 'a'), ('form', 'n'), ('shape', 'n'), ('face', 'n'), ('region', 'n'), ('non-transitory', 'a'), ('machine', 'n'), ('readable', 'a'), ('medium', 'n'), ('claim', 'n'), ('wherein', None), ('second', 'a'), ('video', 'n'), ('frame', 'n'), ('comprises', 'v'), ('non-key', 'a'), ('frame', 'n'), ('video', 'n'), ('sequence', 'n'), ('machine', 'n'), ('readable', 'a'), ('medium', 'n'), ('comprising', 'v'), ('instructions', 'n'), ('response', 'n'), ('executed', 'v'), ('device', 'n'), ('cause', 'n'), ('device', 'n'), ('perform', 'n'), ('video', 'n'), ('coding', 'v'), ('based', 'v'), ('face', 'n'), ('detection', 'n'), ('performing', 'v'), ('face', 'n'), ('detection', 'n'), ('second', 'a'), ('video', 'n'), ('frame', 'n'), ('video', 'n'), ('sequence', 'n'), ('based', 'v'), ('free', 'a'), ('form', 'n'), ('shape', 'n'), ('face', 'n'), ('region', 'n'), ('non-transitory', 'a'), ('machine', 'n'), ('readable', 'a'), ('medium', 'n'), ('claim', 'n'), ('machine', 'n'), ('readable', 'a'), ('medium', 'n'), ('comprising', 'v'), ('instructions', 'n'), ('response', 'n'), ('executed', 'v'), ('device', 'n'), ('cause', 'n'), ('device', 'n'), ('perform', 'n'), ('video', 'n'), ('coding', 'v'), ('based', 'v'), ('face', 'n'), ('detection', 'n'), ('tracking', 'v'), ('second', 'a'), ('free', 'a'), ('form', 'n'), ('shape', 'n'), ('face', 'n'), ('region', 'n'), ('second', 'a'), ('video', 'n'), ('frame', 'n'), ('based', 'v'), ('free', 'a'), ('form', 'n'), ('shape', 'n'), ('face', 'n'), ('region', 'n'), ('video', 'n'), ('frame', 'n'), ('non-transitory', 'a'), ('machine', 'n'), ('readable', 'a'), ('medium', 'n'), ('claim', 'n'), ('wherein', None), ('encoding', 'v'), ('video', 'n'), ('frame', 'n'), ('based', 'v'), ('least', 'a'), ('part', 'n'), ('first', 'a'), ('candidate', 'n'), ('face', 'n'), ('region', 'n'), ('valid', 'a'), ('face', 'n'), ('region', 'n'), ('comprises', 'v'), ('least', 'a'), ('one', None), ('reducing', 'v'), ('quantization', 'n'), ('parameter', 'n'), ('corresponding', 'v'), ('first', 'a'), ('candidate', 'n'), ('face', 'n'), ('region', 'n'), ('adjusting', 'v'), ('lambda', 'n'), ('value', 'n'), ('first', 'r'), ('candidate', 'a'), ('face', 'n'), ('region', 'n'), ('disabling', 'v'), ('skip', 'n'), ('coding', 'v'), ('first', 'a'), ('candidate', 'n'), ('face', 'n'), ('region', 'n'), ('method', 'n'), ('managing', 'v'), ('smart', 'a'), ('database', 'n'), ('stores', 'n'), ('facial', 'a'), ('images', 'n'), ('face', 'v'), ('recognition', 'n'), ('comprising', 'v'), ('steps', 'n'), ('managing', 'v'), ('device', 'n'), ('performing', 'v'), ('process', 'n'), ('counting', 'v'), ('one', None), ('specific', 'a'), ('facial', 'a'), ('images', 'n'), ('corresponding', 'v'), ('least', 'a'), ('one', None), ('specific', 'a'), ('person', 'n'), ('stored', 'v'), ('smart', 'a'), ('database', 'n'), ('new', 'a'), ('facial', 'a'), ('images', 'n'), ('face', 'v'), ('recognition', 'n'), ('continuously', 'r'), ('stored', 'v'), ('process', 'n'), ('determining', 'v'), ('whether', None), ('first', 'a'), ('counted', 'v'), ('value', 'n'), ('representing', 'v'), ('count', 'n'), ('specific', 'a'), ('facial', 'a'), ('images', 'n'), ('satisfies', 'n'), ('preset', 'v'), ('first', 'r'), ('set', 'v'), ('value', 'n'), ('b', 'n'), ('first', 'r'), ('counted', 'v'), ('value', 'n'), ('determined', 'v'), ('satisfying', 'v'), ('first', 'r'), ('set', 'v'), ('value', 'n'), ('managing', 'v'), ('device', 'n'), ('performing', 'v'), ('process', 'n'), ('inputting', 'v'), ('specific', 'a'), ('facial', 'a'), ('images', 'n'), ('neural', 'a'), ('aggregation', 'n'), ('network', 'n'), ('thereby', 'r'), ('allow', 'v'), ('neural', 'a'), ('aggregation', 'n'), ('network', 'n'), ('generate', 'v'), ('quality', 'n'), ('scores', 'n'), ('specific', 'a'), ('facial', 'a'), ('images', 'n'), ('aggregation', 'v'), ('specific', 'a'), ('facial', 'a'), ('images', 'n'), ('process', 'n'), ('sorting', 'v'), ('quality', 'n'), ('scores', 'n'), ('corresponding', 'v'), ('specific', 'a'), ('facial', 'a'), ('images', 'n'), ('descending', 'v'), ('order', 'n'), ('quality', 'n'), ('scores', 'v'), ('process', 'n'), ('counting', 'n'), ('sorted', 'v'), ('specific', 'a'), ('facial', 'a'), ('images', 'n'), ('descending', 'v'), ('order', 'n'), ('second', 'a'), ('counted', 'v'), ('value', 'n'), ('represents', 'v'), ('number', 'n'), ('counted', 'v'), ('part', 'n'), ('specific', 'a'), ('facial', 'a'), ('images', 'n'), ('becomes', 'v'), ('equal', 'a'), ('preset', 'a'), ('second', 'n'), ('set', 'v'), ('value', 'n'), ('process', 'n'), ('deleting', 'v'), ('uncounted', 'a'), ('part', 'n'), ('specific', 'a'), ('facial', 'a'), ('images', 'n'), ('smart', 'a'), ('database', 'n'), ('method', 'n'), ('claim', 'n'), ('comprising', 'v'), ('step', 'n'), ('c', 'r'), ('managing', 'v'), ('device', 'n'), ('performing', 'v'), ('process', 'n'), ('generating', 'v'), ('least', 'a'), ('one', None), ('optimal', 'a'), ('feature', 'n'), ('weighted', 'v'), ('summation', 'n'), ('one', None), ('features', 'v'), ('specific', 'a'), ('facial', 'a'), ('images', 'n'), ('using', 'v'), ('counted', 'a'), ('part', 'n'), ('quality', 'n'), ('scores', 'v'), ('process', 'a'), ('setting', 'v'), ('optimal', 'a'), ('feature', 'n'), ('representative', 'a'), ('face', 'n'), ('corresponding', 'v'), ('specific', 'a'), ('person', 'n'), ('method', 'a'), ('claim', 'n'), ('wherein', 'a'), ('step', 'n'), ('b', 'n'), ('managing', 'v'), ('device', 'n'), ('performs', 'n'), ('process', 'n'), ('inputting', 'v'), ('specific', 'a'), ('facial', 'a'), ('images', 'n'), ('cnn', 'v'), ('neural', 'a'), ('aggregation', 'n'), ('network', 'n'), ('thereby', 'r'), ('allow', 'v'), ('cnn', 'n'), ('generate', 'n'), ('one', None), ('features', 'v'), ('corresponding', 'v'), ('specific', 'a'), ('facial', 'a'), ('images', 'n'), ('process', 'n'), ('inputting', 'v'), ('least', 'a'), ('one', None), ('feature', 'n'), ('vector', 'n'), ('features', 'n'), ('embedded', 'v'), ('aggregation', 'n'), ('module', 'n'), ('including', 'v'), ('least', 'a'), ('two', None), ('attention', 'n'), ('blocks', 'n'), ('thereby', 'r'), ('allow', 'v'), ('aggregation', 'n'), ('module', 'n'), ('generate', 'v'), ('quality', 'n'), ('scores', 'n'), ('features', 'v'), ('method', 'a'), ('claim', 'n'), ('wherein', 'a'), ('step', 'n'), ('b', 'n'), ('managing', 'v'), ('device', 'n'), ('performs', 'n'), ('process', 'n'), ('matching', 'v'), ('i-', 'a'), ('one', None), ('features', 'v'), ('corresponding', 'v'), ('specific', 'a'), ('facial', 'a'), ('images', 'n'), ('stored', 'v'), ('smart', 'a'), ('database', 'n'), ('i-', 'a'), ('quality', 'n'), ('scores', 'n'), ('ii', 'v'), ('specific', 'a'), ('person', 'n'), ('process', 'n'), ('storing', 'v'), ('matched', 'v'), ('features', 'n'), ('matched', 'v'), ('quality', 'n'), ('scores', 'n'), ('smart', 'v'), ('database', 'n'), ('method', 'n'), ('claim', 'n'), ('comprising', 'v'), ('step', 'n'), ('managing', 'v'), ('device', 'n'), ('performing', 'v'), ('one', None), ('process', 'n'), ('learning', 'v'), ('face', 'n'), ('recognition', 'n'), ('system', 'n'), ('using', 'v'), ('specific', 'a'), ('facial', 'a'), ('images', 'n'), ('corresponding', 'v'), ('specific', 'a'), ('person', 'n'), ('stored', 'v'), ('smart', 'a'), ('database', 'n'), ('ii', 'n'), ('process', 'n'), ('transmitting', 'v'), ('specific', 'a'), ('facial', 'a'), ('images', 'n'), ('corresponding', 'v'), ('specific', 'a'), ('person', 'n'), ('learning', 'a'), ('device', 'n'), ('corresponding', 'v'), ('face', 'n'), ('recognition', 'n'), ('system', 'n'), ('thereby', 'r'), ('allow', 'v'), ('learning', 'v'), ('device', 'n'), ('learn', None), ('face', 'n'), ('recognition', 'n'), ('system', 'n'), ('using', 'v'), ('specific', 'a'), ('facial', 'a'), ('images', 'n'), ('method', 'v'), ('claim', 'n'), ('wherein', 'a'), ('neural', 'a'), ('aggregation', 'n'), ('network', 'n'), ('learned', 'v'), ('learning', 'a'), ('device', 'n'), ('repeating', 'v'), ('process', 'n'), ('inputting', 'v'), ('multiple', 'a'), ('facial', 'a'), ('images', 'n'), ('training', 'v'), ('corresponding', 'a'), ('image', 'n'), ('set', 'v'), ('single', 'a'), ('face', 'n'), ('video', 'n'), ('single', 'a'), ('face', 'n'), ('cnn', 'a'), ('neural', 'a'), ('aggregation', 'n'), ('network', 'n'), ('thereby', 'r'), ('allow', 'v'), ('cnn', 'n'), ('generate', 'n'), ('one', None), ('features', 'v'), ('training', 'v'), ('applying', 'v'), ('least', 'a'), ('one', None), ('convolution', 'n'), ('operation', 'n'), ('facial', 'a'), ('images', 'n'), ('training', 'v'), ('ii', 'a'), ('process', 'n'), ('inputting', 'v'), ('least', 'a'), ('one', None), ('feature', 'n'), ('vector', 'n'), ('training', 'n'), ('features', 'n'), ('training', 'v'), ('embedded', 'a'), ('aggregation', 'n'), ('module', 'n'), ('including', 'v'), ('least', 'a'), ('two', None), ('attention', 'n'), ('blocks', 'n'), ('neural', 'a'), ('aggregation', 'n'), ('network', 'n'), ('thereby', 'r'), ('allow', 'a'), ('aggregation', 'n'), ('module', 'n'), ('generate', 'v'), ('quality', 'n'), ('scores', 'n'), ('training', 'v'), ('features', 'n'), ('training', 'v'), ('aggregation', 'n'), ('features', 'n'), ('training', 'v'), ('using', 'v'), ('one', None), ('attention', 'n'), ('parameters', 'n'), ('learned', 'v'), ('previous', 'a'), ('iteration', 'n'), ('iii', 'n'), ('process', 'n'), ('outputting', 'v'), ('least', 'a'), ('one', None), ('optimal', 'a'), ('feature', 'n'), ('training', 'n'), ('weighted', 'a'), ('summation', 'n'), ('features', 'n'), ('training', 'v'), ('using', 'v'), ('quality', 'n'), ('scores', 'n'), ('training', 'v'), ('iv', 'a'), ('process', 'n'), ('updating', 'v'), ('attention', 'n'), ('parameters', 'n'), ('learned', 'v'), ('previous', 'a'), ('iteration', 'n'), ('least', 'a'), ('two', None), ('attention', 'n'), ('blocks', 'n'), ('one', None), ('losses', 'n'), ('minimized', 'v'), ('outputted', 'a'), ('loss', 'n'), ('layer', 'n'), ('referring', 'v'), ('optimal', 'a'), ('feature', 'n'), ('training', 'v'), ('corresponding', 'v'), ('ground', 'n'), ('truth', 'n'), ('managing', 'v'), ('device', 'n'), ('managing', 'v'), ('smart', 'a'), ('database', 'n'), ('stores', 'n'), ('facial', 'a'), ('images', 'n'), ('face', 'v'), ('recognition', 'n'), ('comprising', 'v'), ('least', 'a'), ('one', None), ('memory', 'n'), ('stores', 'n'), ('instructions', 'n'), ('least', 'v'), ('one', None), ('processor', 'n'), ('configured', 'v'), ('execute', 'a'), ('instructions', 'n'), ('perform', 'v'), ('support', 'n'), ('another', None), ('device', 'n'), ('perform', 'n'), ('process', 'n'), ('counting', 'v'), ('one', None), ('specific', 'a'), ('facial', 'a'), ('images', 'n'), ('corresponding', 'v'), ('least', 'a'), ('one', None), ('specific', 'a'), ('person', 'n'), ('stored', 'v'), ('smart', 'a'), ('database', 'n'), ('new', 'a'), ('facial', 'a'), ('images', 'n'), ('face', 'v'), ('recognition', 'n'), ('continuously', 'r'), ('stored', 'v'), ('process', 'n'), ('determining', 'v'), ('whether', None), ('first', 'a'), ('counted', 'v'), ('value', 'n'), ('representing', 'v'), ('count', 'n'), ('specific', 'a'), ('facial', 'a'), ('images', 'n'), ('satisfies', 'n'), ('preset', 'v'), ('first', 'r'), ('set', 'v'), ('value', 'n'), ('ii', 'n'), ('first', 'r'), ('counted', 'v'), ('value', 'n'), ('determined', 'v'), ('satisfying', 'v'), ('first', 'r'), ('set', 'v'), ('value', 'n'), ('process', 'n'), ('inputting', 'v'), ('specific', 'a'), ('facial', 'a'), ('images', 'n'), ('neural', 'a'), ('aggregation', 'n'), ('network', 'n'), ('thereby', 'r'), ('allow', 'v'), ('neural', 'a'), ('aggregation', 'n'), ('network', 'n'), ('generate', 'v'), ('quality', 'n'), ('scores', 'n'), ('specific', 'a'), ('facial', 'a'), ('images', 'n'), ('aggregation', 'v'), ('specific', 'a'), ('facial', 'a'), ('images', 'n'), ('process', 'n'), ('sorting', 'v'), ('quality', 'n'), ('scores', 'n'), ('corresponding', 'v'), ('specific', 'a'), ('facial', 'a'), ('images', 'n'), ('descending', 'v'), ('order', 'n'), ('quality', 'n'), ('scores', 'v'), ('process', 'n'), ('counting', 'n'), ('sorted', 'v'), ('specific', 'a'), ('facial', 'a'), ('images', 'n'), ('descending', 'v'), ('order', 'n'), ('second', 'a'), ('counted', 'v'), ('value', 'n'), ('represents', 'v'), ('number', 'n'), ('counted', 'v'), ('part', 'n'), ('specific', 'a'), ('facial', 'a'), ('images', 'n'), ('becomes', 'v'), ('equal', 'a'), ('preset', 'a'), ('second', 'n'), ('set', 'v'), ('value', 'n'), ('process', 'n'), ('deleting', 'v'), ('uncounted', 'a'), ('part', 'n'), ('specific', 'a'), ('facial', 'a'), ('images', 'n'), ('smart', 'v'), ('database', 'n'), ('managing', 'v'), ('device', 'n'), ('claim', 'n'), ('wherein', 'n'), ('processor', 'n'), ('performs', 'n'), ('iii', 'v'), ('process', 'n'), ('generating', 'v'), ('least', 'a'), ('one', None), ('optimal', 'a'), ('feature', 'n'), ('weighted', 'v'), ('summation', 'n'), ('one', None), ('features', 'v'), ('specific', 'a'), ('facial', 'a'), ('images', 'n'), ('using', 'v'), ('counted', 'a'), ('part', 'n'), ('quality', 'n'), ('scores', 'v'), ('process', 'a'), ('setting', 'v'), ('optimal', 'a'), ('feature', 'n'), ('representative', 'a'), ('face', 'n'), ('corresponding', 'v'), ('specific', 'a'), ('person', 'n'), ('managing', 'v'), ('device', 'n'), ('claim', 'n'), ('wherein', 'n'), ('process', 'n'), ('ii', 'n'), ('processor', 'n'), ('performs', 'n'), ('process', 'n'), ('inputting', 'v'), ('specific', 'a'), ('facial', 'a'), ('images', 'n'), ('cnn', 'v'), ('neural', 'a'), ('aggregation', 'n'), ('network', 'n'), ('thereby', 'r'), ('allow', 'v'), ('cnn', 'n'), ('generate', 'n'), ('one', None), ('features', 'v'), ('corresponding', 'v'), ('specific', 'a'), ('facial', 'a'), ('images', 'n'), ('process', 'n'), ('inputting', 'v'), ('least', 'a'), ('one', None), ('feature', 'n'), ('vector', 'n'), ('features', 'n'), ('embedded', 'v'), ('aggregation', 'n'), ('module', 'n'), ('including', 'v'), ('least', 'a'), ('two', None), ('attention', 'n'), ('blocks', 'n'), ('thereby', 'r'), ('allow', 'v'), ('aggregation', 'n'), ('module', 'n'), ('generate', 'v'), ('quality', 'n'), ('scores', 'n'), ('features', 'v'), ('managing', 'v'), ('device', 'n'), ('claim', 'n'), ('wherein', 'n'), ('process', 'n'), ('ii', 'n'), ('processor', 'n'), ('performs', 'n'), ('process', 'n'), ('matching', 'v'), ('i-', 'a'), ('one', None), ('features', 'v'), ('corresponding', 'v'), ('specific', 'a'), ('facial', 'a'), ('images', 'n'), ('stored', 'v'), ('smart', 'a'), ('database', 'n'), ('i-', 'a'), ('quality', 'n'), ('scores', 'n'), ('ii', 'v'), ('specific', 'a'), ('person', 'n'), ('process', 'n'), ('storing', 'v'), ('matched', 'v'), ('features', 'n'), ('matched', 'v'), ('quality', 'n'), ('scores', 'n'), ('smart', 'v'), ('database', 'n'), ('managing', 'v'), ('device', 'n'), ('claim', 'n'), ('wherein', 'n'), ('processor', 'n'), ('performs', 'n'), ('iv', 'v'), ('one', None), ('process', 'n'), ('learning', 'v'), ('face', 'n'), ('recognition', 'n'), ('system', 'n'), ('using', 'v'), ('specific', 'a'), ('facial', 'a'), ('images', 'n'), ('corresponding', 'v'), ('specific', 'a'), ('person', 'n'), ('stored', 'v'), ('smart', 'a'), ('database', 'n'), ('ii', 'n'), ('process', 'n'), ('transmitting', 'v'), ('specific', 'a'), ('facial', 'a'), ('images', 'n'), ('corresponding', 'v'), ('specific', 'a'), ('person', 'n'), ('learning', 'a'), ('device', 'n'), ('corresponding', 'v'), ('face', 'n'), ('recognition', 'n'), ('system', 'n'), ('thereby', 'r'), ('allow', 'v'), ('learning', 'v'), ('device', 'n'), ('learn', None), ('face', 'n'), ('recognition', 'n'), ('system', 'n'), ('using', 'v'), ('specific', 'a'), ('facial', 'a'), ('images', 'n'), ('managing', 'v'), ('device', 'n'), ('claim', 'n'), ('wherein', None), ('neural', 'a'), ('aggregation', 'n'), ('network', 'n'), ('learned', 'v'), ('learning', 'a'), ('device', 'n'), ('repeating', 'v'), ('process', 'n'), ('inputting', 'v'), ('multiple', 'a'), ('facial', 'a'), ('images', 'n'), ('training', 'v'), ('corresponding', 'a'), ('image', 'n'), ('set', 'v'), ('single', 'a'), ('face', 'n'), ('video', 'n'), ('single', 'a'), ('face', 'n'), ('cnn', 'a'), ('neural', 'a'), ('aggregation', 'n'), ('network', 'n'), ('thereby', 'r'), ('allow', 'v'), ('cnn', 'n'), ('generate', 'n'), ('one', None), ('features', 'v'), ('training', 'v'), ('applying', 'v'), ('least', 'a'), ('one', None), ('convolution', 'n'), ('operation', 'n'), ('facial', 'a'), ('images', 'n'), ('training', 'v'), ('ii', 'a'), ('process', 'n'), ('inputting', 'v'), ('least', 'a'), ('one', None), ('feature', 'n'), ('vector', 'n'), ('training', 'n'), ('features', 'n'), ('training', 'v'), ('embedded', 'a'), ('aggregation', 'n'), ('module', 'n'), ('including', 'v'), ('least', 'a'), ('two', None), ('attention', 'n'), ('blocks', 'n'), ('neural', 'a'), ('aggregation', 'n'), ('network', 'n'), ('thereby', 'r'), ('allow', 'a'), ('aggregation', 'n'), ('module', 'n'), ('generate', 'v'), ('quality', 'n'), ('scores', 'n'), ('training', 'v'), ('features', 'n'), ('training', 'v'), ('aggregation', 'n'), ('features', 'n'), ('training', 'v'), ('using', 'v'), ('one', None), ('attention', 'n'), ('parameters', 'n'), ('learned', 'v'), ('previous', 'a'), ('iteration', 'n'), ('iii', 'n'), ('process', 'n'), ('outputting', 'v'), ('least', 'a'), ('one', None), ('optimal', 'a'), ('feature', 'n'), ('training', 'n'), ('weighted', 'a'), ('summation', 'n'), ('features', 'n'), ('training', 'v'), ('using', 'v'), ('quality', 'n'), ('scores', 'n'), ('training', 'v'), ('iv', 'a'), ('process', 'n'), ('updating', 'v'), ('attention', 'n'), ('parameters', 'n'), ('learned', 'v'), ('previous', 'a'), ('iteration', 'n'), ('least', 'a'), ('two', None), ('attention', 'n'), ('blocks', 'n'), ('one', None), ('losses', 'n'), ('minimized', 'v'), ('outputted', 'a'), ('loss', 'n'), ('layer', 'n'), ('referring', 'v'), ('optimal', 'a'), ('feature', 'n'), ('training', 'v'), ('corresponding', 'v'), ('ground', 'n'), ('truth', 'n'), ('object', None), ('data', 'n'), ('processing', 'v'), ('system', 'n'), ('comprising', 'v'), ('least', 'a'), ('one', None), ('processor', 'n'), ('configured', 'v'), ('execute', None), ('least', 'a'), ('one', None), ('implementation', 'n'), ('plurality', 'n'), ('recognition', 'n'), ('algorithms', 'r'), ('stored', 'v'), ('least', 'a'), ('one', None), ('non-transitory', 'a'), ('computer-readable', 'a'), ('storage', 'n'), ('medium', 'n'), ('recognition', 'n'), ('algorithm', None), ('feature', 'n'), ('density', 'n'), ('selection', 'n'), ('criteria', 'n'), ('data', 'n'), ('preprocessing', 'v'), ('code', 'n'), ('executed', 'v'), ('least', 'a'), ('one', None), ('processor', 'n'), ('data', 'n'), ('preprocessing', 'v'), ('code', 'n'), ('comprising', 'v'), ('invariant', 'a'), ('feature', 'n'), ('identification', 'n'), ('algorithm', 'r'), ('configured', 'v'), ('obtain', 'v'), ('digital', 'a'), ('representation', 'n'), ('scene', 'n'), ('scene', 'n'), ('comprising', 'v'), ('one', None), ('textual', 'a'), ('media', 'n'), ('generate', 'n'), ('set', 'v'), ('invariant', 'a'), ('features', 'n'), ('applying', 'v'), ('invariant', 'a'), ('feature', 'n'), ('identification', 'n'), ('algorithm', None), ('digital', 'a'), ('representation', 'n'), ('cluster', 'n'), ('set', 'v'), ('invariant', 'a'), ('features', 'n'), ('regions', 'n'), ('interest', 'n'), ('digital', 'a'), ('representation', 'n'), ('scene', 'n'), ('region', 'n'), ('interest', 'n'), ('region', 'n'), ('feature', 'n'), ('density', 'n'), ('classify', 'v'), ('region', 'n'), ('classifier', 'a'), ('code', 'n'), ('least', 'a'), ('one', None), ('regions', 'n'), ('interest', 'n'), ('according', 'v'), ('object', 'a'), ('type', 'n'), ('function', 'n'), ('attributes', 'v'), ('derived', 'a'), ('region', 'n'), ('feature', 'n'), ('density', 'n'), ('digital', 'a'), ('representation', 'n'), ('wherein', 'v'), ('least', 'a'), ('one', None), ('classified', 'a'), ('regions', 'n'), ('interest', 'n'), ('corresponds', 'n'), ('text', 'a'), ('use', 'n'), ('classification', 'n'), ('result', 'n'), ('corresponding', 'v'), ('least', 'a'), ('one', None), ('regions', 'n'), ('interest', 'n'), ('classify', 'n'), ('another', None), ('regions', 'n'), ('interest', 'n'), ('according', 'v'), ('object', 'a'), ('type', 'n'), ('wherein', 'n'), ('another', None), ('regions', 'n'), ('interest', 'n'), ('corresponds', 'v'), ('region', 'n'), ('interest', 'n'), ('images', 'n'), ('system', 'n'), ('claim', 'v'), ('wherein', None), ('preprocessing', 'v'), ('code', 'n'), ('based', 'v'), ('feature', 'n'), ('density', 'n'), ('selection', 'n'), ('criteria', 'n'), ('determines', 'v'), ('ocr', 'a'), ('algorithm', 'n'), ('applicable', 'a'), ('text', 'a'), ('recognition', 'n'), ('algorithms', 'n'), ('applicable', 'a'), ('aspects', 'n'), ('photographs', 'v'), ('logos', 'a'), ('system', 'n'), ('claim', 'n'), ('wherein', None), ('user', 'a'), ('creates', 'n'), ('user', 'v'), ('profile', None), ('camera-equipped', 'a'), ('smartphone', 'n'), ('includes', 'v'), ('information', 'n'), ('user', 'n'), ('visually', 'r'), ('impaired', 'a'), ('causes', 'n'), ('prioritized', 'a'), ('execution', 'n'), ('ocr', None), ('algorithm', 'a'), ('text', 'a'), ('reader', 'n'), ('program', 'n'), ('begins', 'v'), ('reading', 'v'), ('text', None), ('user', 'a'), ('quickly', 'r'), ('possible', 'a'), ('system', 'n'), ('claim', 'n'), ('comprising', 'v'), ('audio', 'a'), ('tactile', 'n'), ('feedback', 'n'), ('mechanism', 'n'), ('helps', 'v'), ('user', 'a'), ('position', 'n'), ('smart', 'n'), ('phone', 'n'), ('relative', 'a'), ('text', 'n'), ('system', 'n'), ('claim', 'n'), ('comprising', 'v'), ('``', None), ('hold', 'v'), ('still', 'r'), (\"''\", None), ('audio', 'a'), ('feedback', 'n'), ('signal', 'a'), ('sent', 'v'), ('user', 'a'), ('text', 'n'), ('center', 'n'), ('captured', 'v'), ('scene', 'n'), ('system', 'n'), ('claim', 'n'), ('wherein', None), ('digital', 'a'), ('representation', 'n'), ('comprises', 'n'), ('least', 'v'), ('one', None), ('following', 'v'), ('types', 'n'), ('digital', 'a'), ('data', 'n'), ('image', 'n'), ('data', 'n'), ('video', 'n'), ('data', 'n'), ('audio', 'r'), ('data', 'n'), ('system', 'n'), ('claim', 'n'), ('wherein', 'n'), ('invariant', 'a'), ('feature', 'n'), ('identification', 'n'), ('algorithm', 'n'), ('comprises', 'v'), ('least', 'a'), ('one', None), ('following', 'v'), ('feature', 'n'), ('identification', 'n'), ('algorithms', None), ('fast', 'a'), ('sift', 'n'), ('freak', 'n'), ('brisk', 'a'), ('harris', 'n'), ('daisy', 'n'), ('mser', 'n'), ('system', 'n'), ('claim', 'n'), ('wherein', 'n'), ('invariant', 'a'), ('feature', 'n'), ('identification', 'n'), ('algorithm', 'n'), ('includes', 'v'), ('least', 'a'), ('one', None), ('following', 'v'), ('edge', 'n'), ('detection', 'n'), ('algorithm', 'n'), ('corner', 'n'), ('detection', 'n'), ('algorithm', 'a'), ('saliency', 'n'), ('map', 'n'), ('algorithm', 'n'), ('curve', 'n'), ('detection', 'n'), ('algorithm', None), ('texton', 'n'), ('identification', 'n'), ('algorithm', None), ('wavelets', 'n'), ('algorithm', 'a'), ('system', 'n'), ('claim', 'n'), ('wherein', None), ('least', 'a'), ('one', None), ('region', 'n'), ('interest', 'n'), ('represents', 'v'), ('least', 'a'), ('one', None), ('physical', 'a'), ('object', 'n'), ('scene', 'n'), ('system', 'n'), ('claim', 'n'), ('wherein', None), ('least', 'a'), ('one', None), ('region', 'n'), ('interest', 'n'), ('represents', 'v'), ('least', 'a'), ('one', None), ('textual', 'a'), ('media', 'n'), ('scene', 'n'), ('system', 'n'), ('claim', 'n'), ('wherein', 'a'), ('region', 'n'), ('interest', 'n'), ('represents', 'v'), ('document', 'a'), ('textual', 'a'), ('media', 'n'), ('system', 'n'), ('claim', 'n'), ('wherein', 'a'), ('region', 'n'), ('interest', 'n'), ('represents', 'v'), ('financial', 'a'), ('document', 'n'), ('system', 'n'), ('claim', 'n'), ('wherein', 'a'), ('region', 'n'), ('interest', 'n'), ('represents', 'v'), ('structured', 'v'), ('document', 'n'), ('system', 'n'), ('claim', 'n'), ('wherein', None), ('least', 'a'), ('one', None), ('implementation', 'n'), ('plurality', 'n'), ('recognition', 'n'), ('algorithms', 'v'), ('includes', 'v'), ('least', 'a'), ('one', None), ('following', 'v'), ('template', 'n'), ('driven', 'v'), ('algorithm', 'a'), ('face', 'n'), ('recognition', 'n'), ('algorithm', 'r'), ('optical', 'a'), ('character', 'n'), ('recognition', 'n'), ('algorithm', None), ('speech', 'n'), ('recognition', 'n'), ('algorithm', None), ('object', 'a'), ('recognition', 'n'), ('algorithm', 'n'), ('system', 'n'), ('claim', 'n'), ('wherein', 'n'), ('data', 'n'), ('preprocessing', 'v'), ('code', 'n'), ('configured', 'v'), ('assign', 'a'), ('region', 'n'), ('interest', 'n'), ('least', 'a'), ('one', None), ('recognition', 'n'), ('algorithm', 'n'), ('function', 'n'), ('scene', 'n'), ('context', 'n'), ('derived', 'v'), ('digital', 'a'), ('representation', 'n'), ('system', 'n'), ('claim', 'n'), ('wherein', None), ('scene', 'n'), ('context', 'n'), ('includes', 'v'), ('least', 'a'), ('one', None), ('following', 'v'), ('types', 'n'), ('data', 'n'), ('location', 'n'), ('position', 'n'), ('time', 'n'), ('user', 'a'), ('identity', 'n'), ('news', 'n'), ('event', 'n'), ('medical', 'a'), ('event', 'n'), ('promotion', 'n'), ('system', 'n'), ('claim', 'n'), ('comprising', 'v'), ('mobile', 'a'), ('device', 'n'), ('comprising', 'v'), ('least', 'a'), ('one', None), ('implementation', 'n'), ('plurality', 'n'), ('recognition', 'n'), ('algorithms', None), ('data', 'n'), ('preprocessing', 'v'), ('code', 'n'), ('system', 'n'), ('claim', 'n'), ('wherein', 'v'), ('mobile', 'a'), ('device', 'n'), ('comprises', 'n'), ('least', 'v'), ('one', None), ('following', 'v'), ('smart', 'a'), ('phone', 'n'), ('tablet', 'n'), ('wearable', 'a'), ('glass', 'n'), ('toy', 'n'), ('vehicle', 'n'), ('computer', 'n'), ('phablet', 'n'), ('system', 'n'), ('claim', 'n'), ('comprising', 'v'), ('network-accessible', 'a'), ('server', 'n'), ('device', 'n'), ('comprising', 'v'), ('least', 'a'), ('one', None), ('implementation', 'n'), ('plurality', 'n'), ('recognition', 'n'), ('algorithms', None), ('data', 'n'), ('preprocessing', 'v'), ('code', 'n'), ('system', 'n'), ('claim', 'n'), ('wherein', 'n'), ('object', 'v'), ('type', 'n'), ('includes', 'v'), ('least', 'a'), ('one', None), ('following', 'v'), ('face', 'n'), ('animal', 'a'), ('vehicle', 'n'), ('document', 'n'), ('plant', 'n'), ('building', 'n'), ('appliance', 'n'), ('clothing', 'n'), ('body', 'n'), ('part', 'n'), ('toy', 'n'), ('object', 'v'), ('data', 'n'), ('processing', 'n'), ('system', 'n'), ('comprising', 'v'), ('least', 'a'), ('one', None), ('processor', 'n'), ('configured', 'v'), ('execute', None), ('least', 'a'), ('one', None), ('implementation', 'n'), ('plurality', 'n'), ('recognition', 'n'), ('algorithms', 'r'), ('stored', 'v'), ('least', 'a'), ('one', None), ('non-transitory', 'a'), ('computer-readable', 'a'), ('storage', 'n'), ('medium', 'n'), ('recognition', 'n'), ('algorithm', None), ('feature', 'n'), ('density', 'n'), ('selection', 'n'), ('criteria', 'n'), ('data', 'n'), ('preprocessing', 'v'), ('code', 'n'), ('executed', 'v'), ('least', 'a'), ('one', None), ('processor', 'n'), ('data', 'n'), ('preprocessing', 'v'), ('code', 'n'), ('comprising', 'v'), ('invariant', 'a'), ('feature', 'n'), ('identification', 'n'), ('algorithm', 'r'), ('configured', 'v'), ('obtain', 'v'), ('digital', 'a'), ('representation', 'n'), ('scene', 'n'), ('scene', 'n'), ('comprising', 'v'), ('one', None), ('textual', 'a'), ('media', 'n'), ('generate', 'n'), ('set', 'v'), ('invariant', 'a'), ('features', 'n'), ('applying', 'v'), ('invariant', 'a'), ('feature', 'n'), ('identification', 'n'), ('algorithm', None), ('digital', 'a'), ('representation', 'n'), ('cluster', 'n'), ('set', 'v'), ('invariant', 'a'), ('features', 'n'), ('regions', 'n'), ('interest', 'n'), ('digital', 'a'), ('representation', 'n'), ('scene', 'n'), ('region', 'n'), ('interest', 'n'), ('region', 'n'), ('feature', 'n'), ('density', 'n'), ('classify', 'v'), ('region', 'n'), ('classifier', 'a'), ('code', 'n'), ('least', 'a'), ('one', None), ('regions', 'n'), ('interest', 'n'), ('according', 'v'), ('object', 'a'), ('type', 'n'), ('function', 'n'), ('attributes', 'v'), ('derived', 'a'), ('region', 'n'), ('feature', 'n'), ('density', 'n'), ('digital', 'a'), ('representation', 'n'), ('wherein', 'v'), ('least', 'a'), ('one', None), ('classified', 'a'), ('regions', 'n'), ('interest', 'n'), ('corresponds', 'n'), ('text', 'a'), ('use', 'n'), ('classification', 'n'), ('result', 'n'), ('corresponding', 'v'), ('least', 'a'), ('one', None), ('regions', 'n'), ('interest', 'n'), ('classify', 'n'), ('another', None), ('regions', 'n'), ('interest', 'n'), ('according', 'v'), ('object', 'a'), ('type', 'n'), ('wherein', 'n'), ('another', None), ('regions', 'n'), ('interest', 'n'), ('corresponds', 'v'), ('region', 'n'), ('interest', 'n'), ('images', 'n'), ('assign', 'a'), ('region', 'n'), ('interest', 'n'), ('least', 'a'), ('one', None), ('recognition', 'n'), ('algorithm', None), ('least', 'a'), ('one', None), ('implementation', 'n'), ('plurality', 'n'), ('diverse', 'a'), ('recognition', 'n'), ('algorithms', 'n'), ('function', 'n'), ('region', 'n'), ('feature', 'n'), ('density', 'n'), ('region', 'n'), ('interest', 'n'), ('feature', 'n'), ('density', 'n'), ('selection', 'n'), ('criteria', 'n'), ('least', 'v'), ('one', None), ('implementation', 'n'), ('plurality', 'n'), ('diverse', 'a'), ('recognition', 'n'), ('algorithms', None), ('configure', 'n'), ('assigned', 'v'), ('recognition', 'n'), ('algorithms', 'n'), ('process', 'n'), ('respective', 'a'), ('regions', 'n'), ('interest', 'n'), ('wherein', 'n'), ('preprocessing', 'v'), ('code', 'n'), ('based', 'v'), ('feature', 'n'), ('density', 'n'), ('selection', 'n'), ('criteria', 'n'), ('determines', 'v'), ('ocr', 'a'), ('algorithm', 'n'), ('applicable', 'a'), ('text', 'a'), ('recognition', 'n'), ('algorithms', 'n'), ('applicable', 'a'), ('aspects', 'n'), ('photographs', 'v'), ('logos', 'a'), ('device', 'n'), ('comprising', 'v'), ('least', 'a'), ('one', None), ('processor', 'n'), ('configured', 'v'), ('execute', None), ('least', 'a'), ('one', None), ('implementation', 'n'), ('plurality', 'n'), ('recognition', 'n'), ('algorithms', 'r'), ('stored', 'v'), ('least', 'a'), ('one', None), ('non-transitory', 'a'), ('computer-readable', 'a'), ('storage', 'n'), ('medium', 'n'), ('recognition', 'n'), ('algorithm', None), ('feature', 'n'), ('density', 'n'), ('selection', 'n'), ('criteria', 'n'), ('data', 'n'), ('preprocessing', 'v'), ('code', 'n'), ('executed', 'v'), ('least', 'a'), ('one', None), ('processor', 'n'), ('data', 'n'), ('preprocessing', 'v'), ('code', 'n'), ('comprising', 'v'), ('invariant', 'a'), ('feature', 'n'), ('identification', 'n'), ('algorithm', 'r'), ('configured', 'v'), ('obtain', 'v'), ('digital', 'a'), ('representation', 'n'), ('scene', 'n'), ('scene', 'n'), ('comprising', 'v'), ('one', None), ('textual', 'a'), ('media', 'n'), ('generate', 'n'), ('set', 'v'), ('invariant', 'a'), ('features', 'n'), ('applying', 'v'), ('invariant', 'a'), ('feature', 'n'), ('identification', 'n'), ('algorithm', None), ('digital', 'a'), ('representation', 'n'), ('cluster', 'n'), ('set', 'v'), ('invariant', 'a'), ('features', 'n'), ('regions', 'n'), ('interest', 'n'), ('digital', 'a'), ('representation', 'n'), ('scene', 'n'), ('region', 'n'), ('interest', 'n'), ('region', 'n'), ('feature', 'n'), ('density', 'n'), ('classify', 'v'), ('region', 'n'), ('classifier', 'a'), ('code', 'n'), ('least', 'a'), ('one', None), ('regions', 'n'), ('interest', 'n'), ('according', 'v'), ('object', 'a'), ('type', 'n'), ('function', 'n'), ('attributes', 'v'), ('derived', 'a'), ('region', 'n'), ('feature', 'n'), ('density', 'n'), ('digital', 'a'), ('representation', 'n'), ('wherein', 'v'), ('least', 'a'), ('one', None), ('classified', 'a'), ('regions', 'n'), ('interest', 'n'), ('corresponds', 'n'), ('text', 'a'), ('use', 'n'), ('classification', 'n'), ('result', 'n'), ('corresponding', 'v'), ('least', 'a'), ('one', None), ('regions', 'n'), ('interest', 'n'), ('classify', 'n'), ('another', None), ('regions', 'n'), ('interest', 'n'), ('according', 'v'), ('object', 'a'), ('type', 'n'), ('wherein', 'n'), ('another', None), ('regions', 'n'), ('interest', 'n'), ('corresponds', 'v'), ('region', 'n'), ('interest', 'n'), ('images', 'n'), ('mobile', 'v'), ('terminal', 'a'), ('comprising', 'n'), ('front', 'a'), ('camera', 'n'), ('configured', 'v'), ('obtain', 'v'), ('two-dimensional', 'a'), ('face', 'n'), ('image', 'n'), ('user', 'a'), ('glance', 'n'), ('sensor', 'n'), ('tilted', 'v'), ('certain', 'a'), ('angle', 'n'), ('disposed', 'v'), ('adjacent', 'a'), ('front', 'a'), ('camera', 'n'), ('obtain', 'v'), ('metadata', 'a'), ('face', 'n'), ('image', 'n'), ('controller', 'n'), ('obtaining', 'v'), ('distance', 'n'), ('glance', 'n'), ('sensor', 'n'), ('front', 'n'), ('camera', 'n'), ('distance', 'n'), ('enabling', 'v'), ('area', 'n'), ('overlap', None), ('region', 'n'), ('first', 'a'), ('region', 'n'), ('representing', 'v'), ('range', 'n'), ('photographable', 'a'), ('front', 'n'), ('camera', 'n'), ('overlaps', 'v'), ('second', 'a'), ('region', 'n'), ('representing', 'v'), ('range', 'n'), ('photographable', 'a'), ('glance', 'n'), ('sensor', 'n'), ('maximum', 'n'), ('mobile', 'a'), ('terminal', 'a'), ('claim', 'n'), ('wherein', 'n'), ('controller', 'n'), ('configured', 'v'), ('obtain', 'v'), ('distance', 'n'), ('enabling', 'v'), ('area', 'n'), ('overlap', 'a'), ('region', 'n'), ('maximum', 'a'), ('glance', 'n'), ('sensor', 'n'), ('front', 'n'), ('camera', 'n'), ('varying', 'v'), ('tilting', 'v'), ('angle', 'a'), ('glance', 'n'), ('sensor', 'n'), ('mobile', 'a'), ('terminal', 'a'), ('claim', 'n'), ('wherein', 'n'), ('controller', 'n'), ('configured', 'v'), ('set', 'v'), ('distance', 'n'), ('enabling', 'v'), ('area', 'n'), ('overlap', 'a'), ('region', 'n'), ('maximum', 'a'), ('glance', 'n'), ('sensor', 'n'), ('front', 'n'), ('camera', 'n'), ('tilting', 'v'), ('angle', 'a'), ('glance', 'n'), ('sensor', 'n'), ('optimal', 'a'), ('disposition', 'n'), ('location', 'n'), ('glance', 'n'), ('sensor', 'n'), ('mobile', 'a'), ('terminal', 'a'), ('claim', 'n'), ('wherein', 'n'), ('controller', 'n'), ('configured', 'v'), ('set', 'v'), ('disposition', 'n'), ('location', 'n'), ('front', 'n'), ('camera', 'n'), ('original', 'a'), ('point', 'n'), ('calculates', 'n'), ('coordinates', 'n'), ('first', 'r'), ('triangle', 'v'), ('representing', 'v'), ('first', 'a'), ('region', 'n'), ('based', 'v'), ('field', 'n'), ('view', 'n'), ('front', 'a'), ('camera', 'n'), ('maximum', 'a'), ('photographing', 'v'), ('distance', 'n'), ('front', 'n'), ('camera', 'n'), ('mobile', 'a'), ('terminal', 'a'), ('claim', 'n'), ('wherein', 'n'), ('controller', 'n'), ('configured', 'v'), ('calculate', 'a'), ('coordinates', 'n'), ('second', 'a'), ('triangle', 'a'), ('representing', 'v'), ('second', 'a'), ('region', 'n'), ('based', 'v'), ('field', 'n'), ('view', 'n'), ('glance', 'n'), ('sensor', 'n'), ('maximum', 'n'), ('photographing', 'v'), ('distance', 'n'), ('glance', 'n'), ('sensor', 'n'), ('distance', 'n'), ('front', 'a'), ('camera', 'n'), ('glance', 'n'), ('sensor', 'n'), ('tilting', 'v'), ('angle', 'a'), ('glance', 'n'), ('sensor', 'n'), ('mobile', 'a'), ('terminal', 'a'), ('claim', 'n'), ('wherein', 'n'), ('glance', 'n'), ('sensor', 'n'), ('tilted', 'v'), ('controller', 'n'), ('configured', 'a'), ('calculate', 'n'), ('coordinates', 'n'), ('third', 'a'), ('triangle', 'a'), ('representing', 'v'), ('third', 'a'), ('region', 'n'), ('photographable', 'a'), ('glance', 'n'), ('sensor', 'n'), ('controller', 'n'), ('configured', 'v'), ('rotation-convert', 'a'), ('coordinates', 'n'), ('third', 'a'), ('triangle', 'n'), ('based', 'v'), ('tilting', 'v'), ('angle', 'a'), ('glance', 'n'), ('sensor', 'n'), ('calculate', 'n'), ('coordinates', 'n'), ('second', 'a'), ('triangle', 'v'), ('mobile', 'a'), ('terminal', 'a'), ('claim', 'n'), ('wherein', 'n'), ('controller', 'n'), ('configured', 'v'), ('calculate', 'n'), ('coordinates', 'n'), ('overlap', 'v'), ('region', 'n'), ('based', 'v'), ('coordinates', 'n'), ('first', 'a'), ('triangle', 'a'), ('coordinates', 'n'), ('second', 'a'), ('triangle', 'n'), ('calculates', 'n'), ('area', 'n'), ('overlap', 'v'), ('region', 'n'), ('based', 'v'), ('coordinates', 'n'), ('overlap', 'a'), ('region', 'n'), ('mobile', 'a'), ('terminal', 'a'), ('claim', 'n'), ('wherein', 'n'), ('controller', 'n'), ('configured', 'v'), ('generate', 'a'), ('three-dimensional', 'a'), ('face', 'n'), ('information', 'n'), ('based', 'v'), ('face', 'n'), ('image', 'n'), ('obtained', 'v'), ('front', 'a'), ('camera', 'n'), ('metadata', 'n'), ('obtained', 'v'), ('glance', 'n'), ('sensor', 'n'), ('mobile', 'a'), ('terminal', 'a'), ('claim', 'n'), ('wherein', 'n'), ('metadata', 'n'), ('comprises', 'v'), ('one', None), ('angle', 'n'), ('face', 'n'), ('user', 'n'), ('size', 'n'), ('face', 'n'), ('location', 'n'), ('face', 'n'), ('mobile', 'a'), ('terminal', 'a'), ('claim', 'n'), ('wherein', 'n'), ('angle', 'v'), ('face', 'n'), ('comprises', 'n'), ('angle', 'v'), ('face', 'n'), ('rotated', 'v'), ('one', None), ('pitch', 'n'), ('axis', 'n'), ('roll', 'n'), ('axis', 'n'), ('yaw', 'n'), ('axis', 'v'), ('mobile', 'a'), ('terminal', 'a'), ('claim', 'n'), ('comprising', 'v'), ('memory', 'n'), ('storing', 'v'), ('generated', 'v'), ('face', 'n'), ('information', 'n'), ('wherein', None), ('controller', 'n'), ('configured', 'v'), ('performs', 'n'), ('user', 'a'), ('authentication', 'n'), ('process', 'n'), ('comparing', 'v'), ('stored', 'v'), ('face', 'n'), ('information', 'n'), ('face', 'n'), ('information', 'n'), ('obtained', 'v'), ('user', 'a'), ('authentication', 'n'), ('mobile', 'a'), ('terminal', 'a'), ('claim', 'n'), ('wherein', 'n'), ('glance', 'n'), ('sensor', 'n'), ('controlled', 'v'), ('permanently', 'r'), ('activated', 'v'), ('low', 'a'), ('power', 'n'), ('obtain', 'v'), ('front', 'a'), ('image', 'n'), ('metadata', 'n'), ('front', 'a'), ('image', 'n'), ('mobile', 'a'), ('terminal', 'a'), ('claim', 'n'), ('wherein', 'n'), ('front', 'a'), ('camera', 'n'), ('glance', 'n'), ('sensor', 'n'), ('disposed', 'v'), ('line', 'n'), ('upper', 'a'), ('end', 'n'), ('mobile', 'a'), ('terminal', 'n'), ('mobile', 'a'), ('terminal', 'a'), ('claim', 'n'), ('wherein', 'n'), ('glance', 'n'), ('sensor', 'n'), ('tilted', 'v'), ('one', None), ('direction', 'n'), ('direction', 'n'), ('direction', 'n'), ('left', 'v'), ('direction', 'n'), ('right', 'a'), ('direction', 'n'), ('mobile', 'a'), ('terminal', 'a'), ('claim', 'n'), ('wherein', 'n'), ('metadata', 'n'), ('data', 'n'), ('changed', 'v'), ('mobile', 'a'), ('terminal', 'n'), ('tilted', 'v'), ('external', 'a'), ('physical', 'a'), ('force', 'n'), ('method', 'n'), ('comprising', 'v'), ('receiving', 'v'), ('smart', 'a'), ('television', 'n'), ('tv', 'n'), ('indication', 'n'), ('upcoming', 'v'), ('media', 'n'), ('programming', 'v'), ('wherein', 'n'), ('upcoming', 'a'), ('media', 'n'), ('programming', 'v'), ('based', 'v'), ('user', 'n'), ('profile', 'n'), ('identifying', 'v'), ('one', None), ('devices', 'n'), ('communication', 'n'), ('smart', 'a'), ('tv', 'n'), ('one', None), ('devices', 'n'), ('including', 'v'), ('least', 'a'), ('one', None), ('microphone', 'n'), ('camera', 'n'), ('instructing', 'v'), ('least', 'a'), ('one', None), ('identified', 'a'), ('device', 'n'), ('detect', 'n'), ('audio', 'n'), ('signals', 'n'), ('using', 'v'), ('respective', 'a'), ('microphone', 'n'), ('detect', 'a'), ('visual', 'a'), ('signals', 'n'), ('using', 'v'), ('respective', 'a'), ('camera', 'n'), ('selecting', 'v'), ('least', 'a'), ('one', None), ('device', 'n'), ('one', None), ('devices', 'n'), ('based', 'v'), ('detected', 'a'), ('audio', 'a'), ('signal', 'n'), ('detected', 'v'), ('visual', 'a'), ('signal', 'n'), ('providing', 'v'), ('instructions', 'n'), ('selected', 'v'), ('device', 'n'), ('output', 'n'), ('notification', 'n'), ('related', 'v'), ('upcoming', 'a'), ('media', 'n'), ('programming', 'v'), ('method', 'n'), ('claim', 'n'), ('wherein', None), ('upcoming', 'v'), ('media', 'n'), ('programming', 'v'), ('one', None), ('live', 'a'), ('television', 'n'), ('program', 'n'), ('recorded', 'v'), ('television', 'n'), ('program', 'n'), ('broadcast', 'n'), ('television', 'n'), ('program', 'n'), ('application-provided', 'a'), ('program', 'n'), ('method', 'n'), ('claim', 'n'), ('wherein', None), ('selecting', 'v'), ('first', 'a'), ('device', 'n'), ('based', 'v'), ('detected', 'a'), ('audio', 'a'), ('signal', 'n'), ('includes', 'v'), ('recognizing', 'v'), ('voice', 'n'), ('method', 'n'), ('claim', 'n'), ('comprising', 'v'), ('determining', 'v'), ('distance', 'n'), ('recognized', 'v'), ('voice', 'n'), ('wherein', 'n'), ('selecting', 'v'), ('first', 'a'), ('device', 'n'), ('based', 'v'), ('determined', 'a'), ('distance', 'n'), ('method', 'n'), ('claim', 'n'), ('wherein', None), ('selecting', 'v'), ('first', 'a'), ('device', 'n'), ('based', 'v'), ('detected', 'v'), ('visual', 'a'), ('signals', 'n'), ('includes', 'v'), ('recognizing', 'v'), ('face', 'n'), ('method', 'n'), ('claim', 'n'), ('wherein', None), ('recognizing', 'v'), ('face', 'n'), ('includes', 'v'), ('face', 'a'), ('recognition', 'n'), ('technique', 'n'), ('method', 'n'), ('claim', 'n'), ('comprising', 'v'), ('presenting', 'v'), ('smart', 'a'), ('tv', 'n'), ('upcoming', 'v'), ('media', 'n'), ('programming', 'v'), ('favorite', 'a'), ('channel', 'n'), ('list', 'n'), ('method', 'n'), ('claim', 'n'), ('comprising', 'v'), ('obtaining', 'v'), ('media', 'n'), ('programming', 'v'), ('viewing', 'v'), ('data', 'n'), ('wherein', 'r'), ('media', 'n'), ('programming', 'v'), ('viewing', 'v'), ('data', 'n'), ('includes', 'v'), ('least', 'a'), ('one', None), ('historical', 'a'), ('time', 'n'), ('historical', 'a'), ('date', 'n'), ('one', None), ('media', 'n'), ('programs', 'n'), ('viewed', 'v'), ('obtaining', 'v'), ('least', 'a'), ('one', None), ('current', 'a'), ('time', 'n'), ('current', 'a'), ('date', 'n'), ('processing', 'n'), ('media', 'n'), ('programming', 'v'), ('viewing', 'v'), ('data', 'n'), ('determine', 'n'), ('probability', 'n'), ('one', None), ('media', 'n'), ('programs', 'n'), ('viewed', 'v'), ('based', 'v'), ('least', 'a'), ('one', None), ('current', 'a'), ('time', 'n'), ('current', 'a'), ('date', 'n'), ('presenting', 'n'), ('favorite', 'a'), ('channel', 'n'), ('list', 'n'), ('based', 'v'), ('determined', 'a'), ('probability', 'n'), ('one', None), ('media', 'n'), ('programs', 'n'), ('viewed', 'v'), ('method', 'a'), ('claim', 'n'), ('wherein', 'n'), ('processing', 'v'), ('media', 'n'), ('programming', 'v'), ('viewing', 'v'), ('data', 'n'), ('includes', 'v'), ('employing', 'v'), ('neural', 'a'), ('network', 'n'), ('model', 'n'), ('method', 'n'), ('claim', 'n'), ('wherein', None), ('employing', 'v'), ('neural', 'a'), ('network', 'n'), ('model', 'n'), ('comprises', 'v'), ('determining', 'v'), ('duration', 'n'), ('one', None), ('media', 'n'), ('programs', 'n'), ('viewed', 'v'), ('least', 'a'), ('one', None), ('historical', 'a'), ('time', 'n'), ('historical', 'a'), ('date', 'n'), ('setting', 'v'), ('threshold', 'a'), ('time', 'n'), ('duration', 'n'), ('comparing', 'v'), ('determined', 'v'), ('duration', 'n'), ('threshold', 'a'), ('time', 'n'), ('duration', 'n'), ('filtering', 'v'), ('one', None), ('media', 'n'), ('programs', 'n'), ('viewed', 'v'), ('threshold', 'a'), ('time', 'n'), ('duration', 'n'), ('smart', 'a'), ('television', 'n'), ('tv', 'n'), ('comprising', 'v'), ('network', 'n'), ('interface', 'a'), ('non-transitory', 'a'), ('computer-readable', 'a'), ('medium', 'n'), ('processor', 'n'), ('communication', 'n'), ('network', 'n'), ('interface', 'a'), ('non-transitory', 'a'), ('computer-readable', 'a'), ('medium', 'n'), ('capable', 'a'), ('executing', 'v'), ('processor-executable', 'a'), ('program', 'n'), ('code', 'n'), ('stored', 'v'), ('non-transitory', 'a'), ('computer-readable', 'a'), ('medium', 'n'), ('cause', 'n'), ('smart', 'a'), ('tv', 'n'), ('receive', 'n'), ('indication', 'n'), ('upcoming', 'v'), ('media', 'n'), ('programming', 'v'), ('wherein', 'n'), ('upcoming', 'a'), ('media', 'n'), ('programming', 'v'), ('based', 'v'), ('user', 'n'), ('profile', 'n'), ('identify', 'v'), ('one', None), ('devices', 'n'), ('communication', 'n'), ('smart', 'a'), ('tv', 'n'), ('one', None), ('devices', 'n'), ('including', 'v'), ('least', 'a'), ('one', None), ('microphone', 'n'), ('camera', 'n'), ('instruct', 'n'), ('least', 'a'), ('one', None), ('identified', 'a'), ('device', 'n'), ('detect', 'n'), ('audio', 'n'), ('signals', 'n'), ('using', 'v'), ('respective', 'a'), ('microphone', 'n'), ('detect', 'a'), ('visual', 'a'), ('signals', 'n'), ('using', 'v'), ('respective', 'a'), ('camera', 'n'), ('select', 'n'), ('least', 'a'), ('one', None), ('device', 'n'), ('one', None), ('devices', 'n'), ('based', 'v'), ('detected', 'a'), ('audio', 'a'), ('signal', 'n'), ('detected', 'v'), ('visual', 'a'), ('signal', 'n'), ('provide', 'n'), ('instructions', 'n'), ('selected', 'v'), ('device', 'n'), ('output', 'n'), ('notification', 'n'), ('related', 'v'), ('upcoming', 'a'), ('media', 'n'), ('programming', 'v'), ('smart', 'a'), ('tv', 'n'), ('claim', 'n'), ('wherein', None), ('selecting', 'v'), ('first', 'a'), ('device', 'n'), ('based', 'v'), ('detected', 'a'), ('audio', 'a'), ('signal', 'n'), ('includes', 'v'), ('recognizing', 'v'), ('voice', 'n'), ('smart', 'a'), ('tv', 'n'), ('claim', 'n'), ('wherein', 'n'), ('processor', 'n'), ('capable', 'a'), ('executing', 'v'), ('processor-executable', 'a'), ('program', 'n'), ('code', 'n'), ('determine', 'n'), ('distance', 'n'), ('recognized', 'v'), ('voice', 'n'), ('wherein', 'n'), ('selecting', 'v'), ('first', 'a'), ('device', 'n'), ('based', 'v'), ('determined', 'a'), ('distance', 'n'), ('smart', 'a'), ('tv', 'n'), ('claim', 'n'), ('wherein', None), ('selecting', 'v'), ('first', 'a'), ('device', 'n'), ('based', 'v'), ('detected', 'v'), ('visual', 'a'), ('signals', 'n'), ('includes', 'v'), ('detecting', 'v'), ('presence', 'n'), ('user', 'a'), ('smart', 'a'), ('tv', 'n'), ('claim', 'n'), ('wherein', None), ('detecting', 'v'), ('presence', 'n'), ('user', 'n'), ('includes', 'v'), ('employing', 'v'), ('one', None), ('camera', 'n'), ('microphone', 'n'), ('fingerprint', 'n'), ('sensor', 'n'), ('associated', 'v'), ('least', 'a'), ('one', None), ('smart', 'a'), ('tv', 'n'), ('mobile', 'n'), ('device', 'n'), ('smartphone', 'n'), ('laptop', 'a'), ('computer', 'n'), ('tablet', 'n'), ('device', 'n'), ('wearable', 'a'), ('device', 'n'), ('internet', 'n'), ('things', 'n'), ('iot', 'a'), ('device', 'a'), ('internet', 'n'), ('everything', 'n'), ('ioe', 'n'), ('device', 'n'), ('iot', 'n'), ('hub', 'n'), ('ioe', 'n'), ('hub', 'n'), ('smart', 'a'), ('television', 'n'), ('tv', 'n'), ('comprising', 'n'), ('means', 'v'), ('receiving', 'v'), ('indication', 'n'), ('upcoming', 'v'), ('media', 'n'), ('programming', 'v'), ('wherein', 'n'), ('upcoming', 'a'), ('media', 'n'), ('programming', 'v'), ('based', 'v'), ('user', 'n'), ('profile', 'n'), ('means', 'v'), ('identifying', 'v'), ('one', None), ('devices', 'n'), ('communication', 'n'), ('smart', 'a'), ('tv', 'n'), ('one', None), ('devices', 'n'), ('including', 'v'), ('least', 'a'), ('one', None), ('microphone', 'n'), ('camera', 'n'), ('means', 'v'), ('instructing', 'v'), ('least', 'a'), ('one', None), ('identified', 'a'), ('device', 'n'), ('detect', 'n'), ('audio', 'n'), ('signals', 'n'), ('using', 'v'), ('respective', 'a'), ('microphone', 'n'), ('detect', 'a'), ('visual', 'a'), ('signals', 'n'), ('using', 'v'), ('respective', 'a'), ('camera', 'n'), ('means', 'v'), ('selecting', 'v'), ('least', 'a'), ('one', None), ('device', 'n'), ('one', None), ('devices', 'n'), ('based', 'v'), ('detected', 'a'), ('audio', 'a'), ('signal', 'n'), ('detected', 'v'), ('visual', 'a'), ('signal', 'n'), ('means', 'n'), ('providing', 'v'), ('instructions', 'n'), ('selected', 'v'), ('device', 'n'), ('output', 'n'), ('notification', 'n'), ('related', 'v'), ('upcoming', 'a'), ('media', 'n'), ('programming', 'v'), ('smart', 'a'), ('tv', 'n'), ('claim', 'n'), ('wherein', None), ('one', None), ('devices', 'n'), ('includes', 'v'), ('least', 'a'), ('one', None), ('mobile', 'a'), ('device', 'n'), ('smartphone', 'n'), ('laptop', 'a'), ('computer', 'n'), ('tablet', 'n'), ('device', 'n'), ('wearable', 'a'), ('device', 'n'), ('internet', 'n'), ('things', 'n'), ('iot', 'a'), ('device', 'a'), ('internet', 'n'), ('everything', 'n'), ('ioe', 'n'), ('device', 'n'), ('iot', 'n'), ('hub', 'n'), ('ioe', 'n'), ('hub', 'n'), ('another', None), ('smart', 'a'), ('tv', 'n'), ('smart', 'a'), ('tv', 'n'), ('claim', 'n'), ('wherein', None), ('upcoming', 'v'), ('media', 'n'), ('programming', 'v'), ('one', None), ('live', 'a'), ('television', 'n'), ('program', 'n'), ('recorded', 'v'), ('television', 'n'), ('program', 'n'), ('broadcast', 'n'), ('television', 'n'), ('program', 'n'), ('application-provided', 'a'), ('program', 'n'), ('smart', 'a'), ('tv', 'n'), ('claim', 'n'), ('wherein', None), ('notification', 'n'), ('includes', 'v'), ('least', 'a'), ('one', None), ('push', 'n'), ('message', 'n'), ('sms', 'a'), ('message', 'n'), ('waysms', 'a'), ('message', 'n'), ('audio', 'n'), ('alert', 'n'), ('audio', 'a'), ('message', 'n'), ('email', 'a'), ('message', 'n'), ('smart', 'a'), ('tv', 'n'), ('claim', 'n'), ('comprising', 'v'), ('presenting', 'v'), ('upcoming', 'a'), ('media', 'n'), ('programming', 'v'), ('favorite', 'a'), ('channel', 'n'), ('list', 'n'), ('smart', 'a'), ('tv', 'n'), ('claim', 'n'), ('comprising', 'v'), ('means', 'n'), ('obtaining', 'v'), ('media', 'n'), ('programming', 'v'), ('viewing', 'v'), ('data', 'n'), ('wherein', 'r'), ('media', 'n'), ('programming', 'v'), ('viewing', 'v'), ('data', 'n'), ('includes', 'v'), ('least', 'a'), ('one', None), ('historical', 'a'), ('time', 'n'), ('historical', 'a'), ('date', 'n'), ('one', None), ('media', 'n'), ('programs', 'n'), ('viewed', 'v'), ('smart', 'a'), ('tv', 'n'), ('means', 'n'), ('obtaining', 'v'), ('least', 'a'), ('one', None), ('current', 'a'), ('time', 'n'), ('current', 'a'), ('date', 'n'), ('means', 'v'), ('processing', 'v'), ('media', 'n'), ('programming', 'v'), ('viewing', 'v'), ('data', 'n'), ('determine', 'n'), ('probability', 'n'), ('one', None), ('media', 'n'), ('programs', 'n'), ('viewed', 'v'), ('smart', 'a'), ('tv', 'n'), ('based', 'v'), ('least', 'a'), ('one', None), ('current', 'a'), ('time', 'n'), ('current', 'a'), ('date', 'n'), ('means', 'n'), ('presenting', 'v'), ('favorite', 'a'), ('channel', 'n'), ('list', 'n'), ('based', 'v'), ('determined', 'a'), ('probability', 'n'), ('one', None), ('media', 'n'), ('programs', 'n'), ('viewed', 'v'), ('smart', 'a'), ('tv', 'n'), ('claim', 'n'), ('wherein', 'n'), ('means', 'v'), ('processing', 'v'), ('media', 'n'), ('programming', 'v'), ('viewing', 'v'), ('data', 'n'), ('includes', 'v'), ('employing', 'v'), ('neural', 'a'), ('network', 'n'), ('model', 'n'), ('smart', 'a'), ('tv', 'n'), ('claim', 'n'), ('wherein', None), ('employing', 'v'), ('neural', 'a'), ('network', 'n'), ('model', 'n'), ('comprises', 'v'), ('determining', 'v'), ('duration', 'n'), ('one', None), ('media', 'n'), ('programs', 'n'), ('viewed', 'v'), ('smart', 'a'), ('tv', 'n'), ('least', 'a'), ('one', None), ('historical', 'a'), ('time', 'n'), ('historical', 'a'), ('date', 'n'), ('setting', 'v'), ('threshold', 'a'), ('time', 'n'), ('duration', 'n'), ('comparing', 'v'), ('determined', 'v'), ('duration', 'n'), ('threshold', 'a'), ('time', 'n'), ('duration', 'n'), ('filtering', 'v'), ('one', None), ('media', 'n'), ('programs', 'n'), ('viewed', 'v'), ('threshold', 'a'), ('time', 'n'), ('duration', 'n'), ('smart', 'a'), ('tv', 'n'), ('claim', 'n'), ('comprising', 'n'), ('means', 'v'), ('adjusting', 'v'), ('least', 'a'), ('one', None), ('volume', 'n'), ('brightness', 'n'), ('smart', 'a'), ('tv', 'n'), ('wherein', 'n'), ('adjusting', 'v'), ('based', 'v'), ('least', 'a'), ('one', None), ('historical', 'a'), ('time', 'n'), ('historical', 'a'), ('date', 'n'), ('smart', 'a'), ('tv', 'n'), ('claim', 'n'), ('comprising', 'v'), ('means', 'n'), ('restricting', 'v'), ('access', 'n'), ('one', None), ('media', 'n'), ('programs', 'n'), ('non-transitory', 'a'), ('computer-readable', 'a'), ('medium', 'n'), ('comprising', 'v'), ('processor-executable', 'a'), ('program', 'n'), ('code', 'n'), ('configured', 'v'), ('cause', 'n'), ('processor', 'n'), ('smart', 'a'), ('television', 'n'), ('tv', 'n'), ('receive', 'v'), ('indication', 'n'), ('upcoming', 'a'), ('media', 'n'), ('programming', 'v'), ('wherein', 'n'), ('upcoming', 'a'), ('media', 'n'), ('programming', 'v'), ('based', 'v'), ('user', 'n'), ('profile', 'n'), ('identify', 'v'), ('one', None), ('devices', 'n'), ('communication', 'n'), ('smart', 'a'), ('tv', 'n'), ('one', None), ('devices', 'n'), ('including', 'v'), ('least', 'a'), ('one', None), ('microphone', 'n'), ('camera', 'n'), ('instruct', 'n'), ('least', 'a'), ('one', None), ('identified', 'a'), ('device', 'n'), ('detect', 'n'), ('audio', 'n'), ('signals', 'n'), ('using', 'v'), ('respective', 'a'), ('microphone', 'n'), ('detect', 'a'), ('visual', 'a'), ('signals', 'n'), ('using', 'v'), ('respective', 'a'), ('camera', 'n'), ('select', 'n'), ('least', 'a'), ('one', None), ('device', 'n'), ('one', None), ('devices', 'n'), ('based', 'v'), ('detected', 'a'), ('audio', 'a'), ('signal', 'n'), ('detected', 'v'), ('visual', 'a'), ('signal', 'n'), ('provide', 'n'), ('instructions', 'n'), ('selected', 'v'), ('device', 'n'), ('output', 'n'), ('notification', 'n'), ('related', 'v'), ('upcoming', 'a'), ('media', 'n'), ('programming', 'v'), ('non-transitory', 'a'), ('computer-readable', 'a'), ('medium', 'n'), ('claim', 'n'), ('wherein', None), ('selecting', 'v'), ('first', 'a'), ('device', 'n'), ('based', 'v'), ('detected', 'a'), ('audio', 'a'), ('signal', 'n'), ('includes', 'v'), ('recognizing', 'v'), ('voice', 'n'), ('non-transitory', 'a'), ('computer-readable', 'a'), ('medium', 'n'), ('claim', 'n'), ('wherein', 'n'), ('processor', 'n'), ('capable', 'a'), ('executing', 'v'), ('processor-executable', 'a'), ('program', 'n'), ('code', 'n'), ('determine', 'n'), ('distance', 'n'), ('recognized', 'v'), ('voice', 'n'), ('wherein', 'n'), ('selecting', 'v'), ('first', 'a'), ('device', 'n'), ('based', 'v'), ('determined', 'a'), ('distance', 'n'), ('non-transitory', 'a'), ('computer-readable', 'a'), ('medium', 'n'), ('claim', 'n'), ('wherein', None), ('selecting', 'v'), ('first', 'a'), ('device', 'n'), ('based', 'v'), ('detected', 'v'), ('visual', 'a'), ('signals', 'n'), ('includes', 'v'), ('recognizing', 'v'), ('face', 'n'), ('non-transitory', 'a'), ('computer-readable', 'a'), ('medium', 'n'), ('claim', 'n'), ('wherein', None), ('recognizing', 'v'), ('face', 'n'), ('includes', 'v'), ('face', 'a'), ('recognition', 'n'), ('technique', 'n'), ('camera', 'n'), ('comprising', 'v'), ('sensor', 'a'), ('array', 'n'), ('including', 'v'), ('plurality', 'n'), ('sensors', 'n'), ('infrared', 'v'), ('ir', 'a'), ('illuminator', 'n'), ('configured', 'v'), ('emit', 'r'), ('active', 'a'), ('ir', 'n'), ('light', 'a'), ('ir', 'a'), ('light', 'a'), ('sub-band', 'a'), ('plurality', 'n'), ('spectral', 'a'), ('illuminators', 'n'), ('spectral', 'a'), ('illuminator', 'n'), ('configured', 'v'), ('emit', 'r'), ('active', 'a'), ('spectral', 'a'), ('light', 'n'), ('different', 'a'), ('spectral', 'a'), ('light', 'n'), ('sub-band', 'n'), ('depth', 'n'), ('controller', 'n'), ('machine', 'n'), ('configured', 'v'), ('determine', 'a'), ('depth', 'n'), ('value', 'n'), ('plurality', 'n'), ('sensors', 'n'), ('based', 'v'), ('active', 'a'), ('ir', 'n'), ('light', 'a'), ('spectral', 'a'), ('controller', 'n'), ('machine', 'n'), ('configured', 'v'), ('plurality', 'n'), ('sensors', 'n'), ('determine', 'v'), ('spectral', 'a'), ('value', 'n'), ('spectral', 'a'), ('light', 'a'), ('sub-band', 'a'), ('plurality', 'n'), ('spectral', 'a'), ('illuminators', 'n'), ('output', 'n'), ('machine', 'n'), ('configured', 'v'), ('output', 'n'), ('test', 'n'), ('depth+multi-spectral', 'a'), ('image', 'n'), ('including', 'v'), ('plurality', 'n'), ('pixels', 'n'), ('pixel', 'v'), ('corresponding', 'v'), ('one', None), ('plurality', 'n'), ('sensors', 'n'), ('sensor', 'v'), ('array', 'a'), ('including', 'v'), ('least', 'a'), ('depth', 'a'), ('value', 'n'), ('spectral', 'a'), ('value', 'n'), ('spectral', 'a'), ('light', 'a'), ('sub-band', 'a'), ('plurality', 'n'), ('spectral', 'a'), ('illuminators', 'n'), ('face', 'v'), ('recognition', 'n'), ('machine', 'n'), ('previously', 'r'), ('trained', 'v'), ('set', 'v'), ('labeled', 'a'), ('training', 'n'), ('depth+multi-spectral', 'a'), ('images', 'n'), ('structure', 'n'), ('test', 'n'), ('depth+multi-spectral', 'a'), ('image', 'n'), ('face', 'n'), ('recognition', 'n'), ('machine', 'n'), ('configured', 'v'), ('output', 'n'), ('confidence', 'n'), ('value', 'n'), ('indicating', 'v'), ('likelihood', 'a'), ('test', 'n'), ('depth+multi-spectral', 'a'), ('image', 'n'), ('includes', 'v'), ('face', 'v'), ('camera', 'n'), ('claim', 'n'), ('wherein', None), ('spectral', 'a'), ('value', 'n'), ('calculated', 'v'), ('based', 'v'), ('depth', 'n'), ('value', 'n'), ('determined', 'v'), ('sensor', 'a'), ('corresponds', 'n'), ('pixel', 'a'), ('camera', 'n'), ('claim', 'n'), ('wherein', 'v'), ('face', 'n'), ('recognition', 'n'), ('machine', 'n'), ('configured', 'v'), ('use', None), ('convolutional', 'a'), ('neural', 'a'), ('network', 'n'), ('determine', 'n'), ('confidence', 'n'), ('value', 'n'), ('camera', 'n'), ('claim', 'n'), ('wherein', 'v'), ('face', 'n'), ('recognition', 'n'), ('machine', 'n'), ('includes', 'v'), ('plurality', 'n'), ('input', 'n'), ('nodes', 'n'), ('wherein', 'v'), ('input', 'a'), ('node', 'r'), ('configured', 'v'), ('receive', 'a'), ('pixel', 'n'), ('value', 'n'), ('array', 'n'), ('corresponding', 'v'), ('different', 'a'), ('pixel', 'n'), ('plurality', 'n'), ('pixels', 'n'), ('test', 'v'), ('depth+multi-spectral', 'a'), ('image', 'n'), ('wherein', 'n'), ('pixel', 'v'), ('value', 'n'), ('array', 'n'), ('includes', 'v'), ('depth', None), ('value', 'n'), ('plurality', 'n'), ('multi-spectral', 'a'), ('values', 'n'), ('pixel', 'v'), ('camera', 'n'), ('claim', 'n'), ('wherein', 'a'), ('plurality', 'n'), ('multi-spectral', 'a'), ('values', 'n'), ('pixel', 'v'), ('include', 'v'), ('three', None), ('spectral', 'a'), ('values', 'n'), ('camera', 'v'), ('claim', 'n'), ('wherein', 'n'), ('output', 'n'), ('machine', 'n'), ('configured', 'v'), ('output', 'n'), ('surface', 'n'), ('normal', 'a'), ('pixel', 'a'), ('test', 'n'), ('depth+multi-spectral', 'a'), ('image', 'n'), ('wherein', 'n'), ('pixel', 'v'), ('value', 'n'), ('array', 'n'), ('includes', 'v'), ('surface', 'n'), ('normal', 'a'), ('camera', 'n'), ('claim', 'n'), ('wherein', 'n'), ('output', 'n'), ('machine', 'n'), ('configured', 'v'), ('output', 'n'), ('curvature', 'n'), ('pixel', 'a'), ('test', 'n'), ('depth+multi-spectral', 'a'), ('image', 'n'), ('wherein', 'n'), ('pixel', 'v'), ('value', 'n'), ('array', 'n'), ('includes', 'v'), ('curvature', 'n'), ('camera', 'n'), ('claim', 'n'), ('wherein', 'v'), ('face', 'n'), ('recognition', 'n'), ('machine', 'n'), ('configured', 'v'), ('use', 'n'), ('plurality', 'n'), ('models', 'n'), ('determine', 'v'), ('confidence', 'n'), ('value', 'n'), ('wherein', 'v'), ('plurality', 'n'), ('models', 'n'), ('includes', 'v'), ('plurality', 'n'), ('channel-specific', 'a'), ('models', 'n'), ('wherein', None), ('channel-specific', 'a'), ('model', 'n'), ('configured', 'v'), ('process', 'a'), ('different', 'a'), ('pixel', 'n'), ('parameter', 'n'), ('plurality', 'n'), ('pixels', 'n'), ('test', 'v'), ('depth+multi-spectral', 'a'), ('image', 'n'), ('wherein', 'v'), ('channel-specific', 'a'), ('model', 'n'), ('includes', 'v'), ('plurality', 'n'), ('input', 'n'), ('nodes', 'n'), ('wherein', 'v'), ('channel-specific', 'a'), ('model', 'n'), ('input', 'n'), ('node', 'r'), ('configured', 'v'), ('receive', 'a'), ('pixel', 'n'), ('parameter', 'n'), ('value', 'n'), ('different', 'a'), ('pixel', 'n'), ('plurality', 'n'), ('pixels', 'n'), ('test', 'v'), ('depth+multi-spectral', 'a'), ('image', 'n'), ('camera', 'n'), ('claim', 'n'), ('wherein', 'v'), ('face', 'n'), ('recognition', 'n'), ('machine', 'n'), ('configured', 'v'), ('use', 'r'), ('statistical', 'a'), ('model', 'n'), ('determine', 'n'), ('confidence', 'n'), ('value', 'n'), ('camera', 'n'), ('claim', 'n'), ('wherein', 'v'), ('statistical', 'a'), ('model', 'n'), ('includes', 'v'), ('nearest', 'a'), ('neighbor', 'n'), ('algorithm', 'n'), ('camera', 'n'), ('claim', 'n'), ('wherein', 'v'), ('statistical', 'a'), ('model', 'n'), ('includes', 'v'), ('support', 'n'), ('vector', 'n'), ('machine', 'n'), ('camera', 'n'), ('claim', 'n'), ('wherein', 'v'), ('face', 'n'), ('recognition', 'n'), ('machine', 'n'), ('configured', 'v'), ('output', 'n'), ('location', 'n'), ('test', 'n'), ('depth+multi-spectral', 'a'), ('image', 'n'), ('bounding', 'v'), ('box', 'n'), ('around', None), ('recognized', 'v'), ('face', 'n'), ('camera', 'n'), ('claim', 'n'), ('wherein', 'v'), ('face', 'n'), ('recognition', 'n'), ('machine', 'n'), ('configured', 'v'), ('output', 'n'), ('location', 'n'), ('test', 'n'), ('depth+multi-spectral', 'a'), ('image', 'n'), ('identified', 'v'), ('two-dimensional', 'a'), ('facial', 'a'), ('feature', 'n'), ('recognized', 'v'), ('face', 'n'), ('camera', 'n'), ('claim', 'n'), ('wherein', 'v'), ('face', 'n'), ('recognition', 'n'), ('machine', 'n'), ('configured', 'v'), ('output', 'n'), ('location', 'n'), ('test', 'n'), ('depth+multi-spectral', 'a'), ('image', 'n'), ('identified', 'v'), ('three-dimensional', 'a'), ('facial', 'a'), ('feature', 'n'), ('recognized', 'v'), ('face', 'n'), ('camera', 'n'), ('claim', 'n'), ('wherein', 'v'), ('face', 'n'), ('recognition', 'n'), ('machine', 'n'), ('configured', 'v'), ('output', 'n'), ('location', 'n'), ('test', 'n'), ('depth+multi-spectral', 'a'), ('image', 'n'), ('identified', 'v'), ('spectral', 'a'), ('feature', 'n'), ('recognized', 'v'), ('face', 'n'), ('camera', 'n'), ('claim', 'n'), ('wherein', 'v'), ('face', 'n'), ('recognition', 'n'), ('machine', 'n'), ('configured', 'v'), ('output', 'n'), ('pixel', 'a'), ('test', 'n'), ('depth+multi-spectral', 'a'), ('image', 'n'), ('confidence', 'n'), ('value', 'n'), ('indicating', 'v'), ('likelihood', 'n'), ('pixel', 'n'), ('included', 'v'), ('face', 'n'), ('camera', 'n'), ('claim', 'n'), ('wherein', 'v'), ('face', 'n'), ('recognition', 'n'), ('machine', 'n'), ('configured', 'v'), ('output', 'n'), ('identity', 'n'), ('face', 'n'), ('recognized', 'v'), ('test', None), ('depth+multi-spectral', 'a'), ('image', 'n'), ('camera', 'n'), ('claim', 'n'), ('wherein', 'v'), ('plurality', 'n'), ('sensors', 'n'), ('sensor', 'v'), ('array', 'a'), ('differential', 'a'), ('sensors', 'n'), ('wherein', 'v'), ('spectral', 'a'), ('value', 'n'), ('determined', 'v'), ('based', 'v'), ('depth', 'n'), ('value', 'n'), ('differential', 'a'), ('measurement', 'a'), ('differential', 'n'), ('sensor', 'n'), ('camera', 'n'), ('comprising', 'v'), ('sensor', 'a'), ('array', 'n'), ('including', 'v'), ('plurality', 'n'), ('sensors', 'n'), ('infrared', 'v'), ('ir', 'a'), ('illuminator', 'n'), ('configured', 'v'), ('emit', 'r'), ('active', 'a'), ('ir', 'n'), ('light', 'a'), ('ir', 'a'), ('light', 'a'), ('sub-band', 'a'), ('plurality', 'n'), ('spectral', 'a'), ('illuminators', 'n'), ('spectral', 'a'), ('illuminator', 'n'), ('configured', 'v'), ('emit', 'r'), ('active', 'a'), ('spectral', 'a'), ('light', 'n'), ('different', 'a'), ('spectral', 'a'), ('light', 'n'), ('sub-band', 'n'), ('depth', 'n'), ('controller', 'n'), ('machine', 'n'), ('configured', 'v'), ('determine', 'a'), ('depth', 'n'), ('value', 'n'), ('plurality', 'n'), ('sensors', 'n'), ('based', 'v'), ('active', 'a'), ('ir', 'n'), ('light', 'a'), ('spectral', 'a'), ('controller', 'n'), ('machine', 'n'), ('configured', 'v'), ('plurality', 'n'), ('sensors', 'n'), ('determine', 'v'), ('spectral', 'a'), ('value', 'n'), ('spectral', 'a'), ('light', 'a'), ('sub-band', 'a'), ('plurality', 'n'), ('spectral', 'a'), ('illuminators', 'n'), ('wherein', 'v'), ('spectral', 'a'), ('value', 'n'), ('calculated', 'v'), ('based', 'v'), ('depth', 'n'), ('value', 'n'), ('determined', 'v'), ('sensor', 'a'), ('corresponds', 'n'), ('pixel', 'a'), ('output', 'n'), ('machine', 'n'), ('configured', 'v'), ('output', 'n'), ('test', 'n'), ('depth+multi-spectral', 'a'), ('image', 'n'), ('including', 'v'), ('plurality', 'n'), ('pixels', 'n'), ('pixel', 'v'), ('corresponding', 'v'), ('one', None), ('plurality', 'n'), ('sensors', 'n'), ('sensor', 'v'), ('array', 'a'), ('including', 'v'), ('least', 'a'), ('depth', 'a'), ('value', 'n'), ('spectral', 'a'), ('value', 'n'), ('spectral', 'a'), ('light', 'a'), ('sub-band', 'a'), ('plurality', 'n'), ('spectral', 'a'), ('illuminators', 'n'), ('face', 'v'), ('recognition', 'n'), ('machine', 'n'), ('including', 'v'), ('convolutional', 'a'), ('neural', 'a'), ('network', 'n'), ('previously', 'r'), ('trained', 'v'), ('set', 'v'), ('labeled', 'a'), ('training', 'n'), ('depth+multi-spectral', 'a'), ('images', 'n'), ('structure', 'n'), ('test', 'n'), ('depth+multi-spectral', 'a'), ('image', 'n'), ('face', 'n'), ('recognition', 'n'), ('machine', 'n'), ('configured', 'v'), ('output', 'n'), ('confidence', 'n'), ('value', 'n'), ('indicating', 'v'), ('likelihood', 'a'), ('test', 'n'), ('depth+multi-spectral', 'a'), ('image', 'n'), ('includes', 'v'), ('face', 'v'), ('image', 'n'), ('processing', 'n'), ('method', 'n'), ('comprising', 'v'), ('acquiring', 'v'), ('photo', 'n'), ('album', 'n'), ('obtained', 'v'), ('face', 'n'), ('clustering', 'v'), ('collecting', 'v'), ('face', 'n'), ('information', 'n'), ('respective', 'a'), ('images', 'n'), ('photo', 'v'), ('album', None), ('acquiring', 'v'), ('face', 'n'), ('parameter', 'n'), ('image', 'n'), ('according', 'v'), ('face', 'n'), ('information', 'n'), ('selecting', 'v'), ('cover', 'n'), ('image', 'n'), ('according', 'v'), ('face', 'n'), ('parameter', 'n'), ('image', 'n'), ('taking', 'v'), ('face-region', 'a'), ('image', 'n'), ('cover', 'n'), ('image', 'n'), ('setting', 'v'), ('face-region', 'a'), ('image', 'n'), ('cover', 'n'), ('photo', 'n'), ('album', 'a'), ('wherein', 'n'), ('selecting', 'v'), ('cover', 'n'), ('image', 'n'), ('according', 'v'), ('face', 'n'), ('parameter', 'n'), ('image', 'n'), ('comprises', 'v'), ('performing', 'v'), ('calculation', 'n'), ('face', 'n'), ('parameter', 'n'), ('image', 'n'), ('preset', 'v'), ('way', 'n'), ('obtain', 'v'), ('cover', 'n'), ('score', 'n'), ('image', 'n'), ('selecting', 'v'), ('image', 'n'), ('highest', 'a'), ('cover', 'n'), ('score', 'n'), ('cover', 'a'), ('image', 'n'), ('wherein', 'v'), ('selecting', 'v'), ('image', 'n'), ('highest', 'a'), ('cover', 'n'), ('score', 'n'), ('cover', 'a'), ('image', 'n'), ('comprises', 'v'), ('acquiring', 'v'), ('source', 'n'), ('image', 'n'), ('selecting', 'v'), ('image', 'n'), ('highest', 'a'), ('cover', 'n'), ('score', 'n'), ('images', 'n'), ('coming', 'v'), ('preset', 'n'), ('source', 'n'), ('cover', 'n'), ('image', 'n'), ('method', 'a'), ('according', 'v'), ('claim', 'n'), ('wherein', 'n'), ('selecting', 'v'), ('image', 'n'), ('highest', 'a'), ('cover', 'n'), ('score', 'n'), ('cover', 'a'), ('image', 'n'), ('comprises', 'v'), ('acquiring', 'v'), ('number', 'n'), ('faces', 'v'), ('contained', 'v'), ('image', 'n'), ('determining', 'v'), ('single-person', 'a'), ('images', 'n'), ('according', 'v'), ('number', 'n'), ('faces', 'v'), ('selecting', 'v'), ('single-person', 'a'), ('image', 'n'), ('highest', 'a'), ('cover', 'n'), ('score', 'n'), ('cover', 'a'), ('image', 'n'), ('method', 'n'), ('according', 'v'), ('claim', 'n'), ('wherein', 'n'), ('selecting', 'v'), ('image', 'n'), ('highest', 'a'), ('cover', 'n'), ('score', 'n'), ('cover', 'a'), ('image', 'n'), ('comprises', 'v'), ('single-person', 'a'), ('image', 'n'), ('photo', 'n'), ('album', None), ('determining', 'v'), ('images', 'n'), ('including', 'v'), ('two', None), ('faces', 'v'), ('photo', 'n'), ('album', 'n'), ('selecting', 'v'), ('image', 'n'), ('highest', 'a'), ('cover', 'n'), ('score', 'n'), ('images', 'n'), ('including', 'v'), ('two', None), ('faces', 'v'), ('cover', 'r'), ('image', 'n'), ('method', 'a'), ('according', 'v'), ('claim', 'n'), ('wherein', 'n'), ('face', 'n'), ('information', 'n'), ('comprises', 'v'), ('face', 'n'), ('feature', 'n'), ('points', 'n'), ('face', 'v'), ('parameter', 'n'), ('comprises', 'n'), ('face', 'v'), ('turning', 'v'), ('angle', 'r'), ('acquiring', 'v'), ('face', 'n'), ('parameter', 'n'), ('image', 'n'), ('according', 'v'), ('face', 'n'), ('information', 'n'), ('comprises', 'v'), ('acquiring', 'v'), ('coordinate', 'n'), ('values', 'n'), ('face', 'v'), ('feature', 'n'), ('points', 'n'), ('determining', 'v'), ('distances', 'n'), ('angles', 'n'), ('face', 'v'), ('feature', 'n'), ('points', 'n'), ('determining', 'v'), ('face', 'n'), ('turning', 'v'), ('angle', 'r'), ('according', 'v'), ('distances', 'n'), ('angles', 'n'), ('method', 'v'), ('according', 'v'), ('claim', 'n'), ('wherein', 'n'), ('face', 'n'), ('parameter', 'n'), ('comprises', 'v'), ('face', 'v'), ('ratio', 'n'), ('acquiring', 'v'), ('face', 'n'), ('parameter', 'n'), ('image', 'n'), ('according', 'v'), ('face', 'n'), ('information', 'n'), ('comprises', 'v'), ('determining', 'v'), ('face', 'n'), ('region', 'n'), ('image', 'n'), ('according', 'v'), ('face', 'n'), ('information', 'n'), ('calculating', 'v'), ('ratio', 'n'), ('area', 'n'), ('face', 'n'), ('region', 'n'), ('area', 'n'), ('image', 'n'), ('obtain', 'v'), ('face', 'n'), ('ratio', 'n'), ('method', 'n'), ('according', 'v'), ('claim', 'n'), ('wherein', 'n'), ('calculating', 'v'), ('face', 'n'), ('ratio', 'n'), ('comprises', 'v'), ('one', None), ('face', 'n'), ('image', 'n'), ('subtracting', 'v'), ('area', 'n'), ('occupied', 'v'), ('faces', 'v'), ('face', 'n'), ('corresponding', 'v'), ('photo', 'n'), ('album', 'n'), ('face', 'n'), ('region', 'n'), ('obtain', 'v'), ('remaining', 'v'), ('area', 'n'), ('calculating', 'v'), ('ratio', 'n'), ('remaining', 'v'), ('area', 'n'), ('area', 'n'), ('image', 'n'), ('obtain', 'v'), ('face', 'n'), ('ratio', 'n'), ('method', 'n'), ('according', 'v'), ('claim', 'n'), ('wherein', 'n'), ('collecting', 'v'), ('face', 'n'), ('information', 'n'), ('respective', 'a'), ('images', 'n'), ('photo', 'v'), ('album', 'a'), ('comprises', 'n'), ('acquiring', 'v'), ('image', 'n'), ('identifications', 'n'), ('images', 'v'), ('photo', 'n'), ('album', 'n'), ('extracting', 'v'), ('face', 'n'), ('information', 'n'), ('corresponding', 'v'), ('image', 'n'), ('identifications', 'n'), ('face', 'v'), ('database', 'a'), ('face', 'n'), ('database', 'n'), ('stored', 'v'), ('face', 'n'), ('recognition', 'n'), ('results', 'n'), ('images', 'n'), ('face', 'v'), ('recognition', 'n'), ('results', 'n'), ('including', 'v'), ('face', 'n'), ('information', 'n'), ('image', 'n'), ('processing', 'n'), ('apparatus', 'n'), ('comprising', 'v'), ('processor', 'a'), ('memory', 'n'), ('configured', 'v'), ('store', 'n'), ('instructions', 'n'), ('executable', 'a'), ('processor', 'n'), ('wherein', 'n'), ('processor', 'n'), ('configured', 'v'), ('run', 'v'), ('program', 'n'), ('corresponding', 'n'), ('instructions', 'n'), ('reading', 'v'), ('instructions', 'n'), ('stored', 'v'), ('memory', 'n'), ('perform', 'n'), ('acquiring', 'v'), ('photo', 'n'), ('album', 'n'), ('obtained', 'v'), ('face', 'n'), ('clustering', 'v'), ('collecting', 'v'), ('face', 'n'), ('information', 'n'), ('image', 'n'), ('photo', 'n'), ('album', None), ('acquiring', 'v'), ('face', 'n'), ('parameter', 'n'), ('image', 'n'), ('according', 'v'), ('face', 'n'), ('information', 'n'), ('selecting', 'v'), ('cover', 'n'), ('image', 'n'), ('according', 'v'), ('face', 'n'), ('parameter', 'n'), ('image', 'n'), ('taking', 'v'), ('face-region', 'a'), ('image', 'n'), ('cover', 'n'), ('image', 'n'), ('setting', 'v'), ('face-region', 'a'), ('image', 'n'), ('cover', 'n'), ('photo', 'n'), ('album', 'a'), ('wherein', 'n'), ('processor', 'n'), ('configured', 'v'), ('perform', 'a'), ('calculation', 'n'), ('face', 'n'), ('parameter', 'n'), ('image', 'n'), ('preset', 'v'), ('way', 'n'), ('obtain', 'v'), ('cover', 'n'), ('score', 'n'), ('image', 'n'), ('select', 'a'), ('image', 'n'), ('highest', 'a'), ('cover', 'n'), ('score', 'n'), ('cover', 'a'), ('image', 'n'), ('wherein', 'n'), ('processor', 'n'), ('configured', 'v'), ('acquire', 'v'), ('source', 'n'), ('image', 'n'), ('select', 'a'), ('image', 'n'), ('highest', 'a'), ('cover', 'n'), ('score', 'n'), ('images', 'n'), ('coming', 'v'), ('preset', 'n'), ('source', 'n'), ('cover', 'n'), ('image', 'n'), ('apparatus', 'a'), ('according', 'v'), ('claim', 'n'), ('wherein', 'n'), ('processor', 'n'), ('configured', 'v'), ('acquire', 'v'), ('number', 'n'), ('faces', 'v'), ('contained', 'v'), ('image', 'n'), ('determine', 'a'), ('single-person', 'a'), ('images', 'n'), ('according', 'v'), ('number', 'n'), ('faces', 'v'), ('select', 'a'), ('single-person', 'a'), ('image', 'n'), ('highest', 'a'), ('cover', 'n'), ('score', 'n'), ('cover', 'a'), ('image', 'n'), ('apparatus', 'a'), ('according', 'v'), ('claim', 'n'), ('wherein', 'n'), ('processor', 'n'), ('configured', 'v'), ('single-person', 'a'), ('image', 'n'), ('photo', 'n'), ('album', 'a'), ('determine', 'n'), ('images', 'n'), ('including', 'v'), ('two', None), ('faces', 'v'), ('photo', 'n'), ('album', 'n'), ('select', 'a'), ('image', 'n'), ('highest', 'a'), ('cover', 'n'), ('score', 'n'), ('images', 'n'), ('including', 'v'), ('two', None), ('faces', 'v'), ('cover', 'r'), ('image', 'n'), ('apparatus', 'a'), ('according', 'v'), ('claim', 'n'), ('wherein', 'n'), ('face', 'n'), ('information', 'n'), ('comprises', 'v'), ('face', 'n'), ('feature', 'n'), ('points', 'n'), ('face', 'v'), ('parameter', 'n'), ('comprises', 'n'), ('face', 'v'), ('turning', 'v'), ('angle', 'n'), ('processor', 'n'), ('configured', 'v'), ('acquire', 'v'), ('coordinate', 'n'), ('values', 'n'), ('face', 'v'), ('feature', 'n'), ('points', 'n'), ('determine', 'a'), ('distances', 'n'), ('angles', 'n'), ('face', 'v'), ('feature', 'n'), ('points', 'n'), ('determine', 'a'), ('face', 'n'), ('turning', 'v'), ('angle', 'r'), ('according', 'v'), ('distances', 'n'), ('angles', 'n'), ('apparatus', 'v'), ('according', 'v'), ('claim', 'n'), ('wherein', 'n'), ('face', 'n'), ('parameter', 'n'), ('comprises', 'v'), ('face', 'v'), ('ratio', 'n'), ('processor', 'n'), ('configured', 'v'), ('determine', 'a'), ('face', 'n'), ('region', 'n'), ('image', 'n'), ('according', 'v'), ('face', 'n'), ('information', 'n'), ('calculate', 'n'), ('ratio', 'n'), ('area', 'n'), ('face', 'n'), ('region', 'n'), ('area', 'n'), ('image', 'n'), ('obtain', 'v'), ('face', 'n'), ('ratio', 'n'), ('apparatus', None), ('according', 'v'), ('claim', 'n'), ('wherein', 'n'), ('processor', 'n'), ('configured', 'v'), ('one', None), ('face', 'n'), ('image', 'n'), ('subtract', 'a'), ('area', 'n'), ('occupied', 'v'), ('faces', 'v'), ('face', 'n'), ('corresponding', 'v'), ('photo', 'n'), ('album', 'n'), ('face', 'n'), ('region', 'n'), ('obtain', 'v'), ('remaining', 'v'), ('area', 'n'), ('calculate', 'n'), ('ratio', 'n'), ('remaining', 'v'), ('area', 'n'), ('area', 'n'), ('image', 'n'), ('obtain', 'v'), ('face', 'n'), ('ratio', 'n'), ('apparatus', None), ('according', 'v'), ('claim', 'n'), ('wherein', 'n'), ('processor', 'n'), ('configured', 'v'), ('acquire', 'v'), ('image', 'n'), ('identifications', 'n'), ('images', 'v'), ('photo', 'n'), ('album', 'n'), ('extract', 'a'), ('face', 'n'), ('information', 'n'), ('corresponding', 'v'), ('image', 'n'), ('identifications', 'n'), ('face', 'v'), ('database', 'a'), ('face', 'n'), ('database', 'n'), ('stored', 'v'), ('face', 'n'), ('recognition', 'n'), ('results', 'n'), ('images', 'n'), ('face', 'v'), ('recognition', 'n'), ('results', 'n'), ('including', 'v'), ('face', 'n'), ('information', 'n'), ('electronic', 'a'), ('device', 'n'), ('comprising', 'v'), ('processor', 'a'), ('memory', 'n'), ('display', 'n'), ('screen', 'n'), ('input', 'n'), ('device', 'n'), ('connected', 'v'), ('via', None), ('system', 'n'), ('bus', 'a'), ('wherein', 'a'), ('memory', 'n'), ('stored', 'v'), ('computer', 'n'), ('programs', 'n'), ('executed', 'v'), ('processor', 'n'), ('cause', 'n'), ('processor', 'n'), ('implement', 'a'), ('image', 'n'), ('processing', 'n'), ('method', 'a'), ('image', 'n'), ('processing', 'n'), ('method', 'n'), ('comprising', 'v'), ('acquiring', 'v'), ('photo', 'n'), ('album', 'n'), ('obtained', 'v'), ('face', 'n'), ('clustering', 'v'), ('collecting', 'v'), ('face', 'n'), ('information', 'n'), ('respective', 'a'), ('images', 'n'), ('photo', 'v'), ('album', None), ('acquiring', 'v'), ('face', 'n'), ('parameter', 'n'), ('image', 'n'), ('according', 'v'), ('face', 'n'), ('information', 'n'), ('selecting', 'v'), ('cover', 'n'), ('image', 'n'), ('according', 'v'), ('face', 'n'), ('parameter', 'n'), ('image', 'n'), ('taking', 'v'), ('face-region', 'a'), ('image', 'n'), ('cover', 'n'), ('image', 'n'), ('setting', 'v'), ('face-region', 'a'), ('image', 'n'), ('cover', 'n'), ('photo', 'n'), ('album', 'a'), ('wherein', 'n'), ('selecting', 'v'), ('cover', 'n'), ('image', 'n'), ('according', 'v'), ('face', 'n'), ('parameter', 'n'), ('image', 'n'), ('comprises', 'v'), ('performing', 'v'), ('calculation', 'n'), ('face', 'n'), ('parameter', 'n'), ('image', 'n'), ('preset', 'v'), ('way', 'n'), ('obtain', 'v'), ('cover', 'n'), ('score', 'n'), ('image', 'n'), ('selecting', 'v'), ('image', 'n'), ('highest', 'a'), ('cover', 'n'), ('score', 'n'), ('cover', 'a'), ('image', 'n'), ('wherein', 'v'), ('selecting', 'v'), ('image', 'n'), ('highest', 'a'), ('cover', 'n'), ('score', 'n'), ('cover', 'a'), ('image', 'n'), ('comprises', 'v'), ('acquiring', 'v'), ('source', 'n'), ('image', 'n'), ('selecting', 'v'), ('image', 'n'), ('highest', 'a'), ('cover', 'n'), ('score', 'n'), ('images', 'n'), ('coming', 'v'), ('preset', 'n'), ('source', 'n'), ('cover', 'n'), ('image', 'n'), ('electronic', 'a'), ('device', 'n'), ('according', 'v'), ('claim', 'n'), ('wherein', 'n'), ('electronic', 'a'), ('device', 'n'), ('comprises', 'n'), ('least', 'v'), ('one', None), ('mobile', 'a'), ('phone', 'n'), ('tablet', 'n'), ('computer', 'n'), ('personal', 'a'), ('digital', 'n'), ('assistant', 'n'), ('wearable', 'a'), ('device', 'n'), ('computer-implemented', 'a'), ('method', 'n'), ('comprising', 'v'), ('receiving', 'v'), ('computing', 'v'), ('device', 'n'), ('meeting', 'n'), ('invitation', 'n'), ('identifying', 'v'), ('location', 'n'), ('least', 'a'), ('one', None), ('invitee', 'n'), ('meeting', 'n'), ('invitation', 'n'), ('configured', 'v'), ('provide', None), ('least', 'a'), ('one', None), ('invitee', 'n'), ('physical', 'a'), ('access', 'n'), ('location', 'n'), ('wherein', 'n'), ('meeting', 'n'), ('invitation', 'n'), ('causes', 'v'), ('system', 'n'), ('control', 'n'), ('pathway', 'r'), ('allowing', 'v'), ('physical', 'a'), ('access', 'n'), ('location', 'n'), ('providing', 'v'), ('based', 'v'), ('meeting', 'v'), ('invitation', 'n'), ('least', 'a'), ('one', None), ('invitee', 'n'), ('physical', 'a'), ('access', 'n'), ('location', 'n'), ('controlling', 'v'), ('pathway', 'r'), ('allowing', 'v'), ('least', 'a'), ('one', None), ('invitee', 'n'), ('physically', 'r'), ('access', 'n'), ('location', 'n'), ('pathway', 'n'), ('response', 'n'), ('positioning', 'v'), ('data', 'n'), ('indicating', 'v'), ('least', 'a'), ('one', None), ('invitee', 'n'), ('predetermined', 'v'), ('location', 'n'), ('near', None), ('location', 'n'), ('wherein', 'n'), ('positioning', 'v'), ('data', 'n'), ('based', 'v'), ('part', 'n'), ('face', 'n'), ('recognition', 'n'), ('camera', 'n'), ('system', 'n'), ('identifying', 'v'), ('least', 'a'), ('one', None), ('invitee', 'n'), ('receiving', 'v'), ('positioning', 'v'), ('data', 'n'), ('face', 'n'), ('recognition', 'n'), ('camera', 'n'), ('system', 'n'), ('identifying', 'v'), ('least', 'a'), ('one', None), ('invitee', 'n'), ('wherein', 'n'), ('positioning', 'v'), ('data', 'n'), ('indicates', 'v'), ('pattern', 'a'), ('movement', 'n'), ('least', 'a'), ('one', None), ('invitee', 'n'), ('determining', 'v'), ('pattern', 'a'), ('movement', 'n'), ('indicates', 'v'), ('least', 'a'), ('one', None), ('invitee', 'n'), ('exited', 'v'), ('location', 'n'), ('revoking', 'v'), ('physical', 'a'), ('access', 'n'), ('location', 'n'), ('identified', 'v'), ('meeting', 'v'), ('invitation', 'n'), ('controlling', 'v'), ('pathway', 'r'), ('restrict', 'v'), ('least', 'a'), ('one', None), ('invitee', 'n'), ('identified', 'v'), ('meeting', 'v'), ('invitation', 'n'), ('physical', 'a'), ('access', 'n'), ('location', 'n'), ('pathway', 'n'), ('response', 'n'), ('determining', 'v'), ('pattern', 'a'), ('movement', 'n'), ('indicates', 'v'), ('least', 'a'), ('one', None), ('invitee', 'n'), ('exited', 'v'), ('location', 'n'), ('computer-implemented', 'a'), ('method', 'n'), ('claim', 'n'), ('wherein', None), ('determining', 'v'), ('least', 'a'), ('one', None), ('invitee', 'n'), ('exited', 'v'), ('location', 'n'), ('comprises', 'v'), ('determining', 'v'), ('least', 'a'), ('one', None), ('invitee', 'n'), ('passed', 'v'), ('egress', 'r'), ('associated', 'v'), ('location', 'n'), ('predetermined', 'v'), ('direction', 'n'), ('computer-implemented', 'a'), ('method', 'n'), ('claim', 'n'), ('wherein', None), ('determining', 'v'), ('least', 'a'), ('one', None), ('invitee', 'n'), ('exited', 'v'), ('location', 'n'), ('comprises', 'v'), ('determining', 'v'), ('least', 'a'), ('one', None), ('invitee', 'n'), ('moved', 'v'), ('area', 'n'), ('predetermined', 'v'), ('direction', 'n'), ('computer-implemented', 'a'), ('method', 'n'), ('claim', 'n'), ('wherein', None), ('positioning', 'v'), ('data', 'n'), ('indicates', 'v'), ('second', 'a'), ('pattern', 'a'), ('movement', 'n'), ('least', 'a'), ('one', None), ('invitee', 'n'), ('wherein', 'n'), ('access', 'n'), ('secured', 'v'), ('data', 'n'), ('associated', 'v'), ('location', 'n'), ('provided', 'v'), ('response', 'n'), ('detecting', 'v'), ('second', 'a'), ('pattern', 'a'), ('movement', 'n'), ('computer-implemented', 'a'), ('method', 'n'), ('claim', 'n'), ('comprising', 'v'), ('collating', 'v'), ('secured', 'v'), ('data', 'n'), ('public', 'a'), ('data', 'n'), ('generate', 'v'), ('resource', 'n'), ('data', 'n'), ('communicating', 'v'), ('resource', 'n'), ('data', 'n'), ('client', 'n'), ('computing', 'v'), ('device', 'n'), ('associated', 'v'), ('least', 'a'), ('one', None), ('invitee', 'n'), ('access', 'n'), ('location', 'n'), ('provided', 'v'), ('computer-implemented', 'a'), ('method', 'n'), ('claim', 'n'), ('wherein', None), ('positioning', 'v'), ('data', 'n'), ('indicates', 'v'), ('least', 'a'), ('one', None), ('invitee', 'n'), ('predetermined', 'v'), ('location', 'n'), ('least', 'a'), ('one', None), ('invitee', 'n'), ('passes', 'n'), ('predetermined', 'v'), ('location', 'n'), ('computer-implemented', 'a'), ('method', 'n'), ('claim', 'n'), ('wherein', None), ('positioning', 'v'), ('data', 'n'), ('indicates', 'v'), ('least', 'a'), ('one', None), ('invitee', 'n'), ('predetermined', 'v'), ('location', 'n'), ('least', 'a'), ('one', None), ('invitee', 'n'), ('passes', 'n'), ('predetermined', 'v'), ('location', 'n'), ('near', None), ('location', 'n'), ('predetermined', 'v'), ('direction', 'n'), ('system', 'n'), ('comprising', 'v'), ('processor', 'a'), ('memory', 'n'), ('communication', 'n'), ('processor', 'n'), ('memory', 'n'), ('computer-readable', 'a'), ('instructions', 'n'), ('stored', 'v'), ('thereupon', 'r'), ('executed', 'v'), ('processor', 'n'), ('cause', 'n'), ('processor', 'n'), ('receive', 'v'), ('meeting', 'n'), ('invitation', 'n'), ('indicating', 'v'), ('location', 'n'), ('identity', 'n'), ('meeting', 'n'), ('invitation', 'n'), ('configured', 'v'), ('provide', None), ('least', 'a'), ('one', None), ('invitee', 'n'), ('physical', 'a'), ('access', 'n'), ('location', 'n'), ('wherein', 'n'), ('meeting', 'n'), ('invitation', 'n'), ('causes', 'v'), ('system', 'n'), ('control', 'n'), ('pathway', 'r'), ('allowing', 'v'), ('physical', 'a'), ('access', 'n'), ('location', 'n'), ('provide', None), ('least', 'a'), ('one', None), ('invitee', 'n'), ('associated', 'v'), ('identity', 'n'), ('access', 'n'), ('location', 'n'), ('controlling', 'v'), ('pathway', 'r'), ('allowing', 'v'), ('least', 'a'), ('one', None), ('invitee', 'n'), ('physically', 'r'), ('access', 'n'), ('location', 'n'), ('pathway', 'n'), ('response', 'n'), ('positioning', 'v'), ('data', 'n'), ('indicating', 'v'), ('least', 'a'), ('one', None), ('invitee', 'n'), ('predetermined', 'v'), ('location', 'n'), ('near', None), ('location', 'n'), ('wherein', 'n'), ('positioning', 'v'), ('data', 'n'), ('based', 'v'), ('part', 'n'), ('face', 'n'), ('recognition', 'n'), ('camera', 'n'), ('system', 'n'), ('identifying', 'v'), ('least', 'a'), ('one', None), ('invitee', 'n'), ('receive', 'v'), ('positioning', 'v'), ('data', 'n'), ('face', 'n'), ('recognition', 'n'), ('camera', 'n'), ('system', 'n'), ('identifying', 'v'), ('least', 'a'), ('one', None), ('invitee', 'n'), ('wherein', 'n'), ('positioning', 'v'), ('data', 'n'), ('indicates', 'v'), ('pattern', 'a'), ('movement', 'n'), ('least', 'a'), ('one', None), ('invitee', 'n'), ('determine', 'n'), ('pattern', 'a'), ('movement', 'n'), ('indicates', 'v'), ('least', 'a'), ('one', None), ('invitee', 'n'), ('exited', 'v'), ('location', 'n'), ('revoke', 'v'), ('physical', 'a'), ('access', 'n'), ('location', 'n'), ('identified', 'v'), ('meeting', 'v'), ('invitation', 'n'), ('controlling', 'v'), ('pathway', 'r'), ('restrict', 'v'), ('least', 'a'), ('one', None), ('invitee', 'n'), ('identified', 'v'), ('meeting', 'v'), ('invitation', 'n'), ('physical', 'a'), ('access', 'n'), ('location', 'n'), ('pathway', 'n'), ('response', 'n'), ('determining', 'v'), ('pattern', 'a'), ('movement', 'n'), ('indicates', 'v'), ('least', 'a'), ('one', None), ('invitee', 'n'), ('exited', 'v'), ('location', 'n'), ('system', 'n'), ('claim', 'n'), ('wherein', None), ('determining', 'v'), ('least', 'a'), ('one', None), ('invitee', 'n'), ('exited', 'v'), ('location', 'n'), ('comprises', 'v'), ('determining', 'v'), ('least', 'a'), ('one', None), ('invitee', 'n'), ('passed', 'v'), ('egress', 'r'), ('associated', 'v'), ('location', 'n'), ('system', 'n'), ('claim', 'n'), ('wherein', None), ('determining', 'v'), ('least', 'a'), ('one', None), ('invitee', 'n'), ('exited', 'v'), ('location', 'n'), ('comprises', 'v'), ('determining', 'v'), ('least', 'a'), ('one', None), ('invitee', 'n'), ('moved', 'v'), ('area', 'n'), ('predetermined', 'v'), ('direction', 'n'), ('system', 'n'), ('claim', 'n'), ('wherein', None), ('positioning', 'v'), ('data', 'n'), ('indicates', 'v'), ('second', 'a'), ('pattern', 'a'), ('movement', 'n'), ('least', 'a'), ('one', None), ('invitee', 'n'), ('wherein', 'n'), ('access', 'n'), ('secured', 'v'), ('data', 'n'), ('associated', 'v'), ('location', 'n'), ('provided', 'v'), ('response', 'n'), ('detecting', 'v'), ('second', 'a'), ('pattern', 'a'), ('movement', 'n'), ('system', 'n'), ('claim', 'n'), ('wherein', 'n'), ('instructions', 'n'), ('cause', 'v'), ('processor', 'n'), ('collate', 'n'), ('secured', 'v'), ('data', 'n'), ('public', 'a'), ('data', 'n'), ('generate', 'v'), ('resource', 'n'), ('data', 'n'), ('communicate', 'v'), ('resource', 'n'), ('data', 'n'), ('client', 'n'), ('computing', 'v'), ('device', 'n'), ('associated', 'v'), ('least', 'a'), ('one', None), ('invitee', 'n'), ('access', 'n'), ('location', 'n'), ('provided', 'v'), ('non-transitory', 'a'), ('computer-readable', 'a'), ('storage', 'n'), ('medium', 'n'), ('computer-executable', 'a'), ('instructions', 'n'), ('stored', 'v'), ('thereupon', 'r'), ('executed', 'v'), ('one', None), ('processors', 'n'), ('computing', 'v'), ('device', 'n'), ('cause', 'n'), ('one', None), ('processors', 'n'), ('computing', 'v'), ('device', 'n'), ('receive', 'v'), ('meeting', 'n'), ('invitation', 'n'), ('indicating', 'v'), ('location', 'n'), ('identity', 'n'), ('meeting', 'n'), ('invitation', 'n'), ('configured', 'v'), ('provide', None), ('least', 'a'), ('one', None), ('invitee', 'n'), ('physical', 'a'), ('access', 'n'), ('location', 'n'), ('wherein', 'n'), ('meeting', 'n'), ('invitation', 'n'), ('causes', 'v'), ('system', 'n'), ('control', 'n'), ('pathway', 'r'), ('allowing', 'v'), ('physical', 'a'), ('access', 'n'), ('location', 'n'), ('provide', None), ('least', 'a'), ('one', None), ('invitee', 'n'), ('associated', 'v'), ('identity', 'n'), ('access', 'n'), ('location', 'n'), ('controlling', 'v'), ('pathway', 'r'), ('allowing', 'v'), ('least', 'a'), ('one', None), ('invitee', 'n'), ('physically', 'r'), ('access', 'n'), ('location', 'n'), ('pathway', 'n'), ('response', 'n'), ('positioning', 'v'), ('data', 'n'), ('indicating', 'v'), ('least', 'a'), ('one', None), ('invitee', 'n'), ('predetermined', 'v'), ('location', 'n'), ('near', None), ('location', 'n'), ('wherein', 'n'), ('positioning', 'v'), ('data', 'n'), ('based', 'v'), ('part', 'n'), ('face', 'n'), ('recognition', 'n'), ('camera', 'n'), ('system', 'n'), ('identifying', 'v'), ('least', 'a'), ('one', None), ('invitee', 'n'), ('receive', 'v'), ('positioning', 'v'), ('data', 'n'), ('face', 'n'), ('recognition', 'n'), ('camera', 'n'), ('system', 'n'), ('identifying', 'v'), ('least', 'a'), ('one', None), ('invitee', 'n'), ('wherein', 'n'), ('positioning', 'v'), ('data', 'n'), ('indicates', 'v'), ('pattern', 'a'), ('movement', 'n'), ('least', 'a'), ('one', None), ('invitee', 'n'), ('determine', 'n'), ('pattern', 'a'), ('movement', 'n'), ('indicates', 'v'), ('least', 'a'), ('one', None), ('invitee', 'n'), ('exited', 'v'), ('location', 'n'), ('revoke', 'v'), ('physical', 'a'), ('access', 'n'), ('location', 'n'), ('identified', 'v'), ('meeting', 'v'), ('invitation', 'n'), ('controlling', 'v'), ('pathway', 'r'), ('restrict', 'v'), ('least', 'a'), ('one', None), ('invitee', 'n'), ('identified', 'v'), ('meeting', 'v'), ('invitation', 'n'), ('physical', 'a'), ('access', 'n'), ('location', 'n'), ('pathway', 'n'), ('response', 'n'), ('determining', 'v'), ('pattern', 'a'), ('movement', 'n'), ('indicates', 'v'), ('least', 'a'), ('one', None), ('invitee', 'n'), ('exited', 'v'), ('location', 'n'), ('non-transitory', 'a'), ('computer-readable', 'a'), ('storage', 'n'), ('medium', 'n'), ('claim', 'n'), ('wherein', None), ('determining', 'v'), ('least', 'a'), ('one', None), ('invitee', 'n'), ('exited', 'v'), ('location', 'n'), ('comprises', 'v'), ('determining', 'v'), ('least', 'a'), ('one', None), ('invitee', 'n'), ('passed', 'v'), ('egress', 'r'), ('associated', 'v'), ('location', 'n'), ('non-transitory', 'a'), ('computer-readable', 'a'), ('storage', 'n'), ('medium', 'n'), ('claim', 'n'), ('wherein', None), ('positioning', 'v'), ('data', 'n'), ('indicates', 'v'), ('second', 'a'), ('pattern', 'a'), ('movement', 'n'), ('least', 'a'), ('one', None), ('invitee', 'n'), ('wherein', 'n'), ('access', 'n'), ('secured', 'v'), ('data', 'n'), ('associated', 'v'), ('location', 'n'), ('provided', 'v'), ('response', 'n'), ('detecting', 'v'), ('second', 'a'), ('pattern', 'a'), ('movement', 'n'), ('non-transitory', 'a'), ('computer-readable', 'a'), ('storage', 'n'), ('medium', 'n'), ('claim', 'n'), ('wherein', 'n'), ('instructions', 'n'), ('cause', 'v'), ('one', None), ('processors', 'n'), ('collate', 'v'), ('secured', 'v'), ('data', 'n'), ('public', 'a'), ('data', 'n'), ('generate', 'v'), ('resource', 'n'), ('data', 'n'), ('communicate', 'v'), ('resource', 'n'), ('data', 'n'), ('client', 'n'), ('computing', 'v'), ('device', 'n'), ('associated', 'v'), ('least', 'a'), ('one', None), ('invitee', 'n'), ('access', 'n'), ('location', 'n'), ('provided', 'v'), ('method', 'n'), ('comprising', 'v'), ('receiving', 'v'), ('piece', 'n'), ('content', 'a'), ('salient', 'n'), ('data', 'n'), ('piece', 'n'), ('content', 'n'), ('based', 'v'), ('salient', 'a'), ('data', 'n'), ('determining', 'v'), ('first', 'a'), ('path', 'n'), ('viewport', 'n'), ('piece', 'n'), ('content', 'n'), ('wherein', 'n'), ('first', 'a'), ('path', 'n'), ('viewport', 'n'), ('includes', 'v'), ('different', 'a'), ('salient', 'a'), ('events', 'n'), ('occurring', 'v'), ('piece', 'n'), ('content', 'n'), ('different', 'a'), ('times', 'n'), ('playback', 'v'), ('piece', 'n'), ('content', 'n'), ('providing', 'v'), ('viewport', 'n'), ('display', 'n'), ('device', 'n'), ('wherein', 'v'), ('movement', 'n'), ('viewport', 'n'), ('based', 'v'), ('first', 'a'), ('path', 'n'), ('viewport', 'n'), ('salient', 'n'), ('data', 'n'), ('playback', 'n'), ('detecting', 'v'), ('additional', 'a'), ('salient', 'n'), ('event', 'n'), ('piece', 'n'), ('content', 'n'), ('included', 'v'), ('first', 'a'), ('path', 'n'), ('viewport', 'n'), ('providing', 'v'), ('indication', 'a'), ('additional', 'a'), ('salient', 'n'), ('event', 'n'), ('viewport', 'n'), ('playback', 'n'), ('method', 'n'), ('claim', 'n'), ('wherein', 'v'), ('salient', 'n'), ('data', 'n'), ('identifies', 'n'), ('salient', 'a'), ('event', 'n'), ('piece', 'n'), ('content', 'a'), ('salient', 'n'), ('data', 'n'), ('indicates', 'v'), ('salient', 'a'), ('event', 'n'), ('piece', 'n'), ('content', 'n'), ('corresponding', 'v'), ('point', 'n'), ('location', 'n'), ('salient', 'a'), ('event', 'n'), ('piece', 'n'), ('content', 'n'), ('corresponding', 'v'), ('time', 'n'), ('salient', 'a'), ('event', 'n'), ('occurs', 'v'), ('playback', 'a'), ('method', 'n'), ('claim', 'n'), ('wherein', 'v'), ('salient', 'n'), ('data', 'n'), ('indicates', 'v'), ('salient', 'a'), ('event', 'n'), ('piece', 'n'), ('content', 'n'), ('corresponding', 'v'), ('type', 'a'), ('salient', 'a'), ('event', 'n'), ('corresponding', 'v'), ('strength', 'n'), ('value', 'n'), ('salient', 'a'), ('event', 'n'), ('method', 'n'), ('claim', 'n'), ('wherein', None), ('first', 'a'), ('path', 'n'), ('viewport', 'n'), ('controls', 'n'), ('movement', 'n'), ('viewport', 'n'), ('put', 'v'), ('different', 'a'), ('salient', 'a'), ('events', 'n'), ('view', 'v'), ('viewport', 'r'), ('different', 'a'), ('times', 'n'), ('playback', 'v'), ('method', 'a'), ('claim', 'n'), ('comprising', 'v'), ('detecting', 'v'), ('one', None), ('salient', 'n'), ('events', 'n'), ('piece', 'v'), ('content', 'n'), ('based', 'v'), ('least', 'a'), ('one', None), ('following', 'v'), ('visual', 'a'), ('data', 'n'), ('piece', 'n'), ('content', 'n'), ('audio', 'n'), ('data', 'n'), ('piece', 'n'), ('content', 'n'), ('content', 'a'), ('consumption', 'n'), ('experience', 'n'), ('data', 'n'), ('piece', 'n'), ('content', 'n'), ('wherein', None), ('salient', 'n'), ('data', 'n'), ('indicative', 'a'), ('salient', 'a'), ('event', 'n'), ('detected', 'v'), ('method', 'a'), ('claim', 'n'), ('comprising', 'v'), ('detecting', 'v'), ('one', None), ('salient', 'n'), ('events', 'n'), ('piece', 'v'), ('content', 'n'), ('based', 'v'), ('least', 'a'), ('one', None), ('following', 'v'), ('face', 'n'), ('recognition', 'n'), ('facial', 'a'), ('emotion', 'n'), ('recognition', 'n'), ('object', 'a'), ('recognition', 'n'), ('motion', 'n'), ('recognition', 'n'), ('metadata', 'n'), ('piece', 'n'), ('content', 'n'), ('wherein', None), ('salient', 'n'), ('data', 'n'), ('indicative', 'a'), ('salient', 'a'), ('event', 'n'), ('detected', 'v'), ('method', 'a'), ('claim', 'n'), ('comprising', 'v'), ('detecting', 'v'), ('user', 'a'), ('interaction', 'n'), ('indication', 'n'), ('wherein', None), ('indication', 'n'), ('comprises', 'v'), ('interactive', 'a'), ('hint', 'n'), ('response', 'n'), ('detecting', 'v'), ('user', 'a'), ('interaction', 'n'), ('adapting', 'v'), ('first', 'a'), ('path', 'n'), ('viewport', 'n'), ('second', 'a'), ('path', 'n'), ('viewport', 'n'), ('based', 'v'), ('user', 'a'), ('interaction', 'n'), ('wherein', None), ('second', 'a'), ('path', 'n'), ('viewport', 'n'), ('includes', 'v'), ('additional', 'a'), ('salient', 'n'), ('event', 'n'), ('providing', 'v'), ('updated', 'a'), ('viewport', 'n'), ('piece', 'n'), ('content', 'n'), ('display', 'n'), ('device', 'n'), ('wherein', 'v'), ('movement', 'n'), ('updated', 'v'), ('viewport', 'n'), ('based', 'v'), ('second', 'a'), ('path', 'n'), ('viewport', 'n'), ('salient', 'n'), ('data', 'n'), ('playback', 'v'), ('second', 'a'), ('path', 'n'), ('viewport', 'n'), ('controls', 'n'), ('movement', 'n'), ('updated', 'v'), ('viewport', 'n'), ('put', 'v'), ('additional', 'a'), ('salient', 'n'), ('event', 'n'), ('view', 'n'), ('updated', 'v'), ('viewport', 'n'), ('method', 'n'), ('claim', 'n'), ('comprising', 'v'), ('changing', 'v'), ('weight', 'n'), ('assigned', 'v'), ('additional', 'a'), ('salient', 'n'), ('event', 'n'), ('one', None), ('salient', 'n'), ('events', 'n'), ('piece', 'v'), ('content', 'a'), ('type', 'a'), ('additional', 'a'), ('salient', 'n'), ('event', 'n'), ('method', 'n'), ('claim', 'n'), ('wherein', None), ('second', 'a'), ('path', 'n'), ('viewport', 'n'), ('includes', 'v'), ('one', None), ('salient', 'n'), ('events', 'n'), ('piece', 'v'), ('content', 'a'), ('type', 'a'), ('additional', 'a'), ('salient', 'n'), ('event', 'n'), ('system', 'n'), ('comprising', 'v'), ('least', 'a'), ('one', None), ('processor', 'n'), ('non-transitory', 'a'), ('processor-readable', 'a'), ('memory', 'n'), ('device', 'n'), ('storing', 'v'), ('instructions', 'n'), ('executed', 'v'), ('least', 'a'), ('one', None), ('processor', 'n'), ('causes', 'v'), ('least', 'a'), ('one', None), ('processor', 'n'), ('perform', 'n'), ('operations', 'n'), ('including', 'v'), ('receiving', 'v'), ('piece', 'n'), ('content', 'a'), ('salient', 'n'), ('data', 'n'), ('piece', 'n'), ('content', 'n'), ('based', 'v'), ('salient', 'a'), ('data', 'n'), ('determining', 'v'), ('first', 'a'), ('path', 'n'), ('viewport', 'n'), ('piece', 'n'), ('content', 'n'), ('wherein', 'n'), ('first', 'a'), ('path', 'n'), ('viewport', 'n'), ('includes', 'v'), ('different', 'a'), ('salient', 'a'), ('events', 'n'), ('occurring', 'v'), ('piece', 'n'), ('content', 'n'), ('different', 'a'), ('times', 'n'), ('playback', 'v'), ('piece', 'n'), ('content', 'n'), ('providing', 'v'), ('viewport', 'n'), ('display', 'n'), ('device', 'n'), ('wherein', 'v'), ('movement', 'n'), ('viewport', 'n'), ('based', 'v'), ('first', 'a'), ('path', 'n'), ('viewport', 'n'), ('salient', 'n'), ('data', 'n'), ('playback', 'n'), ('detecting', 'v'), ('additional', 'a'), ('salient', 'n'), ('event', 'n'), ('piece', 'n'), ('content', 'n'), ('included', 'v'), ('first', 'a'), ('path', 'n'), ('viewport', 'n'), ('providing', 'v'), ('indication', 'a'), ('additional', 'a'), ('salient', 'n'), ('event', 'n'), ('viewport', 'n'), ('playback', 'n'), ('system', 'n'), ('claim', 'n'), ('wherein', 'v'), ('salient', 'n'), ('data', 'n'), ('identifies', 'n'), ('salient', 'a'), ('event', 'n'), ('piece', 'n'), ('content', 'a'), ('salient', 'n'), ('data', 'n'), ('indicates', 'v'), ('salient', 'a'), ('event', 'n'), ('piece', 'n'), ('content', 'n'), ('corresponding', 'v'), ('point', 'n'), ('location', 'n'), ('salient', 'a'), ('event', 'n'), ('piece', 'n'), ('content', 'n'), ('corresponding', 'v'), ('time', 'n'), ('salient', 'a'), ('event', 'n'), ('occurs', 'v'), ('playback', 'n'), ('system', 'n'), ('claim', 'n'), ('wherein', 'v'), ('salient', 'n'), ('data', 'n'), ('indicates', 'v'), ('salient', 'a'), ('event', 'n'), ('piece', 'n'), ('content', 'n'), ('corresponding', 'v'), ('type', 'a'), ('salient', 'a'), ('event', 'n'), ('corresponding', 'v'), ('strength', 'n'), ('value', 'n'), ('salient', 'n'), ('event', 'n'), ('system', 'n'), ('claim', 'n'), ('wherein', 'v'), ('salient', 'n'), ('data', 'n'), ('generated', 'v'), ('offline', 'a'), ('server', 'n'), ('system', 'n'), ('claim', 'n'), ('operations', 'n'), ('comprising', 'v'), ('detecting', 'v'), ('one', None), ('salient', 'n'), ('events', 'n'), ('piece', 'v'), ('content', 'n'), ('based', 'v'), ('least', 'a'), ('one', None), ('following', 'v'), ('visual', 'a'), ('data', 'n'), ('piece', 'n'), ('content', 'n'), ('audio', 'n'), ('data', 'n'), ('piece', 'n'), ('content', 'n'), ('content', 'a'), ('consumption', 'n'), ('experience', 'n'), ('data', 'n'), ('piece', 'n'), ('content', 'n'), ('wherein', None), ('salient', 'n'), ('data', 'n'), ('indicative', 'a'), ('salient', 'a'), ('event', 'n'), ('detected', 'v'), ('system', 'n'), ('claim', 'n'), ('operations', 'n'), ('comprising', 'v'), ('detecting', 'v'), ('one', None), ('salient', 'n'), ('events', 'n'), ('piece', 'v'), ('content', 'n'), ('based', 'v'), ('least', 'a'), ('one', None), ('following', 'v'), ('face', 'n'), ('recognition', 'n'), ('facial', 'a'), ('emotion', 'n'), ('recognition', 'n'), ('object', 'a'), ('recognition', 'n'), ('motion', 'n'), ('recognition', 'n'), ('metadata', 'n'), ('piece', 'n'), ('content', 'n'), ('wherein', None), ('salient', 'n'), ('data', 'n'), ('indicative', 'a'), ('salient', 'a'), ('event', 'n'), ('detected', 'v'), ('system', 'n'), ('claim', 'n'), ('operations', 'n'), ('comprising', 'v'), ('detecting', 'v'), ('user', 'a'), ('interaction', 'n'), ('indication', 'n'), ('wherein', None), ('indication', 'n'), ('comprises', 'v'), ('interactive', 'a'), ('hint', 'n'), ('response', 'n'), ('detecting', 'v'), ('user', 'a'), ('interaction', 'n'), ('adapting', 'v'), ('first', 'a'), ('path', 'n'), ('viewport', 'n'), ('second', 'a'), ('path', 'n'), ('viewport', 'n'), ('based', 'v'), ('user', 'a'), ('interaction', 'n'), ('wherein', None), ('second', 'a'), ('path', 'n'), ('viewport', 'n'), ('includes', 'v'), ('additional', 'a'), ('salient', 'n'), ('event', 'n'), ('providing', 'v'), ('updated', 'a'), ('viewport', 'n'), ('piece', 'n'), ('content', 'n'), ('display', 'n'), ('device', 'n'), ('wherein', 'v'), ('movement', 'n'), ('updated', 'v'), ('viewport', 'n'), ('based', 'v'), ('second', 'a'), ('path', 'n'), ('viewport', 'n'), ('salient', 'n'), ('data', 'n'), ('playback', 'v'), ('second', 'a'), ('path', 'n'), ('viewport', 'n'), ('controls', 'n'), ('movement', 'n'), ('updated', 'v'), ('viewport', 'n'), ('put', 'v'), ('additional', 'a'), ('salient', 'n'), ('event', 'n'), ('view', 'n'), ('updated', 'v'), ('viewport', 'n'), ('system', 'n'), ('claim', 'n'), ('operations', 'n'), ('comprising', 'v'), ('changing', 'v'), ('weight', 'n'), ('assigned', 'v'), ('additional', 'a'), ('salient', 'n'), ('event', 'n'), ('one', None), ('salient', 'n'), ('events', 'n'), ('piece', 'v'), ('content', 'a'), ('type', 'a'), ('additional', 'a'), ('salient', 'n'), ('event', 'n'), ('system', 'n'), ('claim', 'n'), ('wherein', None), ('second', 'a'), ('path', 'n'), ('viewport', 'n'), ('includes', 'v'), ('one', None), ('salient', 'n'), ('events', 'n'), ('piece', 'v'), ('content', 'a'), ('type', 'a'), ('additional', 'a'), ('salient', 'n'), ('event', 'n'), ('non-transitory', 'a'), ('computer', 'n'), ('readable', 'a'), ('storage', 'n'), ('medium', 'n'), ('including', 'v'), ('instructions', 'n'), ('perform', 'v'), ('method', 'n'), ('comprising', 'v'), ('receiving', 'v'), ('piece', 'n'), ('content', 'a'), ('salient', 'n'), ('data', 'n'), ('piece', 'n'), ('content', 'n'), ('based', 'v'), ('salient', 'a'), ('data', 'n'), ('determining', 'v'), ('first', 'a'), ('path', 'n'), ('viewport', 'n'), ('piece', 'n'), ('content', 'n'), ('wherein', 'n'), ('first', 'a'), ('path', 'n'), ('viewport', 'n'), ('includes', 'v'), ('different', 'a'), ('salient', 'a'), ('events', 'n'), ('occurring', 'v'), ('piece', 'n'), ('content', 'n'), ('different', 'a'), ('times', 'n'), ('playback', 'v'), ('piece', 'n'), ('content', 'n'), ('providing', 'v'), ('viewport', 'n'), ('display', 'n'), ('device', 'n'), ('wherein', 'v'), ('movement', 'n'), ('viewport', 'n'), ('based', 'v'), ('first', 'a'), ('path', 'n'), ('viewport', 'n'), ('salient', 'n'), ('data', 'n'), ('playback', 'n'), ('detecting', 'v'), ('additional', 'a'), ('salient', 'n'), ('event', 'n'), ('piece', 'n'), ('content', 'n'), ('included', 'v'), ('first', 'a'), ('path', 'n'), ('viewport', 'n'), ('providing', 'v'), ('indication', 'a'), ('additional', 'a'), ('salient', 'n'), ('event', 'n'), ('viewport', 'n'), ('playback', 'n'), ('computer', 'n'), ('readable', 'a'), ('storage', 'n'), ('medium', 'n'), ('claim', 'n'), ('method', 'n'), ('comprising', 'v'), ('detecting', 'v'), ('user', 'a'), ('interaction', 'n'), ('indication', 'n'), ('wherein', None), ('indication', 'n'), ('comprises', 'v'), ('interactive', 'a'), ('hint', 'n'), ('response', 'n'), ('detecting', 'v'), ('user', 'a'), ('interaction', 'n'), ('adapting', 'v'), ('first', 'a'), ('path', 'n'), ('viewport', 'n'), ('second', 'a'), ('path', 'n'), ('viewport', 'n'), ('based', 'v'), ('user', 'a'), ('interaction', 'n'), ('wherein', None), ('second', 'a'), ('path', 'n'), ('viewport', 'n'), ('includes', 'v'), ('additional', 'a'), ('salient', 'n'), ('event', 'n'), ('providing', 'v'), ('updated', 'a'), ('viewport', 'n'), ('piece', 'n'), ('content', 'n'), ('display', 'n'), ('device', 'n'), ('wherein', 'v'), ('movement', 'n'), ('updated', 'v'), ('viewport', 'n'), ('based', 'v'), ('second', 'a'), ('path', 'n'), ('viewport', 'n'), ('salient', 'n'), ('data', 'n'), ('playback', 'v'), ('second', 'a'), ('path', 'n'), ('viewport', 'n'), ('controls', 'n'), ('movement', 'n'), ('updated', 'v'), ('viewport', 'n'), ('put', 'v'), ('additional', 'a'), ('salient', 'n'), ('event', 'n'), ('view', 'n'), ('updated', 'v'), ('viewport', 'n'), ('mobile', 'n'), ('device', 'n'), ('facial', 'a'), ('recognition', 'n'), ('mobile', 'a'), ('device', 'n'), ('comprising', 'v'), ('one', None), ('cameras', 'n'), ('processor', 'n'), ('device', 'n'), ('memory', 'n'), ('coupled', 'v'), ('processor', 'n'), ('device', 'n'), ('processing', 'n'), ('system', 'n'), ('programmed', 'v'), ('receive', 'a'), ('plurality', 'n'), ('images', 'v'), ('one', None), ('cameras', 'n'), ('extract', 'a'), ('feature', 'n'), ('extractor', 'n'), ('utilizing', 'a'), ('convolutional', 'a'), ('neural', 'a'), ('network', 'n'), ('cnn', 'n'), ('enlarged', 'v'), ('intra-class', 'a'), ('variance', 'n'), ('long-tail', 'a'), ('classes', 'n'), ('feature', 'v'), ('vectors', 'n'), ('plurality', 'n'), ('images', 'n'), ('generate', 'v'), ('feature', 'n'), ('generator', 'n'), ('discriminative', 'a'), ('feature', 'n'), ('vectors', 'n'), ('feature', 'v'), ('vectors', 'n'), ('classify', 'v'), ('fully', 'r'), ('connected', 'v'), ('classifier', 'a'), ('identity', 'n'), ('discriminative', 'a'), ('feature', 'n'), ('vectors', 'n'), ('control', 'v'), ('operation', 'n'), ('mobile', 'a'), ('device', 'n'), ('react', 'n'), ('accordance', 'n'), ('identity', 'n'), ('mobile', 'a'), ('device', 'n'), ('recited', 'v'), ('claim', 'n'), ('includes', 'v'), ('communication', 'n'), ('system', 'n'), ('mobile', 'a'), ('device', 'n'), ('recited', 'v'), ('claim', 'n'), ('wherein', 'n'), ('operation', 'n'), ('tags', 'n'), ('video', 'v'), ('identity', 'n'), ('uploads', 'n'), ('video', 'v'), ('social', 'a'), ('media', 'n'), ('mobile', 'a'), ('device', 'n'), ('recited', 'v'), ('claim', 'n'), ('wherein', 'n'), ('operation', 'n'), ('tags', 'n'), ('video', 'v'), ('identity', 'n'), ('sends', 'n'), ('video', 'v'), ('user', 'r'), ('mobile', 'a'), ('device', 'n'), ('recited', 'v'), ('claim', 'n'), ('wherein', 'n'), ('mobile', 'a'), ('device', 'n'), ('smart', 'v'), ('phone', 'n'), ('mobile', 'a'), ('device', 'n'), ('recited', 'v'), ('claim', 'n'), ('wherein', 'n'), ('mobile', 'a'), ('device', 'n'), ('body', 'n'), ('cam', 'v'), ('mobile', 'a'), ('device', 'n'), ('recited', 'v'), ('claim', 'n'), ('programmed', 'v'), ('train', 'a'), ('feature', 'n'), ('extractor', 'n'), ('feature', 'n'), ('generator', 'n'), ('fully', 'r'), ('connected', 'v'), ('classifier', 'a'), ('alternative', 'a'), ('bi-stage', 'n'), ('strategy', 'n'), ('mobile', 'a'), ('device', 'n'), ('recited', 'v'), ('claim', 'n'), ('wherein', 'n'), ('feature', 'n'), ('extractor', 'n'), ('shares', 'n'), ('covariance', 'n'), ('matrices', 'n'), ('across', None), ('classes', 'n'), ('transfer', 'v'), ('intra-class', 'a'), ('variance', 'n'), ('regular', 'a'), ('classes', 'n'), ('long-tail', 'a'), ('classes', 'n'), ('mobile', 'a'), ('device', 'n'), ('recited', 'v'), ('claim', 'n'), ('wherein', 'n'), ('feature', 'n'), ('generator', 'n'), ('optimizes', 'v'), ('softmax', 'a'), ('loss', 'n'), ('joint', 'n'), ('regularization', 'n'), ('weights', 'n'), ('features', 'n'), ('magnitude', 'v'), ('inner', 'a'), ('product', 'n'), ('weights', 'n'), ('features', 'n'), ('mobile', 'a'), ('device', 'n'), ('recited', 'v'), ('claim', 'n'), ('wherein', 'n'), ('feature', 'n'), ('extractor', 'n'), ('averages', 'n'), ('feature', 'v'), ('vector', 'n'), ('flipped', 'v'), ('feature', 'n'), ('vector', 'n'), ('flipped', 'v'), ('feature', 'n'), ('vector', 'n'), ('generated', 'v'), ('horizontally', 'r'), ('flipped', 'v'), ('frame', 'v'), ('one', None), ('plurality', 'n'), ('images', 'v'), ('mobile', 'a'), ('device', 'n'), ('recited', 'v'), ('claim', 'n'), ('wherein', 'n'), ('plurality', 'n'), ('images', 'n'), ('selected', 'v'), ('group', 'n'), ('consisting', 'v'), ('image', 'n'), ('video', 'n'), ('frame', 'n'), ('video', 'n'), ('mobile', 'a'), ('device', 'n'), ('recited', 'v'), ('claim', 'n'), ('wherein', 'n'), ('communication', 'n'), ('system', 'n'), ('connects', 'v'), ('remote', 'a'), ('server', 'n'), ('includes', 'v'), ('facial', 'a'), ('recognition', 'n'), ('network', 'n'), ('mobile', 'a'), ('device', 'n'), ('recited', 'v'), ('claim', 'n'), ('wherein', None), ('one', None), ('stage', 'n'), ('alternative', 'a'), ('bi-stage', 'n'), ('strategy', 'n'), ('fixes', 'n'), ('feature', 'v'), ('extractor', 'n'), ('applies', 'n'), ('feature', 'v'), ('generator', 'n'), ('generate', 'v'), ('new', 'a'), ('transferred', 'v'), ('features', 'n'), ('diverse', 'a'), ('violate', 'a'), ('decision', 'n'), ('boundary', 'n'), ('mobile', 'a'), ('device', 'n'), ('recited', 'v'), ('claim', 'n'), ('wherein', None), ('one', None), ('stage', 'n'), ('alternative', 'a'), ('bi-stage', 'n'), ('strategy', 'n'), ('fixes', 'n'), ('fully', 'r'), ('connected', 'v'), ('classifier', 'a'), ('updates', 'a'), ('feature', 'n'), ('extractor', 'n'), ('feature', 'n'), ('generator', 'n'), ('computer', 'n'), ('program', 'n'), ('product', 'n'), ('mobile', 'a'), ('device', 'n'), ('facial', 'a'), ('recognition', 'n'), ('computer', 'n'), ('program', 'n'), ('product', 'n'), ('comprising', 'v'), ('non-transitory', 'a'), ('computer', 'n'), ('readable', 'a'), ('storage', 'n'), ('medium', 'n'), ('program', 'n'), ('instructions', 'n'), ('embodied', 'v'), ('therewith', 'a'), ('program', 'n'), ('instructions', 'n'), ('executable', 'a'), ('computer', 'n'), ('cause', 'n'), ('computer', 'n'), ('perform', 'n'), ('method', 'n'), ('comprising', 'v'), ('receiving', 'v'), ('processor', 'n'), ('device', 'n'), ('plurality', 'n'), ('images', 'v'), ('extracting', 'v'), ('processor', 'n'), ('device', 'n'), ('feature', 'n'), ('extractor', 'n'), ('utilizing', 'a'), ('convolutional', 'a'), ('neural', 'a'), ('network', 'n'), ('cnn', 'n'), ('enlarged', 'v'), ('intra-class', 'a'), ('variance', 'n'), ('long-tail', 'a'), ('classes', 'n'), ('feature', 'v'), ('vectors', 'n'), ('plurality', 'n'), ('images', 'n'), ('generating', 'v'), ('processor', 'n'), ('device', 'n'), ('feature', 'n'), ('generator', 'n'), ('discriminative', 'a'), ('feature', 'n'), ('vectors', 'n'), ('feature', 'v'), ('vectors', 'n'), ('classifying', 'v'), ('processor', 'n'), ('device', 'n'), ('utilizing', 'v'), ('fully', 'r'), ('connected', 'v'), ('classifier', 'a'), ('identity', 'n'), ('discriminative', 'a'), ('feature', 'n'), ('vector', 'n'), ('controlling', 'v'), ('operation', 'n'), ('mobile', 'a'), ('device', 'n'), ('react', 'n'), ('accordance', 'n'), ('identity', 'n'), ('computer-implemented', 'a'), ('method', 'n'), ('facial', 'a'), ('recognition', 'n'), ('mobile', 'a'), ('device', 'n'), ('method', 'n'), ('comprising', 'v'), ('receiving', 'v'), ('processor', 'n'), ('device', 'n'), ('plurality', 'n'), ('images', 'v'), ('extracting', 'v'), ('processor', 'n'), ('device', 'n'), ('feature', 'n'), ('extractor', 'n'), ('utilizing', 'a'), ('convolutional', 'a'), ('neural', 'a'), ('network', 'n'), ('cnn', 'n'), ('enlarged', 'v'), ('intra-class', 'a'), ('variance', 'n'), ('long-tail', 'a'), ('classes', 'n'), ('feature', 'v'), ('vectors', 'n'), ('plurality', 'n'), ('images', 'n'), ('generating', 'v'), ('processor', 'n'), ('device', 'n'), ('feature', 'n'), ('generator', 'n'), ('discriminative', 'a'), ('feature', 'n'), ('vectors', 'n'), ('feature', 'v'), ('vectors', 'n'), ('classifying', 'v'), ('processor', 'n'), ('device', 'n'), ('utilizing', 'v'), ('fully', 'r'), ('connected', 'v'), ('classifier', 'a'), ('identity', 'n'), ('discriminative', 'a'), ('feature', 'n'), ('vector', 'n'), ('controlling', 'v'), ('operation', 'n'), ('mobile', 'a'), ('device', 'n'), ('react', 'n'), ('accordance', 'n'), ('identity', 'n'), ('computer-implemented', 'a'), ('method', 'n'), ('recited', 'v'), ('claim', 'n'), ('wherein', 'n'), ('controlling', 'v'), ('includes', 'v'), ('tagging', 'v'), ('video', 'n'), ('identity', 'n'), ('uploading', 'v'), ('video', 'a'), ('social', 'a'), ('media', 'n'), ('computer-implemented', 'a'), ('method', 'n'), ('recited', 'v'), ('claim', 'n'), ('wherein', 'n'), ('controlling', 'v'), ('includes', 'v'), ('tagging', 'v'), ('video', 'n'), ('identity', 'n'), ('sending', 'v'), ('video', 'a'), ('user', 'a'), ('computer-implemented', 'a'), ('method', 'n'), ('recited', 'v'), ('claim', 'n'), ('wherein', 'n'), ('extracting', 'v'), ('includes', 'v'), ('sharing', 'v'), ('covariance', 'n'), ('matrices', 'n'), ('across', None), ('classes', 'n'), ('transfer', 'v'), ('intra-class', 'a'), ('variance', 'n'), ('regular', 'a'), ('classes', 'n'), ('long-tail', 'a'), ('classes', 'n'), ('computing', 'v'), ('device', 'n'), ('comprising', 'v'), ('non-transitory', 'a'), ('machine', 'n'), ('readable', 'a'), ('medium', 'n'), ('storing', 'v'), ('machine', 'n'), ('trained', 'v'), ('mt', 'a'), ('network', 'n'), ('comprising', 'v'), ('plurality', 'n'), ('layers', 'n'), ('processing', 'v'), ('nodes', 'n'), ('processing', 'v'), ('node', 'r'), ('configured', 'v'), ('compute', 'n'), ('first', 'r'), ('output', 'n'), ('value', 'n'), ('combining', 'v'), ('set', 'v'), ('output', 'n'), ('values', 'n'), ('set', 'v'), ('processing', 'v'), ('nodes', 'n'), ('use', 'v'), ('piecewise', 'a'), ('linear', 'a'), ('cup', 'n'), ('function', 'n'), ('compute', 'a'), ('second', 'a'), ('output', 'n'), ('value', 'n'), ('first', 'r'), ('output', 'n'), ('value', 'n'), ('processing', 'v'), ('node', 'a'), ('wherein', 'n'), ('piecewise', 'n'), ('linear', 'a'), ('cup', 'n'), ('function', 'n'), ('prior', 'r'), ('training', 'v'), ('mt', 'n'), ('network', 'n'), ('comprises', 'n'), ('least', 'v'), ('first', 'a'), ('linear', 'a'), ('section', 'n'), ('first', 'r'), ('slope', 'n'), ('followed', 'v'), ('ii', 'a'), ('second', 'a'), ('linear', 'a'), ('section', 'n'), ('negative', 'a'), ('second', 'a'), ('slope', 'n'), ('followed', 'v'), ('iii', 'a'), ('third', 'a'), ('linear', 'a'), ('section', 'n'), ('negative', 'a'), ('third', 'a'), ('slope', 'n'), ('different', 'a'), ('second', 'a'), ('slope', 'n'), ('followed', 'v'), ('iv', 'a'), ('fourth', 'a'), ('linear', 'a'), ('section', 'n'), ('positive', 'a'), ('fourth', 'a'), ('slope', 'n'), ('followed', 'v'), ('v', 'a'), ('fifth', 'a'), ('linear', 'a'), ('section', 'n'), ('positive', 'a'), ('fifth', 'a'), ('slope', 'n'), ('different', 'a'), ('fourth', 'a'), ('slope', 'n'), ('followed', 'v'), ('vi', 'a'), ('sixth', 'a'), ('linear', 'a'), ('section', 'n'), ('sixth', 'v'), ('slope', 'n'), ('wherein', 'n'), ('piecewise', 'n'), ('linear', 'a'), ('cup', 'n'), ('function', 'n'), ('symmetric', 'a'), ('vertical', 'a'), ('axis', 'n'), ('third', 'a'), ('fourth', 'a'), ('linear', 'a'), ('sections', 'n'), ('prior', 'r'), ('training', 'v'), ('mt', 'n'), ('network', 'n'), ('content', 'a'), ('capturing', 'n'), ('circuit', 'n'), ('capturing', 'v'), ('content', 'a'), ('processing', 'n'), ('mt', 'n'), ('network', 'n'), ('set', 'v'), ('processing', 'v'), ('units', 'n'), ('executing', 'v'), ('processing', 'v'), ('nodes', 'n'), ('process', 'n'), ('content', 'n'), ('captured', 'v'), ('content', 'a'), ('capturing', 'v'), ('circuit', 'n'), ('wherein', 'n'), ('training', 'n'), ('set', 'v'), ('parameters', 'n'), ('define', 'v'), ('piecewise', 'n'), ('linear', 'a'), ('cup', 'n'), ('function', 'n'), ('node', None), ('first', 'a'), ('second', 'a'), ('pluralities', 'n'), ('processing', 'v'), ('nodes', 'n'), ('processing', 'v'), ('node', 'n'), ('first', 'a'), ('plurality', 'n'), ('processing', 'n'), ('nodes', 'n'), ('configured', 'v'), ('emulate', 'a'), ('boolean', 'n'), ('operator', 'n'), ('output', 'n'), ('value', 'n'), ('processing', 'n'), ('node', 'a'), ('range', 'n'), ('associated', 'v'), ('``', None), (\"''\", None), ('value', 'n'), ('set', 'v'), ('inputs', 'n'), ('processing', 'v'), ('node', 'n'), ('set', 'v'), ('values', 'n'), ('range', 'v'), ('associated', 'v'), ('``', None), (\"''\", None), ('ii', 'n'), ('processing', 'n'), ('node', 'a'), ('second', 'a'), ('plurality', 'n'), ('processing', 'n'), ('nodes', 'n'), ('configured', 'v'), ('emulate', 'a'), ('boolean', 'a'), ('xnor', 'n'), ('operator', 'n'), ('output', 'n'), ('value', 'n'), ('processing', 'n'), ('node', 'a'), ('range', 'n'), ('associated', 'v'), ('``', None), (\"''\", None), ('set', 'n'), ('inputs', 'n'), ('node', 'a'), ('set', 'n'), ('values', 'n'), ('range', 'v'), ('associated', 'v'), ('``', None), (\"''\", None), ('b', 'n'), ('set', 'v'), ('inputs', 'n'), ('node', 'a'), ('set', 'n'), ('values', 'n'), ('range', 'v'), ('associated', 'v'), ('``', None), (\"''\", None), ('value', 'n'), ('computing', 'v'), ('device', 'n'), ('claim', 'n'), ('wherein', None), ('third', 'a'), ('linear', 'a'), ('section', 'n'), ('piecewise', 'n'), ('linear', 'a'), ('cup', 'n'), ('function', 'n'), ('first', 'r'), ('processing', 'v'), ('node', 'n'), ('mt', 'n'), ('network', 'n'), ('different', 'a'), ('slope', 'n'), ('third', 'a'), ('linear', 'a'), ('section', 'n'), ('second', 'a'), ('processing', 'n'), ('node', 'n'), ('mt', 'n'), ('network', 'n'), ('computing', 'v'), ('device', 'n'), ('claim', 'n'), ('wherein', 'n'), ('length', 'v'), ('third', 'a'), ('section', 'n'), ('piecewise', 'n'), ('linear', 'a'), ('cup', 'n'), ('function', 'n'), ('first', 'r'), ('processing', 'v'), ('node', 'n'), ('mt', 'n'), ('network', 'n'), ('different', 'a'), ('length', 'n'), ('third', 'a'), ('section', 'n'), ('piecewise', 'n'), ('linear', 'a'), ('cup', 'n'), ('function', 'n'), ('second', 'a'), ('processing', 'n'), ('node', 'n'), ('mt', 'n'), ('network', 'n'), ('computing', 'v'), ('device', 'n'), ('claim', 'n'), ('wherein', 'a'), ('sets', 'v'), ('parameters', 'n'), ('trained', 'v'), ('part', 'n'), ('back', 'r'), ('propagating', 'v'), ('module', 'n'), ('back', 'r'), ('propagating', 'a'), ('errors', 'n'), ('output', 'n'), ('values', 'n'), ('later', 'r'), ('layers', 'n'), ('processing', 'v'), ('nodes', 'n'), ('earlier', 'r'), ('layers', 'n'), ('processing', 'v'), ('nodes', 'n'), ('adjusting', 'v'), ('set', 'n'), ('parameters', 'n'), ('define', 'v'), ('piecewise', 'n'), ('linear', 'a'), ('cup', 'n'), ('functions', 'n'), ('earlier', 'r'), ('layers', 'n'), ('processing', 'v'), ('nodes', 'n'), ('computing', 'v'), ('device', 'n'), ('claim', 'n'), ('wherein', 'n'), ('processing', 'n'), ('node', 'a'), ('uses', 'n'), ('linear', 'a'), ('function', 'n'), ('defined', 'v'), ('set', 'v'), ('parameters', 'n'), ('compute', 'v'), ('first', 'a'), ('output', 'n'), ('value', 'n'), ('processing', 'v'), ('node', None), ('wherein', 'a'), ('back', 'r'), ('propagating', 'v'), ('module', 'n'), ('back', 'r'), ('propagates', 'v'), ('errors', 'n'), ('output', 'n'), ('values', 'n'), ('later', 'r'), ('layers', 'n'), ('processing', 'v'), ('nodes', 'n'), ('earlier', 'r'), ('layers', 'n'), ('processing', 'v'), ('nodes', 'n'), ('adjusting', 'v'), ('set', 'n'), ('parameters', 'n'), ('define', 'v'), ('linear', 'a'), ('functions', 'n'), ('earlier', 'r'), ('layers', 'n'), ('processing', 'v'), ('nodes', 'n'), ('computing', 'v'), ('device', 'n'), ('claim', 'n'), ('wherein', None), ('first', 'a'), ('plurality', 'n'), ('processing', 'n'), ('nodes', 'n'), ('emulate', 'v'), ('boolean', 'a'), ('operator', 'n'), ('second', 'a'), ('plurality', 'n'), ('processing', 'n'), ('nodes', 'n'), ('emulate', 'v'), ('boolean', 'a'), ('operator', 'n'), ('enable', 'a'), ('mt', 'n'), ('network', 'n'), ('implement', 'a'), ('mathematical', 'a'), ('problems', 'n'), ('computing', 'v'), ('device', 'n'), ('claim', 'n'), ('wherein', None), ('plurality', 'n'), ('processing', 'n'), ('node', 'n'), ('layers', 'n'), ('plurality', 'n'), ('processing', 'n'), ('nodes', 'n'), ('receive', 'v'), ('input', 'n'), ('values', 'n'), ('output', 'n'), ('values', 'n'), ('plurality', 'n'), ('processing', 'n'), ('nodes', 'n'), ('set', 'v'), ('prior', 'a'), ('layers', 'n'), ('computing', 'v'), ('device', 'n'), ('claim', 'n'), ('wherein', 'n'), ('processing', 'n'), ('node', 'a'), ('uses', 'n'), ('linear', 'a'), ('function', 'n'), ('compute', 'n'), ('first', 'r'), ('output', 'n'), ('value', 'n'), ('processing', 'v'), ('node', 'a'), ('wherein', 'n'), ('processing', 'v'), ('node', 'n'), (\"'s\", None), ('piecewise', 'n'), ('linear', 'a'), ('cup', 'n'), ('function', 'n'), ('defined', 'v'), ('along', None), ('first', 'a'), ('second', 'a'), ('axes', 'n'), ('first', 'r'), ('axis', 'v'), ('defining', 'v'), ('range', 'n'), ('output', 'n'), ('values', 'n'), ('processing', 'v'), ('node', 'n'), (\"'s\", None), ('linear', 'a'), ('function', 'n'), ('second', 'a'), ('axis', 'n'), ('defining', 'v'), ('range', 'n'), ('output', 'n'), ('values', 'n'), ('produced', 'v'), ('piecewise', 'a'), ('linear', 'a'), ('cup', 'n'), ('function', 'n'), ('range', 'n'), ('output', 'n'), ('values', 'n'), ('processing', 'v'), ('node', 'n'), (\"'s\", None), ('linear', 'a'), ('function', 'n'), ('computing', 'v'), ('device', 'n'), ('claim', 'n'), ('comprising', 'v'), ('content', 'a'), ('output', 'n'), ('circuit', 'n'), ('presenting', 'v'), ('output', 'n'), ('based', 'v'), ('processing', 'n'), ('content', 'n'), ('mt', 'n'), ('network', 'n'), ('computing', 'v'), ('device', 'n'), ('claim', 'n'), ('wherein', 'n'), ('captured', 'v'), ('content', 'a'), ('one', None), ('image', 'n'), ('audio', 'n'), ('segment', 'n'), ('wherein', 'n'), ('presented', 'v'), ('output', 'n'), ('output', 'n'), ('display', 'v'), ('display', 'n'), ('screen', 'n'), ('computing', 'v'), ('device', 'n'), ('audio', 'n'), ('presentation', 'n'), ('output', 'n'), ('speaker', 'n'), ('computing', 'v'), ('device', 'n'), ('computing', 'v'), ('device', 'n'), ('claim', 'n'), ('wherein', None), ('computing', 'v'), ('device', 'n'), ('mobile', 'a'), ('device', 'n'), ('computing', 'v'), ('device', 'n'), ('claim', 'n'), ('wherein', 'n'), ('mt', 'n'), ('network', 'n'), ('mt', 'n'), ('neural', 'a'), ('network', 'n'), ('processing', 'v'), ('nodes', 'n'), ('mt', 'a'), ('neurons', 'n'), ('computing', 'v'), ('device', 'n'), ('claim', 'n'), ('wherein', 'n'), ('set', 'v'), ('parameters', 'n'), ('configured', 'v'), ('training', 'v'), ('plurality', 'n'), ('processing', 'n'), ('nodes', 'n'), ('comprise', 'v'), ('least', 'a'), ('one', None), ('negative', 'a'), ('second', 'a'), ('third', 'a'), ('slopes', 'n'), ('second', 'a'), ('third', 'a'), ('linear', 'a'), ('sections', 'n'), ('positive', 'a'), ('fourth', 'a'), ('fifth', 'a'), ('slopes', 'n'), ('fourth', 'a'), ('fifth', 'a'), ('linear', 'n'), ('sections', 'n'), ('first', 'r'), ('intercept', 'a'), ('second', 'a'), ('linear', 'a'), ('section', 'n'), ('second', 'a'), ('intercept', 'n'), ('fifth', 'a'), ('linear', 'a'), ('section', 'n'), ('set', 'v'), ('lengths', 'n'), ('least', 'a'), ('second', 'a'), ('third', 'a'), ('fourth', 'a'), ('fifth', 'a'), ('sections', 'n'), ('computing', 'v'), ('device', 'n'), ('claim', 'n'), ('wherein', 'n'), ('trained', 'v'), ('set', 'v'), ('parameters', 'n'), ('define', 'v'), ('piecewise', 'n'), ('linear', 'a'), ('cup', 'n'), ('function', 'n'), ('node', 'n'), ('comprise', 'n'), ('plurality', 'n'), ('output', 'n'), ('values', 'n'), ('computing', 'v'), ('device', 'n'), ('claim', 'n'), ('wherein', None), ('first', 'a'), ('sixth', 'a'), ('slopes', 'n'), ('zerowe', 'v'), ('claim', 'n'), ('system', 'n'), ('comprising', 'v'), ('memory', 'n'), ('device', 'n'), ('store', 'n'), ('input', 'n'), ('image', 'n'), ('processor', 'n'), ('including', 'v'), ('image', 'n'), ('input', 'n'), ('interface', 'v'), ('receive', 'a'), ('input', 'n'), ('image', 'n'), ('pre-processor', 'a'), ('model', 'n'), ('input', 'n'), ('image', 'n'), ('yield', 'n'), ('multi-channel', 'a'), ('image', 'n'), ('feature', 'n'), ('extractor', 'n'), ('extract', 'n'), ('set', 'v'), ('features', 'n'), ('based', 'v'), ('multi-channel', 'a'), ('image', 'n'), ('feature', 'n'), ('selector', 'n'), ('select', 'v'), ('one', None), ('features', 'v'), ('set', 'v'), ('features', 'n'), ('multi-channel', 'a'), ('image', 'n'), ('wherein', 'v'), ('one', None), ('features', 'n'), ('selected', 'v'), ('based', 'v'), ('ability', 'n'), ('differentiate', 'n'), ('features', 'n'), ('feature', 'v'), ('matcher', 'a'), ('match', 'n'), ('one', None), ('features', 'n'), ('learned', 'v'), ('feature', 'n'), ('set', 'v'), ('similarity', 'n'), ('detector', 'n'), ('determine', 'n'), ('whether', None), ('one', None), ('features', 'v'), ('meet', 'r'), ('pre-defined', 'a'), ('similarity', 'n'), ('threshold', 'n'), ('system', 'n'), ('claim', 'n'), ('wherein', None), ('pre-processor', 'a'), ('activate', 'n'), ('one', None), ('channels', 'v'), ('multi-channel', 'n'), ('image', 'n'), ('yield', 'n'), ('one', None), ('activated', 'v'), ('channels', 'n'), ('system', 'n'), ('claim', 'n'), ('wherein', 'v'), ('one', None), ('activated', 'v'), ('channels', 'n'), ('determined', 'v'), ('based', 'v'), ('ability', 'n'), ('differentiate', 'n'), ('features', 'n'), ('system', 'n'), ('claim', 'n'), ('wherein', None), ('pre-processor', 'a'), ('activate', 'n'), ('one', None), ('local', 'a'), ('patches', 'v'), ('one', None), ('activated', 'v'), ('channels', 'n'), ('system', 'n'), ('claim', 'n'), ('wherein', 'v'), ('one', None), ('local', 'a'), ('patches', 'n'), ('determined', 'v'), ('based', 'v'), ('ability', 'n'), ('differentiate', 'n'), ('features', 'n'), ('system', 'n'), ('claim', 'n'), ('wherein', 'a'), ('feature', 'n'), ('matcher', 'n'), ('utilize', 'a'), ('large-scale', 'a'), ('data', 'n'), ('learning', 'v'), ('process', 'n'), ('perform', 'n'), ('feature', 'n'), ('matching', 'v'), ('apparatus', 'n'), ('comprising', 'v'), ('image', 'n'), ('input', 'n'), ('interface', 'v'), ('receive', 'a'), ('input', 'n'), ('image', 'n'), ('pre-processor', 'a'), ('model', 'n'), ('input', 'n'), ('image', 'n'), ('yield', 'n'), ('multi-channel', 'a'), ('image', 'n'), ('feature', 'n'), ('extractor', 'n'), ('extract', 'n'), ('set', 'v'), ('features', 'n'), ('based', 'v'), ('multi-channel', 'a'), ('image', 'n'), ('feature', 'n'), ('selector', 'n'), ('select', 'v'), ('one', None), ('features', 'v'), ('set', 'v'), ('features', 'n'), ('multi-channel', 'a'), ('image', 'n'), ('wherein', 'v'), ('one', None), ('features', 'n'), ('selected', 'v'), ('based', 'v'), ('ability', 'n'), ('differentiate', 'n'), ('features', 'n'), ('feature', 'v'), ('matcher', 'a'), ('match', 'n'), ('one', None), ('features', 'n'), ('learned', 'v'), ('feature', 'n'), ('set', 'v'), ('similarity', 'n'), ('detector', 'n'), ('determine', 'n'), ('whether', None), ('one', None), ('features', 'v'), ('meet', 'r'), ('pre-defined', 'a'), ('similarity', 'n'), ('threshold', 'n'), ('apparatus', 'n'), ('claim', 'n'), ('wherein', None), ('pre-processor', 'a'), ('activate', 'n'), ('one', None), ('channels', 'v'), ('multi-channel', 'n'), ('image', 'n'), ('yield', 'n'), ('one', None), ('activated', 'v'), ('channels', 'n'), ('apparatus', 'v'), ('claim', 'n'), ('wherein', 'v'), ('one', None), ('activated', 'v'), ('channels', 'n'), ('determined', 'v'), ('based', 'v'), ('ability', 'n'), ('differentiate', 'n'), ('features', 'n'), ('apparatus', 'v'), ('claim', 'n'), ('wherein', None), ('pre-processor', 'a'), ('activate', 'n'), ('one', None), ('local', 'a'), ('patches', 'v'), ('one', None), ('activated', 'a'), ('channels', 'n'), ('apparatus', 'v'), ('claim', 'n'), ('wherein', 'v'), ('one', None), ('local', 'a'), ('patches', 'n'), ('determined', 'v'), ('based', 'v'), ('ability', 'n'), ('differentiate', 'n'), ('features', 'n'), ('apparatus', 'v'), ('claim', 'n'), ('wherein', 'n'), ('feature', 'n'), ('matcher', 'n'), ('utilize', 'a'), ('large-scale', 'a'), ('data', 'n'), ('learning', 'v'), ('process', 'n'), ('perform', 'n'), ('feature', 'n'), ('matching', 'v'), ('method', 'n'), ('comprising', 'v'), ('modeling', 'v'), ('input', 'n'), ('image', 'n'), ('yield', 'n'), ('multi-channel', 'a'), ('image', 'n'), ('extracting', 'v'), ('set', 'v'), ('features', 'n'), ('based', 'v'), ('multi-channel', 'a'), ('image', 'n'), ('selecting', 'v'), ('one', None), ('features', 'v'), ('set', 'v'), ('features', 'n'), ('multi-channel', 'a'), ('image', 'n'), ('wherein', 'v'), ('one', None), ('features', 'n'), ('selected', 'v'), ('based', 'v'), ('ability', 'n'), ('differentiate', 'n'), ('features', 'n'), ('matching', 'v'), ('one', None), ('features', 'n'), ('learned', 'v'), ('feature', 'n'), ('set', 'v'), ('determining', 'v'), ('whether', None), ('one', None), ('features', 'v'), ('meet', 'r'), ('pre-defined', 'a'), ('similarity', 'n'), ('threshold', 'n'), ('method', 'n'), ('claim', 'n'), ('wherein', None), ('modeling', 'v'), ('input', 'a'), ('image', 'n'), ('include', 'v'), ('activating', 'v'), ('one', None), ('channels', 'a'), ('multi-channel', 'a'), ('image', 'n'), ('yield', 'n'), ('one', None), ('activated', 'v'), ('channels', 'n'), ('method', 'v'), ('claim', 'n'), ('wherein', 'v'), ('one', None), ('activated', 'v'), ('channels', 'n'), ('determined', 'v'), ('based', 'v'), ('ability', 'n'), ('differentiate', 'n'), ('features', 'n'), ('method', 'v'), ('claim', 'n'), ('wherein', 'n'), ('extracting', 'v'), ('features', 'n'), ('input', 'a'), ('image', 'n'), ('include', 'v'), ('activating', 'v'), ('one', None), ('local', 'a'), ('patches', 'v'), ('one', None), ('activated', 'a'), ('channels', 'n'), ('method', 'v'), ('claim', 'n'), ('wherein', 'v'), ('one', None), ('local', 'a'), ('patches', 'n'), ('determined', 'v'), ('based', 'v'), ('ability', 'n'), ('differentiate', 'n'), ('features', 'n'), ('method', 'v'), ('claim', 'n'), ('wherein', 'n'), ('feature', 'n'), ('matcher', 'n'), ('utilizes', 'a'), ('large-scale', 'a'), ('data', 'n'), ('learning', 'v'), ('process', 'n'), ('perform', 'n'), ('feature', 'n'), ('matching', 'v'), ('least', 'a'), ('one', None), ('non-transitory', 'a'), ('computer', 'n'), ('readable', 'a'), ('storage', 'n'), ('medium', 'n'), ('comprising', 'v'), ('set', 'v'), ('instructions', 'n'), ('executed', 'v'), ('computing', 'v'), ('device', 'n'), ('cause', 'n'), ('computing', 'v'), ('device', 'n'), ('model', 'n'), ('input', 'n'), ('image', 'n'), ('yield', 'n'), ('multi-channel', 'a'), ('image', 'n'), ('extract', 'n'), ('set', 'v'), ('features', 'n'), ('based', 'v'), ('multi-channel', 'a'), ('image', 'n'), ('select', 'v'), ('one', None), ('features', 'v'), ('set', 'v'), ('features', 'n'), ('multi-channel', 'a'), ('image', 'n'), ('wherein', 'n'), ('features', 'v'), ('selected', 'v'), ('based', 'v'), ('ability', 'n'), ('differentiate', 'n'), ('features', 'n'), ('match', 'v'), ('one', None), ('features', 'n'), ('learned', 'v'), ('feature', 'n'), ('set', 'v'), ('determine', 'n'), ('whether', None), ('one', None), ('features', 'v'), ('meet', 'r'), ('pre-defined', 'a'), ('similarity', 'n'), ('threshold', 'v'), ('least', 'a'), ('one', None), ('non-transitory', 'a'), ('computer', 'n'), ('readable', 'a'), ('storage', 'n'), ('medium', 'n'), ('claim', 'n'), ('wherein', 'n'), ('instructions', 'n'), ('executed', 'v'), ('cause', 'n'), ('computing', 'v'), ('device', 'n'), ('activate', 'v'), ('one', None), ('channels', 'n'), ('multi-channel', 'a'), ('image', 'n'), ('yield', 'n'), ('one', None), ('activated', 'v'), ('channels', 'n'), ('least', 'a'), ('one', None), ('non-transitory', 'a'), ('computer', 'n'), ('readable', 'a'), ('storage', 'n'), ('medium', 'n'), ('claim', 'n'), ('wherein', 'n'), ('instructions', 'n'), ('executed', 'v'), ('cause', 'n'), ('computing', 'v'), ('device', 'n'), ('determine', 'n'), ('one', None), ('activated', 'v'), ('channels', 'n'), ('based', 'v'), ('ability', 'n'), ('differentiate', 'n'), ('features', 'n'), ('least', 'v'), ('one', None), ('non-transitory', 'a'), ('computer', 'n'), ('readable', 'a'), ('storage', 'n'), ('medium', 'n'), ('claim', 'n'), ('wherein', None), ('extracting', 'v'), ('features', 'n'), ('input', 'a'), ('image', 'n'), ('include', 'v'), ('activating', 'v'), ('one', None), ('local', 'a'), ('patches', 'v'), ('one', None), ('activated', 'a'), ('channels', 'n'), ('least', 'a'), ('one', None), ('non-transitory', 'a'), ('computer', 'n'), ('readable', 'a'), ('storage', 'n'), ('medium', 'n'), ('claim', 'n'), ('wherein', None), ('one', None), ('local', 'a'), ('patches', 'n'), ('determined', 'v'), ('based', 'v'), ('ability', 'n'), ('differentiate', 'n'), ('features', 'n'), ('least', 'v'), ('one', None), ('non-transitory', 'a'), ('computer', 'n'), ('readable', 'a'), ('storage', 'n'), ('medium', 'n'), ('claim', 'n'), ('wherein', 'a'), ('feature', 'n'), ('matcher', 'n'), ('utilize', 'a'), ('large-scale', 'a'), ('data', 'n'), ('learning', 'v'), ('process', 'n'), ('perform', 'n'), ('feature', 'n'), ('matching', 'v'), ('apparatus', 'n'), ('comprising', 'v'), ('means', 'n'), ('modeling', 'v'), ('input', 'n'), ('image', 'n'), ('yield', 'n'), ('multi-channel', 'a'), ('image', 'n'), ('means', 'v'), ('extracting', 'v'), ('set', 'v'), ('features', 'n'), ('based', 'v'), ('multi-channel', 'a'), ('image', 'n'), ('means', 'v'), ('selecting', 'v'), ('one', None), ('features', 'v'), ('set', 'v'), ('features', 'n'), ('multi-channel', 'a'), ('image', 'n'), ('wherein', 'v'), ('one', None), ('features', 'n'), ('selected', 'v'), ('based', 'v'), ('ability', 'n'), ('differentiate', 'n'), ('features', 'n'), ('means', 'v'), ('matching', 'v'), ('one', None), ('features', 'n'), ('learned', 'v'), ('feature', 'n'), ('set', 'v'), ('means', 'v'), ('determining', 'v'), ('whether', None), ('one', None), ('features', 'v'), ('meet', 'r'), ('pre-defined', 'a'), ('similarity', 'n'), ('threshold', 'n'), ('method', 'n'), ('controlling', 'v'), ('terminal', 'a'), ('terminal', 'a'), ('comprising', 'v'), ('capturing', 'v'), ('apparatus', 'n'), ('least', 'a'), ('one', None), ('processor', 'n'), ('method', 'n'), ('comprising', 'v'), ('acquiring', 'v'), ('capturing', 'v'), ('apparatus', 'a'), ('image', 'n'), ('obtaining', 'v'), ('least', 'a'), ('one', None), ('processor', 'n'), ('motion', 'n'), ('parameter', 'n'), ('terminal', 'a'), ('motion', 'n'), ('parameter', 'n'), ('comprising', 'v'), ('least', 'a'), ('one', None), ('motion', 'n'), ('frequency', 'n'), ('motion', 'n'), ('time', 'n'), ('two', None), ('parameters', 'n'), ('among', None), ('acceleration', 'n'), ('angular', 'a'), ('velocity', 'n'), ('motion', 'n'), ('amplitude', 'n'), ('motion', 'n'), ('frequency', 'n'), ('motion', 'n'), ('time', 'n'), ('transmitting', 'v'), ('least', 'a'), ('one', None), ('processor', 'n'), ('parameter', 'n'), ('threshold', 'v'), ('obtaining', 'v'), ('request', 'n'), ('data', 'n'), ('management', 'n'), ('server', 'r'), ('parameter', 'r'), ('threshold', 'a'), ('obtaining', 'v'), ('request', 'n'), ('comprising', 'v'), ('configuration', 'n'), ('information', 'n'), ('terminal', 'n'), ('receiving', 'n'), ('corresponding', 'v'), ('preset', 'n'), ('thresholds', 'n'), ('correspond', 'n'), ('configuration', 'n'), ('information', 'n'), ('response', 'n'), ('parameter', 'n'), ('threshold', 'v'), ('obtaining', 'v'), ('request', 'n'), ('comparing', 'v'), ('two', None), ('parameters', 'n'), ('corresponding', 'v'), ('preset', 'n'), ('thresholds', 'n'), ('controlling', 'v'), ('least', 'a'), ('one', None), ('processor', 'n'), ('perform', 'n'), ('image', 'n'), ('processing', 'n'), ('acquired', 'v'), ('image', 'n'), ('based', 'v'), ('least', 'a'), ('one', None), ('two', None), ('parameters', 'n'), ('motion', 'v'), ('parameter', 'r'), ('greater', 'a'), ('corresponding', 'v'), ('preset', 'n'), ('threshold', 'n'), ('based', 'v'), ('two', None), ('parameters', 'n'), ('motion', 'v'), ('parameter', 'n'), ('respectively', 'r'), ('greater', 'a'), ('corresponding', 'v'), ('preset', 'n'), ('thresholds', 'n'), ('wherein', 'v'), ('acquiring', 'v'), ('comprises', 'n'), ('acquiring', 'v'), ('image', 'n'), ('real', 'a'), ('time', 'n'), ('obtaining', 'v'), ('comprises', 'n'), ('obtaining', 'v'), ('motion', 'n'), ('parameter', 'n'), ('terminal', 'a'), ('real', 'a'), ('time', 'n'), ('method', 'n'), ('comprising', 'v'), ('response', 'n'), ('least', 'a'), ('one', None), ('two', None), ('parameters', 'n'), ('motion', 'v'), ('parameter', 'r'), ('greater', 'a'), ('corresponding', 'v'), ('preset', 'n'), ('threshold', 'v'), ('obtaining', 'v'), ('motion', 'n'), ('parameter', None), ('terminal', 'a'), ('response', 'n'), ('two', None), ('parameters', 'n'), ('motion', 'v'), ('parameter', 'n'), ('obtained', 'v'), ('latest', 'a'), ('time', 'n'), ('less', None), ('equal', 'a'), ('corresponding', 'n'), ('preset', 'n'), ('thresholds', 'n'), ('performing', 'v'), ('image', 'n'), ('processing', 'n'), ('image', 'n'), ('acquired', 'v'), ('latest', 'a'), ('time', 'n'), ('method', 'n'), ('according', 'v'), ('claim', 'n'), ('wherein', 'n'), ('acquiring', 'v'), ('comprises', 'n'), ('controlling', 'v'), ('least', 'a'), ('one', None), ('processor', 'n'), ('turn', 'n'), ('capturing', 'v'), ('apparatus', 'n'), ('based', 'v'), ('face', 'n'), ('recognition', 'n'), ('instruction', 'n'), ('acquiring', 'v'), ('capturing', 'v'), ('apparatus', 'a'), ('face', 'n'), ('image', 'n'), ('capturing', 'v'), ('apparatus', 'n'), ('turned', 'v'), ('method', 'a'), ('according', 'v'), ('claim', 'n'), ('wherein', 'n'), ('controlling', 'v'), ('perform', 'a'), ('image', 'n'), ('processing', 'n'), ('comprises', 'v'), ('skipping', 'v'), ('performing', 'v'), ('face', 'n'), ('recognition', 'n'), ('acquired', 'v'), ('face', 'n'), ('image', 'n'), ('based', 'v'), ('least', 'a'), ('one', None), ('two', None), ('parameters', 'n'), ('motion', 'v'), ('parameter', 'r'), ('greater', 'a'), ('corresponding', 'v'), ('preset', 'n'), ('threshold', 'n'), ('based', 'v'), ('two', None), ('parameters', 'n'), ('motion', 'v'), ('parameter', 'n'), ('respectively', 'r'), ('greater', 'a'), ('corresponding', 'v'), ('preset', 'n'), ('thresholds', 'n'), ('method', 'v'), ('according', 'v'), ('claim', 'n'), ('wherein', 'n'), ('obtaining', 'v'), ('comprises', 'n'), ('least', 'a'), ('one', None), ('obtaining', 'v'), ('acceleration', 'n'), ('terminal', 'n'), ('using', 'v'), ('acceleration', 'n'), ('sensor', 'n'), ('obtaining', 'v'), ('angular', 'a'), ('velocity', 'n'), ('terminal', 'n'), ('using', 'v'), ('gyro', 'a'), ('sensor', 'n'), ('method', 'n'), ('according', 'v'), ('claim', 'n'), ('wherein', 'n'), ('transmitting', 'v'), ('comprises', 'n'), ('transmitting', 'v'), ('parameter', 'n'), ('threshold', 'v'), ('obtaining', 'v'), ('request', 'n'), ('data', 'n'), ('management', 'n'), ('server', 'n'), ('according', 'v'), ('preset', 'a'), ('time', 'n'), ('period', 'n'), ('method', 'n'), ('according', 'v'), ('claim', 'n'), ('comprising', 'v'), ('generating', 'v'), ('prompt', 'a'), ('information', 'n'), ('based', 'v'), ('least', 'a'), ('one', None), ('two', None), ('parameters', 'n'), ('motion', 'v'), ('parameter', 'r'), ('greater', 'a'), ('corresponding', 'v'), ('preset', 'n'), ('threshold', 'v'), ('prompt', 'a'), ('information', 'n'), ('used', 'v'), ('prompting', 'v'), ('terminal', 'a'), ('stop', 'n'), ('moving', 'v'), ('method', 'a'), ('according', 'v'), ('claim', 'n'), ('wherein', 'n'), ('motion', 'n'), ('parameter', 'n'), ('comprises', 'v'), ('motion', 'n'), ('frequency', 'n'), ('motion', 'n'), ('time', 'n'), ('terminal', 'a'), ('comprising', 'v'), ('capturing', 'v'), ('apparatus', 'n'), ('least', 'a'), ('one', None), ('memory', 'n'), ('configured', 'v'), ('store', 'n'), ('program', 'n'), ('code', 'n'), ('least', 'a'), ('one', None), ('processor', 'n'), ('configured', 'v'), ('access', 'n'), ('least', 'a'), ('one', None), ('memory', 'n'), ('operate', 'n'), ('according', 'v'), ('program', 'n'), ('code', 'n'), ('program', 'n'), ('code', 'n'), ('comprising', 'v'), ('motion', 'n'), ('parameter', 'n'), ('obtaining', 'v'), ('code', 'n'), ('configured', 'v'), ('cause', 'n'), ('least', 'a'), ('one', None), ('processor', 'n'), ('acquire', 'v'), ('image', 'n'), ('using', 'v'), ('capturing', 'v'), ('apparatus', 'n'), ('obtain', 'v'), ('motion', 'n'), ('parameter', 'n'), ('terminal', 'a'), ('motion', 'n'), ('parameter', 'n'), ('comprising', 'v'), ('least', 'a'), ('one', None), ('motion', 'n'), ('frequency', 'n'), ('motion', 'n'), ('time', 'n'), ('two', None), ('parameters', 'n'), ('among', None), ('acceleration', 'n'), ('angular', 'a'), ('velocity', 'n'), ('motion', 'n'), ('amplitude', 'n'), ('motion', 'n'), ('frequency', 'n'), ('motion', 'n'), ('time', 'n'), ('request', 'n'), ('transmitting', 'v'), ('code', 'n'), ('configured', 'v'), ('cause', 'n'), ('least', 'a'), ('one', None), ('processor', 'n'), ('transmit', 'n'), ('parameter', 'n'), ('threshold', 'v'), ('obtaining', 'v'), ('request', 'n'), ('data', 'n'), ('management', 'n'), ('server', 'r'), ('parameter', 'r'), ('threshold', 'a'), ('obtaining', 'v'), ('request', 'n'), ('comprising', 'v'), ('configuration', 'n'), ('information', 'n'), ('terminal', 'n'), ('parameter', 'n'), ('threshold', 'v'), ('receiving', 'v'), ('code', 'n'), ('configured', 'v'), ('cause', 'n'), ('least', 'a'), ('one', None), ('processor', 'n'), ('receive', 'n'), ('corresponding', 'v'), ('preset', 'n'), ('thresholds', 'n'), ('correspond', 'n'), ('configuration', 'n'), ('information', 'n'), ('response', 'n'), ('parameter', 'n'), ('threshold', 'v'), ('obtaining', 'v'), ('request', 'n'), ('comparing', 'v'), ('code', 'n'), ('configured', 'v'), ('cause', 'n'), ('least', 'a'), ('one', None), ('processor', 'n'), ('compare', 'n'), ('two', None), ('parameters', 'n'), ('corresponding', 'v'), ('preset', 'n'), ('thresholds', 'n'), ('control', 'n'), ('code', 'n'), ('configured', 'v'), ('cause', 'n'), ('least', 'a'), ('one', None), ('processor', 'n'), ('perform', 'n'), ('image', 'n'), ('processing', 'n'), ('acquired', 'v'), ('image', 'n'), ('based', 'v'), ('least', 'a'), ('one', None), ('two', None), ('parameters', 'n'), ('motion', 'v'), ('parameter', 'r'), ('greater', 'a'), ('corresponding', 'v'), ('preset', 'n'), ('threshold', 'n'), ('based', 'v'), ('two', None), ('parameters', 'n'), ('motion', 'v'), ('parameter', 'n'), ('respectively', 'r'), ('greater', 'a'), ('corresponding', 'v'), ('preset', 'n'), ('thresholds', 'n'), ('wherein', 'v'), ('motion', 'n'), ('parameter', 'n'), ('obtaining', 'v'), ('code', 'n'), ('causes', 'n'), ('least', 'v'), ('one', None), ('processor', 'n'), ('acquire', 'v'), ('image', 'n'), ('real', 'a'), ('time', 'n'), ('obtain', 'v'), ('motion', 'n'), ('parameter', None), ('terminal', 'a'), ('real', 'a'), ('time', 'n'), ('response', 'n'), ('least', 'a'), ('one', None), ('two', None), ('parameters', 'n'), ('motion', 'v'), ('parameter', 'r'), ('greater', 'a'), ('corresponding', 'v'), ('preset', 'v'), ('threshold', 'a'), ('obtain', 'v'), ('motion', 'n'), ('parameter', 'n'), ('terminal', 'a'), ('wherein', 'n'), ('control', 'n'), ('code', 'n'), ('causes', 'v'), ('least', 'a'), ('one', None), ('processor', 'n'), ('response', 'n'), ('two', None), ('parameters', 'n'), ('motion', 'v'), ('parameter', 'n'), ('obtained', 'v'), ('latest', 'a'), ('time', 'n'), ('less', None), ('equal', 'a'), ('corresponding', 'n'), ('preset', 'n'), ('thresholds', 'n'), ('perform', 'v'), ('image', 'n'), ('processing', 'n'), ('image', 'n'), ('acquired', 'v'), ('latest', 'a'), ('time', 'n'), ('terminal', 'a'), ('according', 'v'), ('claim', 'n'), ('wherein', 'n'), ('program', 'n'), ('code', 'n'), ('comprises', 'v'), ('face', 'v'), ('instruction', 'n'), ('receiving', 'v'), ('code', 'n'), ('configured', 'v'), ('cause', 'n'), ('least', 'a'), ('one', None), ('processor', 'n'), ('receive', 'a'), ('face', 'n'), ('recognition', 'n'), ('instruction', 'n'), ('wherein', None), ('motion', 'n'), ('parameter', 'n'), ('obtaining', 'v'), ('code', 'n'), ('causes', 'n'), ('least', 'v'), ('one', None), ('processor', 'n'), ('control', 'n'), ('according', 'v'), ('face', 'n'), ('recognition', 'n'), ('instruction', 'n'), ('capturing', 'v'), ('apparatus', 'n'), ('turn', 'n'), ('acquire', 'v'), ('face', 'n'), ('image', 'n'), ('using', 'v'), ('capturing', 'v'), ('apparatus', 'n'), ('capturing', 'v'), ('apparatus', 'n'), ('turned', 'v'), ('wherein', 'a'), ('control', 'n'), ('code', 'n'), ('causes', 'v'), ('least', 'a'), ('one', None), ('processor', 'n'), ('skip', 'n'), ('performing', 'v'), ('face', 'n'), ('recognition', 'n'), ('acquired', 'v'), ('face', 'n'), ('image', 'n'), ('based', 'v'), ('least', 'a'), ('one', None), ('two', None), ('parameters', 'n'), ('motion', 'v'), ('parameter', 'r'), ('greater', 'a'), ('corresponding', 'v'), ('preset', 'n'), ('threshold', 'n'), ('based', 'v'), ('two', None), ('parameters', 'n'), ('motion', 'v'), ('parameter', 'n'), ('respectively', 'r'), ('greater', 'a'), ('corresponding', 'v'), ('preset', 'n'), ('thresholds', 'n'), ('terminal', 'a'), ('according', 'v'), ('claim', 'n'), ('wherein', 'n'), ('request', 'n'), ('transmitting', 'v'), ('code', 'n'), ('causes', 'n'), ('least', 'v'), ('one', None), ('processor', 'n'), ('transmit', 'n'), ('parameter', 'n'), ('threshold', 'v'), ('obtaining', 'v'), ('request', 'n'), ('data', 'n'), ('management', 'n'), ('server', 'n'), ('according', 'v'), ('preset', 'a'), ('time', 'n'), ('period', 'n'), ('terminal', 'a'), ('according', 'v'), ('claim', 'n'), ('wherein', 'n'), ('program', 'n'), ('code', 'n'), ('comprises', 'v'), ('prompt', 'a'), ('information', 'n'), ('generation', 'n'), ('code', 'n'), ('configured', 'v'), ('cause', 'n'), ('least', 'a'), ('one', None), ('processor', 'n'), ('generate', 'n'), ('prompt', 'n'), ('information', 'n'), ('based', 'v'), ('least', 'a'), ('one', None), ('two', None), ('parameters', 'n'), ('motion', 'v'), ('parameter', 'r'), ('greater', 'a'), ('corresponding', 'v'), ('preset', 'n'), ('threshold', 'v'), ('prompt', 'a'), ('information', 'n'), ('used', 'v'), ('prompting', 'v'), ('terminal', 'a'), ('stop', 'n'), ('moving', 'v'), ('terminal', 'a'), ('according', 'v'), ('claim', 'n'), ('wherein', 'n'), ('motion', 'n'), ('parameter', 'n'), ('comprises', 'v'), ('motion', 'n'), ('frequency', 'n'), ('motion', 'n'), ('time', 'n'), ('non-transitory', 'a'), ('computer-readable', 'a'), ('storage', 'n'), ('medium', 'n'), ('storing', 'v'), ('machine', 'n'), ('instruction', 'n'), ('executed', 'v'), ('one', None), ('processors', 'n'), ('causes', 'v'), ('one', None), ('processors', 'n'), ('perform', 'v'), ('obtaining', 'v'), ('image', 'n'), ('acquired', 'v'), ('capturing', 'v'), ('apparatus', 'n'), ('obtaining', 'v'), ('motion', 'n'), ('parameter', 'n'), ('terminal', 'a'), ('terminal', 'n'), ('comprising', 'v'), ('capturing', 'v'), ('apparatus', 'a'), ('motion', 'n'), ('parameter', 'n'), ('comprising', 'v'), ('least', 'a'), ('one', None), ('motion', 'n'), ('frequency', 'n'), ('motion', 'n'), ('time', 'n'), ('two', None), ('parameters', 'n'), ('among', None), ('acceleration', 'n'), ('angular', 'a'), ('velocity', 'n'), ('motion', 'n'), ('amplitude', 'n'), ('motion', 'n'), ('frequency', 'n'), ('motion', 'n'), ('time', 'n'), ('transmitting', 'v'), ('parameter', 'n'), ('threshold', 'v'), ('obtaining', 'v'), ('request', 'n'), ('data', 'n'), ('management', 'n'), ('server', 'r'), ('parameter', 'r'), ('threshold', 'a'), ('obtaining', 'v'), ('request', 'n'), ('comprising', 'v'), ('configuration', 'n'), ('information', 'n'), ('terminal', 'n'), ('receiving', 'n'), ('corresponding', 'v'), ('preset', 'n'), ('thresholds', 'n'), ('correspond', 'n'), ('configuration', 'n'), ('information', 'n'), ('response', 'n'), ('parameter', 'n'), ('threshold', 'v'), ('obtaining', 'v'), ('request', 'n'), ('comparing', 'v'), ('two', None), ('parameters', 'n'), ('corresponding', 'v'), ('preset', 'n'), ('thresholds', 'n'), ('controlling', 'v'), ('perform', 'a'), ('image', 'n'), ('processing', 'n'), ('acquired', 'v'), ('image', 'n'), ('based', 'v'), ('least', 'a'), ('one', None), ('two', None), ('parameters', 'n'), ('motion', 'v'), ('parameter', 'r'), ('greater', 'a'), ('corresponding', 'v'), ('preset', 'n'), ('threshold', 'n'), ('based', 'v'), ('two', None), ('parameters', 'n'), ('motion', 'v'), ('parameter', 'n'), ('respectively', 'r'), ('greater', 'a'), ('corresponding', 'v'), ('preset', 'n'), ('thresholds', 'n'), ('wherein', 'v'), ('acquiring', 'v'), ('comprises', 'n'), ('acquiring', 'v'), ('image', 'n'), ('real', 'a'), ('time', 'n'), ('obtaining', 'v'), ('comprises', 'n'), ('obtaining', 'v'), ('motion', 'n'), ('parameter', 'n'), ('terminal', 'a'), ('real', 'a'), ('time', 'n'), ('method', 'n'), ('comprising', 'v'), ('response', 'n'), ('least', 'a'), ('one', None), ('two', None), ('parameters', 'n'), ('motion', 'v'), ('parameter', 'r'), ('greater', 'a'), ('corresponding', 'v'), ('preset', 'n'), ('threshold', 'v'), ('obtaining', 'v'), ('motion', 'n'), ('parameter', None), ('terminal', 'a'), ('response', 'n'), ('two', None), ('parameters', 'n'), ('motion', 'v'), ('parameter', 'n'), ('obtained', 'v'), ('latest', 'a'), ('time', 'n'), ('less', None), ('equal', 'a'), ('corresponding', 'n'), ('preset', 'n'), ('thresholds', 'n'), ('performing', 'v'), ('image', 'n'), ('processing', 'n'), ('image', 'n'), ('acquired', 'v'), ('latest', 'a'), ('time', 'n'), ('non-transitory', 'a'), ('computer-readable', 'a'), ('storage', 'n'), ('medium', 'n'), ('according', 'v'), ('claim', 'n'), ('wherein', 'n'), ('acquired', 'v'), ('image', 'n'), ('face', 'n'), ('image', 'n'), ('image', 'n'), ('processing', 'n'), ('comprises', 'v'), ('performing', 'v'), ('face', 'n'), ('recognition', 'n'), ('non-transitory', 'a'), ('computer-readable', 'a'), ('storage', 'n'), ('medium', 'n'), ('according', 'v'), ('claim', 'n'), ('wherein', 'n'), ('obtaining', 'v'), ('motion', 'n'), ('parameter', 'n'), ('comprises', 'v'), ('least', 'a'), ('one', None), ('obtaining', 'v'), ('acceleration', 'n'), ('terminal', 'n'), ('using', 'v'), ('acceleration', 'n'), ('sensor', 'n'), ('obtaining', 'v'), ('angular', 'a'), ('velocity', 'n'), ('terminal', 'n'), ('using', 'v'), ('gyro', 'a'), ('sensor', 'a'), ('non-transitory', 'a'), ('computer-readable', 'a'), ('storage', 'n'), ('medium', 'n'), ('according', 'v'), ('claim', 'n'), ('wherein', 'n'), ('motion', 'n'), ('parameter', 'n'), ('comprises', 'v'), ('motion', 'n'), ('frequency', 'n'), ('motion', 'n'), ('time', 'n'), ('method', 'n'), ('processing', 'v'), ('drive-through', 'a'), ('order', 'n'), ('method', 'n'), ('comprising', 'v'), ('receiving', 'v'), ('customer', 'n'), ('information', 'n'), ('detected', 'v'), ('vision', 'n'), ('recognition', 'n'), ('providing', 'v'), ('product', 'n'), ('information', 'n'), ('customer', 'n'), ('based', 'v'), ('customer', 'n'), ('information', 'n'), ('processing', 'v'), ('product', 'n'), ('order', 'n'), ('customer', 'n'), ('method', 'n'), ('according', 'v'), ('claim', 'n'), ('wherein', 'n'), ('receiving', 'v'), ('customer', 'n'), ('information', 'n'), ('comprises', 'v'), ('least', 'a'), ('one', None), ('receiving', 'v'), ('customer', 'n'), ('information', 'n'), ('associated', 'v'), ('vehicle', 'n'), ('information', 'n'), ('detected', 'v'), ('vehicle', 'n'), ('recognition', 'n'), ('receiving', 'v'), ('customer', 'n'), ('information', 'n'), ('associated', 'v'), ('identification', 'n'), ('information', 'n'), ('detected', 'v'), ('face', 'n'), ('recognition', 'n'), ('method', 'n'), ('according', 'v'), ('claim', 'n'), ('comprising', 'v'), ('determining', 'v'), ('whether', None), ('customer', 'n'), ('pre-order', 'n'), ('customer', 'n'), ('based', 'v'), ('customer', 'n'), ('information', 'n'), ('wherein', 'n'), ('customer', 'n'), ('determined', 'v'), ('pre-order', 'a'), ('customer', 'n'), ('providing', 'v'), ('product', 'n'), ('information', 'n'), ('based', 'v'), ('customer', 'n'), ('information', 'n'), ('comprises', 'v'), ('providing', 'v'), ('pre-order', 'a'), ('information', 'n'), ('using', 'v'), ('least', 'a'), ('one', None), ('audio', 'a'), ('video', 'n'), ('processing', 'v'), ('product', 'n'), ('order', 'n'), ('customer', 'n'), ('comprises', 'v'), ('providing', 'v'), ('information', 'n'), ('promptly', 'r'), ('guiding', 'v'), ('vehicle', 'n'), ('pickup', 'n'), ('stand', 'v'), ('using', 'v'), ('least', 'a'), ('one', None), ('audio', 'n'), ('video', 'n'), ('providing', 'v'), ('information', 'n'), ('additional', 'a'), ('order', 'n'), ('available', 'a'), ('method', 'n'), ('according', 'v'), ('claim', 'n'), ('wherein', 'n'), ('product', 'n'), ('information', 'n'), ('based', 'v'), ('customer', 'n'), ('information', 'n'), ('comprises', 'v'), ('recently', 'r'), ('ordered', 'v'), ('product', 'n'), ('component', 'n'), ('frequently', 'r'), ('ordered', 'v'), ('product', 'n'), ('component', 'n'), ('order', 'n'), ('history', 'n'), ('customer', 'n'), ('information', 'n'), ('method', 'n'), ('according', 'v'), ('claim', 'n'), ('wherein', 'n'), ('receiving', 'v'), ('customer', 'n'), ('information', 'n'), ('comprises', 'v'), ('receiving', 'v'), ('information', 'n'), ('age', 'n'), ('gender', 'n'), ('passenger', 'n'), ('detected', 'v'), ('face', 'n'), ('recognition', 'n'), ('providing', 'v'), ('product', 'n'), ('information', 'n'), ('customer', 'n'), ('based', 'v'), ('customer', 'n'), ('information', 'n'), ('comprises', 'v'), ('providing', 'v'), ('recommended', 'v'), ('menu', 'a'), ('information', 'n'), ('differentiated', 'v'), ('according', 'v'), ('age', 'n'), ('gender', 'n'), ('method', 'n'), ('according', 'v'), ('claim', 'n'), ('wherein', 'n'), ('processing', 'v'), ('product', 'n'), ('order', 'n'), ('customer', 'n'), ('comprises', 'v'), ('determining', 'v'), ('product', 'n'), ('component', 'n'), ('past', 'a'), ('order', 'n'), ('history', 'n'), ('component', 'n'), ('modified', 'v'), ('product', 'n'), ('component', 'n'), ('product', 'n'), ('order', 'n'), ('method', 'n'), ('according', 'v'), ('claim', 'n'), ('wherein', 'n'), ('processing', 'v'), ('product', 'n'), ('order', 'n'), ('customer', 'n'), ('comprises', 'v'), ('paying', 'v'), ('product', 'n'), ('price', 'n'), ('according', 'v'), ('biometrics-based', 'a'), ('authentication', 'n'), ('communication', 'n'), ('system', 'n'), ('vehicle', 'n'), ('mobile', 'a'), ('terminal', 'n'), ('method', 'n'), ('according', 'v'), ('claim', 'n'), ('wherein', 'n'), ('processing', 'v'), ('product', 'n'), ('order', 'n'), ('customer', 'n'), ('comprises', 'v'), ('issuing', 'v'), ('payment', 'n'), ('number', 'n'), ('divided', 'v'), ('payment', 'n'), ('performing', 'v'), ('divided', 'v'), ('payments', 'n'), ('according', 'v'), ('payment', 'n'), ('requests', 'n'), ('plurality', 'v'), ('mobile', 'a'), ('terminals', 'n'), ('payment', 'n'), ('numbers', 'n'), ('inputted', 'v'), ('method', 'a'), ('according', 'v'), ('claim', 'n'), ('wherein', 'n'), ('processing', 'v'), ('product', 'n'), ('order', 'n'), ('customer', 'n'), ('comprises', 'v'), ('accumulating', 'v'), ('mileage', 'n'), ('account', 'n'), ('corresponding', 'v'), ('mobile', 'a'), ('terminal', 'a'), ('undergoing', 'a'), ('payment', 'n'), ('method', 'n'), ('according', 'v'), ('claim', 'n'), ('wherein', 'n'), ('processing', 'v'), ('product', 'n'), ('order', 'n'), ('customer', 'n'), ('comprises', 'v'), ('suggesting', 'v'), ('takeout', 'r'), ('packaging', 'v'), ('method', 'n'), ('according', 'v'), ('temperature', 'n'), ('product', 'n'), ('atmospheric', 'a'), ('temperature', 'n'), ('weather', 'n'), ('vehicle', 'n'), ('type', 'n'), ('apparatus', 'n'), ('configured', 'v'), ('process', 'a'), ('drive-through', 'a'), ('order', 'n'), ('apparatus', 'n'), ('comprising', 'v'), ('transceiver', 'r'), ('configured', 'v'), ('receive', 'a'), ('customer', 'n'), ('information', 'n'), ('detected', 'v'), ('vision', 'n'), ('recognition', 'n'), ('digital', 'a'), ('signage', 'n'), ('configured', 'v'), ('provide', 'a'), ('product', 'n'), ('information', 'n'), ('customer', 'n'), ('based', 'v'), ('customer', 'n'), ('information', 'n'), ('processor', 'n'), ('configured', 'v'), ('process', 'a'), ('product', 'n'), ('order', 'n'), ('customer', 'n'), ('apparatus', 'n'), ('according', 'v'), ('claim', 'n'), ('wherein', 'n'), ('transceiver', None), ('receives', 'v'), ('least', 'a'), ('one', None), ('customer', 'n'), ('information', 'n'), ('associated', 'v'), ('vehicle', 'n'), ('information', 'n'), ('detected', 'v'), ('vehicle', 'n'), ('recognition', 'n'), ('customer', 'n'), ('information', 'n'), ('associated', 'v'), ('identification', 'n'), ('information', 'n'), ('detected', 'v'), ('face', 'n'), ('recognition', 'n'), ('apparatus', None), ('according', 'v'), ('claim', 'n'), ('wherein', 'n'), ('processor', 'n'), ('configured', 'v'), ('determine', 'n'), ('whether', None), ('customer', 'n'), ('pre-order', 'n'), ('customer', 'n'), ('based', 'v'), ('customer', 'n'), ('information', 'n'), ('customer', 'n'), ('determined', 'v'), ('pre-order', 'a'), ('customer', 'n'), ('perform', 'n'), ('control', 'n'), ('operation', 'n'), ('provide', None), ('pre-order', 'a'), ('information', 'n'), ('control', 'n'), ('digital', 'a'), ('signage', 'n'), ('output', 'n'), ('information', 'n'), ('promptly', 'r'), ('guiding', 'v'), ('vehicle', 'n'), ('pickup', 'n'), ('stand', 'v'), ('provide', 'a'), ('information', 'n'), ('additional', 'a'), ('order', 'n'), ('available', 'a'), ('apparatus', 'n'), ('according', 'v'), ('claim', 'n'), ('wherein', 'n'), ('product', 'n'), ('information', 'n'), ('based', 'v'), ('customer', 'n'), ('information', 'n'), ('comprises', 'v'), ('recently', 'r'), ('ordered', 'v'), ('product', 'n'), ('component', 'n'), ('frequently', 'r'), ('ordered', 'v'), ('product', 'n'), ('component', 'n'), ('order', 'n'), ('history', 'n'), ('customer', 'n'), ('information', 'n'), ('apparatus', 'n'), ('according', 'v'), ('claim', 'n'), ('wherein', 'n'), ('transceiver', 'r'), ('configured', 'v'), ('receive', 'a'), ('information', 'n'), ('age', 'n'), ('gender', 'n'), ('passenger', 'n'), ('detected', 'v'), ('face', 'n'), ('recognition', 'n'), ('processor', 'n'), ('configured', 'v'), ('control', 'n'), ('digital', 'a'), ('signage', 'n'), ('provide', 'n'), ('recommended', 'v'), ('menu', 'a'), ('information', 'n'), ('differentiated', 'v'), ('according', 'v'), ('age', 'n'), ('gender', 'n'), ('apparatus', 'n'), ('according', 'v'), ('claim', 'n'), ('wherein', 'n'), ('processor', 'n'), ('configured', 'v'), ('determine', 'a'), ('product', 'n'), ('component', 'n'), ('past', 'a'), ('order', 'n'), ('history', 'n'), ('component', 'n'), ('modified', 'v'), ('product', 'n'), ('component', 'n'), ('product', 'n'), ('order', 'n'), ('apparatus', 'n'), ('according', 'v'), ('claim', 'n'), ('wherein', 'n'), ('processor', 'n'), ('configured', 'v'), ('pay', 'a'), ('product', 'n'), ('price', 'n'), ('according', 'v'), ('biometrics-based', 'a'), ('authentication', 'n'), ('communication', 'n'), ('system', 'n'), ('vehicle', 'n'), ('mobile', 'a'), ('terminal', 'n'), ('apparatus', 'n'), ('according', 'v'), ('claim', 'n'), ('wherein', 'n'), ('processor', 'n'), ('configured', 'v'), ('issue', 'n'), ('payment', 'n'), ('number', 'n'), ('divided', 'v'), ('payment', 'n'), ('perform', 'n'), ('divided', 'v'), ('payments', 'n'), ('according', 'v'), ('requests', 'n'), ('plurality', 'n'), ('mobile', 'n'), ('terminals', 'n'), ('payment', 'n'), ('numbers', 'n'), ('inputted', 'v'), ('apparatus', 'a'), ('according', 'v'), ('claim', 'n'), ('wherein', 'n'), ('processor', 'n'), ('configured', 'v'), ('accumulate', 'a'), ('mileage', 'n'), ('account', 'n'), ('corresponding', 'v'), ('mobile', 'a'), ('terminal', 'a'), ('undergoing', 'a'), ('payment', 'n'), ('apparatus', 'n'), ('according', 'v'), ('claim', 'n'), ('wherein', 'n'), ('processor', 'n'), ('configured', 'v'), ('control', 'n'), ('digital', 'a'), ('signage', 'n'), ('suggest', 'v'), ('takeout', None), ('packaging', 'n'), ('method', 'n'), ('according', 'v'), ('temperature', 'n'), ('product', 'n'), ('atmospheric', 'a'), ('temperature', 'n'), ('weather', 'n'), ('vehicle', 'n'), ('type', 'a'), ('image', 'n'), ('information', 'n'), ('processing', 'v'), ('method', 'n'), ('performed', 'v'), ('computing', 'v'), ('device', 'n'), ('one', None), ('processors', 'n'), ('memory', 'n'), ('storing', 'v'), ('plurality', 'n'), ('programs', 'n'), ('executed', 'v'), ('one', None), ('processors', 'n'), ('method', 'v'), ('comprising', 'v'), ('identifying', 'v'), ('using', 'v'), ('face', 'n'), ('recognition', 'n'), ('one', None), ('faces', 'v'), ('face', 'n'), ('corresponding', 'v'), ('respective', 'a'), ('person', 'n'), ('captured', 'v'), ('first', 'a'), ('image', 'n'), ('identified', 'v'), ('face', 'n'), ('extracting', 'v'), ('set', 'v'), ('profile', 'a'), ('parameters', 'n'), ('corresponding', 'v'), ('person', 'n'), ('first', 'a'), ('image', 'n'), ('selecting', 'v'), ('plurality', 'n'), ('image', 'n'), ('tiles', 'n'), ('first', 'r'), ('image', 'n'), ('tile', 'n'), ('matches', 'n'), ('face', 'v'), ('corresponding', 'v'), ('person', 'n'), ('first', 'a'), ('image', 'n'), ('accordance', 'n'), ('predefined', 'v'), ('correspondence', 'n'), ('set', 'v'), ('profile', 'a'), ('parameters', 'n'), ('corresponding', 'v'), ('person', 'n'), ('set', 'v'), ('pre-stored', 'a'), ('description', 'n'), ('parameters', 'n'), ('first', 'a'), ('image', 'n'), ('tile', 'n'), ('generating', 'v'), ('second', 'a'), ('image', 'n'), ('covering', 'v'), ('faces', 'v'), ('respective', 'a'), ('persons', 'n'), ('first', 'a'), ('image', 'n'), ('corresponding', 'v'), ('first', 'a'), ('image', 'n'), ('tiles', 'n'), ('sharing', 'v'), ('first', 'a'), ('image', 'n'), ('second', 'a'), ('image', 'n'), ('predefined', 'v'), ('order', 'n'), ('via', None), ('group', 'n'), ('chat', None), ('session', 'n'), ('method', 'n'), ('claim', 'n'), ('wherein', 'n'), ('first', 'r'), ('image', 'n'), ('second', 'a'), ('image', 'n'), ('displayed', 'v'), ('group', 'n'), ('chat', None), ('session', 'n'), ('one', None), ('image', 'n'), ('time', 'n'), ('one', None), ('two', None), ('images', 'n'), ('replaced', 'v'), ('two', None), ('images', 'n'), ('periodically', 'r'), ('method', 'v'), ('claim', 'n'), ('wherein', 'n'), ('extracting', 'v'), ('set', 'v'), ('profile', 'a'), ('parameters', 'n'), ('corresponding', 'v'), ('person', 'n'), ('first', 'a'), ('image', 'n'), ('includes', 'v'), ('determining', 'v'), ('one', None), ('descriptive', 'a'), ('labels', 'n'), ('corresponding', 'v'), ('identified', 'a'), ('face', 'n'), ('corresponding', 'v'), ('person', 'n'), ('using', 'v'), ('first', 'a'), ('machine', 'n'), ('learning', 'v'), ('model', 'n'), ('wherein', 'n'), ('first', 'a'), ('machine', 'n'), ('learning', 'v'), ('model', 'n'), ('trained', 'v'), ('facial', 'a'), ('images', 'n'), ('corresponding', 'v'), ('descriptive', 'a'), ('labels', 'n'), ('method', 'v'), ('claim', 'n'), ('wherein', 'n'), ('extracting', 'v'), ('set', 'v'), ('profile', 'a'), ('parameters', 'n'), ('corresponding', 'v'), ('person', 'n'), ('first', 'a'), ('image', 'n'), ('includes', 'v'), ('determining', 'v'), ('identity', 'n'), ('corresponding', 'v'), ('person', 'n'), ('based', 'v'), ('identified', 'a'), ('face', 'n'), ('corresponding', 'v'), ('person', 'n'), ('locating', 'v'), ('respective', 'a'), ('profile', 'n'), ('information', 'n'), ('first', 'r'), ('person', 'n'), ('based', 'v'), ('determined', 'v'), ('identity', 'n'), ('corresponding', 'v'), ('person', 'n'), ('using', 'v'), ('one', None), ('characteristics', 'n'), ('respective', 'a'), ('profile', 'a'), ('information', 'n'), ('first', 'r'), ('person', 'n'), ('set', 'v'), ('profile', 'n'), ('parameters', 'n'), ('corresponding', 'v'), ('identified', 'a'), ('face', 'n'), ('corresponding', 'v'), ('person', 'n'), ('method', 'a'), ('claim', 'n'), ('wherein', 'n'), ('least', 'v'), ('first', 'a'), ('one', None), ('first', 'a'), ('image', 'n'), ('tiles', 'n'), ('dynamic', 'a'), ('image', 'n'), ('tile', 'n'), ('least', 'a'), ('second', 'a'), ('one', None), ('first', 'a'), ('image', 'n'), ('tiles', 'n'), ('static', 'a'), ('image', 'n'), ('tile', 'n'), ('method', 'n'), ('claim', 'n'), ('including', 'v'), ('receiving', 'v'), ('plurality', 'n'), ('user', 'a'), ('comments', 'n'), ('different', 'a'), ('users', 'n'), ('group', 'n'), ('chat', 'v'), ('session', 'n'), ('user', 'a'), ('comment', 'n'), ('including', 'v'), ('descriptive', 'a'), ('term', 'n'), ('respective', 'a'), ('person', 'n'), ('identified', 'v'), ('first', 'a'), ('image', 'n'), ('choosing', 'v'), ('descriptive', 'a'), ('label', 'n'), ('respective', 'a'), ('person', 'n'), ('according', 'v'), ('plurality', 'n'), ('user', 'n'), ('comments', 'n'), ('updating', 'v'), ('second', 'a'), ('image', 'n'), ('adding', 'v'), ('descriptive', 'a'), ('label', 'n'), ('adjacent', 'n'), ('first', 'r'), ('image', 'n'), ('tile', 'n'), ('respective', 'a'), ('person', 'n'), ('computing', 'v'), ('device', 'n'), ('image', 'n'), ('information', 'n'), ('processing', 'v'), ('comprising', 'v'), ('one', None), ('processors', 'n'), ('memory', 'n'), ('storing', 'v'), ('instructions', 'n'), ('executed', 'v'), ('one', None), ('processors', 'n'), ('cause', 'v'), ('processors', 'n'), ('perform', 'v'), ('plurality', 'n'), ('operations', 'n'), ('comprising', 'v'), ('identifying', 'v'), ('using', 'v'), ('face', 'n'), ('recognition', 'n'), ('one', None), ('faces', 'v'), ('face', 'n'), ('corresponding', 'v'), ('respective', 'a'), ('person', 'n'), ('captured', 'v'), ('first', 'a'), ('image', 'n'), ('identified', 'v'), ('face', 'n'), ('extracting', 'v'), ('set', 'v'), ('profile', 'a'), ('parameters', 'n'), ('corresponding', 'v'), ('person', 'n'), ('first', 'a'), ('image', 'n'), ('selecting', 'v'), ('plurality', 'n'), ('image', 'n'), ('tiles', 'n'), ('first', 'r'), ('image', 'n'), ('tile', 'n'), ('matches', 'n'), ('face', 'v'), ('corresponding', 'v'), ('person', 'n'), ('first', 'a'), ('image', 'n'), ('accordance', 'n'), ('predefined', 'v'), ('correspondence', 'n'), ('set', 'v'), ('profile', 'a'), ('parameters', 'n'), ('corresponding', 'v'), ('person', 'n'), ('set', 'v'), ('pre-stored', 'a'), ('description', 'n'), ('parameters', 'n'), ('first', 'a'), ('image', 'n'), ('tile', 'n'), ('generating', 'v'), ('second', 'a'), ('image', 'n'), ('covering', 'v'), ('faces', 'v'), ('respective', 'a'), ('persons', 'n'), ('first', 'a'), ('image', 'n'), ('corresponding', 'v'), ('first', 'a'), ('image', 'n'), ('tiles', 'n'), ('sharing', 'v'), ('first', 'a'), ('image', 'n'), ('second', 'a'), ('image', 'n'), ('predefined', 'v'), ('order', 'n'), ('via', None), ('group', 'n'), ('chat', None), ('session', 'n'), ('computing', 'v'), ('device', 'n'), ('claim', 'n'), ('wherein', 'n'), ('first', 'r'), ('image', 'n'), ('second', 'a'), ('image', 'n'), ('displayed', 'v'), ('group', 'n'), ('chat', None), ('session', 'n'), ('one', None), ('image', 'n'), ('time', 'n'), ('one', None), ('two', None), ('images', 'n'), ('replaced', 'v'), ('two', None), ('images', 'n'), ('periodically', 'r'), ('computing', 'v'), ('device', 'n'), ('claim', 'n'), ('wherein', None), ('extracting', 'v'), ('set', 'v'), ('profile', 'a'), ('parameters', 'n'), ('corresponding', 'v'), ('person', 'n'), ('first', 'a'), ('image', 'n'), ('includes', 'v'), ('determining', 'v'), ('one', None), ('descriptive', 'a'), ('labels', 'n'), ('corresponding', 'v'), ('identified', 'a'), ('face', 'n'), ('corresponding', 'v'), ('person', 'n'), ('using', 'v'), ('first', 'a'), ('machine', 'n'), ('learning', 'v'), ('model', 'n'), ('wherein', 'n'), ('first', 'a'), ('machine', 'n'), ('learning', 'v'), ('model', 'n'), ('trained', 'v'), ('facial', 'a'), ('images', 'n'), ('corresponding', 'v'), ('descriptive', 'a'), ('labels', 'n'), ('computing', 'v'), ('device', 'n'), ('claim', 'n'), ('wherein', None), ('extracting', 'v'), ('set', 'v'), ('profile', 'a'), ('parameters', 'n'), ('corresponding', 'v'), ('person', 'n'), ('first', 'a'), ('image', 'n'), ('includes', 'v'), ('determining', 'v'), ('identity', 'n'), ('corresponding', 'v'), ('person', 'n'), ('based', 'v'), ('identified', 'a'), ('face', 'n'), ('corresponding', 'v'), ('person', 'n'), ('locating', 'v'), ('respective', 'a'), ('profile', 'n'), ('information', 'n'), ('first', 'r'), ('person', 'n'), ('based', 'v'), ('determined', 'v'), ('identity', 'n'), ('corresponding', 'v'), ('person', 'n'), ('using', 'v'), ('one', None), ('characteristics', 'n'), ('respective', 'a'), ('profile', 'a'), ('information', 'n'), ('first', 'r'), ('person', 'n'), ('set', 'v'), ('profile', 'n'), ('parameters', 'n'), ('corresponding', 'v'), ('identified', 'a'), ('face', 'n'), ('corresponding', 'v'), ('person', 'n'), ('computing', 'v'), ('device', 'n'), ('claim', 'n'), ('wherein', None), ('least', 'a'), ('first', 'a'), ('one', None), ('first', 'a'), ('image', 'n'), ('tiles', 'n'), ('dynamic', 'a'), ('image', 'n'), ('tile', 'n'), ('least', 'a'), ('second', 'a'), ('one', None), ('first', 'a'), ('image', 'n'), ('tiles', 'n'), ('static', 'a'), ('image', 'n'), ('tile', 'n'), ('computing', 'v'), ('device', 'n'), ('claim', 'n'), ('wherein', 'n'), ('plurality', 'n'), ('operations', 'n'), ('include', 'v'), ('receiving', 'v'), ('plurality', 'n'), ('user', 'a'), ('comments', 'n'), ('different', 'a'), ('users', 'n'), ('group', 'n'), ('chat', 'v'), ('session', 'n'), ('user', 'a'), ('comment', 'n'), ('including', 'v'), ('descriptive', 'a'), ('term', 'n'), ('respective', 'a'), ('person', 'n'), ('identified', 'v'), ('first', 'a'), ('image', 'n'), ('choosing', 'v'), ('descriptive', 'a'), ('label', 'n'), ('respective', 'a'), ('person', 'n'), ('according', 'v'), ('plurality', 'n'), ('user', 'n'), ('comments', 'n'), ('updating', 'v'), ('second', 'a'), ('image', 'n'), ('adding', 'v'), ('descriptive', 'a'), ('label', 'n'), ('adjacent', 'n'), ('first', 'r'), ('image', 'n'), ('tile', 'n'), ('respective', 'a'), ('person', 'n'), ('non-transitory', 'a'), ('computer-readable', 'a'), ('storage', 'n'), ('medium', 'n'), ('storing', 'v'), ('instructions', 'n'), ('executed', 'v'), ('computing', 'v'), ('device', 'n'), ('one', None), ('processors', 'n'), ('cause', 'v'), ('computing', 'v'), ('device', 'n'), ('perform', 'n'), ('plurality', 'n'), ('operations', 'n'), ('comprising', 'v'), ('identifying', 'v'), ('using', 'v'), ('face', 'n'), ('recognition', 'n'), ('one', None), ('faces', 'v'), ('face', 'n'), ('corresponding', 'v'), ('respective', 'a'), ('person', 'n'), ('captured', 'v'), ('first', 'a'), ('image', 'n'), ('identified', 'v'), ('face', 'n'), ('extracting', 'v'), ('set', 'v'), ('profile', 'a'), ('parameters', 'n'), ('corresponding', 'v'), ('person', 'n'), ('first', 'a'), ('image', 'n'), ('selecting', 'v'), ('plurality', 'n'), ('image', 'n'), ('tiles', 'n'), ('first', 'r'), ('image', 'n'), ('tile', 'n'), ('matches', 'n'), ('face', 'v'), ('corresponding', 'v'), ('person', 'n'), ('first', 'a'), ('image', 'n'), ('accordance', 'n'), ('predefined', 'v'), ('correspondence', 'n'), ('set', 'v'), ('profile', 'a'), ('parameters', 'n'), ('corresponding', 'v'), ('person', 'n'), ('set', 'v'), ('pre-stored', 'a'), ('description', 'n'), ('parameters', 'n'), ('first', 'a'), ('image', 'n'), ('tile', 'n'), ('generating', 'v'), ('second', 'a'), ('image', 'n'), ('covering', 'v'), ('faces', 'v'), ('respective', 'a'), ('persons', 'n'), ('first', 'a'), ('image', 'n'), ('corresponding', 'v'), ('first', 'a'), ('image', 'n'), ('tiles', 'n'), ('sharing', 'v'), ('first', 'a'), ('image', 'n'), ('second', 'a'), ('image', 'n'), ('predefined', 'v'), ('order', 'n'), ('via', None), ('group', 'n'), ('chat', None), ('session', 'n'), ('non-transitory', 'a'), ('computer-readable', 'a'), ('storage', 'n'), ('medium', 'n'), ('claim', 'n'), ('wherein', 'n'), ('first', 'r'), ('image', 'n'), ('second', 'a'), ('image', 'n'), ('displayed', 'v'), ('group', 'n'), ('chat', None), ('session', 'n'), ('one', None), ('image', 'n'), ('time', 'n'), ('one', None), ('two', None), ('images', 'n'), ('replaced', 'v'), ('two', None), ('images', 'n'), ('periodically', 'r'), ('non-transitory', 'a'), ('computer-readable', 'a'), ('storage', 'n'), ('medium', 'n'), ('claim', 'n'), ('wherein', None), ('extracting', 'v'), ('set', 'v'), ('profile', 'a'), ('parameters', 'n'), ('corresponding', 'v'), ('person', 'n'), ('first', 'a'), ('image', 'n'), ('includes', 'v'), ('determining', 'v'), ('one', None), ('descriptive', 'a'), ('labels', 'n'), ('corresponding', 'v'), ('identified', 'a'), ('face', 'n'), ('corresponding', 'v'), ('person', 'n'), ('using', 'v'), ('first', 'a'), ('machine', 'n'), ('learning', 'v'), ('model', 'n'), ('wherein', 'n'), ('first', 'a'), ('machine', 'n'), ('learning', 'v'), ('model', 'n'), ('trained', 'v'), ('facial', 'a'), ('images', 'n'), ('corresponding', 'v'), ('descriptive', 'a'), ('labels', 'n'), ('non-transitory', 'a'), ('computer-readable', 'a'), ('storage', 'n'), ('medium', 'n'), ('claim', 'n'), ('wherein', None), ('extracting', 'v'), ('set', 'v'), ('profile', 'a'), ('parameters', 'n'), ('corresponding', 'v'), ('person', 'n'), ('first', 'a'), ('image', 'n'), ('includes', 'v'), ('determining', 'v'), ('identity', 'n'), ('corresponding', 'v'), ('person', 'n'), ('based', 'v'), ('identified', 'a'), ('face', 'n'), ('corresponding', 'v'), ('person', 'n'), ('locating', 'v'), ('respective', 'a'), ('profile', 'n'), ('information', 'n'), ('first', 'r'), ('person', 'n'), ('based', 'v'), ('determined', 'v'), ('identity', 'n'), ('corresponding', 'v'), ('person', 'n'), ('using', 'v'), ('one', None), ('characteristics', 'n'), ('respective', 'a'), ('profile', 'a'), ('information', 'n'), ('first', 'r'), ('person', 'n'), ('set', 'v'), ('profile', 'n'), ('parameters', 'n'), ('corresponding', 'v'), ('identified', 'a'), ('face', 'n'), ('corresponding', 'v'), ('person', 'n'), ('non-transitory', 'a'), ('computer-readable', 'a'), ('storage', 'n'), ('medium', 'n'), ('claim', 'n'), ('wherein', None), ('least', 'a'), ('first', 'a'), ('one', None), ('first', 'a'), ('image', 'n'), ('tiles', 'n'), ('dynamic', 'a'), ('image', 'n'), ('tile', 'n'), ('least', 'a'), ('second', 'a'), ('one', None), ('first', 'a'), ('image', 'n'), ('tiles', 'n'), ('static', 'a'), ('image', 'n'), ('tile', 'a'), ('non-transitory', 'a'), ('computer-readable', 'a'), ('storage', 'n'), ('medium', 'n'), ('claim', 'n'), ('wherein', 'n'), ('plurality', 'n'), ('operations', 'n'), ('include', 'v'), ('receiving', 'v'), ('plurality', 'n'), ('user', 'a'), ('comments', 'n'), ('different', 'a'), ('users', 'n'), ('group', 'n'), ('chat', 'v'), ('session', 'n'), ('user', 'a'), ('comment', 'n'), ('including', 'v'), ('descriptive', 'a'), ('term', 'n'), ('respective', 'a'), ('person', 'n'), ('identified', 'v'), ('first', 'a'), ('image', 'n'), ('choosing', 'v'), ('descriptive', 'a'), ('label', 'n'), ('respective', 'a'), ('person', 'n'), ('according', 'v'), ('plurality', 'n'), ('user', 'n'), ('comments', 'n'), ('updating', 'v'), ('second', 'a'), ('image', 'n'), ('adding', 'v'), ('descriptive', 'a'), ('label', 'n'), ('adjacent', 'n'), ('first', 'r'), ('image', 'n'), ('tile', 'n'), ('respective', 'a'), ('person', 'n'), ('method', 'n'), ('comprising', 'v'), ('computing', 'v'), ('system', 'n'), ('determining', 'v'), ('performance', 'n'), ('metric', 'a'), ('eye', 'n'), ('tracking', 'v'), ('system', 'n'), ('first', 'a'), ('performance', 'n'), ('threshold', 'n'), ('wherein', 'n'), ('eye', 'n'), ('tracking', 'v'), ('system', 'n'), ('associated', 'v'), ('head-mounted', 'a'), ('display', 'n'), ('worn', 'v'), ('user', 'r'), ('based', 'v'), ('determination', 'n'), ('performance', 'n'), ('metric', 'a'), ('eye', 'n'), ('tracking', 'v'), ('system', 'n'), ('first', 'a'), ('performance', 'n'), ('threshold', 'v'), ('computer', 'n'), ('system', 'n'), ('performing', 'v'), ('receiving', 'v'), ('one', None), ('first', 'a'), ('inputs', 'n'), ('associated', 'v'), ('body', 'n'), ('user', 'r'), ('estimating', 'v'), ('region', 'n'), ('user', 'n'), ('looking', 'v'), ('within', None), ('field', 'n'), ('view', 'n'), ('head-mounted', 'a'), ('display', 'n'), ('based', 'v'), ('received', 'v'), ('one', None), ('first', 'a'), ('inputs', 'n'), ('associated', 'v'), ('body', 'n'), ('user', 'r'), ('determining', 'v'), ('vergence', 'n'), ('distance', 'n'), ('user', 'n'), ('based', 'v'), ('least', 'a'), ('one', None), ('first', 'a'), ('inputs', 'n'), ('associated', 'v'), ('body', 'n'), ('user', 'r'), ('estimated', 'v'), ('region', 'n'), ('user', 'r'), ('looking', 'v'), ('locations', 'n'), ('one', None), ('objects', 'v'), ('scene', 'n'), ('displayed', 'v'), ('head-mounted', 'a'), ('display', 'n'), ('adjusting', 'v'), ('one', None), ('configurations', 'n'), ('head-mounted', 'a'), ('display', 'n'), ('based', 'v'), ('determined', 'a'), ('vergence', 'n'), ('distance', 'n'), ('user', 'a'), ('method', 'n'), ('claim', 'n'), ('wherein', None), ('one', None), ('configurations', 'n'), ('head-mounted', 'a'), ('display', 'n'), ('comprise', 'n'), ('one', None), ('rendering', 'n'), ('image', 'n'), ('position', 'n'), ('display', 'n'), ('screen', 'a'), ('position', 'n'), ('optics', 'n'), ('block', 'v'), ('method', 'n'), ('claim', 'n'), ('comprising', 'v'), ('determining', 'v'), ('performance', 'n'), ('metric', 'a'), ('eye', 'n'), ('tracking', 'v'), ('system', 'n'), ('second', 'a'), ('performance', 'n'), ('threshold', 'v'), ('receiving', 'v'), ('eye', 'n'), ('tracking', 'v'), ('data', 'n'), ('eye', 'n'), ('tracking', 'v'), ('system', 'n'), ('determining', 'v'), ('vergence', 'n'), ('distance', 'n'), ('user', 'n'), ('based', 'v'), ('eye', 'n'), ('tracking', 'v'), ('data', 'n'), ('one', None), ('first', 'a'), ('inputs', 'n'), ('associated', 'v'), ('body', 'n'), ('user', 'a'), ('method', 'n'), ('claim', 'n'), ('comprising', 'v'), ('receiving', 'v'), ('one', None), ('second', 'a'), ('inputs', 'n'), ('associated', 'v'), ('one', None), ('displaying', 'n'), ('elements', 'n'), ('scene', 'v'), ('displayed', 'v'), ('head-mounted', 'a'), ('display', 'n'), ('determining', 'v'), ('vergence', 'n'), ('distance', 'n'), ('user', 'n'), ('based', 'v'), ('least', 'a'), ('eye', 'n'), ('tracking', 'v'), ('data', 'n'), ('one', None), ('first', 'a'), ('inputs', 'n'), ('associated', 'v'), ('body', 'n'), ('user', 'a'), ('one', None), ('second', 'n'), ('inputs', 'n'), ('associated', 'v'), ('one', None), ('displaying', 'n'), ('elements', 'n'), ('scene', 'v'), ('method', 'a'), ('claim', 'n'), ('comprising', 'v'), ('feeding', 'v'), ('one', None), ('first', 'a'), ('inputs', 'n'), ('associated', 'v'), ('body', 'n'), ('user', 'a'), ('fusion', 'n'), ('algorithm', 'n'), ('wherein', None), ('fusion', 'n'), ('algorithm', 'n'), ('assigns', 'n'), ('weight', 'v'), ('score', 'r'), ('input', 'a'), ('one', None), ('first', 'a'), ('inputs', 'v'), ('determining', 'v'), ('vergence', 'n'), ('distance', 'n'), ('user', 'n'), ('using', 'v'), ('fusion', 'n'), ('algorithm', 'n'), ('based', 'v'), ('one', None), ('first', 'a'), ('inputs', 'n'), ('associated', 'v'), ('body', 'n'), ('user', 'a'), ('determining', 'v'), ('z-depth', 'a'), ('display', 'n'), ('screen', 'n'), ('confidence', 'n'), ('score', 'n'), ('based', 'v'), ('one', None), ('first', 'a'), ('inputs', 'n'), ('associated', 'v'), ('body', 'n'), ('user', 'a'), ('method', 'n'), ('claim', 'n'), ('comprising', 'v'), ('comparing', 'v'), ('confidence', 'n'), ('score', 'n'), ('confidence', 'n'), ('level', 'n'), ('threshold', 'a'), ('response', 'n'), ('determination', 'n'), ('confidence', 'n'), ('score', 'n'), ('confidence', 'n'), ('level', 'n'), ('threshold', 'v'), ('feeding', 'v'), ('one', None), ('second', 'a'), ('inputs', 'n'), ('associated', 'v'), ('one', None), ('displaying', 'n'), ('elements', 'n'), ('scene', 'a'), ('fusion', 'n'), ('algorithm', None), ('determining', 'v'), ('z-depth', 'a'), ('display', 'n'), ('screen', 'n'), ('using', 'v'), ('fusion', 'n'), ('algorithm', 'n'), ('based', 'v'), ('one', None), ('first', 'a'), ('inputs', 'n'), ('associated', 'v'), ('body', 'n'), ('user', 'a'), ('one', None), ('second', 'n'), ('inputs', 'n'), ('associated', 'v'), ('one', None), ('displaying', 'n'), ('elements', 'n'), ('scene', 'v'), ('method', 'a'), ('claim', 'n'), ('comparing', 'v'), ('comparing', 'v'), ('fusion', 'n'), ('algorithm', 'n'), ('confidence', 'n'), ('scores', 'n'), ('associated', 'v'), ('plurality', 'n'), ('combinations', 'n'), ('inputs', 'v'), ('determining', 'v'), ('fusion', 'n'), ('algorithm', None), ('z-depth', 'a'), ('display', 'n'), ('screen', 'n'), ('based', 'v'), ('combination', 'n'), ('inputs', 'n'), ('associated', 'v'), ('highest', 'a'), ('confidence', 'n'), ('score', 'n'), ('method', 'n'), ('claim', 'n'), ('wherein', None), ('z-depth', 'a'), ('confidence', 'n'), ('score', 'n'), ('determined', 'v'), ('fusion', 'n'), ('algorithm', None), ('using', 'v'), ('piecewise', 'n'), ('comparison', 'n'), ('one', None), ('first', 'a'), ('inputs', 'v'), ('one', None), ('second', 'n'), ('inputs', 'v'), ('method', 'a'), ('claim', 'n'), ('wherein', None), ('z-depth', 'a'), ('confidence', 'n'), ('score', 'n'), ('determined', 'v'), ('based', 'v'), ('correlation', 'n'), ('two', None), ('inputs', 'n'), ('one', None), ('first', 'a'), ('inputs', 'v'), ('one', None), ('second', 'n'), ('inputs', 'v'), ('method', 'a'), ('claim', 'n'), ('wherein', 'n'), ('fusion', 'n'), ('algorithm', 'n'), ('comprises', 'v'), ('machine', 'n'), ('learning', 'v'), ('ml', 'a'), ('algorithm', 'a'), ('wherein', 'n'), ('machine', 'n'), ('learning', 'v'), ('ml', 'a'), ('algorithm', 'a'), ('determines', 'n'), ('combination', 'n'), ('first', 'r'), ('inputs', 'v'), ('fed', 'a'), ('fusion', 'n'), ('algorithm', 'n'), ('method', 'n'), ('claim', 'n'), ('wherein', None), ('one', None), ('first', 'a'), ('inputs', 'n'), ('associated', 'v'), ('body', 'n'), ('user', 'a'), ('comprise', 'n'), ('one', None), ('hand', 'n'), ('position', 'n'), ('hand', 'n'), ('direction', 'n'), ('hand', 'n'), ('movement', 'n'), ('hand', 'n'), ('gesture', 'n'), ('head', 'n'), ('position', 'n'), ('head', 'n'), ('direction', 'n'), ('head', 'n'), ('movement', 'n'), ('head', 'n'), ('gesture', 'n'), ('gaze', 'n'), ('angle', 'v'), ('rea', 'n'), ('body', 'n'), ('gesture', 'n'), ('body', 'n'), ('posture', 'n'), ('body', 'n'), ('movement', 'n'), ('behavior', None), ('user', 'n'), ('weighted', 'v'), ('combination', 'n'), ('one', None), ('related', 'a'), ('parameters', 'n'), ('method', 'v'), ('claim', 'n'), ('wherein', 'n'), ('one', None), ('first', 'a'), ('inputs', 'n'), ('associated', 'v'), ('body', 'n'), ('user', 'n'), ('received', 'v'), ('one', None), ('controller', 'n'), ('sensor', 'n'), ('camera', 'n'), ('microphone', 'n'), ('accelerometer', 'n'), ('headset', 'v'), ('worn', 'a'), ('user', 'n'), ('mobile', 'a'), ('device', 'n'), ('method', 'n'), ('claim', 'n'), ('wherein', 'v'), ('one', None), ('second', 'a'), ('inputs', 'n'), ('associated', 'v'), ('one', None), ('displaying', 'n'), ('elements', 'n'), ('comprise', 'v'), ('one', None), ('z-buffer', 'n'), ('value', 'n'), ('associated', 'v'), ('displaying', 'v'), ('element', 'n'), ('displaying', 'v'), ('element', 'n'), ('marked', 'v'), ('developer', 'a'), ('image', 'n'), ('analysis', 'n'), ('result', 'n'), ('shape', 'n'), ('displaying', 'v'), ('element', 'a'), ('face', 'n'), ('recognition', 'n'), ('result', 'n'), ('object', 'a'), ('recognition', 'n'), ('result', 'n'), ('person', 'n'), ('identified', 'v'), ('displaying', 'v'), ('content', 'n'), ('object', 'n'), ('identified', 'v'), ('displaying', 'v'), ('content', 'a'), ('correlation', 'n'), ('two', None), ('displaying', 'v'), ('elements', 'n'), ('weighted', 'v'), ('combination', 'n'), ('one', None), ('second', 'n'), ('inputs', 'v'), ('method', 'a'), ('claim', 'n'), ('comprising', 'v'), ('determining', 'v'), ('performance', 'n'), ('metric', 'a'), ('eye', 'n'), ('tracking', 'v'), ('system', 'n'), ('second', 'a'), ('performance', 'n'), ('threshold', 'v'), ('receiving', 'v'), ('one', None), ('second', 'a'), ('inputs', 'n'), ('associated', 'v'), ('one', None), ('displaying', 'n'), ('elements', 'n'), ('scene', 'v'), ('displayed', 'v'), ('head-mounted', 'a'), ('display', 'n'), ('determining', 'v'), ('vergence', 'n'), ('distance', 'n'), ('user', 'n'), ('based', 'v'), ('least', 'a'), ('one', None), ('first', 'a'), ('inputs', 'n'), ('associated', 'v'), ('body', 'n'), ('user', 'a'), ('one', None), ('second', 'n'), ('inputs', 'n'), ('associated', 'v'), ('one', None), ('displaying', 'n'), ('elements', 'n'), ('method', 'v'), ('claim', 'n'), ('wherein', 'n'), ('determining', 'v'), ('performance', 'n'), ('metric', 'a'), ('eye', 'n'), ('tracking', 'v'), ('system', 'n'), ('second', 'a'), ('performance', 'n'), ('threshold', 'n'), ('comprises', 'v'), ('determining', 'v'), ('eye', 'n'), ('tracking', 'v'), ('system', 'n'), ('exist', 'v'), ('fails', 'n'), ('provide', 'v'), ('eye', 'n'), ('tracking', 'v'), ('data', 'n'), ('method', 'n'), ('claim', 'n'), ('wherein', 'n'), ('performance', 'n'), ('metric', 'a'), ('eye', 'n'), ('tracking', 'v'), ('system', 'n'), ('comprises', 'v'), ('one', None), ('accuracy', 'n'), ('parameter', 'n'), ('eye', 'n'), ('tracking', 'v'), ('system', 'n'), ('precision', 'n'), ('parameter', 'n'), ('eye', 'n'), ('tracking', 'v'), ('system', 'n'), ('value', 'n'), ('parameter', 'n'), ('eye', 'n'), ('tracking', 'v'), ('system', 'n'), ('detectability', 'n'), ('pupil', 'v'), ('metric', 'a'), ('based', 'v'), ('one', None), ('parameters', 'n'), ('associated', 'v'), ('user', 'a'), ('parameter', 'n'), ('change', 'n'), ('parameter', 'n'), ('changing', 'v'), ('trend', 'n'), ('data', 'n'), ('availability', 'n'), ('weighted', 'v'), ('combination', 'n'), ('one', None), ('performance', 'n'), ('related', 'a'), ('parameters', 'n'), ('method', 'v'), ('claim', 'n'), ('wherein', 'v'), ('one', None), ('parameters', 'n'), ('associated', 'v'), ('user', 'r'), ('comprise', 'v'), ('one', None), ('eye', 'n'), ('distance', 'n'), ('user', 'n'), ('pupil', 'n'), ('position', 'n'), ('pupil', 'n'), ('status', 'n'), ('correlation', 'n'), ('two', None), ('pupils', 'n'), ('user', 'a'), ('head', 'n'), ('size', 'n'), ('user', 'a'), ('position', 'n'), ('headset', 'n'), ('worn', 'a'), ('user', 'n'), ('angle', 'n'), ('headset', 'n'), ('worn', None), ('user', 'a'), ('direction', 'n'), ('headset', 'n'), ('worn', None), ('user', 'n'), ('alignment', 'a'), ('eyes', 'n'), ('user', 'r'), ('weighted', 'v'), ('combination', 'n'), ('one', None), ('related', 'a'), ('parameters', 'n'), ('associated', 'v'), ('user', 'a'), ('method', 'n'), ('claim', 'n'), ('wherein', None), ('first', 'a'), ('performance', 'n'), ('threshold', 'n'), ('comprises', 'v'), ('one', None), ('pre-determined', 'a'), ('value', 'n'), ('pre-determined', 'a'), ('range', 'n'), ('state', 'n'), ('data', 'n'), ('changing', 'v'), ('speed', 'n'), ('data', 'n'), ('trend', 'n'), ('data', 'n'), ('change', 'v'), ('one', None), ('non-transitory', 'a'), ('computer-readable', 'a'), ('storage', 'n'), ('media', 'n'), ('embodying', 'v'), ('software', 'n'), ('operable', 'a'), ('executed', 'v'), ('computing', 'n'), ('system', 'n'), ('determine', 'a'), ('performance', 'n'), ('metric', 'a'), ('eye', 'n'), ('tracking', 'v'), ('system', 'n'), ('first', 'a'), ('performance', 'n'), ('threshold', 'n'), ('wherein', 'n'), ('eye', 'n'), ('tracking', 'v'), ('system', 'n'), ('associated', 'v'), ('head-mounted', 'a'), ('display', 'n'), ('worn', 'v'), ('user', 'r'), ('based', 'v'), ('determination', 'n'), ('performance', 'n'), ('metric', 'a'), ('eye', 'n'), ('tracking', 'v'), ('system', 'n'), ('first', 'a'), ('performance', 'n'), ('threshold', 'a'), ('media', 'n'), ('embodying', 'v'), ('software', 'n'), ('operable', 'a'), ('executed', 'v'), ('computing', 'v'), ('system', 'n'), ('receive', 'v'), ('one', None), ('first', 'a'), ('inputs', 'n'), ('associated', 'v'), ('body', 'n'), ('user', 'a'), ('estimate', 'n'), ('region', 'n'), ('user', None), ('looking', 'v'), ('within', None), ('field', 'n'), ('view', 'n'), ('head-mounted', 'a'), ('display', 'n'), ('based', 'v'), ('received', 'v'), ('one', None), ('first', 'a'), ('inputs', 'n'), ('associated', 'v'), ('body', 'n'), ('user', 'a'), ('determine', 'a'), ('vergence', 'n'), ('distance', 'n'), ('user', 'n'), ('based', 'v'), ('least', 'a'), ('one', None), ('first', 'a'), ('inputs', 'n'), ('associated', 'v'), ('body', 'n'), ('user', 'r'), ('estimated', 'v'), ('region', 'n'), ('user', 'r'), ('looking', 'v'), ('locations', 'n'), ('one', None), ('objects', 'v'), ('scene', 'n'), ('displayed', 'v'), ('head-mounted', 'a'), ('display', 'n'), ('adjust', 'v'), ('one', None), ('configurations', 'n'), ('head-mounted', 'a'), ('display', 'n'), ('based', 'v'), ('determined', 'a'), ('vergence', 'n'), ('distance', 'n'), ('user', 'n'), ('system', 'n'), ('comprising', 'v'), ('one', None), ('non-transitory', 'a'), ('computer-readable', 'a'), ('storage', 'n'), ('media', 'n'), ('embodying', 'v'), ('instructions', 'n'), ('one', None), ('processors', 'n'), ('coupled', 'v'), ('storage', 'n'), ('media', 'n'), ('operable', 'a'), ('execute', 'a'), ('instructions', 'n'), ('determine', 'v'), ('performance', 'n'), ('metric', 'a'), ('eye', 'n'), ('tracking', 'v'), ('system', 'n'), ('first', 'a'), ('performance', 'n'), ('threshold', 'n'), ('wherein', 'n'), ('eye', 'n'), ('tracking', 'v'), ('system', 'n'), ('associated', 'v'), ('head-mounted', 'a'), ('display', 'n'), ('worn', 'v'), ('user', 'r'), ('based', 'v'), ('determination', 'n'), ('performance', 'n'), ('metric', 'a'), ('eye', 'n'), ('tracking', 'v'), ('system', 'n'), ('first', 'a'), ('performance', 'n'), ('threshold', 'n'), ('system', 'n'), ('configured', 'v'), ('receive', 'a'), ('one', None), ('first', 'a'), ('inputs', 'n'), ('associated', 'v'), ('body', 'n'), ('user', 'a'), ('estimate', 'n'), ('region', 'n'), ('user', None), ('looking', 'v'), ('within', None), ('field', 'n'), ('view', 'n'), ('head-mounted', 'a'), ('display', 'n'), ('based', 'v'), ('received', 'v'), ('one', None), ('first', 'a'), ('inputs', 'n'), ('associated', 'v'), ('body', 'n'), ('user', 'a'), ('determine', 'a'), ('vergence', 'n'), ('distance', 'n'), ('user', 'n'), ('based', 'v'), ('least', 'a'), ('one', None), ('first', 'a'), ('inputs', 'n'), ('associated', 'v'), ('body', 'n'), ('user', 'r'), ('estimated', 'v'), ('region', 'n'), ('user', 'r'), ('looking', 'v'), ('locations', 'n'), ('one', None), ('objects', 'v'), ('scene', 'n'), ('displayed', 'v'), ('head-mounted', 'a'), ('display', 'n'), ('adjust', 'v'), ('one', None), ('configurations', 'n'), ('head-mounted', 'a'), ('display', 'n'), ('based', 'v'), ('determined', 'a'), ('vergence', 'n'), ('distance', 'n'), ('user', 'a'), ('computer-implemented', 'a'), ('method', 'n'), ('image-based', 'a'), ('self-guided', 'a'), ('object', 'a'), ('detection', 'n'), ('comprising', 'v'), ('receiving', 'v'), ('processor', 'n'), ('device', 'n'), ('set', 'v'), ('images', 'n'), ('images', 'n'), ('respective', 'v'), ('grid', 'a'), ('thereon', 'n'), ('labeled', 'v'), ('regarding', 'v'), ('respective', 'a'), ('object', 'n'), ('detected', 'v'), ('using', 'v'), ('grid', 'a'), ('level', 'n'), ('label', 'n'), ('data', 'n'), ('training', 'n'), ('processor', 'n'), ('device', 'n'), ('grid-based', 'a'), ('object', 'n'), ('detector', 'n'), ('using', 'v'), ('grid', 'a'), ('level', 'n'), ('label', 'n'), ('data', 'n'), ('determining', 'v'), ('processor', 'n'), ('device', 'n'), ('respective', 'n'), ('bounding', 'v'), ('box', 'n'), ('respective', 'a'), ('object', 'a'), ('images', 'n'), ('applying', 'v'), ('local', 'a'), ('segmentation', 'n'), ('images', 'n'), ('training', 'v'), ('processor', 'a'), ('device', 'n'), ('region-based', 'a'), ('convolutional', 'a'), ('neural', 'a'), ('network', 'n'), ('rcnn', 'n'), ('joint', 'n'), ('object', 'a'), ('localization', 'n'), ('object', 'n'), ('classification', 'n'), ('using', 'v'), ('respective', 'a'), ('bounding', 'n'), ('box', 'n'), ('respective', 'a'), ('object', 'a'), ('images', 'n'), ('input', 'v'), ('rcnn', 'a'), ('computer-implemented', 'a'), ('method', 'n'), ('claim', 'n'), ('comprising', 'v'), ('performing', 'v'), ('action', 'n'), ('responsive', 'a'), ('object', 'n'), ('localization', 'n'), ('object', 'a'), ('classification', 'n'), ('respective', 'a'), ('new', 'a'), ('object', 'a'), ('new', 'a'), ('image', 'n'), ('rcnn', 'n'), ('applied', 'v'), ('computer-implemented', 'a'), ('method', 'n'), ('claim', 'n'), ('wherein', None), ('action', 'n'), ('comprises', 'v'), ('autonomously', 'r'), ('controlling', 'v'), ('motor', 'n'), ('vehicle', 'n'), ('avoid', 'v'), ('collision', 'n'), ('new', 'a'), ('object', 'a'), ('responsive', 'a'), ('object', 'n'), ('localization', 'n'), ('object', 'a'), ('classification', 'n'), ('respective', 'a'), ('new', 'a'), ('object', 'a'), ('computer-implemented', 'a'), ('method', 'n'), ('claim', 'n'), ('wherein', 'v'), ('local', 'a'), ('segmentation', 'n'), ('performed', 'v'), ('using', 'v'), ('self-similarity', 'a'), ('search', 'n'), ('template', 'n'), ('matching', 'v'), ('provide', 'r'), ('respective', 'a'), ('bounding', 'v'), ('box', 'n'), ('around', None), ('respective', 'a'), ('object', 'n'), ('set', 'v'), ('images', 'n'), ('computer-implemented', 'a'), ('method', 'a'), ('claim', 'n'), ('wherein', 'v'), ('local', 'a'), ('segmentation', 'n'), ('applied', 'v'), ('images', 'n'), ('segment', 'n'), ('respective', 'a'), ('target', 'n'), ('region', 'n'), ('therein', None), ('computer-implemented', 'a'), ('method', 'n'), ('claim', 'n'), ('wherein', None), ('region-based', 'a'), ('convolutional', 'a'), ('neural', 'a'), ('network', 'n'), ('rcnn', 'n'), ('forms', 'n'), ('model', 'v'), ('object', 'a'), ('training', 'n'), ('stage', 'n'), ('detect', 'a'), ('objects', 'v'), ('new', 'a'), ('images', 'n'), ('inference', 'n'), ('stage', 'n'), ('computer-implemented', 'a'), ('method', 'n'), ('claim', 'n'), ('wherein', 'n'), ('method', 'n'), ('performed', 'v'), ('system', 'n'), ('selected', 'v'), ('group', 'n'), ('consisting', 'v'), ('surveillance', 'n'), ('system', 'n'), ('face', 'n'), ('detection', 'n'), ('system', 'n'), ('face', 'n'), ('recognition', 'n'), ('system', 'n'), ('cancer', 'n'), ('detection', 'n'), ('system', 'n'), ('object', 'v'), ('tracking', 'v'), ('system', 'n'), ('advanced', 'v'), ('driver-assistance', 'n'), ('system', 'n'), ('computer', 'n'), ('program', 'n'), ('product', 'n'), ('image-based', 'a'), ('self-guided', 'a'), ('object', 'n'), ('detection', 'n'), ('computer', 'n'), ('program', 'n'), ('product', 'n'), ('comprising', 'v'), ('non-transitory', 'a'), ('computer', 'n'), ('readable', 'a'), ('storage', 'n'), ('medium', 'n'), ('program', 'n'), ('instructions', 'n'), ('embodied', 'v'), ('therewith', 'a'), ('program', 'n'), ('instructions', 'n'), ('executable', 'a'), ('computer', 'n'), ('cause', 'n'), ('computer', 'n'), ('perform', 'n'), ('method', 'n'), ('comprising', 'v'), ('receiving', 'v'), ('processor', 'n'), ('device', 'n'), ('set', 'v'), ('images', 'n'), ('images', 'n'), ('respective', 'v'), ('grid', 'a'), ('thereon', 'n'), ('labeled', 'v'), ('regarding', 'v'), ('respective', 'a'), ('object', 'n'), ('detected', 'v'), ('using', 'v'), ('grid', 'a'), ('level', 'n'), ('label', 'n'), ('data', 'n'), ('training', 'n'), ('processor', 'n'), ('device', 'n'), ('grid-based', 'a'), ('object', 'n'), ('detector', 'n'), ('using', 'v'), ('grid', 'a'), ('level', 'n'), ('label', 'n'), ('data', 'n'), ('determining', 'v'), ('processor', 'n'), ('device', 'n'), ('respective', 'n'), ('bounding', 'v'), ('box', 'n'), ('respective', 'a'), ('object', 'a'), ('images', 'n'), ('applying', 'v'), ('local', 'a'), ('segmentation', 'n'), ('images', 'n'), ('training', 'v'), ('processor', 'a'), ('device', 'n'), ('region-based', 'a'), ('convolutional', 'a'), ('neural', 'a'), ('network', 'n'), ('rcnn', 'n'), ('joint', 'n'), ('object', 'a'), ('localization', 'n'), ('object', 'n'), ('classification', 'n'), ('using', 'v'), ('respective', 'a'), ('bounding', 'n'), ('box', 'n'), ('respective', 'a'), ('object', 'a'), ('images', 'n'), ('input', 'v'), ('rcnn', 'a'), ('computer', 'n'), ('program', 'n'), ('product', 'n'), ('claim', 'n'), ('wherein', 'n'), ('method', 'n'), ('comprises', 'v'), ('performing', 'v'), ('action', 'n'), ('responsive', 'a'), ('object', 'n'), ('localization', 'n'), ('object', 'a'), ('classification', 'n'), ('respective', 'a'), ('new', 'a'), ('object', 'a'), ('new', 'a'), ('image', 'n'), ('rcnn', 'n'), ('applied', 'v'), ('computer', 'n'), ('program', 'n'), ('product', 'n'), ('claim', 'n'), ('wherein', 'a'), ('action', 'n'), ('comprises', 'v'), ('autonomously', 'r'), ('controlling', 'v'), ('motor', 'n'), ('vehicle', 'n'), ('avoid', 'v'), ('collision', 'n'), ('new', 'a'), ('object', 'a'), ('responsive', 'a'), ('object', 'n'), ('localization', 'n'), ('object', 'a'), ('classification', 'n'), ('respective', 'a'), ('new', 'a'), ('object', 'a'), ('computer', 'n'), ('program', 'n'), ('product', 'n'), ('claim', 'n'), ('wherein', 'a'), ('local', 'a'), ('segmentation', 'n'), ('performed', 'v'), ('using', 'v'), ('self-similarity', 'a'), ('search', 'n'), ('template', 'n'), ('matching', 'v'), ('provide', 'r'), ('respective', 'a'), ('bounding', 'v'), ('box', 'n'), ('around', None), ('respective', 'a'), ('object', 'n'), ('set', 'v'), ('images', 'n'), ('computer', 'n'), ('program', 'n'), ('product', 'n'), ('claim', 'n'), ('wherein', 'a'), ('local', 'a'), ('segmentation', 'n'), ('applied', 'v'), ('images', 'n'), ('segment', 'n'), ('respective', 'a'), ('target', 'n'), ('region', 'n'), ('therein', 'a'), ('computer', 'n'), ('program', 'n'), ('product', 'n'), ('claim', 'n'), ('wherein', None), ('region-based', 'a'), ('convolutional', 'a'), ('neural', 'a'), ('network', 'n'), ('rcnn', 'n'), ('forms', 'n'), ('model', 'v'), ('object', 'a'), ('training', 'n'), ('stage', 'n'), ('detect', 'a'), ('objects', 'v'), ('new', 'a'), ('images', 'n'), ('inference', 'n'), ('stage', 'n'), ('computer', 'n'), ('program', 'n'), ('product', 'n'), ('claim', 'n'), ('wherein', 'n'), ('method', 'n'), ('performed', 'v'), ('system', 'n'), ('selected', 'v'), ('group', 'n'), ('consisting', 'v'), ('surveillance', 'n'), ('system', 'n'), ('face', 'n'), ('detection', 'n'), ('system', 'n'), ('face', 'n'), ('recognition', 'n'), ('system', 'n'), ('cancer', 'n'), ('detection', 'n'), ('system', 'n'), ('object', 'v'), ('tracking', 'v'), ('system', 'n'), ('advanced', 'v'), ('driver-assistance', 'n'), ('system', 'n'), ('computer', 'n'), ('processing', 'v'), ('system', 'n'), ('image-based', 'a'), ('self-guided', 'a'), ('object', 'a'), ('detection', 'n'), ('comprising', 'v'), ('memory', 'n'), ('device', 'n'), ('storing', 'v'), ('program', 'n'), ('code', 'n'), ('processor', 'n'), ('device', 'n'), ('running', 'v'), ('program', 'n'), ('code', 'n'), ('receive', 'v'), ('set', 'v'), ('images', 'n'), ('images', 'n'), ('respective', 'v'), ('grid', 'a'), ('thereon', 'n'), ('labeled', 'v'), ('regarding', 'v'), ('respective', 'a'), ('object', 'n'), ('detected', 'v'), ('using', 'v'), ('grid', 'a'), ('level', 'n'), ('label', 'n'), ('data', 'n'), ('train', 'v'), ('grid-based', 'a'), ('object', 'n'), ('detector', 'n'), ('using', 'v'), ('grid', 'a'), ('level', 'n'), ('label', 'n'), ('data', 'n'), ('determine', 'v'), ('respective', 'a'), ('bounding', 'n'), ('box', 'n'), ('respective', 'a'), ('object', 'a'), ('images', 'n'), ('applying', 'v'), ('local', 'a'), ('segmentation', 'n'), ('images', 'n'), ('train', 'v'), ('region-based', 'a'), ('convolutional', 'a'), ('neural', 'a'), ('network', 'n'), ('rcnn', 'n'), ('joint', 'n'), ('object', 'a'), ('localization', 'n'), ('object', 'n'), ('classification', 'n'), ('using', 'v'), ('respective', 'a'), ('bounding', 'n'), ('box', 'n'), ('respective', 'a'), ('object', 'a'), ('images', 'n'), ('input', 'v'), ('rcnn', 'r'), ('computer', 'n'), ('processing', 'n'), ('system', 'n'), ('claim', 'n'), ('wherein', 'n'), ('processor', 'n'), ('device', 'n'), ('runs', 'v'), ('program', 'n'), ('code', 'n'), ('perform', 'v'), ('action', 'n'), ('responsive', 'a'), ('object', 'n'), ('localization', 'n'), ('object', 'a'), ('classification', 'n'), ('respective', 'a'), ('new', 'a'), ('object', 'a'), ('new', 'a'), ('image', 'n'), ('rcnn', 'n'), ('applied', 'v'), ('computer', 'n'), ('processing', 'n'), ('system', 'n'), ('claim', 'n'), ('wherein', None), ('action', 'n'), ('comprises', 'v'), ('autonomously', 'r'), ('controlling', 'v'), ('motor', 'n'), ('vehicle', 'n'), ('avoid', 'v'), ('collision', 'n'), ('new', 'a'), ('object', 'a'), ('responsive', 'a'), ('object', 'n'), ('localization', 'n'), ('object', 'a'), ('classification', 'n'), ('respective', 'a'), ('new', 'a'), ('object', 'a'), ('computer', 'n'), ('processing', 'n'), ('system', 'n'), ('claim', 'n'), ('wherein', 'r'), ('local', 'a'), ('segmentation', 'n'), ('performed', 'v'), ('using', 'v'), ('self-similarity', 'a'), ('search', 'n'), ('template', 'n'), ('matching', 'v'), ('provide', 'r'), ('respective', 'a'), ('bounding', 'v'), ('box', 'n'), ('around', None), ('respective', 'a'), ('object', 'n'), ('set', 'v'), ('images', 'n'), ('computer', 'n'), ('processing', 'n'), ('system', 'n'), ('claim', 'n'), ('wherein', None), ('region-based', 'a'), ('convolutional', 'a'), ('neural', 'a'), ('network', 'n'), ('rcnn', 'n'), ('forms', 'n'), ('model', 'v'), ('object', 'a'), ('training', 'n'), ('stage', 'n'), ('detect', 'a'), ('objects', 'v'), ('new', 'a'), ('images', 'n'), ('inference', 'n'), ('stage', 'n'), ('computer', 'n'), ('processing', 'n'), ('system', 'n'), ('claim', 'n'), ('wherein', 'v'), ('computer', 'n'), ('processing', 'n'), ('system', 'n'), ('comprised', 'v'), ('system', 'n'), ('selected', 'v'), ('group', 'n'), ('consisting', 'v'), ('surveillance', 'n'), ('system', 'n'), ('face', 'n'), ('detection', 'n'), ('system', 'n'), ('face', 'n'), ('recognition', 'n'), ('system', 'n'), ('cancer', 'n'), ('detection', 'n'), ('system', 'n'), ('object', 'v'), ('tracking', 'v'), ('system', 'n'), ('advanced', 'v'), ('driver-assistance', 'n'), ('system', 'n'), ('method', 'r'), ('scalable', 'a'), ('parallel', 'a'), ('cloud-based', 'a'), ('face', 'n'), ('recognition', 'n'), ('utilizing', 'v'), ('database', 'n'), ('normalized', 'v'), ('stored', 'a'), ('images', 'n'), ('comprising', 'v'), ('capturing', 'v'), ('image', 'n'), ('using', 'v'), ('camera', 'n'), ('detecting', 'v'), ('face', 'n'), ('captured', 'v'), ('image', 'n'), ('normalizing', 'v'), ('detected', 'v'), ('facial', 'a'), ('image', 'n'), ('match', 'n'), ('normalized', 'v'), ('stored', 'a'), ('images', 'n'), ('identifying', 'v'), ('facial', 'a'), ('features', 'n'), ('normalized', 'v'), ('detected', 'a'), ('facial', 'a'), ('image', 'n'), ('generating', 'v'), ('plurality', 'n'), ('facial', 'a'), ('metrics', 'n'), ('facial', 'a'), ('features', 'n'), ('calculating', 'v'), ('euclidean', 'a'), ('distances', 'n'), ('facial', 'a'), ('metrics', 'n'), ('normalized', 'v'), ('detected', 'a'), ('facial', 'a'), ('image', 'n'), ('corresponding', 'v'), ('facial', 'a'), ('metrics', 'n'), ('stored', 'v'), ('images', 'n'), ('comparing', 'v'), ('euclidean', 'a'), ('distance', 'n'), ('predetermined', 'v'), ('threshold', 'a'), ('responsive', 'a'), ('euclidean', 'a'), ('distance', 'n'), ('comparison', 'n'), ('producing', 'v'), ('reduced', 'a'), ('candidate', 'a'), ('list', 'n'), ('best', 'a'), ('possible', 'a'), ('image', 'n'), ('matches', 'n'), ('normalized', 'v'), ('stored', 'a'), ('images', 'n'), ('comparing', 'v'), ('parallel', 'a'), ('normalized', 'v'), ('detected', 'a'), ('facial', 'a'), ('image', 'n'), ('normalized', 'v'), ('stored', 'a'), ('images', 'n'), ('reduced', 'v'), ('candidate', 'a'), ('list', 'n'), ('utilizing', 'v'), ('plurality', 'n'), ('face', 'n'), ('recognition', 'n'), ('algorithms', 'n'), ('processor', 'n'), ('parallel', 'r'), ('processing', 'v'), ('system', 'n'), ('uses', 'v'), ('different', 'a'), ('face', 'n'), ('recognition', 'n'), ('algorithm', None), ('responsive', 'a'), ('comparison', 'n'), ('producing', 'v'), ('best', 'a'), ('match', 'n'), ('results', 'n'), ('parallel', 'a'), ('subset', 'n'), ('reduced', 'v'), ('candidate', 'a'), ('list', 'n'), ('selecting', 'v'), ('final', 'a'), ('match', 'n'), ('best', 'a'), ('match', 'n'), ('results', 'n'), ('using', 'v'), ('deep', 'a'), ('learning', 'v'), ('neural', 'a'), ('network', 'n'), ('face', 'n'), ('recognition', 'n'), ('algorithm', 'n'), ('trained', 'v'), ('outputs', 'n'), ('individual', 'a'), ('face', 'n'), ('recognition', 'n'), ('algorithms', None), ('method', 'n'), ('scalable', 'a'), ('parallel', 'a'), ('cloud-based', 'a'), ('face', 'n'), ('recognition', 'n'), ('claim', 'n'), ('wherein', None), ('detecting', 'v'), ('face', 'n'), ('captured', 'v'), ('image', 'n'), ('comprises', 'v'), ('utilizing', 'v'), ('opencv', 'r'), ('detect', 'a'), ('face', 'n'), ('captured', 'v'), ('image', 'n'), ('extracting', 'v'), ('location', 'a'), ('eyes', 'n'), ('tip', 'v'), ('nose', 'a'), ('face', 'n'), ('determining', 'v'), ('distance', 'n'), ('eyes', 'n'), ('cropping', 'v'), ('face', 'n'), ('captured', 'v'), ('image', 'n'), ('width', 'n'), ('height', 'v'), ('cropped', 'a'), ('face', 'n'), ('image', 'n'), ('function', 'n'), ('distance', 'n'), ('eyes', 'n'), ('rotating', 'v'), ('face', 'n'), ('angle', 'n'), ('rotation', 'n'), ('function', 'n'), ('distance', 'n'), ('eyes', 'n'), ('method', 'r'), ('scalable', 'a'), ('parallel', 'a'), ('cloud-based', 'a'), ('face', 'n'), ('recognition', 'n'), ('claim', 'n'), ('wherein', 'n'), ('width', 'n'), ('cropped', 'v'), ('face', 'n'), ('image', 'n'), ('times', 'n'), ('distance', 'v'), ('eyes', 'n'), ('height', None), ('cropped', 'v'), ('face', 'n'), ('image', 'n'), ('times', 'n'), ('distance', 'v'), ('eyes', 'n'), ('angle', 'a'), ('rotation', 'n'), ('angle', 'n'), ('formed', 'v'), ('straight', 'a'), ('line', 'n'), ('joining', 'v'), ('eyes', 'n'), ('x-axis', 'a'), ('face', 'n'), ('method', 'n'), ('scalable', 'a'), ('parallel', 'a'), ('cloud-based', 'a'), ('face', 'n'), ('recognition', 'n'), ('claim', 'n'), ('wherein', None), ('rotating', 'v'), ('face', 'n'), ('comprises', 'n'), ('rotating', 'v'), ('face', 'n'), ('provide', 'v'), ('frontal', 'a'), ('face', 'n'), ('pattern', 'n'), ('method', 'n'), ('scalable', 'a'), ('parallel', 'a'), ('cloud-based', 'a'), ('face', 'n'), ('recognition', 'n'), ('claim', 'n'), ('comprising', 'v'), ('step', 'n'), ('proportionally', 'r'), ('rescaling', 'v'), ('cropped', 'v'), ('rotated', 'v'), ('image', 'n'), ('method', 'n'), ('scalable', 'a'), ('parallel', 'a'), ('cloud-based', 'a'), ('face', 'n'), ('recognition', 'n'), ('claim', 'n'), ('proportional', 'a'), ('rescaling', 'n'), ('yields', 'n'), ('cropped', 'v'), ('rotated', 'v'), ('image', 'n'), ('size', 'n'), ('pixels', 'n'), ('method', 'r'), ('scalable', 'a'), ('parallel', 'a'), ('cloud-based', 'a'), ('face', 'n'), ('recognition', 'n'), ('claim', 'n'), ('wherein', 'v'), ('facial', 'a'), ('features', 'n'), ('identified', 'v'), ('normalized', 'a'), ('detected', 'v'), ('facial', 'a'), ('image', 'n'), ('comprise', 'n'), ('pair', 'a'), ('eyes', 'n'), ('tip', 'v'), ('nose', 'a'), ('mouth', 'n'), ('center', 'n'), ('mouth', 'n'), ('chin', 'a'), ('area', 'n'), ('comprising', 'v'), ('bottom', 'a'), ('top', 'a'), ('left', 'v'), ('landmark', 'n'), ('top', 'a'), ('right', 'n'), ('landmark', 'n'), ('method', 'n'), ('scalable', 'a'), ('parallel', 'a'), ('cloud-based', 'a'), ('face', 'n'), ('recognition', 'n'), ('claim', 'n'), ('wherein', None), ('generating', 'v'), ('plurality', 'n'), ('facial', 'a'), ('metrics', 'n'), ('comprises', 'n'), ('calculating', 'v'), ('distance', 'n'), ('pair', 'n'), ('eyes', 'n'), ('distance', 'v'), ('eyes', 'n'), ('tip', 'v'), ('nose', 'a'), ('distance', 'n'), ('equal', 'a'), ('width', 'n'), ('mouth', 'n'), ('distance', 'n'), ('tip', 'n'), ('nose', 'r'), ('center', 'a'), ('mouth', 'n'), ('distance', 'n'), ('bottom', 'n'), ('chin', 'n'), ('center', 'n'), ('mouth', 'n'), ('distance', 'n'), ('top', 'n'), ('left', 'v'), ('landmark', 'n'), ('chin', 'n'), ('tip', 'n'), ('nose', 'a'), ('distance', 'n'), ('top', 'a'), ('right', 'n'), ('landmark', 'n'), ('chin', 'a'), ('tip', 'n'), ('nose', 'a'), ('method', 'n'), ('scalable', 'a'), ('parallel', 'a'), ('cloud-based', 'a'), ('face', 'n'), ('recognition', 'n'), ('claim', 'n'), ('wherein', None), ('performing', 'v'), ('euclidean', 'a'), ('distance', 'n'), ('match', 'n'), ('comprises', 'v'), ('partitioning', 'v'), ('normalized', 'v'), ('stored', 'a'), ('images', 'n'), ('plurality', 'v'), ('substantially', 'r'), ('equal', 'a'), ('subsets', 'n'), ('performing', 'v'), ('euclidean', 'a'), ('distance', 'n'), ('match', 'n'), ('facial', 'a'), ('metrics', 'n'), ('normalized', 'v'), ('detected', 'a'), ('facial', 'a'), ('image', 'n'), ('corresponding', 'v'), ('facial', 'a'), ('metrics', 'n'), ('stored', 'v'), ('images', 'n'), ('subsets', 'n'), ('normalized', 'v'), ('stored', 'a'), ('images', 'n'), ('separate', 'v'), ('processor', 'n'), ('parallel', 'n'), ('processing', 'n'), ('system', 'n'), ('generate', 'a'), ('euclidean', 'a'), ('distance', 'n'), ('stored', 'v'), ('image', 'n'), ('subset', 'n'), ('comparing', 'v'), ('euclidean', 'a'), ('distance', 'n'), ('predetermined', 'v'), ('threshold', 'a'), ('separate', 'a'), ('processors', 'n'), ('responsive', 'a'), ('euclidean', 'a'), ('distance', 'n'), ('comparison', 'n'), ('producing', 'v'), ('reduced', 'a'), ('candidate', 'a'), ('list', 'n'), ('best', 'a'), ('possible', 'a'), ('image', 'n'), ('matches', 'n'), ('normalized', 'v'), ('stored', 'a'), ('images', 'n'), ('subset', 'v'), ('combining', 'v'), ('reduced', 'v'), ('candidate', 'n'), ('lists', 'n'), ('subset', 'v'), ('produce', 'v'), ('single', 'a'), ('reduced', 'v'), ('candidate', 'a'), ('list', 'n'), ('method', 'n'), ('scalable', 'a'), ('parallel', 'a'), ('cloud-based', 'a'), ('face', 'n'), ('recognition', 'n'), ('claim', 'n'), ('wherein', 'n'), ('plurality', 'n'), ('face', 'n'), ('recognition', 'n'), ('algorithms', None), ('utilized', 'a'), ('comparing', 'v'), ('parallel', 'a'), ('normalized', 'v'), ('detected', 'a'), ('facial', 'a'), ('image', 'n'), ('normalized', 'v'), ('stored', 'a'), ('images', 'n'), ('reduced', 'v'), ('candidate', 'a'), ('list', 'n'), ('consists', 'v'), ('face', 'v'), ('recognition', 'n'), ('algorithms', 'r'), ('selected', 'v'), ('group', 'n'), ('consisting', 'v'), ('principle', 'a'), ('component', 'a'), ('analysis', 'n'), ('pca-based', 'a'), ('algorithms', 'n'), ('linear', 'a'), ('discriminant', 'a'), ('analysis', 'n'), ('lda', 'n'), ('algorithms', 'a'), ('independent', 'a'), ('component', 'n'), ('analysis', 'n'), ('ica', 'n'), ('algorithms', None), ('kernel-based', 'a'), ('algorithms', 'a'), ('feature-based', 'a'), ('techniques', 'n'), ('algorithms', 'v'), ('based', 'v'), ('neural', 'a'), ('networks', 'n'), ('algorithms', 'v'), ('based', 'v'), ('transforms', 'n'), ('model-based', 'a'), ('face', 'n'), ('recognition', 'n'), ('algorithms', None), ('method', 'n'), ('scalable', 'a'), ('parallel', 'a'), ('cloud-based', 'a'), ('face', 'n'), ('recognition', 'n'), ('claim', 'n'), ('wherein', None), ('pca-based', 'a'), ('algorithms', 'n'), ('include', 'v'), ('eigenfaces', 'n'), ('face', 'v'), ('detectionrecognition', 'n'), ('lda', 'n'), ('algorithms', 'n'), ('include', 'v'), ('fisherfaces', 'n'), ('method', 'a'), ('face', 'n'), ('recognition', 'n'), ('method', 'n'), ('scalable', 'a'), ('parallel', 'a'), ('cloud-based', 'a'), ('face', 'n'), ('recognition', 'n'), ('claim', 'n'), ('wherein', None), ('comparing', 'v'), ('parallel', 'n'), ('captured', 'v'), ('image', 'n'), ('normalized', 'v'), ('stored', 'a'), ('images', 'n'), ('reduced', 'v'), ('candidate', 'a'), ('list', 'n'), ('comprises', 'n'), ('partitioning', 'v'), ('reduced', 'a'), ('candidate', 'n'), ('list', 'n'), ('plurality', 'n'), ('substantially', 'r'), ('equal', 'a'), ('subsets', 'n'), ('processing', 'v'), ('subset', 'a'), ('different', 'a'), ('processor', 'n'), ('parallel', 'n'), ('processing', 'n'), ('system', 'n'), ('uses', 'v'), ('unique', 'a'), ('face', 'n'), ('recognition', 'n'), ('algorithm', None), ('produce', 'n'), ('best', 'a'), ('match', 'n'), ('results', 'n'), ('using', 'v'), ('reduce', 'v'), ('function', 'n'), ('mapreduce', 'n'), ('program', 'n'), ('combine', 'n'), ('best', 'r'), ('match', 'n'), ('results', 'n'), ('subsets', 'n'), ('produce', 'v'), ('single', 'a'), ('set', 'n'), ('best', 'a'), ('match', 'n'), ('results', 'n'), ('method', 'r'), ('scalable', 'a'), ('parallel', 'a'), ('cloud-based', 'a'), ('face', 'n'), ('recognition', 'n'), ('claim', 'n'), ('wherein', 'n'), ('partitioning', 'v'), ('reduced', 'v'), ('candidate', 'a'), ('list', 'n'), ('comprises', 'n'), ('selecting', 'v'), ('images', 'n'), ('comprising', 'v'), ('subset', 'n'), ('optimizing', 'v'), ('variance', 'n'), ('images', 'n'), ('according', 'v'), ('following', 'v'), ('equation', 'n'), ('n', None), ('number', 'n'), ('rows', 'n'), ('columns', 'v'), ('face', 'n'), ('vector', 'n'), ('image', 'n'), ('n', 'a'), ('number', 'n'), ('groups', 'n'), ('σij', 'v'), ('standard', 'a'), ('deviation', 'n'), ('image', 'n'), ('dimension', 'n'), ('group', 'n'), ('j', 'n'), ('face', 'n'), ('image', 'n'), ('vector', 'n'), ('method', 'n'), ('scalable', 'a'), ('parallel', 'a'), ('cloud-based', 'a'), ('face', 'n'), ('recognition', 'n'), ('claim', 'n'), ('wherein', None), ('selecting', 'v'), ('images', 'n'), ('comprising', 'v'), ('subset', 'n'), ('optimizing', 'v'), ('variance', 'n'), ('images', 'n'), ('according', 'v'), ('following', 'v'), ('equation', 'n'), ('dμi', None), ('μj', 'a'), ('euclidean', 'a'), ('distance', 'n'), ('mean', 'n'), ('group', 'n'), ('mean', 'v'), ('group', 'n'), ('j', 'n'), ('face', 'n'), ('image', 'n'), ('vector', 'n'), ('l', 'a'), ('number', 'n'), ('group', 'n'), ('levels', 'n'), ('method', 'v'), ('scalable', 'a'), ('parallel', 'a'), ('cloud-based', 'a'), ('face', 'n'), ('recognition', 'n'), ('claim', 'n'), ('selecting', 'v'), ('final', 'a'), ('match', 'n'), ('best', 'a'), ('match', 'n'), ('results', 'n'), ('utilizing', 'a'), ('deep', 'a'), ('learning', 'n'), ('neural', 'a'), ('network', 'n'), ('face', 'n'), ('recognition', 'n'), ('algorithm', 'n'), ('comprises', 'v'), ('utilizing', 'v'), ('either', None), ('adaboost', 'a'), ('machine-learning', 'a'), ('algorithm', 'a'), ('neural', 'a'), ('networks', 'n'), ('machine-learning', 'a'), ('model', 'n'), ('method', 'n'), ('scalable', 'a'), ('parallel', 'a'), ('cloud-based', 'a'), ('face', 'n'), ('recognition', 'n'), ('claim', 'n'), ('normalizing', 'v'), ('detected', 'v'), ('facial', 'a'), ('image', 'n'), ('match', 'n'), ('normalized', 'v'), ('stored', 'a'), ('images', 'n'), ('includes', 'v'), ('normalizing', 'v'), ('detected', 'v'), ('facial', 'a'), ('image', 'n'), ('size', 'n'), ('orientation', 'n'), ('illumination', 'n'), ('normalized', 'v'), ('stored', 'a'), ('images', 'n'), ('non-transitory', 'a'), ('computer-readable', 'a'), ('medium', 'n'), ('containing', 'v'), ('executable', 'a'), ('program', 'n'), ('instructions', 'n'), ('causing', 'v'), ('computer', 'n'), ('perform', 'n'), ('method', 'n'), ('face', 'n'), ('recognition', 'n'), ('method', 'n'), ('comprising', 'v'), ('detecting', 'v'), ('face', 'n'), ('image', 'n'), ('captured', 'v'), ('camera', 'n'), ('normalizing', 'n'), ('detected', 'v'), ('facial', 'a'), ('image', 'n'), ('match', 'n'), ('normalized', 'v'), ('stored', 'a'), ('images', 'n'), ('identifying', 'v'), ('facial', 'a'), ('features', 'n'), ('normalized', 'v'), ('detected', 'a'), ('facial', 'a'), ('image', 'n'), ('generating', 'v'), ('plurality', 'n'), ('facial', 'a'), ('metrics', 'n'), ('facial', 'a'), ('features', 'n'), ('calculating', 'v'), ('euclidean', 'a'), ('distances', 'n'), ('facial', 'a'), ('metrics', 'n'), ('normalized', 'v'), ('detected', 'a'), ('facial', 'a'), ('image', 'n'), ('corresponding', 'v'), ('facial', 'a'), ('metrics', 'n'), ('stored', 'v'), ('images', 'n'), ('comparing', 'v'), ('euclidean', 'a'), ('distance', 'n'), ('predetermined', 'v'), ('threshold', 'a'), ('responsive', 'a'), ('euclidean', 'a'), ('distance', 'n'), ('comparison', 'n'), ('producing', 'v'), ('reduced', 'a'), ('candidate', 'a'), ('list', 'n'), ('best', 'a'), ('possible', 'a'), ('image', 'n'), ('matches', 'n'), ('normalized', 'v'), ('stored', 'a'), ('images', 'n'), ('comparing', 'v'), ('parallel', 'r'), ('captured', 'v'), ('image', 'n'), ('normalized', 'v'), ('stored', 'a'), ('images', 'n'), ('reduced', 'v'), ('candidate', 'a'), ('list', 'n'), ('utilizing', 'v'), ('plurality', 'n'), ('face', 'n'), ('recognition', 'n'), ('algorithms', 'n'), ('processor', 'n'), ('parallel', 'r'), ('processing', 'v'), ('system', 'n'), ('uses', 'v'), ('different', 'a'), ('face', 'n'), ('recognition', 'n'), ('algorithm', None), ('responsive', 'a'), ('comparison', 'n'), ('producing', 'v'), ('best', 'a'), ('match', 'n'), ('results', 'n'), ('parallel', 'a'), ('subset', 'n'), ('reduced', 'v'), ('candidate', 'a'), ('list', 'n'), ('selecting', 'v'), ('final', 'a'), ('match', 'n'), ('best', 'a'), ('match', 'n'), ('results', 'n'), ('using', 'v'), ('deep', 'a'), ('learning', 'v'), ('neural', 'a'), ('network', 'n'), ('face', 'n'), ('recognition', 'n'), ('algorithm', 'n'), ('trained', 'v'), ('outputs', 'n'), ('individual', 'a'), ('face', 'n'), ('recognition', 'n'), ('algorithms', None), ('non-transitory', 'a'), ('computer-readable', 'a'), ('medium', 'n'), ('containing', 'v'), ('executable', 'a'), ('program', 'n'), ('instructions', 'n'), ('claim', 'v'), ('wherein', 'a'), ('plurality', 'n'), ('face', 'n'), ('recognition', 'n'), ('algorithms', None), ('utilized', 'a'), ('comparing', 'v'), ('parallel', 'a'), ('normalized', 'v'), ('detected', 'a'), ('facial', 'a'), ('image', 'n'), ('normalized', 'v'), ('stored', 'a'), ('images', 'n'), ('reduced', 'v'), ('candidate', 'a'), ('list', 'n'), ('consists', 'v'), ('face', 'v'), ('recognition', 'n'), ('algorithms', 'r'), ('selected', 'v'), ('group', 'n'), ('consisting', 'v'), ('principle', 'a'), ('component', 'a'), ('analysis', 'n'), ('pca-based', 'a'), ('algorithms', 'n'), ('linear', 'a'), ('discriminant', 'a'), ('analysis', 'n'), ('lda', 'n'), ('algorithms', 'a'), ('independent', 'a'), ('component', 'n'), ('analysis', 'n'), ('ica', 'n'), ('algorithms', None), ('kernel-based', 'a'), ('algorithms', 'a'), ('feature-based', 'a'), ('techniques', 'n'), ('algorithms', 'v'), ('based', 'v'), ('neural', 'a'), ('networks', 'n'), ('algorithms', 'v'), ('based', 'v'), ('transforms', 'n'), ('model-based', 'a'), ('face', 'n'), ('recognition', 'n'), ('algorithms', None), ('non-transitory', 'a'), ('computer-readable', 'a'), ('medium', 'n'), ('containing', 'v'), ('executable', 'a'), ('program', 'n'), ('instructions', 'n'), ('claim', 'v'), ('wherein', None), ('pca-based', 'a'), ('algorithms', 'n'), ('include', 'v'), ('eigenfaces', 'n'), ('face', 'v'), ('detectionrecognition', 'n'), ('lda', 'n'), ('algorithms', 'n'), ('include', 'v'), ('fisherfaces', 'n'), ('method', 'a'), ('face', 'n'), ('recognition', 'n'), ('non-transitory', 'a'), ('computer-readable', 'a'), ('medium', 'n'), ('containing', 'v'), ('executable', 'a'), ('program', 'n'), ('instructions', 'n'), ('claim', 'v'), ('selecting', 'v'), ('final', 'a'), ('match', 'n'), ('best', 'a'), ('match', 'n'), ('results', 'n'), ('utilizing', 'a'), ('deep', 'a'), ('learning', 'n'), ('neural', 'a'), ('network', 'n'), ('face', 'n'), ('recognition', 'n'), ('algorithm', 'n'), ('comprises', 'v'), ('utilizing', 'v'), ('either', None), ('adaboost', 'a'), ('machine-learning', 'a'), ('algorithm', 'a'), ('neural', 'a'), ('networks', 'n'), ('machine-learning', 'a'), ('model', 'n'), ('imaging', 'v'), ('device', 'n'), ('comprising', 'v'), ('condensing', 'v'), ('lens', 'a'), ('image', 'n'), ('sensor', 'n'), ('configured', 'v'), ('detect', 'a'), ('light', 'a'), ('passing', 'v'), ('condensing', 'v'), ('lens', 'n'), ('comprising', 'v'), ('pixel', 'n'), ('matrix', 'n'), ('wherein', 'n'), ('pixel', 'n'), ('matrix', 'n'), ('comprises', 'v'), ('plurality', 'n'), ('phase', 'n'), ('detection', 'n'), ('pixel', 'n'), ('pairs', 'n'), ('plurality', 'n'), ('regular', 'a'), ('pixels', 'n'), ('processor', 'n'), ('configured', 'v'), ('turn', 'a'), ('phase', 'a'), ('detection', 'n'), ('pixel', 'n'), ('pairs', 'n'), ('autofocusing', 'v'), ('output', 'n'), ('autofocused', 'v'), ('pixel', 'a'), ('data', 'n'), ('completing', 'v'), ('autofocusing', 'v'), ('divide', 'n'), ('autofocused', 'v'), ('pixel', 'n'), ('data', 'n'), ('first', 'r'), ('subframe', 'a'), ('second', 'a'), ('subframe', 'n'), ('calculate', 'n'), ('image', 'n'), ('features', 'n'), ('least', 'v'), ('one', None), ('first', 'a'), ('subframe', 'a'), ('second', 'a'), ('subframe', 'n'), ('wherein', 'n'), ('image', 'n'), ('features', 'n'), ('comprise', 'v'), ('module', 'a'), ('widths', 'n'), ('finder', 'v'), ('pattern', 'a'), ('finder', 'n'), ('pattern', 'n'), ('predetermined', 'v'), ('ratio', 'a'), ('harr-like', 'a'), ('feature', 'n'), ('gabor', 'n'), ('feature', 'n'), ('determine', 'n'), ('operating', 'v'), ('resolution', 'n'), ('regular', 'a'), ('pixels', 'n'), ('according', 'v'), ('image', 'n'), ('features', 'n'), ('calculated', 'v'), ('least', 'a'), ('one', None), ('first', 'a'), ('subframe', 'a'), ('second', 'a'), ('subframe', 'n'), ('divided', 'v'), ('autofocused', 'a'), ('pixel', 'n'), ('data', 'n'), ('imaging', 'v'), ('device', 'n'), ('claimed', 'v'), ('claim', 'n'), ('wherein', 'n'), ('phase', 'n'), ('detection', 'n'), ('pixel', 'n'), ('pairs', 'n'), ('comprises', 'v'), ('first', 'a'), ('pixel', 'a'), ('second', 'a'), ('pixel', 'n'), ('cover', 'n'), ('layer', 'n'), ('covering', 'v'), ('upon', None), ('first', 'a'), ('region', 'n'), ('first', 'r'), ('pixel', 'v'), ('upon', None), ('second', 'a'), ('region', 'n'), ('second', 'a'), ('pixel', 'n'), ('wherein', 'n'), ('first', 'a'), ('region', 'n'), ('second', 'a'), ('region', 'n'), ('mirror', 'n'), ('symmetrical', 'a'), ('microlens', 'n'), ('aligned', 'v'), ('least', 'a'), ('one', None), ('first', 'a'), ('pixel', 'a'), ('second', 'a'), ('pixel', 'n'), ('imaging', 'v'), ('device', 'n'), ('claimed', 'v'), ('claim', 'n'), ('wherein', 'n'), ('first', 'a'), ('region', 'n'), ('second', 'a'), ('region', 'n'), ('%', 'n'), ('%', 'n'), ('area', 'n'), ('single', 'a'), ('pixel', 'n'), ('imaging', 'v'), ('device', 'n'), ('claimed', 'v'), ('claim', 'n'), ('wherein', 'n'), ('processor', 'n'), ('configured', 'v'), ('perform', 'n'), ('autofocusing', 'v'), ('using', 'v'), ('dual', 'a'), ('pixel', 'n'), ('autofocus', 'n'), ('technique', 'n'), ('according', 'v'), ('pixel', 'n'), ('data', 'n'), ('phase', 'n'), ('detection', 'n'), ('pixel', 'n'), ('pairs', 'n'), ('completing', 'v'), ('autofocusing', 'v'), ('imaging', 'a'), ('device', 'n'), ('claimed', 'v'), ('claim', 'n'), ('wherein', 'n'), ('processor', 'n'), ('configured', 'v'), ('divide', 'a'), ('pixel', 'n'), ('data', 'n'), ('phase', 'n'), ('detection', 'n'), ('pixel', 'n'), ('pairs', 'n'), ('third', 'a'), ('subframe', 'a'), ('fourth', 'a'), ('subframe', 'n'), ('completing', 'v'), ('autofocusing', 'v'), ('perform', 'n'), ('autofocusing', 'v'), ('according', 'v'), ('third', 'a'), ('subframe', 'a'), ('fourth', 'a'), ('subframe', 'n'), ('imaging', 'v'), ('device', 'n'), ('claimed', 'v'), ('claim', 'n'), ('wherein', 'n'), ('processor', 'n'), ('configured', 'v'), ('calibrate', 'a'), ('brightness', 'a'), ('third', 'a'), ('subframe', 'n'), ('fourth', 'a'), ('subframe', 'a'), ('identical', 'a'), ('using', 'v'), ('shading', 'v'), ('algorithm', 'a'), ('imaging', 'v'), ('device', 'n'), ('claimed', 'v'), ('claim', 'n'), ('wherein', 'n'), ('operating', 'v'), ('resolution', 'n'), ('selected', 'v'), ('first', 'a'), ('resolution', 'n'), ('smaller', 'a'), ('number', 'n'), ('regular', 'a'), ('pixels', 'n'), ('second', 'a'), ('resolution', 'n'), ('larger', 'a'), ('first', 'a'), ('resolution', 'n'), ('imaging', 'v'), ('device', 'n'), ('claimed', 'v'), ('claim', 'n'), ('wherein', 'n'), ('regular', 'a'), ('pixels', 'n'), ('turned', 'v'), ('autofocusing', 'v'), ('imaging', 'v'), ('device', 'n'), ('claimed', 'v'), ('claim', 'n'), ('wherein', 'n'), ('number', 'n'), ('phase', 'n'), ('detection', 'n'), ('pixel', 'n'), ('pairs', 'v'), ('smaller', 'a'), ('regular', 'a'), ('pixels', 'n'), ('imaging', 'v'), ('device', 'n'), ('comprising', 'v'), ('condensing', 'v'), ('lens', 'a'), ('image', 'n'), ('sensor', 'n'), ('configured', 'v'), ('detect', 'a'), ('light', 'a'), ('passing', 'v'), ('condensing', 'v'), ('lens', 'n'), ('comprising', 'v'), ('pixel', 'n'), ('matrix', 'n'), ('wherein', 'n'), ('pixel', 'n'), ('matrix', 'n'), ('comprises', 'v'), ('plurality', 'n'), ('phase', 'n'), ('detection', 'n'), ('pixel', 'n'), ('pairs', 'n'), ('plurality', 'n'), ('regular', 'a'), ('pixels', 'n'), ('processor', 'n'), ('configured', 'v'), ('turn', 'a'), ('phase', 'a'), ('detection', 'n'), ('pixel', 'n'), ('pairs', 'n'), ('autofocusing', 'v'), ('output', 'n'), ('autofocused', 'v'), ('pixel', 'a'), ('data', 'n'), ('completing', 'v'), ('autofocusing', 'v'), ('divide', 'n'), ('autofocused', 'v'), ('pixel', 'n'), ('data', 'n'), ('first', 'r'), ('subframe', 'a'), ('second', 'a'), ('subframe', 'n'), ('calculate', 'n'), ('image', 'n'), ('features', 'n'), ('least', 'v'), ('one', None), ('first', 'a'), ('subframe', 'a'), ('second', 'a'), ('subframe', 'n'), ('wherein', 'n'), ('image', 'n'), ('features', 'n'), ('comprise', 'v'), ('module', 'a'), ('widths', 'n'), ('finder', 'v'), ('pattern', 'a'), ('finder', 'n'), ('pattern', 'n'), ('predetermined', 'v'), ('ratio', 'a'), ('harr-like', 'a'), ('feature', 'n'), ('gabor', 'n'), ('feature', 'n'), ('select', 'a'), ('image', 'n'), ('decoding', 'v'), ('image', 'n'), ('recognition', 'n'), ('using', 'v'), ('pixel', 'a'), ('data', 'n'), ('regular', 'a'), ('pixels', 'n'), ('according', 'v'), ('image', 'n'), ('features', 'n'), ('calculated', 'v'), ('least', 'a'), ('one', None), ('first', 'a'), ('subframe', 'a'), ('second', 'a'), ('subframe', 'n'), ('divided', 'v'), ('autofocused', 'a'), ('pixel', 'n'), ('data', 'n'), ('imaging', 'v'), ('device', 'n'), ('claimed', 'v'), ('claim', 'n'), ('wherein', 'n'), ('phase', 'n'), ('detection', 'n'), ('pixel', 'n'), ('pairs', 'n'), ('comprises', 'v'), ('first', 'a'), ('pixel', 'a'), ('second', 'a'), ('pixel', 'n'), ('cover', 'n'), ('layer', 'n'), ('covering', 'v'), ('upon', None), ('first', 'a'), ('region', 'n'), ('first', 'r'), ('pixel', 'v'), ('upon', None), ('second', 'a'), ('region', 'n'), ('second', 'a'), ('pixel', 'n'), ('wherein', 'n'), ('first', 'a'), ('region', 'n'), ('second', 'a'), ('region', 'n'), ('mirror', 'n'), ('symmetrical', 'a'), ('microlens', 'n'), ('aligned', 'v'), ('least', 'a'), ('one', None), ('first', 'a'), ('pixel', 'a'), ('second', 'a'), ('pixel', 'n'), ('imaging', 'v'), ('device', 'n'), ('claimed', 'v'), ('claim', 'n'), ('wherein', 'n'), ('processor', 'n'), ('configured', 'v'), ('perform', 'n'), ('autofocusing', 'v'), ('using', 'v'), ('dual', 'a'), ('pixel', 'n'), ('autofocus', 'n'), ('technique', 'n'), ('according', 'v'), ('pixel', 'n'), ('data', 'n'), ('phase', 'n'), ('detection', 'n'), ('pixel', 'n'), ('pairs', 'n'), ('completing', 'v'), ('autofocusing', 'v'), ('imaging', 'a'), ('device', 'n'), ('claimed', 'v'), ('claim', 'n'), ('wherein', 'n'), ('processor', 'n'), ('configured', 'v'), ('divide', 'a'), ('pixel', 'n'), ('data', 'n'), ('phase', 'n'), ('detection', 'n'), ('pixel', 'n'), ('pairs', 'n'), ('third', 'a'), ('subframe', 'a'), ('fourth', 'a'), ('subframe', 'n'), ('completing', 'v'), ('autofocusing', 'v'), ('calibrate', 'a'), ('brightness', 'a'), ('third', 'a'), ('subframe', 'n'), ('fourth', 'a'), ('subframe', 'a'), ('identical', 'a'), ('using', 'v'), ('shading', 'v'), ('algorithm', 'a'), ('perform', 'n'), ('autofocusing', 'v'), ('according', 'v'), ('third', 'a'), ('subframe', 'a'), ('fourth', 'a'), ('subframe', 'n'), ('imaging', 'v'), ('device', 'n'), ('claimed', 'v'), ('claim', 'n'), ('wherein', 'n'), ('processor', 'n'), ('configured', 'v'), ('calculate', 'a'), ('image', 'n'), ('features', 'n'), ('using', 'v'), ('least', 'a'), ('one', None), ('rule', 'n'), ('based', 'v'), ('algorithm', 'r'), ('machine', 'n'), ('learning', 'v'), ('algorithm', 'a'), ('imaging', 'v'), ('device', 'n'), ('claimed', 'v'), ('claim', 'n'), ('wherein', 'n'), ('image', 'n'), ('decoding', 'v'), ('decoding', 'v'), ('qr', 'n'), ('codes', 'n'), ('image', 'n'), ('recognition', 'n'), ('face', 'n'), ('recognition', 'n'), ('operating', 'v'), ('method', 'n'), ('imaging', 'v'), ('device', 'n'), ('imaging', 'v'), ('device', 'n'), ('comprising', 'v'), ('plurality', 'n'), ('phase', 'n'), ('detection', 'n'), ('pixel', 'n'), ('pairs', 'n'), ('plurality', 'n'), ('regular', 'a'), ('pixels', 'n'), ('operating', 'v'), ('method', 'n'), ('comprising', 'v'), ('turning', 'v'), ('phase', 'n'), ('detection', 'n'), ('pixel', 'n'), ('pairs', 'n'), ('autofocusing', 'v'), ('outputting', 'v'), ('autofocused', 'v'), ('image', 'n'), ('frame', 'n'), ('completing', 'v'), ('autofocusing', 'v'), ('dividing', 'v'), ('autofocused', 'v'), ('image', 'n'), ('frame', 'n'), ('acquired', 'v'), ('phase', 'a'), ('detection', 'n'), ('pixel', 'n'), ('pairs', 'n'), ('first', 'r'), ('subframe', 'a'), ('second', 'a'), ('subframe', 'n'), ('calculating', 'v'), ('image', 'n'), ('features', 'n'), ('least', 'v'), ('one', None), ('first', 'a'), ('subframe', 'a'), ('second', 'a'), ('subframe', 'n'), ('wherein', 'a'), ('image', 'n'), ('feature', 'n'), ('comprise', 'n'), ('module', 'n'), ('widths', 'n'), ('finder', 'v'), ('pattern', 'a'), ('finder', 'n'), ('pattern', 'n'), ('predetermined', 'v'), ('ratio', 'a'), ('harr-like', 'a'), ('feature', 'n'), ('gabor', 'n'), ('feature', 'n'), ('selectively', 'r'), ('activating', 'v'), ('least', 'a'), ('part', 'n'), ('regular', 'a'), ('pixels', 'n'), ('according', 'v'), ('image', 'n'), ('features', 'n'), ('calculated', 'v'), ('least', 'a'), ('one', None), ('first', 'a'), ('subframe', 'a'), ('second', 'a'), ('subframe', 'n'), ('divided', 'v'), ('autofocused', 'a'), ('image', 'n'), ('frame', 'n'), ('operating', 'v'), ('method', 'n'), ('claimed', 'v'), ('claim', 'n'), ('wherein', 'n'), ('selectively', 'r'), ('activating', 'v'), ('comprises', 'n'), ('activating', 'v'), ('first', 'a'), ('part', 'n'), ('regular', 'a'), ('pixels', 'n'), ('perform', 'v'), ('image', 'n'), ('decoding', 'v'), ('according', 'v'), ('pixel', 'n'), ('data', 'n'), ('first', 'a'), ('part', 'n'), ('regular', 'a'), ('pixels', 'n'), ('activating', 'v'), ('regular', 'a'), ('pixels', 'n'), ('perform', 'v'), ('image', 'n'), ('recognition', 'n'), ('according', 'v'), ('pixel', 'n'), ('data', 'n'), ('regular', 'a'), ('pixels', 'n'), ('operating', 'v'), ('method', 'n'), ('claimed', 'v'), ('claim', 'n'), ('wherein', 'n'), ('pixel', 'n'), ('data', 'n'), ('phase', 'n'), ('detection', 'n'), ('pixel', 'n'), ('pairs', 'n'), ('captured', 'v'), ('frame', 'a'), ('pixel', 'n'), ('data', 'n'), ('regular', 'a'), ('pixels', 'n'), ('also', 'r'), ('used', 'v'), ('performing', 'v'), ('image', 'n'), ('decoding', 'v'), ('image', 'n'), ('recognition', 'n'), ('operating', 'v'), ('method', 'n'), ('claimed', 'v'), ('claim', 'n'), ('wherein', 'n'), ('image', 'n'), ('decoding', 'v'), ('decoding', 'v'), ('qr', 'n'), ('codes', 'n'), ('image', 'n'), ('recognition', 'n'), ('face', 'n'), ('recognition', 'n'), ('operating', 'v'), ('method', 'n'), ('claimed', 'v'), ('claim', 'n'), ('wherein', 'n'), ('phase', 'n'), ('detection', 'n'), ('pixel', 'n'), ('pairs', 'n'), ('partially', 'r'), ('covered', 'v'), ('pixels', 'n'), ('structure', 'n'), ('dual', 'a'), ('pixel', 'n'), ('apparatus', 'n'), ('comprising', 'v'), ('first', 'a'), ('camera', 'n'), ('module', 'n'), ('configured', 'v'), ('obtain', 'v'), ('first', 'a'), ('image', 'n'), ('object', 'v'), ('first', 'a'), ('field', 'n'), ('view', 'n'), ('second', 'a'), ('camera', 'n'), ('module', 'n'), ('configured', 'v'), ('obtain', 'v'), ('second', 'a'), ('image', 'n'), ('object', 'a'), ('second', 'a'), ('field', 'n'), ('view', 'n'), ('different', 'a'), ('first', 'a'), ('field', 'n'), ('view', 'n'), ('first', 'r'), ('depth', 'v'), ('map', 'n'), ('generator', 'n'), ('configured', 'v'), ('generate', 'n'), ('first', 'r'), ('depth', 'v'), ('map', 'n'), ('first', 'r'), ('image', 'n'), ('based', 'v'), ('first', 'a'), ('image', 'n'), ('second', 'a'), ('image', 'n'), ('second', 'a'), ('depth', 'n'), ('map', 'n'), ('generator', 'n'), ('configured', 'v'), ('generate', 'a'), ('second', 'a'), ('depth', 'n'), ('map', 'n'), ('second', 'a'), ('image', 'n'), ('based', 'v'), ('first', 'a'), ('image', 'n'), ('second', 'a'), ('image', 'n'), ('first', 'r'), ('depth', 'v'), ('map', 'a'), ('apparatus', 'n'), ('claim', 'n'), ('wherein', None), ('first', 'a'), ('field', 'n'), ('view', 'n'), ('narrow', 'a'), ('angle', 'a'), ('second', 'a'), ('field', 'n'), ('view', 'n'), ('wider', 'v'), ('angle', 'n'), ('apparatus', 'n'), ('claim', 'n'), ('wherein', None), ('second', 'a'), ('image', 'n'), ('divided', 'v'), ('primary', 'a'), ('region', 'n'), ('residual', 'a'), ('region', 'n'), ('second', 'a'), ('depth', 'n'), ('map', 'n'), ('generator', 'n'), ('comprises', 'v'), ('relationship', 'n'), ('estimating', 'v'), ('module', 'n'), ('configured', 'v'), ('estimate', 'n'), ('relationship', 'n'), ('primary', 'a'), ('region', 'n'), ('residual', 'a'), ('region', 'n'), ('based', 'v'), ('first', 'a'), ('image', 'n'), ('second', 'a'), ('image', 'n'), ('depth', 'n'), ('map', 'n'), ('estimating', 'v'), ('module', 'n'), ('configured', 'v'), ('estimate', 'n'), ('depth', 'n'), ('map', 'v'), ('residual', 'a'), ('region', 'n'), ('based', 'v'), ('estimated', 'v'), ('relationship', 'n'), ('first', 'a'), ('depth', 'n'), ('map', 'n'), ('apparatus', 'n'), ('claim', 'n'), ('wherein', 'v'), ('least', 'a'), ('one', None), ('relationship', 'n'), ('estimating', 'v'), ('module', 'n'), ('depth', 'n'), ('map', 'n'), ('estimating', 'v'), ('module', 'n'), ('performs', 'n'), ('estimating', 'v'), ('operation', 'n'), ('based', 'v'), ('neural', 'a'), ('network', 'n'), ('module', 'n'), ('apparatus', 'n'), ('claim', 'n'), ('comprising', 'v'), ('depth', 'n'), ('map', None), ('fusion', 'n'), ('unit', 'n'), ('configured', 'v'), ('generate', 'a'), ('third', 'a'), ('depth', 'n'), ('map', 'n'), ('second', 'a'), ('image', 'n'), ('performing', 'v'), ('fusion', 'n'), ('operation', 'n'), ('based', 'v'), ('first', 'r'), ('depth', 'a'), ('map', 'a'), ('second', 'a'), ('depth', 'n'), ('map', 'n'), ('apparatus', 'n'), ('claim', 'n'), ('wherein', 'n'), ('depth', 'n'), ('map', 'a'), ('fusion', 'n'), ('unit', 'n'), ('comprises', 'v'), ('tone', None), ('mapping', 'n'), ('module', 'n'), ('configured', 'v'), ('generate', 'a'), ('tone-mapped', 'a'), ('second', 'a'), ('depth', 'n'), ('map', 'n'), ('correspond', 'n'), ('first', 'r'), ('depth', 'v'), ('map', 'n'), ('performing', 'v'), ('bias', 'a'), ('removing', 'v'), ('operation', 'n'), ('second', 'a'), ('depth', 'n'), ('map', 'n'), ('fusion', 'n'), ('module', 'n'), ('configured', 'v'), ('generate', 'a'), ('third', 'a'), ('depth', 'n'), ('map', 'n'), ('fusing', 'v'), ('tone-mapped', 'a'), ('second', 'a'), ('depth', 'n'), ('map', 'n'), ('first', 'r'), ('depth', 'v'), ('map', 'a'), ('apparatus', 'n'), ('claim', 'n'), ('wherein', 'n'), ('depth', 'n'), ('map', 'a'), ('fusion', 'n'), ('unit', 'n'), ('comprises', 'v'), ('propagating', 'v'), ('module', 'n'), ('configured', 'v'), ('generate', 'n'), ('propagated', 'v'), ('first', 'a'), ('depth', 'n'), ('map', 'n'), ('second', 'a'), ('image', 'n'), ('iterated', 'v'), ('propagating', 'v'), ('first', 'a'), ('depth', 'n'), ('map', 'n'), ('based', 'v'), ('first', 'r'), ('depth', 'a'), ('map', 'n'), ('second', 'a'), ('image', 'n'), ('fusion', 'n'), ('module', 'n'), ('generates', 'v'), ('third', 'a'), ('depth', 'n'), ('map', 'n'), ('fusing', 'v'), ('tone-mapped', 'a'), ('second', 'a'), ('depth', 'n'), ('map', 'n'), ('propagated', 'v'), ('first', 'a'), ('depth', 'n'), ('map', 'n'), ('apparatus', 'n'), ('claim', 'n'), ('wherein', 'n'), ('depth', 'n'), ('map', 'a'), ('fusion', 'n'), ('unit', 'n'), ('comprises', 'v'), ('post-processing', 'a'), ('module', 'n'), ('configured', 'v'), ('perform', 'a'), ('post-processing', 'a'), ('operation', 'n'), ('third', 'a'), ('depth', 'n'), ('map', 'n'), ('generated', 'v'), ('fusion', 'n'), ('module', 'n'), ('provide', None), ('post-processed', 'a'), ('third', 'a'), ('depth', 'n'), ('map', 'n'), ('apparatus', 'n'), ('claim', 'n'), ('wherein', None), ('post-processing', 'a'), ('module', 'n'), ('performs', 'n'), ('post-processing', 'a'), ('operation', 'n'), ('filtering', 'v'), ('interface', 'n'), ('generated', 'v'), ('third', 'a'), ('depth', 'a'), ('map', 'n'), ('accordance', 'n'), ('fusion', 'n'), ('fusion', 'n'), ('module', 'n'), ('apparatus', 'n'), ('claim', 'n'), ('wherein', None), ('post-processing', 'a'), ('module', 'n'), ('removes', 'v'), ('artifacts', 'n'), ('generated', 'v'), ('third', 'a'), ('depth', 'a'), ('map', 'n'), ('accordance', 'n'), ('fusion', 'n'), ('fusion', 'n'), ('module', 'n'), ('apparatus', 'n'), ('claim', 'n'), ('wherein', None), ('first', 'a'), ('depth', 'n'), ('map', 'n'), ('generator', 'n'), ('analyses', 'v'), ('distance', 'n'), ('relationship', 'n'), ('first', 'a'), ('image', 'n'), ('second', 'a'), ('image', 'n'), ('generates', 'n'), ('first', 'r'), ('depth', 'v'), ('map', 'n'), ('first', 'r'), ('image', 'n'), ('based', 'v'), ('distance', 'n'), ('relationship', 'n'), ('method', 'n'), ('processing', 'n'), ('image', 'n'), ('electronic', 'a'), ('apparatus', 'n'), ('method', 'n'), ('comprising', 'v'), ('obtaining', 'v'), ('first', 'a'), ('image', 'n'), ('object', 'n'), ('using', 'v'), ('first', 'a'), ('camera', 'n'), ('module', 'n'), ('obtaining', 'v'), ('second', 'a'), ('image', 'n'), ('object', 'n'), ('using', 'v'), ('second', 'a'), ('camera', 'n'), ('module', 'n'), ('generating', 'v'), ('first', 'a'), ('depth', 'n'), ('map', 'n'), ('first', 'r'), ('image', 'n'), ('based', 'v'), ('first', 'a'), ('image', 'n'), ('second', 'a'), ('image', 'n'), ('estimating', 'v'), ('relationship', 'n'), ('primary', 'a'), ('region', 'n'), ('second', 'a'), ('image', 'n'), ('residual', 'a'), ('region', 'n'), ('second', 'a'), ('image', 'n'), ('based', 'v'), ('first', 'a'), ('image', 'n'), ('second', 'a'), ('image', 'n'), ('generating', 'v'), ('second', 'a'), ('depth', 'n'), ('map', 'n'), ('second', 'a'), ('image', 'n'), ('based', 'v'), ('estimated', 'v'), ('relationship', 'n'), ('primary', 'a'), ('region', 'n'), ('residual', 'a'), ('region', 'n'), ('first', 'r'), ('depth', 'v'), ('map', 'a'), ('method', 'n'), ('claim', 'n'), ('wherein', 'v'), ('electronic', 'a'), ('apparatus', 'n'), ('comprises', 'n'), ('first', 'r'), ('camera', 'v'), ('module', 'n'), ('including', 'v'), ('first', 'a'), ('lens', 'n'), ('first', 'a'), ('field', 'n'), ('view', 'n'), ('second', 'a'), ('camera', 'n'), ('module', 'n'), ('including', 'v'), ('second', 'a'), ('lens', 'a'), ('second', 'a'), ('field', 'n'), ('view', 'n'), ('wider', 'v'), ('first', 'a'), ('field', 'n'), ('view', 'n'), ('method', 'v'), ('claim', 'n'), ('wherein', 'n'), ('generating', 'v'), ('second', 'a'), ('depth', 'n'), ('map', 'n'), ('comprises', 'v'), ('estimating', 'v'), ('depth', 'n'), ('map', None), ('residual', 'a'), ('region', 'n'), ('based', 'v'), ('estimated', 'v'), ('relationship', 'n'), ('primary', 'a'), ('region', 'n'), ('residual', 'a'), ('region', 'n'), ('first', 'r'), ('depth', 'v'), ('map', 'a'), ('generating', 'v'), ('second', 'a'), ('depth', 'n'), ('map', 'n'), ('based', 'v'), ('depth', 'a'), ('map', 'a'), ('residual', 'a'), ('region', 'n'), ('first', 'r'), ('depth', 'v'), ('map', 'a'), ('method', 'n'), ('claim', 'n'), ('wherein', None), ('estimating', 'v'), ('relationship', 'n'), ('primary', 'a'), ('region', 'n'), ('second', 'a'), ('image', 'n'), ('performed', 'v'), ('using', 'v'), ('neural', 'a'), ('network', 'n'), ('model', 'n'), ('method', 'n'), ('claim', 'n'), ('comprising', 'v'), ('performing', 'v'), ('pre-processing', 'a'), ('operation', 'n'), ('second', 'a'), ('depth', 'n'), ('map', 'n'), ('generating', 'v'), ('third', 'a'), ('depth', 'n'), ('map', 'n'), ('residual', 'a'), ('image', 'n'), ('fusing', 'v'), ('second', 'a'), ('depth', 'a'), ('map', 'n'), ('pre-processing', 'a'), ('operation', 'n'), ('performed', 'v'), ('first', 'a'), ('depth', 'n'), ('map', 'n'), ('method', 'n'), ('claim', 'n'), ('wherein', None), ('performing', 'v'), ('pre-processing', 'a'), ('operation', 'n'), ('comprises', 'n'), ('performing', 'v'), ('tone', 'n'), ('mapping', 'n'), ('operation', 'n'), ('depth', 'n'), ('map', 'n'), ('primary', 'a'), ('region', 'n'), ('depth', 'n'), ('map', 'v'), ('residual', 'a'), ('region', 'n'), ('based', 'v'), ('second', 'a'), ('depth', 'n'), ('map', 'n'), ('operating', 'v'), ('method', 'n'), ('electronic', 'a'), ('apparatus', 'n'), ('electronic', 'a'), ('apparatus', 'n'), ('including', 'v'), ('first', 'a'), ('camera', 'n'), ('module', 'n'), ('providing', 'v'), ('first', 'a'), ('image', 'n'), ('object', 'n'), ('using', 'v'), ('first', 'a'), ('field', 'n'), ('view', 'n'), ('second', 'a'), ('camera', 'n'), ('module', 'n'), ('providing', 'v'), ('second', 'a'), ('image', 'n'), ('object', 'n'), ('using', 'v'), ('second', 'a'), ('field', 'n'), ('view', 'n'), ('wider', 'v'), ('first', 'a'), ('field', 'n'), ('view', 'n'), ('processor', 'n'), ('generating', 'v'), ('depth', 'a'), ('map', 'a'), ('second', 'a'), ('image', 'n'), ('based', 'v'), ('primary', 'a'), ('region', 'n'), ('second', 'a'), ('image', 'n'), ('residual', 'a'), ('region', 'n'), ('second', 'a'), ('image', 'n'), ('operating', 'v'), ('method', 'n'), ('comprising', 'v'), ('generating', 'v'), ('first', 'a'), ('depth', 'n'), ('map', 'n'), ('primary', 'a'), ('region', 'n'), ('estimating', 'v'), ('relationship', 'n'), ('first', 'a'), ('image', 'n'), ('second', 'a'), ('image', 'n'), ('estimating', 'v'), ('relationship', 'n'), ('primary', 'a'), ('region', 'n'), ('residual', 'a'), ('region', 'n'), ('based', 'v'), ('first', 'a'), ('image', 'n'), ('second', 'a'), ('image', 'n'), ('generating', 'v'), ('second', 'a'), ('depth', 'n'), ('map', 'n'), ('second', 'a'), ('image', 'n'), ('estimating', 'v'), ('depth', 'a'), ('map', 'a'), ('second', 'a'), ('region', 'n'), ('based', 'v'), ('estimated', 'v'), ('relationship', 'n'), ('primary', 'a'), ('region', 'n'), ('residual', 'a'), ('region', 'n'), ('generating', 'v'), ('depth', 'a'), ('map', 'a'), ('second', 'a'), ('image', 'n'), ('fusing', 'v'), ('first', 'a'), ('depth', 'n'), ('map', 'n'), ('second', 'a'), ('depth', 'n'), ('map', 'n'), ('operation', 'n'), ('method', 'n'), ('claim', 'n'), ('comprising', 'v'), ('executing', 'v'), ('application', 'n'), ('applies', 'n'), ('image', 'n'), ('effect', 'n'), ('second', 'a'), ('image', 'n'), ('based', 'v'), ('depth', 'a'), ('map', 'n'), ('residual', 'a'), ('image', 'n'), ('operation', 'n'), ('method', None), ('claim', 'n'), ('wherein', None), ('application', 'n'), ('applies', 'v'), ('least', 'a'), ('one', None), ('image', 'n'), ('effect', 'n'), ('auto-focusing', 'a'), ('out-focusing', 'a'), ('forebackground', 'n'), ('separation', 'n'), ('face', 'n'), ('recognition', 'n'), ('object', 'a'), ('detection', 'n'), ('within', None), ('frame', 'n'), ('augmented', 'a'), ('reality', 'n'), ('second', 'a'), ('image', 'n'), ('based', 'v'), ('depth', 'a'), ('map', 'a'), ('second', 'a'), ('image', 'n'), ('payment', 'n'), ('method', 'n'), ('based', 'v'), ('face', 'n'), ('recognition', 'n'), ('comprising', 'v'), ('acquiring', 'v'), ('first', 'a'), ('face', 'n'), ('image', 'n'), ('information', 'n'), ('target', 'n'), ('user', 'n'), ('extracting', 'v'), ('first', 'a'), ('characteristic', 'a'), ('information', 'n'), ('first', 'r'), ('face', 'n'), ('image', 'n'), ('information', 'n'), ('wherein', None), ('first', 'a'), ('characteristic', 'a'), ('information', 'n'), ('includes', 'v'), ('head', 'n'), ('posture', 'n'), ('information', 'n'), ('target', 'n'), ('user', 'n'), ('gaze', 'n'), ('information', 'n'), ('target', 'n'), ('user', 'n'), ('determining', 'v'), ('whether', None), ('target', 'n'), ('user', 'a'), ('willingness', 'n'), ('pay', 'n'), ('according', 'v'), ('head', 'n'), ('posture', 'n'), ('information', 'n'), ('target', 'n'), ('user', 'n'), ('gaze', 'n'), ('information', 'n'), ('target', 'n'), ('user', 'n'), ('including', 'v'), ('determining', 'v'), ('whether', None), ('angle', 'a'), ('rotation', 'n'), ('preset', 'v'), ('direction', 'n'), ('less', 'r'), ('angle', 'a'), ('threshold', 'n'), ('wherein', 'n'), ('head', 'n'), ('posture', 'n'), ('information', 'n'), ('includes', 'v'), ('angle', 'a'), ('rotation', 'n'), ('preset', 'v'), ('direction', 'n'), ('determining', 'v'), ('whether', None), ('probability', 'n'), ('value', 'n'), ('user', 'n'), ('gazes', 'a'), ('payment', 'n'), ('screen', 'n'), ('greater', 'a'), ('probability', 'n'), ('threshold', 'n'), ('wherein', 'n'), ('gaze', 'a'), ('information', 'n'), ('includes', 'v'), ('probability', 'n'), ('value', 'n'), ('user', 'n'), ('gazes', 'a'), ('payment', 'n'), ('screen', 'n'), ('response', 'n'), ('determining', 'v'), ('angle', 'a'), ('rotation', 'n'), ('preset', 'v'), ('direction', 'n'), ('less', 'r'), ('angle', 'a'), ('threshold', 'n'), ('probability', 'n'), ('value', 'n'), ('user', 'n'), ('gazes', 'a'), ('payment', 'n'), ('screen', 'n'), ('greater', 'a'), ('probability', 'n'), ('threshold', 'v'), ('determining', 'v'), ('target', 'n'), ('user', 'a'), ('willingness', 'n'), ('pay', 'n'), ('response', 'n'), ('determining', 'v'), ('target', 'n'), ('user', 'a'), ('willingness', 'n'), ('pay', 'n'), ('completing', 'v'), ('payment', 'n'), ('operation', 'n'), ('based', 'v'), ('face', 'n'), ('recognition', 'n'), ('method', 'n'), ('claimed', 'v'), ('claim', 'n'), ('wherein', 'n'), ('completing', 'v'), ('payment', 'n'), ('operation', 'n'), ('based', 'v'), ('face', 'n'), ('recognition', 'n'), ('comprises', 'v'), ('triggering', 'v'), ('performing', 'v'), ('payment', 'n'), ('initiating', 'n'), ('operation', 'n'), ('acquire', 'v'), ('second', 'a'), ('face', 'n'), ('image', 'n'), ('information', 'n'), ('based', 'v'), ('face', 'n'), ('recognition', 'n'), ('determining', 'v'), ('whether', None), ('second', 'a'), ('characteristic', 'a'), ('information', 'n'), ('extracted', 'v'), ('second', 'a'), ('face', 'n'), ('image', 'n'), ('information', 'n'), ('indicates', 'v'), ('user', 'a'), ('willingness', 'n'), ('pay', 'n'), ('response', 'n'), ('determining', 'v'), ('second', 'a'), ('characteristic', 'a'), ('information', 'n'), ('indicates', 'v'), ('user', 'a'), ('willingness', 'n'), ('pay', 'n'), ('triggering', 'v'), ('performing', 'v'), ('payment', 'n'), ('confirmation', 'n'), ('operation', 'n'), ('complete', 'a'), ('payment', 'n'), ('operation', 'n'), ('based', 'v'), ('payment', 'n'), ('account', 'n'), ('information', 'n'), ('corresponding', 'v'), ('target', 'n'), ('user', 'a'), ('method', 'n'), ('claimed', 'v'), ('claim', 'n'), ('wherein', 'n'), ('determining', 'v'), ('whether', None), ('second', 'a'), ('characteristic', 'a'), ('information', 'n'), ('extracted', 'v'), ('second', 'a'), ('face', 'n'), ('image', 'n'), ('information', 'n'), ('indicates', 'v'), ('user', 'a'), ('willingness', 'n'), ('pay', 'n'), ('comprises', 'v'), ('determining', 'v'), ('whether', None), ('current', 'a'), ('user', 'n'), ('corresponding', 'v'), ('second', 'a'), ('face', 'n'), ('image', 'n'), ('information', 'n'), ('consistent', 'a'), ('target', 'n'), ('user', 'a'), ('response', 'n'), ('determining', 'v'), ('current', 'a'), ('user', 'a'), ('consistent', 'n'), ('target', 'n'), ('user', None), ('determining', 'v'), ('whether', None), ('target', 'n'), ('user', 'a'), ('willingness', 'n'), ('pay', 'n'), ('according', 'v'), ('second', 'a'), ('characteristic', 'a'), ('information', 'n'), ('extracted', 'v'), ('second', 'a'), ('face', 'n'), ('image', 'n'), ('information', 'n'), ('method', 'n'), ('claimed', 'v'), ('claim', 'n'), ('wherein', 'n'), ('extracting', 'v'), ('first', 'a'), ('characteristic', 'a'), ('information', 'n'), ('first', 'r'), ('face', 'n'), ('image', 'n'), ('information', 'n'), ('comprises', 'v'), ('determining', 'v'), ('head', 'n'), ('posture', 'n'), ('information', 'n'), ('target', 'n'), ('user', 'n'), ('using', 'v'), ('head', 'n'), ('posture', 'n'), ('recognition', 'n'), ('model', 'n'), ('based', 'v'), ('first', 'a'), ('face', 'n'), ('image', 'n'), ('information', 'n'), ('determining', 'v'), ('gaze', 'n'), ('information', 'n'), ('target', 'n'), ('user', 'n'), ('using', 'v'), ('gaze', 'a'), ('information', 'n'), ('recognition', 'n'), ('model', 'n'), ('based', 'v'), ('characteristics', 'n'), ('eye', 'n'), ('region', 'n'), ('first', 'r'), ('face', 'a'), ('image', 'n'), ('information', 'n'), ('method', 'n'), ('claimed', 'v'), ('claim', 'n'), ('wherein', 'n'), ('head', 'n'), ('posture', 'n'), ('recognition', 'n'), ('model', 'n'), ('obtained', 'v'), ('training', 'v'), ('acquiring', 'v'), ('first', 'a'), ('sample', 'n'), ('data', 'n'), ('set', 'v'), ('wherein', 'n'), ('first', 'a'), ('sample', 'n'), ('data', 'n'), ('set', 'v'), ('includes', 'v'), ('plurality', 'n'), ('pieces', 'n'), ('first', 'r'), ('sample', 'a'), ('data', 'n'), ('plurality', 'n'), ('pieces', 'n'), ('first', 'r'), ('sample', 'a'), ('data', 'n'), ('includes', 'v'), ('correspondence', 'n'), ('sample', 'n'), ('face', 'n'), ('image', 'n'), ('head', 'n'), ('posture', 'n'), ('information', 'n'), ('determining', 'v'), ('mean', 'a'), ('image', 'n'), ('data', 'n'), ('variance', 'n'), ('image', 'n'), ('data', 'n'), ('plurality', 'n'), ('sample', 'n'), ('face', 'n'), ('images', 'v'), ('plurality', 'n'), ('pieces', 'n'), ('first', 'r'), ('sample', 'a'), ('data', 'n'), ('preprocessing', 'v'), ('sample', 'a'), ('face', 'n'), ('image', 'n'), ('contained', 'v'), ('plurality', 'n'), ('pieces', 'n'), ('first', 'r'), ('sample', 'v'), ('data', 'n'), ('based', 'v'), ('mean', 'a'), ('image', 'n'), ('data', 'n'), ('variance', 'n'), ('image', 'n'), ('data', 'n'), ('obtain', 'v'), ('preprocessed', 'a'), ('sample', 'n'), ('face', 'n'), ('image', 'n'), ('setting', 'v'), ('preprocessed', 'a'), ('sample', 'n'), ('face', 'n'), ('image', 'n'), ('corresponding', 'v'), ('head', 'a'), ('posture', 'n'), ('information', 'n'), ('first', 'r'), ('model', 'v'), ('training', 'v'), ('sample', 'a'), ('performing', 'v'), ('training', 'n'), ('using', 'v'), ('machine', 'n'), ('learning', 'v'), ('method', 'n'), ('based', 'v'), ('plurality', 'n'), ('first', 'a'), ('model', 'n'), ('training', 'n'), ('samples', 'n'), ('obtain', 'v'), ('head', 'a'), ('posture', 'n'), ('recognition', 'n'), ('model', 'n'), ('method', 'n'), ('claimed', 'v'), ('claim', 'n'), ('wherein', 'n'), ('gaze', 'n'), ('information', 'n'), ('recognition', 'n'), ('model', 'n'), ('obtained', 'v'), ('training', 'v'), ('acquiring', 'v'), ('second', 'a'), ('sample', 'n'), ('data', 'n'), ('set', 'v'), ('wherein', 'a'), ('second', 'a'), ('sample', 'n'), ('data', 'n'), ('set', 'v'), ('includes', 'v'), ('plurality', 'n'), ('pieces', 'n'), ('second', 'a'), ('sample', 'n'), ('data', 'n'), ('plurality', 'n'), ('pieces', 'n'), ('second', 'a'), ('sample', 'a'), ('data', 'n'), ('includes', 'v'), ('correspondence', 'n'), ('sample', 'n'), ('eye', 'n'), ('image', 'n'), ('gaze', 'a'), ('information', 'n'), ('determining', 'v'), ('mean', 'a'), ('image', 'n'), ('data', 'n'), ('variance', 'n'), ('image', 'n'), ('data', 'n'), ('plurality', 'n'), ('sample', 'n'), ('eye', 'n'), ('images', 'v'), ('plurality', 'n'), ('pieces', 'n'), ('second', 'a'), ('sample', 'n'), ('data', 'n'), ('preprocessing', 'v'), ('sample', 'n'), ('eye', 'n'), ('image', 'n'), ('contained', 'v'), ('plurality', 'n'), ('pieces', 'n'), ('second', 'a'), ('sample', 'n'), ('data', 'n'), ('based', 'v'), ('mean', 'a'), ('image', 'n'), ('data', 'n'), ('variance', 'n'), ('image', 'n'), ('data', 'n'), ('obtain', 'v'), ('preprocessed', 'a'), ('sample', 'n'), ('eye', 'n'), ('image', 'n'), ('setting', 'v'), ('preprocessed', 'a'), ('sample', 'n'), ('eye', 'n'), ('image', 'n'), ('corresponding', 'v'), ('gaze', 'a'), ('information', 'n'), ('second', 'a'), ('model', 'n'), ('training', 'v'), ('sample', 'a'), ('performing', 'v'), ('training', 'n'), ('using', 'v'), ('machine', 'n'), ('learning', 'v'), ('method', 'n'), ('based', 'v'), ('plurality', 'n'), ('second', 'a'), ('model', 'n'), ('training', 'n'), ('samples', 'n'), ('obtain', 'v'), ('gaze', 'a'), ('information', 'n'), ('recognition', 'n'), ('model', 'n'), ('method', 'n'), ('claimed', 'v'), ('claim', 'n'), ('wherein', 'n'), ('angle', 'v'), ('rotation', 'n'), ('preset', 'v'), ('direction', 'n'), ('comprises', 'v'), ('pitch', 'v'), ('angle', 'n'), ('yaw', 'n'), ('angle', 'n'), ('roll', 'n'), ('angle', 'n'), ('wherein', 'n'), ('pitch', 'n'), ('angle', 'n'), ('refers', 'n'), ('angle', 'v'), ('rotation', 'n'), ('around', None), ('x-axis', 'a'), ('yaw', 'n'), ('angle', 'n'), ('refers', 'n'), ('angle', 'v'), ('rotation', 'n'), ('around', None), ('y-axis', 'a'), ('roll', 'n'), ('angle', 'n'), ('refers', 'n'), ('angle', 'v'), ('rotation', 'n'), ('around', None), ('z-axis', 'a'), ('payment', 'n'), ('device', 'n'), ('based', 'v'), ('face', 'n'), ('recognition', 'n'), ('comprising', 'v'), ('processor', 'a'), ('non-transitory', 'a'), ('computer-readable', 'a'), ('storage', 'n'), ('medium', 'n'), ('storing', 'v'), ('instructions', 'n'), ('executable', 'a'), ('processor', 'n'), ('cause', 'n'), ('device', 'n'), ('perform', 'n'), ('operations', 'n'), ('comprising', 'v'), ('acquiring', 'v'), ('first', 'a'), ('face', 'n'), ('image', 'n'), ('information', 'n'), ('target', 'n'), ('user', 'n'), ('extracting', 'v'), ('first', 'a'), ('characteristic', 'a'), ('information', 'n'), ('first', 'r'), ('face', 'n'), ('image', 'n'), ('information', 'n'), ('wherein', None), ('first', 'a'), ('characteristic', 'a'), ('information', 'n'), ('includes', 'v'), ('head', 'n'), ('posture', 'n'), ('information', 'n'), ('target', 'n'), ('user', 'n'), ('gaze', 'n'), ('information', 'n'), ('target', 'n'), ('user', 'n'), ('determining', 'v'), ('whether', None), ('target', 'n'), ('user', 'a'), ('willingness', 'n'), ('pay', 'n'), ('according', 'v'), ('head', 'n'), ('posture', 'n'), ('information', 'n'), ('target', 'n'), ('user', 'n'), ('gaze', 'n'), ('information', 'n'), ('target', 'n'), ('user', 'n'), ('including', 'v'), ('determining', 'v'), ('whether', None), ('angle', 'a'), ('rotation', 'n'), ('preset', 'v'), ('direction', 'n'), ('less', 'r'), ('angle', 'a'), ('threshold', 'n'), ('wherein', 'n'), ('head', 'n'), ('posture', 'n'), ('information', 'n'), ('includes', 'v'), ('angle', 'a'), ('rotation', 'n'), ('preset', 'v'), ('direction', 'n'), ('determining', 'v'), ('whether', None), ('probability', 'n'), ('value', 'n'), ('user', 'n'), ('gazes', 'a'), ('payment', 'n'), ('screen', 'n'), ('greater', 'a'), ('probability', 'n'), ('threshold', 'n'), ('wherein', 'n'), ('gaze', 'a'), ('information', 'n'), ('includes', 'v'), ('probability', 'n'), ('value', 'n'), ('user', 'n'), ('gazes', 'a'), ('payment', 'n'), ('screen', 'n'), ('response', 'n'), ('determining', 'v'), ('angle', 'a'), ('rotation', 'n'), ('preset', 'v'), ('direction', 'n'), ('less', 'r'), ('angle', 'a'), ('threshold', 'n'), ('probability', 'n'), ('value', 'n'), ('user', 'n'), ('gazes', 'a'), ('payment', 'n'), ('screen', 'n'), ('greater', 'a'), ('probability', 'n'), ('threshold', 'v'), ('determining', 'v'), ('target', 'n'), ('user', 'a'), ('willingness', 'n'), ('pay', 'n'), ('response', 'n'), ('determining', 'v'), ('target', 'n'), ('user', 'a'), ('willingness', 'n'), ('pay', 'n'), ('completing', 'v'), ('payment', 'n'), ('operation', 'n'), ('based', 'v'), ('face', 'n'), ('recognition', 'n'), ('device', 'n'), ('claimed', 'v'), ('claim', 'n'), ('wherein', 'n'), ('completing', 'v'), ('payment', 'n'), ('operation', 'n'), ('based', 'v'), ('face', 'n'), ('recognition', 'n'), ('comprises', 'v'), ('triggering', 'v'), ('performing', 'v'), ('payment', 'n'), ('initiating', 'n'), ('operation', 'n'), ('acquire', 'v'), ('second', 'a'), ('face', 'n'), ('image', 'n'), ('information', 'n'), ('based', 'v'), ('face', 'n'), ('recognition', 'n'), ('determining', 'v'), ('whether', None), ('second', 'a'), ('characteristic', 'a'), ('information', 'n'), ('extracted', 'v'), ('second', 'a'), ('face', 'n'), ('image', 'n'), ('information', 'n'), ('indicates', 'v'), ('user', 'a'), ('willingness', 'n'), ('pay', 'n'), ('response', 'n'), ('determining', 'v'), ('second', 'a'), ('characteristic', 'a'), ('information', 'n'), ('indicates', 'v'), ('user', 'a'), ('willingness', 'n'), ('pay', 'n'), ('triggering', 'v'), ('performing', 'v'), ('payment', 'n'), ('confirmation', 'n'), ('operation', 'n'), ('complete', 'a'), ('payment', 'n'), ('operation', 'n'), ('based', 'v'), ('payment', 'n'), ('account', 'n'), ('information', 'n'), ('corresponding', 'v'), ('target', 'n'), ('user', 'a'), ('device', 'n'), ('claimed', 'v'), ('claim', 'n'), ('wherein', 'n'), ('determining', 'v'), ('whether', None), ('second', 'a'), ('characteristic', 'a'), ('information', 'n'), ('extracted', 'v'), ('second', 'a'), ('face', 'n'), ('image', 'n'), ('information', 'n'), ('indicates', 'v'), ('user', 'a'), ('willingness', 'n'), ('pay', 'n'), ('comprises', 'v'), ('determining', 'v'), ('whether', None), ('current', 'a'), ('user', 'n'), ('corresponding', 'v'), ('second', 'a'), ('face', 'n'), ('image', 'n'), ('information', 'n'), ('consistent', 'a'), ('target', 'n'), ('user', 'a'), ('response', 'n'), ('determining', 'v'), ('current', 'a'), ('user', 'a'), ('consistent', 'n'), ('target', 'n'), ('user', None), ('determining', 'v'), ('whether', None), ('target', 'n'), ('user', 'a'), ('willingness', 'n'), ('pay', 'n'), ('according', 'v'), ('second', 'a'), ('characteristic', 'a'), ('information', 'n'), ('extracted', 'v'), ('second', 'a'), ('face', 'n'), ('image', 'n'), ('information', 'n'), ('device', 'n'), ('claimed', 'v'), ('claim', 'n'), ('wherein', 'n'), ('extracting', 'v'), ('first', 'a'), ('characteristic', 'a'), ('information', 'n'), ('first', 'r'), ('face', 'n'), ('image', 'n'), ('information', 'n'), ('comprises', 'v'), ('determining', 'v'), ('head', 'n'), ('posture', 'n'), ('information', 'n'), ('target', 'n'), ('user', 'n'), ('using', 'v'), ('head', 'n'), ('posture', 'n'), ('recognition', 'n'), ('model', 'n'), ('based', 'v'), ('first', 'a'), ('face', 'n'), ('image', 'n'), ('information', 'n'), ('determining', 'v'), ('gaze', 'n'), ('information', 'n'), ('target', 'n'), ('user', 'n'), ('using', 'v'), ('gaze', 'a'), ('information', 'n'), ('recognition', 'n'), ('model', 'n'), ('based', 'v'), ('characteristics', 'n'), ('eye', 'n'), ('region', 'n'), ('first', 'r'), ('face', 'a'), ('image', 'n'), ('information', 'n'), ('device', 'n'), ('claimed', 'v'), ('claim', 'n'), ('wherein', 'n'), ('head', 'n'), ('posture', 'n'), ('recognition', 'n'), ('model', 'n'), ('obtained', 'v'), ('training', 'v'), ('acquiring', 'v'), ('first', 'a'), ('sample', 'n'), ('data', 'n'), ('set', 'v'), ('wherein', 'n'), ('first', 'a'), ('sample', 'n'), ('data', 'n'), ('set', 'v'), ('includes', 'v'), ('plurality', 'n'), ('pieces', 'n'), ('first', 'r'), ('sample', 'a'), ('data', 'n'), ('plurality', 'n'), ('pieces', 'n'), ('first', 'r'), ('sample', 'a'), ('data', 'n'), ('includes', 'v'), ('correspondence', 'n'), ('sample', 'n'), ('face', 'n'), ('image', 'n'), ('head', 'n'), ('posture', 'n'), ('information', 'n'), ('determining', 'v'), ('mean', 'a'), ('image', 'n'), ('data', 'n'), ('variance', 'n'), ('image', 'n'), ('data', 'n'), ('plurality', 'n'), ('sample', 'n'), ('face', 'n'), ('images', 'v'), ('plurality', 'n'), ('pieces', 'n'), ('first', 'r'), ('sample', 'a'), ('data', 'n'), ('preprocessing', 'v'), ('sample', 'a'), ('face', 'n'), ('image', 'n'), ('contained', 'v'), ('plurality', 'n'), ('pieces', 'n'), ('first', 'r'), ('sample', 'v'), ('data', 'n'), ('based', 'v'), ('mean', 'a'), ('image', 'n'), ('data', 'n'), ('variance', 'n'), ('image', 'n'), ('data', 'n'), ('obtain', 'v'), ('preprocessed', 'a'), ('sample', 'n'), ('face', 'n'), ('image', 'n'), ('setting', 'v'), ('preprocessed', 'a'), ('sample', 'n'), ('face', 'n'), ('image', 'n'), ('corresponding', 'v'), ('head', 'a'), ('posture', 'n'), ('information', 'n'), ('first', 'r'), ('model', 'v'), ('training', 'v'), ('sample', 'a'), ('performing', 'v'), ('training', 'n'), ('using', 'v'), ('machine', 'n'), ('learning', 'v'), ('method', 'n'), ('based', 'v'), ('plurality', 'n'), ('first', 'a'), ('model', 'n'), ('training', 'n'), ('samples', 'n'), ('obtain', 'v'), ('head', 'a'), ('posture', 'n'), ('recognition', 'n'), ('model', 'n'), ('device', 'n'), ('claimed', 'v'), ('claim', 'n'), ('wherein', 'n'), ('gaze', 'n'), ('information', 'n'), ('recognition', 'n'), ('model', 'n'), ('obtained', 'v'), ('training', 'v'), ('acquiring', 'v'), ('second', 'a'), ('sample', 'n'), ('data', 'n'), ('set', 'v'), ('wherein', 'a'), ('second', 'a'), ('sample', 'n'), ('data', 'n'), ('set', 'v'), ('includes', 'v'), ('plurality', 'n'), ('pieces', 'n'), ('second', 'a'), ('sample', 'n'), ('data', 'n'), ('plurality', 'n'), ('pieces', 'n'), ('second', 'a'), ('sample', 'a'), ('data', 'n'), ('includes', 'v'), ('correspondence', 'n'), ('sample', 'n'), ('eye', 'n'), ('image', 'n'), ('gaze', 'a'), ('information', 'n'), ('determining', 'v'), ('mean', 'a'), ('image', 'n'), ('data', 'n'), ('variance', 'n'), ('image', 'n'), ('data', 'n'), ('plurality', 'n'), ('sample', 'n'), ('eye', 'n'), ('images', 'v'), ('plurality', 'n'), ('pieces', 'n'), ('second', 'a'), ('sample', 'n'), ('data', 'n'), ('preprocessing', 'v'), ('sample', 'n'), ('eye', 'n'), ('image', 'n'), ('contained', 'v'), ('plurality', 'n'), ('pieces', 'n'), ('second', 'a'), ('sample', 'n'), ('data', 'n'), ('based', 'v'), ('mean', 'a'), ('image', 'n'), ('data', 'n'), ('variance', 'n'), ('image', 'n'), ('data', 'n'), ('obtain', 'v'), ('preprocessed', 'a'), ('sample', 'n'), ('eye', 'n'), ('image', 'n'), ('setting', 'v'), ('preprocessed', 'a'), ('sample', 'n'), ('eye', 'n'), ('image', 'n'), ('corresponding', 'v'), ('gaze', 'a'), ('information', 'n'), ('second', 'a'), ('model', 'n'), ('training', 'v'), ('sample', 'a'), ('performing', 'v'), ('training', 'n'), ('using', 'v'), ('machine', 'n'), ('learning', 'v'), ('method', 'a'), ('plurality', 'n'), ('second', 'a'), ('model', 'n'), ('training', 'n'), ('samples', 'n'), ('obtain', 'v'), ('gaze', 'a'), ('information', 'n'), ('recognition', 'n'), ('model', 'n'), ('device', 'n'), ('claimed', 'v'), ('claim', 'n'), ('wherein', 'n'), ('angle', 'v'), ('rotation', 'n'), ('preset', 'v'), ('direction', 'n'), ('comprises', 'v'), ('pitch', 'v'), ('angle', 'n'), ('yaw', 'n'), ('angle', 'n'), ('roll', 'n'), ('angle', 'n'), ('wherein', 'n'), ('pitch', 'n'), ('angle', 'n'), ('refers', 'n'), ('angle', 'v'), ('rotation', 'n'), ('around', None), ('x-axis', 'a'), ('yaw', 'n'), ('angle', 'n'), ('refers', 'n'), ('angle', 'v'), ('rotation', 'n'), ('around', None), ('y-axis', 'a'), ('roll', 'n'), ('angle', 'n'), ('refers', 'n'), ('angle', 'v'), ('rotation', 'n'), ('around', None), ('z-axis', 'a'), ('non-transitory', 'a'), ('computer-readable', 'a'), ('storage', 'n'), ('medium', 'n'), ('payment', 'n'), ('based', 'v'), ('face', 'n'), ('recognition', 'n'), ('configured', 'v'), ('instructions', 'n'), ('executable', 'a'), ('one', None), ('processors', 'n'), ('cause', 'v'), ('one', None), ('processors', 'n'), ('perform', 'v'), ('operations', 'n'), ('comprising', 'v'), ('acquiring', 'v'), ('first', 'a'), ('face', 'n'), ('image', 'n'), ('information', 'n'), ('target', 'n'), ('user', 'n'), ('extracting', 'v'), ('first', 'a'), ('characteristic', 'a'), ('information', 'n'), ('first', 'r'), ('face', 'n'), ('image', 'n'), ('information', 'n'), ('wherein', None), ('first', 'a'), ('characteristic', 'a'), ('information', 'n'), ('includes', 'v'), ('head', 'n'), ('posture', 'n'), ('information', 'n'), ('target', 'n'), ('user', 'n'), ('gaze', 'n'), ('information', 'n'), ('target', 'n'), ('user', 'n'), ('determining', 'v'), ('whether', None), ('target', 'n'), ('user', 'a'), ('willingness', 'n'), ('pay', 'n'), ('according', 'v'), ('head', 'n'), ('posture', 'n'), ('information', 'n'), ('target', 'n'), ('user', 'n'), ('gaze', 'n'), ('information', 'n'), ('target', 'n'), ('user', 'n'), ('including', 'v'), ('determining', 'v'), ('whether', None), ('angle', 'a'), ('rotation', 'n'), ('preset', 'v'), ('direction', 'n'), ('less', 'r'), ('angle', 'a'), ('threshold', 'n'), ('wherein', 'n'), ('head', 'n'), ('posture', 'n'), ('information', 'n'), ('includes', 'v'), ('angle', 'a'), ('rotation', 'n'), ('preset', 'v'), ('direction', 'n'), ('determining', 'v'), ('whether', None), ('probability', 'n'), ('value', 'n'), ('user', 'n'), ('gazes', 'a'), ('payment', 'n'), ('screen', 'n'), ('greater', 'a'), ('probability', 'n'), ('threshold', 'n'), ('wherein', 'n'), ('gaze', 'a'), ('information', 'n'), ('includes', 'v'), ('probability', 'n'), ('value', 'n'), ('user', 'n'), ('gazes', 'a'), ('payment', 'n'), ('screen', 'n'), ('response', 'n'), ('determining', 'v'), ('angle', 'a'), ('rotation', 'n'), ('preset', 'v'), ('direction', 'n'), ('less', 'r'), ('angle', 'a'), ('threshold', 'n'), ('probability', 'n'), ('value', 'n'), ('user', 'n'), ('gazes', 'a'), ('payment', 'n'), ('screen', 'n'), ('greater', 'a'), ('probability', 'n'), ('threshold', 'v'), ('determining', 'v'), ('target', 'n'), ('user', 'a'), ('willingness', 'n'), ('pay', 'n'), ('response', 'n'), ('determining', 'v'), ('target', 'n'), ('user', 'a'), ('willingness', 'n'), ('pay', 'n'), ('completing', 'v'), ('payment', 'n'), ('operation', 'n'), ('based', 'v'), ('face', 'n'), ('recognition', 'n'), ('storage', 'n'), ('medium', 'n'), ('claimed', 'v'), ('claim', 'n'), ('wherein', 'n'), ('completing', 'v'), ('payment', 'n'), ('operation', 'n'), ('based', 'v'), ('face', 'n'), ('recognition', 'n'), ('comprises', 'v'), ('triggering', 'v'), ('performing', 'v'), ('payment', 'n'), ('initiating', 'n'), ('operation', 'n'), ('acquire', 'v'), ('second', 'a'), ('face', 'n'), ('image', 'n'), ('information', 'n'), ('based', 'v'), ('face', 'n'), ('recognition', 'n'), ('determining', 'v'), ('whether', None), ('second', 'a'), ('characteristic', 'a'), ('information', 'n'), ('extracted', 'v'), ('second', 'a'), ('face', 'n'), ('image', 'n'), ('information', 'n'), ('indicates', 'v'), ('user', 'a'), ('willingness', 'n'), ('pay', 'n'), ('response', 'n'), ('determining', 'v'), ('second', 'a'), ('characteristic', 'a'), ('information', 'n'), ('indicates', 'v'), ('user', 'a'), ('willingness', 'n'), ('pay', 'n'), ('triggering', 'v'), ('performing', 'v'), ('payment', 'n'), ('confirmation', 'n'), ('operation', 'n'), ('complete', 'a'), ('payment', 'n'), ('operation', 'n'), ('based', 'v'), ('payment', 'n'), ('account', 'n'), ('information', 'n'), ('corresponding', 'v'), ('target', 'n'), ('user', 'a'), ('storage', 'n'), ('medium', 'n'), ('claimed', 'v'), ('claim', 'n'), ('wherein', 'n'), ('determining', 'v'), ('whether', None), ('second', 'a'), ('characteristic', 'a'), ('information', 'n'), ('extracted', 'v'), ('second', 'a'), ('face', 'n'), ('image', 'n'), ('information', 'n'), ('indicates', 'v'), ('user', 'a'), ('willingness', 'n'), ('pay', 'n'), ('comprises', 'v'), ('determining', 'v'), ('whether', None), ('current', 'a'), ('user', 'n'), ('corresponding', 'v'), ('second', 'a'), ('face', 'n'), ('image', 'n'), ('information', 'n'), ('consistent', 'a'), ('target', 'n'), ('user', 'a'), ('response', 'n'), ('determining', 'v'), ('current', 'a'), ('user', 'a'), ('consistent', 'n'), ('target', 'n'), ('user', None), ('determining', 'v'), ('whether', None), ('target', 'n'), ('user', 'a'), ('willingness', 'n'), ('pay', 'n'), ('according', 'v'), ('second', 'a'), ('characteristic', 'a'), ('information', 'n'), ('extracted', 'v'), ('second', 'a'), ('face', 'n'), ('image', 'n'), ('information', 'n'), ('storage', 'n'), ('medium', 'n'), ('claimed', 'v'), ('claim', 'n'), ('wherein', 'n'), ('extracting', 'v'), ('first', 'a'), ('characteristic', 'a'), ('information', 'n'), ('first', 'r'), ('face', 'n'), ('image', 'n'), ('information', 'n'), ('comprises', 'v'), ('determining', 'v'), ('head', 'n'), ('posture', 'n'), ('information', 'n'), ('target', 'n'), ('user', 'n'), ('using', 'v'), ('head', 'n'), ('posture', 'n'), ('recognition', 'n'), ('model', 'n'), ('based', 'v'), ('first', 'a'), ('face', 'n'), ('image', 'n'), ('information', 'n'), ('determining', 'v'), ('gaze', 'n'), ('information', 'n'), ('target', 'n'), ('user', 'n'), ('using', 'v'), ('gaze', 'a'), ('information', 'n'), ('recognition', 'n'), ('model', 'n'), ('based', 'v'), ('characteristics', 'n'), ('eye', 'n'), ('region', 'n'), ('first', 'r'), ('face', 'a'), ('image', 'n'), ('information', 'n'), ('storage', 'n'), ('medium', 'n'), ('claimed', 'v'), ('claim', 'n'), ('wherein', 'n'), ('head', 'n'), ('posture', 'n'), ('recognition', 'n'), ('model', 'n'), ('obtained', 'v'), ('training', 'v'), ('acquiring', 'v'), ('first', 'a'), ('sample', 'n'), ('data', 'n'), ('set', 'v'), ('wherein', 'n'), ('first', 'a'), ('sample', 'n'), ('data', 'n'), ('set', 'v'), ('includes', 'v'), ('plurality', 'n'), ('pieces', 'n'), ('first', 'r'), ('sample', 'a'), ('data', 'n'), ('plurality', 'n'), ('pieces', 'n'), ('first', 'r'), ('sample', 'a'), ('data', 'n'), ('includes', 'v'), ('correspondence', 'n'), ('sample', 'n'), ('face', 'n'), ('image', 'n'), ('head', 'n'), ('posture', 'n'), ('information', 'n'), ('determining', 'v'), ('mean', 'a'), ('image', 'n'), ('data', 'n'), ('variance', 'n'), ('image', 'n'), ('data', 'n'), ('plurality', 'n'), ('sample', 'n'), ('face', 'n'), ('images', 'v'), ('plurality', 'n'), ('pieces', 'n'), ('first', 'r'), ('sample', 'a'), ('data', 'n'), ('preprocessing', 'v'), ('sample', 'a'), ('face', 'n'), ('image', 'n'), ('contained', 'v'), ('plurality', 'n'), ('pieces', 'n'), ('first', 'r'), ('sample', 'v'), ('data', 'n'), ('based', 'v'), ('mean', 'a'), ('image', 'n'), ('data', 'n'), ('variance', 'n'), ('image', 'n'), ('data', 'n'), ('obtain', 'v'), ('preprocessed', 'a'), ('sample', 'n'), ('face', 'n'), ('image', 'n'), ('setting', 'v'), ('preprocessed', 'a'), ('sample', 'n'), ('face', 'n'), ('image', 'n'), ('corresponding', 'v'), ('head', 'a'), ('posture', 'n'), ('information', 'n'), ('first', 'r'), ('model', 'v'), ('training', 'v'), ('sample', 'a'), ('performing', 'v'), ('training', 'n'), ('using', 'v'), ('machine', 'n'), ('learning', 'v'), ('method', 'n'), ('based', 'v'), ('plurality', 'n'), ('first', 'a'), ('model', 'n'), ('training', 'n'), ('samples', 'n'), ('obtain', 'v'), ('head', 'a'), ('posture', 'n'), ('recognition', 'n'), ('model', 'n'), ('wherein', 'v'), ('gaze', 'a'), ('information', 'n'), ('recognition', 'n'), ('model', 'n'), ('obtained', 'v'), ('training', 'v'), ('acquiring', 'v'), ('second', 'a'), ('sample', 'n'), ('data', 'n'), ('set', 'v'), ('wherein', 'a'), ('second', 'a'), ('sample', 'n'), ('data', 'n'), ('set', 'v'), ('includes', 'v'), ('plurality', 'n'), ('pieces', 'n'), ('second', 'a'), ('sample', 'n'), ('data', 'n'), ('plurality', 'n'), ('pieces', 'n'), ('second', 'a'), ('sample', 'a'), ('data', 'n'), ('includes', 'v'), ('correspondence', 'n'), ('sample', 'n'), ('eye', 'n'), ('image', 'n'), ('gaze', 'a'), ('information', 'n'), ('determining', 'v'), ('mean', 'a'), ('image', 'n'), ('data', 'n'), ('variance', 'n'), ('image', 'n'), ('data', 'n'), ('plurality', 'n'), ('sample', 'n'), ('eye', 'n'), ('images', 'v'), ('plurality', 'n'), ('pieces', 'n'), ('second', 'a'), ('sample', 'n'), ('data', 'n'), ('preprocessing', 'v'), ('sample', 'n'), ('eye', 'n'), ('image', 'n'), ('contained', 'v'), ('plurality', 'n'), ('pieces', 'n'), ('second', 'a'), ('sample', 'n'), ('data', 'n'), ('based', 'v'), ('mean', 'a'), ('image', 'n'), ('data', 'n'), ('variance', 'n'), ('image', 'n'), ('data', 'n'), ('obtain', 'v'), ('preprocessed', 'a'), ('sample', 'n'), ('eye', 'n'), ('image', 'n'), ('setting', 'v'), ('preprocessed', 'a'), ('sample', 'n'), ('eye', 'n'), ('image', 'n'), ('corresponding', 'v'), ('gaze', 'a'), ('information', 'n'), ('second', 'a'), ('model', 'n'), ('training', 'v'), ('sample', 'a'), ('performing', 'v'), ('training', 'n'), ('using', 'v'), ('machine', 'n'), ('learning', 'v'), ('method', 'n'), ('based', 'v'), ('plurality', 'n'), ('second', 'a'), ('model', 'n'), ('training', 'n'), ('samples', 'n'), ('obtain', 'v'), ('gaze', 'a'), ('information', 'n'), ('recognition', 'n'), ('model', 'n'), ('storage', 'n'), ('medium', 'n'), ('claimed', 'v'), ('claim', 'n'), ('wherein', 'n'), ('angle', 'v'), ('rotation', 'n'), ('preset', 'v'), ('direction', 'n'), ('comprises', 'v'), ('pitch', 'v'), ('angle', 'n'), ('yaw', 'n'), ('angle', 'n'), ('roll', 'n'), ('angle', 'n'), ('wherein', 'n'), ('pitch', 'n'), ('angle', 'n'), ('refers', 'n'), ('angle', 'v'), ('rotation', 'n'), ('around', None), ('x-axis', 'a'), ('yaw', 'n'), ('angle', 'n'), ('refers', 'n'), ('angle', 'v'), ('rotation', 'n'), ('around', None), ('y-axis', 'a'), ('roll', 'n'), ('angle', 'n'), ('refers', 'n'), ('angle', 'v'), ('rotation', 'n'), ('around', None), ('z-axis', 'a'), ('method', 'n'), ('comprising', 'v'), ('detecting', 'v'), ('motion', 'n'), ('detection', 'n'), ('module', 'n'), ('motion', 'n'), ('subject', 'n'), ('within', None), ('predetermined', 'a'), ('area', 'n'), ('view', 'n'), ('assigning', 'v'), ('unique', 'a'), ('session', 'n'), ('identification', 'n'), ('number', 'n'), ('subject', 'a'), ('detected', 'v'), ('within', None), ('predetermined', 'a'), ('area', 'n'), ('view', 'n'), ('detecting', 'v'), ('facial', 'a'), ('area', 'n'), ('subject', 'n'), ('detected', 'v'), ('within', None), ('predetermined', 'a'), ('area', 'n'), ('view', 'n'), ('generating', 'v'), ('image', 'n'), ('facial', 'a'), ('area', 'n'), ('subject', 'n'), ('assessing', 'v'), ('quality', 'n'), ('image', 'n'), ('facial', 'a'), ('area', 'n'), ('subject', 'a'), ('determining', 'v'), ('identity', 'n'), ('subject', 'n'), ('based', 'v'), ('image', 'n'), ('facial', 'a'), ('area', 'n'), ('subject', 'a'), ('identifying', 'v'), ('intent', 'n'), ('subject', 'a'), ('authorizing', 'v'), ('access', 'n'), ('point', 'n'), ('entry', 'n'), ('based', 'v'), ('determined', 'v'), ('identity', 'n'), ('subject', 'n'), ('based', 'v'), ('intent', 'n'), ('subject', 'a'), ('method', 'n'), ('claim', 'n'), ('comprising', 'v'), ('determining', 'v'), ('one', None), ('additional', 'a'), ('subjects', 'n'), ('within', None), ('predetermined', 'a'), ('area', 'n'), ('view', 'n'), ('assigning', 'v'), ('unique', 'a'), ('session', 'n'), ('identification', 'n'), ('number', 'n'), ('one', None), ('additional', 'a'), ('subjects', 'n'), ('detected', 'v'), ('within', None), ('predetermined', 'a'), ('area', 'n'), ('view', 'n'), ('method', 'n'), ('claim', 'n'), ('wherein', None), ('assessing', 'v'), ('quality', 'n'), ('image', 'n'), ('facial', 'a'), ('area', 'n'), ('subject', 'a'), ('comprises', 'v'), ('assessing', 'v'), ('whether', None), ('quality', 'n'), ('image', 'n'), ('facial', 'a'), ('area', 'n'), ('object', 'n'), ('equates', 'n'), ('predetermined', 'v'), ('metric', 'a'), ('quality', 'n'), ('upon', None), ('determining', 'v'), ('quality', 'n'), ('image', 'n'), ('facial', 'a'), ('area', 'n'), ('object', 'v'), ('inferior', 'a'), ('predetermined', 'v'), ('metric', 'a'), ('quality', 'n'), ('discarding', 'v'), ('image', 'n'), ('facial', 'a'), ('area', 'n'), ('subject', 'a'), ('generating', 'v'), ('second', 'a'), ('image', 'n'), ('facial', 'a'), ('area', 'n'), ('subject', 'a'), ('method', 'n'), ('claim', 'n'), ('comprising', 'v'), ('detecting', 'v'), ('whether', None), ('facial', 'a'), ('area', 'n'), ('subject', 'a'), ('photographic', 'a'), ('image', 'n'), ('upon', None), ('detecting', 'v'), ('facial', 'a'), ('area', 'n'), ('subject', 'a'), ('photographic', 'a'), ('image', 'n'), ('generating', 'v'), ('warning', 'v'), ('restrict', 'a'), ('access', 'n'), ('point', 'n'), ('entry', 'n'), ('method', 'n'), ('claim', 'n'), ('comprising', 'v'), ('conducing', 'v'), ('incremental', 'a'), ('training', 'n'), ('image', 'n'), ('facial', 'a'), ('area', 'n'), ('subject', 'a'), ('method', 'n'), ('claim', 'n'), ('wherein', None), ('conducing', 'v'), ('incremental', 'a'), ('training', 'n'), ('image', 'n'), ('facial', 'a'), ('area', 'n'), ('subject', 'a'), ('comprises', 'n'), ('capturing', 'v'), ('first', 'a'), ('image', 'n'), ('facial', 'a'), ('area', 'n'), ('facial', 'a'), ('landmarks', 'n'), ('converting', 'v'), ('first', 'a'), ('image', 'n'), ('facial', 'a'), ('area', 'n'), ('first', 'r'), ('numeric', 'a'), ('vector', 'n'), ('capturing', 'v'), ('second', 'a'), ('image', 'n'), ('facial', 'a'), ('area', 'n'), ('facial', 'a'), ('landmarks', 'n'), ('converting', 'v'), ('second', 'a'), ('image', 'n'), ('facial', 'a'), ('area', 'n'), ('second', 'a'), ('numeric', 'a'), ('vector', 'n'), ('calculating', 'v'), ('weighted', 'v'), ('mean', 'a'), ('first', 'a'), ('numeric', 'a'), ('vector', 'n'), ('second', 'a'), ('numeric', 'a'), ('vector', 'n'), ('wherein', 'n'), ('weighted', 'v'), ('mean', 'a'), ('represents', 'v'), ('change', 'v'), ('facial', 'a'), ('area', 'n'), ('storing', 'v'), ('weighted', 'a'), ('mean', 'a'), ('database', 'n'), ('method', 'n'), ('claim', 'n'), ('wherein', None), ('determining', 'v'), ('identity', 'n'), ('subject', 'n'), ('based', 'v'), ('image', 'n'), ('facial', 'a'), ('area', 'n'), ('subject', 'a'), ('comprises', 'v'), ('comparing', 'v'), ('image', 'n'), ('facial', 'a'), ('area', 'n'), ('subject', 'a'), ('plurality', 'n'), ('images', 'n'), ('stored', 'v'), ('database', 'n'), ('authenticating', 'v'), ('subject', 'a'), ('method', 'n'), ('claim', 'n'), ('wherein', None), ('identifying', 'v'), ('intent', 'n'), ('subject', 'n'), ('comprises', 'v'), ('upon', None), ('detecting', 'v'), ('facial', 'a'), ('area', 'n'), ('bounding', 'v'), ('box', 'n'), ('commencing', 'v'), ('authentication', 'n'), ('subject', 'a'), ('calculating', 'v'), ('directional', 'a'), ('vector', 'n'), ('face', 'n'), ('subject', 'a'), ('determine', 'a'), ('intent', 'n'), ('subject', 'a'), ('gain', 'n'), ('access', 'n'), ('point', 'n'), ('entry', 'n'), ('based', 'v'), ('directional', 'a'), ('vector', 'n'), ('face', 'n'), ('subject', 'a'), ('granting', 'v'), ('access', 'n'), ('point', 'n'), ('entry', 'n'), ('based', 'v'), ('authentication', 'n'), ('subject', 'n'), ('based', 'v'), ('determining', 'v'), ('intent', 'n'), ('subject', 'a'), ('non-transitory', 'a'), ('computer', 'n'), ('readable', 'a'), ('medium', 'n'), ('program', 'n'), ('instructions', 'n'), ('stored', 'v'), ('thereon', 'a'), ('response', 'n'), ('execution', 'n'), ('computing', 'v'), ('device', 'n'), ('cause', 'n'), ('computing', 'v'), ('device', 'n'), ('perform', 'n'), ('operations', 'n'), ('comprising', 'v'), ('detecting', 'v'), ('motion', 'n'), ('subject', 'n'), ('within', None), ('predetermined', 'a'), ('area', 'n'), ('view', 'n'), ('assigning', 'v'), ('unique', 'a'), ('session', 'n'), ('identification', 'n'), ('number', 'n'), ('subject', 'a'), ('detected', 'v'), ('within', None), ('predetermined', 'a'), ('area', 'n'), ('view', 'n'), ('detecting', 'v'), ('facial', 'a'), ('area', 'n'), ('subject', 'n'), ('detected', 'v'), ('within', None), ('predetermined', 'a'), ('area', 'n'), ('view', 'n'), ('generating', 'v'), ('image', 'n'), ('facial', 'a'), ('area', 'n'), ('subject', 'n'), ('assessing', 'v'), ('quality', 'n'), ('image', 'n'), ('facial', 'a'), ('area', 'n'), ('subject', 'a'), ('determining', 'v'), ('identity', 'n'), ('subject', 'n'), ('based', 'v'), ('image', 'n'), ('facial', 'a'), ('area', 'n'), ('subject', 'a'), ('identifying', 'v'), ('intent', 'n'), ('subject', 'a'), ('authorizing', 'v'), ('access', 'n'), ('point', 'n'), ('entry', 'n'), ('based', 'v'), ('determined', 'v'), ('identity', 'n'), ('subject', 'n'), ('based', 'v'), ('intent', 'n'), ('subject', 'a'), ('non-transitory', 'a'), ('computer', 'n'), ('readable', 'a'), ('medium', 'n'), ('claim', 'n'), ('comprising', 'v'), ('determining', 'v'), ('one', None), ('additional', 'a'), ('subjects', 'n'), ('within', None), ('predetermined', 'a'), ('area', 'n'), ('view', 'n'), ('assigning', 'v'), ('unique', 'a'), ('session', 'n'), ('identification', 'n'), ('number', 'n'), ('one', None), ('additional', 'a'), ('subjects', 'n'), ('detected', 'v'), ('within', None), ('predetermined', 'a'), ('area', 'n'), ('view', 'n'), ('non-transitory', 'a'), ('computer', 'n'), ('readable', 'a'), ('medium', 'n'), ('claim', 'n'), ('wherein', None), ('assessing', 'v'), ('quality', 'n'), ('image', 'n'), ('facial', 'a'), ('area', 'n'), ('subject', 'a'), ('comprises', 'v'), ('assessing', 'v'), ('whether', None), ('quality', 'n'), ('image', 'n'), ('facial', 'a'), ('area', 'n'), ('object', 'n'), ('equates', 'n'), ('predetermined', 'v'), ('metric', 'a'), ('quality', 'n'), ('upon', None), ('determining', 'v'), ('quality', 'n'), ('image', 'n'), ('facial', 'a'), ('area', 'n'), ('object', 'v'), ('inferior', 'a'), ('predetermined', 'v'), ('metric', 'a'), ('quality', 'n'), ('discarding', 'v'), ('image', 'n'), ('facial', 'a'), ('area', 'n'), ('subject', 'a'), ('generating', 'v'), ('second', 'a'), ('image', 'n'), ('facial', 'a'), ('area', 'n'), ('subject', 'a'), ('non-transitory', 'a'), ('computer', 'n'), ('readable', 'a'), ('medium', 'n'), ('claim', 'n'), ('comprising', 'v'), ('detecting', 'v'), ('whether', None), ('facial', 'a'), ('area', 'n'), ('subject', 'a'), ('photographic', 'a'), ('image', 'n'), ('upon', None), ('detecting', 'v'), ('facial', 'a'), ('area', 'n'), ('subject', 'a'), ('photographic', 'a'), ('image', 'n'), ('generating', 'v'), ('warning', 'v'), ('restrict', 'a'), ('access', 'n'), ('access', 'n'), ('point', 'n'), ('non-transitory', 'a'), ('computer', 'n'), ('readable', 'a'), ('medium', 'n'), ('claim', 'n'), ('comprising', 'v'), ('conducing', 'v'), ('incremental', 'a'), ('training', 'n'), ('image', 'n'), ('facial', 'a'), ('area', 'n'), ('subject', 'a'), ('non-transitory', 'a'), ('computer', 'n'), ('readable', 'a'), ('medium', 'n'), ('claim', 'n'), ('wherein', None), ('conducing', 'v'), ('incremental', 'a'), ('training', 'n'), ('image', 'n'), ('facial', 'a'), ('area', 'n'), ('subject', 'a'), ('comprises', 'n'), ('capturing', 'v'), ('first', 'a'), ('image', 'n'), ('facial', 'a'), ('area', 'n'), ('facial', 'a'), ('landmarks', 'n'), ('converting', 'v'), ('first', 'a'), ('image', 'n'), ('facial', 'a'), ('area', 'n'), ('first', 'r'), ('numeric', 'a'), ('vector', 'n'), ('capturing', 'v'), ('second', 'a'), ('image', 'n'), ('facial', 'a'), ('area', 'n'), ('facial', 'a'), ('landmarks', 'n'), ('converting', 'v'), ('second', 'a'), ('image', 'n'), ('facial', 'a'), ('area', 'n'), ('second', 'a'), ('numeric', 'a'), ('vector', 'n'), ('calculating', 'v'), ('weighted', 'v'), ('mean', 'a'), ('first', 'a'), ('numeric', 'a'), ('vector', 'n'), ('second', 'a'), ('numeric', 'a'), ('vector', 'n'), ('wherein', 'n'), ('weighted', 'v'), ('mean', 'a'), ('represents', 'v'), ('change', 'v'), ('facial', 'a'), ('area', 'n'), ('storing', 'v'), ('weighted', 'a'), ('mean', 'a'), ('database', 'n'), ('apparatus', 'n'), ('face', 'n'), ('recognition', 'n'), ('comprising', 'v'), ('processor', 'a'), ('memory', 'n'), ('store', 'n'), ('computer', 'n'), ('program', 'n'), ('instructions', 'n'), ('computer', 'n'), ('program', 'n'), ('instructions', 'n'), ('executed', 'v'), ('processor', 'n'), ('cause', 'n'), ('processor', 'n'), ('perform', 'n'), ('operations', 'n'), ('comprising', 'v'), ('detecting', 'v'), ('motion', 'n'), ('subject', 'n'), ('within', None), ('predetermined', 'a'), ('area', 'n'), ('view', 'n'), ('assigning', 'v'), ('unique', 'a'), ('session', 'n'), ('identification', 'n'), ('number', 'n'), ('subject', 'a'), ('detected', 'v'), ('within', None), ('predetermined', 'a'), ('area', 'n'), ('view', 'n'), ('detecting', 'v'), ('facial', 'a'), ('area', 'n'), ('subject', 'n'), ('detected', 'v'), ('within', None), ('predetermined', 'a'), ('area', 'n'), ('view', 'n'), ('generating', 'v'), ('image', 'n'), ('facial', 'a'), ('area', 'n'), ('subject', 'n'), ('assessing', 'v'), ('quality', 'n'), ('image', 'n'), ('facial', 'a'), ('area', 'n'), ('subject', 'a'), ('determining', 'v'), ('identity', 'n'), ('subject', 'n'), ('based', 'v'), ('image', 'n'), ('facial', 'a'), ('area', 'n'), ('subject', 'a'), ('identifying', 'v'), ('intent', 'n'), ('subject', 'a'), ('authorizing', 'v'), ('access', 'n'), ('point', 'n'), ('entry', 'n'), ('based', 'v'), ('determined', 'v'), ('identity', 'n'), ('subject', 'n'), ('based', 'v'), ('intent', 'n'), ('subject', 'a'), ('apparatus', 'n'), ('claim', 'n'), ('comprising', 'v'), ('determining', 'v'), ('one', None), ('additional', 'a'), ('subjects', 'n'), ('within', None), ('predetermined', 'a'), ('area', 'n'), ('view', 'n'), ('assigning', 'v'), ('unique', 'a'), ('session', 'n'), ('identification', 'n'), ('number', 'n'), ('one', None), ('additional', 'a'), ('subjects', 'n'), ('detected', 'v'), ('within', None), ('predetermined', 'a'), ('area', 'n'), ('view', 'n'), ('apparatus', 'v'), ('claim', 'n'), ('wherein', 'n'), ('assessing', 'v'), ('quality', 'n'), ('image', 'n'), ('facial', 'a'), ('area', 'n'), ('subject', 'a'), ('comprises', 'v'), ('assessing', 'v'), ('whether', None), ('quality', 'n'), ('image', 'n'), ('facial', 'a'), ('area', 'n'), ('object', 'n'), ('equates', 'n'), ('predetermined', 'v'), ('metric', 'a'), ('quality', 'n'), ('upon', None), ('determining', 'v'), ('quality', 'n'), ('image', 'n'), ('facial', 'a'), ('area', 'n'), ('object', 'v'), ('inferior', 'a'), ('predetermined', 'v'), ('metric', 'a'), ('quality', 'n'), ('discarding', 'v'), ('image', 'n'), ('facial', 'a'), ('area', 'n'), ('subject', 'a'), ('generating', 'v'), ('second', 'a'), ('image', 'n'), ('facial', 'a'), ('area', 'n'), ('subject', 'a'), ('apparatus', 'n'), ('claim', 'n'), ('comprising', 'v'), ('detecting', 'v'), ('whether', None), ('facial', 'a'), ('area', 'n'), ('subject', 'a'), ('photographic', 'a'), ('image', 'n'), ('upon', None), ('detecting', 'v'), ('facial', 'a'), ('area', 'n'), ('subject', 'a'), ('photographic', 'a'), ('image', 'n'), ('generating', 'v'), ('warning', 'v'), ('restrict', 'a'), ('access', 'n'), ('access', 'n'), ('point', 'n'), ('apparatus', 'n'), ('claim', 'n'), ('comprising', 'v'), ('conducing', 'v'), ('incremental', 'a'), ('training', 'n'), ('image', 'n'), ('facial', 'a'), ('area', 'n'), ('subject', 'a'), ('apparatus', 'n'), ('claim', 'n'), ('wherein', None), ('conducing', 'v'), ('incremental', 'a'), ('training', 'n'), ('image', 'n'), ('facial', 'a'), ('area', 'n'), ('subject', 'a'), ('comprises', 'n'), ('capturing', 'v'), ('first', 'a'), ('image', 'n'), ('facial', 'a'), ('area', 'n'), ('facial', 'a'), ('landmarks', 'n'), ('converting', 'v'), ('first', 'a'), ('image', 'n'), ('facial', 'a'), ('area', 'n'), ('first', 'r'), ('numeric', 'a'), ('vector', 'n'), ('capturing', 'v'), ('second', 'a'), ('image', 'n'), ('facial', 'a'), ('area', 'n'), ('facial', 'a'), ('landmarks', 'n'), ('converting', 'v'), ('second', 'a'), ('image', 'n'), ('facial', 'a'), ('area', 'n'), ('second', 'a'), ('numeric', 'a'), ('vector', 'n'), ('calculating', 'v'), ('weighted', 'v'), ('mean', 'a'), ('first', 'a'), ('numeric', 'a'), ('vector', 'n'), ('second', 'a'), ('numeric', 'a'), ('vector', 'n'), ('wherein', 'n'), ('weighted', 'v'), ('mean', 'a'), ('represents', 'v'), ('change', 'v'), ('facial', 'a'), ('area', 'n'), ('storing', 'v'), ('weighted', 'a'), ('mean', 'a'), ('database', 'n'), ('robot', 'n'), ('comprising', 'v'), ('body', 'n'), ('configured', 'v'), ('rotate', 'a'), ('tilt', 'n'), ('camera', 'n'), ('coupled', 'v'), ('body', 'n'), ('configured', 'a'), ('rotate', 'n'), ('tilt', 'n'), ('according', 'v'), ('rotate', 'n'), ('tilt', 'n'), ('body', 'n'), ('wherein', 'a'), ('camera', 'n'), ('configured', 'v'), ('acquire', 'v'), ('video', 'n'), ('space', 'n'), ('face', 'n'), ('recognition', 'n'), ('unit', 'n'), ('configured', 'v'), ('recognize', 'a'), ('respective', 'a'), ('faces', 'v'), ('one', None), ('persons', 'n'), ('video', 'v'), ('tracking', 'v'), ('unit', 'n'), ('configured', 'v'), ('track', 'a'), ('motion', 'n'), ('recognized', 'v'), ('faces', 'v'), ('one', None), ('persons', 'n'), ('controller', 'n'), ('configured', 'v'), ('calculate', 'a'), ('respective', 'a'), ('size', 'n'), ('faces', 'v'), ('one', None), ('persons', 'n'), ('select', 'v'), ('first', 'a'), ('person', 'n'), ('among', None), ('one', None), ('persons', 'n'), ('based', 'v'), ('calculated', 'a'), ('sizes', 'n'), ('faces', 'v'), ('control', 'n'), ('least', 'a'), ('one', None), ('direction', 'n'), ('rotation', 'n'), ('camera', 'n'), ('angle', 'n'), ('tilt', 'n'), ('camera', 'n'), ('focal', 'a'), ('distance', 'n'), ('camera', 'n'), ('based', 'v'), ('tracked', 'a'), ('motion', 'n'), ('recognized', 'v'), ('face', 'n'), ('first', 'r'), ('person', 'n'), ('robot', 'a'), ('claim', 'n'), ('wherein', 'n'), ('controller', 'n'), ('configured', 'v'), ('control', 'a'), ('direction', 'n'), ('rotation', 'n'), ('camera', 'n'), ('angle', 'n'), ('tilt', 'n'), ('camera', 'n'), ('achieve', 'v'), ('particular', 'a'), ('orientation', 'n'), ('camera', 'n'), ('relative', 'a'), ('face', 'n'), ('first', 'r'), ('person', 'n'), ('control', 'n'), ('focal', 'a'), ('distance', 'n'), ('camera', 'n'), ('comparing', 'v'), ('respective', 'a'), ('sizes', 'n'), ('face', 'v'), ('first', 'a'), ('person', 'n'), ('motion', 'n'), ('first', 'r'), ('person', 'n'), ('robot', 'a'), ('claim', 'n'), ('wherein', None), ('particular', 'a'), ('orientation', 'n'), ('occurs', 'v'), ('camera', 'n'), ('faces', 'v'), ('general', 'a'), ('direction', 'n'), ('face', 'n'), ('first', 'r'), ('person', 'n'), ('robot', 'a'), ('claim', 'n'), ('wherein', 'n'), ('controller', 'n'), ('configured', 'v'), ('normalize', 'a'), ('sizes', 'n'), ('faces', 'v'), ('one', None), ('persons', 'n'), ('based', 'v'), ('interocular', 'a'), ('distance', 'n'), ('select', 'n'), ('first', 'r'), ('person', 'n'), ('based', 'v'), ('normalized', 'a'), ('sizes', 'n'), ('faces', 'v'), ('one', None), ('persons', 'n'), ('robot', 'v'), ('claim', 'n'), ('wherein', 'n'), ('controller', 'n'), ('configured', 'v'), ('select', 'a'), ('person', 'n'), ('largest', 'a'), ('face', 'n'), ('size', 'n'), ('among', None), ('one', None), ('persons', 'n'), ('first', 'a'), ('person', 'n'), ('robot', 'a'), ('claim', 'n'), ('comprising', 'v'), ('microphone', 'n'), ('configured', 'v'), ('receive', 'a'), ('spoken', 'n'), ('audio', 'n'), ('present', 'a'), ('space', 'n'), ('wherein', 'n'), ('controller', 'n'), ('configured', 'v'), ('select', 'a'), ('first', 'a'), ('person', 'n'), ('based', 'v'), ('received', 'v'), ('spoken', 'a'), ('audio', 'a'), ('robot', 'n'), ('claim', 'n'), ('wherein', 'v'), ('controller', 'n'), ('configured', 'v'), ('control', 'n'), ('gain', 'n'), ('microphone', 'n'), ('comparing', 'v'), ('respective', 'a'), ('sizes', 'n'), ('face', 'v'), ('first', 'a'), ('person', 'n'), ('motion', 'n'), ('first', 'r'), ('person', 'n'), ('robot', 'a'), ('claim', 'n'), ('wherein', 'n'), ('controller', 'n'), ('configured', 'v'), ('calculate', 'a'), ('position', 'n'), ('spoken', 'v'), ('audio', 'n'), ('provided', 'v'), ('select', 'a'), ('first', 'a'), ('person', 'n'), ('based', 'v'), ('whether', None), ('one', None), ('persons', 'n'), ('position', 'n'), ('voice', 'n'), ('signal', 'n'), ('provided', 'v'), ('robot', 'a'), ('claim', 'n'), ('wherein', 'n'), ('controller', 'n'), ('configured', 'v'), ('select', 'a'), ('second', 'a'), ('person', 'n'), ('first', 'a'), ('person', 'n'), ('among', None), ('one', None), ('persons', 'n'), ('second', 'a'), ('person', 'n'), ('located', 'v'), ('position', 'n'), ('spoken', 'v'), ('audio', 'n'), ('provided', 'v'), ('robot', 'a'), ('claim', 'n'), ('wherein', 'n'), ('controller', 'n'), ('configured', 'v'), ('select', 'a'), ('second', 'a'), ('person', 'n'), ('largest', 'a'), ('face', 'n'), ('size', 'n'), ('first', 'a'), ('person', 'n'), ('among', None), ('one', None), ('persons', 'n'), ('none', 'n'), ('one', None), ('persons', 'n'), ('located', 'v'), ('position', 'n'), ('spoken', 'v'), ('audio', 'n'), ('provided', 'v'), ('robot', 'a'), ('claim', 'n'), ('wherein', 'n'), ('controller', 'n'), ('configured', 'v'), ('select', 'a'), ('second', 'a'), ('person', 'n'), ('largest', 'a'), ('face', 'n'), ('size', 'n'), ('first', 'a'), ('person', 'n'), ('among', None), ('one', None), ('persons', 'n'), ('plurality', 'n'), ('persons', 'n'), ('among', None), ('one', None), ('persons', 'n'), ('located', 'v'), ('position', 'n'), ('spoken', 'v'), ('audio', 'n'), ('provided', 'v'), ('robot', 'a'), ('claim', 'n'), ('comprising', 'v'), ('speaker', 'n'), ('wherein', 'n'), ('controller', 'n'), ('configured', 'v'), ('control', 'n'), ('volume', 'n'), ('speaker', 'n'), ('comparing', 'v'), ('respective', 'a'), ('sizes', 'n'), ('face', 'v'), ('first', 'a'), ('person', 'n'), ('motion', 'n'), ('first', 'r'), ('person', 'n'), ('robot', 'a'), ('claim', 'n'), ('wherein', None), ('body', 'n'), ('configured', 'a'), ('rotate', 'a'), ('lateral', 'a'), ('direction', 'n'), ('tilt', 'v'), ('vertical', 'a'), ('direction', 'n'), ('electronic', 'a'), ('device', 'n'), ('comprising', 'v'), ('camera', 'n'), ('coupled', 'v'), ('body', 'n'), ('configured', 'a'), ('rotate', 'n'), ('tilt', 'n'), ('wherein', 'n'), ('camera', 'n'), ('configured', 'v'), ('acquire', 'v'), ('video', 'n'), ('space', 'n'), ('within', None), ('one', None), ('persons', 'n'), ('positioned', 'v'), ('processor', 'n'), ('configured', 'v'), ('recognize', 'v'), ('respective', 'a'), ('faces', 'v'), ('one', None), ('persons', 'n'), ('video', 'v'), ('track', 'a'), ('motion', 'n'), ('recognized', 'v'), ('faces', 'v'), ('one', None), ('persons', 'n'), ('calculate', 'v'), ('respective', 'a'), ('size', 'n'), ('faces', 'v'), ('one', None), ('persons', 'n'), ('select', 'v'), ('first', 'a'), ('person', 'n'), ('among', None), ('one', None), ('persons', 'n'), ('based', 'v'), ('calculated', 'a'), ('sizes', 'n'), ('faces', 'v'), ('control', 'n'), ('least', 'a'), ('one', None), ('direction', 'n'), ('rotation', 'n'), ('camera', 'n'), ('angle', 'n'), ('tilt', 'n'), ('camera', 'n'), ('focal', 'a'), ('distance', 'n'), ('camera', 'n'), ('based', 'v'), ('tracked', 'a'), ('motion', 'n'), ('recognized', 'v'), ('face', 'n'), ('first', 'r'), ('person', 'n'), ('method', 'a'), ('comprising', 'v'), ('acquiring', 'v'), ('camera', 'n'), ('video', 'n'), ('space', 'n'), ('within', None), ('one', None), ('persons', 'n'), ('positioned', 'v'), ('recognizing', 'v'), ('respective', 'a'), ('faces', 'v'), ('one', None), ('persons', 'n'), ('video', None), ('tracking', 'v'), ('motion', 'n'), ('recognized', 'v'), ('faces', 'v'), ('one', None), ('persons', 'n'), ('calculating', 'v'), ('respective', 'a'), ('size', 'n'), ('faces', 'v'), ('one', None), ('persons', 'n'), ('selecting', 'v'), ('first', 'a'), ('person', 'n'), ('among', None), ('one', None), ('persons', 'n'), ('based', 'v'), ('calculated', 'a'), ('sizes', 'n'), ('faces', 'v'), ('controlling', 'v'), ('least', 'a'), ('one', None), ('direction', 'n'), ('rotation', 'n'), ('camera', 'n'), ('angle', 'n'), ('tilt', 'n'), ('camera', 'n'), ('focal', 'a'), ('distance', 'n'), ('camera', 'n'), ('based', 'v'), ('tracked', 'a'), ('motion', 'n'), ('recognized', 'v'), ('face', 'n'), ('first', 'r'), ('person', 'n'), ('method', 'n'), ('inferring', 'v'), ('topics', 'n'), ('multimodal', 'v'), ('file', 'n'), ('method', 'n'), ('comprising', 'v'), ('receiving', 'v'), ('multimodal', 'n'), ('file', 'n'), ('extracting', 'v'), ('set', 'v'), ('entities', 'n'), ('multimodal', 'v'), ('file', 'n'), ('linking', 'v'), ('set', 'v'), ('entities', 'n'), ('produce', 'v'), ('set', 'v'), ('linked', 'v'), ('entities', 'n'), ('obtaining', 'v'), ('reference', 'n'), ('information', 'n'), ('set', 'v'), ('entities', 'n'), ('based', 'v'), ('least', 'a'), ('reference', 'n'), ('information', 'n'), ('generating', 'v'), ('graph', 'n'), ('set', 'v'), ('linked', 'v'), ('entities', 'n'), ('graph', 'v'), ('comprising', 'v'), ('nodes', 'n'), ('edges', 'n'), ('based', 'v'), ('least', 'a'), ('nodes', 'a'), ('edges', 'n'), ('graph', 'v'), ('determining', 'v'), ('clusters', 'n'), ('graph', 'v'), ('based', 'v'), ('least', 'a'), ('clusters', 'n'), ('graph', 'v'), ('identifying', 'v'), ('topic', 'n'), ('candidates', 'n'), ('extracting', 'v'), ('features', 'n'), ('clusters', 'n'), ('graph', 'v'), ('based', 'v'), ('least', 'a'), ('extracted', 'a'), ('features', 'n'), ('selecting', 'v'), ('least', 'a'), ('one', None), ('topicid', 'n'), ('among', None), ('topic', 'a'), ('candidates', 'n'), ('represent', 'v'), ('least', 'a'), ('one', None), ('cluster', 'n'), ('indexing', 'v'), ('multimodal', 'n'), ('file', 'r'), ('least', 'a'), ('one', None), ('topicid', 'n'), ('method', 'n'), ('claim', 'n'), ('wherein', 'n'), ('multimodal', 'n'), ('file', 'n'), ('comprises', 'v'), ('video', 'a'), ('portion', 'n'), ('audio', 'n'), ('portion', 'n'), ('wherein', None), ('extracting', 'v'), ('set', 'n'), ('entities', 'n'), ('multimodal', 'v'), ('file', 'n'), ('comprises', 'n'), ('detecting', 'v'), ('objects', 'n'), ('video', 'a'), ('portion', 'n'), ('multimodal', 'n'), ('file', 'n'), ('detecting', 'v'), ('text', 'a'), ('audio', 'a'), ('portion', 'n'), ('multimodal', 'n'), ('file', 'n'), ('method', 'n'), ('claim', 'n'), ('wherein', None), ('detecting', 'v'), ('objects', 'n'), ('comprises', 'v'), ('performing', 'v'), ('face', 'n'), ('recognition', 'n'), ('method', 'n'), ('claim', 'n'), ('wherein', None), ('detecting', 'v'), ('text', 'a'), ('comprises', 'n'), ('performing', 'v'), ('speech', 'n'), ('text', 'n'), ('process', 'n'), ('method', 'n'), ('claim', 'n'), ('comprising', 'v'), ('identifying', 'a'), ('language', 'n'), ('used', 'v'), ('audio', 'a'), ('portion', 'n'), ('multimodal', 'n'), ('file', 'n'), ('wherein', 'n'), ('performing', 'v'), ('speech', 'a'), ('text', 'n'), ('process', 'n'), ('comprises', 'v'), ('performing', 'v'), ('speech', 'n'), ('text', 'n'), ('process', 'n'), ('identified', 'v'), ('language', 'n'), ('method', 'n'), ('claim', 'n'), ('comprising', 'v'), ('translating', 'v'), ('detected', 'v'), ('text', 'a'), ('method', 'n'), ('claim', 'n'), ('comprising', 'v'), ('determining', 'v'), ('significant', 'a'), ('clusters', 'n'), ('insignificant', 'a'), ('clusters', 'n'), ('determined', 'v'), ('clusters', 'n'), ('wherein', 'v'), ('extracting', 'v'), ('features', 'n'), ('clusters', 'n'), ('graph', 'v'), ('comprises', 'n'), ('extracting', 'v'), ('features', 'n'), ('significant', 'a'), ('clusters', 'n'), ('graph', 'v'), ('method', 'a'), ('claim', 'n'), ('wherein', 'n'), ('extracting', 'v'), ('features', 'n'), ('clusters', 'n'), ('graph', 'v'), ('comprises', 'n'), ('least', 'v'), ('one', None), ('process', 'n'), ('selected', 'v'), ('list', 'n'), ('consisting', 'v'), ('determining', 'v'), ('graph', 'a'), ('diameter', 'n'), ('determining', 'v'), ('jaccard', 'a'), ('coefficient', 'n'), ('method', 'n'), ('claim', 'n'), ('wherein', None), ('selecting', 'v'), ('least', 'a'), ('one', None), ('topicid', 'a'), ('represent', 'n'), ('least', 'a'), ('one', None), ('cluster', 'n'), ('comprises', 'n'), ('based', 'v'), ('least', 'r'), ('extracted', 'a'), ('features', 'n'), ('mapping', 'v'), ('topic', 'n'), ('candidates', 'n'), ('probability', 'n'), ('interval', 'v'), ('based', 'v'), ('least', 'a'), ('mapping', 'v'), ('ranking', 'v'), ('topic', 'n'), ('candidates', 'n'), ('within', None), ('least', 'a'), ('one', None), ('cluster', 'n'), ('selecting', 'v'), ('least', 'a'), ('one', None), ('topicid', 'n'), ('based', 'v'), ('least', 'a'), ('ranking', 'a'), ('method', 'n'), ('claim', 'n'), ('comprising', 'v'), ('translating', 'v'), ('least', 'a'), ('one', None), ('topicid', 'n'), ('wherein', 'n'), ('indexing', 'v'), ('multimodal', 'n'), ('file', 'r'), ('least', 'a'), ('one', None), ('topicid', 'n'), ('comprises', 'v'), ('indexing', 'v'), ('multimodal', 'n'), ('file', 'r'), ('least', 'a'), ('one', None), ('translated', 'v'), ('topicid', 'n'), ('system', 'n'), ('inferring', 'v'), ('topics', 'n'), ('multimodal', 'v'), ('file', 'n'), ('system', 'n'), ('comprising', 'v'), ('entity', 'n'), ('extraction', 'n'), ('component', 'n'), ('comprising', 'v'), ('object', 'a'), ('detection', 'n'), ('component', 'n'), ('speech', 'n'), ('text', 'a'), ('component', 'n'), ('operative', 'a'), ('extract', 'n'), ('set', 'v'), ('entities', 'n'), ('multimodal', 'v'), ('file', 'n'), ('comprising', 'v'), ('video', 'a'), ('portion', 'n'), ('audio', 'n'), ('portion', 'n'), ('entity', 'n'), ('linking', 'v'), ('component', 'a'), ('operative', 'a'), ('link', 'n'), ('extracted', 'v'), ('set', 'a'), ('entities', 'n'), ('produce', 'v'), ('set', 'v'), ('linked', 'v'), ('entities', 'n'), ('information', 'n'), ('retrieval', 'n'), ('component', 'n'), ('operative', 'a'), ('obtain', 'v'), ('reference', 'n'), ('information', 'n'), ('extracted', 'v'), ('set', 'n'), ('entities', 'n'), ('graphing', 'v'), ('analysis', 'n'), ('component', 'n'), ('operative', 'a'), ('generate', 'n'), ('graph', 'n'), ('set', 'v'), ('linked', 'v'), ('entities', 'n'), ('graph', 'v'), ('comprising', 'v'), ('nodes', 'n'), ('edges', 'n'), ('based', 'v'), ('least', 'a'), ('nodes', 'a'), ('edges', 'n'), ('graph', 'v'), ('determine', 'a'), ('clusters', 'n'), ('graph', 'v'), ('based', 'v'), ('least', 'a'), ('clusters', 'n'), ('graph', 'v'), ('identify', 'v'), ('topic', 'n'), ('candidates', 'n'), ('extract', 'a'), ('features', 'n'), ('clusters', 'n'), ('graph', 'v'), ('topicid', 'a'), ('selection', 'n'), ('component', 'n'), ('operative', 'a'), ('rank', 'n'), ('topic', 'n'), ('candidates', 'n'), ('within', None), ('least', 'a'), ('one', None), ('cluster', 'n'), ('based', 'v'), ('least', 'a'), ('ranking', 'a'), ('select', 'a'), ('least', 'a'), ('one', None), ('topicid', 'n'), ('among', None), ('topic', 'a'), ('candidates', 'n'), ('represent', 'v'), ('least', 'a'), ('one', None), ('cluster', 'n'), ('video', 'n'), ('indexer', 'v'), ('operative', 'a'), ('index', 'n'), ('multimodal', 'n'), ('file', None), ('least', 'a'), ('one', None), ('topicid', 'n'), ('system', 'n'), ('claim', 'n'), ('wherein', 'n'), ('object', 'a'), ('detection', 'n'), ('component', 'n'), ('operative', 'a'), ('perform', 'n'), ('face', 'n'), ('recognition', 'n'), ('system', 'n'), ('claim', 'n'), ('wherein', 'n'), ('speech', 'n'), ('text', 'a'), ('component', 'n'), ('operative', 'a'), ('extract', 'a'), ('entity', 'n'), ('information', 'n'), ('least', 'a'), ('two', None), ('different', 'a'), ('languages', 'n'), ('one', None), ('computer', 'n'), ('storage', 'n'), ('devices', 'n'), ('computer-executable', 'a'), ('instructions', 'n'), ('stored', 'v'), ('thereon', 'n'), ('inferring', 'v'), ('topics', 'n'), ('multimodal', 'a'), ('file', 'n'), ('execution', 'n'), ('computer', 'n'), ('cause', 'v'), ('computer', 'n'), ('perform', 'n'), ('operations', 'n'), ('comprising', 'v'), ('receiving', 'v'), ('multimodal', 'n'), ('file', 'n'), ('comprising', 'v'), ('video', 'a'), ('portion', 'n'), ('audio', 'n'), ('portion', 'n'), ('extracting', 'v'), ('set', 'n'), ('entities', 'n'), ('multimodal', 'v'), ('file', 'n'), ('wherein', 'n'), ('extracting', 'v'), ('set', 'v'), ('entities', 'n'), ('multimodal', 'v'), ('file', 'n'), ('comprises', 'n'), ('detecting', 'v'), ('objects', 'n'), ('video', 'a'), ('portion', 'n'), ('multimodal', 'n'), ('file', 'n'), ('face', 'n'), ('recognition', 'n'), ('detecting', 'v'), ('text', 'a'), ('audio', 'a'), ('portion', 'n'), ('multimodal', 'n'), ('file', 'n'), ('speech', 'n'), ('text', 'n'), ('process', 'n'), ('disambiguating', 'v'), ('among', None), ('set', 'v'), ('detected', 'v'), ('entity', 'n'), ('names', 'n'), ('linking', 'v'), ('set', 'n'), ('entities', 'n'), ('produce', 'v'), ('set', 'v'), ('linked', 'v'), ('entities', 'n'), ('obtaining', 'v'), ('reference', 'n'), ('information', 'n'), ('set', 'v'), ('entities', 'n'), ('based', 'v'), ('least', 'a'), ('reference', 'n'), ('information', 'n'), ('generating', 'v'), ('graph', 'n'), ('set', 'v'), ('linked', 'v'), ('entities', 'n'), ('graph', 'v'), ('comprising', 'v'), ('nodes', 'n'), ('edges', 'n'), ('based', 'v'), ('least', 'a'), ('nodes', 'a'), ('edges', 'n'), ('graph', 'v'), ('determining', 'v'), ('clusters', 'n'), ('graph', 'v'), ('determining', 'v'), ('significant', 'a'), ('clusters', 'n'), ('insignificant', 'a'), ('clusters', 'n'), ('determined', 'v'), ('clusters', 'n'), ('based', 'v'), ('least', 'a'), ('significant', 'a'), ('clusters', 'n'), ('graph', 'v'), ('identifying', 'v'), ('topic', 'n'), ('candidates', 'n'), ('extracting', 'v'), ('features', 'n'), ('significant', 'a'), ('clusters', 'n'), ('graph', 'v'), ('based', 'v'), ('least', 'a'), ('extracted', 'a'), ('features', 'n'), ('mapping', 'v'), ('topic', 'n'), ('candidates', 'n'), ('probability', 'n'), ('interval', 'v'), ('based', 'v'), ('least', 'a'), ('mapping', 'v'), ('ranking', 'v'), ('topic', 'n'), ('candidates', 'n'), ('within', None), ('least', 'a'), ('one', None), ('significant', 'a'), ('cluster', 'n'), ('based', 'v'), ('ranking', 'v'), ('selecting', 'v'), ('least', 'a'), ('one', None), ('topicid', 'n'), ('among', None), ('topic', 'a'), ('candidates', 'n'), ('represent', 'v'), ('least', 'a'), ('one', None), ('significant', 'a'), ('cluster', 'n'), ('indexing', 'v'), ('multimodal', 'n'), ('file', 'r'), ('least', 'a'), ('one', None), ('topicid', 'n'), ('one', None), ('computer', 'n'), ('storage', 'n'), ('devices', 'n'), ('claim', 'v'), ('wherein', 'a'), ('operations', 'n'), ('comprise', 'v'), ('identifying', 'v'), ('language', 'n'), ('used', 'v'), ('audio', 'a'), ('portion', 'n'), ('multimodal', 'n'), ('file', 'n'), ('detecting', 'v'), ('text', 'a'), ('audio', 'a'), ('portion', 'n'), ('multimodal', 'n'), ('file', 'n'), ('speech', 'n'), ('text', 'n'), ('process', 'n'), ('comprises', 'v'), ('performing', 'v'), ('speech', 'n'), ('text', 'n'), ('process', 'n'), ('identified', 'v'), ('language权利要求', 'a'), ('system', 'n'), ('alerting', 'v'), ('vision', 'n'), ('impairment', 'n'), ('said', 'v'), ('system', 'n'), ('comprising', 'v'), ('processing', 'v'), ('unit', 'n'), ('configured', 'v'), ('operable', 'a'), ('receiving', 'v'), ('scene', 'n'), ('data', 'n'), ('indicative', 'a'), ('scene', 'n'), ('least', 'a'), ('one', None), ('consumer', 'n'), ('environment', 'n'), ('identifying', 'v'), ('scene', 'n'), ('data', 'n'), ('certain', 'a'), ('consumer', 'n'), ('identifying', 'v'), ('event', 'n'), ('indicative', 'a'), ('behavioral', 'a'), ('compensation', 'n'), ('vision', 'n'), ('impairment', 'n'), ('upon', None), ('identification', 'n'), ('event', 'n'), ('sending', 'v'), ('notification', 'n'), ('relating', 'v'), ('vision', 'n'), ('impairment', 'n'), ('system', 'n'), ('claim', 'n'), ('comprising', 'v'), ('least', 'a'), ('one', None), ('sensing', 'v'), ('unit', 'n'), ('configured', 'v'), ('operable', 'a'), ('detecting', 'v'), ('scene', 'n'), ('data', 'n'), ('system', 'n'), ('claim', 'n'), ('wherein', 'n'), ('said', 'v'), ('least', 'a'), ('one', None), ('sensing', 'v'), ('unit', 'n'), ('comprises', 'v'), ('least', 'a'), ('one', None), ('least', 'a'), ('one', None), ('imaging', 'v'), ('unit', 'n'), ('configured', 'v'), ('operable', 'a'), ('capturing', 'v'), ('least', 'a'), ('one', None), ('image', 'n'), ('least', 'a'), ('portion', 'n'), ('consumer', 'n'), (\"'s\", None), ('body', 'n'), ('least', 'v'), ('one', None), ('motion', 'n'), ('detector', 'n'), ('configured', 'v'), ('operable', 'a'), ('detecting', 'v'), ('consumer', 'n'), ('data', 'n'), ('indicative', 'a'), ('motion', 'n'), ('consumer', 'n'), ('least', 'a'), ('one', None), ('eye', 'n'), ('tracker', 'n'), ('configured', 'v'), ('operable', 'a'), ('tracking', 'v'), ('eye', 'n'), ('motion', 'n'), ('consumer', 'n'), ('system', 'n'), ('claim', 'n'), ('wherein', None), ('least', 'a'), ('one', None), ('imaging', 'v'), ('unit', 'n'), ('comprises', 'v'), ('plurality', 'n'), ('cameras', 'n'), ('placed', 'v'), ('different', 'a'), ('heights', 'n'), ('system', 'n'), ('one', None), ('claims', 'v'), ('wherein', 'n'), ('said', 'v'), ('sensing', 'v'), ('unit', 'n'), ('accommodated', 'v'), ('optical', 'a'), ('digital', 'a'), ('eyewear', 'n'), ('frame', 'n'), ('display', 'n'), ('system', 'n'), ('one', None), ('claims', 'v'), ('wherein', 'n'), ('said', 'v'), ('processing', 'n'), ('unit', 'n'), ('configured', 'v'), ('operable', 'a'), ('identifying', 'v'), ('consumer', 'n'), (\"'s\", None), ('condition', 'n'), ('said', 'v'), ('consumer', 'n'), (\"'s\", None), ('condition', 'n'), ('comprising', 'v'), ('consumer', 'n'), ('data', 'n'), ('indicative', 'a'), ('consumer', 'n'), (\"'s\", None), ('position', 'n'), ('location', 'n'), ('relative', 'a'), ('least', 'a'), ('one', None), ('object', 'a'), ('consumer', 'n'), (\"'s\", None), ('environment', 'n'), ('said', 'v'), ('consumer', 'n'), ('data', 'n'), ('comprises', 'n'), ('least', 'v'), ('one', None), ('consumer', 'n'), (\"'s\", None), ('face', 'n'), ('eyewear', 'a'), ('posture', 'n'), ('position', 'n'), ('sound', 'n'), ('motion', 'n'), ('system', 'n'), ('one', None), ('claims', 'v'), ('wherein', 'n'), ('said', 'v'), ('event', 'n'), ('comprises', 'n'), ('least', 'v'), ('one', None), ('position', 'n'), ('orientation', 'n'), ('head', 'n'), ('increase', 'n'), ('decrease', 'n'), ('viewing', 'v'), ('distance', 'n'), ('consumer', 'n'), ('viewed', 'v'), ('object', 'a'), ('changing', 'v'), ('position', 'n'), ('eyeglasses', 'n'), ('worn', 'a'), ('consumer', 'n'), ('system', 'n'), ('one', None), ('claims', 'v'), ('wherein', 'n'), ('said', 'v'), ('event', 'n'), ('identified', 'v'), ('identifying', 'n'), ('images', 'n'), ('image', 'n'), ('feature', 'n'), ('indicative', 'a'), ('behavioral', 'a'), ('compensation', 'n'), ('performing', 'v'), ('bruckner', 'a'), ('test', 'n'), ('performing', 'v'), ('hirschberg', 'a'), ('test', 'n'), ('measuring', 'v'), ('blink', 'n'), ('count', 'n'), ('frequency', 'n'), ('system', 'n'), ('claim', 'n'), ('wherein', 'n'), ('image', 'n'), ('feature', 'n'), ('indicative', 'a'), ('behavioral', 'a'), ('compensation', 'n'), ('comprises', 'n'), ('squinting', 'v'), ('head', 'n'), ('orientation', 'n'), ('certain', 'a'), ('distances', 'n'), ('object', 'v'), ('consumer', 'n'), (\"'s\", None), ('eyes', 'n'), ('certain', 'a'), ('position', 'n'), ('eyeglasses', 'v'), ('consumer', 'n'), (\"'s\", None), ('face', 'n'), ('strabismus', 'n'), ('cataracts', 'v'), ('reflections', 'n'), ('eye', 'n'), ('system', 'n'), ('one', None), ('claims', 'v'), ('wherein', 'n'), ('notification', 'n'), ('includes', 'v'), ('least', 'a'), ('one', None), ('data', 'n'), ('indicative', 'n'), ('identified', 'v'), ('event', 'n'), ('data', 'n'), ('indicative', 'a'), ('identified', 'a'), ('consumer', 'n'), ('ophthalmologic', 'n'), ('recommendations', 'n'), ('based', 'v'), ('identified', 'a'), ('event', 'n'), ('lack', 'n'), ('events', 'n'), ('appointment', 'a'), ('vision', 'n'), ('test', 'n'), ('system', 'n'), ('one', None), ('claims', 'v'), ('wherein', 'n'), ('said', 'v'), ('processing', 'n'), ('unit', 'n'), ('comprises', 'v'), ('memory', 'n'), ('storing', 'v'), ('least', 'a'), ('one', None), ('reference', 'n'), ('data', 'n'), ('indicative', 'a'), ('behavioral', 'a'), ('compensation', 'n'), ('vision', 'n'), ('impairment', 'n'), ('data', 'n'), ('indicative', 'a'), ('notification', 'n'), ('data', 'n'), ('indicative', 'a'), ('follow-up', 'a'), ('notification', 'n'), ('system', 'n'), ('claim', 'n'), ('wherein', 'n'), ('said', 'v'), ('processing', 'n'), ('unit', 'n'), ('configured', 'v'), ('least', 'a'), ('one', None), ('identifying', 'v'), ('event', 'n'), ('upon', None), ('comparison', 'n'), ('detected', 'v'), ('data', 'n'), ('reference', 'n'), ('data', 'n'), ('determining', 'v'), ('probability', 'n'), ('vision', 'n'), ('impairment', 'a'), ('consumer', 'n'), ('based', 'v'), ('comparison', 'n'), ('system', 'n'), ('one', None), ('claims', 'v'), ('wherein', 'n'), ('said', 'v'), ('processing', 'n'), ('unit', 'n'), ('comprises', 'v'), ('communication', 'n'), ('interface', 'n'), ('configured', 'v'), ('sending', 'v'), ('notification', 'n'), ('least', 'a'), ('one', None), ('identified', 'a'), ('consumer', 'n'), ('party', 'n'), ('system', 'n'), ('one', None), ('claims', 'v'), ('wherein', 'n'), ('said', 'v'), ('processing', 'n'), ('unit', 'n'), ('configured', 'v'), ('providing', 'v'), ('frame', 'n'), ('recommendation', 'n'), ('system', 'n'), ('one', None), ('claims', 'v'), ('wherein', 'n'), ('said', 'v'), ('memory', 'n'), ('configured', 'v'), ('storing', 'a'), ('database', 'n'), ('including', 'v'), ('multiplicity', 'n'), ('data', 'n'), ('sets', 'n'), ('related', 'a'), ('plurality', 'n'), ('spectacle', 'n'), ('frame', 'n'), ('models', 'n'), ('sizes', 'v'), ('system', 'n'), ('according', 'v'), ('claim', 'n'), ('wherein', 'n'), ('said', 'v'), ('processing', 'n'), ('unit', 'n'), ('configured', 'v'), ('operable', 'a'), ('correlate', 'n'), ('frames', 'n'), ('parameters', 'n'), ('ophthalmic', 'v'), ('prescriptions', 'n'), ('system', 'n'), ('according', 'v'), ('claims', 'n'), ('wherein', 'n'), ('said', 'v'), ('processing', 'n'), ('unit', 'n'), ('configured', 'v'), ('operable', 'a'), ('correlate', 'n'), ('frames', 'n'), ('parameters', 'n'), ('facial', 'a'), ('features', 'n'), ('system', 'n'), ('according', 'v'), ('claims', 'n'), ('wherein', 'n'), ('said', 'v'), ('processing', 'n'), ('unit', 'n'), ('configured', 'v'), ('operable', 'a'), ('correlate', 'n'), ('frames', 'n'), ('parameters', 'n'), ('eyewear', 'v'), ('preferences', 'n'), ('system', 'n'), ('according', 'v'), ('claims', 'n'), ('comprising', 'v'), ('server', 'r'), ('least', 'a'), ('one', None), ('computer', 'n'), ('entity', 'n'), ('linked', 'v'), ('server', 'r'), ('via', None), ('network', 'n'), ('wherein', 'n'), ('said', 'v'), ('network', 'n'), ('configured', 'v'), ('receive', 'a'), ('respond', 'n'), ('requests', 'n'), ('sent', 'v'), ('across', None), ('network', 'n'), ('transmitting', 'v'), ('one', None), ('modules', 'n'), ('computer', 'n'), ('executable', 'a'), ('program', 'n'), ('instructions', 'n'), ('displayable', 'a'), ('data', 'n'), ('network', 'n'), ('connected', 'v'), ('user', 'r'), ('computer', 'n'), ('platform', 'n'), ('response', 'n'), ('request', 'n'), ('wherein', 'n'), ('said', 'v'), ('modules', 'n'), ('include', 'v'), ('modules', 'n'), ('configured', 'v'), ('receive', 'a'), ('transmit', 'n'), ('image', 'n'), ('information', 'n'), ('transmitting', 'v'), ('frame', 'n'), ('recommendation', 'n'), ('optical', 'a'), ('lens', 'v'), ('option', 'n'), ('recommendation', 'n'), ('based', 'v'), ('received', 'v'), ('image', 'n'), ('information', 'n'), ('display', 'n'), ('network', 'n'), ('connected', 'v'), ('user', 'r'), ('computer', 'n'), ('platform', 'n'), ('computer', 'n'), ('program', 'n'), ('instructions', 'n'), ('stored', 'v'), ('local', 'a'), ('storage', 'n'), ('executed', 'v'), ('processing', 'v'), ('unit', 'n'), ('cause', 'n'), ('processing', 'v'), ('unit', 'n'), ('receive', 'a'), ('data', 'n'), ('indicative', 'a'), ('scene', 'n'), ('least', 'a'), ('one', None), ('consumer', 'n'), ('environment', 'n'), ('identify', 'v'), ('data', 'n'), ('certain', 'a'), ('consumer', 'n'), ('identify', 'v'), ('event', 'n'), ('indicative', 'a'), ('behavioral', 'a'), ('compensation', 'n'), ('vision', 'n'), ('impairment', 'n'), ('upon', None), ('identification', 'n'), ('event', 'n'), ('send', 'v'), ('notification', 'n'), ('relating', 'v'), ('vision', 'n'), ('impairment', 'a'), ('computer', 'n'), ('program', 'n'), ('product', 'n'), ('stored', 'v'), ('tangible', 'a'), ('computer', 'n'), ('readable', 'a'), ('medium', 'n'), ('comprising', 'v'), ('library', 'a'), ('software', 'n'), ('modules', 'n'), ('cause', 'v'), ('computer', 'n'), ('executing', 'v'), ('prompt', 'a'), ('information', 'n'), ('pertinent', 'n'), ('least', 'a'), ('one', None), ('eyeglasses', 'v'), ('recommendation', 'n'), ('optical', 'a'), ('lens', 'v'), ('option', 'n'), ('recommendation', 'n'), ('store', 'n'), ('said', 'v'), ('information', 'n'), ('display', 'n'), ('eyewear', 'v'), ('recommendations', 'n'), ('computer', 'n'), ('program', 'n'), ('product', 'n'), ('claim', 'n'), ('wherein', 'n'), ('said', 'v'), ('library', 'a'), ('comprises', 'n'), ('module', 'n'), ('frame', 'n'), ('selection', 'n'), ('point', 'n'), ('sales', 'n'), ('advertising', 'v'), ('computer', 'n'), ('platform', 'n'), ('facilitating', 'v'), ('eye', 'n'), ('glasses', 'n'), ('marketing', 'v'), ('selection', 'n'), ('comprising', 'v'), ('camera', 'n'), ('processor', 'n'), ('configured', 'v'), ('execute', 'a'), ('computer', 'n'), ('program', 'n'), ('instructions', 'n'), ('cause', 'v'), ('processor', 'n'), ('take', 'v'), ('image', 'n'), ('consumer', 'n'), ('identify', 'v'), ('image', 'n'), ('certain', 'a'), ('consumer', 'n'), ('identify', 'v'), ('event', 'n'), ('indicative', 'a'), ('behavioral', 'a'), ('compensation', 'n'), ('vision', 'n'), ('impairment', 'n'), ('upon', None), ('identification', 'n'), ('event', 'n'), ('sending', 'v'), ('notification', 'n'), ('relating', 'v'), ('vision', 'n'), ('impairment', 'a'), ('local', 'a'), ('storage', 'n'), ('processor', 'n'), ('executable', 'a'), ('instructions', 'n'), ('carrying', 'v'), ('storage', 'n'), ('information', 'n'), ('method', 'n'), ('alerting', 'v'), ('vision', 'n'), ('impairment', 'n'), ('said', 'v'), ('method', 'a'), ('comprising', 'v'), ('identifying', 'v'), ('certain', 'a'), ('individual', 'a'), ('scene', 'n'), ('data', 'n'), ('indicative', 'a'), ('scene', 'n'), ('least', 'a'), ('one', None), ('consumer', 'n'), ('environment', 'n'), ('identifying', 'v'), ('event', 'n'), ('indicative', 'a'), ('behavioral', 'a'), ('compensation', 'n'), ('vision', 'n'), ('impairment', 'n'), ('upon', None), ('identification', 'n'), ('event', 'n'), ('sending', 'v'), ('notification', 'n'), ('vision', 'n'), ('impairment', 'n'), ('method', 'n'), ('claim', 'n'), ('comprising', 'v'), ('detecting', 'v'), ('data', 'n'), ('indicative', 'a'), ('scene', 'n'), ('least', 'a'), ('one', None), ('consumer', 'n'), ('retail', 'a'), ('environment', 'n'), ('method', 'n'), ('claim', 'n'), ('wherein', None), ('detecting', 'v'), ('data', 'n'), ('indicative', 'a'), ('least', 'a'), ('one', None), ('consumer', 'n'), ('comprises', 'v'), ('least', 'a'), ('one', None), ('capturing', 'v'), ('least', 'a'), ('one', None), ('image', 'n'), ('least', 'v'), ('one', None), ('consumer', 'n'), ('detecting', 'v'), ('data', 'n'), ('indicative', 'a'), ('motion', 'n'), ('consumer', 'n'), ('tracking', 'v'), ('eye', 'n'), ('motion', 'n'), ('consumer', 'n'), ('method', 'n'), ('claim', 'n'), ('wherein', None), ('capturing', 'v'), ('least', 'a'), ('one', None), ('image', 'n'), ('least', 'v'), ('one', None), ('consumer', 'n'), ('comprises', 'v'), ('continuously', 'r'), ('recording', 'v'), ('scene', 'n'), ('method', 'n'), ('one', None), ('claims', 'v'), ('comprising', 'v'), ('identifying', 'v'), ('data', 'n'), ('consumer', 'n'), (\"'\", None), ('condition', 'n'), ('including', 'v'), ('data', 'n'), ('indicative', 'a'), ('consumer', 'n'), (\"'s\", None), ('position', 'n'), ('location', 'n'), ('relative', 'a'), ('consumer', 'n'), (\"'s\", None), ('environment', 'n'), ('said', 'v'), ('data', 'n'), ('comprising', 'v'), ('least', 'a'), ('one', None), ('consumer', 'n'), (\"'s\", None), ('face', 'n'), ('posture', 'n'), ('position', 'n'), ('sound', 'n'), ('motion', 'n'), ('method', 'n'), ('one', None), ('claims', 'v'), ('wherein', 'n'), ('said', 'v'), ('event', 'n'), ('comprises', 'n'), ('least', 'v'), ('one', None), ('position', 'n'), ('orientation', 'n'), ('head', 'n'), ('increase', 'n'), ('decrease', 'n'), ('viewing', 'v'), ('distance', 'n'), ('consumer', 'n'), ('viewed', 'v'), ('object', 'a'), ('changing', 'v'), ('position', 'n'), ('eyeglasses', 'n'), ('worn', 'a'), ('consumer', 'n'), ('method', 'n'), ('one', None), ('claims', 'v'), ('wherein', 'n'), ('identifying', 'v'), ('event', 'n'), ('comprises', 'n'), ('identifying', 'v'), ('images', 'n'), ('image', 'n'), ('feature', 'n'), ('indicative', 'a'), ('behavioral', 'a'), ('compensation', 'n'), ('performing', 'v'), ('bruckner', 'a'), ('test', 'n'), ('performing', 'v'), ('hirschberg', 'a'), ('test', 'n'), ('measuring', 'v'), ('blink', 'n'), ('countfrequency', 'n'), ('method', 'n'), ('claim', 'n'), ('wherein', None), ('image', 'n'), ('feature', 'n'), ('indicative', 'a'), ('behavioral', 'a'), ('compensation', 'n'), ('comprises', 'n'), ('squinting', 'v'), ('head', 'n'), ('orientation', 'n'), ('certain', 'a'), ('distances', 'n'), ('object', 'v'), ('consumer', 'n'), (\"'s\", None), ('eyes', 'n'), ('certain', 'a'), ('position', 'n'), ('eyeglasses', 'v'), ('consumer', 'n'), (\"'s\", None), ('face', 'n'), ('strabismus', 'n'), ('cataracts', 'v'), ('reflections', 'n'), ('eye', 'n'), ('method', 'v'), ('one', None), ('claims', 'n'), ('wherein', 'v'), ('identifying', 'v'), ('least', 'a'), ('one', None), ('image', 'n'), ('consumer', 'n'), ('retail', 'a'), ('environment', 'n'), ('comprising', 'v'), ('least', 'a'), ('one', None), ('receiving', 'v'), ('data', 'n'), ('characterizing', 'v'), ('retail', 'a'), ('environment', 'n'), ('performing', 'v'), ('face', 'n'), ('recognition', 'n'), ('method', None), ('one', None), ('claims', 'n'), ('wherein', 'v'), ('sending', 'v'), ('notification', 'n'), ('comprising', 'v'), ('sending', 'v'), ('notification', 'n'), ('least', 'a'), ('one', None), ('identified', 'a'), ('consumer', 'n'), ('party', 'n'), ('method', 'n'), ('one', None), ('claims', 'v'), ('wherein', 'n'), ('notification', 'n'), ('includes', 'v'), ('least', 'a'), ('one', None), ('data', 'n'), ('indicative', 'n'), ('identified', 'v'), ('event', 'n'), ('data', 'n'), ('indicative', 'a'), ('identified', 'a'), ('consumer', 'n'), ('ophthalmologic', 'n'), ('recommendations', 'n'), ('based', 'v'), ('identified', 'a'), ('event', 'n'), ('lack', 'n'), ('events', 'n'), ('appointment', 'a'), ('vision', 'n'), ('test', 'n'), ('method', 'n'), ('one', None), ('claims', 'v'), ('comprising', 'v'), ('storing', 'v'), ('least', 'a'), ('one', None), ('reference', 'n'), ('data', 'n'), ('indicative', 'a'), ('behavioral', 'a'), ('compensation', 'n'), ('vision', 'n'), ('impairment', 'n'), ('data', 'n'), ('indicative', 'a'), ('notification', 'n'), ('data', 'n'), ('indicative', 'a'), ('follow-up', 'a'), ('notification', 'n'), ('method', 'n'), ('claim', 'n'), ('comprising', 'v'), ('identifying', 'v'), ('event', 'n'), ('upon', None), ('comparison', 'n'), ('detected', 'v'), ('data', 'n'), ('reference', 'n'), ('data', 'n'), ('determining', 'v'), ('probability', 'n'), ('vision', 'n'), ('impairment', 'a'), ('consumer', 'n'), ('based', 'v'), ('comparison', 'a'), ('computer', 'n'), ('program', 'n'), ('intended', 'v'), ('stored', 'a'), ('memory', 'n'), ('processor', 'n'), ('unit', 'n'), ('computer', 'n'), ('system', 'n'), ('removable', 'a'), ('memory', 'n'), ('medium', 'n'), ('adapted', 'v'), ('cooperate', 'a'), ('reader', 'n'), ('processor', 'n'), ('unit', 'n'), ('comprising', 'v'), ('instructions', 'n'), ('implementing', 'v'), ('method', 'n'), ('according', 'v'), ('claims', 'n')]\n"
     ]
    }
   ],
   "source": [
    "def simpler_pos_tag(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return \"a\"\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return \"v\"\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return \"n\"\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return \"r\"\n",
    "    else:         \n",
    "        return None\n",
    "    \n",
    "simpler_POS_text_a = []\n",
    "\n",
    "# for each tuple of the list, we create a new tuple: the first element is the token, the second is\n",
    "# the simplified pos tag, obtained calling the function simpler_pos_tag()\n",
    "# then we append the new created tuple to a new list, which will be the output\n",
    "for tuple in cleaned_POS_text_a:\n",
    "    if tuple[1] == 'NNP':   #this is because there is some text in japanese categorized as 'NNP';\n",
    "                            #no other relevant words are categorized in such a way\n",
    "        continue;\n",
    "    POS_tuple = (tuple[0], simpler_pos_tag(tuple[1]))\n",
    "    simpler_POS_text_a.append(POS_tuple)\n",
    "    \n",
    "print(simpler_POS_text_a)\n",
    "\n",
    "simpler_POS_text_c = []\n",
    "\n",
    "for tuple in cleaned_POS_text_c:\n",
    "    if tuple[1] == 'NNP':   #this is because there is some text in japanese categorized as 'NNP';\n",
    "                            #no other relevant words are categorized in such a way\n",
    "        continue;\n",
    "    POS_tuple = (tuple[0], simpler_pos_tag(tuple[1]))\n",
    "    simpler_POS_text_c.append(POS_tuple)\n",
    "    \n",
    "print(simpler_POS_text_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0c67ce",
   "metadata": {},
   "source": [
    "### Lemmatization\n",
    "In this step we lemmatize the pos text, so we obtain the final two vectors with all the lemmas we need for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6ed471ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c56f1de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['electronic', 'apparatus', 'include', 'image', 'capturing', 'device', 'storage', 'device', 'processor', 'operation', 'method', 'thereof', 'provide', 'image', 'capture', 'device', 'capture', 'image', 'user', 'storage', 'device', 'record', 'plurality', 'modules', 'processor', 'couple', 'image', 'capture', 'device', 'storage', 'device', 'configure', 'configure', 'image', 'capture', 'device', 'capture', 'head', 'image', 'user', 'perform', 'face', 'recognition', 'operation', 'obtain', 'face', 'region', 'detect', 'plurality', 'facial', 'landmark', 'within', 'face', 'region', 'estimate', 'head', 'posture', 'angle', 'user', 'accord', 'facial', 'landmark', 'calculate', 'gaze', 'position', 'user', 'gaze', 'screen', 'accord', 'head', 'posture', 'angle', 'plurality', 'rotation', 'reference', 'angle', 'plurality', 'predetermine', 'calibration', 'position', 'configure', 'screen', 'display', 'correspond', 'visual', 'effect', 'accord', 'gaze', 'positionthe', 'present', 'disclosure', 'provide', 'computation', 'method', 'product', 'thereof', 'computation', 'method', 'adopts', 'fusion', 'method', 'perform', 'machine', 'learn', 'computation', 'technical', 'effect', 'present', 'disclosure', 'include', 'few', 'computation', 'less', 'power', 'consumptiona', 'method', 'detect', 'body', 'information', 'passenger', 'vehicle', 'base', 'human', \"'\", 'status', 'recognition', 'provide', 'method', 'include', 'step', 'passenger', 'body', 'information-detecting', 'device', 'inputting', 'interior', 'image', 'vehicle', 'face', 'recognition', 'network', 'detect', 'face', 'passenger', 'output', 'passenger', 'feature', 'information', 'inputting', 'interior', 'image', 'body', 'recognition', 'network', 'detect', 'body', 'output', 'body-part', 'length', 'information', 'b', 'retrieve', 'specific', 'height', 'mapping', 'information', 'refer', 'height', 'map', 'table', 'ratio', 'segment', 'body', 'portion', 'human', 'group', 'height', 'per', 'human', 'group', 'acquire', 'specific', 'height', 'specific', 'passenger', 'retrieve', 'specific', 'weight', 'map', 'information', 'weight', 'mapping', 'table', 'correlation', 'height', 'weight', 'per', 'human', 'group', 'acquire', 'weight', 'specific', 'passenger', 'refer', 'specific', 'heighttechniques', 'relate', 'improved', 'video', 'cod', 'base', 'face', 'detection', 'region', 'extraction', 'track', 'discuss', 'technique', 'may', 'include', 'perform', 'facial', 'search', 'video', 'frame', 'determine', 'candidate', 'face', 'region', 'video', 'frame', 'test', 'candidate', 'face', 'region', 'base', 'skin', 'tone', 'information', 'determine', 'valid', 'invalid', 'face', 'region', 'reject', 'invalid', 'face', 'region', 'encode', 'video', 'frame', 'base', 'valid', 'face', 'region', 'generate', 'cod', 'bitstreama', 'method', 'manage', 'smart', 'database', 'store', 'facial', 'image', 'face', 'recognition', 'provide', 'method', 'include', 'step', 'manage', 'device', 'count', 'specific', 'facial', 'image', 'correspond', 'specific', 'person', 'smart', 'database', 'new', 'facial', 'image', 'continuously', 'store', 'determine', 'whether', 'first', 'count', 'value', 'represent', 'count', 'specific', 'facial', 'image', 'satisfies', 'first', 'set', 'value', 'b', 'first', 'count', 'value', 'satisfies', 'first', 'set', 'value', 'inputting', 'specific', 'facial', 'image', 'neural', 'aggregation', 'network', 'generate', 'quality', 'score', 'specific', 'facial', 'image', 'aggregation', 'specific', 'facial', 'image', 'second', 'count', 'value', 'represent', 'count', 'specific', 'quality', 'score', 'among', 'quality', 'score', 'high', 'count', 'thereof', 'satisfies', 'second', 'set', 'value', 'delete', 'part', 'specific', 'facial', 'image', 'correspond', 'uncounted', 'quality', 'score', 'smart', 'databasea', 'system', 'capable', 'determine', 'recognition', 'algorithm', 'apply', 'region', 'interest', 'within', 'digital', 'representation', 'present', 'preprocessing', 'module', 'utilizes', 'one', 'feature', 'identification', 'algorithm', 'determine', 'region', 'interest', 'base', 'feature', 'density', 'preprocessing', 'module', 'leverage', 'feature', 'density', 'signature', 'region', 'determine', 'plurality', 'diverse', 'recognition', 'module', 'operate', 'region', 'interest', 'specific', 'embodiment', 'focus', 'structure', 'document', 'also', 'present', 'disclosed', 'approach', 'enhance', 'addition', 'object', 'classifier', 'classifies', 'type', 'object', 'find', 'region', 'interestdisclosed', 'mobile', 'terminal', 'mobile', 'terminal', 'may', 'include', 'front', 'camera', 'obtain', 'face', 'image', 'user', 'glance', 'sensor', 'tilt', 'certain', 'angle', 'dispose', 'adjacent', 'front', 'camera', 'obtain', 'metadata', 'face', 'image', 'controller', 'obtain', 'distance', 'glance', 'sensor', 'front', 'camera', 'distance', 'enable', 'area', 'overlap', 'region', 'first', 'region', 'represent', 'range', 'photographable', 'front', 'camera', 'overlap', 'second', 'region', 'represent', 'range', 'photographable', 'glance', 'sensor', 'maximumthis', 'disclosure', 'provide', 'system', 'method', 'apparatus', 'include', 'computer', 'program', 'encode', 'computer', 'storage', 'medium', 'intelligent', 'rout', 'notification', 'related', 'medium', 'program', 'one', 'aspect', 'smart', 'television', 'tv', 'implement', 'track', 'user', \"'s\", 'tv', 'watch', 'behavior', 'anticipate', 'programming', 'base', 'behavior', 'aspect', 'smart', 'tv', 'implement', 'detect', 'user', \"'s\", 'presence', 'base', 'detection', 'automatically', 'change', 'tv', 'channel', 'medium', 'program', 'analyze', 'desirable', 'user', 'aspect', 'smart', 'tv', 'implement', 'transmit', 'notification', 'instruction', 'electronic', 'device', 'within', 'network', 'attempt', 'alert', 'user', 'upcoming', 'medium', 'program', 'additionally', 'smart', 'tv', 'implement', 'transmit', 'detection', 'instruction', 'electronic', 'device', 'within', 'network', 'whereby', 'electronic', 'device', 'attempt', 'detect', 'user', \"'s\", 'presence', 'voice', 'facial', 'recognitiona', 'camera', 'configure', 'output', 'test', 'depth+multi-spectral', 'image', 'include', 'plurality', 'pixel', 'pixel', 'correspond', 'one', 'plurality', 'sensor', 'sensor', 'array', 'camera', 'include', 'least', 'depth', 'value', 'spectral', 'value', 'spectral', 'light', 'sub-band', 'plurality', 'spectral', 'illuminators', 'camera', 'face', 'recognition', 'machine', 'previously', 'train', 'set', 'labeled', 'training', 'depth+multi-spectral', 'image', 'structure', 'test', 'depth+multi-spectral', 'image', 'face', 'recognition', 'machine', 'configure', 'output', 'confidence', 'value', 'indicate', 'likelihood', 'test', 'depth+multi-spectral', 'image', 'include', 'faceembodiments', 'present', 'disclosure', 'relate', 'image', 'processing', 'method', 'apparatus', 'electronic', 'device', 'method', 'include', 'acquire', 'photo', 'album', 'obtain', 'face', 'cluster', 'collect', 'face', 'information', 'respective', 'image', 'photo', 'album', 'acquire', 'face', 'parameter', 'image', 'accord', 'face', 'information', 'select', 'cover', 'image', 'accord', 'face', 'parameter', 'image', 'take', 'face-region', 'image', 'cover', 'image', 'set', 'face-region', 'image', 'cover', 'photo', 'albumtechniques', 'describe', 'herein', 'provide', 'location-based', 'access', 'control', 'secure', 'resource', 'generally', 'describe', 'configuration', 'disclose', 'herein', 'enable', 'system', 'dynamically', 'modify', 'access', 'secure', 'resource', 'base', 'one', 'location-related', 'action', 'example', 'technique', 'disclose', 'herein', 'enable', 'compute', 'system', 'control', 'access', 'resource', 'compute', 'device', 'display', 'device', 'secure', 'location', 'secure', 'data', 'configuration', 'technique', 'disclose', 'herein', 'enable', 'controlled', 'access', 'secure', 'resource', 'base', 'least', 'part', 'invitation', 'associate', 'location', 'position', 'data', 'indicate', 'location', 'userone', 'embodiment', 'provide', 'method', 'comprise', 'receive', 'piece', 'content', 'salient', 'moment', 'data', 'piece', 'content', 'method', 'comprises', 'base', 'salient', 'moment', 'data', 'determine', 'first', 'path', 'viewport', 'piece', 'content', 'method', 'comprise', 'display', 'viewport', 'display', 'device', 'movement', 'viewport', 'base', 'first', 'path', 'playback', 'piece', 'content', 'method', 'comprise', 'generate', 'augmentation', 'salient', 'moment', 'occur', 'piece', 'content', 'present', 'augmentation', 'viewport', 'portion', 'playback', 'augmentation', 'comprise', 'interactive', 'hint', 'guide', 'viewport', 'salient', 'momenta', 'computer-implemented', 'method', 'system', 'computer', 'program', 'product', 'provide', 'facial', 'recognition', 'method', 'include', 'receive', 'processor', 'device', 'plurality', 'image', 'method', 'also', 'include', 'extract', 'processor', 'device', 'feature', 'extractor', 'utilizing', 'convolutional', 'neural', 'network', 'cnn', 'enlarge', 'intra-class', 'variance', 'long-tail', 'class', 'feature', 'vector', 'plurality', 'image', 'method', 'additionally', 'include', 'generate', 'processor', 'device', 'feature', 'generator', 'discriminative', 'feature', 'vector', 'feature', 'vector', 'method', 'include', 'classify', 'processor', 'device', 'utilize', 'fully', 'connect', 'classifier', 'identity', 'discriminative', 'feature', 'vector', 'method', 'also', 'include', 'control', 'operation', 'processor-based', 'machine', 'react', 'accordance', 'identitysome', 'embodiment', 'invention', 'provide', 'efficient', 'expressive', 'machine-trained', 'network', 'perform', 'machine', 'learn', 'machine-trained', 'mt', 'network', 'embodiment', 'use', 'novel', 'processing', 'node', 'novel', 'activation', 'function', 'allow', 'mt', 'network', 'efficiently', 'define', 'few', 'processing', 'node', 'layer', 'complex', 'mathematical', 'expression', 'solve', 'particular', 'problem', 'eg', 'face', 'recognition', 'speech', 'recognition', 'etc', 'embodiment', 'activation', 'function', 'eg', 'cup', 'function', 'use', 'numerous', 'process', 'node', 'mt', 'network', 'machine', 'learn', 'activation', 'function', 'configure', 'differently', 'different', 'process', 'node', 'different', 'node', 'emulate', 'implement', 'two', 'different', 'function', 'eg', 'two', 'boolean', 'logical', 'operator', 'xor', 'activation', 'function', 'embodiment', 'periodic', 'function', 'configure', 'implement', 'different', 'function', 'eg', 'different', 'sinusoidal', 'functionsmethods', 'system', 'may', 'provide', 'facial', 'recognition', 'least', 'one', 'input', 'image', 'utilizing', 'hierarchical', 'feature', 'learn', 'pair-wise', 'classification', 'receptive', 'field', 'theory', 'may', 'use', 'input', 'image', 'generate', 'pre-processed', 'multi-channel', 'image', 'channel', 'pre-processed', 'image', 'may', 'activate', 'base', 'amount', 'feature', 'rich', 'detail', 'within', 'channel', 'similarly', 'local', 'patch', 'may', 'activate', 'base', 'discriminant', 'feature', 'within', 'local', 'patch', 'feature', 'may', 'extract', 'local', 'patch', 'discriminant', 'feature', 'may', 'select', 'order', 'perform', 'feature', 'match', 'pair', 'set', 'system', 'may', 'utilize', 'patch', 'feature', 'pool', 'pair-wise', 'matching', 'large-scale', 'training', 'order', 'quickly', 'accurately', 'perform', 'facial', 'recognition', 'low', 'cost', 'system', 'memory', 'computationa', 'method', 'control', 'terminal', 'provide', 'terminal', 'include', 'capture', 'apparatus', 'least', 'one', 'processor', 'image', 'acquire', 'capture', 'apparatus', 'motion', 'parameter', 'terminal', 'obtain', 'image', 'processing', 'acquire', 'image', 'control', 'perform', 'base', 'motion', 'parameter', 'equal', 'less', 'preset', 'parameter', 'threshold', 'skip', 'base', 'motion', 'parameter', 'great', 'preset', 'parameter', 'thresholda', 'drive-through', 'order', 'processing', 'method', 'apparatus', 'disclose', 'drive-through', 'order', 'processing', 'method', 'include', 'receive', 'customer', 'information', 'detect', 'vision', 'recognition', 'provide', 'product', 'information', 'base', 'customer', 'information', 'process', 'product', 'order', 'customer', 'accord', 'present', 'disclosure', 'possible', 'rapidly', 'process', 'order', 'use', 'customer', 'information', 'base', 'customer', 'recognition', 'use', 'artificial', 'intelligence', 'ai', 'model', 'machine', 'learn', 'g', 'networkan', 'image', 'processing', 'method', 'perform', 'compute', 'device', 'include', 'identify', 'use', 'face', 'recognition', 'one', 'face', 'face', 'correspond', 'respective', 'person', 'capture', 'first', 'image', 'identify', 'face', 'extract', 'set', 'profile', 'parameter', 'correspond', 'person', 'first', 'image', 'select', 'plurality', 'image', 'tile', 'first', 'image', 'tile', 'match', 'face', 'correspond', 'person', 'first', 'image', 'accordance', 'predefined', 'correspondence', 'set', 'profile', 'parameter', 'correspond', 'person', 'set', 'pre-stored', 'description', 'parameter', 'first', 'image', 'tile', 'generate', 'second', 'image', 'cover', 'face', 'respective', 'person', 'first', 'image', 'correspond', 'first', 'image', 'tile', 'share', 'first', 'image', 'second', 'image', 'predefined', 'order', 'via', 'group', 'chat', 'sessionin', 'one', 'embodiment', 'artificial', 'reality', 'system', 'determine', 'performance', 'metric', 'eye', 'track', 'system', 'first', 'performance', 'threshold', 'eye', 'track', 'system', 'associate', 'head-mounted', 'display', 'wear', 'user', 'artificial', 'reality', 'system', 'receive', 'first', 'input', 'associate', 'body', 'user', 'determines', 'region', 'user', 'look', 'within', 'field', 'view', 'head-mounted', 'display', 'base', 'receive', 'first', 'inputs', 'system', 'determine', 'vergence', 'distance', 'user', 'base', 'least', 'first', 'input', 'associate', 'body', 'user', 'region', 'user', 'look', 'location', 'one', 'object', 'scene', 'display', 'head-mounted', 'display', 'system', 'adjust', 'one', 'configuration', 'head-mounted', 'display', 'base', 'determined', 'vergence', 'distance', 'usera', 'computer-implemented', 'method', 'provide', 'image-based', 'self-guided', 'object', 'detection', 'method', 'include', 'receive', 'processor', 'device', 'set', 'image', 'image', 'respective', 'grid', 'thereon', 'label', 'regard', 'respective', 'object', 'detect', 'use', 'grid', 'level', 'label', 'data', 'method', 'include', 'train', 'processor', 'device', 'grid-based', 'object', 'detector', 'use', 'grid', 'level', 'label', 'data', 'method', 'also', 'include', 'determine', 'processor', 'device', 'respective', 'bound', 'box', 'respective', 'object', 'image', 'apply', 'local', 'segmentation', 'image', 'method', 'additionally', 'include', 'training', 'processor', 'device', 'region-based', 'convolutional', 'neural', 'network', 'rcnn', 'joint', 'object', 'localization', 'object', 'classification', 'use', 'respective', 'bounding', 'box', 'respective', 'object', 'image', 'input', 'rcnna', 'system', 'method', 'face', 'recognition', 'comprise', 'multiple', 'phase', 'implement', 'parallel', 'architecture', 'first', 'phase', 'normalization', 'phase', 'whereby', 'capture', 'image', 'normalize', 'size', 'orientation', 'illumination', 'store', 'image', 'preexist', 'database', 'second', 'phase', 'feature', 'extractiondistance', 'matrix', 'phase', 'distance', 'matrix', 'generate', 'captured', 'image', 'coarse', 'recognition', 'phase', 'generate', 'distance', 'matrix', 'compare', 'distance', 'matrix', 'database', 'use', 'euclidean', 'distance', 'match', 'create', 'candidate', 'list', 'detail', 'recognition', 'phase', 'multiple', 'face', 'recognition', 'algorithms', 'applied', 'candidate', 'list', 'produce', 'final', 'result', 'distance', 'matrix', 'normalized', 'database', 'may', 'break', 'parallel', 'list', 'parallelization', 'feature', 'extractiondistance', 'matrix', 'phase', 'candidate', 'list', 'may', 'also', 'group', 'accord', 'dissimilarity', 'algorithm', 'parallel', 'processing', 'detailed', 'recognition', 'phasean', 'imaging', 'device', 'include', 'pixel', 'matrix', 'processor', 'provide', 'pixel', 'matrix', 'include', 'plurality', 'phase', 'detection', 'pixel', 'plurality', 'regular', 'pixel', 'processor', 'performs', 'autofocusing', 'accord', 'pixel', 'data', 'phase', 'detection', 'pixel', 'determine', 'operate', 'resolution', 'regular', 'pixel', 'accord', 'autofocused', 'pixel', 'data', 'phase', 'detection', 'pixel', 'wherein', 'phase', 'detection', 'pixel', 'always-on', 'pixel', 'regular', 'pixel', 'selectively', 'turn', 'autofocusing', 'accomplishedan', 'apparatus', 'include', 'first', 'camera', 'module', 'provide', 'first', 'image', 'object', 'first', 'field', 'view', 'second', 'camera', 'module', 'provide', 'second', 'image', 'object', 'second', 'field', 'view', 'different', 'first', 'field', 'view', 'first', 'depth', 'map', 'generator', 'generates', 'first', 'depth', 'map', 'first', 'image', 'base', 'first', 'image', 'second', 'image', 'second', 'depth', 'map', 'generator', 'generate', 'second', 'depth', 'map', 'second', 'image', 'base', 'first', 'image', 'second', 'image', 'first', 'depth', 'mapmethods', 'system', 'apparatus', 'include', 'computer', 'program', 'encode', 'computer', 'storage', 'medium', 'payment', 'base', 'face', 'recognition', 'provide', 'one', 'method', 'include', 'acquire', 'first', 'face', 'image', 'information', 'target', 'user', 'extract', 'first', 'characteristic', 'information', 'first', 'face', 'image', 'information', 'wherein', 'first', 'characteristic', 'information', 'include', 'head', 'posture', 'information', 'target', 'user', 'gaze', 'information', 'target', 'user', 'determine', 'whether', 'target', 'user', 'willingness', 'pay', 'accord', 'head', 'posture', 'information', 'target', 'user', 'gaze', 'information', 'target', 'user', 'include', 'determine', 'whether', 'angle', 'rotation', 'preset', 'direction', 'less', 'angle', 'threshold', 'whether', 'probability', 'value', 'user', 'gazes', 'payment', 'screen', 'great', 'probability', 'threshold', 'response', 'determine', 'target', 'user', 'willingness', 'pay', 'complete', 'payment', 'operation', 'base', 'face', 'recognitiona', 'novel', 'method', 'apparatus', 'face', 'authentication', 'disclose', 'disclose', 'method', 'comprise', 'detect', 'motion', 'subject', 'within', 'predetermined', 'area', 'view', 'assign', 'unique', 'session', 'identification', 'number', 'subject', 'detect', 'within', 'predetermined', 'area', 'view', 'detect', 'facial', 'area', 'subject', 'detect', 'within', 'predetermined', 'area', 'view', 'generate', 'image', 'facial', 'area', 'subject', 'assess', 'quality', 'image', 'facial', 'area', 'subject', 'conduce', 'incremental', 'training', 'image', 'facial', 'area', 'subject', 'determine', 'identity', 'subject', 'base', 'image', 'facial', 'area', 'subject', 'identify', 'intent', 'subject', 'authorize', 'access', 'point', 'entry', 'base', 'determine', 'identity', 'subject', 'base', 'intent', 'subjectdisclosed', 'herein', 'robot', 'electronic', 'device', 'acquire', 'video', 'method', 'acquire', 'video', 'use', 'robot', 'robot', 'include', 'camera', 'configure', 'rotate', 'lateral', 'direction', 'tilt', 'vertical', 'direction', 'control', 'least', 'one', 'direction', 'rotation', 'camera', 'angle', 'tilt', 'camera', 'focal', 'distance', 'camera', 'recognize', 'track', 'user', 'video', 'acquire', 'camerasystems', 'method', 'disclose', 'infer', 'topic', 'file', 'contain', 'audio', 'video', 'example', 'multimodal', 'multimedia', 'file', 'order', 'facilitate', 'video', 'index', 'set', 'entity', 'extract', 'file', 'link', 'produce', 'graph', 'reference', 'information', 'also', 'obtain', 'set', 'entity', 'entity', 'may', 'draw', 'example', 'wikipedia', 'category', 'large', 'ontological', 'data', 'source', 'analysis', 'graph', 'use', 'unsupervised', 'learn', 'permit', 'determine', 'cluster', 'graph', 'extract', 'feature', 'cluster', 'possibly', 'use', 'supervise', 'learn', 'provide', 'selection', 'topic', 'identifier', 'topic', 'identifier', 'use', 'index', 'filea', 'face', 'recognition', 'method', 'neural', 'network', 'train', 'method', 'apparatus', 'electronic', 'device', 'method', 'comprise', 'obtain', 'first', 'face', 'image', 'mean', 'first', 'camera', 'extract', 'first', 'face', 'feature', 'first', 'face', 'image', 'compare', 'first', 'face', 'feature', 'pre-stored', 'second', 'face', 'feature', 'obtain', 'reference', 'similarity', 'second', 'face', 'feature', 'obtain', 'extracting', 'feature', 'second', 'face', 'image', 'obtain', 'second', 'camera', 'second', 'camera', 'first', 'camera', 'different', 'type', 'camera', 'determine', 'accord', 'reference', 'similarity', 'whether', 'first', 'face', 'feature', 'second', 'face', 'feature', 'correspond', 'person', 'present', 'invention', 'disclose', 'technique', 'alert', 'vision', 'impairment', 'system', 'comprise', 'process', 'unit', 'configure', 'operable', 'receive', 'scene', 'data', 'indicative', 'scene', 'least', 'one', 'consumer', 'environment', 'identify', 'scene', 'data', 'certain', 'consumer', 'identify', 'event', 'indicative', 'behavioral', 'compensation', 'vision', 'impairment', 'upon', 'identification', 'event', 'send', 'notification', 'relate', 'vision', 'impairment']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['electronic', 'device', 'configure', 'make', 'screen', 'display', 'plurality', 'image', 'frame', 'comprise', 'image', 'capture', 'device', 'storage', 'device', 'store', 'plurality', 'module', 'processor', 'couple', 'image', 'capture', 'device', 'storage', 'device', 'configure', 'execute', 'module', 'storage', 'device', 'configure', 'screen', 'display', 'plurality', 'marker', 'object', 'plurality', 'predetermine', 'calibration', 'position', 'configure', 'image', 'capturing', 'device', 'capture', 'plurality', 'first', 'head', 'image', 'user', 'look', 'predetermine', 'calibration', 'position', 'perform', 'plurality', 'first', 'face', 'recognition', 'operation', 'first', 'head', 'image', 'obtain', 'plurality', 'first', 'face', 'region', 'correspond', 'predetermined', 'calibration', 'position', 'detect', 'plurality', 'first', 'facial', 'landmark', 'correspond', 'first', 'face', 'region', 'calculate', 'plurality', 'rotation', 'reference', 'angle', 'user', 'look', 'predetermined', 'calibration', 'position', 'accord', 'first', 'facial', 'landmark', 'configure', 'image', 'capture', 'device', 'capture', 'second', 'head', 'image', 'user', 'perform', 'second', 'face', 'recognition', 'operation', 'second', 'head', 'image', 'obtain', 'second', 'face', 'region', 'detect', 'plurality', 'second', 'facial', 'landmark', 'within', 'second', 'face', 'region', 'estimate', 'head', 'posture', 'angle', 'user', 'accord', 'second', 'facial', 'landmark', 'calculate', 'gaze', 'position', 'user', 'screen', 'accord', 'head', 'posture', 'angle', 'rotation', 'reference', 'angle', 'predetermine', 'calibration', 'position', 'configure', 'screen', 'display', 'correspond', 'visual', 'effect', 'accord', 'gaze', 'position', 'electronic', 'device', 'accord', 'claim', 'wherein', 'gaze', 'position', 'comprises', 'first', 'coordinate', 'value', 'first', 'axial', 'direction', 'second', 'coordinate', 'value', 'second', 'axial', 'direction', 'electronic', 'device', 'accord', 'claim', 'wherein', 'head', 'posture', 'angle', 'comprise', 'head', 'pitch', 'angle', 'head', 'yaw', 'angle', 'rotation', 'reference', 'angle', 'comprise', 'first', 'pitch', 'angle', 'second', 'pitch', 'angle', 'first', 'yaw', 'angle', 'second', 'yaw', 'angle', 'correspond', 'predetermined', 'calibration', 'position', 'electronic', 'device', 'accord', 'claim', 'wherein', 'processor', 'performs', 'interpolation', 'operation', 'extrapolation', 'operation', 'accord', 'first', 'yaw', 'angle', 'second', 'yaw', 'angle', 'first', 'position', 'correspond', 'first', 'yaw', 'angle', 'among', 'predetermined', 'calibration', 'position', 'second', 'position', 'correspond', 'second', 'yaw', 'angle', 'among', 'predetermined', 'calibration', 'position', 'head', 'yaw', 'angle', 'thereby', 'obtain', 'first', 'coordinate', 'value', 'gaze', 'position', 'processor', 'performs', 'interpolation', 'operation', 'extrapolation', 'operation', 'accord', 'first', 'pitch', 'angle', 'second', 'pitch', 'angle', 'third', 'position', 'correspond', 'first', 'pitch', 'angle', 'among', 'predetermined', 'calibration', 'position', 'fourth', 'position', 'correspond', 'second', 'pitch', 'angle', 'among', 'predetermined', 'calibration', 'position', 'head', 'pitch', 'angle', 'thereby', 'obtain', 'second', 'coordinate', 'value', 'gaze', 'position', 'electronic', 'device', 'accord', 'claim', 'wherein', 'processor', 'calculates', 'plurality', 'first', 'view', 'distance', 'user', 'screen', 'accord', 'first', 'facial', 'landmark', 'processor', 'estimate', 'second', 'view', 'distance', 'user', 'screen', 'accord', 'second', 'facial', 'landmark', 'processor', 'adjusts', 'rotation', 'reference', 'angle', 'gaze', 'position', 'accord', 'second', 'viewing', 'distance', 'first', 'view', 'distance', 'electronic', 'device', 'accord', 'claim', 'wherein', 'processor', 'map', 'plurality', 'two-dimensional', 'position', 'coordinate', 'second', 'facial', 'landmark', 'plane', 'coordinate', 'system', 'plurality', 'three-dimensional', 'position', 'coordinate', 'three-dimensional', 'coordinate', 'system', 'processor', 'estimate', 'head', 'posture', 'angle', 'accord', 'three-dimensional', 'position', 'coordinate', 'second', 'facial', 'landmark', 'electronic', 'device', 'accord', 'claim', 'wherein', 'second', 'head', 'image', 'comprise', 'wearable', 'device', 'second', 'facial', 'landmark', 'comprise', 'plurality', 'third', 'facial', 'landmark', 'user', 'cover', 'wearable', 'device', 'electronic', 'device', 'accord', 'claim', 'wherein', 'second', 'head', 'image', 'comprise', 'wearable', 'device', 'second', 'facial', 'landmark', 'comprise', 'one', 'simulate', 'landmark', 'mark', 'wearable', 'device', 'operate', 'method', 'adapt', 'electronic', 'device', 'comprise', 'image', 'capture', 'device', 'make', 'screen', 'display', 'plurality', 'image', 'frame', 'method', 'comprise', 'configure', 'screen', 'display', 'plurality', 'marker', 'object', 'plurality', 'predetermine', 'calibration', 'position', 'configure', 'image', 'capture', 'device', 'capture', 'plurality', 'first', 'head', 'image', 'user', 'look', 'predetermine', 'calibration', 'position', 'perform', 'plurality', 'first', 'face', 'recognition', 'operation', 'first', 'head', 'image', 'obtain', 'plurality', 'first', 'face', 'region', 'correspond', 'predetermined', 'calibration', 'position', 'detect', 'plurality', 'first', 'facial', 'landmark', 'correspond', 'first', 'face', 'region', 'calculate', 'plurality', 'rotation', 'reference', 'angle', 'user', 'look', 'predetermined', 'calibration', 'position', 'accord', 'first', 'facial', 'landmark', 'configure', 'image', 'capture', 'device', 'capture', 'second', 'head', 'image', 'user', 'perform', 'second', 'face', 'recognition', 'operation', 'second', 'head', 'image', 'obtain', 'second', 'face', 'region', 'detect', 'plurality', 'second', 'facial', 'landmark', 'within', 'second', 'face', 'region', 'estimate', 'head', 'posture', 'angle', 'user', 'accord', 'second', 'facial', 'landmark', 'calculate', 'gaze', 'position', 'user', 'screen', 'accord', 'head', 'posture', 'angle', 'rotation', 'reference', 'angle', 'predetermine', 'calibration', 'position', 'configure', 'screen', 'display', 'correspond', 'visual', 'effect', 'accord', 'gaze', 'position', 'operation', 'method', 'accord', 'claim', 'wherein', 'gaze', 'position', 'comprises', 'first', 'coordinate', 'value', 'first', 'axial', 'direction', 'second', 'coordinate', 'value', 'second', 'axial', 'direction', 'operation', 'method', 'accord', 'claim', 'wherein', 'head', 'posture', 'angle', 'comprise', 'head', 'pitch', 'angle', 'head', 'yaw', 'angle', 'rotation', 'reference', 'angle', 'comprise', 'first', 'pitch', 'angle', 'second', 'pitch', 'angle', 'first', 'yaw', 'angle', 'second', 'yaw', 'angle', 'correspond', 'predetermined', 'calibration', 'position', 'operation', 'method', 'accord', 'claim', 'wherein', 'step', 'calculate', 'gaze', 'position', 'user', 'screen', 'accord', 'head', 'posture', 'angle', 'rotation', 'reference', 'angle', 'predetermine', 'calibration', 'position', 'comprise', 'perform', 'interpolation', 'operation', 'extrapolation', 'operation', 'accord', 'first', 'yaw', 'angle', 'second', 'yaw', 'angle', 'first', 'position', 'correspond', 'first', 'yaw', 'angle', 'among', 'predetermined', 'calibration', 'position', 'second', 'position', 'correspond', 'second', 'yaw', 'angle', 'among', 'predetermined', 'calibration', 'position', 'head', 'yaw', 'angle', 'thereby', 'obtain', 'first', 'coordinate', 'value', 'gaze', 'position', 'perform', 'interpolation', 'operation', 'extrapolation', 'operation', 'accord', 'first', 'pitch', 'angle', 'second', 'pitch', 'angle', 'third', 'position', 'correspond', 'first', 'pitch', 'angle', 'among', 'predetermined', 'calibration', 'position', 'fourth', 'position', 'correspond', 'second', 'pitch', 'angle', 'among', 'predetermined', 'calibration', 'position', 'head', 'pitch', 'angle', 'thereby', 'obtain', 'second', 'coordinate', 'value', 'gaze', 'position', 'operation', 'method', 'accord', 'claim', 'wherein', 'method', 'comprise', 'calculate', 'plurality', 'first', 'view', 'distance', 'user', 'screen', 'accord', 'first', 'facial', 'landmark', 'estimate', 'second', 'view', 'distance', 'user', 'screen', 'accord', 'second', 'facial', 'landmark', 'adjust', 'rotation', 'reference', 'angle', 'gaze', 'position', 'accord', 'second', 'viewing', 'distance', 'first', 'view', 'distance', 'operation', 'method', 'accord', 'claim', 'wherein', 'method', 'comprise', 'map', 'plurality', 'two-dimensional', 'position', 'coordinate', 'second', 'facial', 'landmark', 'plane', 'coordinate', 'system', 'plurality', 'three-dimensional', 'position', 'coordinate', 'three-dimensional', 'coordinate', 'system', 'estimate', 'head', 'posture', 'angle', 'accord', 'three-dimensional', 'position', 'coordinate', 'second', 'facial', 'landmark', 'operation', 'method', 'accord', 'claim', 'wherein', 'second', 'head', 'image', 'comprise', 'wearable', 'device', 'second', 'facial', 'landmark', 'comprise', 'plurality', 'third', 'facial', 'landmark', 'user', 'cover', 'wearable', 'device', 'operation', 'method', 'accord', 'claim', 'wherein', 'second', 'head', 'image', 'comprise', 'wearable', 'device', 'second', 'facial', 'landmark', 'comprise', 'one', 'simulate', 'landmark', 'mark', 'wearable', 'device', 'computation', 'method', 'apply', 'compute', 'system', 'wherein', 'compute', 'system', 'comprise', 'control', 'unit', 'computation', 'group', 'general', 'storage', 'unit', 'wherein', 'control', 'unit', 'comprise', 'first', 'memory', 'decode', 'logic', 'controller', 'wherein', 'computation', 'group', 'comprise', 'group', 'controller', 'plurality', 'compute', 'unit', 'general', 'storage', 'unit', 'configure', 'store', 'data', 'computation', 'method', 'comprise', 'receive', 'controller', 'first', 'level', 'instruction', 'sequence', 'partition', 'decode', 'logic', 'first', 'level', 'instruction', 'sequence', 'plurality', 'second', 'level', 'instruction', 'sequence', 'create', 'controller', 'thread', 'plurality', 'second', 'level', 'instruction', 'sequence', 'allocate', 'controller', 'independent', 'register', 'well', 'configure', 'independent', 'address', 'function', 'thread', 'thread', 'wherein', 'integer', 'great', 'equal', 'obtain', 'group', 'controller', 'plurality', 'computation', 'type', 'plurality', 'second', 'level', 'instruction', 'sequence', 'obtain', 'correspond', 'fusion', 'computation', 'manner', 'computation', 'type', 'accord', 'plurality', 'computation', 'type', 'adopt', 'plurality', 'compute', 'unit', 'fusion', 'computation', 'manner', 'call', 'thread', 'perform', 'computation', 'plurality', 'second', 'level', 'instruction', 'sequence', 'obtain', 'final', 'result', 'method', 'claim', 'wherein', 'obtain', 'group', 'controller', 'plurality', 'computation', 'type', 'plurality', 'second', 'level', 'instruction', 'sequence', 'obtain', 'correspond', 'fusion', 'computation', 'manner', 'computation', 'type', 'accord', 'plurality', 'computation', 'type', 'adopt', 'plurality', 'compute', 'unit', 'fusion', 'computation', 'manner', 'call', 'thread', 'perform', 'computation', 'plurality', 'second', 'instruction', 'sequence', 'obtain', 'final', 'result', 'computation', 'type', 'represent', 'computation', 'operation', 'type', 'group', 'controller', 'call', 'combine', 'computation', 'manner', 'single', 'instruction', 'multiple', 'data', 'type', 'combination', 'single', 'instruction', 'multiple', 'thread', 'use', 'thread', 'perform', 'combine', 'computation', 'manner', 'obtain', 'final', 'result', 'include', 'partition', 'decode', 'logic', 'thread', 'n', 'wrap', 'allocate', 'plurality', 'compute', 'unit', 'convert', 'group', 'controller', 'plurality', 'second', 'instruction', 'sequence', 'plurality', 'second', 'control', 'signal', 'send', 'second', 'control', 'signal', 'plurality', 'compute', 'unit', 'call', 'plurality', 'compute', 'unit', 'wrap', 'allocate', 'compute', 'unit', 'second', 'control', 'signal', 'fetch', 'correspond', 'data', 'accord', 'independent', 'address', 'function', 'perform', 'plurality', 'compute', 'unit', 'computation', 'data', 'obtain', 'plurality', 'intermediate', 'result', 'splice', 'plurality', 'intermediate', 'result', 'obtain', 'final', 'result', 'method', 'claim', 'wherein', 'obtain', 'group', 'controller', 'plurality', 'computation', 'type', 'plurality', 'second', 'level', 'instruction', 'sequence', 'obtain', 'correspond', 'fusion', 'computation', 'manner', 'computation', 'type', 'accord', 'plurality', 'computation', 'type', 'adopt', 'plurality', 'compute', 'unit', 'fusion', 'computation', 'manner', 'call', 'thread', 'perform', 'computation', 'plurality', 'second', 'instruction', 'sequence', 'obtain', 'final', 'result', 'computation', 'type', 'represent', 'computation', 'operation', 'different', 'type', 'group', 'controller', 'call', 'simultaneous', 'multi-threading', 'thread', 'perform', 'computation', 'obtain', 'final', 'result', 'include', 'partition', 'decode', 'logic', 'thread', 'n', 'wrap', 'convert', 'plurality', 'second', 'instruction', 'sequence', 'plurality', 'second', 'control', 'signal', 'obtain', 'group', 'controller', 'computation', 'type', 'support', 'plurality', 'compute', 'unit', 'allocate', 'controller', 'n', 'wrap', 'plurality', 'second', 'control', 'signal', 'correspond', 'compute', 'unit', 'support', 'computation', 'type', 'wrap', 'second', 'control', 'signal', 'call', 'plurality', 'compute', 'unit', 'wrap', 'allocate', 'compute', 'unit', 'second', 'control', 'signal', 'fetch', 'plurality', 'compute', 'unit', 'correspond', 'data', 'perform', 'plurality', 'compute', 'unit', 'computation', 'data', 'obtain', 'plurality', 'intermediate', 'result', 'splice', 'intermediate', 'result', 'obtain', 'final', 'result', 'method', 'claim', 'comprise', 'wrap', 'plurality', 'wrap', 'block', 'add', 'wrap', 'wait', 'queue', 'data', 'wrap', 'already', 'fetch', 'add', 'wrap', 'preparation', 'queue', 'wherein', 'preparation', 'queue', 'queue', 'wrap', 'schedule', 'execute', 'locate', 'compute', 'resource', 'idle', 'method', 'claim', 'wherein', 'first', 'level', 'instruction', 'sequence', 'include', 'long', 'instruction', 'second', 'level', 'instruction', 'sequence', 'include', 'instruction', 'sequence', 'method', 'claim', 'wherein', 'compute', 'system', 'include', 'tree', 'module', 'wherein', 'tree', 'module', 'include', 'root', 'port', 'plurality', 'branch', 'port', 'wherein', 'root', 'port', 'tree', 'module', 'connect', 'group', 'controller', 'plurality', 'branch', 'port', 'tree', 'module', 'connect', 'compute', 'unit', 'plurality', 'compute', 'unit', 'respectively', 'tree', 'module', 'configure', 'forward', 'data', 'block', 'wrap', 'instruction', 'sequence', 'group', 'controller', 'plurality', 'compute', 'unit', 'method', 'claim', 'wherein', 'tree', 'module', 'n-ary', 'tree', 'wherein', 'n', 'integer', 'great', 'equal', 'method', 'claim', 'wherein', 'compute', 'system', 'include', 'branch', 'process', 'circuit', 'wherein', 'branch', 'process', 'circuit', 'connect', 'group', 'controller', 'plurality', 'compute', 'unit', 'branch', 'process', 'circuit', 'configure', 'forward', 'data', 'wrap', 'instruction', 'sequence', 'group', 'controller', 'plurality', 'compute', 'unit', 'compute', 'system', 'comprise', 'control', 'unit', 'computation', 'group', 'general', 'storage', 'unit', 'wherein', 'control', 'unit', 'include', 'first', 'memory', 'decode', 'logic', 'controller', 'computation', 'group', 'include', 'group', 'controller', 'plurality', 'compute', 'unit', 'general', 'storage', 'unit', 'configure', 'store', 'data', 'controller', 'configure', 'receive', 'first', 'level', 'instruction', 'sequence', 'control', 'first', 'memory', 'decode', 'logic', 'decode', 'logic', 'configure', 'partition', 'first', 'level', 'instruction', 'sequence', 'plurality', 'second', 'level', 'instruction', 'sequence', 'controller', 'configured', 'create', 'thread', 'plurality', 'second', 'level', 'instruction', 'sequence', 'allocate', 'independent', 'register', 'configure', 'independent', 'address', 'function', 'thread', 'thread', 'integer', 'great', 'equal', 'controller', 'configure', 'convert', 'plurality', 'second', 'instruction', 'sequence', 'plurality', 'control', 'signal', 'send', 'group', 'controller', 'group', 'controller', 'configure', 'receive', 'plurality', 'control', 'signal', 'obtain', 'plurality', 'computational', 'type', 'plurality', 'control', 'signal', 'divide', 'thread', 'n', 'wrap', 'allocate', 'n', 'wrap', 'plurality', 'control', 'signal', 'plurality', 'compute', 'unit', 'accord', 'plurality', 'computational', 'type', 'plurality', 'compute', 'unit', 'configure', 'fetch', 'data', 'general', 'storage', 'unit', 'allocate', 'wrap', 'control', 'signal', 'perform', 'computation', 'obtain', 'intermediate', 'result', 'group', 'controller', 'configure', 'splice', 'intermediate', 'result', 'obtain', 'final', 'computation', 'result', 'compute', 'system', 'claim', 'wherein', 'plurality', 'compute', 'unit', 'include', 'addition', 'compute', 'unit', 'multiplication', 'compute', 'unit', 'activation', 'compute', 'unit', 'dedicate', 'compute', 'unit', 'compute', 'system', 'claim', 'wherein', 'dedicate', 'compute', 'unit', 'include', 'face', 'recognition', 'compute', 'unit', 'graphic', 'compute', 'unit', 'fingerprint', 'compute', 'unit', 'neural', 'network', 'compute', 'unit', 'compute', 'system', 'claim', 'wherein', 'group', 'controller', 'configure', 'computation', 'type', 'plurality', 'control', 'signal', 'graphic', 'computation', 'fingerprint', 'identification', 'face', 'recognition', 'neural', 'network', 'operation', 'allocate', 'plurality', 'control', 'signal', 'face', 'recognition', 'compute', 'unit', 'graphic', 'compute', 'unit', 'fingerprint', 'compute', 'unit', 'neural', 'network', 'compute', 'unit', 'respectively', 'compute', 'system', 'claim', 'wherein', 'first', 'level', 'instruction', 'sequence', 'include', 'long', 'instruction', 'second', 'level', 'instruction', 'sequence', 'include', 'instruction', 'sequence', 'compute', 'system', 'claim', 'comprise', 'tree', 'module', 'wherein', 'tree', 'module', 'include', 'root', 'port', 'plurality', 'branch', 'port', 'wherein', 'root', 'port', 'tree', 'module', 'connect', 'group', 'controller', 'plurality', 'branch', 'port', 'tree', 'module', 'connect', 'compute', 'unit', 'plurality', 'compute', 'unit', 'respectively', 'tree', 'module', 'configure', 'forward', 'data', 'block', 'wrap', 'instruction', 'sequence', 'group', 'controller', 'plurality', 'compute', 'unit', 'compute', 'system', 'claim', 'wherein', 'tree', 'module', 'n-ary', 'tree', 'wherein', 'n', 'integer', 'great', 'equal', 'computing', 'system', 'claim', 'wherein', 'compute', 'system', 'include', 'branch', 'processing', 'circuit', 'branch', 'process', 'circuit', 'connect', 'group', 'controller', 'plurality', 'compute', 'unit', 'branch', 'process', 'circuit', 'configure', 'forward', 'data', 'wrap', 'instruction', 'sequence', 'group', 'controller', 'plurality', 'compute', 'unit', 'computer', 'program', 'product', 'comprise', 'non-instant', 'computer', 'readable', 'storage', 'medium', 'wherein', 'computer', 'program', 'store', 'non-instant', 'computer', 'readable', 'storage', 'medium', 'computer', 'program', 'capable', 'cause', 'computer', 'perform', 'method', 'claim', 'operation', 'method', 'detect', 'body', 'information', 'one', 'passenger', 'vehicle', 'base', 'human', \"'\", 'status', 'recognition', 'comprise', 'step', 'least', 'one', 'interior', 'image', 'interior', 'vehicle', 'acquire', 'passenger', 'body', 'information-detecting', 'device', 'perform', 'process', 'inputting', 'interior', 'image', 'face', 'recognition', 'network', 'thereby', 'allow', 'face', 'recognition', 'network', 'detect', 'face', 'passenger', 'interior', 'image', 'thus', 'output', 'multiple', 'piece', 'passenger', 'feature', 'information', 'correspond', 'detect', 'face', 'ii', 'process', 'inputting', 'interior', 'image', 'body', 'recognition', 'network', 'thereby', 'allow', 'body', 'recognition', 'network', 'detect', 'body', 'passenger', 'interior', 'image', 'thus', 'output', 'body-part', 'length', 'information', 'detect', 'body', 'b', 'passenger', 'body', 'information-detecting', 'device', 'perform', 'process', 'retrieve', 'specific', 'height', 'mapping', 'information', 'correspond', 'specific', 'passenger', 'feature', 'information', 'specific', 'passenger', 'height', 'map', 'table', 'store', 'height', 'map', 'information', 'represent', 'respective', 'one', 'predetermine', 'ratio', 'one', 'segment', 'body', 'portion', 'human', 'group', 'height', 'per', 'human', 'group', 'process', 'acquire', 'specific', 'height', 'specific', 'passenger', 'specific', 'height', 'map', 'information', 'refer', 'specific', 'body-part', 'length', 'information', 'specific', 'passenger', 'process', 'retrieve', 'specific', 'weight', 'map', 'information', 'correspond', 'specific', 'passenger', 'feature', 'information', 'weight', 'map', 'table', 'store', 'multiple', 'piece', 'weight', 'map', 'information', 'represent', 'predetermine', 'correlation', 'height', 'weight', 'per', 'human', 'group', 'process', 'acquire', 'weight', 'specific', 'passenger', 'specific', 'weight', 'map', 'information', 'refer', 'specific', 'height', 'specific', 'passenger', 'method', 'claim', 'wherein', 'step', 'passenger', 'body', 'information-detecting', 'device', 'performs', 'process', 'inputting', 'interior', 'image', 'body', 'recognition', 'network', 'thereby', 'allow', 'body', 'recognition', 'network', 'output', 'one', 'feature', 'tensors', 'one', 'channel', 'correspond', 'interior', 'image', 'via', 'feature', 'extraction', 'network', 'ii', 'generate', 'least', 'one', 'keypoint', 'heatmap', 'least', 'one', 'part', 'affinity', 'field', 'one', 'channel', 'correspond', 'feature', 'tensor', 'via', 'keypoint', 'heatmap', '&', 'part', 'affinity', 'field', 'extractor', 'iii', 'extract', 'keypoints', 'keypoint', 'heatmap', 'via', 'keypoint', 'detector', 'group', 'extract', 'keypoints', 'refer', 'part', 'affinity', 'field', 'thus', 'generate', 'body', 'part', 'per', 'passenger', 'result', 'allow', 'body', 'recognition', 'network', 'output', 'multiple', 'piece', 'body-part', 'length', 'information', 'passenger', 'refer', 'body', 'part', 'per', 'passenger', 'method', 'claim', 'wherein', 'feature', 'extraction', 'network', 'include', 'least', 'one', 'convolutional', 'layer', 'applies', 'least', 'one', 'convolution', 'operation', 'interior', 'image', 'thereby', 'output', 'feature', 'tensor', 'method', 'claim', 'wherein', 'keypoint', 'heatmap', '&', 'part', 'affinity', 'field', 'extractor', 'include', 'one', 'fully', 'convolutional', 'network', 'convolutional', 'layer', 'apply', 'fully-convolution', 'operation', 'convolution', 'operation', 'feature', 'tensor', 'thereby', 'generate', 'keypoint', 'heatmap', 'part', 'affinity', 'field', 'method', 'claim', 'wherein', 'keypoint', 'detector', 'connects', 'refer', 'part', 'affinity', 'field', 'pair', 'respectively', 'high', 'mutual', 'connection', 'probability', 'connect', 'among', 'extracted', 'keypoints', 'thereby', 'group', 'extract', 'keypoints', 'method', 'claim', 'wherein', 'feature', 'extraction', 'network', 'keypoint', 'heatmap', '&', 'part', 'affinity', 'field', 'extractor', 'learn', 'learning', 'device', 'perform', 'process', 'inputting', 'least', 'one', 'training', 'image', 'include', 'one', 'object', 'train', 'feature', 'extraction', 'network', 'thereby', 'allow', 'feature', 'extraction', 'network', 'generate', 'one', 'feature', 'tensor', 'train', 'one', 'channel', 'apply', 'least', 'one', 'convolutional', 'operation', 'training', 'image', 'ii', 'process', 'inputting', 'feature', 'tensor', 'train', 'keypoint', 'heatmap', '&', 'part', 'affinity', 'field', 'extractor', 'thereby', 'allow', 'keypoint', 'heatmap', '&', 'part', 'affinity', 'field', 'extractor', 'generate', 'one', 'keypoint', 'heatmaps', 'train', 'one', 'part', 'affinity', 'field', 'train', 'one', 'channels', 'feature', 'tensor', 'train', 'iii', 'process', 'inputting', 'keypoint', 'heatmaps', 'train', 'part', 'affinity', 'field', 'train', 'keypoint', 'detector', 'thereby', 'allow', 'keypoint', 'detector', 'extract', 'keypoints', 'train', 'keypoint', 'heatmaps', 'train', 'process', 'grouping', 'extract', 'keypoints', 'train', 'refer', 'part', 'affinity', 'field', 'train', 'thereby', 'detect', 'keypoints', 'per', 'object', 'train', 'iv', 'process', 'allow', 'loss', 'layer', 'calculate', 'one', 'loss', 'refer', 'keypoints', 'per', 'object', 'train', 'correspond', 'ground', 'truth', 'thereby', 'adjust', 'one', 'parameter', 'feature', 'extraction', 'network', 'keypoint', 'heatmap', '&', 'part', 'affinity', 'field', 'extractor', 'loss', 'minimize', 'backpropagation', 'use', 'loss', 'method', 'claim', 'wherein', 'step', 'passenger', 'body', 'information-detecting', 'device', 'performs', 'process', 'inputting', 'interior', 'image', 'face', 'recognition', 'network', 'thereby', 'allow', 'face', 'recognition', 'network', 'detect', 'face', 'passenger', 'locate', 'interior', 'image', 'via', 'face', 'detector', 'output', 'multiple', 'piece', 'passenger', 'feature', 'information', 'facial', 'image', 'via', 'facial', 'feature', 'classifier', 'method', 'claim', 'wherein', 'step', 'passenger', 'body', 'information-detecting', 'device', 'performs', 'process', 'inputting', 'interior', 'image', 'face', 'recognition', 'network', 'thereby', 'allow', 'face', 'recognition', 'network', 'apply', 'least', 'one', 'convolution', 'operation', 'interior', 'image', 'thus', 'output', 'least', 'one', 'feature', 'map', 'correspond', 'interior', 'image', 'via', 'least', 'one', 'convolutional', 'layer', 'ii', 'output', 'one', 'proposal', 'box', 'passenger', 'estimate', 'located', 'feature', 'map', 'via', 'region', 'proposal', 'network', 'iii', 'apply', 'pool', 'operation', 'one', 'region', 'correspond', 'proposal', 'box', 'feature', 'map', 'thus', 'output', 'least', 'one', 'feature', 'vector', 'via', 'pool', 'layer', 'iv', 'apply', 'fully-connected', 'operation', 'feature', 'vector', 'thus', 'output', 'multiple', 'piece', 'passenger', 'feature', 'information', 'correspond', 'face', 'passenger', 'correspond', 'proposal', 'box', 'via', 'fully', 'connect', 'layer', 'method', 'claim', 'wherein', 'multiple', 'piece', 'passenger', 'feature', 'information', 'include', 'age', 'gender', 'race', 'correspond', 'passenger', 'passenger', 'body', 'information-detecting', 'device', 'detect', 'body', 'information', 'one', 'passenger', 'vehicle', 'base', 'human', \"'\", 'status', 'recognition', 'comprise', 'least', 'one', 'memory', 'store', 'instruction', 'least', 'one', 'processor', 'configure', 'execute', 'instruction', 'perform', 'support', 'another', 'device', 'perform', 'least', 'one', 'interior', 'image', 'interior', 'vehicle', 'acquire', 'process', 'inputting', 'interior', 'image', 'face', 'recognition', 'network', 'thereby', 'allow', 'face', 'recognition', 'network', 'detect', 'face', 'passenger', 'interior', 'image', 'thus', 'output', 'multiple', 'piece', 'passenger', 'feature', 'information', 'correspond', 'detect', 'face', 'ii', 'process', 'inputting', 'interior', 'image', 'body', 'recognition', 'network', 'thereby', 'allow', 'body', 'recognition', 'network', 'detect', 'body', 'passenger', 'interior', 'image', 'thus', 'output', 'body-part', 'length', 'information', 'detect', 'body', 'ii', 'process', 'retrieve', 'specific', 'height', 'mapping', 'information', 'correspond', 'specific', 'passenger', 'feature', 'information', 'specific', 'passenger', 'height', 'map', 'table', 'store', 'height', 'map', 'information', 'represent', 'respective', 'one', 'predetermine', 'ratio', 'one', 'segment', 'body', 'portion', 'human', 'group', 'height', 'per', 'human', 'group', 'process', 'acquire', 'specific', 'height', 'specific', 'passenger', 'specific', 'height', 'map', 'information', 'refer', 'specific', 'body-part', 'length', 'information', 'specific', 'passenger', 'process', 'retrieve', 'specific', 'weight', 'map', 'information', 'correspond', 'specific', 'passenger', 'feature', 'information', 'weight', 'map', 'table', 'store', 'multiple', 'piece', 'weight', 'map', 'information', 'represent', 'predetermine', 'correlation', 'height', 'weight', 'per', 'human', 'group', 'process', 'acquire', 'weight', 'specific', 'passenger', 'specific', 'weight', 'map', 'information', 'refer', 'specific', 'height', 'specific', 'passenger', 'passenger', 'body', 'information-detecting', 'device', 'claim', 'wherein', 'process', 'processor', 'performs', 'process', 'inputting', 'interior', 'image', 'body', 'recognition', 'network', 'thereby', 'allow', 'body', 'recognition', 'network', 'output', 'one', 'feature', 'tensors', 'one', 'channel', 'correspond', 'interior', 'image', 'via', 'feature', 'extraction', 'network', 'ii', 'generate', 'least', 'one', 'keypoint', 'heatmap', 'least', 'one', 'part', 'affinity', 'field', 'one', 'channel', 'correspond', 'feature', 'tensor', 'via', 'keypoint', 'heatmap', '&', 'part', 'affinity', 'field', 'extractor', 'iii', 'extract', 'keypoints', 'keypoint', 'heatmap', 'via', 'keypoint', 'detector', 'group', 'extract', 'keypoints', 'refer', 'part', 'affinity', 'field', 'thus', 'generate', 'body', 'part', 'per', 'passenger', 'result', 'allow', 'body', 'recognition', 'network', 'output', 'multiple', 'piece', 'body-part', 'length', 'information', 'passenger', 'refer', 'body', 'part', 'per', 'passenger', 'passenger', 'body', 'information-detecting', 'device', 'claim', 'wherein', 'heatmap', '&', 'part', 'affinity', 'field', 'extractor', 'include', 'one', 'fully', 'convolutional', 'network', 'convolutional', 'layer', 'apply', 'fully-convolution', 'operation', 'convolution', 'operation', 'feature', 'tensor', 'thereby', 'generate', 'keypoint', 'heatmap', 'part', 'affinity', 'field', 'passenger', 'body', 'information-detecting', 'device', 'claim', 'wherein', 'keypoint', 'detector', 'connects', 'refer', 'part', 'affinity', 'field', 'pair', 'respectively', 'high', 'mutual', 'connection', 'probability', 'connect', 'among', 'extracted', 'keypoints', 'thereby', 'group', 'extract', 'keypoints', 'passenger', 'body', 'information-detecting', 'device', 'claim', 'wherein', 'feature', 'extraction', 'network', 'keypoint', 'heatmap', '&', 'part', 'affinity', 'field', 'extractor', 'learn', 'learning', 'device', 'perform', 'process', 'inputting', 'least', 'one', 'training', 'image', 'include', 'one', 'object', 'train', 'feature', 'extraction', 'network', 'thereby', 'allow', 'feature', 'extraction', 'network', 'generate', 'one', 'feature', 'tensor', 'train', 'one', 'channel', 'apply', 'least', 'one', 'convolutional', 'operation', 'training', 'image', 'ii', 'process', 'inputting', 'feature', 'tensor', 'train', 'keypoint', 'heatmap', '&', 'part', 'affinity', 'field', 'extractor', 'thereby', 'allow', 'keypoint', 'heatmap', '&', 'part', 'affinity', 'field', 'extractor', 'generate', 'one', 'keypoint', 'heatmaps', 'train', 'one', 'part', 'affinity', 'field', 'train', 'one', 'channels', 'feature', 'tensor', 'train', 'iii', 'process', 'inputting', 'keypoint', 'heatmaps', 'train', 'part', 'affinity', 'field', 'train', 'keypoint', 'detector', 'thereby', 'allow', 'keypoint', 'detector', 'extract', 'keypoints', 'train', 'keypoint', 'heatmaps', 'train', 'process', 'grouping', 'extract', 'keypoints', 'train', 'refer', 'part', 'affinity', 'field', 'train', 'thereby', 'detect', 'keypoints', 'per', 'object', 'train', 'iv', 'process', 'allow', 'loss', 'layer', 'calculate', 'one', 'loss', 'refer', 'keypoints', 'per', 'object', 'train', 'correspond', 'ground', 'truth', 'thereby', 'adjust', 'one', 'parameter', 'feature', 'extraction', 'network', 'keypoint', 'heatmap', '&', 'part', 'affinity', 'field', 'extractor', 'loss', 'minimize', 'backpropagation', 'use', 'loss', 'passenger', 'body', 'information-detecting', 'device', 'claim', 'wherein', 'process', 'processor', 'performs', 'process', 'inputting', 'interior', 'image', 'face', 'recognition', 'network', 'thereby', 'allow', 'face', 'recognition', 'network', 'apply', 'least', 'one', 'convolution', 'operation', 'interior', 'image', 'thus', 'output', 'least', 'one', 'feature', 'map', 'correspond', 'interior', 'image', 'via', 'least', 'one', 'convolutional', 'layer', 'ii', 'output', 'one', 'proposal', 'box', 'passenger', 'estimate', 'located', 'feature', 'map', 'via', 'region', 'proposal', 'network', 'iii', 'apply', 'pool', 'operation', 'one', 'region', 'correspond', 'proposal', 'box', 'feature', 'map', 'thus', 'output', 'least', 'one', 'feature', 'vector', 'via', 'pool', 'layer', 'iv', 'apply', 'fully-connected', 'operation', 'feature', 'vector', 'thus', 'output', 'multiple', 'piece', 'passenger', 'feature', 'information', 'correspond', 'face', 'passenger', 'correspond', 'proposal', 'box', 'via', 'fully', 'connect', 'layer', 'computer', 'implement', 'method', 'perform', 'video', 'cod', 'base', 'face', 'detection', 'comprise', 'receive', 'video', 'frame', 'comprise', 'one', 'plurality', 'video', 'frame', 'video', 'sequence', 'determine', 'video', 'frame', 'key', 'frame', 'video', 'sequence', 'perform', 'response', 'video', 'frame', 'key', 'frame', 'video', 'sequence', 'multi-stage', 'facial', 'search', 'video', 'frame', 'base', 'predetermined', 'feature', 'template', 'predetermine', 'number', 'stage', 'determine', 'first', 'candidate', 'face', 'region', 'second', 'candidate', 'face', 'region', 'video', 'frame', 'test', 'first', 'second', 'candidate', 'face', 'region', 'base', 'skin', 'tone', 'information', 'determine', 'first', 'candidate', 'face', 'region', 'valid', 'face', 'region', 'second', 'candidate', 'face', 'region', 'invalid', 'face', 'region', 'reject', 'second', 'candidate', 'face', 'region', 'output', 'first', 'candidate', 'face', 'region', 'encode', 'video', 'frame', 'base', 'least', 'part', 'first', 'candidate', 'face', 'region', 'valid', 'face', 'region', 'generate', 'cod', 'bitstream', 'method', 'claim', 'wherein', 'skin', 'tone', 'information', 'comprise', 'skin', 'probability', 'map', 'method', 'claim', 'wherein', 'say', 'test', 'first', 'second', 'candidate', 'face', 'region', 'base', 'skin', 'tone', 'information', 'perform', 'response', 'video', 'frame', 'key', 'frame', 'video', 'sequence', 'method', 'claim', 'wherein', 'first', 'candidate', 'face', 'region', 'comprise', 'rectangular', 'region', 'method', 'comprise', 'determine', 'free', 'form', 'shape', 'face', 'region', 'correspond', 'first', 'candidate', 'face', 'region', 'wherein', 'free', 'form', 'shape', 'face', 'region', 'least', 'one', 'pixel', 'accuracy', 'small', 'block', 'pixel', 'accuracy', 'method', 'claim', 'wherein', 'determine', 'free', 'form', 'shape', 'face', 'region', 'comprise', 'generate', 'enhance', 'skip', 'probability', 'map', 'correspond', 'first', 'candidate', 'face', 'region', 'binarizing', 'enhance', 'skip', 'probability', 'map', 'overlay', 'binarized', 'enhanced', 'skip', 'probability', 'map', 'least', 'portion', 'video', 'frame', 'provide', 'free', 'form', 'shape', 'face', 'region', 'method', 'claim', 'wherein', 'second', 'video', 'frame', 'comprise', 'non-key', 'frame', 'video', 'sequence', 'method', 'comprise', 'perform', 'face', 'detection', 'second', 'video', 'frame', 'video', 'sequence', 'base', 'free', 'form', 'shape', 'face', 'region', 'method', 'claim', 'comprise', 'track', 'second', 'free', 'form', 'shape', 'face', 'region', 'second', 'video', 'frame', 'base', 'free', 'form', 'shape', 'face', 'region', 'video', 'frame', 'method', 'claim', 'wherein', 'track', 'second', 'free', 'form', 'shape', 'face', 'region', 'comprise', 'determine', 'location', 'second', 'valid', 'face', 'region', 'second', 'video', 'frame', 'base', 'displacement', 'offset', 'respect', 'first', 'candidate', 'face', 'region', 'method', 'claim', 'comprise', 'determine', 'displacement', 'offset', 'base', 'offset', 'centroid', 'bound', 'box', 'around', 'skin', 'enhance', 'region', 'correspond', 'first', 'candidate', 'face', 'region', 'second', 'centroid', 'second', 'bounding', 'box', 'around', 'second', 'skin', 'enhance', 'region', 'second', 'video', 'frame', 'method', 'claim', 'wherein', 'encode', 'video', 'frame', 'base', 'least', 'part', 'first', 'candidate', 'face', 'region', 'valid', 'face', 'region', 'comprise', 'least', 'one', 'reduce', 'quantization', 'parameter', 'correspond', 'first', 'candidate', 'face', 'region', 'adjust', 'lambda', 'value', 'first', 'candidate', 'face', 'region', 'disable', 'skip', 'cod', 'first', 'candidate', 'face', 'region', 'method', 'claim', 'wherein', 'bitstream', 'comprise', 'least', 'one', 'hadvanced', 'video', 'cod', 'avc', 'compliant', 'bitstream', 'hhigh', 'efficiency', 'video', 'cod', 'hevc', 'compliant', 'bitstream', 'vp', 'compliant', 'bitstream', 'vp', 'compliant', 'bitstream', 'alliance', 'open', 'medium', 'aom', 'av', 'compliant', 'bitstream', 'computer', 'implement', 'method', 'perform', 'face', 'detection', 'comprise', 'receive', 'video', 'frame', 'sequence', 'video', 'frame', 'perform', 'multi-stage', 'facial', 'search', 'video', 'frame', 'base', 'predetermined', 'feature', 'template', 'predetermine', 'number', 'stage', 'determine', 'first', 'candidate', 'face', 'region', 'second', 'candidate', 'face', 'region', 'video', 'frame', 'test', 'first', 'second', 'candidate', 'face', 'region', 'base', 'skin', 'tone', 'information', 'determine', 'first', 'candidate', 'face', 'region', 'valid', 'face', 'region', 'second', 'candidate', 'face', 'region', 'invalid', 'face', 'region', 'reject', 'second', 'candidate', 'face', 'region', 'output', 'first', 'candidate', 'face', 'region', 'valid', 'face', 'region', 'process', 'provide', 'index', 'indicative', 'person', 'present', 'video', 'frame', 'base', 'valid', 'face', 'region', 'method', 'claim', 'wherein', 'sequence', 'video', 'frame', 'comprises', 'sequence', 'surveillance', 'video', 'frame', 'method', 'comprise', 'perform', 'face', 'recognition', 'surveillance', 'video', 'frame', 'base', 'valid', 'face', 'region', 'method', 'claim', 'wherein', 'sequence', 'video', 'frame', 'comprises', 'sequence', 'decode', 'video', 'frame', 'method', 'comprise', 'add', 'marker', 'correspond', 'receive', 'video', 'frame', 'perform', 'face', 'recognition', 'receive', 'video', 'frame', 'base', 'valid', 'face', 'region', 'method', 'claim', 'wherein', 'sequence', 'video', 'frame', 'receive', 'device', 'login', 'attempt', 'method', 'comprise', 'perform', 'face', 'recognition', 'base', 'valid', 'face', 'region', 'allow', 'access', 'device', 'secure', 'face', 'recognize', 'method', 'claim', 'wherein', 'sequence', 'video', 'frame', 'comprises', 'sequence', 'videoconferencing', 'frame', 'method', 'comprise', 'encode', 'video', 'frame', 'base', 'least', 'part', 'valid', 'face', 'region', 'generate', 'cod', 'bitstream', 'method', 'claim', 'wherein', 'encode', 'video', 'frame', 'comprise', 'encode', 'background', 'region', 'video', 'frame', 'bitstream', 'method', 'claim', 'comprise', 'encode', 'video', 'frame', 'base', 'least', 'part', 'valid', 'face', 'region', 'generate', 'cod', 'bitstream', 'wherein', 'encode', 'video', 'frame', 'comprise', 'include', 'metadata', 'correspond', 'valid', 'face', 'region', 'bitstream', 'method', 'claim', 'comprise', 'decode', 'cod', 'bitstream', 'generate', 'decode', 'video', 'frame', 'determine', 'metadata', 'correspond', 'valid', 'face', 'region', 'bitstream', 'method', 'claim', 'comprise', 'least', 'one', 'replace', 'valid', 'face', 'region', 'base', 'decode', 'metadata', 'crop', 'display', 'image', 'data', 'correspond', 'valid', 'face', 'region', 'base', 'decode', 'metadata', 'index', 'decode', 'video', 'frame', 'base', 'decode', 'metadata', 'system', 'perform', 'video', 'cod', 'base', 'face', 'detection', 'comprise', 'memory', 'configure', 'store', 'video', 'frame', 'comprise', 'one', 'plurality', 'video', 'frame', 'video', 'sequence', 'processor', 'couple', 'memory', 'processor', 'receive', 'video', 'frame', 'determine', 'video', 'frame', 'key', 'frame', 'video', 'sequence', 'perform', 'response', 'video', 'frame', 'key', 'frame', 'video', 'sequence', 'multi-stage', 'facial', 'search', 'video', 'frame', 'base', 'predetermined', 'feature', 'template', 'predetermine', 'number', 'stage', 'determine', 'first', 'candidate', 'face', 'region', 'second', 'candidate', 'face', 'region', 'video', 'frame', 'test', 'first', 'second', 'candidate', 'face', 'region', 'base', 'skin', 'tone', 'information', 'determine', 'first', 'candidate', 'face', 'region', 'valid', 'face', 'region', 'second', 'candidate', 'face', 'region', 'invalid', 'face', 'region', 'reject', 'second', 'candidate', 'face', 'region', 'output', 'first', 'candidate', 'face', 'region', 'encode', 'video', 'frame', 'base', 'least', 'part', 'first', 'candidate', 'face', 'region', 'valid', 'face', 'region', 'generate', 'cod', 'bitstream', 'system', 'claim', 'wherein', 'skin', 'tone', 'information', 'comprise', 'skin', 'probability', 'map', 'system', 'claim', 'wherein', 'first', 'candidate', 'face', 'region', 'comprise', 'rectangular', 'region', 'processor', 'determine', 'free', 'form', 'shape', 'face', 'region', 'correspond', 'first', 'candidate', 'face', 'region', 'wherein', 'free', 'form', 'shape', 'face', 'region', 'least', 'one', 'pixel', 'accuracy', 'small', 'block', 'pixel', 'accuracy', 'system', 'claim', 'wherein', 'processor', 'determine', 'free', 'form', 'shape', 'face', 'region', 'comprise', 'processor', 'generate', 'enhance', 'skip', 'probability', 'map', 'correspond', 'first', 'candidate', 'face', 'region', 'binarize', 'enhance', 'skip', 'probability', 'map', 'overlay', 'binarized', 'enhanced', 'skip', 'probability', 'map', 'least', 'portion', 'video', 'frame', 'provide', 'free', 'form', 'shape', 'face', 'region', 'system', 'claim', 'wherein', 'second', 'video', 'frame', 'comprise', 'non-key', 'frame', 'video', 'sequence', 'processor', 'perform', 'face', 'detection', 'second', 'video', 'frame', 'video', 'sequence', 'base', 'free', 'form', 'shape', 'face', 'region', 'system', 'claim', 'wherein', 'processor', 'track', 'second', 'free', 'form', 'shape', 'face', 'region', 'second', 'video', 'frame', 'base', 'free', 'form', 'shape', 'face', 'region', 'video', 'frame', 'system', 'claim', 'wherein', 'encode', 'video', 'frame', 'base', 'least', 'part', 'first', 'candidate', 'face', 'region', 'valid', 'face', 'region', 'comprise', 'processor', 'reduce', 'quantization', 'parameter', 'correspond', 'first', 'candidate', 'face', 'region', 'adjust', 'lambda', 'value', 'first', 'candidate', 'face', 'region', 'disable', 'skip', 'cod', 'first', 'candidate', 'face', 'region', 'least', 'one', 'non-transitory', 'machine', 'readable', 'medium', 'comprise', 'plurality', 'instruction', 'response', 'execute', 'device', 'cause', 'device', 'perform', 'video', 'cod', 'base', 'face', 'detection', 'receive', 'video', 'frame', 'comprise', 'one', 'plurality', 'video', 'frame', 'video', 'sequence', 'determine', 'video', 'frame', 'key', 'frame', 'video', 'sequence', 'perform', 'response', 'video', 'frame', 'key', 'frame', 'video', 'sequence', 'multi-stage', 'facial', 'search', 'video', 'frame', 'base', 'predetermined', 'feature', 'template', 'predetermine', 'number', 'stage', 'determine', 'first', 'candidate', 'face', 'region', 'second', 'candidate', 'face', 'region', 'video', 'frame', 'test', 'first', 'second', 'candidate', 'face', 'region', 'base', 'skin', 'tone', 'information', 'determine', 'first', 'candidate', 'face', 'region', 'valid', 'face', 'region', 'second', 'candidate', 'face', 'region', 'invalid', 'face', 'region', 'reject', 'second', 'candidate', 'face', 'region', 'output', 'first', 'candidate', 'face', 'region', 'encode', 'video', 'frame', 'base', 'least', 'part', 'first', 'candidate', 'face', 'region', 'valid', 'face', 'region', 'generate', 'cod', 'bitstream', 'non-transitory', 'machine', 'readable', 'medium', 'claim', 'wherein', 'skin', 'tone', 'information', 'comprise', 'skin', 'probability', 'map', 'non-transitory', 'machine', 'readable', 'medium', 'claim', 'wherein', 'first', 'candidate', 'face', 'region', 'comprise', 'rectangular', 'region', 'machine', 'readable', 'medium', 'comprise', 'instruction', 'response', 'execute', 'device', 'cause', 'device', 'perform', 'video', 'cod', 'base', 'face', 'detection', 'determine', 'free', 'form', 'shape', 'face', 'region', 'correspond', 'first', 'candidate', 'face', 'region', 'wherein', 'free', 'form', 'shape', 'face', 'region', 'least', 'one', 'pixel', 'accuracy', 'small', 'block', 'pixel', 'accuracy', 'non-transitory', 'machine', 'readable', 'medium', 'claim', 'wherein', 'determine', 'free', 'form', 'shape', 'face', 'region', 'comprise', 'generate', 'enhance', 'skip', 'probability', 'map', 'correspond', 'first', 'candidate', 'face', 'region', 'binarizing', 'enhance', 'skip', 'probability', 'map', 'overlay', 'binarized', 'enhanced', 'skip', 'probability', 'map', 'least', 'portion', 'video', 'frame', 'provide', 'free', 'form', 'shape', 'face', 'region', 'non-transitory', 'machine', 'readable', 'medium', 'claim', 'wherein', 'second', 'video', 'frame', 'comprise', 'non-key', 'frame', 'video', 'sequence', 'machine', 'readable', 'medium', 'comprise', 'instruction', 'response', 'execute', 'device', 'cause', 'device', 'perform', 'video', 'cod', 'base', 'face', 'detection', 'perform', 'face', 'detection', 'second', 'video', 'frame', 'video', 'sequence', 'base', 'free', 'form', 'shape', 'face', 'region', 'non-transitory', 'machine', 'readable', 'medium', 'claim', 'machine', 'readable', 'medium', 'comprise', 'instruction', 'response', 'execute', 'device', 'cause', 'device', 'perform', 'video', 'cod', 'base', 'face', 'detection', 'track', 'second', 'free', 'form', 'shape', 'face', 'region', 'second', 'video', 'frame', 'base', 'free', 'form', 'shape', 'face', 'region', 'video', 'frame', 'non-transitory', 'machine', 'readable', 'medium', 'claim', 'wherein', 'encode', 'video', 'frame', 'base', 'least', 'part', 'first', 'candidate', 'face', 'region', 'valid', 'face', 'region', 'comprise', 'least', 'one', 'reduce', 'quantization', 'parameter', 'correspond', 'first', 'candidate', 'face', 'region', 'adjust', 'lambda', 'value', 'first', 'candidate', 'face', 'region', 'disable', 'skip', 'cod', 'first', 'candidate', 'face', 'region', 'method', 'manage', 'smart', 'database', 'store', 'facial', 'image', 'face', 'recognition', 'comprise', 'step', 'manage', 'device', 'perform', 'process', 'count', 'one', 'specific', 'facial', 'image', 'correspond', 'least', 'one', 'specific', 'person', 'store', 'smart', 'database', 'new', 'facial', 'image', 'face', 'recognition', 'continuously', 'store', 'process', 'determine', 'whether', 'first', 'count', 'value', 'represent', 'count', 'specific', 'facial', 'image', 'satisfies', 'preset', 'first', 'set', 'value', 'b', 'first', 'count', 'value', 'determine', 'satisfy', 'first', 'set', 'value', 'manage', 'device', 'perform', 'process', 'inputting', 'specific', 'facial', 'image', 'neural', 'aggregation', 'network', 'thereby', 'allow', 'neural', 'aggregation', 'network', 'generate', 'quality', 'score', 'specific', 'facial', 'image', 'aggregation', 'specific', 'facial', 'image', 'process', 'sort', 'quality', 'score', 'correspond', 'specific', 'facial', 'image', 'descend', 'order', 'quality', 'score', 'process', 'counting', 'sort', 'specific', 'facial', 'image', 'descend', 'order', 'second', 'count', 'value', 'represent', 'number', 'count', 'part', 'specific', 'facial', 'image', 'become', 'equal', 'preset', 'second', 'set', 'value', 'process', 'delete', 'uncounted', 'part', 'specific', 'facial', 'image', 'smart', 'database', 'method', 'claim', 'comprise', 'step', 'c', 'manage', 'device', 'perform', 'process', 'generate', 'least', 'one', 'optimal', 'feature', 'weight', 'summation', 'one', 'feature', 'specific', 'facial', 'image', 'use', 'counted', 'part', 'quality', 'score', 'process', 'set', 'optimal', 'feature', 'representative', 'face', 'correspond', 'specific', 'person', 'method', 'claim', 'wherein', 'step', 'b', 'manage', 'device', 'performs', 'process', 'inputting', 'specific', 'facial', 'image', 'cnn', 'neural', 'aggregation', 'network', 'thereby', 'allow', 'cnn', 'generate', 'one', 'feature', 'correspond', 'specific', 'facial', 'image', 'process', 'inputting', 'least', 'one', 'feature', 'vector', 'feature', 'embed', 'aggregation', 'module', 'include', 'least', 'two', 'attention', 'block', 'thereby', 'allow', 'aggregation', 'module', 'generate', 'quality', 'score', 'feature', 'method', 'claim', 'wherein', 'step', 'b', 'manage', 'device', 'performs', 'process', 'match', 'i-', 'one', 'feature', 'correspond', 'specific', 'facial', 'image', 'store', 'smart', 'database', 'i-', 'quality', 'score', 'ii', 'specific', 'person', 'process', 'store', 'match', 'feature', 'match', 'quality', 'score', 'smart', 'database', 'method', 'claim', 'comprise', 'step', 'manage', 'device', 'perform', 'one', 'process', 'learn', 'face', 'recognition', 'system', 'use', 'specific', 'facial', 'image', 'correspond', 'specific', 'person', 'store', 'smart', 'database', 'ii', 'process', 'transmit', 'specific', 'facial', 'image', 'correspond', 'specific', 'person', 'learning', 'device', 'correspond', 'face', 'recognition', 'system', 'thereby', 'allow', 'learn', 'device', 'learn', 'face', 'recognition', 'system', 'use', 'specific', 'facial', 'image', 'method', 'claim', 'wherein', 'neural', 'aggregation', 'network', 'learn', 'learning', 'device', 'repeat', 'process', 'inputting', 'multiple', 'facial', 'image', 'train', 'corresponding', 'image', 'set', 'single', 'face', 'video', 'single', 'face', 'cnn', 'neural', 'aggregation', 'network', 'thereby', 'allow', 'cnn', 'generate', 'one', 'feature', 'train', 'apply', 'least', 'one', 'convolution', 'operation', 'facial', 'image', 'train', 'ii', 'process', 'inputting', 'least', 'one', 'feature', 'vector', 'training', 'feature', 'train', 'embedded', 'aggregation', 'module', 'include', 'least', 'two', 'attention', 'block', 'neural', 'aggregation', 'network', 'thereby', 'allow', 'aggregation', 'module', 'generate', 'quality', 'score', 'train', 'feature', 'train', 'aggregation', 'feature', 'train', 'use', 'one', 'attention', 'parameter', 'learn', 'previous', 'iteration', 'iii', 'process', 'output', 'least', 'one', 'optimal', 'feature', 'training', 'weighted', 'summation', 'feature', 'train', 'use', 'quality', 'score', 'train', 'iv', 'process', 'update', 'attention', 'parameter', 'learn', 'previous', 'iteration', 'least', 'two', 'attention', 'block', 'one', 'loss', 'minimize', 'outputted', 'loss', 'layer', 'refer', 'optimal', 'feature', 'train', 'correspond', 'ground', 'truth', 'manage', 'device', 'manage', 'smart', 'database', 'store', 'facial', 'image', 'face', 'recognition', 'comprise', 'least', 'one', 'memory', 'store', 'instruction', 'least', 'one', 'processor', 'configure', 'execute', 'instruction', 'perform', 'support', 'another', 'device', 'perform', 'process', 'count', 'one', 'specific', 'facial', 'image', 'correspond', 'least', 'one', 'specific', 'person', 'store', 'smart', 'database', 'new', 'facial', 'image', 'face', 'recognition', 'continuously', 'store', 'process', 'determine', 'whether', 'first', 'count', 'value', 'represent', 'count', 'specific', 'facial', 'image', 'satisfies', 'preset', 'first', 'set', 'value', 'ii', 'first', 'count', 'value', 'determine', 'satisfy', 'first', 'set', 'value', 'process', 'inputting', 'specific', 'facial', 'image', 'neural', 'aggregation', 'network', 'thereby', 'allow', 'neural', 'aggregation', 'network', 'generate', 'quality', 'score', 'specific', 'facial', 'image', 'aggregation', 'specific', 'facial', 'image', 'process', 'sort', 'quality', 'score', 'correspond', 'specific', 'facial', 'image', 'descend', 'order', 'quality', 'score', 'process', 'counting', 'sort', 'specific', 'facial', 'image', 'descend', 'order', 'second', 'count', 'value', 'represent', 'number', 'count', 'part', 'specific', 'facial', 'image', 'become', 'equal', 'preset', 'second', 'set', 'value', 'process', 'delete', 'uncounted', 'part', 'specific', 'facial', 'image', 'smart', 'database', 'manage', 'device', 'claim', 'wherein', 'processor', 'performs', 'iii', 'process', 'generate', 'least', 'one', 'optimal', 'feature', 'weight', 'summation', 'one', 'feature', 'specific', 'facial', 'image', 'use', 'counted', 'part', 'quality', 'score', 'process', 'set', 'optimal', 'feature', 'representative', 'face', 'correspond', 'specific', 'person', 'manage', 'device', 'claim', 'wherein', 'process', 'ii', 'processor', 'performs', 'process', 'inputting', 'specific', 'facial', 'image', 'cnn', 'neural', 'aggregation', 'network', 'thereby', 'allow', 'cnn', 'generate', 'one', 'feature', 'correspond', 'specific', 'facial', 'image', 'process', 'inputting', 'least', 'one', 'feature', 'vector', 'feature', 'embed', 'aggregation', 'module', 'include', 'least', 'two', 'attention', 'block', 'thereby', 'allow', 'aggregation', 'module', 'generate', 'quality', 'score', 'feature', 'manage', 'device', 'claim', 'wherein', 'process', 'ii', 'processor', 'performs', 'process', 'match', 'i-', 'one', 'feature', 'correspond', 'specific', 'facial', 'image', 'store', 'smart', 'database', 'i-', 'quality', 'score', 'ii', 'specific', 'person', 'process', 'store', 'match', 'feature', 'match', 'quality', 'score', 'smart', 'database', 'manage', 'device', 'claim', 'wherein', 'processor', 'performs', 'iv', 'one', 'process', 'learn', 'face', 'recognition', 'system', 'use', 'specific', 'facial', 'image', 'correspond', 'specific', 'person', 'store', 'smart', 'database', 'ii', 'process', 'transmit', 'specific', 'facial', 'image', 'correspond', 'specific', 'person', 'learning', 'device', 'correspond', 'face', 'recognition', 'system', 'thereby', 'allow', 'learn', 'device', 'learn', 'face', 'recognition', 'system', 'use', 'specific', 'facial', 'image', 'manage', 'device', 'claim', 'wherein', 'neural', 'aggregation', 'network', 'learn', 'learning', 'device', 'repeat', 'process', 'inputting', 'multiple', 'facial', 'image', 'train', 'corresponding', 'image', 'set', 'single', 'face', 'video', 'single', 'face', 'cnn', 'neural', 'aggregation', 'network', 'thereby', 'allow', 'cnn', 'generate', 'one', 'feature', 'train', 'apply', 'least', 'one', 'convolution', 'operation', 'facial', 'image', 'train', 'ii', 'process', 'inputting', 'least', 'one', 'feature', 'vector', 'training', 'feature', 'train', 'embedded', 'aggregation', 'module', 'include', 'least', 'two', 'attention', 'block', 'neural', 'aggregation', 'network', 'thereby', 'allow', 'aggregation', 'module', 'generate', 'quality', 'score', 'train', 'feature', 'train', 'aggregation', 'feature', 'train', 'use', 'one', 'attention', 'parameter', 'learn', 'previous', 'iteration', 'iii', 'process', 'output', 'least', 'one', 'optimal', 'feature', 'training', 'weighted', 'summation', 'feature', 'train', 'use', 'quality', 'score', 'train', 'iv', 'process', 'update', 'attention', 'parameter', 'learn', 'previous', 'iteration', 'least', 'two', 'attention', 'block', 'one', 'loss', 'minimize', 'outputted', 'loss', 'layer', 'refer', 'optimal', 'feature', 'train', 'correspond', 'ground', 'truth', 'object', 'data', 'process', 'system', 'comprise', 'least', 'one', 'processor', 'configure', 'execute', 'least', 'one', 'implementation', 'plurality', 'recognition', 'algorithms', 'store', 'least', 'one', 'non-transitory', 'computer-readable', 'storage', 'medium', 'recognition', 'algorithm', 'feature', 'density', 'selection', 'criterion', 'data', 'preprocessing', 'code', 'execute', 'least', 'one', 'processor', 'data', 'preprocessing', 'code', 'comprise', 'invariant', 'feature', 'identification', 'algorithm', 'configure', 'obtain', 'digital', 'representation', 'scene', 'scene', 'comprise', 'one', 'textual', 'medium', 'generate', 'set', 'invariant', 'feature', 'apply', 'invariant', 'feature', 'identification', 'algorithm', 'digital', 'representation', 'cluster', 'set', 'invariant', 'feature', 'region', 'interest', 'digital', 'representation', 'scene', 'region', 'interest', 'region', 'feature', 'density', 'classify', 'region', 'classifier', 'code', 'least', 'one', 'region', 'interest', 'accord', 'object', 'type', 'function', 'attribute', 'derived', 'region', 'feature', 'density', 'digital', 'representation', 'wherein', 'least', 'one', 'classified', 'region', 'interest', 'corresponds', 'text', 'use', 'classification', 'result', 'correspond', 'least', 'one', 'region', 'interest', 'classify', 'another', 'region', 'interest', 'accord', 'object', 'type', 'wherein', 'another', 'region', 'interest', 'correspond', 'region', 'interest', 'image', 'system', 'claim', 'wherein', 'preprocessing', 'code', 'base', 'feature', 'density', 'selection', 'criterion', 'determine', 'ocr', 'algorithm', 'applicable', 'text', 'recognition', 'algorithm', 'applicable', 'aspect', 'photograph', 'logos', 'system', 'claim', 'wherein', 'user', 'creates', 'user', 'profile', 'camera-equipped', 'smartphone', 'include', 'information', 'user', 'visually', 'impaired', 'cause', 'prioritized', 'execution', 'ocr', 'algorithm', 'text', 'reader', 'program', 'begin', 'read', 'text', 'user', 'quickly', 'possible', 'system', 'claim', 'comprise', 'audio', 'tactile', 'feedback', 'mechanism', 'help', 'user', 'position', 'smart', 'phone', 'relative', 'text', 'system', 'claim', 'comprise', '``', 'hold', 'still', \"''\", 'audio', 'feedback', 'signal', 'send', 'user', 'text', 'center', 'capture', 'scene', 'system', 'claim', 'wherein', 'digital', 'representation', 'comprises', 'least', 'one', 'follow', 'type', 'digital', 'data', 'image', 'data', 'video', 'data', 'audio', 'data', 'system', 'claim', 'wherein', 'invariant', 'feature', 'identification', 'algorithm', 'comprise', 'least', 'one', 'follow', 'feature', 'identification', 'algorithm', 'fast', 'sift', 'freak', 'brisk', 'harris', 'daisy', 'mser', 'system', 'claim', 'wherein', 'invariant', 'feature', 'identification', 'algorithm', 'include', 'least', 'one', 'follow', 'edge', 'detection', 'algorithm', 'corner', 'detection', 'algorithm', 'saliency', 'map', 'algorithm', 'curve', 'detection', 'algorithm', 'texton', 'identification', 'algorithm', 'wavelet', 'algorithm', 'system', 'claim', 'wherein', 'least', 'one', 'region', 'interest', 'represent', 'least', 'one', 'physical', 'object', 'scene', 'system', 'claim', 'wherein', 'least', 'one', 'region', 'interest', 'represent', 'least', 'one', 'textual', 'medium', 'scene', 'system', 'claim', 'wherein', 'region', 'interest', 'represent', 'document', 'textual', 'medium', 'system', 'claim', 'wherein', 'region', 'interest', 'represent', 'financial', 'document', 'system', 'claim', 'wherein', 'region', 'interest', 'represent', 'structure', 'document', 'system', 'claim', 'wherein', 'least', 'one', 'implementation', 'plurality', 'recognition', 'algorithms', 'include', 'least', 'one', 'follow', 'template', 'drive', 'algorithm', 'face', 'recognition', 'algorithm', 'optical', 'character', 'recognition', 'algorithm', 'speech', 'recognition', 'algorithm', 'object', 'recognition', 'algorithm', 'system', 'claim', 'wherein', 'data', 'preprocessing', 'code', 'configure', 'assign', 'region', 'interest', 'least', 'one', 'recognition', 'algorithm', 'function', 'scene', 'context', 'derive', 'digital', 'representation', 'system', 'claim', 'wherein', 'scene', 'context', 'include', 'least', 'one', 'follow', 'type', 'data', 'location', 'position', 'time', 'user', 'identity', 'news', 'event', 'medical', 'event', 'promotion', 'system', 'claim', 'comprise', 'mobile', 'device', 'comprise', 'least', 'one', 'implementation', 'plurality', 'recognition', 'algorithm', 'data', 'preprocessing', 'code', 'system', 'claim', 'wherein', 'mobile', 'device', 'comprises', 'least', 'one', 'follow', 'smart', 'phone', 'tablet', 'wearable', 'glass', 'toy', 'vehicle', 'computer', 'phablet', 'system', 'claim', 'comprise', 'network-accessible', 'server', 'device', 'comprise', 'least', 'one', 'implementation', 'plurality', 'recognition', 'algorithm', 'data', 'preprocessing', 'code', 'system', 'claim', 'wherein', 'object', 'type', 'include', 'least', 'one', 'follow', 'face', 'animal', 'vehicle', 'document', 'plant', 'building', 'appliance', 'clothing', 'body', 'part', 'toy', 'object', 'data', 'processing', 'system', 'comprise', 'least', 'one', 'processor', 'configure', 'execute', 'least', 'one', 'implementation', 'plurality', 'recognition', 'algorithms', 'store', 'least', 'one', 'non-transitory', 'computer-readable', 'storage', 'medium', 'recognition', 'algorithm', 'feature', 'density', 'selection', 'criterion', 'data', 'preprocessing', 'code', 'execute', 'least', 'one', 'processor', 'data', 'preprocessing', 'code', 'comprise', 'invariant', 'feature', 'identification', 'algorithm', 'configure', 'obtain', 'digital', 'representation', 'scene', 'scene', 'comprise', 'one', 'textual', 'medium', 'generate', 'set', 'invariant', 'feature', 'apply', 'invariant', 'feature', 'identification', 'algorithm', 'digital', 'representation', 'cluster', 'set', 'invariant', 'feature', 'region', 'interest', 'digital', 'representation', 'scene', 'region', 'interest', 'region', 'feature', 'density', 'classify', 'region', 'classifier', 'code', 'least', 'one', 'region', 'interest', 'accord', 'object', 'type', 'function', 'attribute', 'derived', 'region', 'feature', 'density', 'digital', 'representation', 'wherein', 'least', 'one', 'classified', 'region', 'interest', 'corresponds', 'text', 'use', 'classification', 'result', 'correspond', 'least', 'one', 'region', 'interest', 'classify', 'another', 'region', 'interest', 'accord', 'object', 'type', 'wherein', 'another', 'region', 'interest', 'correspond', 'region', 'interest', 'image', 'assign', 'region', 'interest', 'least', 'one', 'recognition', 'algorithm', 'least', 'one', 'implementation', 'plurality', 'diverse', 'recognition', 'algorithm', 'function', 'region', 'feature', 'density', 'region', 'interest', 'feature', 'density', 'selection', 'criterion', 'least', 'one', 'implementation', 'plurality', 'diverse', 'recognition', 'algorithm', 'configure', 'assign', 'recognition', 'algorithm', 'process', 'respective', 'region', 'interest', 'wherein', 'preprocessing', 'code', 'base', 'feature', 'density', 'selection', 'criterion', 'determine', 'ocr', 'algorithm', 'applicable', 'text', 'recognition', 'algorithm', 'applicable', 'aspect', 'photograph', 'logos', 'device', 'comprise', 'least', 'one', 'processor', 'configure', 'execute', 'least', 'one', 'implementation', 'plurality', 'recognition', 'algorithms', 'store', 'least', 'one', 'non-transitory', 'computer-readable', 'storage', 'medium', 'recognition', 'algorithm', 'feature', 'density', 'selection', 'criterion', 'data', 'preprocessing', 'code', 'execute', 'least', 'one', 'processor', 'data', 'preprocessing', 'code', 'comprise', 'invariant', 'feature', 'identification', 'algorithm', 'configure', 'obtain', 'digital', 'representation', 'scene', 'scene', 'comprise', 'one', 'textual', 'medium', 'generate', 'set', 'invariant', 'feature', 'apply', 'invariant', 'feature', 'identification', 'algorithm', 'digital', 'representation', 'cluster', 'set', 'invariant', 'feature', 'region', 'interest', 'digital', 'representation', 'scene', 'region', 'interest', 'region', 'feature', 'density', 'classify', 'region', 'classifier', 'code', 'least', 'one', 'region', 'interest', 'accord', 'object', 'type', 'function', 'attribute', 'derived', 'region', 'feature', 'density', 'digital', 'representation', 'wherein', 'least', 'one', 'classified', 'region', 'interest', 'corresponds', 'text', 'use', 'classification', 'result', 'correspond', 'least', 'one', 'region', 'interest', 'classify', 'another', 'region', 'interest', 'accord', 'object', 'type', 'wherein', 'another', 'region', 'interest', 'correspond', 'region', 'interest', 'image', 'mobile', 'terminal', 'comprising', 'front', 'camera', 'configure', 'obtain', 'two-dimensional', 'face', 'image', 'user', 'glance', 'sensor', 'tilt', 'certain', 'angle', 'dispose', 'adjacent', 'front', 'camera', 'obtain', 'metadata', 'face', 'image', 'controller', 'obtain', 'distance', 'glance', 'sensor', 'front', 'camera', 'distance', 'enable', 'area', 'overlap', 'region', 'first', 'region', 'represent', 'range', 'photographable', 'front', 'camera', 'overlap', 'second', 'region', 'represent', 'range', 'photographable', 'glance', 'sensor', 'maximum', 'mobile', 'terminal', 'claim', 'wherein', 'controller', 'configure', 'obtain', 'distance', 'enable', 'area', 'overlap', 'region', 'maximum', 'glance', 'sensor', 'front', 'camera', 'vary', 'tilt', 'angle', 'glance', 'sensor', 'mobile', 'terminal', 'claim', 'wherein', 'controller', 'configure', 'set', 'distance', 'enable', 'area', 'overlap', 'region', 'maximum', 'glance', 'sensor', 'front', 'camera', 'tilt', 'angle', 'glance', 'sensor', 'optimal', 'disposition', 'location', 'glance', 'sensor', 'mobile', 'terminal', 'claim', 'wherein', 'controller', 'configure', 'set', 'disposition', 'location', 'front', 'camera', 'original', 'point', 'calculates', 'coordinate', 'first', 'triangle', 'represent', 'first', 'region', 'base', 'field', 'view', 'front', 'camera', 'maximum', 'photograph', 'distance', 'front', 'camera', 'mobile', 'terminal', 'claim', 'wherein', 'controller', 'configure', 'calculate', 'coordinate', 'second', 'triangle', 'represent', 'second', 'region', 'base', 'field', 'view', 'glance', 'sensor', 'maximum', 'photograph', 'distance', 'glance', 'sensor', 'distance', 'front', 'camera', 'glance', 'sensor', 'tilt', 'angle', 'glance', 'sensor', 'mobile', 'terminal', 'claim', 'wherein', 'glance', 'sensor', 'tilt', 'controller', 'configured', 'calculate', 'coordinate', 'third', 'triangle', 'represent', 'third', 'region', 'photographable', 'glance', 'sensor', 'controller', 'configure', 'rotation-convert', 'coordinate', 'third', 'triangle', 'base', 'tilt', 'angle', 'glance', 'sensor', 'calculate', 'coordinate', 'second', 'triangle', 'mobile', 'terminal', 'claim', 'wherein', 'controller', 'configure', 'calculate', 'coordinate', 'overlap', 'region', 'base', 'coordinate', 'first', 'triangle', 'coordinate', 'second', 'triangle', 'calculates', 'area', 'overlap', 'region', 'base', 'coordinate', 'overlap', 'region', 'mobile', 'terminal', 'claim', 'wherein', 'controller', 'configure', 'generate', 'three-dimensional', 'face', 'information', 'base', 'face', 'image', 'obtain', 'front', 'camera', 'metadata', 'obtain', 'glance', 'sensor', 'mobile', 'terminal', 'claim', 'wherein', 'metadata', 'comprise', 'one', 'angle', 'face', 'user', 'size', 'face', 'location', 'face', 'mobile', 'terminal', 'claim', 'wherein', 'angle', 'face', 'comprises', 'angle', 'face', 'rotate', 'one', 'pitch', 'axis', 'roll', 'axis', 'yaw', 'axis', 'mobile', 'terminal', 'claim', 'comprise', 'memory', 'store', 'generate', 'face', 'information', 'wherein', 'controller', 'configure', 'performs', 'user', 'authentication', 'process', 'compare', 'store', 'face', 'information', 'face', 'information', 'obtain', 'user', 'authentication', 'mobile', 'terminal', 'claim', 'wherein', 'glance', 'sensor', 'control', 'permanently', 'activate', 'low', 'power', 'obtain', 'front', 'image', 'metadata', 'front', 'image', 'mobile', 'terminal', 'claim', 'wherein', 'front', 'camera', 'glance', 'sensor', 'dispose', 'line', 'upper', 'end', 'mobile', 'terminal', 'mobile', 'terminal', 'claim', 'wherein', 'glance', 'sensor', 'tilt', 'one', 'direction', 'direction', 'direction', 'leave', 'direction', 'right', 'direction', 'mobile', 'terminal', 'claim', 'wherein', 'metadata', 'data', 'change', 'mobile', 'terminal', 'tilt', 'external', 'physical', 'force', 'method', 'comprise', 'receive', 'smart', 'television', 'tv', 'indication', 'upcoming', 'medium', 'program', 'wherein', 'upcoming', 'medium', 'program', 'base', 'user', 'profile', 'identify', 'one', 'device', 'communication', 'smart', 'tv', 'one', 'device', 'include', 'least', 'one', 'microphone', 'camera', 'instruct', 'least', 'one', 'identified', 'device', 'detect', 'audio', 'signal', 'use', 'respective', 'microphone', 'detect', 'visual', 'signal', 'use', 'respective', 'camera', 'select', 'least', 'one', 'device', 'one', 'device', 'base', 'detected', 'audio', 'signal', 'detect', 'visual', 'signal', 'provide', 'instruction', 'select', 'device', 'output', 'notification', 'relate', 'upcoming', 'medium', 'program', 'method', 'claim', 'wherein', 'upcoming', 'medium', 'program', 'one', 'live', 'television', 'program', 'record', 'television', 'program', 'broadcast', 'television', 'program', 'application-provided', 'program', 'method', 'claim', 'wherein', 'select', 'first', 'device', 'base', 'detected', 'audio', 'signal', 'include', 'recognize', 'voice', 'method', 'claim', 'comprise', 'determine', 'distance', 'recognize', 'voice', 'wherein', 'select', 'first', 'device', 'base', 'determined', 'distance', 'method', 'claim', 'wherein', 'select', 'first', 'device', 'base', 'detect', 'visual', 'signal', 'include', 'recognize', 'face', 'method', 'claim', 'wherein', 'recognize', 'face', 'include', 'face', 'recognition', 'technique', 'method', 'claim', 'comprise', 'present', 'smart', 'tv', 'upcoming', 'medium', 'program', 'favorite', 'channel', 'list', 'method', 'claim', 'comprise', 'obtain', 'medium', 'program', 'view', 'data', 'wherein', 'medium', 'program', 'view', 'data', 'include', 'least', 'one', 'historical', 'time', 'historical', 'date', 'one', 'medium', 'program', 'view', 'obtain', 'least', 'one', 'current', 'time', 'current', 'date', 'processing', 'medium', 'program', 'view', 'data', 'determine', 'probability', 'one', 'medium', 'program', 'view', 'base', 'least', 'one', 'current', 'time', 'current', 'date', 'presenting', 'favorite', 'channel', 'list', 'base', 'determined', 'probability', 'one', 'medium', 'program', 'view', 'method', 'claim', 'wherein', 'process', 'medium', 'program', 'view', 'data', 'include', 'employ', 'neural', 'network', 'model', 'method', 'claim', 'wherein', 'employ', 'neural', 'network', 'model', 'comprise', 'determine', 'duration', 'one', 'medium', 'program', 'view', 'least', 'one', 'historical', 'time', 'historical', 'date', 'set', 'threshold', 'time', 'duration', 'compare', 'determine', 'duration', 'threshold', 'time', 'duration', 'filter', 'one', 'medium', 'program', 'view', 'threshold', 'time', 'duration', 'smart', 'television', 'tv', 'comprise', 'network', 'interface', 'non-transitory', 'computer-readable', 'medium', 'processor', 'communication', 'network', 'interface', 'non-transitory', 'computer-readable', 'medium', 'capable', 'execute', 'processor-executable', 'program', 'code', 'store', 'non-transitory', 'computer-readable', 'medium', 'cause', 'smart', 'tv', 'receive', 'indication', 'upcoming', 'medium', 'program', 'wherein', 'upcoming', 'medium', 'program', 'base', 'user', 'profile', 'identify', 'one', 'device', 'communication', 'smart', 'tv', 'one', 'device', 'include', 'least', 'one', 'microphone', 'camera', 'instruct', 'least', 'one', 'identified', 'device', 'detect', 'audio', 'signal', 'use', 'respective', 'microphone', 'detect', 'visual', 'signal', 'use', 'respective', 'camera', 'select', 'least', 'one', 'device', 'one', 'device', 'base', 'detected', 'audio', 'signal', 'detect', 'visual', 'signal', 'provide', 'instruction', 'select', 'device', 'output', 'notification', 'relate', 'upcoming', 'medium', 'program', 'smart', 'tv', 'claim', 'wherein', 'select', 'first', 'device', 'base', 'detected', 'audio', 'signal', 'include', 'recognize', 'voice', 'smart', 'tv', 'claim', 'wherein', 'processor', 'capable', 'execute', 'processor-executable', 'program', 'code', 'determine', 'distance', 'recognize', 'voice', 'wherein', 'select', 'first', 'device', 'base', 'determined', 'distance', 'smart', 'tv', 'claim', 'wherein', 'select', 'first', 'device', 'base', 'detect', 'visual', 'signal', 'include', 'detect', 'presence', 'user', 'smart', 'tv', 'claim', 'wherein', 'detect', 'presence', 'user', 'include', 'employ', 'one', 'camera', 'microphone', 'fingerprint', 'sensor', 'associate', 'least', 'one', 'smart', 'tv', 'mobile', 'device', 'smartphone', 'laptop', 'computer', 'tablet', 'device', 'wearable', 'device', 'internet', 'thing', 'iot', 'device', 'internet', 'everything', 'ioe', 'device', 'iot', 'hub', 'ioe', 'hub', 'smart', 'television', 'tv', 'comprising', 'mean', 'receive', 'indication', 'upcoming', 'medium', 'program', 'wherein', 'upcoming', 'medium', 'program', 'base', 'user', 'profile', 'mean', 'identify', 'one', 'device', 'communication', 'smart', 'tv', 'one', 'device', 'include', 'least', 'one', 'microphone', 'camera', 'mean', 'instruct', 'least', 'one', 'identified', 'device', 'detect', 'audio', 'signal', 'use', 'respective', 'microphone', 'detect', 'visual', 'signal', 'use', 'respective', 'camera', 'mean', 'select', 'least', 'one', 'device', 'one', 'device', 'base', 'detected', 'audio', 'signal', 'detect', 'visual', 'signal', 'mean', 'provide', 'instruction', 'select', 'device', 'output', 'notification', 'relate', 'upcoming', 'medium', 'program', 'smart', 'tv', 'claim', 'wherein', 'one', 'device', 'include', 'least', 'one', 'mobile', 'device', 'smartphone', 'laptop', 'computer', 'tablet', 'device', 'wearable', 'device', 'internet', 'thing', 'iot', 'device', 'internet', 'everything', 'ioe', 'device', 'iot', 'hub', 'ioe', 'hub', 'another', 'smart', 'tv', 'smart', 'tv', 'claim', 'wherein', 'upcoming', 'medium', 'program', 'one', 'live', 'television', 'program', 'record', 'television', 'program', 'broadcast', 'television', 'program', 'application-provided', 'program', 'smart', 'tv', 'claim', 'wherein', 'notification', 'include', 'least', 'one', 'push', 'message', 'sms', 'message', 'waysms', 'message', 'audio', 'alert', 'audio', 'message', 'email', 'message', 'smart', 'tv', 'claim', 'comprise', 'present', 'upcoming', 'medium', 'program', 'favorite', 'channel', 'list', 'smart', 'tv', 'claim', 'comprise', 'mean', 'obtain', 'medium', 'program', 'view', 'data', 'wherein', 'medium', 'program', 'view', 'data', 'include', 'least', 'one', 'historical', 'time', 'historical', 'date', 'one', 'medium', 'program', 'view', 'smart', 'tv', 'mean', 'obtain', 'least', 'one', 'current', 'time', 'current', 'date', 'mean', 'process', 'medium', 'program', 'view', 'data', 'determine', 'probability', 'one', 'medium', 'program', 'view', 'smart', 'tv', 'base', 'least', 'one', 'current', 'time', 'current', 'date', 'mean', 'present', 'favorite', 'channel', 'list', 'base', 'determined', 'probability', 'one', 'medium', 'program', 'view', 'smart', 'tv', 'claim', 'wherein', 'mean', 'process', 'medium', 'program', 'view', 'data', 'include', 'employ', 'neural', 'network', 'model', 'smart', 'tv', 'claim', 'wherein', 'employ', 'neural', 'network', 'model', 'comprise', 'determine', 'duration', 'one', 'medium', 'program', 'view', 'smart', 'tv', 'least', 'one', 'historical', 'time', 'historical', 'date', 'set', 'threshold', 'time', 'duration', 'compare', 'determine', 'duration', 'threshold', 'time', 'duration', 'filter', 'one', 'medium', 'program', 'view', 'threshold', 'time', 'duration', 'smart', 'tv', 'claim', 'comprising', 'mean', 'adjust', 'least', 'one', 'volume', 'brightness', 'smart', 'tv', 'wherein', 'adjust', 'base', 'least', 'one', 'historical', 'time', 'historical', 'date', 'smart', 'tv', 'claim', 'comprise', 'mean', 'restrict', 'access', 'one', 'medium', 'program', 'non-transitory', 'computer-readable', 'medium', 'comprise', 'processor-executable', 'program', 'code', 'configure', 'cause', 'processor', 'smart', 'television', 'tv', 'receive', 'indication', 'upcoming', 'medium', 'program', 'wherein', 'upcoming', 'medium', 'program', 'base', 'user', 'profile', 'identify', 'one', 'device', 'communication', 'smart', 'tv', 'one', 'device', 'include', 'least', 'one', 'microphone', 'camera', 'instruct', 'least', 'one', 'identified', 'device', 'detect', 'audio', 'signal', 'use', 'respective', 'microphone', 'detect', 'visual', 'signal', 'use', 'respective', 'camera', 'select', 'least', 'one', 'device', 'one', 'device', 'base', 'detected', 'audio', 'signal', 'detect', 'visual', 'signal', 'provide', 'instruction', 'select', 'device', 'output', 'notification', 'relate', 'upcoming', 'medium', 'program', 'non-transitory', 'computer-readable', 'medium', 'claim', 'wherein', 'select', 'first', 'device', 'base', 'detected', 'audio', 'signal', 'include', 'recognize', 'voice', 'non-transitory', 'computer-readable', 'medium', 'claim', 'wherein', 'processor', 'capable', 'execute', 'processor-executable', 'program', 'code', 'determine', 'distance', 'recognize', 'voice', 'wherein', 'select', 'first', 'device', 'base', 'determined', 'distance', 'non-transitory', 'computer-readable', 'medium', 'claim', 'wherein', 'select', 'first', 'device', 'base', 'detect', 'visual', 'signal', 'include', 'recognize', 'face', 'non-transitory', 'computer-readable', 'medium', 'claim', 'wherein', 'recognize', 'face', 'include', 'face', 'recognition', 'technique', 'camera', 'comprise', 'sensor', 'array', 'include', 'plurality', 'sensor', 'infrared', 'ir', 'illuminator', 'configure', 'emit', 'active', 'ir', 'light', 'ir', 'light', 'sub-band', 'plurality', 'spectral', 'illuminators', 'spectral', 'illuminator', 'configure', 'emit', 'active', 'spectral', 'light', 'different', 'spectral', 'light', 'sub-band', 'depth', 'controller', 'machine', 'configure', 'determine', 'depth', 'value', 'plurality', 'sensor', 'base', 'active', 'ir', 'light', 'spectral', 'controller', 'machine', 'configure', 'plurality', 'sensor', 'determine', 'spectral', 'value', 'spectral', 'light', 'sub-band', 'plurality', 'spectral', 'illuminators', 'output', 'machine', 'configure', 'output', 'test', 'depth+multi-spectral', 'image', 'include', 'plurality', 'pixel', 'pixel', 'correspond', 'one', 'plurality', 'sensor', 'sensor', 'array', 'include', 'least', 'depth', 'value', 'spectral', 'value', 'spectral', 'light', 'sub-band', 'plurality', 'spectral', 'illuminators', 'face', 'recognition', 'machine', 'previously', 'train', 'set', 'labeled', 'training', 'depth+multi-spectral', 'image', 'structure', 'test', 'depth+multi-spectral', 'image', 'face', 'recognition', 'machine', 'configure', 'output', 'confidence', 'value', 'indicate', 'likelihood', 'test', 'depth+multi-spectral', 'image', 'include', 'face', 'camera', 'claim', 'wherein', 'spectral', 'value', 'calculate', 'base', 'depth', 'value', 'determine', 'sensor', 'corresponds', 'pixel', 'camera', 'claim', 'wherein', 'face', 'recognition', 'machine', 'configure', 'use', 'convolutional', 'neural', 'network', 'determine', 'confidence', 'value', 'camera', 'claim', 'wherein', 'face', 'recognition', 'machine', 'include', 'plurality', 'input', 'node', 'wherein', 'input', 'node', 'configure', 'receive', 'pixel', 'value', 'array', 'correspond', 'different', 'pixel', 'plurality', 'pixel', 'test', 'depth+multi-spectral', 'image', 'wherein', 'pixel', 'value', 'array', 'include', 'depth', 'value', 'plurality', 'multi-spectral', 'value', 'pixel', 'camera', 'claim', 'wherein', 'plurality', 'multi-spectral', 'value', 'pixel', 'include', 'three', 'spectral', 'value', 'camera', 'claim', 'wherein', 'output', 'machine', 'configure', 'output', 'surface', 'normal', 'pixel', 'test', 'depth+multi-spectral', 'image', 'wherein', 'pixel', 'value', 'array', 'include', 'surface', 'normal', 'camera', 'claim', 'wherein', 'output', 'machine', 'configure', 'output', 'curvature', 'pixel', 'test', 'depth+multi-spectral', 'image', 'wherein', 'pixel', 'value', 'array', 'include', 'curvature', 'camera', 'claim', 'wherein', 'face', 'recognition', 'machine', 'configure', 'use', 'plurality', 'model', 'determine', 'confidence', 'value', 'wherein', 'plurality', 'model', 'include', 'plurality', 'channel-specific', 'model', 'wherein', 'channel-specific', 'model', 'configure', 'process', 'different', 'pixel', 'parameter', 'plurality', 'pixel', 'test', 'depth+multi-spectral', 'image', 'wherein', 'channel-specific', 'model', 'include', 'plurality', 'input', 'node', 'wherein', 'channel-specific', 'model', 'input', 'node', 'configure', 'receive', 'pixel', 'parameter', 'value', 'different', 'pixel', 'plurality', 'pixel', 'test', 'depth+multi-spectral', 'image', 'camera', 'claim', 'wherein', 'face', 'recognition', 'machine', 'configure', 'use', 'statistical', 'model', 'determine', 'confidence', 'value', 'camera', 'claim', 'wherein', 'statistical', 'model', 'include', 'near', 'neighbor', 'algorithm', 'camera', 'claim', 'wherein', 'statistical', 'model', 'include', 'support', 'vector', 'machine', 'camera', 'claim', 'wherein', 'face', 'recognition', 'machine', 'configure', 'output', 'location', 'test', 'depth+multi-spectral', 'image', 'bound', 'box', 'around', 'recognize', 'face', 'camera', 'claim', 'wherein', 'face', 'recognition', 'machine', 'configure', 'output', 'location', 'test', 'depth+multi-spectral', 'image', 'identify', 'two-dimensional', 'facial', 'feature', 'recognize', 'face', 'camera', 'claim', 'wherein', 'face', 'recognition', 'machine', 'configure', 'output', 'location', 'test', 'depth+multi-spectral', 'image', 'identify', 'three-dimensional', 'facial', 'feature', 'recognize', 'face', 'camera', 'claim', 'wherein', 'face', 'recognition', 'machine', 'configure', 'output', 'location', 'test', 'depth+multi-spectral', 'image', 'identify', 'spectral', 'feature', 'recognize', 'face', 'camera', 'claim', 'wherein', 'face', 'recognition', 'machine', 'configure', 'output', 'pixel', 'test', 'depth+multi-spectral', 'image', 'confidence', 'value', 'indicate', 'likelihood', 'pixel', 'include', 'face', 'camera', 'claim', 'wherein', 'face', 'recognition', 'machine', 'configure', 'output', 'identity', 'face', 'recognize', 'test', 'depth+multi-spectral', 'image', 'camera', 'claim', 'wherein', 'plurality', 'sensor', 'sensor', 'array', 'differential', 'sensor', 'wherein', 'spectral', 'value', 'determine', 'base', 'depth', 'value', 'differential', 'measurement', 'differential', 'sensor', 'camera', 'comprise', 'sensor', 'array', 'include', 'plurality', 'sensor', 'infrared', 'ir', 'illuminator', 'configure', 'emit', 'active', 'ir', 'light', 'ir', 'light', 'sub-band', 'plurality', 'spectral', 'illuminators', 'spectral', 'illuminator', 'configure', 'emit', 'active', 'spectral', 'light', 'different', 'spectral', 'light', 'sub-band', 'depth', 'controller', 'machine', 'configure', 'determine', 'depth', 'value', 'plurality', 'sensor', 'base', 'active', 'ir', 'light', 'spectral', 'controller', 'machine', 'configure', 'plurality', 'sensor', 'determine', 'spectral', 'value', 'spectral', 'light', 'sub-band', 'plurality', 'spectral', 'illuminators', 'wherein', 'spectral', 'value', 'calculate', 'base', 'depth', 'value', 'determine', 'sensor', 'corresponds', 'pixel', 'output', 'machine', 'configure', 'output', 'test', 'depth+multi-spectral', 'image', 'include', 'plurality', 'pixel', 'pixel', 'correspond', 'one', 'plurality', 'sensor', 'sensor', 'array', 'include', 'least', 'depth', 'value', 'spectral', 'value', 'spectral', 'light', 'sub-band', 'plurality', 'spectral', 'illuminators', 'face', 'recognition', 'machine', 'include', 'convolutional', 'neural', 'network', 'previously', 'train', 'set', 'labeled', 'training', 'depth+multi-spectral', 'image', 'structure', 'test', 'depth+multi-spectral', 'image', 'face', 'recognition', 'machine', 'configure', 'output', 'confidence', 'value', 'indicate', 'likelihood', 'test', 'depth+multi-spectral', 'image', 'include', 'face', 'image', 'processing', 'method', 'comprise', 'acquire', 'photo', 'album', 'obtain', 'face', 'cluster', 'collect', 'face', 'information', 'respective', 'image', 'photo', 'album', 'acquire', 'face', 'parameter', 'image', 'accord', 'face', 'information', 'select', 'cover', 'image', 'accord', 'face', 'parameter', 'image', 'take', 'face-region', 'image', 'cover', 'image', 'set', 'face-region', 'image', 'cover', 'photo', 'album', 'wherein', 'select', 'cover', 'image', 'accord', 'face', 'parameter', 'image', 'comprise', 'perform', 'calculation', 'face', 'parameter', 'image', 'preset', 'way', 'obtain', 'cover', 'score', 'image', 'select', 'image', 'high', 'cover', 'score', 'cover', 'image', 'wherein', 'select', 'image', 'high', 'cover', 'score', 'cover', 'image', 'comprise', 'acquire', 'source', 'image', 'select', 'image', 'high', 'cover', 'score', 'image', 'come', 'preset', 'source', 'cover', 'image', 'method', 'accord', 'claim', 'wherein', 'select', 'image', 'high', 'cover', 'score', 'cover', 'image', 'comprise', 'acquire', 'number', 'face', 'contain', 'image', 'determine', 'single-person', 'image', 'accord', 'number', 'face', 'select', 'single-person', 'image', 'high', 'cover', 'score', 'cover', 'image', 'method', 'accord', 'claim', 'wherein', 'select', 'image', 'high', 'cover', 'score', 'cover', 'image', 'comprise', 'single-person', 'image', 'photo', 'album', 'determine', 'image', 'include', 'two', 'face', 'photo', 'album', 'select', 'image', 'high', 'cover', 'score', 'image', 'include', 'two', 'face', 'cover', 'image', 'method', 'accord', 'claim', 'wherein', 'face', 'information', 'comprise', 'face', 'feature', 'point', 'face', 'parameter', 'comprises', 'face', 'turn', 'angle', 'acquire', 'face', 'parameter', 'image', 'accord', 'face', 'information', 'comprise', 'acquire', 'coordinate', 'value', 'face', 'feature', 'point', 'determine', 'distance', 'angle', 'face', 'feature', 'point', 'determine', 'face', 'turn', 'angle', 'accord', 'distance', 'angle', 'method', 'accord', 'claim', 'wherein', 'face', 'parameter', 'comprise', 'face', 'ratio', 'acquire', 'face', 'parameter', 'image', 'accord', 'face', 'information', 'comprise', 'determine', 'face', 'region', 'image', 'accord', 'face', 'information', 'calculate', 'ratio', 'area', 'face', 'region', 'area', 'image', 'obtain', 'face', 'ratio', 'method', 'accord', 'claim', 'wherein', 'calculate', 'face', 'ratio', 'comprise', 'one', 'face', 'image', 'subtract', 'area', 'occupy', 'face', 'face', 'correspond', 'photo', 'album', 'face', 'region', 'obtain', 'remain', 'area', 'calculate', 'ratio', 'remain', 'area', 'area', 'image', 'obtain', 'face', 'ratio', 'method', 'accord', 'claim', 'wherein', 'collect', 'face', 'information', 'respective', 'image', 'photo', 'album', 'comprises', 'acquire', 'image', 'identification', 'image', 'photo', 'album', 'extract', 'face', 'information', 'correspond', 'image', 'identification', 'face', 'database', 'face', 'database', 'store', 'face', 'recognition', 'result', 'image', 'face', 'recognition', 'result', 'include', 'face', 'information', 'image', 'processing', 'apparatus', 'comprise', 'processor', 'memory', 'configure', 'store', 'instruction', 'executable', 'processor', 'wherein', 'processor', 'configure', 'run', 'program', 'corresponding', 'instruction', 'read', 'instruction', 'store', 'memory', 'perform', 'acquire', 'photo', 'album', 'obtain', 'face', 'cluster', 'collect', 'face', 'information', 'image', 'photo', 'album', 'acquire', 'face', 'parameter', 'image', 'accord', 'face', 'information', 'select', 'cover', 'image', 'accord', 'face', 'parameter', 'image', 'take', 'face-region', 'image', 'cover', 'image', 'set', 'face-region', 'image', 'cover', 'photo', 'album', 'wherein', 'processor', 'configure', 'perform', 'calculation', 'face', 'parameter', 'image', 'preset', 'way', 'obtain', 'cover', 'score', 'image', 'select', 'image', 'high', 'cover', 'score', 'cover', 'image', 'wherein', 'processor', 'configure', 'acquire', 'source', 'image', 'select', 'image', 'high', 'cover', 'score', 'image', 'come', 'preset', 'source', 'cover', 'image', 'apparatus', 'accord', 'claim', 'wherein', 'processor', 'configure', 'acquire', 'number', 'face', 'contain', 'image', 'determine', 'single-person', 'image', 'accord', 'number', 'face', 'select', 'single-person', 'image', 'high', 'cover', 'score', 'cover', 'image', 'apparatus', 'accord', 'claim', 'wherein', 'processor', 'configure', 'single-person', 'image', 'photo', 'album', 'determine', 'image', 'include', 'two', 'face', 'photo', 'album', 'select', 'image', 'high', 'cover', 'score', 'image', 'include', 'two', 'face', 'cover', 'image', 'apparatus', 'accord', 'claim', 'wherein', 'face', 'information', 'comprise', 'face', 'feature', 'point', 'face', 'parameter', 'comprises', 'face', 'turn', 'angle', 'processor', 'configure', 'acquire', 'coordinate', 'value', 'face', 'feature', 'point', 'determine', 'distance', 'angle', 'face', 'feature', 'point', 'determine', 'face', 'turn', 'angle', 'accord', 'distance', 'angle', 'apparatus', 'accord', 'claim', 'wherein', 'face', 'parameter', 'comprise', 'face', 'ratio', 'processor', 'configure', 'determine', 'face', 'region', 'image', 'accord', 'face', 'information', 'calculate', 'ratio', 'area', 'face', 'region', 'area', 'image', 'obtain', 'face', 'ratio', 'apparatus', 'accord', 'claim', 'wherein', 'processor', 'configure', 'one', 'face', 'image', 'subtract', 'area', 'occupy', 'face', 'face', 'correspond', 'photo', 'album', 'face', 'region', 'obtain', 'remain', 'area', 'calculate', 'ratio', 'remain', 'area', 'area', 'image', 'obtain', 'face', 'ratio', 'apparatus', 'accord', 'claim', 'wherein', 'processor', 'configure', 'acquire', 'image', 'identification', 'image', 'photo', 'album', 'extract', 'face', 'information', 'correspond', 'image', 'identification', 'face', 'database', 'face', 'database', 'store', 'face', 'recognition', 'result', 'image', 'face', 'recognition', 'result', 'include', 'face', 'information', 'electronic', 'device', 'comprise', 'processor', 'memory', 'display', 'screen', 'input', 'device', 'connect', 'via', 'system', 'bus', 'wherein', 'memory', 'store', 'computer', 'program', 'execute', 'processor', 'cause', 'processor', 'implement', 'image', 'processing', 'method', 'image', 'processing', 'method', 'comprise', 'acquire', 'photo', 'album', 'obtain', 'face', 'cluster', 'collect', 'face', 'information', 'respective', 'image', 'photo', 'album', 'acquire', 'face', 'parameter', 'image', 'accord', 'face', 'information', 'select', 'cover', 'image', 'accord', 'face', 'parameter', 'image', 'take', 'face-region', 'image', 'cover', 'image', 'set', 'face-region', 'image', 'cover', 'photo', 'album', 'wherein', 'select', 'cover', 'image', 'accord', 'face', 'parameter', 'image', 'comprise', 'perform', 'calculation', 'face', 'parameter', 'image', 'preset', 'way', 'obtain', 'cover', 'score', 'image', 'select', 'image', 'high', 'cover', 'score', 'cover', 'image', 'wherein', 'select', 'image', 'high', 'cover', 'score', 'cover', 'image', 'comprise', 'acquire', 'source', 'image', 'select', 'image', 'high', 'cover', 'score', 'image', 'come', 'preset', 'source', 'cover', 'image', 'electronic', 'device', 'accord', 'claim', 'wherein', 'electronic', 'device', 'comprises', 'least', 'one', 'mobile', 'phone', 'tablet', 'computer', 'personal', 'digital', 'assistant', 'wearable', 'device', 'computer-implemented', 'method', 'comprise', 'receive', 'compute', 'device', 'meeting', 'invitation', 'identify', 'location', 'least', 'one', 'invitee', 'meeting', 'invitation', 'configure', 'provide', 'least', 'one', 'invitee', 'physical', 'access', 'location', 'wherein', 'meeting', 'invitation', 'cause', 'system', 'control', 'pathway', 'allow', 'physical', 'access', 'location', 'provide', 'base', 'meet', 'invitation', 'least', 'one', 'invitee', 'physical', 'access', 'location', 'control', 'pathway', 'allow', 'least', 'one', 'invitee', 'physically', 'access', 'location', 'pathway', 'response', 'position', 'data', 'indicate', 'least', 'one', 'invitee', 'predetermine', 'location', 'near', 'location', 'wherein', 'position', 'data', 'base', 'part', 'face', 'recognition', 'camera', 'system', 'identify', 'least', 'one', 'invitee', 'receive', 'position', 'data', 'face', 'recognition', 'camera', 'system', 'identify', 'least', 'one', 'invitee', 'wherein', 'position', 'data', 'indicate', 'pattern', 'movement', 'least', 'one', 'invitee', 'determine', 'pattern', 'movement', 'indicate', 'least', 'one', 'invitee', 'exit', 'location', 'revoke', 'physical', 'access', 'location', 'identify', 'meet', 'invitation', 'control', 'pathway', 'restrict', 'least', 'one', 'invitee', 'identify', 'meet', 'invitation', 'physical', 'access', 'location', 'pathway', 'response', 'determine', 'pattern', 'movement', 'indicate', 'least', 'one', 'invitee', 'exit', 'location', 'computer-implemented', 'method', 'claim', 'wherein', 'determine', 'least', 'one', 'invitee', 'exit', 'location', 'comprise', 'determine', 'least', 'one', 'invitee', 'pass', 'egress', 'associate', 'location', 'predetermine', 'direction', 'computer-implemented', 'method', 'claim', 'wherein', 'determine', 'least', 'one', 'invitee', 'exit', 'location', 'comprise', 'determine', 'least', 'one', 'invitee', 'move', 'area', 'predetermine', 'direction', 'computer-implemented', 'method', 'claim', 'wherein', 'position', 'data', 'indicate', 'second', 'pattern', 'movement', 'least', 'one', 'invitee', 'wherein', 'access', 'secure', 'data', 'associate', 'location', 'provide', 'response', 'detect', 'second', 'pattern', 'movement', 'computer-implemented', 'method', 'claim', 'comprise', 'collate', 'secure', 'data', 'public', 'data', 'generate', 'resource', 'data', 'communicate', 'resource', 'data', 'client', 'compute', 'device', 'associate', 'least', 'one', 'invitee', 'access', 'location', 'provide', 'computer-implemented', 'method', 'claim', 'wherein', 'position', 'data', 'indicate', 'least', 'one', 'invitee', 'predetermine', 'location', 'least', 'one', 'invitee', 'pass', 'predetermine', 'location', 'computer-implemented', 'method', 'claim', 'wherein', 'position', 'data', 'indicate', 'least', 'one', 'invitee', 'predetermine', 'location', 'least', 'one', 'invitee', 'pass', 'predetermine', 'location', 'near', 'location', 'predetermine', 'direction', 'system', 'comprise', 'processor', 'memory', 'communication', 'processor', 'memory', 'computer-readable', 'instruction', 'store', 'thereupon', 'execute', 'processor', 'cause', 'processor', 'receive', 'meeting', 'invitation', 'indicate', 'location', 'identity', 'meeting', 'invitation', 'configure', 'provide', 'least', 'one', 'invitee', 'physical', 'access', 'location', 'wherein', 'meeting', 'invitation', 'cause', 'system', 'control', 'pathway', 'allow', 'physical', 'access', 'location', 'provide', 'least', 'one', 'invitee', 'associate', 'identity', 'access', 'location', 'control', 'pathway', 'allow', 'least', 'one', 'invitee', 'physically', 'access', 'location', 'pathway', 'response', 'position', 'data', 'indicate', 'least', 'one', 'invitee', 'predetermine', 'location', 'near', 'location', 'wherein', 'position', 'data', 'base', 'part', 'face', 'recognition', 'camera', 'system', 'identify', 'least', 'one', 'invitee', 'receive', 'position', 'data', 'face', 'recognition', 'camera', 'system', 'identify', 'least', 'one', 'invitee', 'wherein', 'position', 'data', 'indicate', 'pattern', 'movement', 'least', 'one', 'invitee', 'determine', 'pattern', 'movement', 'indicate', 'least', 'one', 'invitee', 'exit', 'location', 'revoke', 'physical', 'access', 'location', 'identify', 'meet', 'invitation', 'control', 'pathway', 'restrict', 'least', 'one', 'invitee', 'identify', 'meet', 'invitation', 'physical', 'access', 'location', 'pathway', 'response', 'determine', 'pattern', 'movement', 'indicate', 'least', 'one', 'invitee', 'exit', 'location', 'system', 'claim', 'wherein', 'determine', 'least', 'one', 'invitee', 'exit', 'location', 'comprise', 'determine', 'least', 'one', 'invitee', 'pass', 'egress', 'associate', 'location', 'system', 'claim', 'wherein', 'determine', 'least', 'one', 'invitee', 'exit', 'location', 'comprise', 'determine', 'least', 'one', 'invitee', 'move', 'area', 'predetermine', 'direction', 'system', 'claim', 'wherein', 'position', 'data', 'indicate', 'second', 'pattern', 'movement', 'least', 'one', 'invitee', 'wherein', 'access', 'secure', 'data', 'associate', 'location', 'provide', 'response', 'detect', 'second', 'pattern', 'movement', 'system', 'claim', 'wherein', 'instruction', 'cause', 'processor', 'collate', 'secure', 'data', 'public', 'data', 'generate', 'resource', 'data', 'communicate', 'resource', 'data', 'client', 'compute', 'device', 'associate', 'least', 'one', 'invitee', 'access', 'location', 'provide', 'non-transitory', 'computer-readable', 'storage', 'medium', 'computer-executable', 'instruction', 'store', 'thereupon', 'execute', 'one', 'processor', 'compute', 'device', 'cause', 'one', 'processor', 'compute', 'device', 'receive', 'meeting', 'invitation', 'indicate', 'location', 'identity', 'meeting', 'invitation', 'configure', 'provide', 'least', 'one', 'invitee', 'physical', 'access', 'location', 'wherein', 'meeting', 'invitation', 'cause', 'system', 'control', 'pathway', 'allow', 'physical', 'access', 'location', 'provide', 'least', 'one', 'invitee', 'associate', 'identity', 'access', 'location', 'control', 'pathway', 'allow', 'least', 'one', 'invitee', 'physically', 'access', 'location', 'pathway', 'response', 'position', 'data', 'indicate', 'least', 'one', 'invitee', 'predetermine', 'location', 'near', 'location', 'wherein', 'position', 'data', 'base', 'part', 'face', 'recognition', 'camera', 'system', 'identify', 'least', 'one', 'invitee', 'receive', 'position', 'data', 'face', 'recognition', 'camera', 'system', 'identify', 'least', 'one', 'invitee', 'wherein', 'position', 'data', 'indicate', 'pattern', 'movement', 'least', 'one', 'invitee', 'determine', 'pattern', 'movement', 'indicate', 'least', 'one', 'invitee', 'exit', 'location', 'revoke', 'physical', 'access', 'location', 'identify', 'meet', 'invitation', 'control', 'pathway', 'restrict', 'least', 'one', 'invitee', 'identify', 'meet', 'invitation', 'physical', 'access', 'location', 'pathway', 'response', 'determine', 'pattern', 'movement', 'indicate', 'least', 'one', 'invitee', 'exit', 'location', 'non-transitory', 'computer-readable', 'storage', 'medium', 'claim', 'wherein', 'determine', 'least', 'one', 'invitee', 'exit', 'location', 'comprise', 'determine', 'least', 'one', 'invitee', 'pass', 'egress', 'associate', 'location', 'non-transitory', 'computer-readable', 'storage', 'medium', 'claim', 'wherein', 'position', 'data', 'indicate', 'second', 'pattern', 'movement', 'least', 'one', 'invitee', 'wherein', 'access', 'secure', 'data', 'associate', 'location', 'provide', 'response', 'detect', 'second', 'pattern', 'movement', 'non-transitory', 'computer-readable', 'storage', 'medium', 'claim', 'wherein', 'instruction', 'cause', 'one', 'processor', 'collate', 'secure', 'data', 'public', 'data', 'generate', 'resource', 'data', 'communicate', 'resource', 'data', 'client', 'compute', 'device', 'associate', 'least', 'one', 'invitee', 'access', 'location', 'provide', 'method', 'comprise', 'receive', 'piece', 'content', 'salient', 'data', 'piece', 'content', 'base', 'salient', 'data', 'determine', 'first', 'path', 'viewport', 'piece', 'content', 'wherein', 'first', 'path', 'viewport', 'include', 'different', 'salient', 'event', 'occur', 'piece', 'content', 'different', 'time', 'playback', 'piece', 'content', 'provide', 'viewport', 'display', 'device', 'wherein', 'movement', 'viewport', 'base', 'first', 'path', 'viewport', 'salient', 'data', 'playback', 'detect', 'additional', 'salient', 'event', 'piece', 'content', 'include', 'first', 'path', 'viewport', 'provide', 'indication', 'additional', 'salient', 'event', 'viewport', 'playback', 'method', 'claim', 'wherein', 'salient', 'data', 'identifies', 'salient', 'event', 'piece', 'content', 'salient', 'data', 'indicate', 'salient', 'event', 'piece', 'content', 'correspond', 'point', 'location', 'salient', 'event', 'piece', 'content', 'correspond', 'time', 'salient', 'event', 'occur', 'playback', 'method', 'claim', 'wherein', 'salient', 'data', 'indicate', 'salient', 'event', 'piece', 'content', 'correspond', 'type', 'salient', 'event', 'correspond', 'strength', 'value', 'salient', 'event', 'method', 'claim', 'wherein', 'first', 'path', 'viewport', 'control', 'movement', 'viewport', 'put', 'different', 'salient', 'event', 'view', 'viewport', 'different', 'time', 'playback', 'method', 'claim', 'comprise', 'detect', 'one', 'salient', 'event', 'piece', 'content', 'base', 'least', 'one', 'follow', 'visual', 'data', 'piece', 'content', 'audio', 'data', 'piece', 'content', 'content', 'consumption', 'experience', 'data', 'piece', 'content', 'wherein', 'salient', 'data', 'indicative', 'salient', 'event', 'detect', 'method', 'claim', 'comprise', 'detect', 'one', 'salient', 'event', 'piece', 'content', 'base', 'least', 'one', 'follow', 'face', 'recognition', 'facial', 'emotion', 'recognition', 'object', 'recognition', 'motion', 'recognition', 'metadata', 'piece', 'content', 'wherein', 'salient', 'data', 'indicative', 'salient', 'event', 'detect', 'method', 'claim', 'comprise', 'detect', 'user', 'interaction', 'indication', 'wherein', 'indication', 'comprise', 'interactive', 'hint', 'response', 'detect', 'user', 'interaction', 'adapt', 'first', 'path', 'viewport', 'second', 'path', 'viewport', 'base', 'user', 'interaction', 'wherein', 'second', 'path', 'viewport', 'include', 'additional', 'salient', 'event', 'provide', 'updated', 'viewport', 'piece', 'content', 'display', 'device', 'wherein', 'movement', 'update', 'viewport', 'base', 'second', 'path', 'viewport', 'salient', 'data', 'playback', 'second', 'path', 'viewport', 'control', 'movement', 'update', 'viewport', 'put', 'additional', 'salient', 'event', 'view', 'update', 'viewport', 'method', 'claim', 'comprise', 'change', 'weight', 'assign', 'additional', 'salient', 'event', 'one', 'salient', 'event', 'piece', 'content', 'type', 'additional', 'salient', 'event', 'method', 'claim', 'wherein', 'second', 'path', 'viewport', 'include', 'one', 'salient', 'event', 'piece', 'content', 'type', 'additional', 'salient', 'event', 'system', 'comprise', 'least', 'one', 'processor', 'non-transitory', 'processor-readable', 'memory', 'device', 'store', 'instruction', 'execute', 'least', 'one', 'processor', 'cause', 'least', 'one', 'processor', 'perform', 'operation', 'include', 'receive', 'piece', 'content', 'salient', 'data', 'piece', 'content', 'base', 'salient', 'data', 'determine', 'first', 'path', 'viewport', 'piece', 'content', 'wherein', 'first', 'path', 'viewport', 'include', 'different', 'salient', 'event', 'occur', 'piece', 'content', 'different', 'time', 'playback', 'piece', 'content', 'provide', 'viewport', 'display', 'device', 'wherein', 'movement', 'viewport', 'base', 'first', 'path', 'viewport', 'salient', 'data', 'playback', 'detect', 'additional', 'salient', 'event', 'piece', 'content', 'include', 'first', 'path', 'viewport', 'provide', 'indication', 'additional', 'salient', 'event', 'viewport', 'playback', 'system', 'claim', 'wherein', 'salient', 'data', 'identifies', 'salient', 'event', 'piece', 'content', 'salient', 'data', 'indicate', 'salient', 'event', 'piece', 'content', 'correspond', 'point', 'location', 'salient', 'event', 'piece', 'content', 'correspond', 'time', 'salient', 'event', 'occur', 'playback', 'system', 'claim', 'wherein', 'salient', 'data', 'indicate', 'salient', 'event', 'piece', 'content', 'correspond', 'type', 'salient', 'event', 'correspond', 'strength', 'value', 'salient', 'event', 'system', 'claim', 'wherein', 'salient', 'data', 'generate', 'offline', 'server', 'system', 'claim', 'operation', 'comprise', 'detect', 'one', 'salient', 'event', 'piece', 'content', 'base', 'least', 'one', 'follow', 'visual', 'data', 'piece', 'content', 'audio', 'data', 'piece', 'content', 'content', 'consumption', 'experience', 'data', 'piece', 'content', 'wherein', 'salient', 'data', 'indicative', 'salient', 'event', 'detect', 'system', 'claim', 'operation', 'comprise', 'detect', 'one', 'salient', 'event', 'piece', 'content', 'base', 'least', 'one', 'follow', 'face', 'recognition', 'facial', 'emotion', 'recognition', 'object', 'recognition', 'motion', 'recognition', 'metadata', 'piece', 'content', 'wherein', 'salient', 'data', 'indicative', 'salient', 'event', 'detect', 'system', 'claim', 'operation', 'comprise', 'detect', 'user', 'interaction', 'indication', 'wherein', 'indication', 'comprise', 'interactive', 'hint', 'response', 'detect', 'user', 'interaction', 'adapt', 'first', 'path', 'viewport', 'second', 'path', 'viewport', 'base', 'user', 'interaction', 'wherein', 'second', 'path', 'viewport', 'include', 'additional', 'salient', 'event', 'provide', 'updated', 'viewport', 'piece', 'content', 'display', 'device', 'wherein', 'movement', 'update', 'viewport', 'base', 'second', 'path', 'viewport', 'salient', 'data', 'playback', 'second', 'path', 'viewport', 'control', 'movement', 'update', 'viewport', 'put', 'additional', 'salient', 'event', 'view', 'update', 'viewport', 'system', 'claim', 'operation', 'comprise', 'change', 'weight', 'assign', 'additional', 'salient', 'event', 'one', 'salient', 'event', 'piece', 'content', 'type', 'additional', 'salient', 'event', 'system', 'claim', 'wherein', 'second', 'path', 'viewport', 'include', 'one', 'salient', 'event', 'piece', 'content', 'type', 'additional', 'salient', 'event', 'non-transitory', 'computer', 'readable', 'storage', 'medium', 'include', 'instruction', 'perform', 'method', 'comprise', 'receive', 'piece', 'content', 'salient', 'data', 'piece', 'content', 'base', 'salient', 'data', 'determine', 'first', 'path', 'viewport', 'piece', 'content', 'wherein', 'first', 'path', 'viewport', 'include', 'different', 'salient', 'event', 'occur', 'piece', 'content', 'different', 'time', 'playback', 'piece', 'content', 'provide', 'viewport', 'display', 'device', 'wherein', 'movement', 'viewport', 'base', 'first', 'path', 'viewport', 'salient', 'data', 'playback', 'detect', 'additional', 'salient', 'event', 'piece', 'content', 'include', 'first', 'path', 'viewport', 'provide', 'indication', 'additional', 'salient', 'event', 'viewport', 'playback', 'computer', 'readable', 'storage', 'medium', 'claim', 'method', 'comprise', 'detect', 'user', 'interaction', 'indication', 'wherein', 'indication', 'comprise', 'interactive', 'hint', 'response', 'detect', 'user', 'interaction', 'adapt', 'first', 'path', 'viewport', 'second', 'path', 'viewport', 'base', 'user', 'interaction', 'wherein', 'second', 'path', 'viewport', 'include', 'additional', 'salient', 'event', 'provide', 'updated', 'viewport', 'piece', 'content', 'display', 'device', 'wherein', 'movement', 'update', 'viewport', 'base', 'second', 'path', 'viewport', 'salient', 'data', 'playback', 'second', 'path', 'viewport', 'control', 'movement', 'update', 'viewport', 'put', 'additional', 'salient', 'event', 'view', 'update', 'viewport', 'mobile', 'device', 'facial', 'recognition', 'mobile', 'device', 'comprise', 'one', 'camera', 'processor', 'device', 'memory', 'couple', 'processor', 'device', 'processing', 'system', 'program', 'receive', 'plurality', 'image', 'one', 'camera', 'extract', 'feature', 'extractor', 'utilizing', 'convolutional', 'neural', 'network', 'cnn', 'enlarge', 'intra-class', 'variance', 'long-tail', 'class', 'feature', 'vector', 'plurality', 'image', 'generate', 'feature', 'generator', 'discriminative', 'feature', 'vector', 'feature', 'vector', 'classify', 'fully', 'connect', 'classifier', 'identity', 'discriminative', 'feature', 'vector', 'control', 'operation', 'mobile', 'device', 'react', 'accordance', 'identity', 'mobile', 'device', 'recite', 'claim', 'include', 'communication', 'system', 'mobile', 'device', 'recite', 'claim', 'wherein', 'operation', 'tag', 'video', 'identity', 'uploads', 'video', 'social', 'medium', 'mobile', 'device', 'recite', 'claim', 'wherein', 'operation', 'tag', 'video', 'identity', 'sends', 'video', 'user', 'mobile', 'device', 'recite', 'claim', 'wherein', 'mobile', 'device', 'smart', 'phone', 'mobile', 'device', 'recite', 'claim', 'wherein', 'mobile', 'device', 'body', 'cam', 'mobile', 'device', 'recite', 'claim', 'program', 'train', 'feature', 'extractor', 'feature', 'generator', 'fully', 'connect', 'classifier', 'alternative', 'bi-stage', 'strategy', 'mobile', 'device', 'recite', 'claim', 'wherein', 'feature', 'extractor', 'share', 'covariance', 'matrix', 'across', 'class', 'transfer', 'intra-class', 'variance', 'regular', 'class', 'long-tail', 'class', 'mobile', 'device', 'recite', 'claim', 'wherein', 'feature', 'generator', 'optimize', 'softmax', 'loss', 'joint', 'regularization', 'weight', 'feature', 'magnitude', 'inner', 'product', 'weight', 'feature', 'mobile', 'device', 'recite', 'claim', 'wherein', 'feature', 'extractor', 'average', 'feature', 'vector', 'flip', 'feature', 'vector', 'flip', 'feature', 'vector', 'generate', 'horizontally', 'flip', 'frame', 'one', 'plurality', 'image', 'mobile', 'device', 'recite', 'claim', 'wherein', 'plurality', 'image', 'select', 'group', 'consist', 'image', 'video', 'frame', 'video', 'mobile', 'device', 'recite', 'claim', 'wherein', 'communication', 'system', 'connect', 'remote', 'server', 'include', 'facial', 'recognition', 'network', 'mobile', 'device', 'recite', 'claim', 'wherein', 'one', 'stage', 'alternative', 'bi-stage', 'strategy', 'fix', 'feature', 'extractor', 'applies', 'feature', 'generator', 'generate', 'new', 'transfer', 'feature', 'diverse', 'violate', 'decision', 'boundary', 'mobile', 'device', 'recite', 'claim', 'wherein', 'one', 'stage', 'alternative', 'bi-stage', 'strategy', 'fix', 'fully', 'connect', 'classifier', 'updates', 'feature', 'extractor', 'feature', 'generator', 'computer', 'program', 'product', 'mobile', 'device', 'facial', 'recognition', 'computer', 'program', 'product', 'comprise', 'non-transitory', 'computer', 'readable', 'storage', 'medium', 'program', 'instruction', 'embody', 'therewith', 'program', 'instruction', 'executable', 'computer', 'cause', 'computer', 'perform', 'method', 'comprise', 'receive', 'processor', 'device', 'plurality', 'image', 'extract', 'processor', 'device', 'feature', 'extractor', 'utilizing', 'convolutional', 'neural', 'network', 'cnn', 'enlarge', 'intra-class', 'variance', 'long-tail', 'class', 'feature', 'vector', 'plurality', 'image', 'generate', 'processor', 'device', 'feature', 'generator', 'discriminative', 'feature', 'vector', 'feature', 'vector', 'classify', 'processor', 'device', 'utilize', 'fully', 'connect', 'classifier', 'identity', 'discriminative', 'feature', 'vector', 'control', 'operation', 'mobile', 'device', 'react', 'accordance', 'identity', 'computer-implemented', 'method', 'facial', 'recognition', 'mobile', 'device', 'method', 'comprise', 'receive', 'processor', 'device', 'plurality', 'image', 'extract', 'processor', 'device', 'feature', 'extractor', 'utilizing', 'convolutional', 'neural', 'network', 'cnn', 'enlarge', 'intra-class', 'variance', 'long-tail', 'class', 'feature', 'vector', 'plurality', 'image', 'generate', 'processor', 'device', 'feature', 'generator', 'discriminative', 'feature', 'vector', 'feature', 'vector', 'classify', 'processor', 'device', 'utilize', 'fully', 'connect', 'classifier', 'identity', 'discriminative', 'feature', 'vector', 'control', 'operation', 'mobile', 'device', 'react', 'accordance', 'identity', 'computer-implemented', 'method', 'recite', 'claim', 'wherein', 'control', 'include', 'tag', 'video', 'identity', 'upload', 'video', 'social', 'medium', 'computer-implemented', 'method', 'recite', 'claim', 'wherein', 'control', 'include', 'tag', 'video', 'identity', 'send', 'video', 'user', 'computer-implemented', 'method', 'recite', 'claim', 'wherein', 'extract', 'include', 'share', 'covariance', 'matrix', 'across', 'class', 'transfer', 'intra-class', 'variance', 'regular', 'class', 'long-tail', 'class', 'compute', 'device', 'comprise', 'non-transitory', 'machine', 'readable', 'medium', 'store', 'machine', 'train', 'mt', 'network', 'comprise', 'plurality', 'layer', 'process', 'node', 'process', 'node', 'configure', 'compute', 'first', 'output', 'value', 'combine', 'set', 'output', 'value', 'set', 'process', 'node', 'use', 'piecewise', 'linear', 'cup', 'function', 'compute', 'second', 'output', 'value', 'first', 'output', 'value', 'process', 'node', 'wherein', 'piecewise', 'linear', 'cup', 'function', 'prior', 'train', 'mt', 'network', 'comprises', 'least', 'first', 'linear', 'section', 'first', 'slope', 'follow', 'ii', 'second', 'linear', 'section', 'negative', 'second', 'slope', 'follow', 'iii', 'third', 'linear', 'section', 'negative', 'third', 'slope', 'different', 'second', 'slope', 'follow', 'iv', 'fourth', 'linear', 'section', 'positive', 'fourth', 'slope', 'follow', 'v', 'fifth', 'linear', 'section', 'positive', 'fifth', 'slope', 'different', 'fourth', 'slope', 'follow', 'vi', 'sixth', 'linear', 'section', 'sixth', 'slope', 'wherein', 'piecewise', 'linear', 'cup', 'function', 'symmetric', 'vertical', 'axis', 'third', 'fourth', 'linear', 'section', 'prior', 'train', 'mt', 'network', 'content', 'capturing', 'circuit', 'capture', 'content', 'processing', 'mt', 'network', 'set', 'process', 'unit', 'execute', 'process', 'node', 'process', 'content', 'capture', 'content', 'capture', 'circuit', 'wherein', 'training', 'set', 'parameter', 'define', 'piecewise', 'linear', 'cup', 'function', 'node', 'first', 'second', 'plurality', 'process', 'node', 'process', 'node', 'first', 'plurality', 'processing', 'node', 'configure', 'emulate', 'boolean', 'operator', 'output', 'value', 'processing', 'node', 'range', 'associate', '``', \"''\", 'value', 'set', 'input', 'process', 'node', 'set', 'value', 'range', 'associate', '``', \"''\", 'ii', 'processing', 'node', 'second', 'plurality', 'processing', 'node', 'configure', 'emulate', 'boolean', 'xnor', 'operator', 'output', 'value', 'processing', 'node', 'range', 'associate', '``', \"''\", 'set', 'input', 'node', 'set', 'value', 'range', 'associate', '``', \"''\", 'b', 'set', 'input', 'node', 'set', 'value', 'range', 'associate', '``', \"''\", 'value', 'compute', 'device', 'claim', 'wherein', 'third', 'linear', 'section', 'piecewise', 'linear', 'cup', 'function', 'first', 'process', 'node', 'mt', 'network', 'different', 'slope', 'third', 'linear', 'section', 'second', 'processing', 'node', 'mt', 'network', 'compute', 'device', 'claim', 'wherein', 'length', 'third', 'section', 'piecewise', 'linear', 'cup', 'function', 'first', 'process', 'node', 'mt', 'network', 'different', 'length', 'third', 'section', 'piecewise', 'linear', 'cup', 'function', 'second', 'processing', 'node', 'mt', 'network', 'compute', 'device', 'claim', 'wherein', 'set', 'parameter', 'train', 'part', 'back', 'propagate', 'module', 'back', 'propagating', 'error', 'output', 'value', 'later', 'layer', 'process', 'node', 'earlier', 'layer', 'process', 'node', 'adjust', 'set', 'parameter', 'define', 'piecewise', 'linear', 'cup', 'function', 'earlier', 'layer', 'process', 'node', 'compute', 'device', 'claim', 'wherein', 'processing', 'node', 'us', 'linear', 'function', 'define', 'set', 'parameter', 'compute', 'first', 'output', 'value', 'process', 'node', 'wherein', 'back', 'propagate', 'module', 'back', 'propagate', 'error', 'output', 'value', 'later', 'layer', 'process', 'node', 'earlier', 'layer', 'process', 'node', 'adjust', 'set', 'parameter', 'define', 'linear', 'function', 'earlier', 'layer', 'process', 'node', 'compute', 'device', 'claim', 'wherein', 'first', 'plurality', 'processing', 'node', 'emulate', 'boolean', 'operator', 'second', 'plurality', 'processing', 'node', 'emulate', 'boolean', 'operator', 'enable', 'mt', 'network', 'implement', 'mathematical', 'problem', 'compute', 'device', 'claim', 'wherein', 'plurality', 'processing', 'node', 'layer', 'plurality', 'processing', 'node', 'receive', 'input', 'value', 'output', 'value', 'plurality', 'processing', 'node', 'set', 'prior', 'layer', 'compute', 'device', 'claim', 'wherein', 'processing', 'node', 'us', 'linear', 'function', 'compute', 'first', 'output', 'value', 'process', 'node', 'wherein', 'process', 'node', \"'s\", 'piecewise', 'linear', 'cup', 'function', 'define', 'along', 'first', 'second', 'ax', 'first', 'axis', 'define', 'range', 'output', 'value', 'process', 'node', \"'s\", 'linear', 'function', 'second', 'axis', 'define', 'range', 'output', 'value', 'produce', 'piecewise', 'linear', 'cup', 'function', 'range', 'output', 'value', 'process', 'node', \"'s\", 'linear', 'function', 'compute', 'device', 'claim', 'comprise', 'content', 'output', 'circuit', 'present', 'output', 'base', 'processing', 'content', 'mt', 'network', 'compute', 'device', 'claim', 'wherein', 'capture', 'content', 'one', 'image', 'audio', 'segment', 'wherein', 'present', 'output', 'output', 'display', 'display', 'screen', 'compute', 'device', 'audio', 'presentation', 'output', 'speaker', 'compute', 'device', 'compute', 'device', 'claim', 'wherein', 'compute', 'device', 'mobile', 'device', 'compute', 'device', 'claim', 'wherein', 'mt', 'network', 'mt', 'neural', 'network', 'process', 'node', 'mt', 'neuron', 'compute', 'device', 'claim', 'wherein', 'set', 'parameter', 'configure', 'train', 'plurality', 'processing', 'node', 'comprise', 'least', 'one', 'negative', 'second', 'third', 'slope', 'second', 'third', 'linear', 'section', 'positive', 'fourth', 'fifth', 'slope', 'fourth', 'fifth', 'linear', 'section', 'first', 'intercept', 'second', 'linear', 'section', 'second', 'intercept', 'fifth', 'linear', 'section', 'set', 'length', 'least', 'second', 'third', 'fourth', 'fifth', 'section', 'compute', 'device', 'claim', 'wherein', 'train', 'set', 'parameter', 'define', 'piecewise', 'linear', 'cup', 'function', 'node', 'comprise', 'plurality', 'output', 'value', 'compute', 'device', 'claim', 'wherein', 'first', 'sixth', 'slope', 'zerowe', 'claim', 'system', 'comprise', 'memory', 'device', 'store', 'input', 'image', 'processor', 'include', 'image', 'input', 'interface', 'receive', 'input', 'image', 'pre-processor', 'model', 'input', 'image', 'yield', 'multi-channel', 'image', 'feature', 'extractor', 'extract', 'set', 'feature', 'base', 'multi-channel', 'image', 'feature', 'selector', 'select', 'one', 'feature', 'set', 'feature', 'multi-channel', 'image', 'wherein', 'one', 'feature', 'select', 'base', 'ability', 'differentiate', 'feature', 'feature', 'matcher', 'match', 'one', 'feature', 'learn', 'feature', 'set', 'similarity', 'detector', 'determine', 'whether', 'one', 'feature', 'meet', 'pre-defined', 'similarity', 'threshold', 'system', 'claim', 'wherein', 'pre-processor', 'activate', 'one', 'channel', 'multi-channel', 'image', 'yield', 'one', 'activate', 'channel', 'system', 'claim', 'wherein', 'one', 'activate', 'channel', 'determine', 'base', 'ability', 'differentiate', 'feature', 'system', 'claim', 'wherein', 'pre-processor', 'activate', 'one', 'local', 'patch', 'one', 'activate', 'channel', 'system', 'claim', 'wherein', 'one', 'local', 'patch', 'determine', 'base', 'ability', 'differentiate', 'feature', 'system', 'claim', 'wherein', 'feature', 'matcher', 'utilize', 'large-scale', 'data', 'learn', 'process', 'perform', 'feature', 'match', 'apparatus', 'comprise', 'image', 'input', 'interface', 'receive', 'input', 'image', 'pre-processor', 'model', 'input', 'image', 'yield', 'multi-channel', 'image', 'feature', 'extractor', 'extract', 'set', 'feature', 'base', 'multi-channel', 'image', 'feature', 'selector', 'select', 'one', 'feature', 'set', 'feature', 'multi-channel', 'image', 'wherein', 'one', 'feature', 'select', 'base', 'ability', 'differentiate', 'feature', 'feature', 'matcher', 'match', 'one', 'feature', 'learn', 'feature', 'set', 'similarity', 'detector', 'determine', 'whether', 'one', 'feature', 'meet', 'pre-defined', 'similarity', 'threshold', 'apparatus', 'claim', 'wherein', 'pre-processor', 'activate', 'one', 'channel', 'multi-channel', 'image', 'yield', 'one', 'activate', 'channel', 'apparatus', 'claim', 'wherein', 'one', 'activate', 'channel', 'determine', 'base', 'ability', 'differentiate', 'feature', 'apparatus', 'claim', 'wherein', 'pre-processor', 'activate', 'one', 'local', 'patch', 'one', 'activated', 'channel', 'apparatus', 'claim', 'wherein', 'one', 'local', 'patch', 'determine', 'base', 'ability', 'differentiate', 'feature', 'apparatus', 'claim', 'wherein', 'feature', 'matcher', 'utilize', 'large-scale', 'data', 'learn', 'process', 'perform', 'feature', 'match', 'method', 'comprise', 'model', 'input', 'image', 'yield', 'multi-channel', 'image', 'extract', 'set', 'feature', 'base', 'multi-channel', 'image', 'select', 'one', 'feature', 'set', 'feature', 'multi-channel', 'image', 'wherein', 'one', 'feature', 'select', 'base', 'ability', 'differentiate', 'feature', 'match', 'one', 'feature', 'learn', 'feature', 'set', 'determine', 'whether', 'one', 'feature', 'meet', 'pre-defined', 'similarity', 'threshold', 'method', 'claim', 'wherein', 'model', 'input', 'image', 'include', 'activate', 'one', 'channels', 'multi-channel', 'image', 'yield', 'one', 'activate', 'channel', 'method', 'claim', 'wherein', 'one', 'activate', 'channel', 'determine', 'base', 'ability', 'differentiate', 'feature', 'method', 'claim', 'wherein', 'extract', 'feature', 'input', 'image', 'include', 'activate', 'one', 'local', 'patch', 'one', 'activated', 'channel', 'method', 'claim', 'wherein', 'one', 'local', 'patch', 'determine', 'base', 'ability', 'differentiate', 'feature', 'method', 'claim', 'wherein', 'feature', 'matcher', 'utilizes', 'large-scale', 'data', 'learn', 'process', 'perform', 'feature', 'match', 'least', 'one', 'non-transitory', 'computer', 'readable', 'storage', 'medium', 'comprise', 'set', 'instruction', 'execute', 'compute', 'device', 'cause', 'compute', 'device', 'model', 'input', 'image', 'yield', 'multi-channel', 'image', 'extract', 'set', 'feature', 'base', 'multi-channel', 'image', 'select', 'one', 'feature', 'set', 'feature', 'multi-channel', 'image', 'wherein', 'feature', 'select', 'base', 'ability', 'differentiate', 'feature', 'match', 'one', 'feature', 'learn', 'feature', 'set', 'determine', 'whether', 'one', 'feature', 'meet', 'pre-defined', 'similarity', 'threshold', 'least', 'one', 'non-transitory', 'computer', 'readable', 'storage', 'medium', 'claim', 'wherein', 'instruction', 'execute', 'cause', 'compute', 'device', 'activate', 'one', 'channel', 'multi-channel', 'image', 'yield', 'one', 'activate', 'channel', 'least', 'one', 'non-transitory', 'computer', 'readable', 'storage', 'medium', 'claim', 'wherein', 'instruction', 'execute', 'cause', 'compute', 'device', 'determine', 'one', 'activate', 'channel', 'base', 'ability', 'differentiate', 'feature', 'least', 'one', 'non-transitory', 'computer', 'readable', 'storage', 'medium', 'claim', 'wherein', 'extract', 'feature', 'input', 'image', 'include', 'activate', 'one', 'local', 'patch', 'one', 'activated', 'channel', 'least', 'one', 'non-transitory', 'computer', 'readable', 'storage', 'medium', 'claim', 'wherein', 'one', 'local', 'patch', 'determine', 'base', 'ability', 'differentiate', 'feature', 'least', 'one', 'non-transitory', 'computer', 'readable', 'storage', 'medium', 'claim', 'wherein', 'feature', 'matcher', 'utilize', 'large-scale', 'data', 'learn', 'process', 'perform', 'feature', 'match', 'apparatus', 'comprise', 'mean', 'model', 'input', 'image', 'yield', 'multi-channel', 'image', 'mean', 'extract', 'set', 'feature', 'base', 'multi-channel', 'image', 'mean', 'select', 'one', 'feature', 'set', 'feature', 'multi-channel', 'image', 'wherein', 'one', 'feature', 'select', 'base', 'ability', 'differentiate', 'feature', 'mean', 'match', 'one', 'feature', 'learn', 'feature', 'set', 'mean', 'determine', 'whether', 'one', 'feature', 'meet', 'pre-defined', 'similarity', 'threshold', 'method', 'control', 'terminal', 'terminal', 'comprise', 'capture', 'apparatus', 'least', 'one', 'processor', 'method', 'comprise', 'acquire', 'capture', 'apparatus', 'image', 'obtain', 'least', 'one', 'processor', 'motion', 'parameter', 'terminal', 'motion', 'parameter', 'comprise', 'least', 'one', 'motion', 'frequency', 'motion', 'time', 'two', 'parameter', 'among', 'acceleration', 'angular', 'velocity', 'motion', 'amplitude', 'motion', 'frequency', 'motion', 'time', 'transmit', 'least', 'one', 'processor', 'parameter', 'threshold', 'obtain', 'request', 'data', 'management', 'server', 'parameter', 'threshold', 'obtain', 'request', 'comprise', 'configuration', 'information', 'terminal', 'receiving', 'correspond', 'preset', 'threshold', 'correspond', 'configuration', 'information', 'response', 'parameter', 'threshold', 'obtain', 'request', 'compare', 'two', 'parameter', 'correspond', 'preset', 'threshold', 'control', 'least', 'one', 'processor', 'perform', 'image', 'processing', 'acquire', 'image', 'base', 'least', 'one', 'two', 'parameter', 'motion', 'parameter', 'great', 'correspond', 'preset', 'threshold', 'base', 'two', 'parameter', 'motion', 'parameter', 'respectively', 'great', 'correspond', 'preset', 'threshold', 'wherein', 'acquire', 'comprises', 'acquire', 'image', 'real', 'time', 'obtain', 'comprises', 'obtain', 'motion', 'parameter', 'terminal', 'real', 'time', 'method', 'comprise', 'response', 'least', 'one', 'two', 'parameter', 'motion', 'parameter', 'great', 'correspond', 'preset', 'threshold', 'obtain', 'motion', 'parameter', 'terminal', 'response', 'two', 'parameter', 'motion', 'parameter', 'obtain', 'late', 'time', 'le', 'equal', 'corresponding', 'preset', 'threshold', 'perform', 'image', 'processing', 'image', 'acquire', 'late', 'time', 'method', 'accord', 'claim', 'wherein', 'acquire', 'comprises', 'control', 'least', 'one', 'processor', 'turn', 'capture', 'apparatus', 'base', 'face', 'recognition', 'instruction', 'acquire', 'capture', 'apparatus', 'face', 'image', 'capture', 'apparatus', 'turn', 'method', 'accord', 'claim', 'wherein', 'control', 'perform', 'image', 'processing', 'comprise', 'skip', 'perform', 'face', 'recognition', 'acquire', 'face', 'image', 'base', 'least', 'one', 'two', 'parameter', 'motion', 'parameter', 'great', 'correspond', 'preset', 'threshold', 'base', 'two', 'parameter', 'motion', 'parameter', 'respectively', 'great', 'correspond', 'preset', 'threshold', 'method', 'accord', 'claim', 'wherein', 'obtain', 'comprises', 'least', 'one', 'obtain', 'acceleration', 'terminal', 'use', 'acceleration', 'sensor', 'obtain', 'angular', 'velocity', 'terminal', 'use', 'gyro', 'sensor', 'method', 'accord', 'claim', 'wherein', 'transmit', 'comprises', 'transmit', 'parameter', 'threshold', 'obtain', 'request', 'data', 'management', 'server', 'accord', 'preset', 'time', 'period', 'method', 'accord', 'claim', 'comprise', 'generate', 'prompt', 'information', 'base', 'least', 'one', 'two', 'parameter', 'motion', 'parameter', 'great', 'correspond', 'preset', 'threshold', 'prompt', 'information', 'use', 'prompt', 'terminal', 'stop', 'move', 'method', 'accord', 'claim', 'wherein', 'motion', 'parameter', 'comprise', 'motion', 'frequency', 'motion', 'time', 'terminal', 'comprise', 'capture', 'apparatus', 'least', 'one', 'memory', 'configure', 'store', 'program', 'code', 'least', 'one', 'processor', 'configure', 'access', 'least', 'one', 'memory', 'operate', 'accord', 'program', 'code', 'program', 'code', 'comprise', 'motion', 'parameter', 'obtain', 'code', 'configure', 'cause', 'least', 'one', 'processor', 'acquire', 'image', 'use', 'capture', 'apparatus', 'obtain', 'motion', 'parameter', 'terminal', 'motion', 'parameter', 'comprise', 'least', 'one', 'motion', 'frequency', 'motion', 'time', 'two', 'parameter', 'among', 'acceleration', 'angular', 'velocity', 'motion', 'amplitude', 'motion', 'frequency', 'motion', 'time', 'request', 'transmit', 'code', 'configure', 'cause', 'least', 'one', 'processor', 'transmit', 'parameter', 'threshold', 'obtain', 'request', 'data', 'management', 'server', 'parameter', 'threshold', 'obtain', 'request', 'comprise', 'configuration', 'information', 'terminal', 'parameter', 'threshold', 'receive', 'code', 'configure', 'cause', 'least', 'one', 'processor', 'receive', 'correspond', 'preset', 'threshold', 'correspond', 'configuration', 'information', 'response', 'parameter', 'threshold', 'obtain', 'request', 'compare', 'code', 'configure', 'cause', 'least', 'one', 'processor', 'compare', 'two', 'parameter', 'correspond', 'preset', 'threshold', 'control', 'code', 'configure', 'cause', 'least', 'one', 'processor', 'perform', 'image', 'processing', 'acquire', 'image', 'base', 'least', 'one', 'two', 'parameter', 'motion', 'parameter', 'great', 'correspond', 'preset', 'threshold', 'base', 'two', 'parameter', 'motion', 'parameter', 'respectively', 'great', 'correspond', 'preset', 'threshold', 'wherein', 'motion', 'parameter', 'obtain', 'code', 'cause', 'least', 'one', 'processor', 'acquire', 'image', 'real', 'time', 'obtain', 'motion', 'parameter', 'terminal', 'real', 'time', 'response', 'least', 'one', 'two', 'parameter', 'motion', 'parameter', 'great', 'correspond', 'preset', 'threshold', 'obtain', 'motion', 'parameter', 'terminal', 'wherein', 'control', 'code', 'cause', 'least', 'one', 'processor', 'response', 'two', 'parameter', 'motion', 'parameter', 'obtain', 'late', 'time', 'le', 'equal', 'corresponding', 'preset', 'threshold', 'perform', 'image', 'processing', 'image', 'acquire', 'late', 'time', 'terminal', 'accord', 'claim', 'wherein', 'program', 'code', 'comprise', 'face', 'instruction', 'receive', 'code', 'configure', 'cause', 'least', 'one', 'processor', 'receive', 'face', 'recognition', 'instruction', 'wherein', 'motion', 'parameter', 'obtain', 'code', 'cause', 'least', 'one', 'processor', 'control', 'accord', 'face', 'recognition', 'instruction', 'capture', 'apparatus', 'turn', 'acquire', 'face', 'image', 'use', 'capture', 'apparatus', 'capture', 'apparatus', 'turn', 'wherein', 'control', 'code', 'cause', 'least', 'one', 'processor', 'skip', 'perform', 'face', 'recognition', 'acquire', 'face', 'image', 'base', 'least', 'one', 'two', 'parameter', 'motion', 'parameter', 'great', 'correspond', 'preset', 'threshold', 'base', 'two', 'parameter', 'motion', 'parameter', 'respectively', 'great', 'correspond', 'preset', 'threshold', 'terminal', 'accord', 'claim', 'wherein', 'request', 'transmit', 'code', 'cause', 'least', 'one', 'processor', 'transmit', 'parameter', 'threshold', 'obtain', 'request', 'data', 'management', 'server', 'accord', 'preset', 'time', 'period', 'terminal', 'accord', 'claim', 'wherein', 'program', 'code', 'comprise', 'prompt', 'information', 'generation', 'code', 'configure', 'cause', 'least', 'one', 'processor', 'generate', 'prompt', 'information', 'base', 'least', 'one', 'two', 'parameter', 'motion', 'parameter', 'great', 'correspond', 'preset', 'threshold', 'prompt', 'information', 'use', 'prompt', 'terminal', 'stop', 'move', 'terminal', 'accord', 'claim', 'wherein', 'motion', 'parameter', 'comprise', 'motion', 'frequency', 'motion', 'time', 'non-transitory', 'computer-readable', 'storage', 'medium', 'store', 'machine', 'instruction', 'execute', 'one', 'processor', 'cause', 'one', 'processor', 'perform', 'obtain', 'image', 'acquire', 'capture', 'apparatus', 'obtain', 'motion', 'parameter', 'terminal', 'terminal', 'comprise', 'capture', 'apparatus', 'motion', 'parameter', 'comprise', 'least', 'one', 'motion', 'frequency', 'motion', 'time', 'two', 'parameter', 'among', 'acceleration', 'angular', 'velocity', 'motion', 'amplitude', 'motion', 'frequency', 'motion', 'time', 'transmit', 'parameter', 'threshold', 'obtain', 'request', 'data', 'management', 'server', 'parameter', 'threshold', 'obtain', 'request', 'comprise', 'configuration', 'information', 'terminal', 'receiving', 'correspond', 'preset', 'threshold', 'correspond', 'configuration', 'information', 'response', 'parameter', 'threshold', 'obtain', 'request', 'compare', 'two', 'parameter', 'correspond', 'preset', 'threshold', 'control', 'perform', 'image', 'processing', 'acquire', 'image', 'base', 'least', 'one', 'two', 'parameter', 'motion', 'parameter', 'great', 'correspond', 'preset', 'threshold', 'base', 'two', 'parameter', 'motion', 'parameter', 'respectively', 'great', 'correspond', 'preset', 'threshold', 'wherein', 'acquire', 'comprises', 'acquire', 'image', 'real', 'time', 'obtain', 'comprises', 'obtain', 'motion', 'parameter', 'terminal', 'real', 'time', 'method', 'comprise', 'response', 'least', 'one', 'two', 'parameter', 'motion', 'parameter', 'great', 'correspond', 'preset', 'threshold', 'obtain', 'motion', 'parameter', 'terminal', 'response', 'two', 'parameter', 'motion', 'parameter', 'obtain', 'late', 'time', 'le', 'equal', 'corresponding', 'preset', 'threshold', 'perform', 'image', 'processing', 'image', 'acquire', 'late', 'time', 'non-transitory', 'computer-readable', 'storage', 'medium', 'accord', 'claim', 'wherein', 'acquire', 'image', 'face', 'image', 'image', 'processing', 'comprise', 'perform', 'face', 'recognition', 'non-transitory', 'computer-readable', 'storage', 'medium', 'accord', 'claim', 'wherein', 'obtain', 'motion', 'parameter', 'comprise', 'least', 'one', 'obtain', 'acceleration', 'terminal', 'use', 'acceleration', 'sensor', 'obtain', 'angular', 'velocity', 'terminal', 'use', 'gyro', 'sensor', 'non-transitory', 'computer-readable', 'storage', 'medium', 'accord', 'claim', 'wherein', 'motion', 'parameter', 'comprise', 'motion', 'frequency', 'motion', 'time', 'method', 'process', 'drive-through', 'order', 'method', 'comprise', 'receive', 'customer', 'information', 'detect', 'vision', 'recognition', 'provide', 'product', 'information', 'customer', 'base', 'customer', 'information', 'process', 'product', 'order', 'customer', 'method', 'accord', 'claim', 'wherein', 'receive', 'customer', 'information', 'comprise', 'least', 'one', 'receive', 'customer', 'information', 'associate', 'vehicle', 'information', 'detect', 'vehicle', 'recognition', 'receive', 'customer', 'information', 'associate', 'identification', 'information', 'detect', 'face', 'recognition', 'method', 'accord', 'claim', 'comprise', 'determine', 'whether', 'customer', 'pre-order', 'customer', 'base', 'customer', 'information', 'wherein', 'customer', 'determine', 'pre-order', 'customer', 'provide', 'product', 'information', 'base', 'customer', 'information', 'comprise', 'provide', 'pre-order', 'information', 'use', 'least', 'one', 'audio', 'video', 'process', 'product', 'order', 'customer', 'comprise', 'provide', 'information', 'promptly', 'guide', 'vehicle', 'pickup', 'stand', 'use', 'least', 'one', 'audio', 'video', 'provide', 'information', 'additional', 'order', 'available', 'method', 'accord', 'claim', 'wherein', 'product', 'information', 'base', 'customer', 'information', 'comprise', 'recently', 'order', 'product', 'component', 'frequently', 'order', 'product', 'component', 'order', 'history', 'customer', 'information', 'method', 'accord', 'claim', 'wherein', 'receive', 'customer', 'information', 'comprise', 'receive', 'information', 'age', 'gender', 'passenger', 'detect', 'face', 'recognition', 'provide', 'product', 'information', 'customer', 'base', 'customer', 'information', 'comprise', 'provide', 'recommend', 'menu', 'information', 'differentiate', 'accord', 'age', 'gender', 'method', 'accord', 'claim', 'wherein', 'process', 'product', 'order', 'customer', 'comprise', 'determine', 'product', 'component', 'past', 'order', 'history', 'component', 'modify', 'product', 'component', 'product', 'order', 'method', 'accord', 'claim', 'wherein', 'process', 'product', 'order', 'customer', 'comprise', 'pay', 'product', 'price', 'accord', 'biometrics-based', 'authentication', 'communication', 'system', 'vehicle', 'mobile', 'terminal', 'method', 'accord', 'claim', 'wherein', 'process', 'product', 'order', 'customer', 'comprise', 'issue', 'payment', 'number', 'divide', 'payment', 'perform', 'divide', 'payment', 'accord', 'payment', 'request', 'plurality', 'mobile', 'terminal', 'payment', 'number', 'inputted', 'method', 'accord', 'claim', 'wherein', 'process', 'product', 'order', 'customer', 'comprise', 'accumulate', 'mileage', 'account', 'correspond', 'mobile', 'terminal', 'undergoing', 'payment', 'method', 'accord', 'claim', 'wherein', 'process', 'product', 'order', 'customer', 'comprise', 'suggest', 'takeout', 'package', 'method', 'accord', 'temperature', 'product', 'atmospheric', 'temperature', 'weather', 'vehicle', 'type', 'apparatus', 'configure', 'process', 'drive-through', 'order', 'apparatus', 'comprise', 'transceiver', 'configure', 'receive', 'customer', 'information', 'detect', 'vision', 'recognition', 'digital', 'signage', 'configure', 'provide', 'product', 'information', 'customer', 'base', 'customer', 'information', 'processor', 'configure', 'process', 'product', 'order', 'customer', 'apparatus', 'accord', 'claim', 'wherein', 'transceiver', 'receive', 'least', 'one', 'customer', 'information', 'associate', 'vehicle', 'information', 'detect', 'vehicle', 'recognition', 'customer', 'information', 'associate', 'identification', 'information', 'detect', 'face', 'recognition', 'apparatus', 'accord', 'claim', 'wherein', 'processor', 'configure', 'determine', 'whether', 'customer', 'pre-order', 'customer', 'base', 'customer', 'information', 'customer', 'determine', 'pre-order', 'customer', 'perform', 'control', 'operation', 'provide', 'pre-order', 'information', 'control', 'digital', 'signage', 'output', 'information', 'promptly', 'guide', 'vehicle', 'pickup', 'stand', 'provide', 'information', 'additional', 'order', 'available', 'apparatus', 'accord', 'claim', 'wherein', 'product', 'information', 'base', 'customer', 'information', 'comprise', 'recently', 'order', 'product', 'component', 'frequently', 'order', 'product', 'component', 'order', 'history', 'customer', 'information', 'apparatus', 'accord', 'claim', 'wherein', 'transceiver', 'configure', 'receive', 'information', 'age', 'gender', 'passenger', 'detect', 'face', 'recognition', 'processor', 'configure', 'control', 'digital', 'signage', 'provide', 'recommend', 'menu', 'information', 'differentiate', 'accord', 'age', 'gender', 'apparatus', 'accord', 'claim', 'wherein', 'processor', 'configure', 'determine', 'product', 'component', 'past', 'order', 'history', 'component', 'modify', 'product', 'component', 'product', 'order', 'apparatus', 'accord', 'claim', 'wherein', 'processor', 'configure', 'pay', 'product', 'price', 'accord', 'biometrics-based', 'authentication', 'communication', 'system', 'vehicle', 'mobile', 'terminal', 'apparatus', 'accord', 'claim', 'wherein', 'processor', 'configure', 'issue', 'payment', 'number', 'divide', 'payment', 'perform', 'divide', 'payment', 'accord', 'request', 'plurality', 'mobile', 'terminal', 'payment', 'number', 'inputted', 'apparatus', 'accord', 'claim', 'wherein', 'processor', 'configure', 'accumulate', 'mileage', 'account', 'correspond', 'mobile', 'terminal', 'undergoing', 'payment', 'apparatus', 'accord', 'claim', 'wherein', 'processor', 'configure', 'control', 'digital', 'signage', 'suggest', 'takeout', 'packaging', 'method', 'accord', 'temperature', 'product', 'atmospheric', 'temperature', 'weather', 'vehicle', 'type', 'image', 'information', 'process', 'method', 'perform', 'compute', 'device', 'one', 'processor', 'memory', 'store', 'plurality', 'program', 'execute', 'one', 'processor', 'method', 'comprise', 'identify', 'use', 'face', 'recognition', 'one', 'face', 'face', 'correspond', 'respective', 'person', 'capture', 'first', 'image', 'identify', 'face', 'extract', 'set', 'profile', 'parameter', 'correspond', 'person', 'first', 'image', 'select', 'plurality', 'image', 'tile', 'first', 'image', 'tile', 'match', 'face', 'correspond', 'person', 'first', 'image', 'accordance', 'predefined', 'correspondence', 'set', 'profile', 'parameter', 'correspond', 'person', 'set', 'pre-stored', 'description', 'parameter', 'first', 'image', 'tile', 'generate', 'second', 'image', 'cover', 'face', 'respective', 'person', 'first', 'image', 'correspond', 'first', 'image', 'tile', 'share', 'first', 'image', 'second', 'image', 'predefined', 'order', 'via', 'group', 'chat', 'session', 'method', 'claim', 'wherein', 'first', 'image', 'second', 'image', 'display', 'group', 'chat', 'session', 'one', 'image', 'time', 'one', 'two', 'image', 'replace', 'two', 'image', 'periodically', 'method', 'claim', 'wherein', 'extract', 'set', 'profile', 'parameter', 'correspond', 'person', 'first', 'image', 'include', 'determine', 'one', 'descriptive', 'label', 'correspond', 'identified', 'face', 'correspond', 'person', 'use', 'first', 'machine', 'learn', 'model', 'wherein', 'first', 'machine', 'learn', 'model', 'train', 'facial', 'image', 'correspond', 'descriptive', 'label', 'method', 'claim', 'wherein', 'extract', 'set', 'profile', 'parameter', 'correspond', 'person', 'first', 'image', 'include', 'determine', 'identity', 'correspond', 'person', 'base', 'identified', 'face', 'correspond', 'person', 'locate', 'respective', 'profile', 'information', 'first', 'person', 'base', 'determine', 'identity', 'correspond', 'person', 'use', 'one', 'characteristic', 'respective', 'profile', 'information', 'first', 'person', 'set', 'profile', 'parameter', 'correspond', 'identified', 'face', 'correspond', 'person', 'method', 'claim', 'wherein', 'least', 'first', 'one', 'first', 'image', 'tile', 'dynamic', 'image', 'tile', 'least', 'second', 'one', 'first', 'image', 'tile', 'static', 'image', 'tile', 'method', 'claim', 'include', 'receive', 'plurality', 'user', 'comment', 'different', 'user', 'group', 'chat', 'session', 'user', 'comment', 'include', 'descriptive', 'term', 'respective', 'person', 'identify', 'first', 'image', 'choose', 'descriptive', 'label', 'respective', 'person', 'accord', 'plurality', 'user', 'comment', 'update', 'second', 'image', 'add', 'descriptive', 'label', 'adjacent', 'first', 'image', 'tile', 'respective', 'person', 'compute', 'device', 'image', 'information', 'process', 'comprise', 'one', 'processor', 'memory', 'store', 'instruction', 'execute', 'one', 'processor', 'cause', 'processor', 'perform', 'plurality', 'operation', 'comprise', 'identify', 'use', 'face', 'recognition', 'one', 'face', 'face', 'correspond', 'respective', 'person', 'capture', 'first', 'image', 'identify', 'face', 'extract', 'set', 'profile', 'parameter', 'correspond', 'person', 'first', 'image', 'select', 'plurality', 'image', 'tile', 'first', 'image', 'tile', 'match', 'face', 'correspond', 'person', 'first', 'image', 'accordance', 'predefined', 'correspondence', 'set', 'profile', 'parameter', 'correspond', 'person', 'set', 'pre-stored', 'description', 'parameter', 'first', 'image', 'tile', 'generate', 'second', 'image', 'cover', 'face', 'respective', 'person', 'first', 'image', 'correspond', 'first', 'image', 'tile', 'share', 'first', 'image', 'second', 'image', 'predefined', 'order', 'via', 'group', 'chat', 'session', 'compute', 'device', 'claim', 'wherein', 'first', 'image', 'second', 'image', 'display', 'group', 'chat', 'session', 'one', 'image', 'time', 'one', 'two', 'image', 'replace', 'two', 'image', 'periodically', 'compute', 'device', 'claim', 'wherein', 'extract', 'set', 'profile', 'parameter', 'correspond', 'person', 'first', 'image', 'include', 'determine', 'one', 'descriptive', 'label', 'correspond', 'identified', 'face', 'correspond', 'person', 'use', 'first', 'machine', 'learn', 'model', 'wherein', 'first', 'machine', 'learn', 'model', 'train', 'facial', 'image', 'correspond', 'descriptive', 'label', 'compute', 'device', 'claim', 'wherein', 'extract', 'set', 'profile', 'parameter', 'correspond', 'person', 'first', 'image', 'include', 'determine', 'identity', 'correspond', 'person', 'base', 'identified', 'face', 'correspond', 'person', 'locate', 'respective', 'profile', 'information', 'first', 'person', 'base', 'determine', 'identity', 'correspond', 'person', 'use', 'one', 'characteristic', 'respective', 'profile', 'information', 'first', 'person', 'set', 'profile', 'parameter', 'correspond', 'identified', 'face', 'correspond', 'person', 'compute', 'device', 'claim', 'wherein', 'least', 'first', 'one', 'first', 'image', 'tile', 'dynamic', 'image', 'tile', 'least', 'second', 'one', 'first', 'image', 'tile', 'static', 'image', 'tile', 'compute', 'device', 'claim', 'wherein', 'plurality', 'operation', 'include', 'receive', 'plurality', 'user', 'comment', 'different', 'user', 'group', 'chat', 'session', 'user', 'comment', 'include', 'descriptive', 'term', 'respective', 'person', 'identify', 'first', 'image', 'choose', 'descriptive', 'label', 'respective', 'person', 'accord', 'plurality', 'user', 'comment', 'update', 'second', 'image', 'add', 'descriptive', 'label', 'adjacent', 'first', 'image', 'tile', 'respective', 'person', 'non-transitory', 'computer-readable', 'storage', 'medium', 'store', 'instruction', 'execute', 'compute', 'device', 'one', 'processor', 'cause', 'compute', 'device', 'perform', 'plurality', 'operation', 'comprise', 'identify', 'use', 'face', 'recognition', 'one', 'face', 'face', 'correspond', 'respective', 'person', 'capture', 'first', 'image', 'identify', 'face', 'extract', 'set', 'profile', 'parameter', 'correspond', 'person', 'first', 'image', 'select', 'plurality', 'image', 'tile', 'first', 'image', 'tile', 'match', 'face', 'correspond', 'person', 'first', 'image', 'accordance', 'predefined', 'correspondence', 'set', 'profile', 'parameter', 'correspond', 'person', 'set', 'pre-stored', 'description', 'parameter', 'first', 'image', 'tile', 'generate', 'second', 'image', 'cover', 'face', 'respective', 'person', 'first', 'image', 'correspond', 'first', 'image', 'tile', 'share', 'first', 'image', 'second', 'image', 'predefined', 'order', 'via', 'group', 'chat', 'session', 'non-transitory', 'computer-readable', 'storage', 'medium', 'claim', 'wherein', 'first', 'image', 'second', 'image', 'display', 'group', 'chat', 'session', 'one', 'image', 'time', 'one', 'two', 'image', 'replace', 'two', 'image', 'periodically', 'non-transitory', 'computer-readable', 'storage', 'medium', 'claim', 'wherein', 'extract', 'set', 'profile', 'parameter', 'correspond', 'person', 'first', 'image', 'include', 'determine', 'one', 'descriptive', 'label', 'correspond', 'identified', 'face', 'correspond', 'person', 'use', 'first', 'machine', 'learn', 'model', 'wherein', 'first', 'machine', 'learn', 'model', 'train', 'facial', 'image', 'correspond', 'descriptive', 'label', 'non-transitory', 'computer-readable', 'storage', 'medium', 'claim', 'wherein', 'extract', 'set', 'profile', 'parameter', 'correspond', 'person', 'first', 'image', 'include', 'determine', 'identity', 'correspond', 'person', 'base', 'identified', 'face', 'correspond', 'person', 'locate', 'respective', 'profile', 'information', 'first', 'person', 'base', 'determine', 'identity', 'correspond', 'person', 'use', 'one', 'characteristic', 'respective', 'profile', 'information', 'first', 'person', 'set', 'profile', 'parameter', 'correspond', 'identified', 'face', 'correspond', 'person', 'non-transitory', 'computer-readable', 'storage', 'medium', 'claim', 'wherein', 'least', 'first', 'one', 'first', 'image', 'tile', 'dynamic', 'image', 'tile', 'least', 'second', 'one', 'first', 'image', 'tile', 'static', 'image', 'tile', 'non-transitory', 'computer-readable', 'storage', 'medium', 'claim', 'wherein', 'plurality', 'operation', 'include', 'receive', 'plurality', 'user', 'comment', 'different', 'user', 'group', 'chat', 'session', 'user', 'comment', 'include', 'descriptive', 'term', 'respective', 'person', 'identify', 'first', 'image', 'choose', 'descriptive', 'label', 'respective', 'person', 'accord', 'plurality', 'user', 'comment', 'update', 'second', 'image', 'add', 'descriptive', 'label', 'adjacent', 'first', 'image', 'tile', 'respective', 'person', 'method', 'comprise', 'compute', 'system', 'determine', 'performance', 'metric', 'eye', 'track', 'system', 'first', 'performance', 'threshold', 'wherein', 'eye', 'track', 'system', 'associate', 'head-mounted', 'display', 'wear', 'user', 'base', 'determination', 'performance', 'metric', 'eye', 'track', 'system', 'first', 'performance', 'threshold', 'computer', 'system', 'perform', 'receive', 'one', 'first', 'input', 'associate', 'body', 'user', 'estimate', 'region', 'user', 'look', 'within', 'field', 'view', 'head-mounted', 'display', 'base', 'receive', 'one', 'first', 'input', 'associate', 'body', 'user', 'determine', 'vergence', 'distance', 'user', 'base', 'least', 'one', 'first', 'input', 'associate', 'body', 'user', 'estimate', 'region', 'user', 'look', 'location', 'one', 'object', 'scene', 'display', 'head-mounted', 'display', 'adjust', 'one', 'configuration', 'head-mounted', 'display', 'base', 'determined', 'vergence', 'distance', 'user', 'method', 'claim', 'wherein', 'one', 'configuration', 'head-mounted', 'display', 'comprise', 'one', 'rendering', 'image', 'position', 'display', 'screen', 'position', 'optic', 'block', 'method', 'claim', 'comprise', 'determine', 'performance', 'metric', 'eye', 'track', 'system', 'second', 'performance', 'threshold', 'receive', 'eye', 'track', 'data', 'eye', 'track', 'system', 'determine', 'vergence', 'distance', 'user', 'base', 'eye', 'track', 'data', 'one', 'first', 'input', 'associate', 'body', 'user', 'method', 'claim', 'comprise', 'receive', 'one', 'second', 'input', 'associate', 'one', 'displaying', 'element', 'scene', 'display', 'head-mounted', 'display', 'determine', 'vergence', 'distance', 'user', 'base', 'least', 'eye', 'track', 'data', 'one', 'first', 'input', 'associate', 'body', 'user', 'one', 'second', 'input', 'associate', 'one', 'displaying', 'element', 'scene', 'method', 'claim', 'comprise', 'feed', 'one', 'first', 'input', 'associate', 'body', 'user', 'fusion', 'algorithm', 'wherein', 'fusion', 'algorithm', 'assigns', 'weight', 'score', 'input', 'one', 'first', 'input', 'determine', 'vergence', 'distance', 'user', 'use', 'fusion', 'algorithm', 'base', 'one', 'first', 'input', 'associate', 'body', 'user', 'determine', 'z-depth', 'display', 'screen', 'confidence', 'score', 'base', 'one', 'first', 'input', 'associate', 'body', 'user', 'method', 'claim', 'comprise', 'compare', 'confidence', 'score', 'confidence', 'level', 'threshold', 'response', 'determination', 'confidence', 'score', 'confidence', 'level', 'threshold', 'feed', 'one', 'second', 'input', 'associate', 'one', 'displaying', 'element', 'scene', 'fusion', 'algorithm', 'determine', 'z-depth', 'display', 'screen', 'use', 'fusion', 'algorithm', 'base', 'one', 'first', 'input', 'associate', 'body', 'user', 'one', 'second', 'input', 'associate', 'one', 'displaying', 'element', 'scene', 'method', 'claim', 'compare', 'compare', 'fusion', 'algorithm', 'confidence', 'score', 'associate', 'plurality', 'combination', 'input', 'determine', 'fusion', 'algorithm', 'z-depth', 'display', 'screen', 'base', 'combination', 'input', 'associate', 'high', 'confidence', 'score', 'method', 'claim', 'wherein', 'z-depth', 'confidence', 'score', 'determine', 'fusion', 'algorithm', 'use', 'piecewise', 'comparison', 'one', 'first', 'input', 'one', 'second', 'input', 'method', 'claim', 'wherein', 'z-depth', 'confidence', 'score', 'determine', 'base', 'correlation', 'two', 'input', 'one', 'first', 'input', 'one', 'second', 'input', 'method', 'claim', 'wherein', 'fusion', 'algorithm', 'comprise', 'machine', 'learn', 'ml', 'algorithm', 'wherein', 'machine', 'learn', 'ml', 'algorithm', 'determines', 'combination', 'first', 'input', 'fed', 'fusion', 'algorithm', 'method', 'claim', 'wherein', 'one', 'first', 'input', 'associate', 'body', 'user', 'comprise', 'one', 'hand', 'position', 'hand', 'direction', 'hand', 'movement', 'hand', 'gesture', 'head', 'position', 'head', 'direction', 'head', 'movement', 'head', 'gesture', 'gaze', 'angle', 'rea', 'body', 'gesture', 'body', 'posture', 'body', 'movement', 'behavior', 'user', 'weight', 'combination', 'one', 'related', 'parameter', 'method', 'claim', 'wherein', 'one', 'first', 'input', 'associate', 'body', 'user', 'receive', 'one', 'controller', 'sensor', 'camera', 'microphone', 'accelerometer', 'headset', 'worn', 'user', 'mobile', 'device', 'method', 'claim', 'wherein', 'one', 'second', 'input', 'associate', 'one', 'displaying', 'element', 'comprise', 'one', 'z-buffer', 'value', 'associate', 'display', 'element', 'display', 'element', 'mark', 'developer', 'image', 'analysis', 'result', 'shape', 'display', 'element', 'face', 'recognition', 'result', 'object', 'recognition', 'result', 'person', 'identify', 'display', 'content', 'object', 'identify', 'display', 'content', 'correlation', 'two', 'display', 'element', 'weight', 'combination', 'one', 'second', 'input', 'method', 'claim', 'comprise', 'determine', 'performance', 'metric', 'eye', 'track', 'system', 'second', 'performance', 'threshold', 'receive', 'one', 'second', 'input', 'associate', 'one', 'displaying', 'element', 'scene', 'display', 'head-mounted', 'display', 'determine', 'vergence', 'distance', 'user', 'base', 'least', 'one', 'first', 'input', 'associate', 'body', 'user', 'one', 'second', 'input', 'associate', 'one', 'displaying', 'element', 'method', 'claim', 'wherein', 'determine', 'performance', 'metric', 'eye', 'track', 'system', 'second', 'performance', 'threshold', 'comprise', 'determine', 'eye', 'track', 'system', 'exist', 'fails', 'provide', 'eye', 'track', 'data', 'method', 'claim', 'wherein', 'performance', 'metric', 'eye', 'track', 'system', 'comprise', 'one', 'accuracy', 'parameter', 'eye', 'track', 'system', 'precision', 'parameter', 'eye', 'track', 'system', 'value', 'parameter', 'eye', 'track', 'system', 'detectability', 'pupil', 'metric', 'base', 'one', 'parameter', 'associate', 'user', 'parameter', 'change', 'parameter', 'change', 'trend', 'data', 'availability', 'weight', 'combination', 'one', 'performance', 'related', 'parameter', 'method', 'claim', 'wherein', 'one', 'parameter', 'associate', 'user', 'comprise', 'one', 'eye', 'distance', 'user', 'pupil', 'position', 'pupil', 'status', 'correlation', 'two', 'pupil', 'user', 'head', 'size', 'user', 'position', 'headset', 'worn', 'user', 'angle', 'headset', 'worn', 'user', 'direction', 'headset', 'worn', 'user', 'alignment', 'eye', 'user', 'weight', 'combination', 'one', 'related', 'parameter', 'associate', 'user', 'method', 'claim', 'wherein', 'first', 'performance', 'threshold', 'comprise', 'one', 'pre-determined', 'value', 'pre-determined', 'range', 'state', 'data', 'change', 'speed', 'data', 'trend', 'data', 'change', 'one', 'non-transitory', 'computer-readable', 'storage', 'medium', 'embody', 'software', 'operable', 'execute', 'computing', 'system', 'determine', 'performance', 'metric', 'eye', 'track', 'system', 'first', 'performance', 'threshold', 'wherein', 'eye', 'track', 'system', 'associate', 'head-mounted', 'display', 'wear', 'user', 'base', 'determination', 'performance', 'metric', 'eye', 'track', 'system', 'first', 'performance', 'threshold', 'medium', 'embody', 'software', 'operable', 'execute', 'compute', 'system', 'receive', 'one', 'first', 'input', 'associate', 'body', 'user', 'estimate', 'region', 'user', 'look', 'within', 'field', 'view', 'head-mounted', 'display', 'base', 'receive', 'one', 'first', 'input', 'associate', 'body', 'user', 'determine', 'vergence', 'distance', 'user', 'base', 'least', 'one', 'first', 'input', 'associate', 'body', 'user', 'estimate', 'region', 'user', 'look', 'location', 'one', 'object', 'scene', 'display', 'head-mounted', 'display', 'adjust', 'one', 'configuration', 'head-mounted', 'display', 'base', 'determined', 'vergence', 'distance', 'user', 'system', 'comprise', 'one', 'non-transitory', 'computer-readable', 'storage', 'medium', 'embody', 'instruction', 'one', 'processor', 'couple', 'storage', 'medium', 'operable', 'execute', 'instruction', 'determine', 'performance', 'metric', 'eye', 'track', 'system', 'first', 'performance', 'threshold', 'wherein', 'eye', 'track', 'system', 'associate', 'head-mounted', 'display', 'wear', 'user', 'base', 'determination', 'performance', 'metric', 'eye', 'track', 'system', 'first', 'performance', 'threshold', 'system', 'configure', 'receive', 'one', 'first', 'input', 'associate', 'body', 'user', 'estimate', 'region', 'user', 'look', 'within', 'field', 'view', 'head-mounted', 'display', 'base', 'receive', 'one', 'first', 'input', 'associate', 'body', 'user', 'determine', 'vergence', 'distance', 'user', 'base', 'least', 'one', 'first', 'input', 'associate', 'body', 'user', 'estimate', 'region', 'user', 'look', 'location', 'one', 'object', 'scene', 'display', 'head-mounted', 'display', 'adjust', 'one', 'configuration', 'head-mounted', 'display', 'base', 'determined', 'vergence', 'distance', 'user', 'computer-implemented', 'method', 'image-based', 'self-guided', 'object', 'detection', 'comprise', 'receive', 'processor', 'device', 'set', 'image', 'image', 'respective', 'grid', 'thereon', 'label', 'regard', 'respective', 'object', 'detect', 'use', 'grid', 'level', 'label', 'data', 'training', 'processor', 'device', 'grid-based', 'object', 'detector', 'use', 'grid', 'level', 'label', 'data', 'determine', 'processor', 'device', 'respective', 'bound', 'box', 'respective', 'object', 'image', 'apply', 'local', 'segmentation', 'image', 'train', 'processor', 'device', 'region-based', 'convolutional', 'neural', 'network', 'rcnn', 'joint', 'object', 'localization', 'object', 'classification', 'use', 'respective', 'bounding', 'box', 'respective', 'object', 'image', 'input', 'rcnn', 'computer-implemented', 'method', 'claim', 'comprise', 'perform', 'action', 'responsive', 'object', 'localization', 'object', 'classification', 'respective', 'new', 'object', 'new', 'image', 'rcnn', 'apply', 'computer-implemented', 'method', 'claim', 'wherein', 'action', 'comprise', 'autonomously', 'control', 'motor', 'vehicle', 'avoid', 'collision', 'new', 'object', 'responsive', 'object', 'localization', 'object', 'classification', 'respective', 'new', 'object', 'computer-implemented', 'method', 'claim', 'wherein', 'local', 'segmentation', 'perform', 'use', 'self-similarity', 'search', 'template', 'match', 'provide', 'respective', 'bound', 'box', 'around', 'respective', 'object', 'set', 'image', 'computer-implemented', 'method', 'claim', 'wherein', 'local', 'segmentation', 'apply', 'image', 'segment', 'respective', 'target', 'region', 'therein', 'computer-implemented', 'method', 'claim', 'wherein', 'region-based', 'convolutional', 'neural', 'network', 'rcnn', 'form', 'model', 'object', 'training', 'stage', 'detect', 'object', 'new', 'image', 'inference', 'stage', 'computer-implemented', 'method', 'claim', 'wherein', 'method', 'perform', 'system', 'select', 'group', 'consist', 'surveillance', 'system', 'face', 'detection', 'system', 'face', 'recognition', 'system', 'cancer', 'detection', 'system', 'object', 'track', 'system', 'advance', 'driver-assistance', 'system', 'computer', 'program', 'product', 'image-based', 'self-guided', 'object', 'detection', 'computer', 'program', 'product', 'comprise', 'non-transitory', 'computer', 'readable', 'storage', 'medium', 'program', 'instruction', 'embody', 'therewith', 'program', 'instruction', 'executable', 'computer', 'cause', 'computer', 'perform', 'method', 'comprise', 'receive', 'processor', 'device', 'set', 'image', 'image', 'respective', 'grid', 'thereon', 'label', 'regard', 'respective', 'object', 'detect', 'use', 'grid', 'level', 'label', 'data', 'training', 'processor', 'device', 'grid-based', 'object', 'detector', 'use', 'grid', 'level', 'label', 'data', 'determine', 'processor', 'device', 'respective', 'bound', 'box', 'respective', 'object', 'image', 'apply', 'local', 'segmentation', 'image', 'train', 'processor', 'device', 'region-based', 'convolutional', 'neural', 'network', 'rcnn', 'joint', 'object', 'localization', 'object', 'classification', 'use', 'respective', 'bounding', 'box', 'respective', 'object', 'image', 'input', 'rcnn', 'computer', 'program', 'product', 'claim', 'wherein', 'method', 'comprise', 'perform', 'action', 'responsive', 'object', 'localization', 'object', 'classification', 'respective', 'new', 'object', 'new', 'image', 'rcnn', 'apply', 'computer', 'program', 'product', 'claim', 'wherein', 'action', 'comprise', 'autonomously', 'control', 'motor', 'vehicle', 'avoid', 'collision', 'new', 'object', 'responsive', 'object', 'localization', 'object', 'classification', 'respective', 'new', 'object', 'computer', 'program', 'product', 'claim', 'wherein', 'local', 'segmentation', 'perform', 'use', 'self-similarity', 'search', 'template', 'match', 'provide', 'respective', 'bound', 'box', 'around', 'respective', 'object', 'set', 'image', 'computer', 'program', 'product', 'claim', 'wherein', 'local', 'segmentation', 'apply', 'image', 'segment', 'respective', 'target', 'region', 'therein', 'computer', 'program', 'product', 'claim', 'wherein', 'region-based', 'convolutional', 'neural', 'network', 'rcnn', 'form', 'model', 'object', 'training', 'stage', 'detect', 'object', 'new', 'image', 'inference', 'stage', 'computer', 'program', 'product', 'claim', 'wherein', 'method', 'perform', 'system', 'select', 'group', 'consist', 'surveillance', 'system', 'face', 'detection', 'system', 'face', 'recognition', 'system', 'cancer', 'detection', 'system', 'object', 'track', 'system', 'advance', 'driver-assistance', 'system', 'computer', 'process', 'system', 'image-based', 'self-guided', 'object', 'detection', 'comprise', 'memory', 'device', 'store', 'program', 'code', 'processor', 'device', 'run', 'program', 'code', 'receive', 'set', 'image', 'image', 'respective', 'grid', 'thereon', 'label', 'regard', 'respective', 'object', 'detect', 'use', 'grid', 'level', 'label', 'data', 'train', 'grid-based', 'object', 'detector', 'use', 'grid', 'level', 'label', 'data', 'determine', 'respective', 'bounding', 'box', 'respective', 'object', 'image', 'apply', 'local', 'segmentation', 'image', 'train', 'region-based', 'convolutional', 'neural', 'network', 'rcnn', 'joint', 'object', 'localization', 'object', 'classification', 'use', 'respective', 'bounding', 'box', 'respective', 'object', 'image', 'input', 'rcnn', 'computer', 'processing', 'system', 'claim', 'wherein', 'processor', 'device', 'run', 'program', 'code', 'perform', 'action', 'responsive', 'object', 'localization', 'object', 'classification', 'respective', 'new', 'object', 'new', 'image', 'rcnn', 'apply', 'computer', 'processing', 'system', 'claim', 'wherein', 'action', 'comprise', 'autonomously', 'control', 'motor', 'vehicle', 'avoid', 'collision', 'new', 'object', 'responsive', 'object', 'localization', 'object', 'classification', 'respective', 'new', 'object', 'computer', 'processing', 'system', 'claim', 'wherein', 'local', 'segmentation', 'perform', 'use', 'self-similarity', 'search', 'template', 'match', 'provide', 'respective', 'bound', 'box', 'around', 'respective', 'object', 'set', 'image', 'computer', 'processing', 'system', 'claim', 'wherein', 'region-based', 'convolutional', 'neural', 'network', 'rcnn', 'form', 'model', 'object', 'training', 'stage', 'detect', 'object', 'new', 'image', 'inference', 'stage', 'computer', 'processing', 'system', 'claim', 'wherein', 'computer', 'processing', 'system', 'comprise', 'system', 'select', 'group', 'consist', 'surveillance', 'system', 'face', 'detection', 'system', 'face', 'recognition', 'system', 'cancer', 'detection', 'system', 'object', 'track', 'system', 'advance', 'driver-assistance', 'system', 'method', 'scalable', 'parallel', 'cloud-based', 'face', 'recognition', 'utilize', 'database', 'normalize', 'stored', 'image', 'comprise', 'capture', 'image', 'use', 'camera', 'detect', 'face', 'capture', 'image', 'normalize', 'detect', 'facial', 'image', 'match', 'normalize', 'stored', 'image', 'identify', 'facial', 'feature', 'normalize', 'detected', 'facial', 'image', 'generate', 'plurality', 'facial', 'metric', 'facial', 'feature', 'calculate', 'euclidean', 'distance', 'facial', 'metric', 'normalize', 'detected', 'facial', 'image', 'correspond', 'facial', 'metric', 'store', 'image', 'compare', 'euclidean', 'distance', 'predetermine', 'threshold', 'responsive', 'euclidean', 'distance', 'comparison', 'produce', 'reduced', 'candidate', 'list', 'best', 'possible', 'image', 'match', 'normalize', 'stored', 'image', 'compare', 'parallel', 'normalize', 'detected', 'facial', 'image', 'normalize', 'stored', 'image', 'reduce', 'candidate', 'list', 'utilize', 'plurality', 'face', 'recognition', 'algorithm', 'processor', 'parallel', 'process', 'system', 'use', 'different', 'face', 'recognition', 'algorithm', 'responsive', 'comparison', 'produce', 'best', 'match', 'result', 'parallel', 'subset', 'reduce', 'candidate', 'list', 'select', 'final', 'match', 'best', 'match', 'result', 'use', 'deep', 'learn', 'neural', 'network', 'face', 'recognition', 'algorithm', 'train', 'output', 'individual', 'face', 'recognition', 'algorithm', 'method', 'scalable', 'parallel', 'cloud-based', 'face', 'recognition', 'claim', 'wherein', 'detect', 'face', 'capture', 'image', 'comprise', 'utilize', 'opencv', 'detect', 'face', 'capture', 'image', 'extract', 'location', 'eye', 'tip', 'nose', 'face', 'determine', 'distance', 'eye', 'crop', 'face', 'capture', 'image', 'width', 'height', 'cropped', 'face', 'image', 'function', 'distance', 'eye', 'rotate', 'face', 'angle', 'rotation', 'function', 'distance', 'eye', 'method', 'scalable', 'parallel', 'cloud-based', 'face', 'recognition', 'claim', 'wherein', 'width', 'crop', 'face', 'image', 'time', 'distance', 'eye', 'height', 'crop', 'face', 'image', 'time', 'distance', 'eye', 'angle', 'rotation', 'angle', 'form', 'straight', 'line', 'join', 'eye', 'x-axis', 'face', 'method', 'scalable', 'parallel', 'cloud-based', 'face', 'recognition', 'claim', 'wherein', 'rotate', 'face', 'comprises', 'rotate', 'face', 'provide', 'frontal', 'face', 'pattern', 'method', 'scalable', 'parallel', 'cloud-based', 'face', 'recognition', 'claim', 'comprise', 'step', 'proportionally', 'rescale', 'crop', 'rotate', 'image', 'method', 'scalable', 'parallel', 'cloud-based', 'face', 'recognition', 'claim', 'proportional', 'rescaling', 'yield', 'crop', 'rotate', 'image', 'size', 'pixel', 'method', 'scalable', 'parallel', 'cloud-based', 'face', 'recognition', 'claim', 'wherein', 'facial', 'feature', 'identify', 'normalized', 'detect', 'facial', 'image', 'comprise', 'pair', 'eye', 'tip', 'nose', 'mouth', 'center', 'mouth', 'chin', 'area', 'comprise', 'bottom', 'top', 'leave', 'landmark', 'top', 'right', 'landmark', 'method', 'scalable', 'parallel', 'cloud-based', 'face', 'recognition', 'claim', 'wherein', 'generate', 'plurality', 'facial', 'metric', 'comprises', 'calculate', 'distance', 'pair', 'eye', 'distance', 'eye', 'tip', 'nose', 'distance', 'equal', 'width', 'mouth', 'distance', 'tip', 'nose', 'center', 'mouth', 'distance', 'bottom', 'chin', 'center', 'mouth', 'distance', 'top', 'leave', 'landmark', 'chin', 'tip', 'nose', 'distance', 'top', 'right', 'landmark', 'chin', 'tip', 'nose', 'method', 'scalable', 'parallel', 'cloud-based', 'face', 'recognition', 'claim', 'wherein', 'perform', 'euclidean', 'distance', 'match', 'comprise', 'partition', 'normalize', 'stored', 'image', 'plurality', 'substantially', 'equal', 'subset', 'perform', 'euclidean', 'distance', 'match', 'facial', 'metric', 'normalize', 'detected', 'facial', 'image', 'correspond', 'facial', 'metric', 'store', 'image', 'subset', 'normalize', 'stored', 'image', 'separate', 'processor', 'parallel', 'processing', 'system', 'generate', 'euclidean', 'distance', 'store', 'image', 'subset', 'compare', 'euclidean', 'distance', 'predetermine', 'threshold', 'separate', 'processor', 'responsive', 'euclidean', 'distance', 'comparison', 'produce', 'reduced', 'candidate', 'list', 'best', 'possible', 'image', 'match', 'normalize', 'stored', 'image', 'subset', 'combine', 'reduce', 'candidate', 'list', 'subset', 'produce', 'single', 'reduce', 'candidate', 'list', 'method', 'scalable', 'parallel', 'cloud-based', 'face', 'recognition', 'claim', 'wherein', 'plurality', 'face', 'recognition', 'algorithm', 'utilized', 'compare', 'parallel', 'normalize', 'detected', 'facial', 'image', 'normalize', 'stored', 'image', 'reduce', 'candidate', 'list', 'consist', 'face', 'recognition', 'algorithms', 'select', 'group', 'consist', 'principle', 'component', 'analysis', 'pca-based', 'algorithm', 'linear', 'discriminant', 'analysis', 'lda', 'algorithms', 'independent', 'component', 'analysis', 'ica', 'algorithm', 'kernel-based', 'algorithms', 'feature-based', 'technique', 'algorithms', 'base', 'neural', 'network', 'algorithms', 'base', 'transforms', 'model-based', 'face', 'recognition', 'algorithm', 'method', 'scalable', 'parallel', 'cloud-based', 'face', 'recognition', 'claim', 'wherein', 'pca-based', 'algorithm', 'include', 'eigenfaces', 'face', 'detectionrecognition', 'lda', 'algorithm', 'include', 'fisherfaces', 'method', 'face', 'recognition', 'method', 'scalable', 'parallel', 'cloud-based', 'face', 'recognition', 'claim', 'wherein', 'compare', 'parallel', 'capture', 'image', 'normalize', 'stored', 'image', 'reduce', 'candidate', 'list', 'comprises', 'partition', 'reduced', 'candidate', 'list', 'plurality', 'substantially', 'equal', 'subset', 'process', 'subset', 'different', 'processor', 'parallel', 'processing', 'system', 'use', 'unique', 'face', 'recognition', 'algorithm', 'produce', 'best', 'match', 'result', 'use', 'reduce', 'function', 'mapreduce', 'program', 'combine', 'best', 'match', 'result', 'subset', 'produce', 'single', 'set', 'best', 'match', 'result', 'method', 'scalable', 'parallel', 'cloud-based', 'face', 'recognition', 'claim', 'wherein', 'partition', 'reduce', 'candidate', 'list', 'comprises', 'select', 'image', 'comprise', 'subset', 'optimize', 'variance', 'image', 'accord', 'follow', 'equation', 'n', 'number', 'row', 'columns', 'face', 'vector', 'image', 'n', 'number', 'group', 'σij', 'standard', 'deviation', 'image', 'dimension', 'group', 'j', 'face', 'image', 'vector', 'method', 'scalable', 'parallel', 'cloud-based', 'face', 'recognition', 'claim', 'wherein', 'select', 'image', 'comprise', 'subset', 'optimize', 'variance', 'image', 'accord', 'follow', 'equation', 'dμi', 'μj', 'euclidean', 'distance', 'mean', 'group', 'mean', 'group', 'j', 'face', 'image', 'vector', 'l', 'number', 'group', 'level', 'method', 'scalable', 'parallel', 'cloud-based', 'face', 'recognition', 'claim', 'select', 'final', 'match', 'best', 'match', 'result', 'utilizing', 'deep', 'learning', 'neural', 'network', 'face', 'recognition', 'algorithm', 'comprise', 'utilize', 'either', 'adaboost', 'machine-learning', 'algorithm', 'neural', 'network', 'machine-learning', 'model', 'method', 'scalable', 'parallel', 'cloud-based', 'face', 'recognition', 'claim', 'normalize', 'detect', 'facial', 'image', 'match', 'normalize', 'stored', 'image', 'include', 'normalize', 'detect', 'facial', 'image', 'size', 'orientation', 'illumination', 'normalize', 'stored', 'image', 'non-transitory', 'computer-readable', 'medium', 'contain', 'executable', 'program', 'instruction', 'cause', 'computer', 'perform', 'method', 'face', 'recognition', 'method', 'comprise', 'detect', 'face', 'image', 'capture', 'camera', 'normalizing', 'detect', 'facial', 'image', 'match', 'normalize', 'stored', 'image', 'identify', 'facial', 'feature', 'normalize', 'detected', 'facial', 'image', 'generate', 'plurality', 'facial', 'metric', 'facial', 'feature', 'calculate', 'euclidean', 'distance', 'facial', 'metric', 'normalize', 'detected', 'facial', 'image', 'correspond', 'facial', 'metric', 'store', 'image', 'compare', 'euclidean', 'distance', 'predetermine', 'threshold', 'responsive', 'euclidean', 'distance', 'comparison', 'produce', 'reduced', 'candidate', 'list', 'best', 'possible', 'image', 'match', 'normalize', 'stored', 'image', 'compare', 'parallel', 'capture', 'image', 'normalize', 'stored', 'image', 'reduce', 'candidate', 'list', 'utilize', 'plurality', 'face', 'recognition', 'algorithm', 'processor', 'parallel', 'process', 'system', 'use', 'different', 'face', 'recognition', 'algorithm', 'responsive', 'comparison', 'produce', 'best', 'match', 'result', 'parallel', 'subset', 'reduce', 'candidate', 'list', 'select', 'final', 'match', 'best', 'match', 'result', 'use', 'deep', 'learn', 'neural', 'network', 'face', 'recognition', 'algorithm', 'train', 'output', 'individual', 'face', 'recognition', 'algorithm', 'non-transitory', 'computer-readable', 'medium', 'contain', 'executable', 'program', 'instruction', 'claim', 'wherein', 'plurality', 'face', 'recognition', 'algorithm', 'utilized', 'compare', 'parallel', 'normalize', 'detected', 'facial', 'image', 'normalize', 'stored', 'image', 'reduce', 'candidate', 'list', 'consist', 'face', 'recognition', 'algorithms', 'select', 'group', 'consist', 'principle', 'component', 'analysis', 'pca-based', 'algorithm', 'linear', 'discriminant', 'analysis', 'lda', 'algorithms', 'independent', 'component', 'analysis', 'ica', 'algorithm', 'kernel-based', 'algorithms', 'feature-based', 'technique', 'algorithms', 'base', 'neural', 'network', 'algorithms', 'base', 'transforms', 'model-based', 'face', 'recognition', 'algorithm', 'non-transitory', 'computer-readable', 'medium', 'contain', 'executable', 'program', 'instruction', 'claim', 'wherein', 'pca-based', 'algorithm', 'include', 'eigenfaces', 'face', 'detectionrecognition', 'lda', 'algorithm', 'include', 'fisherfaces', 'method', 'face', 'recognition', 'non-transitory', 'computer-readable', 'medium', 'contain', 'executable', 'program', 'instruction', 'claim', 'select', 'final', 'match', 'best', 'match', 'result', 'utilizing', 'deep', 'learning', 'neural', 'network', 'face', 'recognition', 'algorithm', 'comprise', 'utilize', 'either', 'adaboost', 'machine-learning', 'algorithm', 'neural', 'network', 'machine-learning', 'model', 'image', 'device', 'comprise', 'condense', 'lens', 'image', 'sensor', 'configure', 'detect', 'light', 'pass', 'condense', 'lens', 'comprise', 'pixel', 'matrix', 'wherein', 'pixel', 'matrix', 'comprise', 'plurality', 'phase', 'detection', 'pixel', 'pair', 'plurality', 'regular', 'pixel', 'processor', 'configure', 'turn', 'phase', 'detection', 'pixel', 'pair', 'autofocusing', 'output', 'autofocused', 'pixel', 'data', 'complete', 'autofocusing', 'divide', 'autofocused', 'pixel', 'data', 'first', 'subframe', 'second', 'subframe', 'calculate', 'image', 'feature', 'least', 'one', 'first', 'subframe', 'second', 'subframe', 'wherein', 'image', 'feature', 'comprise', 'module', 'width', 'finder', 'pattern', 'finder', 'pattern', 'predetermine', 'ratio', 'harr-like', 'feature', 'gabor', 'feature', 'determine', 'operate', 'resolution', 'regular', 'pixel', 'accord', 'image', 'feature', 'calculate', 'least', 'one', 'first', 'subframe', 'second', 'subframe', 'divide', 'autofocused', 'pixel', 'data', 'image', 'device', 'claim', 'claim', 'wherein', 'phase', 'detection', 'pixel', 'pair', 'comprise', 'first', 'pixel', 'second', 'pixel', 'cover', 'layer', 'cover', 'upon', 'first', 'region', 'first', 'pixel', 'upon', 'second', 'region', 'second', 'pixel', 'wherein', 'first', 'region', 'second', 'region', 'mirror', 'symmetrical', 'microlens', 'align', 'least', 'one', 'first', 'pixel', 'second', 'pixel', 'image', 'device', 'claim', 'claim', 'wherein', 'first', 'region', 'second', 'region', '%', '%', 'area', 'single', 'pixel', 'image', 'device', 'claim', 'claim', 'wherein', 'processor', 'configure', 'perform', 'autofocusing', 'use', 'dual', 'pixel', 'autofocus', 'technique', 'accord', 'pixel', 'data', 'phase', 'detection', 'pixel', 'pair', 'complete', 'autofocusing', 'imaging', 'device', 'claim', 'claim', 'wherein', 'processor', 'configure', 'divide', 'pixel', 'data', 'phase', 'detection', 'pixel', 'pair', 'third', 'subframe', 'fourth', 'subframe', 'complete', 'autofocusing', 'perform', 'autofocusing', 'accord', 'third', 'subframe', 'fourth', 'subframe', 'image', 'device', 'claim', 'claim', 'wherein', 'processor', 'configure', 'calibrate', 'brightness', 'third', 'subframe', 'fourth', 'subframe', 'identical', 'use', 'shade', 'algorithm', 'image', 'device', 'claim', 'claim', 'wherein', 'operate', 'resolution', 'select', 'first', 'resolution', 'small', 'number', 'regular', 'pixel', 'second', 'resolution', 'large', 'first', 'resolution', 'image', 'device', 'claim', 'claim', 'wherein', 'regular', 'pixel', 'turn', 'autofocusing', 'image', 'device', 'claim', 'claim', 'wherein', 'number', 'phase', 'detection', 'pixel', 'pair', 'small', 'regular', 'pixel', 'image', 'device', 'comprise', 'condense', 'lens', 'image', 'sensor', 'configure', 'detect', 'light', 'pass', 'condense', 'lens', 'comprise', 'pixel', 'matrix', 'wherein', 'pixel', 'matrix', 'comprise', 'plurality', 'phase', 'detection', 'pixel', 'pair', 'plurality', 'regular', 'pixel', 'processor', 'configure', 'turn', 'phase', 'detection', 'pixel', 'pair', 'autofocusing', 'output', 'autofocused', 'pixel', 'data', 'complete', 'autofocusing', 'divide', 'autofocused', 'pixel', 'data', 'first', 'subframe', 'second', 'subframe', 'calculate', 'image', 'feature', 'least', 'one', 'first', 'subframe', 'second', 'subframe', 'wherein', 'image', 'feature', 'comprise', 'module', 'width', 'finder', 'pattern', 'finder', 'pattern', 'predetermine', 'ratio', 'harr-like', 'feature', 'gabor', 'feature', 'select', 'image', 'decode', 'image', 'recognition', 'use', 'pixel', 'data', 'regular', 'pixel', 'accord', 'image', 'feature', 'calculate', 'least', 'one', 'first', 'subframe', 'second', 'subframe', 'divide', 'autofocused', 'pixel', 'data', 'image', 'device', 'claim', 'claim', 'wherein', 'phase', 'detection', 'pixel', 'pair', 'comprise', 'first', 'pixel', 'second', 'pixel', 'cover', 'layer', 'cover', 'upon', 'first', 'region', 'first', 'pixel', 'upon', 'second', 'region', 'second', 'pixel', 'wherein', 'first', 'region', 'second', 'region', 'mirror', 'symmetrical', 'microlens', 'align', 'least', 'one', 'first', 'pixel', 'second', 'pixel', 'image', 'device', 'claim', 'claim', 'wherein', 'processor', 'configure', 'perform', 'autofocusing', 'use', 'dual', 'pixel', 'autofocus', 'technique', 'accord', 'pixel', 'data', 'phase', 'detection', 'pixel', 'pair', 'complete', 'autofocusing', 'imaging', 'device', 'claim', 'claim', 'wherein', 'processor', 'configure', 'divide', 'pixel', 'data', 'phase', 'detection', 'pixel', 'pair', 'third', 'subframe', 'fourth', 'subframe', 'complete', 'autofocusing', 'calibrate', 'brightness', 'third', 'subframe', 'fourth', 'subframe', 'identical', 'use', 'shade', 'algorithm', 'perform', 'autofocusing', 'accord', 'third', 'subframe', 'fourth', 'subframe', 'image', 'device', 'claim', 'claim', 'wherein', 'processor', 'configure', 'calculate', 'image', 'feature', 'use', 'least', 'one', 'rule', 'base', 'algorithm', 'machine', 'learn', 'algorithm', 'image', 'device', 'claim', 'claim', 'wherein', 'image', 'decode', 'decode', 'qr', 'code', 'image', 'recognition', 'face', 'recognition', 'operate', 'method', 'image', 'device', 'image', 'device', 'comprise', 'plurality', 'phase', 'detection', 'pixel', 'pair', 'plurality', 'regular', 'pixel', 'operate', 'method', 'comprise', 'turn', 'phase', 'detection', 'pixel', 'pair', 'autofocusing', 'output', 'autofocused', 'image', 'frame', 'complete', 'autofocusing', 'divide', 'autofocused', 'image', 'frame', 'acquire', 'phase', 'detection', 'pixel', 'pair', 'first', 'subframe', 'second', 'subframe', 'calculate', 'image', 'feature', 'least', 'one', 'first', 'subframe', 'second', 'subframe', 'wherein', 'image', 'feature', 'comprise', 'module', 'width', 'finder', 'pattern', 'finder', 'pattern', 'predetermine', 'ratio', 'harr-like', 'feature', 'gabor', 'feature', 'selectively', 'activate', 'least', 'part', 'regular', 'pixel', 'accord', 'image', 'feature', 'calculate', 'least', 'one', 'first', 'subframe', 'second', 'subframe', 'divide', 'autofocused', 'image', 'frame', 'operate', 'method', 'claim', 'claim', 'wherein', 'selectively', 'activate', 'comprises', 'activate', 'first', 'part', 'regular', 'pixel', 'perform', 'image', 'decode', 'accord', 'pixel', 'data', 'first', 'part', 'regular', 'pixel', 'activate', 'regular', 'pixel', 'perform', 'image', 'recognition', 'accord', 'pixel', 'data', 'regular', 'pixel', 'operate', 'method', 'claim', 'claim', 'wherein', 'pixel', 'data', 'phase', 'detection', 'pixel', 'pair', 'capture', 'frame', 'pixel', 'data', 'regular', 'pixel', 'also', 'use', 'perform', 'image', 'decode', 'image', 'recognition', 'operate', 'method', 'claim', 'claim', 'wherein', 'image', 'decode', 'decode', 'qr', 'code', 'image', 'recognition', 'face', 'recognition', 'operate', 'method', 'claim', 'claim', 'wherein', 'phase', 'detection', 'pixel', 'pair', 'partially', 'cover', 'pixel', 'structure', 'dual', 'pixel', 'apparatus', 'comprise', 'first', 'camera', 'module', 'configure', 'obtain', 'first', 'image', 'object', 'first', 'field', 'view', 'second', 'camera', 'module', 'configure', 'obtain', 'second', 'image', 'object', 'second', 'field', 'view', 'different', 'first', 'field', 'view', 'first', 'depth', 'map', 'generator', 'configure', 'generate', 'first', 'depth', 'map', 'first', 'image', 'base', 'first', 'image', 'second', 'image', 'second', 'depth', 'map', 'generator', 'configure', 'generate', 'second', 'depth', 'map', 'second', 'image', 'base', 'first', 'image', 'second', 'image', 'first', 'depth', 'map', 'apparatus', 'claim', 'wherein', 'first', 'field', 'view', 'narrow', 'angle', 'second', 'field', 'view', 'wider', 'angle', 'apparatus', 'claim', 'wherein', 'second', 'image', 'divide', 'primary', 'region', 'residual', 'region', 'second', 'depth', 'map', 'generator', 'comprise', 'relationship', 'estimate', 'module', 'configure', 'estimate', 'relationship', 'primary', 'region', 'residual', 'region', 'base', 'first', 'image', 'second', 'image', 'depth', 'map', 'estimate', 'module', 'configure', 'estimate', 'depth', 'map', 'residual', 'region', 'base', 'estimate', 'relationship', 'first', 'depth', 'map', 'apparatus', 'claim', 'wherein', 'least', 'one', 'relationship', 'estimate', 'module', 'depth', 'map', 'estimate', 'module', 'performs', 'estimate', 'operation', 'base', 'neural', 'network', 'module', 'apparatus', 'claim', 'comprise', 'depth', 'map', 'fusion', 'unit', 'configure', 'generate', 'third', 'depth', 'map', 'second', 'image', 'perform', 'fusion', 'operation', 'base', 'first', 'depth', 'map', 'second', 'depth', 'map', 'apparatus', 'claim', 'wherein', 'depth', 'map', 'fusion', 'unit', 'comprise', 'tone', 'mapping', 'module', 'configure', 'generate', 'tone-mapped', 'second', 'depth', 'map', 'correspond', 'first', 'depth', 'map', 'perform', 'bias', 'remove', 'operation', 'second', 'depth', 'map', 'fusion', 'module', 'configure', 'generate', 'third', 'depth', 'map', 'fuse', 'tone-mapped', 'second', 'depth', 'map', 'first', 'depth', 'map', 'apparatus', 'claim', 'wherein', 'depth', 'map', 'fusion', 'unit', 'comprise', 'propagate', 'module', 'configure', 'generate', 'propagate', 'first', 'depth', 'map', 'second', 'image', 'iterate', 'propagate', 'first', 'depth', 'map', 'base', 'first', 'depth', 'map', 'second', 'image', 'fusion', 'module', 'generate', 'third', 'depth', 'map', 'fuse', 'tone-mapped', 'second', 'depth', 'map', 'propagate', 'first', 'depth', 'map', 'apparatus', 'claim', 'wherein', 'depth', 'map', 'fusion', 'unit', 'comprise', 'post-processing', 'module', 'configure', 'perform', 'post-processing', 'operation', 'third', 'depth', 'map', 'generate', 'fusion', 'module', 'provide', 'post-processed', 'third', 'depth', 'map', 'apparatus', 'claim', 'wherein', 'post-processing', 'module', 'performs', 'post-processing', 'operation', 'filter', 'interface', 'generate', 'third', 'depth', 'map', 'accordance', 'fusion', 'fusion', 'module', 'apparatus', 'claim', 'wherein', 'post-processing', 'module', 'remove', 'artifact', 'generate', 'third', 'depth', 'map', 'accordance', 'fusion', 'fusion', 'module', 'apparatus', 'claim', 'wherein', 'first', 'depth', 'map', 'generator', 'analyse', 'distance', 'relationship', 'first', 'image', 'second', 'image', 'generates', 'first', 'depth', 'map', 'first', 'image', 'base', 'distance', 'relationship', 'method', 'processing', 'image', 'electronic', 'apparatus', 'method', 'comprise', 'obtain', 'first', 'image', 'object', 'use', 'first', 'camera', 'module', 'obtain', 'second', 'image', 'object', 'use', 'second', 'camera', 'module', 'generate', 'first', 'depth', 'map', 'first', 'image', 'base', 'first', 'image', 'second', 'image', 'estimate', 'relationship', 'primary', 'region', 'second', 'image', 'residual', 'region', 'second', 'image', 'base', 'first', 'image', 'second', 'image', 'generate', 'second', 'depth', 'map', 'second', 'image', 'base', 'estimate', 'relationship', 'primary', 'region', 'residual', 'region', 'first', 'depth', 'map', 'method', 'claim', 'wherein', 'electronic', 'apparatus', 'comprises', 'first', 'camera', 'module', 'include', 'first', 'lens', 'first', 'field', 'view', 'second', 'camera', 'module', 'include', 'second', 'lens', 'second', 'field', 'view', 'wider', 'first', 'field', 'view', 'method', 'claim', 'wherein', 'generate', 'second', 'depth', 'map', 'comprise', 'estimate', 'depth', 'map', 'residual', 'region', 'base', 'estimate', 'relationship', 'primary', 'region', 'residual', 'region', 'first', 'depth', 'map', 'generate', 'second', 'depth', 'map', 'base', 'depth', 'map', 'residual', 'region', 'first', 'depth', 'map', 'method', 'claim', 'wherein', 'estimate', 'relationship', 'primary', 'region', 'second', 'image', 'perform', 'use', 'neural', 'network', 'model', 'method', 'claim', 'comprise', 'perform', 'pre-processing', 'operation', 'second', 'depth', 'map', 'generate', 'third', 'depth', 'map', 'residual', 'image', 'fuse', 'second', 'depth', 'map', 'pre-processing', 'operation', 'perform', 'first', 'depth', 'map', 'method', 'claim', 'wherein', 'perform', 'pre-processing', 'operation', 'comprises', 'perform', 'tone', 'mapping', 'operation', 'depth', 'map', 'primary', 'region', 'depth', 'map', 'residual', 'region', 'base', 'second', 'depth', 'map', 'operate', 'method', 'electronic', 'apparatus', 'electronic', 'apparatus', 'include', 'first', 'camera', 'module', 'provide', 'first', 'image', 'object', 'use', 'first', 'field', 'view', 'second', 'camera', 'module', 'provide', 'second', 'image', 'object', 'use', 'second', 'field', 'view', 'wider', 'first', 'field', 'view', 'processor', 'generate', 'depth', 'map', 'second', 'image', 'base', 'primary', 'region', 'second', 'image', 'residual', 'region', 'second', 'image', 'operate', 'method', 'comprise', 'generate', 'first', 'depth', 'map', 'primary', 'region', 'estimate', 'relationship', 'first', 'image', 'second', 'image', 'estimate', 'relationship', 'primary', 'region', 'residual', 'region', 'base', 'first', 'image', 'second', 'image', 'generate', 'second', 'depth', 'map', 'second', 'image', 'estimate', 'depth', 'map', 'second', 'region', 'base', 'estimate', 'relationship', 'primary', 'region', 'residual', 'region', 'generate', 'depth', 'map', 'second', 'image', 'fuse', 'first', 'depth', 'map', 'second', 'depth', 'map', 'operation', 'method', 'claim', 'comprise', 'execute', 'application', 'applies', 'image', 'effect', 'second', 'image', 'base', 'depth', 'map', 'residual', 'image', 'operation', 'method', 'claim', 'wherein', 'application', 'apply', 'least', 'one', 'image', 'effect', 'auto-focusing', 'out-focusing', 'forebackground', 'separation', 'face', 'recognition', 'object', 'detection', 'within', 'frame', 'augmented', 'reality', 'second', 'image', 'base', 'depth', 'map', 'second', 'image', 'payment', 'method', 'base', 'face', 'recognition', 'comprise', 'acquire', 'first', 'face', 'image', 'information', 'target', 'user', 'extract', 'first', 'characteristic', 'information', 'first', 'face', 'image', 'information', 'wherein', 'first', 'characteristic', 'information', 'include', 'head', 'posture', 'information', 'target', 'user', 'gaze', 'information', 'target', 'user', 'determine', 'whether', 'target', 'user', 'willingness', 'pay', 'accord', 'head', 'posture', 'information', 'target', 'user', 'gaze', 'information', 'target', 'user', 'include', 'determine', 'whether', 'angle', 'rotation', 'preset', 'direction', 'less', 'angle', 'threshold', 'wherein', 'head', 'posture', 'information', 'include', 'angle', 'rotation', 'preset', 'direction', 'determine', 'whether', 'probability', 'value', 'user', 'gazes', 'payment', 'screen', 'great', 'probability', 'threshold', 'wherein', 'gaze', 'information', 'include', 'probability', 'value', 'user', 'gazes', 'payment', 'screen', 'response', 'determine', 'angle', 'rotation', 'preset', 'direction', 'less', 'angle', 'threshold', 'probability', 'value', 'user', 'gazes', 'payment', 'screen', 'great', 'probability', 'threshold', 'determine', 'target', 'user', 'willingness', 'pay', 'response', 'determine', 'target', 'user', 'willingness', 'pay', 'complete', 'payment', 'operation', 'base', 'face', 'recognition', 'method', 'claim', 'claim', 'wherein', 'complete', 'payment', 'operation', 'base', 'face', 'recognition', 'comprise', 'trigger', 'perform', 'payment', 'initiating', 'operation', 'acquire', 'second', 'face', 'image', 'information', 'base', 'face', 'recognition', 'determine', 'whether', 'second', 'characteristic', 'information', 'extract', 'second', 'face', 'image', 'information', 'indicate', 'user', 'willingness', 'pay', 'response', 'determine', 'second', 'characteristic', 'information', 'indicate', 'user', 'willingness', 'pay', 'trigger', 'perform', 'payment', 'confirmation', 'operation', 'complete', 'payment', 'operation', 'base', 'payment', 'account', 'information', 'correspond', 'target', 'user', 'method', 'claim', 'claim', 'wherein', 'determine', 'whether', 'second', 'characteristic', 'information', 'extract', 'second', 'face', 'image', 'information', 'indicate', 'user', 'willingness', 'pay', 'comprise', 'determine', 'whether', 'current', 'user', 'correspond', 'second', 'face', 'image', 'information', 'consistent', 'target', 'user', 'response', 'determine', 'current', 'user', 'consistent', 'target', 'user', 'determine', 'whether', 'target', 'user', 'willingness', 'pay', 'accord', 'second', 'characteristic', 'information', 'extract', 'second', 'face', 'image', 'information', 'method', 'claim', 'claim', 'wherein', 'extract', 'first', 'characteristic', 'information', 'first', 'face', 'image', 'information', 'comprise', 'determine', 'head', 'posture', 'information', 'target', 'user', 'use', 'head', 'posture', 'recognition', 'model', 'base', 'first', 'face', 'image', 'information', 'determine', 'gaze', 'information', 'target', 'user', 'use', 'gaze', 'information', 'recognition', 'model', 'base', 'characteristic', 'eye', 'region', 'first', 'face', 'image', 'information', 'method', 'claim', 'claim', 'wherein', 'head', 'posture', 'recognition', 'model', 'obtain', 'train', 'acquire', 'first', 'sample', 'data', 'set', 'wherein', 'first', 'sample', 'data', 'set', 'include', 'plurality', 'piece', 'first', 'sample', 'data', 'plurality', 'piece', 'first', 'sample', 'data', 'include', 'correspondence', 'sample', 'face', 'image', 'head', 'posture', 'information', 'determine', 'mean', 'image', 'data', 'variance', 'image', 'data', 'plurality', 'sample', 'face', 'image', 'plurality', 'piece', 'first', 'sample', 'data', 'preprocessing', 'sample', 'face', 'image', 'contain', 'plurality', 'piece', 'first', 'sample', 'data', 'base', 'mean', 'image', 'data', 'variance', 'image', 'data', 'obtain', 'preprocessed', 'sample', 'face', 'image', 'set', 'preprocessed', 'sample', 'face', 'image', 'correspond', 'head', 'posture', 'information', 'first', 'model', 'train', 'sample', 'perform', 'training', 'use', 'machine', 'learn', 'method', 'base', 'plurality', 'first', 'model', 'training', 'sample', 'obtain', 'head', 'posture', 'recognition', 'model', 'method', 'claim', 'claim', 'wherein', 'gaze', 'information', 'recognition', 'model', 'obtain', 'train', 'acquire', 'second', 'sample', 'data', 'set', 'wherein', 'second', 'sample', 'data', 'set', 'include', 'plurality', 'piece', 'second', 'sample', 'data', 'plurality', 'piece', 'second', 'sample', 'data', 'include', 'correspondence', 'sample', 'eye', 'image', 'gaze', 'information', 'determine', 'mean', 'image', 'data', 'variance', 'image', 'data', 'plurality', 'sample', 'eye', 'image', 'plurality', 'piece', 'second', 'sample', 'data', 'preprocessing', 'sample', 'eye', 'image', 'contain', 'plurality', 'piece', 'second', 'sample', 'data', 'base', 'mean', 'image', 'data', 'variance', 'image', 'data', 'obtain', 'preprocessed', 'sample', 'eye', 'image', 'set', 'preprocessed', 'sample', 'eye', 'image', 'correspond', 'gaze', 'information', 'second', 'model', 'train', 'sample', 'perform', 'training', 'use', 'machine', 'learn', 'method', 'base', 'plurality', 'second', 'model', 'training', 'sample', 'obtain', 'gaze', 'information', 'recognition', 'model', 'method', 'claim', 'claim', 'wherein', 'angle', 'rotation', 'preset', 'direction', 'comprise', 'pitch', 'angle', 'yaw', 'angle', 'roll', 'angle', 'wherein', 'pitch', 'angle', 'refers', 'angle', 'rotation', 'around', 'x-axis', 'yaw', 'angle', 'refers', 'angle', 'rotation', 'around', 'y-axis', 'roll', 'angle', 'refers', 'angle', 'rotation', 'around', 'z-axis', 'payment', 'device', 'base', 'face', 'recognition', 'comprise', 'processor', 'non-transitory', 'computer-readable', 'storage', 'medium', 'store', 'instruction', 'executable', 'processor', 'cause', 'device', 'perform', 'operation', 'comprise', 'acquire', 'first', 'face', 'image', 'information', 'target', 'user', 'extract', 'first', 'characteristic', 'information', 'first', 'face', 'image', 'information', 'wherein', 'first', 'characteristic', 'information', 'include', 'head', 'posture', 'information', 'target', 'user', 'gaze', 'information', 'target', 'user', 'determine', 'whether', 'target', 'user', 'willingness', 'pay', 'accord', 'head', 'posture', 'information', 'target', 'user', 'gaze', 'information', 'target', 'user', 'include', 'determine', 'whether', 'angle', 'rotation', 'preset', 'direction', 'less', 'angle', 'threshold', 'wherein', 'head', 'posture', 'information', 'include', 'angle', 'rotation', 'preset', 'direction', 'determine', 'whether', 'probability', 'value', 'user', 'gazes', 'payment', 'screen', 'great', 'probability', 'threshold', 'wherein', 'gaze', 'information', 'include', 'probability', 'value', 'user', 'gazes', 'payment', 'screen', 'response', 'determine', 'angle', 'rotation', 'preset', 'direction', 'less', 'angle', 'threshold', 'probability', 'value', 'user', 'gazes', 'payment', 'screen', 'great', 'probability', 'threshold', 'determine', 'target', 'user', 'willingness', 'pay', 'response', 'determine', 'target', 'user', 'willingness', 'pay', 'complete', 'payment', 'operation', 'base', 'face', 'recognition', 'device', 'claim', 'claim', 'wherein', 'complete', 'payment', 'operation', 'base', 'face', 'recognition', 'comprise', 'trigger', 'perform', 'payment', 'initiating', 'operation', 'acquire', 'second', 'face', 'image', 'information', 'base', 'face', 'recognition', 'determine', 'whether', 'second', 'characteristic', 'information', 'extract', 'second', 'face', 'image', 'information', 'indicate', 'user', 'willingness', 'pay', 'response', 'determine', 'second', 'characteristic', 'information', 'indicate', 'user', 'willingness', 'pay', 'trigger', 'perform', 'payment', 'confirmation', 'operation', 'complete', 'payment', 'operation', 'base', 'payment', 'account', 'information', 'correspond', 'target', 'user', 'device', 'claim', 'claim', 'wherein', 'determine', 'whether', 'second', 'characteristic', 'information', 'extract', 'second', 'face', 'image', 'information', 'indicate', 'user', 'willingness', 'pay', 'comprise', 'determine', 'whether', 'current', 'user', 'correspond', 'second', 'face', 'image', 'information', 'consistent', 'target', 'user', 'response', 'determine', 'current', 'user', 'consistent', 'target', 'user', 'determine', 'whether', 'target', 'user', 'willingness', 'pay', 'accord', 'second', 'characteristic', 'information', 'extract', 'second', 'face', 'image', 'information', 'device', 'claim', 'claim', 'wherein', 'extract', 'first', 'characteristic', 'information', 'first', 'face', 'image', 'information', 'comprise', 'determine', 'head', 'posture', 'information', 'target', 'user', 'use', 'head', 'posture', 'recognition', 'model', 'base', 'first', 'face', 'image', 'information', 'determine', 'gaze', 'information', 'target', 'user', 'use', 'gaze', 'information', 'recognition', 'model', 'base', 'characteristic', 'eye', 'region', 'first', 'face', 'image', 'information', 'device', 'claim', 'claim', 'wherein', 'head', 'posture', 'recognition', 'model', 'obtain', 'train', 'acquire', 'first', 'sample', 'data', 'set', 'wherein', 'first', 'sample', 'data', 'set', 'include', 'plurality', 'piece', 'first', 'sample', 'data', 'plurality', 'piece', 'first', 'sample', 'data', 'include', 'correspondence', 'sample', 'face', 'image', 'head', 'posture', 'information', 'determine', 'mean', 'image', 'data', 'variance', 'image', 'data', 'plurality', 'sample', 'face', 'image', 'plurality', 'piece', 'first', 'sample', 'data', 'preprocessing', 'sample', 'face', 'image', 'contain', 'plurality', 'piece', 'first', 'sample', 'data', 'base', 'mean', 'image', 'data', 'variance', 'image', 'data', 'obtain', 'preprocessed', 'sample', 'face', 'image', 'set', 'preprocessed', 'sample', 'face', 'image', 'correspond', 'head', 'posture', 'information', 'first', 'model', 'train', 'sample', 'perform', 'training', 'use', 'machine', 'learn', 'method', 'base', 'plurality', 'first', 'model', 'training', 'sample', 'obtain', 'head', 'posture', 'recognition', 'model', 'device', 'claim', 'claim', 'wherein', 'gaze', 'information', 'recognition', 'model', 'obtain', 'train', 'acquire', 'second', 'sample', 'data', 'set', 'wherein', 'second', 'sample', 'data', 'set', 'include', 'plurality', 'piece', 'second', 'sample', 'data', 'plurality', 'piece', 'second', 'sample', 'data', 'include', 'correspondence', 'sample', 'eye', 'image', 'gaze', 'information', 'determine', 'mean', 'image', 'data', 'variance', 'image', 'data', 'plurality', 'sample', 'eye', 'image', 'plurality', 'piece', 'second', 'sample', 'data', 'preprocessing', 'sample', 'eye', 'image', 'contain', 'plurality', 'piece', 'second', 'sample', 'data', 'base', 'mean', 'image', 'data', 'variance', 'image', 'data', 'obtain', 'preprocessed', 'sample', 'eye', 'image', 'set', 'preprocessed', 'sample', 'eye', 'image', 'correspond', 'gaze', 'information', 'second', 'model', 'train', 'sample', 'perform', 'training', 'use', 'machine', 'learn', 'method', 'plurality', 'second', 'model', 'training', 'sample', 'obtain', 'gaze', 'information', 'recognition', 'model', 'device', 'claim', 'claim', 'wherein', 'angle', 'rotation', 'preset', 'direction', 'comprise', 'pitch', 'angle', 'yaw', 'angle', 'roll', 'angle', 'wherein', 'pitch', 'angle', 'refers', 'angle', 'rotation', 'around', 'x-axis', 'yaw', 'angle', 'refers', 'angle', 'rotation', 'around', 'y-axis', 'roll', 'angle', 'refers', 'angle', 'rotation', 'around', 'z-axis', 'non-transitory', 'computer-readable', 'storage', 'medium', 'payment', 'base', 'face', 'recognition', 'configure', 'instruction', 'executable', 'one', 'processor', 'cause', 'one', 'processor', 'perform', 'operation', 'comprise', 'acquire', 'first', 'face', 'image', 'information', 'target', 'user', 'extract', 'first', 'characteristic', 'information', 'first', 'face', 'image', 'information', 'wherein', 'first', 'characteristic', 'information', 'include', 'head', 'posture', 'information', 'target', 'user', 'gaze', 'information', 'target', 'user', 'determine', 'whether', 'target', 'user', 'willingness', 'pay', 'accord', 'head', 'posture', 'information', 'target', 'user', 'gaze', 'information', 'target', 'user', 'include', 'determine', 'whether', 'angle', 'rotation', 'preset', 'direction', 'less', 'angle', 'threshold', 'wherein', 'head', 'posture', 'information', 'include', 'angle', 'rotation', 'preset', 'direction', 'determine', 'whether', 'probability', 'value', 'user', 'gazes', 'payment', 'screen', 'great', 'probability', 'threshold', 'wherein', 'gaze', 'information', 'include', 'probability', 'value', 'user', 'gazes', 'payment', 'screen', 'response', 'determine', 'angle', 'rotation', 'preset', 'direction', 'less', 'angle', 'threshold', 'probability', 'value', 'user', 'gazes', 'payment', 'screen', 'great', 'probability', 'threshold', 'determine', 'target', 'user', 'willingness', 'pay', 'response', 'determine', 'target', 'user', 'willingness', 'pay', 'complete', 'payment', 'operation', 'base', 'face', 'recognition', 'storage', 'medium', 'claim', 'claim', 'wherein', 'complete', 'payment', 'operation', 'base', 'face', 'recognition', 'comprise', 'trigger', 'perform', 'payment', 'initiating', 'operation', 'acquire', 'second', 'face', 'image', 'information', 'base', 'face', 'recognition', 'determine', 'whether', 'second', 'characteristic', 'information', 'extract', 'second', 'face', 'image', 'information', 'indicate', 'user', 'willingness', 'pay', 'response', 'determine', 'second', 'characteristic', 'information', 'indicate', 'user', 'willingness', 'pay', 'trigger', 'perform', 'payment', 'confirmation', 'operation', 'complete', 'payment', 'operation', 'base', 'payment', 'account', 'information', 'correspond', 'target', 'user', 'storage', 'medium', 'claim', 'claim', 'wherein', 'determine', 'whether', 'second', 'characteristic', 'information', 'extract', 'second', 'face', 'image', 'information', 'indicate', 'user', 'willingness', 'pay', 'comprise', 'determine', 'whether', 'current', 'user', 'correspond', 'second', 'face', 'image', 'information', 'consistent', 'target', 'user', 'response', 'determine', 'current', 'user', 'consistent', 'target', 'user', 'determine', 'whether', 'target', 'user', 'willingness', 'pay', 'accord', 'second', 'characteristic', 'information', 'extract', 'second', 'face', 'image', 'information', 'storage', 'medium', 'claim', 'claim', 'wherein', 'extract', 'first', 'characteristic', 'information', 'first', 'face', 'image', 'information', 'comprise', 'determine', 'head', 'posture', 'information', 'target', 'user', 'use', 'head', 'posture', 'recognition', 'model', 'base', 'first', 'face', 'image', 'information', 'determine', 'gaze', 'information', 'target', 'user', 'use', 'gaze', 'information', 'recognition', 'model', 'base', 'characteristic', 'eye', 'region', 'first', 'face', 'image', 'information', 'storage', 'medium', 'claim', 'claim', 'wherein', 'head', 'posture', 'recognition', 'model', 'obtain', 'train', 'acquire', 'first', 'sample', 'data', 'set', 'wherein', 'first', 'sample', 'data', 'set', 'include', 'plurality', 'piece', 'first', 'sample', 'data', 'plurality', 'piece', 'first', 'sample', 'data', 'include', 'correspondence', 'sample', 'face', 'image', 'head', 'posture', 'information', 'determine', 'mean', 'image', 'data', 'variance', 'image', 'data', 'plurality', 'sample', 'face', 'image', 'plurality', 'piece', 'first', 'sample', 'data', 'preprocessing', 'sample', 'face', 'image', 'contain', 'plurality', 'piece', 'first', 'sample', 'data', 'base', 'mean', 'image', 'data', 'variance', 'image', 'data', 'obtain', 'preprocessed', 'sample', 'face', 'image', 'set', 'preprocessed', 'sample', 'face', 'image', 'correspond', 'head', 'posture', 'information', 'first', 'model', 'train', 'sample', 'perform', 'training', 'use', 'machine', 'learn', 'method', 'base', 'plurality', 'first', 'model', 'training', 'sample', 'obtain', 'head', 'posture', 'recognition', 'model', 'wherein', 'gaze', 'information', 'recognition', 'model', 'obtain', 'train', 'acquire', 'second', 'sample', 'data', 'set', 'wherein', 'second', 'sample', 'data', 'set', 'include', 'plurality', 'piece', 'second', 'sample', 'data', 'plurality', 'piece', 'second', 'sample', 'data', 'include', 'correspondence', 'sample', 'eye', 'image', 'gaze', 'information', 'determine', 'mean', 'image', 'data', 'variance', 'image', 'data', 'plurality', 'sample', 'eye', 'image', 'plurality', 'piece', 'second', 'sample', 'data', 'preprocessing', 'sample', 'eye', 'image', 'contain', 'plurality', 'piece', 'second', 'sample', 'data', 'base', 'mean', 'image', 'data', 'variance', 'image', 'data', 'obtain', 'preprocessed', 'sample', 'eye', 'image', 'set', 'preprocessed', 'sample', 'eye', 'image', 'correspond', 'gaze', 'information', 'second', 'model', 'train', 'sample', 'perform', 'training', 'use', 'machine', 'learn', 'method', 'base', 'plurality', 'second', 'model', 'training', 'sample', 'obtain', 'gaze', 'information', 'recognition', 'model', 'storage', 'medium', 'claim', 'claim', 'wherein', 'angle', 'rotation', 'preset', 'direction', 'comprise', 'pitch', 'angle', 'yaw', 'angle', 'roll', 'angle', 'wherein', 'pitch', 'angle', 'refers', 'angle', 'rotation', 'around', 'x-axis', 'yaw', 'angle', 'refers', 'angle', 'rotation', 'around', 'y-axis', 'roll', 'angle', 'refers', 'angle', 'rotation', 'around', 'z-axis', 'method', 'comprise', 'detect', 'motion', 'detection', 'module', 'motion', 'subject', 'within', 'predetermined', 'area', 'view', 'assign', 'unique', 'session', 'identification', 'number', 'subject', 'detect', 'within', 'predetermined', 'area', 'view', 'detect', 'facial', 'area', 'subject', 'detect', 'within', 'predetermined', 'area', 'view', 'generate', 'image', 'facial', 'area', 'subject', 'assess', 'quality', 'image', 'facial', 'area', 'subject', 'determine', 'identity', 'subject', 'base', 'image', 'facial', 'area', 'subject', 'identify', 'intent', 'subject', 'authorize', 'access', 'point', 'entry', 'base', 'determine', 'identity', 'subject', 'base', 'intent', 'subject', 'method', 'claim', 'comprise', 'determine', 'one', 'additional', 'subject', 'within', 'predetermined', 'area', 'view', 'assign', 'unique', 'session', 'identification', 'number', 'one', 'additional', 'subject', 'detect', 'within', 'predetermined', 'area', 'view', 'method', 'claim', 'wherein', 'assess', 'quality', 'image', 'facial', 'area', 'subject', 'comprise', 'assess', 'whether', 'quality', 'image', 'facial', 'area', 'object', 'equates', 'predetermine', 'metric', 'quality', 'upon', 'determine', 'quality', 'image', 'facial', 'area', 'object', 'inferior', 'predetermine', 'metric', 'quality', 'discard', 'image', 'facial', 'area', 'subject', 'generate', 'second', 'image', 'facial', 'area', 'subject', 'method', 'claim', 'comprise', 'detect', 'whether', 'facial', 'area', 'subject', 'photographic', 'image', 'upon', 'detect', 'facial', 'area', 'subject', 'photographic', 'image', 'generate', 'warn', 'restrict', 'access', 'point', 'entry', 'method', 'claim', 'comprise', 'conduce', 'incremental', 'training', 'image', 'facial', 'area', 'subject', 'method', 'claim', 'wherein', 'conduce', 'incremental', 'training', 'image', 'facial', 'area', 'subject', 'comprises', 'capture', 'first', 'image', 'facial', 'area', 'facial', 'landmark', 'convert', 'first', 'image', 'facial', 'area', 'first', 'numeric', 'vector', 'capture', 'second', 'image', 'facial', 'area', 'facial', 'landmark', 'convert', 'second', 'image', 'facial', 'area', 'second', 'numeric', 'vector', 'calculate', 'weight', 'mean', 'first', 'numeric', 'vector', 'second', 'numeric', 'vector', 'wherein', 'weight', 'mean', 'represent', 'change', 'facial', 'area', 'store', 'weighted', 'mean', 'database', 'method', 'claim', 'wherein', 'determine', 'identity', 'subject', 'base', 'image', 'facial', 'area', 'subject', 'comprise', 'compare', 'image', 'facial', 'area', 'subject', 'plurality', 'image', 'store', 'database', 'authenticate', 'subject', 'method', 'claim', 'wherein', 'identify', 'intent', 'subject', 'comprise', 'upon', 'detect', 'facial', 'area', 'bound', 'box', 'commence', 'authentication', 'subject', 'calculate', 'directional', 'vector', 'face', 'subject', 'determine', 'intent', 'subject', 'gain', 'access', 'point', 'entry', 'base', 'directional', 'vector', 'face', 'subject', 'grant', 'access', 'point', 'entry', 'base', 'authentication', 'subject', 'base', 'determine', 'intent', 'subject', 'non-transitory', 'computer', 'readable', 'medium', 'program', 'instruction', 'store', 'thereon', 'response', 'execution', 'compute', 'device', 'cause', 'compute', 'device', 'perform', 'operation', 'comprise', 'detect', 'motion', 'subject', 'within', 'predetermined', 'area', 'view', 'assign', 'unique', 'session', 'identification', 'number', 'subject', 'detect', 'within', 'predetermined', 'area', 'view', 'detect', 'facial', 'area', 'subject', 'detect', 'within', 'predetermined', 'area', 'view', 'generate', 'image', 'facial', 'area', 'subject', 'assess', 'quality', 'image', 'facial', 'area', 'subject', 'determine', 'identity', 'subject', 'base', 'image', 'facial', 'area', 'subject', 'identify', 'intent', 'subject', 'authorize', 'access', 'point', 'entry', 'base', 'determine', 'identity', 'subject', 'base', 'intent', 'subject', 'non-transitory', 'computer', 'readable', 'medium', 'claim', 'comprise', 'determine', 'one', 'additional', 'subject', 'within', 'predetermined', 'area', 'view', 'assign', 'unique', 'session', 'identification', 'number', 'one', 'additional', 'subject', 'detect', 'within', 'predetermined', 'area', 'view', 'non-transitory', 'computer', 'readable', 'medium', 'claim', 'wherein', 'assess', 'quality', 'image', 'facial', 'area', 'subject', 'comprise', 'assess', 'whether', 'quality', 'image', 'facial', 'area', 'object', 'equates', 'predetermine', 'metric', 'quality', 'upon', 'determine', 'quality', 'image', 'facial', 'area', 'object', 'inferior', 'predetermine', 'metric', 'quality', 'discard', 'image', 'facial', 'area', 'subject', 'generate', 'second', 'image', 'facial', 'area', 'subject', 'non-transitory', 'computer', 'readable', 'medium', 'claim', 'comprise', 'detect', 'whether', 'facial', 'area', 'subject', 'photographic', 'image', 'upon', 'detect', 'facial', 'area', 'subject', 'photographic', 'image', 'generate', 'warn', 'restrict', 'access', 'access', 'point', 'non-transitory', 'computer', 'readable', 'medium', 'claim', 'comprise', 'conduce', 'incremental', 'training', 'image', 'facial', 'area', 'subject', 'non-transitory', 'computer', 'readable', 'medium', 'claim', 'wherein', 'conduce', 'incremental', 'training', 'image', 'facial', 'area', 'subject', 'comprises', 'capture', 'first', 'image', 'facial', 'area', 'facial', 'landmark', 'convert', 'first', 'image', 'facial', 'area', 'first', 'numeric', 'vector', 'capture', 'second', 'image', 'facial', 'area', 'facial', 'landmark', 'convert', 'second', 'image', 'facial', 'area', 'second', 'numeric', 'vector', 'calculate', 'weight', 'mean', 'first', 'numeric', 'vector', 'second', 'numeric', 'vector', 'wherein', 'weight', 'mean', 'represent', 'change', 'facial', 'area', 'store', 'weighted', 'mean', 'database', 'apparatus', 'face', 'recognition', 'comprise', 'processor', 'memory', 'store', 'computer', 'program', 'instruction', 'computer', 'program', 'instruction', 'execute', 'processor', 'cause', 'processor', 'perform', 'operation', 'comprise', 'detect', 'motion', 'subject', 'within', 'predetermined', 'area', 'view', 'assign', 'unique', 'session', 'identification', 'number', 'subject', 'detect', 'within', 'predetermined', 'area', 'view', 'detect', 'facial', 'area', 'subject', 'detect', 'within', 'predetermined', 'area', 'view', 'generate', 'image', 'facial', 'area', 'subject', 'assess', 'quality', 'image', 'facial', 'area', 'subject', 'determine', 'identity', 'subject', 'base', 'image', 'facial', 'area', 'subject', 'identify', 'intent', 'subject', 'authorize', 'access', 'point', 'entry', 'base', 'determine', 'identity', 'subject', 'base', 'intent', 'subject', 'apparatus', 'claim', 'comprise', 'determine', 'one', 'additional', 'subject', 'within', 'predetermined', 'area', 'view', 'assign', 'unique', 'session', 'identification', 'number', 'one', 'additional', 'subject', 'detect', 'within', 'predetermined', 'area', 'view', 'apparatus', 'claim', 'wherein', 'assess', 'quality', 'image', 'facial', 'area', 'subject', 'comprise', 'assess', 'whether', 'quality', 'image', 'facial', 'area', 'object', 'equates', 'predetermine', 'metric', 'quality', 'upon', 'determine', 'quality', 'image', 'facial', 'area', 'object', 'inferior', 'predetermine', 'metric', 'quality', 'discard', 'image', 'facial', 'area', 'subject', 'generate', 'second', 'image', 'facial', 'area', 'subject', 'apparatus', 'claim', 'comprise', 'detect', 'whether', 'facial', 'area', 'subject', 'photographic', 'image', 'upon', 'detect', 'facial', 'area', 'subject', 'photographic', 'image', 'generate', 'warn', 'restrict', 'access', 'access', 'point', 'apparatus', 'claim', 'comprise', 'conduce', 'incremental', 'training', 'image', 'facial', 'area', 'subject', 'apparatus', 'claim', 'wherein', 'conduce', 'incremental', 'training', 'image', 'facial', 'area', 'subject', 'comprises', 'capture', 'first', 'image', 'facial', 'area', 'facial', 'landmark', 'convert', 'first', 'image', 'facial', 'area', 'first', 'numeric', 'vector', 'capture', 'second', 'image', 'facial', 'area', 'facial', 'landmark', 'convert', 'second', 'image', 'facial', 'area', 'second', 'numeric', 'vector', 'calculate', 'weight', 'mean', 'first', 'numeric', 'vector', 'second', 'numeric', 'vector', 'wherein', 'weight', 'mean', 'represent', 'change', 'facial', 'area', 'store', 'weighted', 'mean', 'database', 'robot', 'comprise', 'body', 'configure', 'rotate', 'tilt', 'camera', 'couple', 'body', 'configured', 'rotate', 'tilt', 'accord', 'rotate', 'tilt', 'body', 'wherein', 'camera', 'configure', 'acquire', 'video', 'space', 'face', 'recognition', 'unit', 'configure', 'recognize', 'respective', 'face', 'one', 'person', 'video', 'track', 'unit', 'configure', 'track', 'motion', 'recognize', 'face', 'one', 'person', 'controller', 'configure', 'calculate', 'respective', 'size', 'face', 'one', 'person', 'select', 'first', 'person', 'among', 'one', 'person', 'base', 'calculated', 'size', 'face', 'control', 'least', 'one', 'direction', 'rotation', 'camera', 'angle', 'tilt', 'camera', 'focal', 'distance', 'camera', 'base', 'tracked', 'motion', 'recognize', 'face', 'first', 'person', 'robot', 'claim', 'wherein', 'controller', 'configure', 'control', 'direction', 'rotation', 'camera', 'angle', 'tilt', 'camera', 'achieve', 'particular', 'orientation', 'camera', 'relative', 'face', 'first', 'person', 'control', 'focal', 'distance', 'camera', 'compare', 'respective', 'size', 'face', 'first', 'person', 'motion', 'first', 'person', 'robot', 'claim', 'wherein', 'particular', 'orientation', 'occur', 'camera', 'face', 'general', 'direction', 'face', 'first', 'person', 'robot', 'claim', 'wherein', 'controller', 'configure', 'normalize', 'size', 'face', 'one', 'person', 'base', 'interocular', 'distance', 'select', 'first', 'person', 'base', 'normalized', 'size', 'face', 'one', 'person', 'robot', 'claim', 'wherein', 'controller', 'configure', 'select', 'person', 'large', 'face', 'size', 'among', 'one', 'person', 'first', 'person', 'robot', 'claim', 'comprise', 'microphone', 'configure', 'receive', 'spoken', 'audio', 'present', 'space', 'wherein', 'controller', 'configure', 'select', 'first', 'person', 'base', 'receive', 'spoken', 'audio', 'robot', 'claim', 'wherein', 'controller', 'configure', 'control', 'gain', 'microphone', 'compare', 'respective', 'size', 'face', 'first', 'person', 'motion', 'first', 'person', 'robot', 'claim', 'wherein', 'controller', 'configure', 'calculate', 'position', 'speak', 'audio', 'provide', 'select', 'first', 'person', 'base', 'whether', 'one', 'person', 'position', 'voice', 'signal', 'provide', 'robot', 'claim', 'wherein', 'controller', 'configure', 'select', 'second', 'person', 'first', 'person', 'among', 'one', 'person', 'second', 'person', 'locate', 'position', 'speak', 'audio', 'provide', 'robot', 'claim', 'wherein', 'controller', 'configure', 'select', 'second', 'person', 'large', 'face', 'size', 'first', 'person', 'among', 'one', 'person', 'none', 'one', 'person', 'locate', 'position', 'speak', 'audio', 'provide', 'robot', 'claim', 'wherein', 'controller', 'configure', 'select', 'second', 'person', 'large', 'face', 'size', 'first', 'person', 'among', 'one', 'person', 'plurality', 'person', 'among', 'one', 'person', 'locate', 'position', 'speak', 'audio', 'provide', 'robot', 'claim', 'comprise', 'speaker', 'wherein', 'controller', 'configure', 'control', 'volume', 'speaker', 'compare', 'respective', 'size', 'face', 'first', 'person', 'motion', 'first', 'person', 'robot', 'claim', 'wherein', 'body', 'configured', 'rotate', 'lateral', 'direction', 'tilt', 'vertical', 'direction', 'electronic', 'device', 'comprise', 'camera', 'couple', 'body', 'configured', 'rotate', 'tilt', 'wherein', 'camera', 'configure', 'acquire', 'video', 'space', 'within', 'one', 'person', 'position', 'processor', 'configure', 'recognize', 'respective', 'face', 'one', 'person', 'video', 'track', 'motion', 'recognize', 'face', 'one', 'person', 'calculate', 'respective', 'size', 'face', 'one', 'person', 'select', 'first', 'person', 'among', 'one', 'person', 'base', 'calculated', 'size', 'face', 'control', 'least', 'one', 'direction', 'rotation', 'camera', 'angle', 'tilt', 'camera', 'focal', 'distance', 'camera', 'base', 'tracked', 'motion', 'recognize', 'face', 'first', 'person', 'method', 'comprise', 'acquire', 'camera', 'video', 'space', 'within', 'one', 'person', 'position', 'recognize', 'respective', 'face', 'one', 'person', 'video', 'track', 'motion', 'recognize', 'face', 'one', 'person', 'calculate', 'respective', 'size', 'face', 'one', 'person', 'select', 'first', 'person', 'among', 'one', 'person', 'base', 'calculated', 'size', 'face', 'control', 'least', 'one', 'direction', 'rotation', 'camera', 'angle', 'tilt', 'camera', 'focal', 'distance', 'camera', 'base', 'tracked', 'motion', 'recognize', 'face', 'first', 'person', 'method', 'infer', 'topic', 'multimodal', 'file', 'method', 'comprise', 'receive', 'multimodal', 'file', 'extract', 'set', 'entity', 'multimodal', 'file', 'link', 'set', 'entity', 'produce', 'set', 'link', 'entity', 'obtain', 'reference', 'information', 'set', 'entity', 'base', 'least', 'reference', 'information', 'generate', 'graph', 'set', 'link', 'entity', 'graph', 'comprise', 'node', 'edge', 'base', 'least', 'nodes', 'edge', 'graph', 'determine', 'cluster', 'graph', 'base', 'least', 'cluster', 'graph', 'identify', 'topic', 'candidate', 'extract', 'feature', 'cluster', 'graph', 'base', 'least', 'extracted', 'feature', 'select', 'least', 'one', 'topicid', 'among', 'topic', 'candidate', 'represent', 'least', 'one', 'cluster', 'index', 'multimodal', 'file', 'least', 'one', 'topicid', 'method', 'claim', 'wherein', 'multimodal', 'file', 'comprise', 'video', 'portion', 'audio', 'portion', 'wherein', 'extract', 'set', 'entity', 'multimodal', 'file', 'comprises', 'detect', 'object', 'video', 'portion', 'multimodal', 'file', 'detect', 'text', 'audio', 'portion', 'multimodal', 'file', 'method', 'claim', 'wherein', 'detect', 'object', 'comprise', 'perform', 'face', 'recognition', 'method', 'claim', 'wherein', 'detect', 'text', 'comprises', 'perform', 'speech', 'text', 'process', 'method', 'claim', 'comprise', 'identifying', 'language', 'use', 'audio', 'portion', 'multimodal', 'file', 'wherein', 'perform', 'speech', 'text', 'process', 'comprise', 'perform', 'speech', 'text', 'process', 'identify', 'language', 'method', 'claim', 'comprise', 'translate', 'detect', 'text', 'method', 'claim', 'comprise', 'determine', 'significant', 'cluster', 'insignificant', 'cluster', 'determine', 'cluster', 'wherein', 'extract', 'feature', 'cluster', 'graph', 'comprises', 'extract', 'feature', 'significant', 'cluster', 'graph', 'method', 'claim', 'wherein', 'extract', 'feature', 'cluster', 'graph', 'comprises', 'least', 'one', 'process', 'select', 'list', 'consist', 'determine', 'graph', 'diameter', 'determine', 'jaccard', 'coefficient', 'method', 'claim', 'wherein', 'select', 'least', 'one', 'topicid', 'represent', 'least', 'one', 'cluster', 'comprises', 'base', 'least', 'extracted', 'feature', 'map', 'topic', 'candidate', 'probability', 'interval', 'base', 'least', 'map', 'rank', 'topic', 'candidate', 'within', 'least', 'one', 'cluster', 'select', 'least', 'one', 'topicid', 'base', 'least', 'ranking', 'method', 'claim', 'comprise', 'translate', 'least', 'one', 'topicid', 'wherein', 'index', 'multimodal', 'file', 'least', 'one', 'topicid', 'comprise', 'index', 'multimodal', 'file', 'least', 'one', 'translate', 'topicid', 'system', 'infer', 'topic', 'multimodal', 'file', 'system', 'comprise', 'entity', 'extraction', 'component', 'comprise', 'object', 'detection', 'component', 'speech', 'text', 'component', 'operative', 'extract', 'set', 'entity', 'multimodal', 'file', 'comprise', 'video', 'portion', 'audio', 'portion', 'entity', 'link', 'component', 'operative', 'link', 'extract', 'set', 'entity', 'produce', 'set', 'link', 'entity', 'information', 'retrieval', 'component', 'operative', 'obtain', 'reference', 'information', 'extract', 'set', 'entity', 'graph', 'analysis', 'component', 'operative', 'generate', 'graph', 'set', 'link', 'entity', 'graph', 'comprise', 'node', 'edge', 'base', 'least', 'nodes', 'edge', 'graph', 'determine', 'cluster', 'graph', 'base', 'least', 'cluster', 'graph', 'identify', 'topic', 'candidate', 'extract', 'feature', 'cluster', 'graph', 'topicid', 'selection', 'component', 'operative', 'rank', 'topic', 'candidate', 'within', 'least', 'one', 'cluster', 'base', 'least', 'ranking', 'select', 'least', 'one', 'topicid', 'among', 'topic', 'candidate', 'represent', 'least', 'one', 'cluster', 'video', 'indexer', 'operative', 'index', 'multimodal', 'file', 'least', 'one', 'topicid', 'system', 'claim', 'wherein', 'object', 'detection', 'component', 'operative', 'perform', 'face', 'recognition', 'system', 'claim', 'wherein', 'speech', 'text', 'component', 'operative', 'extract', 'entity', 'information', 'least', 'two', 'different', 'language', 'one', 'computer', 'storage', 'device', 'computer-executable', 'instruction', 'store', 'thereon', 'infer', 'topic', 'multimodal', 'file', 'execution', 'computer', 'cause', 'computer', 'perform', 'operation', 'comprise', 'receive', 'multimodal', 'file', 'comprise', 'video', 'portion', 'audio', 'portion', 'extract', 'set', 'entity', 'multimodal', 'file', 'wherein', 'extract', 'set', 'entity', 'multimodal', 'file', 'comprises', 'detect', 'object', 'video', 'portion', 'multimodal', 'file', 'face', 'recognition', 'detect', 'text', 'audio', 'portion', 'multimodal', 'file', 'speech', 'text', 'process', 'disambiguate', 'among', 'set', 'detect', 'entity', 'name', 'link', 'set', 'entity', 'produce', 'set', 'link', 'entity', 'obtain', 'reference', 'information', 'set', 'entity', 'base', 'least', 'reference', 'information', 'generate', 'graph', 'set', 'link', 'entity', 'graph', 'comprise', 'node', 'edge', 'base', 'least', 'nodes', 'edge', 'graph', 'determine', 'cluster', 'graph', 'determine', 'significant', 'cluster', 'insignificant', 'cluster', 'determine', 'cluster', 'base', 'least', 'significant', 'cluster', 'graph', 'identify', 'topic', 'candidate', 'extract', 'feature', 'significant', 'cluster', 'graph', 'base', 'least', 'extracted', 'feature', 'map', 'topic', 'candidate', 'probability', 'interval', 'base', 'least', 'map', 'rank', 'topic', 'candidate', 'within', 'least', 'one', 'significant', 'cluster', 'base', 'rank', 'select', 'least', 'one', 'topicid', 'among', 'topic', 'candidate', 'represent', 'least', 'one', 'significant', 'cluster', 'index', 'multimodal', 'file', 'least', 'one', 'topicid', 'one', 'computer', 'storage', 'device', 'claim', 'wherein', 'operation', 'comprise', 'identify', 'language', 'use', 'audio', 'portion', 'multimodal', 'file', 'detect', 'text', 'audio', 'portion', 'multimodal', 'file', 'speech', 'text', 'process', 'comprise', 'perform', 'speech', 'text', 'process', 'identify', 'language权利要求', 'system', 'alert', 'vision', 'impairment', 'say', 'system', 'comprise', 'process', 'unit', 'configure', 'operable', 'receive', 'scene', 'data', 'indicative', 'scene', 'least', 'one', 'consumer', 'environment', 'identify', 'scene', 'data', 'certain', 'consumer', 'identify', 'event', 'indicative', 'behavioral', 'compensation', 'vision', 'impairment', 'upon', 'identification', 'event', 'send', 'notification', 'relate', 'vision', 'impairment', 'system', 'claim', 'comprise', 'least', 'one', 'sense', 'unit', 'configure', 'operable', 'detect', 'scene', 'data', 'system', 'claim', 'wherein', 'say', 'least', 'one', 'sense', 'unit', 'comprise', 'least', 'one', 'least', 'one', 'image', 'unit', 'configure', 'operable', 'capture', 'least', 'one', 'image', 'least', 'portion', 'consumer', \"'s\", 'body', 'least', 'one', 'motion', 'detector', 'configure', 'operable', 'detect', 'consumer', 'data', 'indicative', 'motion', 'consumer', 'least', 'one', 'eye', 'tracker', 'configure', 'operable', 'track', 'eye', 'motion', 'consumer', 'system', 'claim', 'wherein', 'least', 'one', 'image', 'unit', 'comprise', 'plurality', 'camera', 'place', 'different', 'height', 'system', 'one', 'claim', 'wherein', 'say', 'sense', 'unit', 'accommodate', 'optical', 'digital', 'eyewear', 'frame', 'display', 'system', 'one', 'claim', 'wherein', 'say', 'processing', 'unit', 'configure', 'operable', 'identify', 'consumer', \"'s\", 'condition', 'say', 'consumer', \"'s\", 'condition', 'comprise', 'consumer', 'data', 'indicative', 'consumer', \"'s\", 'position', 'location', 'relative', 'least', 'one', 'object', 'consumer', \"'s\", 'environment', 'say', 'consumer', 'data', 'comprises', 'least', 'one', 'consumer', \"'s\", 'face', 'eyewear', 'posture', 'position', 'sound', 'motion', 'system', 'one', 'claim', 'wherein', 'say', 'event', 'comprises', 'least', 'one', 'position', 'orientation', 'head', 'increase', 'decrease', 'view', 'distance', 'consumer', 'view', 'object', 'change', 'position', 'eyeglass', 'worn', 'consumer', 'system', 'one', 'claim', 'wherein', 'say', 'event', 'identify', 'identifying', 'image', 'image', 'feature', 'indicative', 'behavioral', 'compensation', 'perform', 'bruckner', 'test', 'perform', 'hirschberg', 'test', 'measure', 'blink', 'count', 'frequency', 'system', 'claim', 'wherein', 'image', 'feature', 'indicative', 'behavioral', 'compensation', 'comprises', 'squint', 'head', 'orientation', 'certain', 'distance', 'object', 'consumer', \"'s\", 'eye', 'certain', 'position', 'eyeglasses', 'consumer', \"'s\", 'face', 'strabismus', 'cataracts', 'reflection', 'eye', 'system', 'one', 'claim', 'wherein', 'notification', 'include', 'least', 'one', 'data', 'indicative', 'identify', 'event', 'data', 'indicative', 'identified', 'consumer', 'ophthalmologic', 'recommendation', 'base', 'identified', 'event', 'lack', 'event', 'appointment', 'vision', 'test', 'system', 'one', 'claim', 'wherein', 'say', 'processing', 'unit', 'comprise', 'memory', 'store', 'least', 'one', 'reference', 'data', 'indicative', 'behavioral', 'compensation', 'vision', 'impairment', 'data', 'indicative', 'notification', 'data', 'indicative', 'follow-up', 'notification', 'system', 'claim', 'wherein', 'say', 'processing', 'unit', 'configure', 'least', 'one', 'identify', 'event', 'upon', 'comparison', 'detect', 'data', 'reference', 'data', 'determine', 'probability', 'vision', 'impairment', 'consumer', 'base', 'comparison', 'system', 'one', 'claim', 'wherein', 'say', 'processing', 'unit', 'comprise', 'communication', 'interface', 'configure', 'send', 'notification', 'least', 'one', 'identified', 'consumer', 'party', 'system', 'one', 'claim', 'wherein', 'say', 'processing', 'unit', 'configure', 'provide', 'frame', 'recommendation', 'system', 'one', 'claim', 'wherein', 'say', 'memory', 'configure', 'storing', 'database', 'include', 'multiplicity', 'data', 'set', 'related', 'plurality', 'spectacle', 'frame', 'model', 'size', 'system', 'accord', 'claim', 'wherein', 'say', 'processing', 'unit', 'configure', 'operable', 'correlate', 'frame', 'parameter', 'ophthalmic', 'prescription', 'system', 'accord', 'claim', 'wherein', 'say', 'processing', 'unit', 'configure', 'operable', 'correlate', 'frame', 'parameter', 'facial', 'feature', 'system', 'accord', 'claim', 'wherein', 'say', 'processing', 'unit', 'configure', 'operable', 'correlate', 'frame', 'parameter', 'eyewear', 'preference', 'system', 'accord', 'claim', 'comprise', 'server', 'least', 'one', 'computer', 'entity', 'link', 'server', 'via', 'network', 'wherein', 'say', 'network', 'configure', 'receive', 'respond', 'request', 'send', 'across', 'network', 'transmit', 'one', 'module', 'computer', 'executable', 'program', 'instruction', 'displayable', 'data', 'network', 'connect', 'user', 'computer', 'platform', 'response', 'request', 'wherein', 'say', 'module', 'include', 'module', 'configure', 'receive', 'transmit', 'image', 'information', 'transmit', 'frame', 'recommendation', 'optical', 'lens', 'option', 'recommendation', 'base', 'receive', 'image', 'information', 'display', 'network', 'connect', 'user', 'computer', 'platform', 'computer', 'program', 'instruction', 'store', 'local', 'storage', 'execute', 'process', 'unit', 'cause', 'process', 'unit', 'receive', 'data', 'indicative', 'scene', 'least', 'one', 'consumer', 'environment', 'identify', 'data', 'certain', 'consumer', 'identify', 'event', 'indicative', 'behavioral', 'compensation', 'vision', 'impairment', 'upon', 'identification', 'event', 'send', 'notification', 'relate', 'vision', 'impairment', 'computer', 'program', 'product', 'store', 'tangible', 'computer', 'readable', 'medium', 'comprise', 'library', 'software', 'module', 'cause', 'computer', 'execute', 'prompt', 'information', 'pertinent', 'least', 'one', 'eyeglasses', 'recommendation', 'optical', 'lens', 'option', 'recommendation', 'store', 'say', 'information', 'display', 'eyewear', 'recommendation', 'computer', 'program', 'product', 'claim', 'wherein', 'say', 'library', 'comprises', 'module', 'frame', 'selection', 'point', 'sale', 'advertise', 'computer', 'platform', 'facilitate', 'eye', 'glass', 'market', 'selection', 'comprise', 'camera', 'processor', 'configure', 'execute', 'computer', 'program', 'instruction', 'cause', 'processor', 'take', 'image', 'consumer', 'identify', 'image', 'certain', 'consumer', 'identify', 'event', 'indicative', 'behavioral', 'compensation', 'vision', 'impairment', 'upon', 'identification', 'event', 'send', 'notification', 'relate', 'vision', 'impairment', 'local', 'storage', 'processor', 'executable', 'instruction', 'carry', 'storage', 'information', 'method', 'alert', 'vision', 'impairment', 'say', 'method', 'comprise', 'identify', 'certain', 'individual', 'scene', 'data', 'indicative', 'scene', 'least', 'one', 'consumer', 'environment', 'identify', 'event', 'indicative', 'behavioral', 'compensation', 'vision', 'impairment', 'upon', 'identification', 'event', 'send', 'notification', 'vision', 'impairment', 'method', 'claim', 'comprise', 'detect', 'data', 'indicative', 'scene', 'least', 'one', 'consumer', 'retail', 'environment', 'method', 'claim', 'wherein', 'detect', 'data', 'indicative', 'least', 'one', 'consumer', 'comprise', 'least', 'one', 'capture', 'least', 'one', 'image', 'least', 'one', 'consumer', 'detect', 'data', 'indicative', 'motion', 'consumer', 'track', 'eye', 'motion', 'consumer', 'method', 'claim', 'wherein', 'capture', 'least', 'one', 'image', 'least', 'one', 'consumer', 'comprise', 'continuously', 'record', 'scene', 'method', 'one', 'claim', 'comprise', 'identify', 'data', 'consumer', \"'\", 'condition', 'include', 'data', 'indicative', 'consumer', \"'s\", 'position', 'location', 'relative', 'consumer', \"'s\", 'environment', 'say', 'data', 'comprise', 'least', 'one', 'consumer', \"'s\", 'face', 'posture', 'position', 'sound', 'motion', 'method', 'one', 'claim', 'wherein', 'say', 'event', 'comprises', 'least', 'one', 'position', 'orientation', 'head', 'increase', 'decrease', 'view', 'distance', 'consumer', 'view', 'object', 'change', 'position', 'eyeglass', 'worn', 'consumer', 'method', 'one', 'claim', 'wherein', 'identify', 'event', 'comprises', 'identify', 'image', 'image', 'feature', 'indicative', 'behavioral', 'compensation', 'perform', 'bruckner', 'test', 'perform', 'hirschberg', 'test', 'measure', 'blink', 'countfrequency', 'method', 'claim', 'wherein', 'image', 'feature', 'indicative', 'behavioral', 'compensation', 'comprises', 'squint', 'head', 'orientation', 'certain', 'distance', 'object', 'consumer', \"'s\", 'eye', 'certain', 'position', 'eyeglasses', 'consumer', \"'s\", 'face', 'strabismus', 'cataracts', 'reflection', 'eye', 'method', 'one', 'claim', 'wherein', 'identify', 'least', 'one', 'image', 'consumer', 'retail', 'environment', 'comprise', 'least', 'one', 'receive', 'data', 'characterize', 'retail', 'environment', 'perform', 'face', 'recognition', 'method', 'one', 'claim', 'wherein', 'send', 'notification', 'comprise', 'send', 'notification', 'least', 'one', 'identified', 'consumer', 'party', 'method', 'one', 'claim', 'wherein', 'notification', 'include', 'least', 'one', 'data', 'indicative', 'identify', 'event', 'data', 'indicative', 'identified', 'consumer', 'ophthalmologic', 'recommendation', 'base', 'identified', 'event', 'lack', 'event', 'appointment', 'vision', 'test', 'method', 'one', 'claim', 'comprise', 'store', 'least', 'one', 'reference', 'data', 'indicative', 'behavioral', 'compensation', 'vision', 'impairment', 'data', 'indicative', 'notification', 'data', 'indicative', 'follow-up', 'notification', 'method', 'claim', 'comprise', 'identify', 'event', 'upon', 'comparison', 'detect', 'data', 'reference', 'data', 'determine', 'probability', 'vision', 'impairment', 'consumer', 'base', 'comparison', 'computer', 'program', 'intend', 'stored', 'memory', 'processor', 'unit', 'computer', 'system', 'removable', 'memory', 'medium', 'adapt', 'cooperate', 'reader', 'processor', 'unit', 'comprise', 'instruction', 'implement', 'method', 'accord', 'claim']\n"
     ]
    }
   ],
   "source": [
    "lemmatized_text_a = []\n",
    "\n",
    "for tuple in simpler_POS_text_a:\n",
    "    if (tuple[1] == None):\n",
    "        lemmatized_text_a.append(lemmatizer.lemmatize(tuple[0]))\n",
    "    else:\n",
    "        lemmatized_text_a.append(lemmatizer.lemmatize(tuple[0], pos=tuple[1]))\n",
    "    \n",
    "print(lemmatized_text_a)\n",
    "\n",
    "lemmatized_text_c = []\n",
    "\n",
    "for tuple in simpler_POS_text_c:\n",
    "    if (tuple[1] == None):\n",
    "        lemmatized_text_c.append(lemmatizer.lemmatize(tuple[0]))\n",
    "    else:\n",
    "        lemmatized_text_c.append(lemmatizer.lemmatize(tuple[0], pos=tuple[1]))\n",
    "    \n",
    "print(lemmatized_text_c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
