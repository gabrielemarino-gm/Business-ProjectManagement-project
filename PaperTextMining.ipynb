{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69dec909",
   "metadata": {},
   "source": [
    "## Paper Text Mining\n",
    "Here we are going to mine and process the text for a specific paper; in the end we are going to use three differents keyword extraction libraries to obtain all the main "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "897b8cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting files...\n",
      "File Not Encrypted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stefa\\anaconda3\\lib\\site-packages\\PyPDF2\\_reader.py:1351: PdfReadWarning: Xref table not zero-indexed. ID numbers for objects will be corrected.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing extractor...\n",
      "Loading text...\n",
      "Candidate Selection...\n",
      "Weighting...\n",
      "Selecting 10 best candidates...\n",
      "sample images\n",
      "class containsmsamples\n",
      "optimal discriminant vectors\n",
      "fig\n",
      "great number\n",
      "set\n",
      "face image\n",
      "recognition society\n",
      "dierent methods\n",
      "withinclass scatter matrix\n",
      "[('sample images', 0.03142200965534665), ('class containsmsamples', 0.02467444277138319), ('optimal discriminant vectors', 0.021151517342831692), ('fig', 0.018339550083292973), ('great number', 0.01739710648680436), ('set', 0.017002328074481318), ('face image', 0.01578486388962984), ('recognition society', 0.015242317449343533), ('dierent methods', 0.014175236730822818), ('withinclass scatter matrix', 0.014095380313097733)]\n",
      "discriminantvectors\n",
      "lda\n",
      "discriminantvector\n",
      "recognition\n",
      "discriminant\n",
      "[('eigenfaces', 0.3929), ('keywordsface', 0.3597), ('featurevectors', 0.3572), ('pca', 0.325), ('faces', 0.3192)]\n",
      "Initializing extractor...\n",
      "Loading text...\n",
      "Candidate Selection...\n",
      "Weighting...\n",
      "Selecting 40 best candidates...\n",
      "highdimensional sample\n",
      "class containsm sample letykmdenote\n",
      "ed fisher\n",
      "et al\n",
      "betweenclass scatter\n",
      "train database\n",
      "sign\n",
      "experimental result\n",
      "thesmall sample size problem paper\n",
      "accurate stable method\n",
      "vector\n",
      "sign mean class database\n",
      "criterion function\n",
      "wellknown approach present section\n",
      "maximum value ie\n",
      "phase pixel group\n",
      "large eigenvalue matrix\n",
      "modi\n",
      "criterion lemma\n",
      "expressive vector derive null space\n",
      "kmkkmmxkmlf chen et alpattern result\n",
      "earlier process use\n",
      "eigenvectors\n",
      "ap proach\n",
      "linear algebra\n",
      "eigenvalue eigenvectors\n",
      "use ref\n",
      "data\n",
      "algorithm base foleysammon\n",
      "optimal\n",
      "new base technique\n",
      "conclude su cient derive vector\n",
      "normal process derive vector subspace\n",
      "subspace\n",
      "section feature extraction section\n",
      "qtsbq qtswq\n",
      "case\n",
      "withinclass scatter sample\n",
      "total scatter matrix st\n",
      "feature vector ofxkmthrough transformationqqt ykm\n",
      "optimal projection ax vector\n",
      "new process\n",
      "rank ofswisr ier\n",
      "faceonly database use\n",
      "projection vector base modi\n",
      "stability problem eigenvalues\n",
      "image size\n",
      "training time result\n",
      "arbitrary projection\n",
      "wherexnk\n",
      "class separability purpose\n",
      "horizontal axis\n",
      "dimensionality reduction sim\n",
      "thepdimensional image\n",
      "second fourth column\n",
      "correspond rate\n",
      "eigen value ofsw subspace\n",
      "maximal value\n",
      "pureaface portion order ful\n",
      "fromstsb table\n",
      "spanmaidswai\n",
      "qtsbqo special circumstance modi\n",
      "frontal view\n",
      "minnkm paper\n",
      "person\n",
      "km mykmynkykmynkt\n",
      "important\n",
      "detail\n",
      "qtsbqqtsbqqtswq proof\n",
      "approach detail conventional potential problem\n",
      "nd projection vectorsqs thatqtswq\n",
      "thesepndimensional vector cluster intomgroups\n",
      "way\n",
      "sample form\n",
      "computational di culty\n",
      "gray value pixel\n",
      "approach hand approach\n",
      "condition\n",
      "subsequent experiment experiment\n",
      "rst stage\n",
      "keywordsface\n",
      "eigenfaces\n",
      "facial\n",
      "processing\n",
      "face\n",
      "[('keywordsface', 0.3548), ('eigenfaces', 0.313), ('facial', 0.2814), ('processing', 0.2623), ('face', 0.2621)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1292269.3173891134,\n",
       "  \"rnfkq eigenvectors corre sponding large eigenvalue matrix sbswsb small sample size problem occur point eigenvectors sbswsbwill di cult compute due singularity problem order avoid direct computation sbswsb liu et al suggest derive dis criminant vector complementary subspace null space ofstst '' sbsw denote total scat ter matrix null space ofstis span eigenvectors correspond zero eigenvalue ofst since total scatter matrixstin complementary subspace nonsingular feasible follow normal process derive vector subspace however still critical problem associate approach '' rst problem liu et al approach validity vector problem know purpose maximize betweenclass scatter minimize thelf chen et alpattern withinclass scatter simultaneously special case whereqtswq '' andqtsbqo eq de '' nitely reach maximum value offkq however arbitrary projection vectorqsatisfying condition guarantee derivation maximumqtsbqvalue circumstance correct process complete withinclass scatter minimize betweenclass scatter surely maximize second problem associate liu et al approach stability problem ref author state eigenvector sensitive small perturbation correspond eigenvalue close another eigenvalue matrix unfortunately ref matrix use derive optimal projec tion vector suer abovementioned problem word optimal projection vector determina tion process may severely inuenced whenever small perturbation add third problem associate liu et al approach singularity problem approach still calculate inverse matrixst paper propose e cient accurate stable method derive vector base modi '' ed fisher ’ criterion propose approach calculate projection vector null space swbecause projection vector find subspace make projected sample form zero withinclass scatter furthermore also prove '' nding optimal projection vector original sample space equivalent calculate expres sive vector via principal component analysis abovementioned subspace follow shall describe propose method detail propose method let database comprisekclasses class containsmdistinct sample letxkmbe anndimen sional column vector denote feature vector extract themth sample thekth class suppose swandsbare respectively betweenclass scatter matrix ofxkm ’ k '' km '' suppose total scatter matrixst '' swsb accord linear algebra de '' nitions matricesstsw sbrankstranksbranksw whererankst '' minnkmranksb '' minnk andranksw `` minnkm paper shall determine projection vector null subspace ofsw therefore rank ofswcertainly major focus research suppose rank ofswisr ier '' minnkm ifr '' n implies kmnnkmnknkmnk n inequality mean rank stis equal ton consequently ifswis nonsingular stis nonsingular circumstance singularity problem matrixstsbiscomputed normal process hand ifris small thann small sample size problem occur case propose new method derive optimal projection vector illustrate graphically process derive optimal projection vector whenrn top part stand original sample space rep resents linear transformation „ x '' swxx since rank ofswis small dimensionality rn must exist subspacelsuch `` spanmaidswai '' fori '' nrnhere call null space ofsw bottom part theow chart vector determination process illustrate letq '' aanr first samplesx transform frominto subspace transformationqqt eigenvec tor correspond large eigenvalue tweenclass scatter matrixsiba new matrix form transformed sample subspaceare select vector follow shall describe approach detail first lemma show subspace derive vector base maximize modi '' ed fisher ’ criterion lemma suppose '' spanmaidswai '' airni '' nrn wherenis dimensionality samplesswis sample andris rank ofsw letsbdenote betweenclass scatter matrix sample eachqjlwhich satisxesqjtsbqjoit maximize functionfkq '' qtsbqqtsbqqtswq proof since bothsbandsware real symmetric qtsbq andqtswq allqrn follow qtsbqqtsbqqtswqnfkq `` qtsbq qtsbqqtswq obvious thatfkq '' ifqtsbqo qtswq '' eachqqjcan represent linear combination main ieqj '' nriaiai whereaiis projection coe cient ofqjwith respect toai fore swqj '' swnr iaiai '' nr iaiswai '' nqjtswqj '' conclude eachqjwhich satis '' esqjtsbqjo functionfkq maxi mizedlf chen et alpattern illustration projection vector determination process top '' gure „ linear transformation fromto „ x '' swxxis null space ofsw middle '' gurexstands original sample andxiis transform sample feature ofxobtained transformationqqt whereq '' aanrnis dimensionality samplesris rank ofsw andswai '' eachai vector compute betweenclass scatter matrixsmb ofxi lemma critical issue relate small sample size problem occur arbitrary vectorqjthat maximizesfkq necessarily optimal vector situationqjtsbqjis guarantee reach maximal value therefore one conclude su cient derive vector simply base modi '' ed fisher ’ criterion small sample size problem occur follow lemma show transform sample inis complete zero matrix lemma important prove correct determination vector long depend total scatter matrix instead vector derive directly betweenclass scatter matrix lemma letqqtbe transformation transforms sample ininto subspace whereq '' aanris annnrmatrix eachaisatisxes swai '' '' nr subspace span orthonormal ofai ’ sample transform subspacethroughqqt siwof transform sample inis complete zero matrixproofsupposexkmis feature vector extract themth sample thekth class data base comprisedkclasses class containsm sample letykmdenote transformed feature vector ofxkmthrough transformationqqt ykm '' qqtxkmynk '' qqtxnk andyn '' qqtxn wherexnk '' mmmxkmandx '' kmkkmmxkmthus siw '' k km mykmynkykmynkt `` k km mqqtxkmqqtxnkqqtxkmqqtxnkt `` qqtk km mxkmxnkxkmxnkqqt `` qqtswqqt '' sinceswq '' mention earlier process use determine projec tion ax sample projection project sample form minimum withinclass scatter maximum betweenclass scatter lemma tell u anyqj long satis '' esqjtsbqjo modi '' ed fisher ’ criterionfkq maximize lf chen et alpattern however lemma also tell u add another criterion perform depend fisher ’ criterion lemma hand tell u selection ofqjenforcessiw '' saysit '' siwsib '' sib sincesiwis consistently equal select projection ax maxi mize betweenclass scatter two lemma know maximize betweenclass scatter inis equal maximizing total scatter circumstance apply princi pal component analysis pca method derive projection vector ful '' requirement physical meaning pca '' nd expressive projection vector project sample retain informa tion original sample expressive vector derive pca process theleigenvectors correspond thellargest eigenvalue ofsit lijinijipnis dimensionality sample andjirepresents eigenvalue order theith place insit basicallyjiis decrease order tonif p '' good enough representation obtain follow shall show propose method theorem base two lemmas theorem suppose thatq '' aanrand thatai eigenvectors correspond zero eigenvalue swin original feature space wherenis dimensionality featurevectors andris rank ofsw letdenote subspace span eigenvectorsaanrifris small thann expressivevectorqjinobtained transformationqqtwill proof lemma know siwinis complete zero matrix thus betweenclass scatter matrixsibinis equal total scatter matrixsitin expressive projection vectorqjinsatis `` esqjtsibqj ’ supposesb '' sibskb wheresbsib andskbare real symmetric qjtsbqj '' qjtsibqjqjtskbqjqjtsibqj ’ nqjtsbqjo show thatqjis optimal solution within maximizefkq since expressive projection vectorqjincan maximize value ofqjtsbqj andqjtswqj '' know conclude expressive projection vector inis dis criminant projection vector infor projecting sample onto projective feature space base theorem euclidean distance classi '' er use perform classi '' cation projec tive feature spacethe propose algorithm inputnndimensional vector outputthe optimal vector alln input vector algorithm step calculate withinclass scatterswand betweenclass scattersb step suppose rank ofswisrifr '' n eigenvectors correspond large eigenvalue matrix sbswsb otherwise go next step step perform singular value decomposition swassw '' u '' v becauseswis symmetric step let '' llrlr ln andq '' lr ln show ref null space ofswcan span bylr ln step computesib wheresib '' qqtsbqqtt step calculate eigenvectors correspond large eigenvalue ofsiband use form vector experimental result database construction feature extraction facial image database contain person class person dierent face im age frontal view obtain process collect facial image follow ask person sit front ccd camera neutral expression slightly head move frontal view period record videotape wellcontrolled light condition later frame grabber use grab image frame videotape store resolution pixel accord ing conclusion drawn ref state statisticsbased face system base solely ‘ pureaface portion faceonly database build use previously de veloped morphologybased '' lter part database show pixel group database image transform normalized size database image pile aligned orientation process dimensional vector obtain vector cluster mgroups wheremstands require resolution use thekmeans cluster method image average gray value group calculate thesemmean value use represent whole image therefore dimensionality image reduce tomdimensions sincemis variable stand dimensionality feature vector experimentation design anlf chen et alpattern table face result obtain apply dierent num bers feature extract image train database contains person person contain six distinct sample number featuresnumber projection ax use rate training time '' '' '' '' experimental result obtain use method small sample size problem\"),\n",
       " (1191128.8804618495,\n",
       "  \"correspond author telx fax email addressliaoiissinicaedutw hym liao pattern new base face system solve small sample size problem lifen chen hongyuan mark liao '' mingtat ko '' jachen lin gwojong yu department computer information science national chiao tung university hsinchu taiwan `` institute information science academia sinica institute computer science information engineering national central university chungli taiwan receive june receive revised form june accept june abstract new base face system present paper linear analysis one popular linear projection technique feature extraction major drawback applying may encounter thesmall sample size problem paper propose new base technique solve small sample size problem also prove expressive vector derive null space use principal component analysis pca equal derive original space use experimental result show new process improve performance face system signi '' cantly pattern publish elsevier science ltd right reserve keywordsface feature extraction linear analysis linear algebra introduction face hot research topic recent year complete face system include two step ie face detection face paper attention focus face part last year successful face system develop reported literature among works system report refs adopt linear analysis approach enhance class separability purpose one popular linear projection technique feature extraction '' nds projectionvectors map highdimensional sample onto lowdimensional space use projection vector determine projection ax project sample form maximum betweenclass scatter minimum withinclass scatter simulta neously projective feature space major draw back apply may encounter socalledsmall sample size problem problem arise whenever number sample small dimensionality sample circum stance sample scatter matrix may become singular execution may encounter computational di culty recent year many researcher notice problem try solve use ref goudail et al propose technique calculate local autocorrelation coe cients sample image achieve dimensionality reduction sim ilarly swets weng apply pca approach accomplish reduction image dimensionality besides image dimensionality reduction researcher pattern publish elsevier science ltd right reserve pii try overcome computational di culty directly use linear algebra instead calculate eigenvalue eigenvectors annnmatrix fukunaga propose e cient algorithm calculate eig envalues eigenvectors anmmmatrix nis dimensionality sample andmis rank sw ref tian et al use positive pseudoinverse matrix winstead calcu lating matrixsw purpose hong yang try add singular value perturbation swand madeswa nonsingular matrix ref cheng et al propose another method base principle rank decomposition matrix three method base conventional fisher criterion function liu et al modi '' ed conventional fisher criterion function conduct number research base new criterion function use total scatter matrix st '' sbsw divisor original fisher func tion instead merely use propose another algorithm base foleysammon transform select projection vector know purpose process maximize tweenclass scatter simultaneously minimize withinclass scatter small sample size problem occur swis singular theory linear algebra tell u possible '' nd projection vectorsqs thatqtswq '' qtsbqo special circumstance modi '' ed fisher ’ criterion function propose liu et al de '' nitely reach maximum value ie however arbitrary projection vectorqsatisfying maximum value modi '' ed fisher ’ criterion guarantee maximum class separability unlessqtsbqis maximize liu et al approach also suers stability problem eigenvalues deter mine use method may close problem result instability projec tion vector determination process another drawback liu et al approach method still calculate inverse matrix time calculation inverse matrix believe bottleneck reduces e ciency paper e cient accurate stable method propose calculate projection vector base modi '' ed fisher ’ cri terion feature extraction twostage procedure devise '' rst stage homogeneous region group partition base geometric characteristic eye nose mouth partition use mean gray value pixel within partition represent fore every reduced feature vector second stage use feature vector extract '' rst stage determine projection ax base new process propose new process start calculate projection vector null space sw null space span eigenvectors correspond zero eigen value ofsw subspace exist ieswis nonsingular thenstis also nonsingular circumstance choose eigenvectors correspond ing large eigenvalue matrix sbswsbas vector wise small sample size problem occur case choose vector maximize betweenclass scatter transform sample projection ax since withinclass scatter sample zero null space ofsw projection vector satisfy objective process one maximize betweenclass scatter similar concept mention ref ever show investigation result draw conclusion concern concept conduct series experiment compare result liu et al approach template matching approach experimental sults show method superior liu et al approach template matching approach term accuracy furthermore also prove method well liu et al approach term train e ciency well stabil ity indicate new process signi '' cantly improve performance face system organization rest paper follow section complete twophase feature extraction procedure introduce experimental result cluding database construction experiment small sample size problem comparison two wellknown approach present section finally conclude remark give section feature extraction section shall describe detail propose feature extraction technique include two phase pixel group generalize base modi `` ed fisher ’ function pixel group accord conclusion drawn ref statisticsbased face system base solely ‘ pureaface portion order ful '' requirement build faceonly database use previously develop morphology base '' lter use morphological '' lter eye analogue segment group pair use locate potential face region thus every constituent oflf chen et alpattern example normalize faceonly image top two row image person bottom two row another person illustration pixel group processnnormalized pile align orientation suppose image size ispp thenpndimensional vector obtain element vector gray value pixel inndierent imagesthe faceonly database face portion contain eye nose mouth example face database show order execute pixel group abovementioned faceonly image transform normalized size let train database comprise ofnnormalized faceonly image sizepp pile thesenimages align orientation show therefore obtainpndimensional vector whose element gray value pixel thesepndimensional vector cluster intomgroups use thek mean cluster method wheremis resolution transform image cluster image par titioned intomgroups pixel assign one group image calculate average gray value group use thesemmean value represent whole image thus thepdimensional image reduce tomdimensional withmp show example transform image image leftmost column original im age size others transform image increase resolution respectively leave right pixel group use transform image execute second phase generalize generalize purpose pixel group reduce dimen sionality sample extract geometric feature however take class separability consid eration literature well know technique deal class separability problem use determine themost projection ax project sample onto ax project sample form maximum betweenclass scatter min imum withinclass scatter projective feature space follow shall '' rst introduce ap proach relate work second subsec tion shall describe approach detail conventional potential problem let training comprisekclasses one determine mapping xjkm '' atxkm wherexkmdenotes thendimensional feature vector extract themth sample thekth class xjkmdenotes theddimensional projective feature vector xkmtransformed thendtransformation matrixa one way '' nd mappingais use fisher criterion fq '' qtsbq qtswq whereqrnsb '' kkxnkxnxnkxntandsw '' kkmmxkmxnkxkmxnktare betweenclass scatter matrix respectively wherexnk '' mmmxkmandxn '' kmkkmmxkmlf chen et alpattern result obtain perform pixel grouping image leftmost column original image others transform image increase resolu tions leave right column vector ofacan choose ofqj ’ qj '' arg max q project thexkm ’ wherek '' k '' onto theqjaxis project samplesxjkm ’ k '' km '' form maximum tweenclass scatter minimum withinclass scatter vectorqjis call optimal projection vector accord linear algebra allqjs eigen vector correspond large eigenvalue swsb major drawback apply ap proach may encounter thesmall sample size problem small sample size problem occur whenever number sample small thedimensionality sample whenever happen matrixswbecomes singular computation swbecomes complex di cult liu et al seriously address problem one eorts propose modi '' ed fisher ’ criterion function fkq replace original fisher functionfq prove thatfkq exactly equivalent tofq arg max q\"),\n",
       " (292456.1583204834,\n",
       "  \"phd degrees electrical engineering northwestern university respectively research associate computer vision image process laboratory northwestern university july join institute information science academia sinica assistant research fellow promote associate research fellow research fellow respectively currently deputy director institute dr liao ’ current research interest computer vision signal processing waveletbased image analysis contentbased image retrieval image watermaking recipient young investigator ’ award academia sinica best paper award image processing pattern taiwan paper award society dr liao serve program chair international symposium multimedia information processing ismip also serve program committee international symposium arti '' cial neural network international symposium multitechnology information process international conference tool ai dr liao associate editor ieee transaction multimedia journal information science engineering member ieee computer society international neural network society inn authorjachen lin bear republic china receive bs degree computer science ms degree apply mathematics national chiao tung university taiwan receive phd degree mathematics purdue university usa instructor national chiao tung university graduate instructor purdue university join department computer information science national chiao tung university august currently professor recent research interest include pattern image processing dr lin member phitauphi scholastic honor society hy mark liao cc han gj yu hr tyan mc chen lh chen face use faceonly database new approach proceeding third asian conference computer vision hong kong lecture note computer science vol pp b moghaddam pentland probabilistic visual learning object representation ieee trans pattern anal mach intell turk pentland eigenfaces j cogni tive neurosci k liu cheng j yang algebraic feature extraction image base optimal cri terion pattern f goudail e lange iwamoto k n otsu face system use local autocorrelations multiscale integration ieee trans pattern anal mach intell swets j weng use eigenfeatures image retrieval ieee trans pattern anal mach intell pn belhumeur jp hespanha dj kiregman eigen face v '' sherfaces use class speci '' c linear projection ieee trans pattern anal mach intell k fukunaga introduction statistical pattern recogni tion academic press new york q tian barbero zh gu sh lee image classi '' ca tion foleysammon transform opt eng ziquan hong jingyu yang optimal plane small number sample design method ofclassi '' er plane pattern cheng ym jy yang optimal '' sher dis criminant analysis use rank decomposition pattern k liu cheng j yang generalize optimal vector pattern k liu yq cheng jy yang liu e cient algo rithm foleysammon optimal vec tor algebraic method int j pattern recog artif intell dh foley jw sammon optimal vector ieee trans comput lf chen hym liao cc han jc lin statisticsbased face system base pure face portion probabilistic decisionbased proof proceeding symposium image speech signal processing robotics chinese university hong kong september invited pp fisher mathematical theory probability macmillan new york gw stewart introduction matrix computation academic press new york b noble jw daniel apply linear algebra prentice hall englewood cli nj rc gonzalez wood digital image processing addisonwesley read ak jain rc dub algorithms cluster data prenticehall englewood cli nj lf chen et alpattern authormingtat ko receive bs\"),\n",
       " (241036.50279188415,\n",
       "  \"sign represent respectively result obtain use approach liu et al approach ac obvious training time require liu et al approach grow exponentially database augmented reason outcome projection ax deter mination process liu et al method projectionaxes determine iteratively iteration algorithm derive projection vector recal culated subspace therefore training time expo nentially proportional number class adopt database comparison liu et al approach approach require constant time train approach calculate sub space derive projection vector subspace experimental result show comparison liu et al approach term accuracy e ciency follow shall compare method liu et al method use another important criterionthe stability criterion table show experimental result regard stability test method liu et al thislf chen et alpattern table stability test execute derivation '' rst optimal projection vector train database comprise class class contain three sample element show second fourth column represent orientation dierence current optimal projection vector projection vector derive previous iteration iteration method liu method orientation dierence degree rate orientation dierence degree rate table eigenvalue use derive '' rst optimal projection vector element show left column eigen value determine use method one show right column determine use liu et al method eigenvalue determine use methodeigenvalues determine use liu method e e e e e e e e e e e e e e e e e e experiment try compute '' rst optimal projection vector iteration leftmost column table indicate iteration number element show second fourth column table orientation dierence degree current optimal projection vector projection vector de rive previous iteration data show second column obtain apply method data show fourth column obtain apply liu et al method theoretically opti mal projection vector determine base data stay change slightly consecutive iteration table obvious projection vector determine method stable consecutive iteration hand projection vector determine liu et al method change signi '' cantly every two con secutive iteration linear algebra tell u eigenvector sensitive small perturbation correspond eigenvalue close another eigen value matrix table show eigenvalues obtain method liu et al obvious eigenvalue obtain method quite dierent however eigenvalues ob tained liu et al method almost data con '' rm method much stable liu et al another important issue need discuss inuence reserve percentage ofdim rate since construction ofis time consume task approach would like show empirically use part space approach still obtain good result illustrate inuence reserve percentage ofdim rate number ofclasses change\"),\n",
       " (211153.03703156076,\n",
       "  \"sign mean two three six sample class respectively database comprised class '' gure show information person uniformly distribute null space ofsw therefore percentage ofdim inuence result much class contain database high percentage ofshould reserve obtain good result hand show information person uniform ly distribute null space ofsw therefore thepercentage ofdim inuence result much conclude remark paper propose new base face system know major drawback applying may encounter small sample size problem small sample size prob lem occur swbecomes singular apply theory linear algebra '' nd projection vectorsq ’ qtswq '' andqtsbqo special cir cumstances modi '' ed fisher ’ criterion function pro pose liu et al reach maximum value ie however find arbitrary projection vectorqsatisfying maximum value modi '' ed fisher ’ criterion guarantee maximum class separability unlessqtsbqis maximize therefore propose new process start calculation projection vector null space sw subspace exist ieswis nonsingular normal process use solve problem otherwise small sample size problem occur choose vector maximize betweenclass scatter transform sample projection ax since withinclass scatter sample zero null space ofsw projection vector satisfy objective process one maximize betweenclass scatter experimental result show method superior liu et al ap proach term accuracy train e ciency stability reference r chellappa c wilson sirohey human machine face survey proc ieee valentin h abdi toole g cottrell connection ist model face process survey pattern recogni tion r brunelli poggio face feature versus template ieee trans pattern anal mach intell samal p iyengar automatic analysis human face facial expression survey pattern sh jeng hy mark liao cc han chern yt liu facial feature detection use geometrical face model e cient approach pattern cc han hy mark liao gj yu lh chen fast face detection via morphologybased preprocessing pattern appearlf chen et alpattern authorlifen chen receive bs degree computer science national chiao tung university hsingchu phd student department computer information science national chiao tung university research interest include image processing pattern computer vision wavelet authormark liao receive bs degree physic national university hsinchu\"),\n",
       " (84014.18043402777,\n",
       "  \"sign mean class database contain three six sample respectivelyexperiment decide best value ofmfor subsequent experiment experiment chose training database contain person six frontal view sample person test purpose use person test database within database obtain sample person since database use large database projection vector could directly compute fromstsb table show experimental result obtain ap ply dierentmvalues '' data show second column table number projection ax use certain resolution number projection ax adopt decide check thepvalue mention section preached use correspond number projection ax maximum number projection ax therefore form '' correspond number projection ax adopt respec tively table '' nd thatm '' suitable number feature term rate training e ciency therefore subsequent experiment number '' globally use experiment small sample size problem order evaluate method interact small sample size problem include problem like number sample class total number class use conducted experiment show result horizontal axis repres ents number class use vertical axis represent correspond rate\"),\n",
       " (79014.08786432381,\n",
       "  \"sign show stand result obtain use approach liu et al ap proach templatematching approach respective ly furthermore data show ac experimental result obtain class contain respectively sample among three ap proaches templatematching approach perform base solely original feature vector therefore involved process furthermore data show obvious liu et al approach worst basically serious problem occur liu approach degrade discriminate capability although thederived vector maximize modi '' ed fisher ’ criterion function optimal class separability condition objective process surely satis '' ed therefore projection ax deter mine liu et al approach could guarantee provide best class separability database sample therefore wonder performance liu et al approach even worse templatematching approach hand approach apparently superior force withinclass scatter subspace zero constraint restrict problem small domain hence could solve much easy way another advantage approach need tolf chen et alpattern training time require method\"),\n",
       " (50498.43161527834,\n",
       "  \"rnfq follow shall directly describe two theorem ref related work theorem suppose r ndimensional space '' xrfxgxandfxgx let hx '' fxgxandhx '' fxfxgxthen hxhas maximum include positiveinxnity point maximum pointx theorem fisher ’ criterion functionfqcan replace fkq '' qtsbq qtswqqtsbq course solve optimal two theorem know thatfq fkq functionally equivalent term solve optimal projection ax vector therefore one choose eitherfqorfkq derive optimal projection ax paper propose new method calculate optimal projection ax base fkq accord normal process solu tions max q\"),\n",
       " (49742.463521764905,\n",
       "  \"sign indicate sample class respectively experimentation result show reect propose approach perform fairly well size database small however whenkthe number class multiply number sample minus close tonn '' performance drop signi '' cantly phenomenon es pecially true case wherem '' section mention information derive vector depend null space ofsw dimension ofdim equal nkmk wherenis equal ki number class andmis number sample class whenm '' andkapproached km close ton circumstance recogni tion rate drop signi '' cantly see reason phenomenon emerge low value ofdim thedim value small many space available derive projection ax hence rate drop inspect another curve\"),\n",
       " (44948.77356426158,\n",
       "  'sign see since two sample class correspond curve rate monotonous case contain sample class part experiment provide good guide make good decision regard number sample class number class database one want solve small sample size problem good performance experi mental result use good reference comparison approach order demonstrate eectiveness ap proach conduct series experiment com par result obtain use two wellknown approach show experimental result obtain use approach liu et al ap proach template match approach horizontal axes vertical ax represent number class database correspondinglf chen et alpattern experimental result obtain use method'),\n",
       " (38060.23960762228,\n",
       "  'sign horizontal axis represent number class database vertical axis stand training time result obtain class contains two sample b result obtain class contains three sample c result obtain class contains six samplescompute inverse matrix liu et al computa tion inverse matrix indispensable however since project sample onto appropriate subspace computation inverse matrix consider time bottleneck avoid another advantage approach liu et al approach training time requirement show three experiment experiment use dierent number sample class b c'),\n",
       " (30351.53395363407,\n",
       "  'mathematics national university respectively receive phd computer science national tsing hua university since join institute information science associate research fellow dr ko major research interest include design analysis algorithms computational geometry graph algorithms realtime system computer graphic authorgwojong yu born keelung taiwan receive bs degree information computer engineering chungyuan christian university chungli currently work toward phd degree computer science research interest include face statistical pattern neural networkslf chen et alpattern'),\n",
       " (13999.385436604327,\n",
       "  'sign indicate sample class respectively see reserve dim rate could always reach moreover result show reect information retain spacethe null space ofsw sensitive number class meanslf chen et alpattern illustration inuence reserve percentage dim rate'),\n",
       " (12253.346440560743,\n",
       "  'sign mean class database respectively class contains three distinct sample `` gure show information contain null space swwas sensitive number class database illustration inuence reserve percentage dim rate'),\n",
       " (12198.672207933172,\n",
       "  'sign horizontal axis represent number class database vertical axis stand rate result obtain class contains two sample b result obtain class contains three sample c result obtain class contains six sample rate respectively addition'),\n",
       " (11300.86578186985,\n",
       "  'sign indicate class database respectively mention class class contain three distinct sample three curve show obvious reser ving ofdim rate could still maintain hand illustrates inuence reserve percentage ofdim rate number sample class change'),\n",
       " (3695.944927536232, \"rnfkq '' arg max q\"),\n",
       " (2832.1360090002167, 'sign mean class database contain sample'),\n",
       " (1322.6588203463202, 'sign liu method'),\n",
       " (1322.6588203463202, 'sign liu method'),\n",
       " (712.1625, 'sign template match'),\n",
       " (89.5625, 'sign')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "from PyPDF2 import PdfFileReader\n",
    "\n",
    "def extract_text(filename):\n",
    "    #with open(pdf_path, 'rb') as f:\n",
    "    f = open(filename, 'rb')\n",
    "    pdf = PdfFileReader(f);\n",
    "    if pdf.isEncrypted:\n",
    "        try:\n",
    "            pdf.decrypt('')\n",
    "            print('File Decrypted (PyPDF2)')\n",
    "        except:\n",
    "            command = (\"cp \"+ filename +\n",
    "                \" temp.pdf; qpdf --password='' --decrypt temp.pdf \" + filename\n",
    "                + \"; rm temp.pdf\")\n",
    "            os.system(command)\n",
    "            print('File Decrypted (qpdf)')\n",
    "            return \"\"\n",
    "            #f = open(filename, 'rb')\n",
    "            #pdf = PdfFileReader(f)\n",
    "    else:\n",
    "        print('File Not Encrypted')\n",
    "    curtext= \"\"\n",
    "    for i in range(0,pdf.getNumPages()):\n",
    "        \n",
    "        page = pdf.getPage(i)\n",
    "        #print(page.extractText())\n",
    "        curtext += page.extractText()\n",
    "    return curtext\n",
    "    \n",
    "     \n",
    "path = 'C:\\\\Users\\\\stefa\\\\OneDrive\\\\Desktop\\\\Uni\\\\Business\\\\Project\\\\Papers\\\\face_recognition_systems'\n",
    "# path = 'C:\\\\Users\\\\stefa\\\\OneDrive\\\\Desktop\\\\Uni\\\\Business\\\\Project\\\\Papers\\\\fusion_method'\n",
    "# path = 'C:\\\\Users\\\\stefa\\\\OneDrive\\\\Desktop\\\\Uni\\\\Business\\\\Project\\\\Papers\\\\keypoint_heatmap'\n",
    "# path = 'C:\\\\Users\\\\stefa\\\\OneDrive\\\\Desktop\\\\Uni\\\\Business\\\\Project\\\\Papers\\\\face_cluster'\n",
    "# path = 'C:\\\\Users\\\\stefa\\\\OneDrive\\\\Desktop\\\\Uni\\\\Business\\\\Project\\\\Papers\\\\neural_aggregation_network'\n",
    "# path = 'C:\\\\Users\\\\stefa\\\\OneDrive\\\\Desktop\\\\Uni\\\\Business\\\\Project\\\\Papers\\\\field_view_head_mounted_display'\n",
    "# path = 'C:\\\\Users\\\\stefa\\\\OneDrive\\\\Desktop\\\\Uni\\\\Business\\\\Project\\\\Papers\\\\feature_network'\n",
    "\n",
    "print(\"Getting files...\")\n",
    "# getting all files from the directory given by the path\n",
    "files = os.listdir(path)\n",
    "# moving to the desired directory\n",
    "os.chdir(path)\n",
    "text = \"\"\n",
    "cur_text = \"\"\n",
    "filename = 'C:\\\\Users\\\\stefa\\\\OneDrive\\\\Desktop\\\\Uni\\\\Business\\\\Project\\\\Papers\\\\face_recognition_systems\\\\1-s2.0-S0031320399001399-main.pdf'\n",
    "if filename.endswith('.pdf'):\n",
    "    text += extract_text(filename); # read file content\n",
    "\n",
    "# lower() is a Python function for strings\n",
    "lower_text = \"\"\n",
    "for pdf_text in text:\n",
    "    lower_text += pdf_text.lower() #we pick each word and add to a variable, which will contain all the text\n",
    "\n",
    "#white space removal \n",
    "def remove_whitespace(text):\n",
    "    return  \" \".join(text.split())\n",
    "\n",
    "lower_text = remove_whitespace(lower_text)\n",
    "\n",
    "\n",
    "#punctuation and digits removal: we replace any undesired character with a ''\n",
    "for char in '?.,¡!/;:*#-~+±–—=%<>{}[]()@1234567890':  \n",
    "    lower_text = lower_text.replace(char,'')\n",
    "\n",
    "import pke\n",
    "\n",
    "# initialize keyphrase extraction model, here TopicRank\n",
    "print(\"Initializing extractor...\")\n",
    "extractor = pke.unsupervised.TopicRank()\n",
    "\n",
    "# load the content of the document, here document is expected to be in raw\n",
    "# format (i.e. a simple text file) and preprocessing is carried out using spacy\n",
    "print(\"Loading text...\");\n",
    "extractor.load_document(input=lower_text, language='en')\n",
    "\n",
    "# keyphrase candidate selection, in the case of TopicRank: sequences of nouns\n",
    "# and adjectives (i.e. `(Noun|Adj)*`)\n",
    "print(\"Candidate Selection...\")\n",
    "extractor.candidate_selection()\n",
    "\n",
    "# candidate weighting, in the case of TopicRank: using a random walk algorithm\n",
    "print(\"Weighting...\")\n",
    "extractor.candidate_weighting()\n",
    "\n",
    "# N-best selection, keyphrases contains the 10 highest scored candidates as\n",
    "# (keyphrase, score) tuples\n",
    "print(\"Selecting 10 best candidates...\")\n",
    "keyphrases = extractor.get_n_best(n=10)\n",
    "for tuple in keyphrases:\n",
    "    print(tuple[0])\n",
    "    lower_text = lower_text.replace(tuple[0],'')\n",
    "print(keyphrases)\n",
    "\n",
    "from keybert import KeyBERT\n",
    "kw_model = KeyBERT()\n",
    "keywords = kw_model.extract_keywords(lower_text)\n",
    "for tuple in keywords:\n",
    "    print(tuple[0])\n",
    "    lower_text = lower_text.replace(tuple[0],'')\n",
    "\n",
    "print(kw_model.extract_keywords(lower_text, keyphrase_ngram_range=(1, 1), stop_words=None))\n",
    "\n",
    "import nltk\n",
    "nltk.sent_tokenize(lower_text)\n",
    "\n",
    "# the output is a list, where each element is a token of the original text\n",
    "tokenized_text = nltk.word_tokenize(lower_text)\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stopwords_en = stopwords.words('english')\n",
    "\n",
    "# we prepare a empty list, which will contain the words after the stopwords removal\n",
    "tokenized_vector = []\n",
    "\n",
    "# we iterate into the list of tokens obtained through the tokenization\n",
    "for token in tokenized_text:\n",
    "    # if a token is not a stopword, we insert it in the list\n",
    "    if token not in stopwords_en:\n",
    "        tokenized_vector.append(token)\n",
    "\n",
    "# the output is a list of all the tokens of the original text excluding the stopwords\n",
    "\n",
    "pos_tagging = nltk.pos_tag(tokenized_vector)\n",
    "\n",
    "cleaned_POS_text = []\n",
    "\n",
    "for tuple in pos_tagging:\n",
    "    # POS tagged text is a list of tuples, where the first element tuple[0] is a token and the second one tuple[1] is\n",
    "    # the Part of Speech. If the POS has length == 1, the token is punctuation, otherwise it is not, and we insert it\n",
    "    # in the list cleaned_POS_text\n",
    "    if len(tuple[1]) > 1:\n",
    "        cleaned_POS_text.append(tuple)\n",
    "\n",
    "def simpler_pos_tag(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return \"a\"\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return \"v\"\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return \"n\"\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return \"r\"\n",
    "    else:         \n",
    "        return None\n",
    "    \n",
    "simpler_POS_text = []\n",
    "\n",
    "# for each tuple of the list, we create a new tuple: the first element is the token, the second is\n",
    "# the simplified pos tag, obtained calling the function simpler_pos_tag()\n",
    "# then we append the new created tuple to a new list, which will be the output\n",
    "for tuple in cleaned_POS_text:\n",
    "    if tuple[1] == 'NNP':   #this is because there is some text in japanese categorized as 'NNP';\n",
    "                            #no other relevant words are categorized in such a way\n",
    "        continue;\n",
    "    POS_tuple = (tuple[0], simpler_pos_tag(tuple[1]))\n",
    "    simpler_POS_text.append(POS_tuple)\n",
    "    \n",
    "\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "lemmatized_text = []\n",
    "\n",
    "for tuple in simpler_POS_text:\n",
    "    if (tuple[1] == None):\n",
    "        lemmatized_text.append(lemmatizer.lemmatize(tuple[0]))\n",
    "    else:\n",
    "        lemmatized_text.append(lemmatizer.lemmatize(tuple[0], pos=tuple[1]))\n",
    "\n",
    "lem_text = \"\"\n",
    "for abstract_text in lemmatized_text:\n",
    "    lem_text += abstract_text + \" \" #we pick each word and add to a variable, which will contain all the text\n",
    "lem_text\n",
    "\n",
    "import pke\n",
    "# initialize keyphrase extraction model, here TopicRank\n",
    "print(\"Initializing extractor...\")\n",
    "extractor = pke.unsupervised.TopicRank()\n",
    "\n",
    "# load the content of the document, here document is expected to be in raw\n",
    "# format (i.e. a simple text file) and preprocessing is carried out using spacy\n",
    "print(\"Loading text...\");\n",
    "extractor.load_document(input=lem_text, language='en')\n",
    "\n",
    "# keyphrase candidate selection, in the case of TopicRank: sequences of nouns\n",
    "# and adjectives (i.e. `(Noun|Adj)*`)\n",
    "print(\"Candidate Selection...\")\n",
    "extractor.candidate_selection()\n",
    "\n",
    "# candidate weighting, in the case of TopicRank: using a random walk algorithm\n",
    "print(\"Weighting...\")\n",
    "extractor.candidate_weighting()\n",
    "\n",
    "# N-best selection, keyphrases contains the 10 highest scored candidates as\n",
    "# (keyphrase, score) tuples\n",
    "print(\"Selecting 40 best candidates...\")\n",
    "keyphrases = extractor.get_n_best(n=80)\n",
    "for tuple in keyphrases:\n",
    "    print(tuple[0])\n",
    "#print(keyphrases)\n",
    "\n",
    "from keybert import KeyBERT\n",
    "kw_model = KeyBERT()\n",
    "keywords = kw_model.extract_keywords(lem_text)\n",
    "for tuple in keywords:\n",
    "    print(tuple[0])\n",
    "\n",
    "print(kw_model.extract_keywords(lem_text, keyphrase_ngram_range=(1, 1), stop_words=None))\n",
    "\n",
    "from rake_nltk import Rake\n",
    "\n",
    "# Uses stopwords for english from NLTK, and all puntuation characters by\n",
    "# default\n",
    "r = Rake()\n",
    "\n",
    "# Extraction given the text.\n",
    "r.extract_keywords_from_text(lem_text)\n",
    "\n",
    "# To get keyword phrases ranked highest to lowest.\n",
    "r.get_ranked_phrases()\n",
    "\n",
    "# To get keyword phrases ranked highest to lowest with scores.\n",
    "r.get_ranked_phrases_with_scores()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccec8ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
