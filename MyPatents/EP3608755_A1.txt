<document>

<filing_date>
2018-10-09
</filing_date>

<publication_date>
2020-02-12
</publication_date>

<priority_date>
2018-08-09
</priority_date>

<ipc_classes>
G06F3/01,G06F3/03,G06K9/00
</ipc_classes>

<assignee>
ACER
</assignee>

<inventors>
CHIU, SHENG-LIN
HUNG, YING-SHIH
LEE, AN-CHENG
WU, CHENG-TSE
</inventors>

<docdb_family_id>
63832223
</docdb_family_id>

<title>
ELECTRONIC APPARATUS OPERATED BY HEAD MOVEMENT AND OPERATION METHOD THEREOF
</title>

<abstract>
An electronic apparatus including an image capturing device, a storage device and a processor and an operation method thereof are provided. The image capturing device captures an image for a user, and the storage device records a plurality of modules. The processor is coupled to the image capturing device and the storage device and is configured to: configure the image capturing device to capture a head image of a user; perform a face recognition operation to obtain a face region; detect a plurality of facial landmarks within the face region; estimate a head posture angle of the user according to the facial landmarks; calculate a gaze position where the user gazes on the screen according to the head posture angle, a plurality of rotation reference angle, and a plurality of predetermined calibration positions; and configure the screen to display a corresponding visual effect according to the gaze position.
</abstract>

<claims>
1. An electronic device (10), configured to make a screen (110) to display a plurality of image frames, comprising: an image capturing device (120); a storage device (130), storing a plurality of modules; and a processor (14), coupled to the image capturing device (140) and the storage device (130), configured to execute the modules in the storage device (130) to: configure the screen (110) to display a plurality of marker objects at a plurality of predetermined calibration positions; configure the image capturing device (120) to capture a plurality of first head images when a user is looking at the predetermined calibration positions; (S301) perform a plurality of first face recognition operations on the first head images to obtain a plurality of first face regions corresponding to the predetermined calibration positions; (S302) detect a plurality of first facial landmarks corresponding to the first face regions; (S303) calculate a plurality of rotation reference angles of the user looking at the predetermined calibration positions according to the first facial landmarks; configure the image capturing device (120) to capture a second head image of the user; perform a second face recognition operation on the second head image to obtain a second face region; detect a plurality of second facial landmarks within the second face region; (S304) estimate a head posture angle of the user according to the second facial landmarks; calculate a gaze position of the user on the screen (110) according to the head posture angle, the rotation reference angles, and the predetermined calibration positions; and configure the screen (110) to display a corresponding visual effect according to the gaze position.
2. The electronic device (10) according to claim 1, wherein the gaze position comprises a first coordinate value in a first axial direction and a second coordinate value in a second axial direction.
3. The electronic device (10) according to claim 2, wherein the head posture angles comprise a head pitch angle and a head yaw angle, and the rotation reference angles comprise a first pitch angle, a second pitch angle, a first yaw angle, and a second yaw angle corresponding to the predetermined calibration positions.
4. The electronic device (10) according to claim 3, wherein the processor (140) performs interpolation operation or extrapolation operation according to the first yaw angle, the second yaw angle, a first position corresponding to the first yaw angle among the predetermined calibration positions, a second position corresponding to the second yaw angle among the predetermined calibration positions and the head yaw angle, thereby obtaining the first coordinate value of the gaze position; and
the processor (140) performs interpolation operation or extrapolation operation according to the first pitch angle, the second pitch angle, a third position corresponding to the first pitch angle among the predetermined calibration positions, a fourth position corresponding to the second pitch angle among the predetermined calibration positions and the head pitch angle, thereby obtaining the second coordinate value of the gaze position.
5. The electronic device (10) according to claim 1, wherein the processor (140) calculates a plurality of first viewing distances between the user and the screen (110) according to the first facial landmarks;
The processor (140) estimates a second viewing distance between the user and the screen (110) according to the second facial landmarks; and
the processor (140) adjusts the rotation reference angles or the gaze position according to the second viewing distance and the first viewing distances.
6. The electronic device (10) according to claim 1, wherein the processor (140) maps a plurality of two-dimensional position coordinates of the second facial landmarks under a plane coordinate system to a plurality of three-dimensional position coordinates under a three-dimensional coordinate system; and
the processor (140) estimates the head posture angle according to the three-dimensional position coordinates of the second facial landmarks.
7. The electronic device (10) according to claim 1, wherein the second head image comprises a wearable device, and the second facial landmarks do not comprise a plurality of third facial landmarks of the user covered by the wearable device.
8. The electronic device (10) according to claim 1, wherein the second head image comprises a wearable device, and the second facial landmarks comprise one or more simulated landmarks marked by the wearable device.
9. An operating method, adapted for an electronic device (10) comprising an image capturing device (120) and making a screen (110) to display a plurality of image frames, the method comprising: configuring the screen (110) to display a plurality of marker objects at a plurality of predetermined calibration positions; configuring the image capturing device (120) to capture a plurality of first head images when a user is looking at the predetermined calibration positions; (S301) performing a plurality of first face recognition operations on the first head images to obtain a plurality of first face regions corresponding to the predetermined calibration positions; (S302) detecting a plurality of first facial landmarks corresponding to the first face regions; (S303) calculating a plurality of rotation reference angles of the user looking at the predetermined calibration positions according to the first facial landmarks; configuring the image capturing device (120) to capture a second head image of the user; performing a second face recognition operation on the second head image to obtain a second face region; (S304) detecting a plurality of second facial landmarks within the second face region; estimating a head posture angle of the user according to the second facial landmarks; calculating a gaze position of the user on the screen (110) according to the head posture angle, the rotation reference angles, and the predetermined calibration positions; and (S305) configuring the screen (110) to display a corresponding visual effect according to the gaze position.
10. The operation method according to claim 9, wherein the gaze position comprises a first coordinate value in a first axial direction and a second coordinate value in a second axial direction.
11. The operation method according to claim 10, wherein the head posture angles comprise a head pitch angle and a head yaw angle, and the rotation reference angles comprise a first pitch angle, a second pitch angle, a first yaw angle, and a second yaw angle corresponding to the predetermined calibration positions.
12. The operation method according to claim 11, wherein the step of calculating the gaze position of the user on the screen (110) according to the head posture angle, the rotation reference angles and the predetermined calibration positions comprises: performing interpolation operation or extrapolation operation according to the first yaw angle, the second yaw angle, a first position corresponding to the first yaw angle among the predetermined calibration positions, a second position corresponding to the second yaw angle among the predetermined calibration positions and the head yaw angle, thereby obtaining the first coordinate value of the gaze position; and performing interpolation operation or extrapolation operation according to the first pitch angle, the second pitch angle, a third position corresponding to the first pitch angle among the predetermined calibration positions, a fourth position corresponding to the second pitch angle among the predetermined calibration positions and the head pitch angle, thereby obtaining the second coordinate value of the gaze position.
13. The operation method according to claim 9, wherein the method further comprises: calculating a plurality of first viewing distances between the user and the screen (110) according to the first facial landmarks; estimating a second viewing distance between the user and the screen (110) according to the second facial landmarks; and adjusting the rotation reference angles or the gaze position according to the second viewing distance and the first viewing distances.
14. The operation method according to claim 9, wherein the method further comprises: mapping a plurality of two-dimensional position coordinates of the second facial landmarks under a plane coordinate system to a plurality of three-dimensional position coordinates under a three-dimensional coordinate system; and estimating the head posture angle according to the three-dimensional position coordinates of the second facial landmarks.
15. The operation method according to claim 9, wherein the second head image comprises a wearable device, and the second facial landmarks do not comprise a plurality of third facial landmarks of the user covered by the wearable device.
16. The operation method according to claim 9, wherein the second head image comprises a wearable device, and the second facial landmarks comprise one or more simulated landmarks marked by the wearable device.
</claims>
</document>
