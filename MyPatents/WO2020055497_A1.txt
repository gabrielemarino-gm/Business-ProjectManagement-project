<document>

<filing_date>
2019-06-28
</filing_date>

<publication_date>
2020-03-19
</publication_date>

<priority_date>
2018-09-13
</priority_date>

<ipc_classes>
G06F16/483,G06F16/683,G06F16/783
</ipc_classes>

<assignee>
MICROSOFT TECHNOLOGY LICENSING
</assignee>

<inventors>
AMI, EYLON
JASSIN, OHAD
LEVI, AVNER
LIN, CHIN-YEW
NIR, ORON
NURIELI, DANIEL
RONEN, ROYI
</inventors>

<docdb_family_id>
67470636
</docdb_family_id>

<title>
INFERRING TOPICS WITH ENTITY LINKING AND ONTOLOGICAL DATA
</title>

<abstract>
Systems and methods are disclosed for inferring topics from a file containing both audio and video, for example a multimodal or multimedia file, in order to facilitate video indexing. A set of entities is extracted from the file and linked to produce a graph, and reference information is also obtained for the set of entities. Entities may be drawn, for example, from Wikipedia categories, or other large ontological data sources. Analysis of the graph, using unsupervised learning, permits determining clusters in the graph. Extracting features from the clusters, possibly using supervised learning, provides for selection of topic identifiers. The topic identifiers are then used for indexing the file.
</abstract>

<claims>
1. A method of inferring topics from a multimodal file, the method comprising: receiving a multimodal file;
extracting a set of entities from the multimodal file;
linking the set of entities to produce a set of linked entities;
obtaining reference information for the set of entities;
based at least on the reference information, generating a graph of the set of linked entities, the graph comprising nodes and edges;
based at least on the nodes and edges of the graph, determining clusters in the graph;
based at least on the clusters in the graph, identifying topic candidates;
extracting features from the clusters in the graph;
based at least on the extracted features, selecting at least one TopicID from among the topic candidates to represent at least one cluster; and
indexing the multimodal file with the at least one TopicID.
2. The method of claim 1 wherein the multimodal file comprises a video portion and an audio portion and wherein extracting a set of entities from the multimodal file comprises:
detecting objects in the video portion of the multimodal file; and
detecting text in the audio portion of the multimodal file.
3. The method of claim 2 wherein detecting objects comprises performing face recognition.
4. The method of claim 2 wherein detecting text comprises performing a speech to text process.
5. The method of claim 4 further comprising:
identifying a language used in the audio portion of the multimodal file, and wherein performing a speech to text process comprises performing a speech to text process in the identified language.
6. The method of claim 4 further comprising:
translating the detected text.
7. The method of claim 1 further comprising:
determining significant clusters and insignificant clusters in the determined clusters, and
wherein extracting features from the clusters in the graph comprises extracting features from the significant clusters in the graph.
8. The method of claim 1 wherein extracting features from the clusters in the graph comprises at least one process selected from the list consisting of:
determining a graph diameter and determining a Jaccard coefficient.
9. The method of claim 1 wherein selecting at least one TopicID to represent at least one cluster comprises:
based at least on the extracted features, mapping topic candidates into a probability interval; and
based at least on the mapping, ranking topic candidates within the at least one cluster, and
selecting the at least one TopicID based at least on the ranking.
10. The method of claim 1 further comprising:
translating the at least one TopicID, and
wherein indexing the multimodal file with the at least one TopicID comprises indexing the multimodal file with the at least one translated TopicID.
11. A system for inferring topics from a multimodal file, the system comprising: an entity extraction component comprising an object detection component and a speech to text component, operative to extract a set of entities from a multimodal file comprising a video portion and an audio portion;
an entity linking component operative to link the extracted set of entities to produce a set of linked entities;
an information retrieval component operative to obtain reference information for the extracted set of entities;
a graphing and analysis component operative to:
generate a graph of the set of linked entities, the graph comprising nodes and edges;
based at least on the nodes and edges of the graph, determine clusters in the graph;
based at least on the clusters in the graph, identify topic candidates; and extract features from the clusters in the graph;
a TopicID selection component operative to:
rank the topic candidates within at least one cluster; and
based at least on the ranking, select at least one TopicID from among the topic candidates to represent at least one cluster; and a video indexer operative to index the multimodal file with the at least one TopicID.
12. The system of claim 11 wherein the object detection component is operative to perform face recognition.
13. The system of claim 11 wherein the speech to text component is operative to extract entity information in at least two different languages.
14. One or more computer storage devices having computer-executable instructions stored thereon for inferring topics from a multimodal file, which, on execution by a computer, cause the computer to perform operations comprising:
receiving a multimodal file comprising a video portion and an audio portion; extracting a set of entities from the multimodal file, wherein extracting a set of entities from the multimodal file comprises:
detecting objects in the video portion of the multimodal file with face recognition;
detecting text in the audio portion of the multimodal file with a speech to text process; and
disambiguating among a set of detected entity names;
linking the set of entities to produce a set of linked entities;
obtaining reference information for the set of entities;
based at least on the reference information, generating a graph of the set of linked entities, the graph comprising nodes and edges;
based at least on the nodes and edges of the graph, determining clusters in the graph;
determining significant clusters and insignificant clusters in the determined clusters;
based at least on the significant clusters in the graph, identifying topic candidates; extracting features from the significant clusters in the graph;
based at least on the extracted features, mapping the topic candidates into a probability interval;
based at least on the mapping, ranking the topic candidates within at least one significant cluster,
based on the ranking, selecting at least one TopicID from among the topic candidates to represent the at least one significant cluster; and
indexing the multimodal file with the at least one TopicID.
15. The one or more computer storage devices of claim 14 wherein the operations further comprise:
identifying a language used in the audio portion of the multimodal file, and detecting text in the audio portion of the multimodal file with a speech to text process comprises performing a speech to text process in the identified language.
</claims>
</document>
